<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>LeeMeng - Lee Meng</title><link href="https://leemeng.tw/" rel="alternate"></link><link href="https://leemeng.tw/feeds/lee-meng.atom.xml" rel="self"></link><id>https://leemeng.tw/</id><updated>2019-07-10T09:00:00+09:00</updated><entry><title>進擊的 BERT：NLP 界的巨人之力與遷移學習</title><link href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" rel="alternate"></link><published>2019-07-10T09:00:00+09:00</published><updated>2019-07-10T09:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-07-10:/attack_on_bert_transfer_learning_in_nlp.html</id><summary type="html">&lt;p&gt;這篇是給所有人的 BERT 科普文以及操作入門手冊。文中將簡單介紹知名的語言代表模型 BERT 以及如何用其實現兩階段的遷移學習。讀者將有機會透過 PyTorch 的程式碼來直觀理解 BERT 的運作方式並實際 fine tune 一個真實存在的假新聞分類任務。閱讀完本文的讀者將能把 BERT 與遷移學習運用到其他自己感興趣的 NLP 任務。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        這是一篇 BERT 科普文，帶你直觀理解並實際運用現在 NLP 領域的巨人之力。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你還有印象，在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;自然語言處理（NLP）與深度學習入門指南&lt;/a&gt;裡我使用了 LSTM 以及 Google 的語言代表模型 &lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt; 來分類中文假新聞。而最後因為 BERT 本身的強大，我不費吹灰之力就在&lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/leaderboard"&gt;該 Kaggle 競賽&lt;/a&gt;達到 85 % 的正確率，距離第一名 3 %，總排名前 30 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/kaggle-final-result.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當初我是使用 &lt;a href="https://github.com/google-research/bert"&gt;TensorFlow 官方釋出的 BERT&lt;/a&gt; 進行 fine tuning，但使用方式並不是那麼直覺。最近適逢 &lt;a href="https://pytorch.org/hub"&gt;PyTorch Hub&lt;/a&gt; 上架 &lt;a href="https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/"&gt;BERT&lt;/a&gt;，李宏毅教授的&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;機器學習課程&lt;/a&gt;也推出了 &lt;a href="https://www.youtube.com/watch?v=UYPa347-DdE"&gt;BERT 的教學影片&lt;/a&gt;，我認為現在正是你了解並&lt;strong&gt;實際運用&lt;/strong&gt; BERT 的最佳時機！&lt;/p&gt;
&lt;p&gt;這篇文章會簡單介紹 BERT 並展示如何使用 BERT 做&lt;a href="https://docs.google.com/presentation/d/1DJI1yX4U5IgApGwavt0AmOCLWwso7ou1Un93sMuAWmA/edit?usp=sharing"&gt;遷移學習（Transfer Learning）&lt;/a&gt;。我在文末也會提供一些有趣的研究及應用 ，讓你可以進一步探索變化快速的 NLP 世界。&lt;/p&gt;
&lt;p&gt;如果你完全不熟 NLP 或是壓根子沒聽過什麼是 BERT，我強力建議你之後找時間（或是現在！）觀看李宏毅教授說明 &lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt;、BERT 以及 &lt;a href="https://github.com/openai/gpt-2"&gt;GPT&lt;/a&gt; 等模型的影片，淺顯易懂：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/UYPa347-DdE"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        李宏毅教授講解目前 NLP 領域的最新研究是如何讓機器讀懂文字的（我超愛這截圖）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我接下來會花點篇幅闡述 BERT 的基礎概念。如果你已經十分熟悉 BERT 而且迫不及待想要馬上將 BERT 應用到自己的 NLP 任務上面，可以直接跳到&lt;a href="#用-BERT-fine-tune-下游任務"&gt;用 BERT fine tune 下游任務&lt;/a&gt;一節。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="BERT：理解上下文的語言代表模型"&gt;BERT：理解上下文的語言代表模型&lt;a class="anchor-link" href="#BERT：理解上下文的語言代表模型"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個簡單的 convention，等等文中會穿插使用的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;代表&lt;/li&gt;
&lt;li&gt;representation&lt;/li&gt;
&lt;li&gt;repr.&lt;/li&gt;
&lt;li&gt;repr. 向量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;指的都是一個可以用來&lt;strong&gt;代表&lt;/strong&gt;某詞彙（在某個語境下）的多維連續向量（continuous vector）。&lt;/p&gt;
&lt;p&gt;現在在 NLP 圈混的，應該沒有人會說自己不曉得 Transformer 的&lt;a href="https://arxiv.org/abs/1706.03762"&gt;經典論文 Attention Is All You Need&lt;/a&gt; 以及其知名的&lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#Encoder-Decoder-%E6%A8%A1%E5%9E%8B-+-%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6"&gt;自注意力機制（Self-attention mechanism）&lt;/a&gt;。&lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT&lt;/a&gt; 全名為 &lt;strong&gt;B&lt;/strong&gt;idirectional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from &lt;strong&gt;T&lt;/strong&gt;ransformers，是 Google 以無監督的方式利用大量無標註文本「煉成」的&lt;strong&gt;語言代表模型&lt;/strong&gt;，其架構為 Transformer 中的 Encoder。&lt;/p&gt;
&lt;p&gt;我在&lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html"&gt;淺談神經機器翻譯 &amp;amp; 用 Transformer 英翻中&lt;/a&gt;一文已經鉅細靡遺地解說過所有 Transformer 的相關概念，這邊就不再贅述。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        BERT 其實就是 Transformer 中的 Encoder，只是有很多層
                        （&lt;a href="https://youtu.be/UYPa347-DdE?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;BERT 是傳統語言模型的一種變形，而&lt;a href="https://youtu.be/iWea12EAu6U"&gt;語言模型（&lt;strong&gt;L&lt;/strong&gt;anguage &lt;strong&gt;M&lt;/strong&gt;odel, LM）&lt;/a&gt;做的事情就是在給定一些詞彙的前提下， 去估計下一個詞彙出現的機率分佈。在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 給我們寫點金庸&lt;/a&gt;裡的 LSTM 也是一個語言模型 ，只是跟 BERT 差了很多個數量級。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/lm-equation.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        給定前 t 個在字典裡的詞彙，語言模型要去估計第 t + 1 個詞彙的機率分佈 P
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為何會想要訓練一個 LM？因為有種種好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;好處 1：無監督數據無限大。不像 &lt;a href="http://www.image-net.org/"&gt;ImageNet&lt;/a&gt; 還要找人標注數據，要訓練 LM 的話網路上所有文本都是你潛在的資料集（BERT 預訓練使用的數據集共有 33 &lt;strong&gt;億&lt;/strong&gt;個字，其中包含維基百科及 &lt;a href="https://arxiv.org/abs/1506.06724"&gt;BooksCorpus&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;好處 2：厲害的 LM 能夠學會語法結構、解讀語義甚至&lt;a href="http://ckip.iis.sinica.edu.tw/project/coreference/"&gt;指代消解&lt;/a&gt;。透過特徵擷取或是 fine-tuning 能更有效率地訓練下游任務並提升其表現&lt;/li&gt;
&lt;li&gt;好處 3：減少處理不同 NLP 任務所需的 architecture engineering 成本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一般人很容易理解前兩點的好處，但事實上第三點的影響也十分深遠。以往為了解決不同的 NLP 任務，我們會為該任務設計一個最適合的神經網路架構並做訓練。以下是一些簡單例子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/model_architecture_nlp_tasks.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一般會依照不同 NLP 任務的性質為其貼身打造特定的模型架構
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我不會介紹上述模型的運作原理，只是想讓你了解不同的 NLP 任務通常需要不同的模型，而設計這些模型並測試其 performance 是非常耗費成本的（人力、時間、計算資源）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如果有一個能直接處理各式 NLP 任務的通用架構該有多好？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;隨著時代演進，不少人很自然地有了這樣子的想法，而 BERT 就是其中一個將此概念付諸實踐的例子。&lt;a href="https://arxiv.org/pdf/1810.04805.pdf"&gt;BERT 論文&lt;/a&gt;的作者們使用 Transfomer Encoder、大量文本以及兩個預訓練目標，事先訓練好一個可以套用到多個 NLP 任務的 BERT 模型，再以此為基礎 fine tune 多個下游任務。&lt;/p&gt;
&lt;p&gt;這就是近來 NLP 領域非常流行的&lt;strong&gt;兩階段&lt;/strong&gt;遷移學習：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先以 LM Pretraining 的方式預先訓練出一個對自然語言有一定「理解」的通用模型&lt;/li&gt;
&lt;li&gt;再將該模型拿來做特徵擷取或是 fine tune 下游的（監督式）任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-2phase.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        兩階段遷移學習在 BERT 下的應用：使用預先訓練好的 BERT 對下游任務做 fine tuning
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面這個示意圖最重要的概念是預訓練步驟跟 fine-tuning 步驟所用的 BERT 是&lt;strong&gt;一模一樣&lt;/strong&gt;的。當你學會使用 BERT 就能用同個架構訓練多種 NLP 任務，大大減少自己設計模型的 architecture engineering 成本，投資報酬率高到爆炸。&lt;/p&gt;
&lt;p&gt;壞消息是，天下沒有白吃的午餐。&lt;/p&gt;
&lt;p&gt;要訓練好一個有 1.1 億參數的 12 層 &lt;strong&gt;BERT-BASE&lt;/strong&gt; 得用 16 個 &lt;a href="https://cloudplatform.googleblog.com/2018/06/Cloud-TPU-now-offers-preemptible-pricing-and-global-availability.html"&gt;TPU chips&lt;/a&gt; 跑上整整 4 天，&lt;a href="https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82"&gt;花費 500 鎂&lt;/a&gt;；24 層的 &lt;strong&gt;BERT-LARGE&lt;/strong&gt; 則有 3.4 億個參數，得用 64 個 TPU chips（約 7000 鎂）訓練。喔對了，別忘了多次實驗得把這些成本乘上幾倍。&lt;a href="https://twitter.com/arnicas/status/1147426600180494337?s=20"&gt;最近也有 NLP 研究者呼籲大家把訓練好的模型開源釋出&lt;/a&gt;以減少重複訓練對環境造成的影響。&lt;/p&gt;
&lt;p&gt;好消息是，BERT 作者們有開源釋出訓練好的模型，只要使用 &lt;a href="https://github.com/google-research/bert"&gt;TensorFlow&lt;/a&gt; 或是 &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;PyTorch&lt;/a&gt; 將已訓練好的 BERT 載入，就能省去預訓練步驟的所有昂貴成本。好 BERT 不用嗎？&lt;/p&gt;
&lt;p&gt;雖然一般來說我們只需要用訓練好的 BERT 做 fine-tuning，稍微瞭解預訓練步驟的內容能讓你直觀地理解它在做些什麼。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-pretrain-tasks.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        BERT 在預訓練時需要完成的兩個任務
                        （&lt;a href="https://youtu.be/UYPa347-DdE?list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Google 在預訓練 BERT 時讓它&lt;strong&gt;同時&lt;/strong&gt;進行兩個任務：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;克漏字填空（&lt;a href="https://journals.sagepub.com/doi/abs/10.1177/107769905303000401"&gt;1953 年被提出的 Cloze task&lt;/a&gt;，學術點的說法是 &lt;strong&gt;M&lt;/strong&gt;asked &lt;strong&gt;L&lt;/strong&gt;anguage &lt;strong&gt;M&lt;/strong&gt;odel, MLM）&lt;/li&gt;
&lt;li&gt;判斷第 2 個句子在原始文本中是否跟第 1 個句子相接（&lt;strong&gt;N&lt;/strong&gt;ext &lt;strong&gt;S&lt;/strong&gt;entence &lt;strong&gt;P&lt;/strong&gt;rediction, NSP）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對上通天文下知地理的鄉民們來說，要完成這兩個任務簡單到爆。只要稍微看一下&lt;strong&gt;前後文&lt;/strong&gt;就能知道左邊克漏字任務的 &lt;code&gt;[MASK]&lt;/code&gt; 裡頭該填 &lt;code&gt;退了&lt;/code&gt;；而 &lt;code&gt;醒醒吧&lt;/code&gt; 後面接 &lt;code&gt;你沒有妹妹&lt;/code&gt; 也十分合情合理。&lt;/p&gt;
&lt;p&gt;讓我們馬上載入 &lt;a href="https://pytorch.org/hub"&gt;PyTorch Hub&lt;/a&gt; 上的 &lt;a href="https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/"&gt;BERT 模型&lt;/a&gt;體驗看看。首先我們需要安裝一些簡單的函式庫：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;%%bash
pip install tqdm boto3 requests regex -q
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著載入中文 BERT 使用的 tokenizer：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;clear_output&lt;/span&gt;

&lt;span class="n"&gt;GITHUB_REPO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"huggingface/pytorch-pretrained-BERT"&lt;/span&gt; &lt;span class="c1"&gt;# 感謝 HuggingFace 團隊造福後人&lt;/span&gt;
&lt;span class="n"&gt;PRETRAINED_MODEL_NAME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"bert-base-chinese"&lt;/span&gt;  &lt;span class="c1"&gt;# 指定繁簡中文 BERT-BASE 預訓練模型&lt;/span&gt;

&lt;span class="c1"&gt;# 取得此預訓練模型所使用的 tokenizer&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GITHUB_REPO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'bertTokenizer'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;PRETRAINED_MODEL_NAME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"PyTorch 版本："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;PyTorch 版本： 1.1.0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你直觀了解 BERT 運作，本文使用包含繁體與簡體中文的預訓練模型。 你可以在 &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/hubconfs/bert_hubconf.py"&gt;Hugging Face 團隊的 repo &lt;/a&gt; 裡看到所有可從 PyTorch Hub 載入的 BERT 預訓練模型。截至目前為止有以下模型可供使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bert-base-chinese&lt;/li&gt;
&lt;li&gt;bert-base-uncased&lt;/li&gt;
&lt;li&gt;bert-base-cased&lt;/li&gt;
&lt;li&gt;bert-base-german-cased&lt;/li&gt;
&lt;li&gt;bert-base-multilingual-uncased&lt;/li&gt;
&lt;li&gt;bert-base-multilingual-cased&lt;/li&gt;
&lt;li&gt;bert-large-cased&lt;/li&gt;
&lt;li&gt;bert-large-uncased&lt;/li&gt;
&lt;li&gt;bert-large-uncased-whole-word-masking&lt;/li&gt;
&lt;li&gt;bert-large-cased-whole-word-masking&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些模型的參數都已經被訓練完成，而主要差別在於：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;預訓練步驟時用的文本語言&lt;/li&gt;
&lt;li&gt;有無分大小寫&lt;/li&gt;
&lt;li&gt;層數的不同&lt;/li&gt;
&lt;li&gt;預訓練時遮住 wordpieces 或是整個 word&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了本文使用的中文 BERT 以外，常被拿來應用與研究的是英文的 &lt;code&gt;bert-base-cased&lt;/code&gt; 模型。&lt;/p&gt;
&lt;p&gt;現在讓我們看看 tokenizer 裡頭的字典資訊：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"字典大小："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;字典大小： 21128
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如上所示，中文 BERT 的字典大小約有 2.1 萬個 tokens。沒記錯的話，英文 BERT 的字典則大約是 3 萬 tokens 左右。我們可以瞧瞧中文 BERT 字典裡頭紀錄的一些 tokens 以及其對應的索引：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="n"&gt;random_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;random_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;random_tokens&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{0:20}{1:15}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"index"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_tokens&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_ids&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{0:15}{1:10}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;id&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;token               index          
-------------------------
看                    4692
##闰                 20368
weeks               11973
##犯                 17363
##嘅                 14703
max                  8621
##朽                 16380
##う                  8981
尾                    2227
佳                     881
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;BERT 使用當初 &lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html"&gt;Google NMT&lt;/a&gt; 提出的 &lt;a href="https://arxiv.org/abs/1609.08144"&gt;WordPiece Tokenization&lt;/a&gt; ，將本來的 words 拆成更小粒度的 wordpieces，有效處理&lt;a href="https://en.wiktionary.org/wiki/OOV"&gt;不在字典裡頭的詞彙&lt;/a&gt; 。中文的話大致上就像是 character-level tokenization，而有 &lt;code&gt;##&lt;/code&gt; 前綴的 tokens 即為 wordpieces。&lt;/p&gt;
&lt;p&gt;以詞彙 &lt;code&gt;fragment&lt;/code&gt; 來說，其可以被拆成 &lt;code&gt;frag&lt;/code&gt; 與 &lt;code&gt;##ment&lt;/code&gt; 兩個 pieces，而一個 word 也可以獨自形成一個 wordpiece。wordpieces 可以由蒐集大量文本並找出其中常見的 pattern 取得。&lt;/p&gt;
&lt;p&gt;另外有趣的是ㄅㄆㄇㄈ也有被收錄：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;647&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;657&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;some_pairs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;vocab&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;pair&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;some_pairs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pair&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;('ㄅ', 647)
('ㄆ', 648)
('ㄇ', 649)
('ㄉ', 650)
('ㄋ', 651)
('ㄌ', 652)
('ㄍ', 653)
('ㄎ', 654)
('ㄏ', 655)
('ㄒ', 656)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們利用中文 BERT 的 tokenizer 將一個中文句子斷詞看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"[CLS] 等到潮水 [MASK] 了，就知道誰沒穿褲子。"&lt;/span&gt;
&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_tokens_to_ids&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ids&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[CLS] 等到潮水 [MASK] 了，就知道誰沒穿褲子。
['[CLS]', '等', '到', '潮', '水', '[MASK]', '了', '，', '就', '知'] ...
[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了一般的 wordpieces 以外，BERT 裡頭有 5 個特殊 tokens 各司其職：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[CLS]&lt;/code&gt;：在做分類任務時其最後一層的 repr. 會被視為整個輸入序列的 repr.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[SEP]&lt;/code&gt;：有兩個句子的文本會被串接成一個輸入序列，並在兩句之間插入這個 token 以做區隔&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[UNK]&lt;/code&gt;：沒出現在 BERT 字典裡頭的字會被這個 token 取代&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[PAD]&lt;/code&gt;：zero padding 遮罩，將長度不一的輸入序列補齊方便做 batch 運算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[MASK]&lt;/code&gt;：未知遮罩，僅在預訓練階段會用到&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如上例所示，&lt;code&gt;[CLS]&lt;/code&gt; 一般會被放在輸入序列的最前面，而 zero padding 在之前的 &lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#%E7%9B%B4%E8%A7%80%E7%90%86%E8%A7%A3%E9%81%AE%E7%BD%A9%E5%9C%A8%E6%B3%A8%E6%84%8F%E5%87%BD%E5%BC%8F%E4%B8%AD%E7%9A%84%E6%95%88%E6%9E%9C"&gt;Transformer 文章裡已經有非常詳細的介紹&lt;/a&gt;。&lt;code&gt;[MASK]&lt;/code&gt; token 一般在 fine-tuning 或是 feature extraction 時不會用到，這邊只是為了展示預訓練階段的克漏字任務才使用的。&lt;/p&gt;
&lt;p&gt;現在馬上讓我們看看給定上面有 &lt;code&gt;[MASK]&lt;/code&gt; 的句子，BERT 會填入什麼字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;這段程式碼載入已經訓練好的 masked 語言模型並對有 [MASK] 的句子做預測&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;

&lt;span class="c1"&gt;# 除了 tokens 以外我們還需要辨別句子的 segment ids&lt;/span&gt;
&lt;span class="n"&gt;tokens_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;ids&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# (1, seq_len)&lt;/span&gt;
&lt;span class="n"&gt;segments_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (1, seq_len)&lt;/span&gt;
&lt;span class="n"&gt;maskedLM_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GITHUB_REPO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                &lt;span class="s1"&gt;'bertForMaskedLM'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                &lt;span class="n"&gt;PRETRAINED_MODEL_NAME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# 使用 masked LM 估計 [MASK] 位置所代表的實際 token &lt;/span&gt;
&lt;span class="n"&gt;maskedLM_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;no_grad&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maskedLM_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segments_tensors&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# (1, seq_len, num_hidden_units)&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;maskedLM_model&lt;/span&gt;

&lt;span class="c1"&gt;# 將 [MASK] 位置的機率分佈取 top k 最有可能的 tokens 出來&lt;/span&gt;
&lt;span class="n"&gt;masked_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;topk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;masked_index&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predicted_tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_ids_to_tokens&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="c1"&gt;# 顯示 top k 可能的字。一般我們就是取 top 1 當作預測值&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"輸入 tokens ："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;'...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_tokens&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;masked_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Top &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt; (&lt;/span&gt;&lt;span class="si"&gt;{:2}&lt;/span&gt;&lt;span class="s2"&gt;%)：&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="s1"&gt;'...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;輸入 tokens ： ['[CLS]', '等', '到', '潮', '水', '[MASK]', '了', '，', '就', '知'] ...
--------------------------------------------------
Top 1 (67%)：['[CLS]', '等', '到', '潮', '水', '來', '了', '，', '就', '知'] ...
Top 2 (25%)：['[CLS]', '等', '到', '潮', '水', '濕', '了', '，', '就', '知'] ...
Top 3 ( 2%)：['[CLS]', '等', '到', '潮', '水', '過', '了', '，', '就', '知'] ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Google 在訓練中文 BERT 鐵定沒看&lt;a href="https://term.ptt.cc/"&gt;批踢踢&lt;/a&gt;，還無法預測出我們最想要的那個 &lt;code&gt;退&lt;/code&gt; 字。而最接近的 &lt;code&gt;過&lt;/code&gt; 的出現機率只有 2%，但我會說以語言代表模型以及自然語言理解的角度來看這結果已經不差了。BERT 透過關注 &lt;code&gt;潮&lt;/code&gt; 與 &lt;code&gt;水&lt;/code&gt; 這兩個字，從 2 萬多個 wordpieces 的可能性中選出 &lt;code&gt;來&lt;/code&gt; 作為這個情境下 &lt;code&gt;[MASK]&lt;/code&gt; token 的預測值 ，也還算說的過去。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-attention.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是 &lt;a href="https://github.com/jessevig/bertviz"&gt;BertViz&lt;/a&gt; 視覺化 BERT 注意力的結果，我等等會列出安裝步驟讓你自己玩玩。值得一提的是，以上是第 8 層 Encoder block 中 &lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html#Multi-head-attention%EF%BC%9A%E4%BD%A0%E7%9C%8B%E4%BD%A0%E7%9A%84%EF%BC%8C%E6%88%91%E7%9C%8B%E6%88%91%E7%9A%84"&gt;Multi-head attention&lt;/a&gt; 裡頭某一個 head 的自注意力結果。並不是每個 head 都會關注在一樣的位置。透過 multi-head 自注意力機制，BERT 可以讓不同 heads 在不同的 representation subspaces 裡學會關注不同位置的不同 repr.。&lt;/p&gt;
&lt;p&gt;學會填克漏字讓 BERT 更好地 model 每個詞彙在不同語境下該有的 repr.，而 NSP 任務則能幫助 BERT model 兩個句子之間的關係，這在&lt;a href="https://zh.wikipedia.org/wiki/%E5%95%8F%E7%AD%94%E7%B3%BB%E7%B5%B1"&gt;問答系統 QA&lt;/a&gt;、&lt;a href="http://nlpprogress.com/english/natural_language_inference.html"&gt;自然語言推論 NLI &lt;/a&gt;或是後面我們會看到的&lt;a href="#用-BERT-fine-tune-下游任務"&gt;假新聞分類任務&lt;/a&gt;都很有幫助。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣的 word repr. 就是近年十分盛行的 &lt;a href="https://youtu.be/S-CspeZ8FHc"&gt;contextual word representation&lt;/a&gt; 概念。跟以往沒有蘊含上下文資訊的 &lt;a href="https://youtu.be/8rXD5-xhemo"&gt;Word2Vec、GloVe&lt;/a&gt; 等無語境的詞嵌入向量有很大的差異。用稍微學術一點的說法就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        Contextual word repr. 讓同 word type 的 word token 在不同語境下有不同的表示方式；而傳統的詞向量無論上下文，都會讓同 type 的 word token 的 repr. 相同。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;直覺上 contextual word representation 比較能反映人類語言的真實情況，畢竟同個詞彙的含義在不同情境下相異是再正常不過的事情。在不同語境下給同個詞彙相同的 word repr. 這件事情在近年的 NLP 領域裡頭顯得越來越不合理。&lt;/p&gt;
&lt;p&gt;為了讓你加深印象，讓我再舉個具體的例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;情境 1：

胖虎叫大雄去買漫畫，回來慢了就打他。

情境 2：

妹妹說胖虎是「胖子」，他聽了很不開心。
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;很明顯地，在這兩個情境裡頭「他」所代表的語義以及指稱的對象皆不同。如果仍使用沒蘊含上下文 / 語境資訊的詞向量，機器就會很難正確地「解讀」這兩個句子所蘊含的語義了。&lt;/p&gt;
&lt;p&gt;現在讓我們跟隨&lt;a href="https://colab.research.google.com/drive/1g2nhY9vZG-PLC3w3dcHGqwsHBAXnD9EY"&gt;這個 Colab 筆記本&lt;/a&gt;安裝 BERT 的視覺化工具 &lt;a href="https://github.com/jessevig/bertviz"&gt;BertViz&lt;/a&gt;，看看 BERT 會怎麼處理這兩個情境：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 安裝 BertViz&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="nb"&gt;test&lt;/span&gt; -d bertviz_repo &lt;span class="o"&gt;||&lt;/span&gt; git clone https://github.com/jessevig/bertviz bertviz_repo
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="s1"&gt;'bertviz_repo'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'bertviz_repo'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# import packages&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bertviz.pytorch_pretrained_bert&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BertModel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BertTokenizer&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bertviz.head_view_bert&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;

&lt;span class="c1"&gt;# 在 jupyter notebook 裡頭顯示 visualzation 的 helper&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call_html&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;IPython&lt;/span&gt;
  &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;IPython&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;core&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HTML&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'''&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;lt;script src="/static/components/requirejs/require.js"&amp;gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;lt;script&amp;gt;&lt;/span&gt;
&lt;span class="s1"&gt;          requirejs.config({&lt;/span&gt;
&lt;span class="s1"&gt;            paths: {&lt;/span&gt;
&lt;span class="s1"&gt;              base: '/static/base',&lt;/span&gt;
&lt;span class="s1"&gt;              "d3": "https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min",&lt;/span&gt;
&lt;span class="s1"&gt;              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',&lt;/span&gt;
&lt;span class="s1"&gt;            },&lt;/span&gt;
&lt;span class="s1"&gt;          });&lt;/span&gt;
&lt;span class="s1"&gt;        &amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;span class="s1"&gt;        '''&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Setup 以後就能非常輕鬆地將 BERT 內部的注意力機制視覺化出來：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 記得我們是使用中文 BERT&lt;/span&gt;
&lt;span class="n"&gt;bert_version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'bert-base-chinese'&lt;/span&gt;
&lt;span class="n"&gt;bertviz_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BertModel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_pretrained&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bert_version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bertviz_tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BertTokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_pretrained&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bert_version&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 情境 1 的句子&lt;/span&gt;
&lt;span class="n"&gt;sentence_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"胖虎叫大雄去買漫畫，"&lt;/span&gt;
&lt;span class="n"&gt;sentence_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"回來慢了就打他。"&lt;/span&gt;
&lt;span class="n"&gt;call_html&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bertviz_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bertviz_tokenizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence_b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 注意：執行這段程式碼以後只會顯示下圖左側的結果。&lt;/span&gt;
&lt;span class="c1"&gt;# 為了方便你比較，我把情境 2 的結果也同時附上&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-coreference.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是 BERT 裡第 9 層 Encoder block 其中一個 head 的注意力結果。&lt;/p&gt;
&lt;p&gt;圖中的線條代表該 head 在更新「他」（左側）的 repr. 時關注其他詞彙（右側）的注意力程度。越粗代表關注權重（attention weights）越高。很明顯地這個 head 具有一定的&lt;a href="https://youtu.be/i19m4GzBhfc"&gt;指代消解（Coreference Resolution）&lt;/a&gt;能力，能正確地關注「他」所指代的對象。&lt;/p&gt;
&lt;p&gt;要處理指代消解需要對自然語言有不少理解，而 BERT 在沒有標注數據的情況下透過自注意力機制、深度雙向語言模型以及「閱讀」大量文本達到這樣的水準，是一件令人雀躍的事情。&lt;/p&gt;
&lt;p&gt;當然 BERT 並不是第一個嘗試產生 contextual word repr. 的語言模型。在它之前最知名的例子有剛剛提到的 &lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt; 以及 &lt;a href="https://github.com/openai/gpt-2"&gt;GPT&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert_elmo_gpt.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        ELMo、GPT 以及 BERT 都透過訓練語言模型來獲得 contextual word representation
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;ELMo 利用獨立訓練的雙向兩層 LSTM  做語言模型並將中間得到的隱狀態向量串接當作每個詞彙的 contextual word repr.；GPT 則是使用 Transformer 的 Decoder 來訓練一個中規中矩從左到右的語言模型。&lt;/p&gt;
&lt;p&gt;BERT 跟它們的差異在於利用 MLM（即克漏字）的概念及 Transformer Encoder 的架構，擺脫以往語言模型只能從單個方向（由左到右或由右到左）估計下個詞彙出現機率的窘境，訓練出一個&lt;strong&gt;雙向&lt;/strong&gt;的語言代表模型。這使得 BERT 輸出的每個 token 的 repr. &lt;code&gt;Tn&lt;/code&gt; 都同時蘊含了前後文資訊，真正的&lt;strong&gt;雙向&lt;/strong&gt; representation。&lt;/p&gt;
&lt;p&gt;跟以往模型相比，BERT 能更好地處理自然語言，在著名的問答任務 &lt;a href="https://rajpurkar.github.io/SQuAD-explorer/"&gt;SQuAD2.0&lt;/a&gt; 也有卓越表現：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/squad2.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        SQuAD 2.0 目前排行榜的前 5 名有 4 個有使用 BERT
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想我又犯了解說癖，這些東西你可能在看這篇文章之前就全懂了。但希望這些對 BERT 的 high level 介紹能幫助更多人直覺地理解 BERT 的強大之處以及為何值得學習它。&lt;/p&gt;
&lt;p&gt;假如你仍然似懂非懂，只需記得：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        BERT 是一個強大的語言代表模型，給它一段文本序列，它能回傳一段相同長度且蘊含上下文資訊的 word repr. 序列，對下游的 NLP 任務很有幫助。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這樣的概念以後，我們接下來要做的事情很簡單，就是將自己感興趣的 NLP 任務的文本丟入 BERT ，為文本裡頭的每個 token 取得有語境的 word repr.，並以此 repr. 進一步 fine tune 當前任務，取得更好的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用-BERT-fine-tune-下游任務"&gt;用 BERT fine tune 下游任務&lt;a class="anchor-link" href="#用-BERT-fine-tune-下游任務"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;給所有人的 NLP 入門指南&lt;/a&gt;碰過的&lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/submissions"&gt;假新聞分類任務&lt;/a&gt;將會是本文拿 BERT 來做 fine-tuning 的例子。選擇這個任務的最主要理由是因為中文數據容易理解，另外網路上針對兩個句子做分類的例子也較少。&lt;/p&gt;
&lt;p&gt;就算你對假新聞分類沒興趣也建議繼續閱讀。因為本節談到的所有概念完全可以被套用到其他語言的文本以及不同的 NLP 任務之上。因此我希望接下來你能一邊閱讀一邊想像如何用同樣的方式把 BERT 拿來處理你自己感興趣的 NLP 任務。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/view-data-on-kaggle.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        給定假新聞 title1，判斷另一新聞 title2 跟 title1 的關係（同意、反對或無關）
                        （&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;fine tune BERT 來解決新的下游任務有 5 個簡單步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#1.-準備原始文本數據"&gt;準備原始文本數據&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2.-將原始文本轉換成-BERT-相容的輸入格式"&gt;將原始文本轉換成 BERT 相容的輸入格式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3.-在-BERT-之上加入新-layer-成下游任務模型"&gt;在 BERT 之上加入新 layer 成下游任務模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4.-訓練該下游任務模型"&gt;訓練該下游任務模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5.-對新樣本做推論"&gt;對新樣本做推論&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;對，就是那麼直覺。而且你應該已經看出步驟 1、4 及 5 都跟訓練一般模型所需的步驟無太大差異。跟 BERT 最相關的細節事實上是步驟 2 跟 3：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何將原始數據轉換成 &lt;strong&gt;BERT 相容&lt;/strong&gt;的輸入格式？&lt;/li&gt;
&lt;li&gt;如何在 BERT 之上建立 layer(s) 以符合下游任務需求？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;事不宜遲，讓我們馬上以假新聞分類任務為例回答這些問題。&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;我在之前的文章已經說明過&lt;/a&gt;，這個任務的輸入是兩個句子，輸出是 3 個類別機率的多類別分類任務（multi-class classification task），跟 NLP 領域裡常見的&lt;a href="https://paperswithcode.com/task/natural-language-inference/latest"&gt;自然語言推論（Natural Language Inference）&lt;/a&gt;具有相同性質。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="1.-準備原始文本數據"&gt;1. 準備原始文本數據&lt;a class="anchor-link" href="#1.-準備原始文本數據"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了最大化再現性（reproducibility）以及幫助有興趣的讀者深入研究，我會列出所有的程式碼，你只要複製貼上就能完整重現文中所有結果並生成能提交到 Kaggle 競賽的預測檔案。你當然也可以選擇直接閱讀，不一定要下載數據。&lt;/p&gt;
&lt;p&gt;因為 Kaggle 網站本身的限制，我無法直接提供數據載點。如果你想要跟著本文練習以 BERT fine tune 一個假新聞的分類模型，可以先&lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/data"&gt;前往該 Kaggle 競賽下載資料集&lt;/a&gt;。下載完數據你的資料夾裡應該會有兩個壓縮檔，分別代表訓練集和測試集：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;glob&lt;/span&gt;
&lt;span class="n"&gt;glob&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;glob&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"*.csv.zip"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['test.csv.zip', 'train.csv.zip']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著就是我實際處理訓練資料集的程式碼。再次申明，你只需稍微瀏覽註解並感受一下處理邏輯即可，no pressure。&lt;/p&gt;
&lt;p&gt;因為競賽早就結束，我們不必花費時間衝高分數。比起衝高準確度，讓我們做點有趣的事情：從 32 萬筆訓練數據裡頭隨機抽樣 1 % 來讓 BERT 學怎麼分類假新聞。&lt;/p&gt;
&lt;p&gt;我們可以看看 BERT 本身的語言理解能力對只有少量標註數據的任務有什麼幫助：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;前處理原始的訓練數據集。&lt;/span&gt;
&lt;span class="sd"&gt;你不需了解細節，只需要看註解了解邏輯或是輸出的數據格式即可&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="c1"&gt;# 解壓縮從 Kaggle 競賽下載的訓練壓縮檔案&lt;/span&gt;
&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"unzip train.csv.zip"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 簡單的數據清理，去除空白標題的 examples&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;empty_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isnull&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; \
               &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isnull&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; \
               &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
               &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'0'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="n"&gt;empty_title&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 剔除過長的樣本以避免 BERT 無法將整個輸入序列放入記憶體不多的 GPU&lt;/span&gt;
&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title1_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title2_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="c1"&gt;# 只用 1% 訓練數據看看 BERT 對少量標註數據有多少幫助&lt;/span&gt;
&lt;span class="n"&gt;SAMPLE_FRAC&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.01&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frac&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_FRAC&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;9527&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 去除不必要的欄位並重新命名兩標題的欄位名&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'label'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'text_a'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'text_b'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'label'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train.tsv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"訓練樣本數："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/df_train.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事情變得更有趣了。因為我們在抽樣 1 % 的數據後還將過長的樣本去除，實際上會被拿來訓練的樣本數只有 2,657 筆，佔不到參賽時可以用的訓練數據的 1 %，是非常少量的數據。&lt;/p&gt;
&lt;p&gt;我們也可以看到 &lt;code&gt;unrelated&lt;/code&gt; 的樣本佔了 68 %，因此我們用 BERT 訓練出來的分類器最少最少要超過多數決的 68 % baseline 才行：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;value_counts&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;unrelated    0.679338
agreed       0.294317
disagreed    0.026346
Name: label, dtype: float64&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著我也對最後要預測的測試集做些非常基本的前處理，方便之後提交符合競賽要求的格式。你也不需了解所有細節，只要知道我們最後要預測 8 萬筆樣本：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"unzip test.csv.zip"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"test.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"title1_zh"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"title2_zh"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"id"&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"text_a"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"text_b"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Id"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"test.tsv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"預測樣本數："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/df_test.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ratio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"測試集樣本數 / 訓練集樣本數 = &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s2"&gt; 倍"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ratio&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;測試集樣本數 / 訓練集樣本數 = 30.2 倍
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為測試集的樣本數是我們迷你訓練集的 30 倍之多，後面你會看到反而是推論需要花費比較久的時間，模型本身一下就訓練完了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="2.-將原始文本轉換成-BERT-相容的輸入格式"&gt;2. 將原始文本轉換成 BERT 相容的輸入格式&lt;a class="anchor-link" href="#2.-將原始文本轉換成-BERT-相容的輸入格式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;處理完原始數據以後，最關鍵的就是了解如何讓 BERT 讀取這些數據以做訓練和推論。這時候我們需要了解 BERT 的輸入編碼格式。&lt;/p&gt;
&lt;p&gt;這步驟是本文的精華所在，你將看到在其他只單純說明 BERT 概念的文章不會提及的所有實務細節。以下是&lt;a href="https://arxiv.org/pdf/1810.04805.pdf"&gt;原論文&lt;/a&gt;裡頭展示的成對句子編碼示意圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/practical_bert_encoding_for_pytorch.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        加入 PyTorch 使用細節的 BERT 成對句子編碼示意圖
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第二條分隔線&lt;strong&gt;之上&lt;/strong&gt;的內容是論文裡展示的例子。圖中的每個 Token Embedding 都對應到前面提過的一個 wordpiece，而 Segment Embeddings 則代表不同句子的位置，是學出來的。Positional Embeddings 則跟其他 Transformer 架構中出現的位置編碼同出一轍。&lt;/p&gt;
&lt;p&gt;實際運用 PyTorch 的 BERT 時最重要的則是在第二條分隔線&lt;strong&gt;之下&lt;/strong&gt;的資訊。我們需要將原始文本轉換成  &lt;strong&gt;3 種 id tensors&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;tokens_tensor&lt;/code&gt;：代表識別每個 token 的索引值，用 tokenizer 轉換即可&lt;/li&gt;
&lt;li&gt;&lt;code&gt;segments_tensor&lt;/code&gt;：用來識別句子界限。第一句為 0，第二句則為 1。另外注意句子間的 &lt;code&gt;[SEP]&lt;/code&gt; 為 0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;masks_tensor&lt;/code&gt;：用來界定自注意力機制範圍。1 讓 BERT 關注該位置，0 則代表是 padding 不需關注&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;論文裡的例子並沒有說明 &lt;code&gt;[PAD]&lt;/code&gt; token，但實務上每個 batch 裡頭的輸入序列長短不一，為了讓 GPU 平行運算我們需要將 batch 裡的每個輸入序列都補上 zero padding 以保證它們長度一致。另外 &lt;code&gt;masks_tensor&lt;/code&gt; 以及 &lt;code&gt;segments_tensor&lt;/code&gt; 在 &lt;code&gt;[PAD]&lt;/code&gt; 對應位置的值也都是 0，切記切記。&lt;/p&gt;
&lt;p&gt;有了這些背景知識以後，要實作一個 &lt;code&gt;Dataset&lt;/code&gt; 並將原始文本轉換成 BERT 相容的格式就變得十分容易了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。&lt;/span&gt;
&lt;span class="sd"&gt;此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：&lt;/span&gt;
&lt;span class="sd"&gt;- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]&lt;/span&gt;
&lt;span class="sd"&gt;- segments_tensor：可以用來識別兩個句子界限的 binary tensor&lt;/span&gt;
&lt;span class="sd"&gt;- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torch.utils.data&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Dataset&lt;/span&gt;
 
    
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;FakeNewsDataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 讀取前處理後的 tsv 檔並初始化一些參數&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"train"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"test"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;# 一般訓練你會需要 dev set&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt;
        &lt;span class="c1"&gt;# 大數據你會需要用 iterator=True&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;".tsv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fillna&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'agreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'disagreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'unrelated'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;  &lt;span class="c1"&gt;# 我們將使用 BERT tokenizer&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 定義回傳一筆訓練 / 測試數據的函式&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__getitem__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"test"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;text_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
            &lt;span class="n"&gt;label_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;text_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;
            &lt;span class="c1"&gt;# 將 label 文字也轉換成索引方便轉換成 tensor&lt;/span&gt;
            &lt;span class="n"&gt;label_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;label_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            
        &lt;span class="c1"&gt;# 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]&lt;/span&gt;
        &lt;span class="n"&gt;word_pieces&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"[CLS]"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;tokens_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;word_pieces&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tokens_a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"[SEP]"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;len_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word_pieces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="c1"&gt;# 第二個句子的 BERT tokens&lt;/span&gt;
        &lt;span class="n"&gt;tokens_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;word_pieces&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tokens_b&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"[SEP]"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;len_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word_pieces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;len_a&lt;/span&gt;
        
        &lt;span class="c1"&gt;# 將整個 token 序列轉換成索引序列&lt;/span&gt;
        &lt;span class="n"&gt;ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_tokens_to_ids&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word_pieces&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tokens_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ids&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="c1"&gt;# 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句&lt;/span&gt;
        &lt;span class="n"&gt;segments_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tensor&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;len_a&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;len_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;long&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segments_tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label_tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__len__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;
    
    
&lt;span class="c1"&gt;# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞&lt;/span&gt;
&lt;span class="n"&gt;trainset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FakeNewsDataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這段程式碼不難，我也很想硬掰些台詞撐撐場面，但該說的重點都寫成註解給你看了。如果你想要把自己手上的文本轉換成 BERT 看得懂的東西，那徹底理解這個 &lt;code&gt;Dataset&lt;/code&gt; 的實作邏輯就非常重要了。&lt;/p&gt;
&lt;p&gt;現在讓我們看看第一個訓練樣本轉換前後的格式差異：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 選擇第一個樣本&lt;/span&gt;
&lt;span class="n"&gt;sample_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

&lt;span class="c1"&gt;# 將原始文本拿出做比較&lt;/span&gt;
&lt;span class="n"&gt;text_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trainset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sample_idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;

&lt;span class="c1"&gt;# 利用剛剛建立的 Dataset 取出轉換後的 id tensors&lt;/span&gt;
&lt;span class="n"&gt;tokens_tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segments_tensor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label_tensor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;trainset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sample_idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 將 tokens_tensor 還原成文本&lt;/span&gt;
&lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_ids_to_tokens&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;combined_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;""&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"""[原始文本]&lt;/span&gt;
&lt;span class="s2"&gt;句子 1：&lt;/span&gt;&lt;span class="si"&gt;{text_a}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;句子 2：&lt;/span&gt;&lt;span class="si"&gt;{text_b}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;分類  ：&lt;/span&gt;&lt;span class="si"&gt;{label}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;--------------------&lt;/span&gt;

&lt;span class="s2"&gt;[Dataset 回傳的 tensors]&lt;/span&gt;
&lt;span class="s2"&gt;tokens_tensor  ：&lt;/span&gt;&lt;span class="si"&gt;{tokens_tensor}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;segments_tensor：&lt;/span&gt;&lt;span class="si"&gt;{segments_tensor}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;label_tensor   ：&lt;/span&gt;&lt;span class="si"&gt;{label_tensor}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;--------------------&lt;/span&gt;

&lt;span class="s2"&gt;[還原 tokens_tensors]&lt;/span&gt;
&lt;span class="si"&gt;{combined_text}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[原始文本]
句子 1：苏有朋要结婚了，但网友觉得他还是和林心如比较合适
句子 2：好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！
分類  ：unrelated

--------------------

[Dataset 回傳的 tensors]
tokens_tensor  ：tensor([ 101, 5722, 3300, 3301, 6206, 5310, 2042,  749, 8024,  852, 5381, 1351,
        6230, 2533,  800, 6820, 3221, 1469, 3360, 2552, 1963, 3683, 6772, 1394,
        6844,  102, 1962, 7318, 6057, 5310, 2042, 5314,  679, 2042, 3184, 4638,
        4912, 2269, 2803, 5709, 4413, 8024,  948, 7450, 4638, 4912, 2269, 2957,
        3717, 7027, 5010, 1526, 5722, 3300, 3301, 8013,  102])

segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1])

label_tensor   ：2

--------------------

[還原 tokens_tensors]
[CLS]苏有朋要结婚了，但网友觉得他还是和林心如比较合适[SEP]好闺蜜结婚给不婚族的秦岚扔花球，倒霉的秦岚掉水里笑哭苏有朋！[SEP]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，我很雞婆地幫你把處理前後的差異都列了出來，你現在應該了解我們定義的 &lt;code&gt;trainset&lt;/code&gt; 回傳的 tensors 跟原始文本之間的關係了吧！如果你之後想要一行行解析上面我定義的這個 &lt;code&gt;Dataset&lt;/code&gt;，強烈建議安裝在 Github 上已經得到超過 1 萬星的 &lt;a href="https://github.com/cool-RR/PySnooper"&gt;PySnooper&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;!&lt;/span&gt;&lt;span class="n"&gt;pip&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;pysnooper&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pysnooper&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;FakeNewsDataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="nd"&gt;@pysnooper.snoop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# 加入以了解所有轉換過程&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__getitem__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;加上 &lt;code&gt;@pysnooper.snoop()&lt;/code&gt;、重新定義 &lt;code&gt;FakeNewsDataset&lt;/code&gt;、初始化一個新的 &lt;code&gt;trainset&lt;/code&gt; 並將第一個樣本取出即可看到這樣的 logging 訊息：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/debug_with_pysnooper.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用 PySnooper 讓你輕鬆了解怎麼將原始文本變得「 BERT 相容」
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了 &lt;code&gt;Dataset&lt;/code&gt; 以後，我們還需要一個 &lt;code&gt;DataLoader&lt;/code&gt; 來回傳成一個個的 mini-batch。畢竟我們不可能一次把整個數據集塞入 GPU，對吧？&lt;/p&gt;
&lt;p&gt;痾 ... 你剛剛應該沒有打算這麼做吧？&lt;/p&gt;
&lt;p&gt;除了上面的 &lt;code&gt;FakeNewsDataset&lt;/code&gt; 實作以外，以下的程式碼是你在想將 BERT 應用到自己的 NLP 任務時會需要徹底搞懂的部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;實作可以一次回傳一個 mini-batch 的 DataLoader&lt;/span&gt;
&lt;span class="sd"&gt;這個 DataLoader 吃我們上面定義的 `FakeNewsDataset`，&lt;/span&gt;
&lt;span class="sd"&gt;回傳訓練 BERT 時會需要的 4 個 tensors：&lt;/span&gt;
&lt;span class="sd"&gt;- tokens_tensors  : (batch_size, max_seq_len_in_batch)&lt;/span&gt;
&lt;span class="sd"&gt;- segments_tensors: (batch_size, max_seq_len_in_batch)&lt;/span&gt;
&lt;span class="sd"&gt;- masks_tensors   : (batch_size, max_seq_len_in_batch)&lt;/span&gt;
&lt;span class="sd"&gt;- label_ids       : (batch_size)&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torch.utils.data&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DataLoader&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;torch.nn.utils.rnn&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pad_sequence&lt;/span&gt;

&lt;span class="c1"&gt;# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是&lt;/span&gt;
&lt;span class="c1"&gt;# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：&lt;/span&gt;
&lt;span class="c1"&gt;# - tokens_tensor&lt;/span&gt;
&lt;span class="c1"&gt;# - segments_tensor&lt;/span&gt;
&lt;span class="c1"&gt;# - label_tensor&lt;/span&gt;
&lt;span class="c1"&gt;# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_mini_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;tokens_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;segments_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 測試集有 labels&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;label_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;samples&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;label_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
    
    &lt;span class="c1"&gt;# zero pad 到同一序列長度&lt;/span&gt;
    &lt;span class="n"&gt;tokens_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pad_sequence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                  &lt;span class="n"&gt;batch_first&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;segments_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pad_sequence&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;segments_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                    &lt;span class="n"&gt;batch_first&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# attention masks，將 tokens_tensors 裡頭不為 zero padding&lt;/span&gt;
    &lt;span class="c1"&gt;# 的位置設為 1 讓 BERT 只關注這些位置的 tokens&lt;/span&gt;
    &lt;span class="n"&gt;masks_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens_tensors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;long&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;masks_tensors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;masks_tensors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;masked_fill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tokens_tensors&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tokens_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segments_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;masks_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label_ids&lt;/span&gt;


&lt;span class="c1"&gt;# 初始化一個每次回傳 64 個訓練樣本的 DataLoader&lt;/span&gt;
&lt;span class="c1"&gt;# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="n"&gt;trainloader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DataLoader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trainset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                         &lt;span class="n"&gt;collate_fn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;create_mini_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;加上註解，我相信這應該是你在整個網路上能看到最平易近人的實作了。這段程式碼是你要實際將 mini-batch 丟入 BERT 做訓練以及預測的關鍵，務必搞清楚每一行在做些什麼。&lt;/p&gt;
&lt;p&gt;有了可以回傳 mini-batch 的 &lt;code&gt;DataLoader&lt;/code&gt; 後，讓我們馬上拿出一個 batch 看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;trainloader&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;tokens_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;segments_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
    &lt;span class="n"&gt;masks_tensors&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label_ids&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;tokens_tensors.shape   = &lt;/span&gt;&lt;span class="si"&gt;{tokens_tensors.shape}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;
&lt;span class="si"&gt;{tokens_tensors}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;------------------------&lt;/span&gt;
&lt;span class="s2"&gt;segments_tensors.shape = &lt;/span&gt;&lt;span class="si"&gt;{segments_tensors.shape}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="si"&gt;{segments_tensors}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;------------------------&lt;/span&gt;
&lt;span class="s2"&gt;masks_tensors.shape    = &lt;/span&gt;&lt;span class="si"&gt;{masks_tensors.shape}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="si"&gt;{masks_tensors}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;------------------------&lt;/span&gt;
&lt;span class="s2"&gt;label_ids.shape        = &lt;/span&gt;&lt;span class="si"&gt;{label_ids.shape}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="si"&gt;{label_ids}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
tokens_tensors.shape   = torch.Size([64, 63]) 
tensor([[ 101, 5722, 3300,  ...,    0,    0,    0],
        [ 101, 4255, 3160,  ..., 8013,  102,    0],
        [ 101,  711, 2506,  ..., 8013,  102,    0],
        ...,
        [ 101,  671, 2157,  ...,    0,    0,    0],
        [ 101, 1380,  677,  ...,    0,    0,    0],
        [ 101, 2458, 1853,  ...,    0,    0,    0]])
------------------------
segments_tensors.shape = torch.Size([64, 63])
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 1, 1, 0],
        [0, 0, 0,  ..., 1, 1, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]])
------------------------
masks_tensors.shape    = torch.Size([64, 63])
tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        [1, 1, 1,  ..., 1, 1, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]])
------------------------
label_ids.shape        = torch.Size([64])
tensor([2, 0, 2, 2, 1, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,
        2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0,
        0, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0])

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;建立 BERT 用的 mini-batch 時最需要注意的就是 zero padding 的存在了。你可以發現除了 &lt;code&gt;lable_ids&lt;/code&gt; 以外，其他 3 個 tensors 的每個樣本的最後大都為 0，這是因為每個樣本的 tokens 序列基本上長度都會不同，需要補 padding。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/from_raw_data_to_bert_compatible.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止我們已經成功地將原始文本轉換成 BERT 相容的輸入格式了。這節是本篇文章最重要，也最需要花點時間咀嚼的內容。在有這些 tensors 的前提下，要在 BERT 之上訓練我們自己的下游任務完全是一塊蛋糕。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="3.-在-BERT-之上加入新-layer-成下游任務模型"&gt;3. 在 BERT 之上加入新 layer 成下游任務模型&lt;a class="anchor-link" href="#3.-在-BERT-之上加入新-layer-成下游任務模型"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我從&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;李宏毅教授講解 BERT 的投影片&lt;/a&gt;中擷取出&lt;a href="https://arxiv.org/pdf/1810.04805.pdf"&gt;原論文&lt;/a&gt;提到的 4 種 fine-tuning BERT 情境，並整合了一些有用資訊：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert_fine_tuning_tasks.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在 4 種 NLP 任務上 fine-tuning BERT 的例子
                        （&lt;a href="https://www.youtube.com/watch?v=UYPa347-DdE" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資訊量不少，但我假設你在&lt;a href="https://youtu.be/UYPa347-DdE"&gt;前面教授的 BERT 影片&lt;/a&gt;或是其他地方已經看過類似的圖。&lt;/p&gt;
&lt;p&gt;首先，我們前面一直提到的 fine-tuning BERT 指的是在&lt;strong&gt;預訓練完&lt;/strong&gt;的 BERT 之上加入新的線性分類器（Linear Classifier），並利用下游任務的目標函式&lt;strong&gt;從頭&lt;/strong&gt;訓練分類器並&lt;strong&gt;微調&lt;/strong&gt; BERT 的參數。這樣做的目的是讓整個模型（BERT + Linear Classifier）能一起最大化當前下游任務的目標。&lt;/p&gt;
&lt;p&gt;圖中紅色小字則是該任務類型常被拿來比較的資料集，比方說 &lt;a href="https://www.nyu.edu/projects/bowman/multinli/"&gt;MNLI&lt;/a&gt; 及 &lt;a href="https://rajpurkar.github.io/SQuAD-explorer/explore/1.1/dev/"&gt;SQuAD v1.1&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;不過現在對我們來說最重要的是圖中的藍色字體。多虧了 &lt;a href="https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/"&gt;HuggingFace 團隊&lt;/a&gt;，要用 PyTorch fine-tuing BERT 是件非常容易的事情。每個藍色字體都對應到一個可以處理下游任務的&lt;strong&gt;模型&lt;/strong&gt;，而這邊說的模型指的是&lt;strong&gt;已訓練的 BERT + Linear Classifier&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;按圖索驥，因為假新聞分類是一個成對句子分類任務，自然就對應到上圖的左下角。&lt;code&gt;FINETUNE_TASK&lt;/code&gt; 則為 bertForSequenceClassification：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 載入一個可以做中文多分類任務的模型，n_class = 3&lt;/span&gt;
&lt;span class="n"&gt;GITHUB_REPO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"huggingface/pytorch-pretrained-BERT"&lt;/span&gt;
&lt;span class="n"&gt;PRETRAINED_MODEL_NAME&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"bert-base-chinese"&lt;/span&gt;
&lt;span class="n"&gt;FINETUNE_TASK&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"bertForSequenceClassification"&lt;/span&gt;

&lt;span class="n"&gt;NUM_LABELS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hub&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;GITHUB_REPO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                       &lt;span class="n"&gt;FINETUNE_TASK&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                       &lt;span class="n"&gt;PRETRAINED_MODEL_NAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                       &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;NUM_LABELS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# high-level 顯示此模型裡的 modules&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;name            module&lt;/span&gt;
&lt;span class="s2"&gt;----------------------"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;named_children&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"bert"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;named_children&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{name}&lt;/span&gt;&lt;span class="s2"&gt;:&lt;/span&gt;&lt;span class="si"&gt;{n}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{:15}&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
name            module
----------------------
bert:embeddings
bert:encoder
bert:pooler
dropout         Dropout(p=0.1)
classifier      Linear(in_features=768, out_features=3, bias=True)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒錯，一行程式碼就初始化了一個可以用 BERT 做文本多分類的模型 &lt;code&gt;model&lt;/code&gt;。我也列出了 &lt;code&gt;model&lt;/code&gt; 裡頭最 high level 的模組，資料流則從上到下，通過：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BERT 處理各種 &lt;code&gt;embeddings&lt;/code&gt; 的模組&lt;/li&gt;
&lt;li&gt;在&lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html"&gt;神經機器翻譯&lt;/a&gt;就已經看過的 Transformer Encoder&lt;/li&gt;
&lt;li&gt;一個 pool &lt;code&gt;[CLS]&lt;/code&gt; token 在所有層的 repr. 的 &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT/blob/a6f2511811f08c24184f8162f226f252cb6ceaa4/pytorch_pretrained_bert/modeling.py#L494"&gt;BertPooler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Dropout 層&lt;/li&gt;
&lt;li&gt;回傳 3 個類別 logits 的線性分類器 &lt;code&gt;classifier&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而 &lt;code&gt;classifer&lt;/code&gt; 就只是將從 BERT 那邊拿到的 &lt;code&gt;[CLS]&lt;/code&gt; token 的 repr. 做一個線性轉換而已，非常簡單。我也將我們實際使用的分類模型 &lt;code&gt;BertForSequenceClassification&lt;/code&gt; 實作簡化一下供你參考：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;BertForSequenceClassification&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BertPreTrainedModel&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BertForSequenceClassification&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bert&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BertModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 載入預訓練 BERT&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_dropout_prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# 簡單 linear 層&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classifier&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hidden_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
          &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_ids&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_type_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# BERT 輸入就是 tokens, segments, masks&lt;/span&gt;
        &lt;span class="n"&gt;outputs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_ids&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;token_type_ids&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
        &lt;span class="n"&gt;pooled_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pooled_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# 線性分類器將 dropout 後的 BERT repr. 轉成類別 logits&lt;/span&gt;
        &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pooled_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# 輸入有 labels 的話直接計算 Cross Entropy 回傳，方便！&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;loss_fct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loss_fct&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;view&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;
        &lt;span class="c1"&gt;# 有要求回傳注意矩陣的話回傳&lt;/span&gt;
        &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;output_attentions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;all_attentions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;
        &lt;span class="c1"&gt;# 回傳各類別的 logits&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣應該清楚多了吧！我們的分類模型 &lt;code&gt;model&lt;/code&gt; 也就只是在 BERT 之上加入 dropout 以及簡單的 linear classifier，最後輸出用來預測類別的 logits。 這就是兩階段遷移學習強大的地方：你不用再自己依照不同 NLP 任務從零設計非常複雜的模型，只需要站在巨人肩膀上，然後再做一點點事情就好了。&lt;/p&gt;
&lt;p&gt;你也可以看到整個分類模型 &lt;code&gt;model&lt;/code&gt; 預設的隱狀態維度為 768。如果你想要更改 BERT 的超參數，可以透過給一個 &lt;code&gt;config&lt;/code&gt; dict 來設定。以下則是分類模型 &lt;code&gt;model&lt;/code&gt; 預設的參數設定：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;{
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128
}&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Dropout、LayerNorm、全連接層數以及 mutli-head attentions 的 &lt;code&gt;num_attention_heads&lt;/code&gt; 等超參數我們也都已經在之前的 Transformer 文章看過了，這邊就不再贅述。&lt;/p&gt;
&lt;p&gt;目前 &lt;a href="https://pytorch.org/hub/huggingface_pytorch-pretrained-bert_bert/"&gt;PyTorch Hub&lt;/a&gt; 上有 8 種模型以及一個 tokenizer 可供使用，依照用途可以分為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本款：&lt;ul&gt;
&lt;li&gt;bertModel&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bertTokenizer&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;預訓練階段&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bertForMaskedLM&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;bertForNextSentencePrediction&lt;/li&gt;
&lt;li&gt;bertForPreTraining&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tuning 階段&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;bertForSequenceClassification&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;bertForTokenClassification&lt;/li&gt;
&lt;li&gt;bertForQuestionAnswering&lt;/li&gt;
&lt;li&gt;bertForMultipleChoice&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;粗體是本文用到的模型。如果你想要完全 DIY 自己的模型，可以載入純 &lt;code&gt;bertModel&lt;/code&gt; 並參考上面看到的 &lt;code&gt;BertForSequenceClassification&lt;/code&gt; 的實作。當然建議盡量不要重造輪子。如果只是想要了解其背後實作邏輯，可以參考 &lt;a href="https://github.com/huggingface/pytorch-pretrained-BERT"&gt;pytorch-pretrained-BERT&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;有了 &lt;code&gt;model&lt;/code&gt; 以及我們在前一節建立的 &lt;code&gt;trainloader&lt;/code&gt;，讓我們寫一個簡單函式測試現在 &lt;code&gt;model&lt;/code&gt; 在訓練集上的分類準確率：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;定義一個可以針對特定 DataLoader 取得模型預測結果以及分類準確度的函式&lt;/span&gt;
&lt;span class="sd"&gt;之後也可以用來生成上傳到 Kaggle 競賽的預測結果&lt;/span&gt;
&lt;span class="sd"&gt;"""&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_predictions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataloader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;compute_acc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
    &lt;span class="n"&gt;correct&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# 推論模式&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;no_grad&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="c1"&gt;# 遍巡整個資料集&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dataloader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="c1"&gt;# 將所有 tensors 移到 GPU 上&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_cuda&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"cuda:0"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            
            &lt;span class="c1"&gt;# 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks&lt;/span&gt;
            &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            
            &lt;span class="c1"&gt;# 用來計算訓練集的分類準確率&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;compute_acc&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;correct&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                
            &lt;span class="c1"&gt;# 將當前 batch 記錄下來&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;compute_acc&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;correct&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;
    
&lt;span class="c1"&gt;# 讓模型跑在 GPU 上並取得訓練集的分類準確率&lt;/span&gt;
&lt;span class="n"&gt;device&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"cuda:0"&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cuda&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_available&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="s2"&gt;"cpu"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"device:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_predictions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trainloader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;compute_acc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"classification acc:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;device: cuda:0
classification acc: 0.5216409484380881
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;毫不意外，模型裡新加的線性分類器才剛剛被初始化，整個分類模型的表現低於 68 %  的 baseline 是非常正常的。因為模型是隨機初始化的，你的執行結果可能跟我有點差距，但應該不會超過 68 %。&lt;/p&gt;
&lt;p&gt;另外我們也可以算算整個分類模型以及裡頭的簡單分類器有多少參數：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_learnable_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;requires_grad&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
     
&lt;span class="n"&gt;model_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_learnable_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clf_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_learnable_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classifier&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;整個分類模型的參數量：{sum(p.numel() for p in model_params)}&lt;/span&gt;
&lt;span class="s2"&gt;線性分類器的參數量：{sum(p.numel() for p in clf_params)}&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
整個分類模型的參數量：102269955
線性分類器的參數量：2307

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新增的 classifier 在 BERT 面前可說是滄海一粟。而因為分類模型大多數的參數都是從已訓練的 BERT 來的，實際上我們需要從頭訓練的參數量非常之少，這也是遷移學習的好處。&lt;/p&gt;
&lt;p&gt;當然，一次 forward 所需的時間也不少就是了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="4.-訓練該下游任務模型"&gt;4. 訓練該下游任務模型&lt;a class="anchor-link" href="#4.-訓練該下游任務模型"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接下來沒有什麼新玩意了，除了需要記得我們前面定義的 batch 數據格式以外，訓練分類模型 &lt;code&gt;model&lt;/code&gt; 就跟一般你使用 PyTorch 訓練模型做的事情相同。&lt;/p&gt;
&lt;p&gt;為了避免失焦，訓練程式碼我只保留核心部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;

# 使用 Adam Optim 更新整個分類模型的參數
optimizer = torch.optim.Adam(model_params, lr=1.0e-4)

EPOCHS = 6  # 幸運數字
for epoch in range(EPOCHS):
    
    running_loss = 0.0
    for data in trainloader:
        
        tokens_tensors, segments_tensors, \
        masks_tensors, labels = [t.to(device) for t in data]

        # 將參數梯度歸零
        optimizer.zero_grad()
        # forward pass
        loss = model(input_ids=tokens_tensors, 
                     token_type_ids=segments_tensors, 
                     attention_mask=masks_tensors, 
                     labels=labels)
        # backward
        loss.backward()
        optimizer.step()
        
        # 紀錄當前 batch loss
        running_loss += loss.item()
        
    # 計算分類準確率
    _, acc = get_predictions(model, trainloader, compute_acc=True)

    print('[epoch %d] loss: %.3f, acc: %.3f' %
          (epoch + 1, running_loss, acc))
    
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[epoch 1] loss: 21.751, acc: 0.906
[epoch 2] loss: 10.893, acc: 0.977
[epoch 3] loss: 6.226, acc: 0.944
[epoch 4] loss: 4.111, acc: 0.987
[epoch 5] loss: 1.886, acc: 0.992
[epoch 6] loss: 0.931, acc: 0.998
CPU times: user 2min 43s, sys: 1min 49s, total: 4min 32s
Wall time: 4min 34s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;哇嗚！我們成功地 Fine-tune BERT 了！&lt;/p&gt;
&lt;p&gt;儘管擁有 1 億參數的分類模型十分巨大，多虧了小訓練集的助攻（？），幾個 epochs 的訓練過程在 5 分鐘內就結束了。從準確率看得出我們的分類模型在非常小量的訓練集的表現已經接近完美，讓我們看看這個模型在真實世界，也就是 Kaggle 競賽上的測試集能得到怎麼樣的成績。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="5.-對新樣本做推論"&gt;5. 對新樣本做推論&lt;a class="anchor-link" href="#5.-對新樣本做推論"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們要做的事情很單純，就只是用訓練過後的分類模型 &lt;code&gt;model&lt;/code&gt; 為測試集裡的每個樣本產生預測分類。執行完以下程式碼，我們就能得到一個能直接繳交到 Kaggle 競賽的 csv 檔案：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
# 建立測試集。這邊我們可以用跟訓練時不同的 batch_size，看你 GPU 多大
testset = FakeNewsDataset("test", tokenizer=tokenizer)
testloader = DataLoader(testset, batch_size=256, 
                        collate_fn=create_mini_batch)

# 用分類模型預測測試集
predictions = get_predictions(model, testloader)

# 用來將預測的 label id 轉回 label 文字
index_map = {v: k for k, v in testset.label_map.items()}

# 生成 Kaggle 繳交檔案
df = pd.DataFrame({"Category": predictions.tolist()})
df['Category'] = df.Category.apply(lambda x: index_map[x])
df_pred = pd.concat([testset.df.loc[:, ["Id"]], 
                          df.loc[:, 'Category']], axis=1)
df_pred.to_csv('bert_1_prec_training_samples.csv', index=False)
df_pred.head()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;CPU times: user 4min 28s, sys: 2min 40s, total: 7min 8s
Wall time: 7min 9s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/kaggle_csv.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;ls bert*.csv
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;bert_1_prec_training_samples.csv
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們前面就說過測試集是訓練集的 30 倍，因此光是做推論就得花不少時間。廢話不多說，讓我將生成的預測結果上傳到 Kaggle 網站，看看會得到怎麼樣的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/kaggle_result.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在不到 1 % 的數據 Fine-tuing BERT 可以達到 80 % 測試準確率
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;測試集是訓練集的 30 倍大，overfitting 完全是可預期的。不過跟我們一開始多數決的 68 % baseline 相比，以 BERT fine tune 的分類模型在測試集達到 80 %，整整上升了 12 %。雖然這篇文章的重點一直都不在最大化這個假新聞分類任務的準確率，還是別忘了我們只用了不到原來競賽 1 % 的數據以及不到 5 分鐘的時間就達到這樣的結果。&lt;/p&gt;
&lt;p&gt;讓我們忘了準確率，看看 BERT 本身在 fine tuning 之前與之後的差異。以下程式碼列出模型成功預測 &lt;code&gt;disagreed&lt;/code&gt; 類別的一些例子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_predictions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trainloader&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;"predicted"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;()})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'predicted'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predicted&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;index_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;df1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;trainset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'predicted'&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;disagreed_tp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'disagreed'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; \
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predicted&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; \
                &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text_a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;df1&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;disagreed_tp&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/disagreed_df.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其實用肉眼看看這些例子，以你對自然語言的理解應該能猜出要能正確判斷 &lt;code&gt;text_b&lt;/code&gt; 是反對 &lt;code&gt;text_a&lt;/code&gt;，首先要先關注「謠」、「假」等代表反對意義的詞彙，接著再看看兩個句子間有沒有含義相反的詞彙。&lt;/p&gt;
&lt;p&gt;讓我們從中隨意選取一個例子，看看 fine tuned 後的 BERT 能不能關注到該關注的位置。再次出動 &lt;a href="https://github.com/jessevig/bertviz"&gt;BertViz&lt;/a&gt; 來視覺化 BERT 的注意權重：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 觀察訓練過後的 model 在處理假新聞分類任務時關注的位置&lt;/span&gt;
&lt;span class="c1"&gt;# 去掉 `state_dict` 即可觀看原始 BERT 結果&lt;/span&gt;
&lt;span class="n"&gt;bert_version&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'bert-base-chinese'&lt;/span&gt;
&lt;span class="n"&gt;bertviz_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BertModel&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_pretrained&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bert_version&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                          &lt;span class="n"&gt;state_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bert&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;state_dict&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="n"&gt;sentence_a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"烟王褚时健去世"&lt;/span&gt;
&lt;span class="n"&gt;sentence_b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"辟谣：一代烟王褚时健安好！"&lt;/span&gt;

&lt;span class="n"&gt;call_html&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bertviz_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bertviz_tokenizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence_a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence_b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 這段程式碼會顯示下圖中右邊的結果&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/bert/cls_repr_change_after_fine_tuning.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們說過在 BERT 裡頭，第一個 &lt;code&gt;[CLS]&lt;/code&gt; 的 repr. 代表著整個輸入序列的 repr.。&lt;/p&gt;
&lt;p&gt;左邊是一般預訓練完的 BERT。如果你還記得 BERT 的其中一個預訓練任務 NSP 的話，就會了解這時的 &lt;code&gt;[CLS]&lt;/code&gt; 所包含的資訊大多是要用來預測第二句本來是否接在第一句後面。以這個 head 而言，&lt;code&gt;[CLS]&lt;/code&gt; 仍只把注意力放在兩句間的 &lt;code&gt;[SEP]&lt;/code&gt; 上。&lt;/p&gt;
&lt;p&gt;有趣的是在看過一些假新聞分類數據以後（右圖），這個 head 在更新 &lt;code&gt;[CLS]&lt;/code&gt; 的 repr. 時會開始關注跟下游任務目標相關的詞彙。在 fine tune 一陣子之後，它學會關注兩句之間「衝突」的位置，並將這些資訊更新到 &lt;code&gt;[CLS]&lt;/code&gt; 裡頭，讓之後的 Linear Classifier 有辦法從中獲得分類的資訊：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;闢謠&lt;/li&gt;
&lt;li&gt;去世&lt;/li&gt;
&lt;li&gt;安好&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;考慮到我們只給 BERT 看不到 1 % 的數據，這樣的結果不差。我想如果有時間 fine tune 整個訓練集的話能會得到更好的成果。&lt;/p&gt;
&lt;p&gt;好啦，到此為止你應該充分理解 BERT 並能自己動手 fine tuning 了。讓我們進入最後一個小節。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一路過來，你現在應該已經能夠：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直觀理解 BERT 內部自注意力機制的物理意義&lt;/li&gt;
&lt;li&gt;向其他人清楚解釋何謂 BERT 以及其運作的原理&lt;/li&gt;
&lt;li&gt;了解 contextual word repr. 及兩階段遷移學習&lt;/li&gt;
&lt;li&gt;將文本數據轉換成 BERT 相容的輸入格式&lt;/li&gt;
&lt;li&gt;依據下游任務 fine tuning BERT 並進行推論&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;恭喜！你現在已經具備能夠進一步探索最新 NLP 研究與應用的領域了。&lt;/p&gt;
&lt;p&gt;（好啦，事實上沒那麼簡單，但至少是個好的開始）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/unilm.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        UniLM 用 3 種語言模型作為預訓練目標，可以 fine tune 自然語言生成任務，是值得期待的研究
                        （&lt;a href="https://arxiv.org/abs/1905.03197" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我還有好多東西想跟你分享，但因為時間有限，在這邊就簡單地條列出來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BERT 的 Encoder 架構很適合做&lt;a href="http://web.stanford.edu/class/cs224u/"&gt;自然語言理解 NLU &lt;/a&gt;任務，但如文章摘要等&lt;a href="https://youtu.be/4uG1NMKNWCU"&gt;自然語言生成 NLG &lt;/a&gt;的任務就不太 okay。&lt;a href="https://github.com/nlpyang/BertSum"&gt;BertSum&lt;/a&gt; 則是一篇利用 BERT 做萃取式摘要並在 &lt;a href="https://paperswithcode.com/sota/document-summarization-on-cnn-daily-mail"&gt;CNN/Dailymail 取得 SOTA&lt;/a&gt; 的研究，適合想要在 BERT 之上開發自己模型的人參考作法&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1905.03197"&gt;UniLM&lt;/a&gt; 透過「玩弄」注意力遮罩使得其可以在預訓練階段同時訓練 3 種語言模型，讓 fine tune NLG 任務不再是夢想。如果你懂我在&lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html"&gt;之前的 Transformer 文章&lt;/a&gt;內講解的遮罩概念，上面那張圖你馬上就能讀懂&lt;/li&gt;
&lt;li&gt;最近新的 NLP 王者非 &lt;a href="https://arxiv.org/abs/1906.08237"&gt;XLNet&lt;/a&gt; 莫屬。其表現打敗 BERT 自然不需多言，但&lt;a href="https://medium.com/syncedreview/the-staggering-cost-of-training-sota-ai-models-e329e80fa82"&gt;訓練該模型所需的花費&lt;/a&gt;令人不禁思考這樣的大公司遊戲是否就是我們要的未來&lt;/li&gt;
&lt;li&gt;有些人認為 BERT 不夠通用，因為 Fine-tuning 時還要依照不同下游任務加入新的 Linear Classifier。有些人提倡使用 Multitask Learning 想辦法弄出更通用的模型，而 &lt;a href="https://decanlp.com/"&gt;decaNLP&lt;/a&gt; 是一個知名例子。&lt;/li&gt;
&lt;li&gt;PyTorch 的 BERT 雖然使用上十分直覺，如果沒有強大的 GPU 還是很難在實務上使用。你可以嘗試特徵擷取或是 freeze BERT。另外如果你是以個人身份進行研究，但又希望能最小化成本並加快模型訓練效率，我會推薦花點時間學會&lt;a href="https://colab.sandbox.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb"&gt;在 Colab 上使用 TensorFlow Hub 及 TPU 訓練模型 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他的碎念留待下次吧。&lt;/p&gt;
&lt;p&gt;當時在撰寫&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;進入 NLP 世界的最佳橋樑&lt;/a&gt;一文時我希望能用自己的微薄之力搭起一座橋樑，讓更多人平順地進入 NLP 世界。作為該篇文章的續篇，這次我希望已經在 NLP 世界的你，能夠進一步掌握突破城牆的巨人之力，前往更遠的地方。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        對，這篇文章就是那巨人的脊髓液。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="自然語言處理"></category><category term="NLP"></category><category term="PyTorch"></category></entry><entry><title>淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中</title><link href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" rel="alternate"></link><published>2019-06-17T05:40:00+09:00</published><updated>2019-06-17T05:40:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-06-17:/neural-machine-translation-with-transformer-and-tensorflow2.html</id><summary type="html">&lt;p&gt;本文分為兩大部分。前半將帶讀者簡單回顧 Seq2Seq 模型、自注意力機制以及 Transformer 等近年在機器翻譯領域裡頭的重要發展與概念；後半段則將帶著讀者實作一個可以將英文句子翻譯成中文的 Transformer。透過瞭解其背後運作原理，讀者將能把類似的概念應用到如圖像描述、閱讀理解以及語音辨識等各式各樣的機器學習任務之上。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;style&gt;
   pre {
      overflow-x: auto;
      word-wrap: break-word;
   }
&lt;/style&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        那時，全世界的語言都一樣。人們說：『來吧，我們要建一座塔，塔頂通天，為了揚我們的名，免得我們被分散到世界各地。』耶和華說：『看哪！他們成爲一樣的人民、用同樣的語言。如今既蓋起塔來，以後就沒有他們無法完成的事情了。我們下去！在那裏變亂他們的口音，使他們的言語彼此不通。』
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ 《創世記》第十一章&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是聖經中著名的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B7%B4%E5%88%A5%E5%A1%94"&gt;巴別塔&lt;/a&gt;橋段，用來解釋為何當今世上有那麼多種語言。當年的上帝或許過於杞人憂天，但近年多虧了&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;，&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"&gt;機器翻譯&lt;/a&gt;的快速發展讓人不禁覺得，或許巴別塔很快就不再只是虛幻傳說了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/google-translate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/google-translate.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        以往被視為非常困難的中 -&amp;gt; 英翻譯如今在深度學習的加持下也有不錯的水準
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器翻譯的研究之所以如此重要且迷人，是因為它將有機會讓未來任何人都不受語言的限制，獲得世界上任何他或她想要的資訊與知識。&lt;/p&gt;
&lt;p&gt;在這篇文章的前半部分，我們會先花點時間來回顧&lt;a href="https://en.wikipedia.org/wiki/Neural_machine_translation"&gt;神經機器翻譯&lt;/a&gt;裡頭的一些重要概念。接著在具備這些概念以及&lt;a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA"&gt;其他背景知識&lt;/a&gt;的前提之下，利用最新的 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow 2&lt;/a&gt; 來實作一個可以將英文句子翻譯成中文的神經網路架構：&lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer"&gt;Transformer&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-high-level-view.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Transformer 將法文句子翻譯成英文
                        （&lt;a href="http://jalammar.github.io/illustrated-transformer/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是一個非常簡化的示意圖。Transformer 實際上是一種基於自注意力機制的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=3208"&gt;Seq2Seq 模型&lt;/a&gt;，近年在&lt;a href="https://paperswithcode.com/task/image-captioning"&gt;圖像描述&lt;/a&gt;、&lt;a href="https://zh.wikipedia.org/wiki/%E8%81%8A%E5%A4%A9%E6%A9%9F%E5%99%A8%E4%BA%BA"&gt;聊天機器人&lt;/a&gt;、&lt;a href="https://zh.wikipedia.org/zh-hant/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB"&gt;語音辨識&lt;/a&gt;以及機器翻譯等各大領域大發異彩。但因為其相對複雜，到現在還是有種現象：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        了解 Transformer 相關技術的人已經用了好一陣子且用得很開心，不知道的人還是不知道。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這並不僅限於 Transformer，因為深度學習牽涉的研究範圍實在太廣了。透過這篇文章，我希望能幫助你開始了解神經機器翻譯以及 Transformer 的相關知識。&lt;/p&gt;
&lt;p&gt;當我們完成實作並訓練出一個 Transformer 以後，除了可以英翻中以外，我們還能清楚地了解其是如何利用強大的&lt;a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;amp;feature=youtu.be"&gt;注意力機制&lt;/a&gt;（我們在 &lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;Encoder-Decoder 模型 + 注意力機制&lt;/a&gt;一節會仔細探討此概念）來做到精準且自然的翻譯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Transformer 在將英文句子翻譯成中文時會「關注」需要注意的英文詞彙來生成對應的中文字詞
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了翻譯出來的中文正確無誤以外，從上圖你可以發現很有趣的現象。&lt;/p&gt;
&lt;p&gt;給定左側的英文，Transformer 在生成其對應的中文翻譯時都會給每個英文詞彙不同的「注意程度」。小方格越亮則代表模型在生成某中文字時放越多的注意力在左側對應的英文詞彙上。&lt;/p&gt;
&lt;p&gt;仔細看你會發現這個已經訓練好的 Transformer 在翻譯：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「必」、「須」時會關注「must」&lt;/li&gt;
&lt;li&gt;「希」、「望」時會關注「hope」&lt;/li&gt;
&lt;li&gt;「公」、「民」時會關注「citizens」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;乍看之下好像稀鬆平常，但事實上我們在訓練模型時並不會告訴它這些詞彙之間的對應關係或是任何語言學的知識。我們就只是餵給它多組相同意思的中英句子，並讓它自己學會怎麼做翻譯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        好黑魔法，不學嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在英翻中的情境下，神經網路要做的事情就是讀入左側的英文句子，接著生成右側的中文句子（繁中對英文的翻譯資料集稀少，此文將以簡體為例）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-zh-training-sentences.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        訓練資料是多組相同語義的成對中英句子（當然仍需前處理）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一些你需先具備的基礎知識"&gt;一些你需先具備的基礎知識&lt;a class="anchor-link" href="#一些你需先具備的基礎知識"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我在文中會盡量言簡意賅地介紹所有你需要了解的深度學習概念，並附上相關連結供你參考。但就像在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;天龍八部&lt;/a&gt;或是眾多武俠小說都有提過的重要準則：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        武功修習有先後順序，勿求一步登天。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管在 &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;2017 年就已被提出&lt;/a&gt;，本文即將探討並實作的 &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;Transformer&lt;/a&gt; 仍算是相當進階的神經網路架構。因此具備以下的基礎知識能幫助你更順利地理解本文內容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一點點&lt;a href="https://demo.leemeng.tw/"&gt;卷積神經網路&lt;/a&gt;的概念&lt;/li&gt;
&lt;li&gt;清楚理解&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;循環神經網路&lt;/a&gt;的運算方式&lt;/li&gt;
&lt;li&gt;基本的&lt;a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/"&gt;自然語言處理&lt;/a&gt;知識&lt;/li&gt;
&lt;li&gt;基本的&lt;a href="https://youtu.be/uUrt8xgdMbs?list=PLJV_el3uVTsNmr39gwbyV-0KjULUsN7fW"&gt;線性代數&lt;/a&gt;如矩陣相乘運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/nlp-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        中研院這篇文章清楚地說明了自然語言處理在中文上的研究與應用
                        （圖片來源：&lt;a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/" target="_blank"&gt;研之有物&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望這樣的要求沒把你嚇跑，因為事實上你大約需要好幾倍的相關知識來成功實作 Transformer。&lt;a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA"&gt;儘管在實作前你會看到一些額外要求&lt;/a&gt;，本文的前半部分還是相當平易近人的，還請放心閱讀。&lt;/p&gt;
&lt;p&gt;當你想要深入了解某些細節的時候，可以參考這節附上的連結或是文內說明概念時附上的圖片來源。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        想更深入了解文中講述的各種概念，點擊相關的「圖片來源」就對了。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前言很長，但好戲才在後頭。如果你已經準備好進入神經機器翻譯的世界的話，現在就讓我們正式開始這趟旅程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器翻譯近代史"&gt;機器翻譯近代史&lt;a class="anchor-link" href="#機器翻譯近代史"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;鑑往知來。了解一點機器翻譯的歷史以及 Transformer 是怎麼跑出來的會對實作很有幫助。&lt;/p&gt;
&lt;p&gt;機器翻譯（&lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;T&lt;/strong&gt;ranslation）本身的概念&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E6%AD%B7%E5%8F%B2"&gt;最早可追溯到 17 世紀&lt;/a&gt;。自從那開始，人們嘗試並研究了各式各樣的方法，寫了一大堆規則、蒐集了數以萬計的翻譯結果來嘗試自動化翻譯。隨著時代演進，我們有了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基於規則的機器翻譯 RBMT&lt;/li&gt;
&lt;li&gt;基於範例的機器翻譯 EBMT&lt;/li&gt;
&lt;li&gt;統計機器翻譯 SMT&lt;/li&gt;
&lt;li&gt;近年的神經機器翻譯 NMT&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/mt-history.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        近代機器翻譯發展簡史
                        （&lt;a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多遠古時代的東西我們不會討論，而 NMT 當然是本文的重點。不過在那之前讓我們非常簡短地看一下 SMT。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="統計機器翻譯：基於短語的翻譯"&gt;統計機器翻譯：基於短語的翻譯&lt;a class="anchor-link" href="#統計機器翻譯：基於短語的翻譯"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器翻譯的歷史很長，但一直要到 21 世紀初期&lt;a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"&gt;統計機器翻譯（&lt;strong&gt;S&lt;/strong&gt;tatistical &lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;T&lt;/strong&gt;ranslation，簡稱 SMT）&lt;/a&gt;技術成熟以後，機器翻譯的品質才稍微使人滿意。其中最知名的例子當屬 &lt;a href="https://ai.googleblog.com/2006/04/statistical-machine-translation-live.html"&gt;Google 在 2006 年發布的 SMT 翻譯系統&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;不限於 Google，當時不少最先進的 SMT 系統都採用了&lt;a href="https://en.wikipedia.org/wiki/Statistical_machine_translation#Phrase-based_translation"&gt;基於短語的機器翻譯（Phrase-Based MT）&lt;/a&gt; 演算法。PBMT 最大的特色是先將來源語言（Source Language）的句子切成短語或是詞彙，接著大致上獨立地將這些詞彙翻譯成目標語言（Target Language）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/pbmt.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        基於短語的 SMT（Phrase-Based SMT）
                        （&lt;a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;PBMT 的翻譯結果相較於早年基於規則（Rule-Based）的手法已經進步很多，但仍然需要大量的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%AF%AD%E6%96%99"&gt;平行語料&lt;/a&gt;、對齊語料來取得較好的結果。且因為是以短語為單位在做翻譯，這些短語拼湊出來的句子仍然不夠自然。&lt;/p&gt;
&lt;p&gt;如果你跟我一樣有用過早年的 Google 翻譯，應該還能隱約記得當年那些充斥著「機械感」的翻譯結果。&lt;/p&gt;
&lt;p&gt;（如果你有當年 Google 翻譯結果的截圖的話歡迎提供）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="神經機器翻譯：Encoder-Decoder-模型"&gt;神經機器翻譯：Encoder-Decoder 模型&lt;a class="anchor-link" href="#神經機器翻譯：Encoder-Decoder-模型"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;顧名思義，神經機器翻譯 NMT 即代表使用&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;類神經網路（Neural Network）&lt;/a&gt;來做機器翻譯。&lt;/p&gt;
&lt;p&gt;不管是英文、法文還是中文，一個自然語言的句子基本上可以被視為一個有時間順序的序列數據（Sequence Data）。而&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1"&gt;我們曾提過 RNN 很適合用來處理有時間關係的序列數據&lt;/a&gt;。給定一個向量序列，RNN 就是回傳一個一樣長度的向量序列作為輸出。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 很適合拿來處理具有時間順序的序列數據（下方的詞在丟入 RNN 前會被轉成詞向量）
                        （&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當我們把來源語言以及目標語言的句子都視為一個獨立的序列以後，機器翻譯事實上就是一個&lt;a href="https://youtu.be/ZjfjPzXw6og"&gt;序列生成（Sequence Generation）&lt;/a&gt;任務：對一個輸入序列（來源語言）做些有意義的轉換與處理以後，輸出一個新的序列（目標語言）。&lt;/p&gt;
&lt;p&gt;而在深度學習時代，我們一般會使用以 RNN 為基礎的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=3208"&gt;Encoder-Decoder 架構（又被稱作 Sequence to Sequence / Seq2Seq 模型）&lt;/a&gt;來做序列生成：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-animate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-animate.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        一個以 RNN 為基礎的 Encoder-Decoder / Seq2Seq 模型將法文翻譯成英文的步驟
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Seq2Seq 模型裡頭 Encoder 跟 Decoder 是各自獨立的 RNN。Encoder 把輸入的句子做處理後所得到的隱狀態向量（圖中的 &lt;code&gt;Hidden State#3&lt;/code&gt;）交給 Decoder 來生成目標語言。&lt;/p&gt;
&lt;p&gt;你可以想像兩個語義相同的法英句子雖然使用的語言、語順不一樣，但因為它們有相同的語義，Encoder 在將整個&lt;strong&gt;法文&lt;/strong&gt;句子濃縮成一個嵌入空間（Embedding Space）中的向量後，Decoder 能利用隱含在該向量中的語義資訊來重新生成具有相同意涵的&lt;strong&gt;英文&lt;/strong&gt;句子。&lt;/p&gt;
&lt;p&gt;這樣的模型就像是在模擬人類做翻譯的&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E7%BF%BB%E8%AD%AF%E6%B5%81%E7%A8%8B"&gt;兩個主要過程&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（Encoder）解譯來源文字的文意&lt;/li&gt;
&lt;li&gt;（Decoder）重新編譯該文意至目標語言&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然人類在做翻譯時有更多步驟、也會考慮更多東西，但 Seq2Seq 模型的表現已經很不錯了。&lt;/p&gt;
&lt;p&gt;有些人閱讀到這裡可能會問：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如果我們利用 Seq2Seq 模型將多種語言的句子都轉換到某個嵌入空間裡頭，該空間會長成什麼樣子呢？是相同語言的句子靠得比較近，還是不同語言但擁有同語義的句子會靠得比較近呢？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是一個很好的研究問題。&lt;/p&gt;
&lt;p&gt;而如果我們試著把這個問題圖像化，則結果可能長得像這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/multi-lang-emb.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        大哉問：神經網路將句子轉換完所形成的向量空間比較靠近左邊還是右邊？
                        （&lt;a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=1035" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;圖中的點代表不同句子，不同顏色則代表不同語言。如果結果是左邊，代表神經網路並沒有創出一個「語義」空間，而只是把不同語言都投射到該嵌入空間裡頭的不同位置，接著才在該空間裡進行不同語言之間的轉換（中轉英、英轉法 etc.）。&lt;/p&gt;
&lt;p&gt;我們比較想要的是右邊的情況：無關語言，只要句子的語義接近，彼此的距離就相近的語義空間。&lt;/p&gt;
&lt;p&gt;而 &lt;a href="https://aclweb.org/anthology/Q17-1024"&gt;Google 在 2016 年的研究結果&lt;/a&gt;發現，在此空間裡頭語言相異但擁有同語義的句子之間的距離 &lt;code&gt;d1&lt;/code&gt;，要比同語言但不同語義的句子之間的距離 &lt;code&gt;d2&lt;/code&gt; 要小得多（即  &lt;code&gt;d1 &amp;lt;&amp;lt; d2&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;換句話說，在此空間中同語義的句子會靠得比較近，我們實際得到的空間比較像右邊。&lt;/p&gt;
&lt;p&gt;而如果我們將這些句子做 &lt;a href="https://distill.pub/2016/misread-tsne/"&gt;t-SNE&lt;/a&gt; ，甚至可以得到這樣的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/gnmt-multilingual.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/gnmt-multilingual.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在 Seq2Seq 模型創造出來的「語義」空間裡頭，不同語言但同語義的句子彼此相當接近
                        （&lt;a href="https://projector.tensorflow.org/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;此研究告訴我們，只要對自然語言做正確的轉換，就能將語言相異但同語義的句子都轉換成彼此距離相近的語義向量，並以此做出好的翻譯。&lt;/p&gt;
&lt;p&gt;以下是我隨意挑選出來的一組句子，它們在該空間裡的距離相近：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;英文：
From low-cost pharmacy brand moisturizers to high-priced cosmetics brand moisturizers, competition is fierce.

日文：
低価格の薬品ブランドの保湿剤から高価な百貨店の化粧品ブランドのためには, 競争が激しい

韓文：
싸구려백화점화장품브랜드 moisturizers 에 저렴한약국브랜드 moisturizers 에서 , 경쟁이큰있습니다
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這些句子都代表著類似的意思：「從低價的保濕劑到高價的化妝品牌，競爭都十分激烈」。&lt;/p&gt;
&lt;p&gt;如果你想進一步了解這個視覺化結果，可以閱讀 &lt;a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=789"&gt;Google Brain 的詳細解說&lt;/a&gt;或是上 &lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt; 自己試看看。&lt;/p&gt;
&lt;p&gt;另外值得注意的是，機器翻譯本身是一種&lt;a href="https://youtu.be/ZjfjPzXw6og?t=2816"&gt;有條件的序列生成任務（Conditional Sequence Generation）&lt;/a&gt;：給定一個特定的輸入句子（文字序列），依此條件輸出另外一個句子（文字序列）。這跟在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸&lt;/a&gt;一文中會隨機生成天龍八部文章的&lt;a href="https://zh.wikipedia.org/wiki/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B"&gt;語言模型（Language Model）&lt;/a&gt;是有所差異的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/lstm-sequence-generation.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/lstm-sequence-generation.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        隨機序列生成的例子：一個以 LSTM 實作的簡單語言模型
                        （&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說，語言模型可以在不給定任何輸入的情況下生成非常隨機的文字序列；但針對機器翻譯這種有條件的序列生成任務，我們通常希望給定相同輸入，輸出的結果越穩定越好（或是每次都一模一樣）。&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#TODO"&gt;實作的時候&lt;/a&gt;會看到怎麼達成這件事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder-Decoder-模型-+-注意力機制"&gt;Encoder-Decoder 模型 + 注意力機制&lt;a class="anchor-link" href="#Encoder-Decoder-模型-+-注意力機制"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，你現在應該已經了解如何使用 Seq2Seq 模型來做 NMT 了，不過現在讓我們再次複習其運作方式。這次我們把用 RNN 實作的 Encoder / Decoder 在每個時間點做的事情從左到右一字排開：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="{filename}images/transformer/seq2seq-unrolled-no-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-no-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        以 RNN 為基礎的 Seq2Seq 模型做 NMT 的流程
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基本款的 Seq2Seq 模型表現得不錯，但其實有可以改善的地方。你有看出來了嗎？上圖的輸入句子只有 3 個詞彙，但如果我們想輸入一個很長的句子呢？&lt;/p&gt;
&lt;p&gt;我們前面曾提過 Seq2Seq 模型裡的一個重要假設是 Encoder 能把輸入句子的語義 / 文本脈絡全都壓縮成&lt;strong&gt;一個&lt;/strong&gt;固定維度的語義向量。之後 Decoder 只要利用該向量裡頭的資訊就能重新生成具有相同意義，但不同語言的句子。&lt;/p&gt;
&lt;p&gt;但你可以想像當我們只有一個向量的時候，是不太可能把一個很長的句子的所有資訊打包起來的。&lt;/p&gt;
&lt;p&gt;這時候怎麼辦呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        與其只把 Encoder 處理完句子產生的最後「一個」向量交給 Decoder 並要求其從中萃取整句資訊，不如將 Encoder 在處理每個詞彙後所生成的「所有」輸出向量都交給 Decoder，讓 Decoder 自己決定在生成新序列的時候要把「注意」放在 Encoder 的哪些輸出向量上面。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這事實上就是&lt;a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;amp;feature=youtu.be"&gt;注意力機制（Attention Mechanism）&lt;/a&gt;的中心思想：提供更多資訊給 Decoder，並透過類似資料庫存取的概念，令其自行學會該怎麼提取資訊。兩篇核心論文分別在 &lt;a href="https://arxiv.org/abs/1409.0473"&gt;2014 年 9 月&lt;/a&gt;及 &lt;a href="https://arxiv.org/abs/1508.04025"&gt;2015 年 8 月&lt;/a&gt;釋出，概念不難但威力十分強大。&lt;/p&gt;
&lt;p&gt;以下就是將注意力機制加到 Seq2Seq 模型後的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        注意力機制讓 Decoder 在生成新序列時能查看 Encoder 裡所有可能有用的隱狀態向量
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以拉回去跟沒有注意力機制的 Seq2Seq 模型比較一下差異。&lt;/p&gt;
&lt;p&gt;現在你會看到 Encoder 把處理完每個詞彙所產生的向量都交給 Decoder 了。且透過注意力機制，Decoder 在生成新序列的每個元素時都能&lt;strong&gt;動態地&lt;/strong&gt;考慮自己要看哪些 Encoder 的向量（還有決定從中該擷取多少資訊），因此這種運用注意力機制的 Seq2Seq 架構又被稱作&lt;a href="https://youtu.be/ZjfjPzXw6og?t=3528"&gt;動態的條件序列生成（Dynamic Conditional Generation）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq_detail.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq_detail.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        法翻英時，Decoder 在生成每個英文詞彙時都在 Encoder 的每個輸出向量上放不同的注意程度
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際構想並證明其有效的研究者們十分厲害，且其概念也挺符合人類直覺的，對吧？&lt;/p&gt;
&lt;p&gt;為了方便讀者理解，上面動畫實際上隱藏了一些細節：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;呈現算好的注意程度而不是計算過程&lt;/li&gt;
&lt;li&gt;Encoder / 跟 Decoder 的實際架構&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;既然是深度學習，Encoder / Decoder 一般來說都是由多個 &lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;LSTM&lt;/a&gt; / &lt;a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit"&gt;GRU&lt;/a&gt; 等 RNN Layers 所疊起來的。而注意力機制在這種情境下實際的運作方式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/attention_mechanism_luong.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        英翻法情境下，Decoder 在第一個時間點進行的注意力機制
                        （&lt;a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;左右兩邊分別是 Encoder 與 Decoder ，縱軸則是多層的神經網路區塊 / 層。&lt;/p&gt;
&lt;p&gt;雖然上張動畫是法翻英（這邊是英翻法），但該動畫也是以一樣的概念將圖中的注意權重（attention weights ）視覺化出來（注意權重和為 1）。&lt;/p&gt;
&lt;p&gt;現在讓我們看一下注意力機制實際的計算步驟。在 Decoder 的每個時間點，我們都會進行注意力機制以讓 Decoder 從 Encoder 取得語境資訊：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;拿 Decoder 當下的紅色隱狀態向量 &lt;code&gt;ht&lt;/code&gt; 跟 Encoder 所有藍色隱狀態向量 &lt;code&gt;hs&lt;/code&gt; 做比較，利用 &lt;code&gt;score&lt;/code&gt; 函式計算出 &lt;code&gt;ht&lt;/code&gt; 對每個 &lt;code&gt;hs&lt;/code&gt; 的注意程度&lt;/li&gt;
&lt;li&gt;以此注意程度為權重，&lt;strong&gt;加權平均&lt;/strong&gt;所有 Encoder 隱狀態 &lt;code&gt;hs&lt;/code&gt; 以取得上下文向量 &lt;code&gt;context vector&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將此上下文向量與 Decoder 隱狀態結合成一個注意向量 &lt;code&gt;attention vector&lt;/code&gt; 並作為該時間的輸出&lt;/li&gt;
&lt;li&gt;該注意向量會作為 Decoder 下個時間點的輸入&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;定義 &lt;code&gt;score&lt;/code&gt; 函式的方式不少，現在就先讓我們假設有這麼一個函式。&lt;/p&gt;
&lt;p&gt;至此為止，你應該已經能夠看懂注意力機制的計算公式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/attention-equation.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        注意力機制前 3 步驟的數學式子
                        （&lt;a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而之所以稱為注意權重（attention weights），是因為注意力機制可以被視為是一個學習來源語言和目標語言&lt;strong&gt;每一個單詞之間關係&lt;/strong&gt;的小型神經網路，而這些權重是該神經網路的參數。&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#TODO"&gt;後面的章節&lt;/a&gt;會實際看到，在訓練還沒開始前，這些權重都是隨機且無意義的。是透過訓練，神經網路才知道該為這些權重賦予什麼值。&lt;/p&gt;
&lt;p&gt;你也會發現我在文中提及多次的「注意程度」就是這裡的「注意權重」，而前者是一種擬人化的說法。你可以想像這些權重值讓當下的 Decoder 曉得該放多少關注在 Encoder 個別的隱狀態身上，並依此從它們身上取得上下文資訊（步驟 2）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        而事實上神經網路並沒有意識，因此也不會有感知層次上的「注意」。它學到的是讓注意力機制產生最好結果的「參數權重」，而不是我們人類想像的「注意程度」。只有人類可以賦予神經網路裡頭的計算意義。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有點扯遠了，畢竟這裡應該沒有人文學系的讀者。&lt;/p&gt;
&lt;p&gt;讓我們拉回注意力機制。&lt;/p&gt;
&lt;p&gt;將此機制加入 Seq2Seq 模型後，NMT 系統的翻譯水準再次起飛。Google 在 2016 年推出的 &lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html"&gt;Google Neural Machine Translation system（GNMT）&lt;/a&gt; 是一個知名的案例。除了注意力機制以外，GNMT &lt;a href="https://arxiv.org/abs/1609.08144"&gt;在 Encoder 跟 Decoder 都採用了多達 8 層的 LSTM 神經網路&lt;/a&gt;，讓更多人見識到深度學習的威力。&lt;/p&gt;
&lt;p&gt;跟 Google 10 年前推出的 PBMT 系統比起來，翻譯錯誤率平均下降了 60 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/nmt-model-fast.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/nmt-model-fast.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        利用注意力機制的 GNMT 讓 Decoder 在生成「Knowledge」時能放注意力在 Encoder 處理完「知」與「識」的兩個輸出向量 e0 &amp;amp; e1
                        （&lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上圖為 GNMT 做中翻英的過程。Encoder 跟 Decoder 之間的線條代表注意力（Attention），線條越粗代表下面的 Decoder 在生成某英文字時越關注上方的某些中文字。模型自己學會在翻譯時該看來源句子中的哪些資訊，很聰明，不是嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為其卓越的翻譯品質，在 GNMT 推出的那段時間，搭配注意力機制的 Seq2Seq 模型基本上就是拿來做 NMT 系統的不二人選。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/nmt-vs-pbmt.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        NMT、PBMT 以及人類在中英翻譯時的結果比較
                        （&lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;話說當年 Google 導入 GNMT 時釋出了 8 個語言之間的對應翻譯，&lt;a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/"&gt;涵蓋了約 1/3 的世界人口以及超過 35 % 的 Google 翻譯查詢&lt;/a&gt;，是機器翻譯發展的一個重要里程碑。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Transformer：Seq2Seq-模型-+-自注意力機制"&gt;Transformer：Seq2Seq 模型 + 自注意力機制&lt;a class="anchor-link" href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好酒沉甕底，萬眾矚目的時刻來了。&lt;/p&gt;
&lt;p&gt;標題已經破梗。你已經知道我們將探討本文主角 Transformer，且理論上越後面出來的 BOSS 越強。&lt;/p&gt;
&lt;p&gt;但你現在可能在想：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        Seq2Seq 模型搭配注意力機制感覺已經很猛了，難道還有什麼可以改善的嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案是肯定的 Yes。&lt;/p&gt;
&lt;p&gt;不過這次問題不是出在 Encoder 跟 Decoder 中間交換的資訊不夠，也不是 Seq2Seq 架構本身有什麼問題，問題是出在我們是用 &lt;strong&gt;RNN&lt;/strong&gt; 來實作 Encoder 以及 Decoder。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-09-NN-Types-FP/"&gt;循環神經網路 RNN&lt;/a&gt; 時常被拿來處理序列數據，但其運作方式存在著一個困擾研究者已久的問題：無法有效地平行運算。以一個有 4 個元素的輸入序列為例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[a1, a2, a3, a4]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要獲得最後一個時間點的輸出向量 &lt;code&gt;b4&lt;/code&gt; 得把整個輸入序列跑過一遍才行：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/rnn-vs-self-attn-layer.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        自注意層可以做到跟雙向 RNN 一樣的事情，還可以平行運算
                        （&lt;a href="https://www.youtube.com/watch?v=ugWDIIOHtPA" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1706.03762"&gt;Google 在 2017 年 6 月的一篇論文：Attention Is All You Need&lt;/a&gt; 裡參考了注意力機制，提出了&lt;strong&gt;自&lt;/strong&gt;注意力機制（Self-Attention mechanism）。這個機制不只跟 RNN 一樣可以處理序列數據，還可以平行運算。&lt;/p&gt;
&lt;p&gt;以剛剛的輸入序列 &lt;code&gt;a[]&lt;/code&gt; 為例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[a1, a2, a3, a4]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;一個自注意層（Self-Attention Layer）可以利用矩陣運算在等同於 RNN 的一個時間點內就回傳所有 &lt;code&gt;bi&lt;/code&gt; ，且每個 &lt;code&gt;bi&lt;/code&gt; 都包含了整個輸入序列的資訊。相比之下，RNN 得經過 4 個時間點依序看過 &lt;code&gt;[a1, a2, a3, a4]&lt;/code&gt; 以後才能取得序列中最後一個元素的輸出 &lt;code&gt;b4&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;雖然我們還沒講到實際的運作過程，但在給定一個輸入序列的情境下，自注意力機制的基本精神就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在建立序列中每個元素的 repr. 時，同時去「注意」並擷取同個序列中其他元素的語義資訊。接著將這些語義資訊合併成上下文資訊並當作自己的 repr. 回傳。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;repr. 為 &lt;a href="https://dictionary.cambridge.org/zht/%E8%A9%9E%E5%85%B8/%E8%8B%B1%E8%AA%9E-%E6%BC%A2%E8%AA%9E-%E7%B9%81%E9%AB%94/representation"&gt;representation&lt;/a&gt; 縮寫，在本文的機器翻譯情境裡頭，其意味著可以用來描述某個詞彙、句子意涵的多維實數張量。&lt;/p&gt;
&lt;p&gt;雖然我們一直強調自注意力機制的平行能力，如果你還記得我們在&lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;上一節&lt;/a&gt;講述的注意力機制，就會發現在 Seq2Seq 架構裡頭自注意力機制跟注意力機制講的根本是同樣一件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注 Encoder 的輸出序列，從中獲得上下文資訊&lt;/li&gt;
&lt;li&gt;自注意力機制讓 Encoder 在生成輸入元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊&lt;/li&gt;
&lt;li&gt;自注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現一個非常重要的模式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        注意力機制跟自注意力機制都是讓序列 q 關注序列 k 來將上下文資訊 v 匯總到序列 q 的 repr. 裡頭，只是使用的序列不同。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這也是為何&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt;在後面實作時我們只需要一個注意函式&lt;/a&gt;就好了。總之透過新設計的自注意力機制以及原有的注意力機制，&lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention Is All You Need 論文&lt;/a&gt;作者們打造了一個完全不需使用 RNN 的 Seq2Seq 模型：Transformer。以下是 Transformer 中非常簡化的 Encoder-Decoder 版本，讓我們找找哪邊用到了（自）注意力機制：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/Transformer_decoder.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在 Transformer 裡頭共有 3 個地方用到（自）注意力機制
                        （&lt;a href="http://jalammar.github.io/illustrated-transformer/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Transformer 裡頭，Decoder 利用注意力機制關注 Encoder 的輸出序列（Encoder-Decoder Attention），而 Encoder 跟 Decoder 各自利用自注意力機制關注自己處理的序列（Self-Attention）。無法平行運算的 RNN 完全消失，名符其實的 Attention is all you need.&lt;/p&gt;
&lt;p&gt;以下則是 Transformer 實際上將英文句子翻譯到法文的過程：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        用 Transformer 將英文句子翻譯到法文的例子
                        （&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以 Transformer 實作的 NMT 系統基本上可以分為 6 個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Encoder 為輸入序列裡的每個詞彙產生初始的 repr. （即詞向量），以空圈表示&lt;/li&gt;
&lt;li&gt;利用自注意力機制將序列中所有詞彙的語義資訊各自匯總成每個詞彙的 repr.，以實圈表示&lt;/li&gt;
&lt;li&gt;Encoder 重複 N 次自注意力機制，讓每個詞彙的 repr. 彼此持續修正以完整納入上下文語義&lt;/li&gt;
&lt;li&gt;Decoder 在生成每個法文字時也運用了自注意力機制，關注自己之前已生成的元素，將其語義也納入之後生成的元素&lt;/li&gt;
&lt;li&gt;在自注意力機制後，Decoder 接著利用注意力機制關注 Encoder 的所有輸出並將其資訊納入當前生成元素的 repr.&lt;/li&gt;
&lt;li&gt;Decoder 重複步驟 4, 5 以讓當前元素完整包含整體語義&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上面動畫的 N 為 3，代表著 Encoder 與 Decoder 的層數。這是一個可以依照任務調整的超參數。&lt;/p&gt;
&lt;p&gt;如果你看懂這張圖的資訊流動，就等於瞭解 Transformer 的核心精神了，恭喜！如果仍然有不明瞭的地方，可以搭配我上面的說明多看幾遍動畫或是直接閱讀 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Google AI 部落格的原文介紹&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-ge-bleu-comparison.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Transformer 釋出時與其他模型在英德翻譯資料集上的比較
                        （&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;自注意力機制解開了 RNN 加在 GPU 上的拘束器。作者們用了 8 個 &lt;a href="https://www.nvidia.com.tw/object/tesla-p100-tw.html"&gt;NVIDIA P100 GPU&lt;/a&gt;，花了 3 天半訓練了一個 Transformer，而該模型在 &lt;a href="http://statmt.org/wmt14/"&gt;WMT 2014&lt;/a&gt;  英法 / 英德翻譯都取得了最高水準的成績。&lt;/p&gt;
&lt;p&gt;跟其他模型相比，這訓練時間跟其創造的優異成績在當時可以說是逆天的存在。自此「大注意時代」展開，該論文至今超過 1800 次引用，所有研究領域都被自注意力機制相關的論文洗了一波。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/ramona-flwrs-1310216-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒能趕上開心洗論文的最佳時機也別傷心難過，對我們來說仍然有個十分重要的訊息：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        多數以 RNN 做過的研究，都可以用自注意力機制來取代；多數用 Seq2Seq 架構實現過的應用，也都可以用 Transformer 來替換。模型訓練速度更快，結果可能更好。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這也是我決定寫這篇文章的理由之一。雖然本文是以機器翻譯的角度來介紹 Transformer，但事實上只要是能用 RNN 或 Seq2Seq 模型進行的研究領域，你都會看到已經有大量跟（自）注意力機制或是 Transformer 有關的論文了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本摘要（Text Summarization）&lt;/li&gt;
&lt;li&gt;圖像描述（Image Captioning）&lt;/li&gt;
&lt;li&gt;閱讀理解（Reading Comprehension）&lt;/li&gt;
&lt;li&gt;語音辨識（Voice Recognition）&lt;/li&gt;
&lt;li&gt;語言模型（Language Model）&lt;/li&gt;
&lt;li&gt;聊天機器人（Chat Bot）&lt;/li&gt;
&lt;li&gt;其他任何可以用 RNN 的潛在應用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然不是每個人都喜歡或需要看論文。如果你只是想要應用 Transformer 也沒問題。除了閱讀學術論文以外，Google 的 &lt;a href="https://github.com/google-research/bert"&gt;BERT（Github 上現在超過 1.5 萬顆星）&lt;/a&gt;顛覆以往自然語言的處理方式，讓你可以進行 NLP 的遷移學習（transfer learning），輕鬆利用前人智慧來完成手上的 NLP 任務； &lt;a href="https://openai.com/blog/better-language-models/"&gt;OpenAI 的 GPT&lt;/a&gt; 則是非常厲害的語言模型，能產生非常順暢的文章。你可以在這邊看到一個&lt;a href="https://talktotransformer.com"&gt;線上產生各種文章的 demo&lt;/a&gt;，或是最近&lt;a href="https://lexfridman.com/deeptweets/"&gt; Lex Fridman 使用 GPT-2 產生名人 Tweets&lt;/a&gt; 的例子 。&lt;/p&gt;
&lt;p&gt;這些都是 Transformer 的應用。想了解更多，我推薦李宏毅教授最近&lt;a href="https://www.youtube.com/watch?v=UYPa347-DdE"&gt;講解 ELMO、BERT 以及 GPT 的 YouTube 影片&lt;/a&gt;，十分通俗易懂 ：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/UYPa347-DdE"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        李宏毅教授講解目前 NLP 領域的最新研究是如何讓機器讀懂文字的
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你接下來想往深度學習領域發展（尤其是自然語言處理這塊），了解（自）注意力機制以及 Transformer 的運作方式幾乎可以說是必經之路。就算沒打算自己手刻 Transformer，你現在應該也稍微能夠體會現代的神經網路到底在在對自然語言做些什麼了。&lt;/p&gt;
&lt;p&gt;至此本文的上半部分結束。在下半段我們將實作一個能進行英翻中的 Transformer。等等會說明一項要你完成的事情，不過現在先離開位置喝點東西、讓眼睛跟腦袋休息一下吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/adam-jaime-119551-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="師傅引進門，修行在個人_1"&gt;師傅引進門，修行在個人&lt;a class="anchor-link" href="#師傅引進門，修行在個人"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你回來了嗎？還是等不及待地想繼續往下閱讀？&lt;/p&gt;
&lt;p&gt;接下來我們會進入實際的程式實作。但跟前半段相比難度呈指數型上升，因此我只推薦符合以下條件的讀者閱讀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想透過實作 Transformer 來徹底了解其內部運作原理的人&lt;/li&gt;
&lt;li&gt;願意先花 1 小時了解 Transformer 的細節概念與理論的人&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你馬上就會知道 1 個小時代表什麼意思。如果你覺得這聽起來很 ok，那可以繼續閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/obama-not-bad.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="#機器翻譯近代史"&gt;機器翻譯近代史&lt;/a&gt;一章我們已經花了不少篇幅講解了許多在實作 Transformer 時會有幫助的重要概念，其中包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#神經機器翻譯：Encoder-Decoder-模型"&gt;Seq2Seq 模型的運作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;注意力機制的概念與計算過程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;自注意力機制與 Transformer 的精神&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;壞消息是，深度學習裡頭理論跟實作的差異常常是很大的。儘管這些背景知識對理解 Transformer 的精神非常有幫助，對從來沒有用過 &lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;RNN 實現文本生成&lt;/a&gt;或是以&lt;a href="https://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention"&gt; Seq2Seq 模型 + 注意力機制實現過 NMT&lt;/a&gt; 的人來說，要在第一次就正確實現 Transformer 仍是一個巨大的挑戰。&lt;/p&gt;
&lt;p&gt;就算不說理論跟實作的差異，讓我們看看 &lt;a href="https://www.tensorflow.org/alpha/tutorials/text/transformer"&gt;TensorFlow 官方釋出的最新 Transformer 教學&lt;/a&gt;裡頭有多少內容：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tf-tutorial-oveview.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/tf-tutorial-oveview.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        TensorFlow 官方的 Transformer 教學
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面是我用這輩子最快的速度捲動該頁面再加速後的結果，可以看出內容還真不少。儘管中文化很重要，我在這篇文章裡不會幫你把其中的敘述翻成中文（畢竟你的英文可能比我好）&lt;/p&gt;
&lt;p&gt;反之，我將利用 TensorFlow 官方的程式碼，以最適合「初心者」理解的實作順序來講述 Transformer 的重要技術細節及概念。在閱讀本文之後，你將有能力自行理解 TensorFlow 官方教學以及其他網路上的實作（比方說 HarvardNLP 以 &lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 實現的 &lt;a href="http://nlp.seas.harvard.edu//2018/04/03/attention.html#additional-components-bpe-search-averaging"&gt;The Annotated Transformer&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;但在實作前有件事情要請你完成：觀看個 YouTube 影片。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        教授講解 self-attention 計算方式及 Transformer 的運作原理，強力推薦
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在閱讀此文的讀者真的很幸福。&lt;/p&gt;
&lt;p&gt;李宏毅教授前陣子才在&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;他 2019 年的台大機器學習課程&lt;/a&gt;發佈了 &lt;a href="https://www.youtube.com/watch?v=ugWDIIOHtPA"&gt;Transformer 的教學影片&lt;/a&gt;，而這可以說是世界上最好的中文教學影片。如果你真的想要深入理解 Transformer，在實作前至少把上面的影片看完吧！你可以少走很多彎路。&lt;/p&gt;
&lt;p&gt;實作時我會盡量重述關鍵概念，但如果有先看影片你會比較容易理解我在碎碎念什麼。如果看完影片你的小宇宙開始發光發熱，也可以先讀讀 &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Transformer 的原始論文&lt;/a&gt;，跟很多學術論文比起來相當好讀，真心不騙。&lt;/p&gt;
&lt;p&gt;重申一次，除非你已經了解基本注意力機制的運算以及 Transformer 的整體架構，否則我不建議繼續閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/you-should-not-pass.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="11-個重要-Transformer-概念回顧"&gt;11 個重要 Transformer 概念回顧&lt;a class="anchor-link" href="#11-個重要-Transformer-概念回顧"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;怎麼樣？你應該已經從教授的課程中學到不少重要概念了吧？我不知道你還記得多少，但讓我非常簡單地幫你複習一下。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;自注意層（Self-Attention Layer）跟 RNN 一樣，輸入是一個序列，輸出一個序列。但是該層可以平行計算，且輸出序列中的每個向量都已經看了整個序列的資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意層將輸入序列 &lt;code&gt;I&lt;/code&gt; 裡頭的每個位置的向量 &lt;code&gt;i&lt;/code&gt; 透過 3 個線性轉換分別變成 3 個向量：&lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt;，並將每個位置的 &lt;code&gt;q&lt;/code&gt; 拿去跟序列中其他位置的 &lt;code&gt;k&lt;/code&gt; 做匹配，算出匹配程度後利用 softmax 層取得介於 0 到 1 之間的權重值，並以此權重跟每個位置的 &lt;code&gt;v&lt;/code&gt; 作加權平均，最後取得該位置的輸出向量 &lt;code&gt;o&lt;/code&gt;。全部位置的輸出向量可以同時平行計算，最後輸出序列 &lt;code&gt;O&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;計算匹配程度（注意）的方法不只一種，只要能吃進 2 個向量並吐出一個數值即可。但在 Transformer 論文原文是將 2 向量做 dot product 算匹配程度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我們可以透過大量矩陣運算以及 GPU 將概念 2 提到的注意力機制的計算全部平行化，加快訓練效率（也是本文實作的重點）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多頭注意力機制（Multi-head Attention）是將輸入序列中的每個位置的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt; 切割成多個 &lt;code&gt;qi&lt;/code&gt;、&lt;code&gt;ki&lt;/code&gt; 和 &lt;code&gt;vi&lt;/code&gt; 再分別各自進行注意力機制。各自處理完以後把所有結果串接並視情況降維。這樣的好處是能讓各個 head 各司其職，學會關注序列中不同位置在不同 representaton spaces 的資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意力機制這樣的計算的好處是「天涯若比鄰」：序列中每個位置都可以在 O(1) 的距離內關注任一其他位置的資訊，運算效率較雙向 RNN 優秀。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意層可以取代 Seq2Seq 模型裡頭以 RNN 為基礎的 Encoder / Decoder，而實際上全部替換掉後就（大致上）是 Transformer。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意力機制預設沒有「先後順序」的概念，而這也是為何其可以快速平行運算的原因。在進行如機器翻譯等序列生成任務時，我們需要額外加入位置編碼（Positioning Encoding）來加入順序資訊。而在 Transformer 原論文中此值為手設而非訓練出來的模型權重。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Transformer 是一個 Seq2Seq 模型，自然包含了 Encoder / Decoder，而 Encoder 及 Decoder 可以包含多層結構相同的 blocks，裡頭每層都會有 multi-head attention 以及 Feed Forward Network。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在每個 Encoder / Decoder block 裡頭，我們還會使用殘差連結（Residual Connection）以及 Layer Normalization。這些能幫助模型穩定訓練。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Decoder 在關注 Encoder 輸出時會需要遮罩（mask）來避免看到未來資訊。我們後面會看到，事實上還會需要其他遮罩。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這些應該是你在看完影片後學到的東西。如果你想要快速複習，這裡則是&lt;a href="https://bit.ly/2QT4loG"&gt;教授課程的 PDF 檔&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你之後也可以隨時透過左側導覽的圖片 icon 來快速回顧 Transformer 的整體架構以及教授添加的註解。我相信在實作的時候它可以幫得上點忙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-left-nav.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-left-nav.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這些背景知識以後，在理解程式碼時會輕鬆許多。你也可以一邊執行 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb"&gt;TensorFlow 官方的 Colab 筆記本&lt;/a&gt;一邊參考底下實作。&lt;/p&gt;
&lt;p&gt;好戲登場！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="安裝函式庫並設置環境"&gt;安裝函式庫並設置環境&lt;a class="anchor-link" href="#安裝函式庫並設置環境"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊我們引進一些常用的 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 函式庫，這應該不需要特別說明。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mpl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pprint&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pprint&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;clear_output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較值得注意的是我們將以&lt;a href="https://pypi.org/project/tf-nightly-2.0-preview/"&gt;最新的 TensorFlow 2 Beta 版本&lt;/a&gt;來實作本文的 Transformer。另外也會透過 &lt;a href="https://www.tensorflow.org/datasets"&gt;TensorFlow Datasets&lt;/a&gt; 來使用前人幫我們準備好的英中翻譯資料集：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;pip install tensorflow-gpu&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.0.0-beta0
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow_datasets&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tfds&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;2.0.0-beta0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外為了避免 TensorFlow 吐給我們太多不必要的資訊，在此文中我也將改變 logging 等級。&lt;a href="https://www.tensorflow.org/alpha/guide/effective_tf2#api_cleanup"&gt;在 TensorFlow 2 裡頭因為 &lt;code&gt;tf.logging&lt;/code&gt; 被 deprecated&lt;/a&gt;，我們可以直接用 &lt;code&gt;logging&lt;/code&gt;  模組來做到這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;logging&lt;/span&gt;
&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"error"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_printoptions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppress&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們同時也讓 numpy 不要顯示科學記號。這樣可以讓我們之後在做一些 Tensor 運算的時候版面能乾淨一點。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著定義一些之後在儲存檔案時會用到的路徑變數：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"nmt"&lt;/span&gt;
&lt;span class="n"&gt;en_vocab_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"en_vocab"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zh_vocab_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"zh_vocab"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;checkpoint_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"checkpoints"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;log_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'logs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;download_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"tensorflow-datasets/downloads"&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makedirs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立輸入管道"&gt;建立輸入管道&lt;a class="anchor-link" href="#建立輸入管道"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現行的 GPU 以及 TPU 能透過平行運算幫我們顯著地縮短訓練一個 step 所需的時間。而為了讓平行計算能發揮最佳性能，我們需要最佳化&lt;a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn"&gt;輸入管道（Input pipeline）&lt;/a&gt;，以在當前訓練步驟完成之前就準備好下一個時間點 GPU 要用的數據。&lt;/p&gt;
&lt;p&gt;而我們將透過 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data"&gt;tf.data API&lt;/a&gt; 以及前面導入的 &lt;a href="https://www.tensorflow.org/datasets"&gt;TensorFlow Datasets&lt;/a&gt; 來建置高效的輸入管道，並將&lt;a href="http://www.statmt.org/wmt19/"&gt;機器翻譯競賽 WMT 2019&lt;/a&gt; 的中英資料集準備好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="下載並準備資料集"&gt;下載並準備資料集&lt;a class="anchor-link" href="#下載並準備資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先看看 &lt;code&gt;tfds&lt;/code&gt; 裡頭 WMT 2019 的中英翻譯有哪些資料來源：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tmp_builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"wmt19_translate/zh-en"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subsets&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;{NamedSplit('train'): ['newscommentary_v14',
                       'wikititles_v1',
                       'uncorpus_v1',
                       'casia2015',
                       'casict2011',
                       'casict2015',
                       'datum2015',
                       'datum2017',
                       'neu2017'],
 NamedSplit('validation'): ['newstest2018']}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;可以看到在 WMT 2019 裡中英對照的數據來源還算不少。其中幾個很好猜到其性質：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聯合國數據：&lt;code&gt;uncorpus_v1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;維基百科標題：&lt;code&gt;wikititles_v1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;新聞評論：&lt;code&gt;newscommentary_v14&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然大量數據對訓練神經網路很有幫助，本文為了節省訓練 Transformer 所需的時間，在這裡我們就只選擇一個資料來源當作資料集。至於要選哪個資料來源呢？&lt;/p&gt;
&lt;p&gt;聯合國的數據非常龐大，而維基百科標題通常內容很短，&lt;a href="http://www.casmacat.eu/corpus/news-commentary.html"&gt;新聞評論&lt;/a&gt;感覺是一個相對適合的選擇。我們可以在設定檔 &lt;code&gt;config&lt;/code&gt; 裡頭指定新聞評論這個資料來源並請 TensorFlow Datasets 下載：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;translate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wmt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WmtConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"0.0.2"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="n"&gt;language_pair&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"zh"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="n"&gt;subsets&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Split&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"newscommentary_v14"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"wmt_translate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download_and_prepare&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;download_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;download_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tfds-demo.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/tfds-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的指令約需 2 分鐘完成，而在過程中 &lt;code&gt;tfds&lt;/code&gt; 幫我們完成不少工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下載包含原始數據的壓縮檔&lt;/li&gt;
&lt;li&gt;解壓縮得到 CSV 檔案&lt;/li&gt;
&lt;li&gt;逐行讀取該 CSV 裡頭所有中英句子&lt;/li&gt;
&lt;li&gt;將不符合格式的 row 自動過濾&lt;/li&gt;
&lt;li&gt;Shuffle 數據&lt;/li&gt;
&lt;li&gt;將原數據轉換成 &lt;a href="https://www.tensorflow.org/alpha/guide/data#consuming_tfrecord_data"&gt;TFRecord 數據&lt;/a&gt;以加速讀取&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多花點時間把相關 &lt;a href="https://www.tensorflow.org/datasets/datasets#wmt19_translate"&gt;API 文件&lt;/a&gt;看熟，你就能把清理、準備數據的時間花在建構模型以及跑實驗上面。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="切割資料集"&gt;切割資料集&lt;a class="anchor-link" href="#切割資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們只下載了一個新聞評論的數據集，裡頭還是有超過 30 萬筆的中英平行句子。為了減少訓練所需的時間，讓我們使用 &lt;code&gt;tfds.Split&lt;/code&gt; 定義一個將此數據集切成多個部分的 &lt;code&gt;split&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_perc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;val_prec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;drop_prec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;train_perc&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;val_prec&lt;/span&gt;

&lt;span class="n"&gt;split&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Split&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subsplit&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;train_perc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_prec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;drop_prec&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;split&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(NamedSplit('train')(tfds.percent[0:20]),
 NamedSplit('train')(tfds.percent[20:21]),
 NamedSplit('train')(tfds.percent[21:100]))&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個 &lt;code&gt;split&lt;/code&gt; 請 &lt;code&gt;tfds&lt;/code&gt; 將剛剛處理好的新聞評論資料集再進一步切成 3 個部分，數據量分佈如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split 1：20% 數據&lt;/li&gt;
&lt;li&gt;Split 2：1% 數據&lt;/li&gt;
&lt;li&gt;Split 3：79% 數據&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們將前兩個 splits 拿來當作訓練以及驗證集，剩餘的部分（第 3 個 split）捨棄不用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;as_supervised&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_examples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;examples&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&amp;lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&amp;gt;
&amp;lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以在&lt;a href="https://github.com/tensorflow/datasets/blob/master/docs/splits.md"&gt;這邊&lt;/a&gt;找到更多跟 &lt;code&gt;split&lt;/code&gt; 相關的用法。&lt;/p&gt;
&lt;p&gt;這時候 &lt;code&gt;train_examples&lt;/code&gt; 跟 &lt;code&gt;val_examples&lt;/code&gt; 都已經是 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"&gt;tf.data.Dataset&lt;/a&gt;。我們在&lt;a href="#前處理數據"&gt;前處理數據&lt;/a&gt;一節會看到這些數據在被丟入神經網路前需要經過什麼轉換，不過現在先讓我們簡單讀幾筆數據出來看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tf.Tensor(b'Making Do With More', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97', shape=(), dtype=string)
----------
tf.Tensor(b'If the Putins, Erdo\xc4\x9fans, and Orb\xc3\xa1ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa6\x82\xe6\x9e\x9c\xe6\x99\xae\xe4\xba\xac\xe3\x80\x81\xe5\x9f\x83\xe5\xb0\x94\xe5\xa4\x9a\xe5\xae\x89\xe5\x92\x8c\xe6\xac\xa7\xe5\xb0\x94\xe7\x8f\xad\xe5\xb8\x8c\xe6\x9c\x9b\xe7\xbb\xa7\xe7\xbb\xad\xe4\xba\xab\xe6\x9c\x89\xe5\xbc\x80\xe6\x94\xbe\xe5\x9b\xbd\xe9\x99\x85\xe4\xbd\x93\xe7\xb3\xbb\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe7\xbb\x8f\xe6\xb5\x8e\xe5\x88\xa9\xe7\x9b\x8a\xef\xbc\x8c\xe5\xb0\xb1\xe4\xb8\x8d\xe8\x83\xbd\xe7\xae\x80\xe5\x8d\x95\xe5\x9c\xb0\xe5\x88\xb6\xe5\xae\x9a\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x82', shape=(), dtype=string)
----------
tf.Tensor(b'This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.', shape=(), dtype=string)
tf.Tensor(b'\xe5\x8f\xaa\xe6\x9c\x89\xe5\x9c\xa8\xe5\x8f\x91\xe7\x94\x9f\xe6\xb7\xb1\xe5\xba\xa6\xe8\x90\xa7\xe6\x9d\xa1\xe6\x88\x96\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x8d\xe5\xb8\xb8\xe4\xba\x8b\xe4\xbb\xb6\xe6\x97\xb6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\x80\xe4\xb8\x8a\xe9\x99\x90\xe6\x89\x8d\xe8\x83\xbd\xe5\x81\x9a\xe5\x87\xba\xe8\xb0\x83\xe6\x95\xb4\xef\xbc\x8c\xe4\xbb\xa5\xe4\xbe\xbf\xe8\xae\xa9\xe5\x8f\x8d\xe5\x91\xa8\xe6\x9c\x9f\xe6\x94\xbf\xe7\xad\x96\xe5\xae\x9e\xe6\x96\xbd\xe8\xb6\xb3\xe5\xa4\x9f\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe4\xbd\xbf\xe4\xba\xba\xe4\xbb\xac\xe4\xb8\x80\xe8\x87\xb4\xe8\xae\xa4\xe4\xb8\xba\xe5\xa2\x9e\xe5\x8a\xa0\xe7\x9a\x84\xe8\xb5\xa4\xe5\xad\x97\xe6\x98\xaf\xe5\x91\xa8\xe6\x9c\x9f\xe6\x80\xa7\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe7\xbb\x93\xe6\x9e\x84\xe6\x80\xa7\xe7\x9a\x84\xe3\x80\x82', shape=(), dtype=string)
----------
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟預期一樣，每一個例子（每一次的 &lt;code&gt;take&lt;/code&gt;）都包含了 2 個以 unicode 呈現的 &lt;code&gt;tf.Tensor&lt;/code&gt;。它們有一樣的語義，只是一個是英文，一個是中文。&lt;/p&gt;
&lt;p&gt;讓我們將這些 Tensors 實際儲存的字串利用 &lt;code&gt;numpy()&lt;/code&gt; 取出並解碼看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"utf-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"utf-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 之後用來簡單評估模型的訓練情況&lt;/span&gt;
  &lt;span class="n"&gt;sample_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Making Do With More
多劳应多得
----------
If the Putins, Erdoğans, and Orb&amp;aacute;ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.
如果普京、埃尔多安和欧尔班希望继续享有开放国际体系提供的经济利益，就不能简单地制定自己的规则。
----------
This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.
只有在发生深度萧条或其他反常事件时，这一上限才能做出调整，以便让反周期政策实施足够的长度，使人们一致认为增加的赤字是周期性的，而不是结构性的。
----------
Fascist and communist regimes of the past, which followed a similar instrumentalist approach to democracy, come to mind here.
在此我们想起了过去的法西斯主义和共产主义。 它们都相似地将民主作为实现其目的的工具。
----------
This phase culminated with the collapse of communism in 1989, but the chance to overcome the Continent&amp;rsquo;s historical divisions now required a redefinition of the European project.
这种状态随着1989年共产主义崩溃而达至巅峰，但是克服欧洲大陆历史性分裂的机遇现在需要重新定义欧洲计划。
----------
The eurozone&amp;rsquo;s collapse (and, for all practical purposes, that of the EU itself) forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。
----------
With energy and enthusiasm, Burden turned that operation into a thriving health (not health-care) agency that covers three cities and about 300,000 people on the western edge of Los Angeles.
在能量与激情的推动下，波顿将BCHD打造成了欣欣向荣的健康（而非医疗）机构，其服务范围覆盖了洛杉矶西侧三座城市的30万人。
----------
The result could be a world of fragmented blocs &amp;ndash; an outcome that would undermine not only global prosperity, but also cooperation on shared challenges.
其结果可能是一个四分五裂的世界 &amp;mdash; &amp;mdash; 这一结果不但会破坏全球繁荣，也会破坏面对共同挑战的合作。
----------
Among the questions being asked by NGOs, the UN, and national donors is how to prevent the recurrence of past mistakes.
现在NGO们、联合国和捐助国们问得最多的一个问题就是如何避免再犯过去的错误。
----------
Managing the rise of NCDs will require long-term thinking, and government leaders will have to make investments that might pay off only after they are no longer in office.
管理NCD的增加需要长期思维，政府领导人必须进行要在他们离任多年后才能收回成本的投资。
----------
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想像一下沒有對應的中文，要閱讀這些英文得花多少時間。你可以試著消化其中幾句中文與其對應的英文句子，並比較一下所需要的時間差異。&lt;/p&gt;
&lt;p&gt;雖然只是隨意列出的 10 個中英句子，你應該跟我一樣也能感受到機器翻譯研究的重要以及其能帶給我們的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建立中文與英文字典"&gt;建立中文與英文字典&lt;a class="anchor-link" href="#建立中文與英文字典"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就跟大多數 NLP 專案相同，有了原始的中英句子以後我們得分別為其建立字典來將每個詞彙轉成索引（Index）。&lt;code&gt;tfds.features.text&lt;/code&gt; 底下的 &lt;code&gt;SubwordTextEncoder&lt;/code&gt; 提供非常方便的 API 讓我們掃過整個訓練資料集並建立字典。&lt;/p&gt;
&lt;p&gt;首先為英文語料建立字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
try:
  subword_encoder_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)
  print(f"載入已建立的字典： {en_vocab_file}")
except:
  print("沒有已建立的字典，從頭建立。")
  subword_encoder_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(
      (en.numpy() for en, _ in train_examples), 
      target_vocab_size=2**13) # 有需要可以調整字典大小
  
  # 將字典檔案存下以方便下次 warmstart
  subword_encoder_en.save_to_file(en_vocab_file)
  

print(f"字典大小：{subword_encoder_en.vocab_size}")
print(f"前 10 個 subwords：{subword_encoder_en.subwords[:10]}")
print()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;載入已建立的字典： /content/gdrive/My Drive/nmt/en_vocab
字典大小：8135
前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'that_', 'is_']

CPU times: user 41 ms, sys: 7.43 ms, total: 48.4 ms
Wall time: 391 ms
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你的語料庫（corpus） 不小，要掃過整個資料集並建立一個字典得花不少時間。因此實務上我們會先使用 &lt;code&gt;load_from_file&lt;/code&gt; 函式嘗試讀取之前已經建好的字典檔案，失敗才 &lt;code&gt;build_from_corpus&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;這招很基本，但在你需要重複處理巨大語料庫時非常重要。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;subword_encoder_en&lt;/code&gt; 則是利用 &lt;a href="https://arxiv.org/pdf/1609.08144.pdf"&gt;GNMT 當初推出的 wordpieces&lt;/a&gt; 來進行斷詞，而簡單來說其產生的子詞（subword）介於這兩者之間：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用英文字母分隔的斷詞（character-delimited）&lt;/li&gt;
&lt;li&gt;用空白分隔的斷詞（word-delimited）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在掃過所有英文句子以後，&lt;code&gt;subword_encoder_en&lt;/code&gt; 建立一個有 8135 個子詞的字典。我們可以用該字典來幫我們將一個英文句子轉成對應的索引序列（index sequence）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Taiwan is beautiful.'&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[2700, 7911, 10, 2942, 7457, 1163, 7925]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣的索引序列你應該已經見怪不怪了。我們在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;以前的 NLP 入門文章&lt;/a&gt;也使用 &lt;code&gt;tf.keras&lt;/code&gt; 裡頭的 &lt;code&gt;Tokenizer&lt;/code&gt; 做過類似的事情。&lt;/p&gt;
&lt;p&gt;接著讓我們將這些索引還原，看看它們的長相：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{0:10}{1:6}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Index"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Subword"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;subword&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{0:5}{1:6}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Index     Subword
---------------
 2700     Taiwan
 7911      
   10     is 
 2942     bea
 7457     uti
 1163     ful
 7925     .
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當 subword tokenizer 遇到從沒出現過在字典裡的詞彙，會將該詞拆成多個子詞（subwords）。比方說上面句中的 &lt;code&gt;beautiful&lt;/code&gt; 就被拆成 &lt;code&gt;bea uti ful&lt;/code&gt;。這也是為何這種斷詞方法比較不怕沒有出現過在字典裡的字（out-of-vocabulary words）。&lt;/p&gt;
&lt;p&gt;另外別在意我為了對齊寫的 &lt;code&gt;print&lt;/code&gt; 語法。重點是我們可以用 &lt;code&gt;subword_encoder_en&lt;/code&gt; 的 &lt;code&gt;decode&lt;/code&gt; 函式再度將索引數字轉回其對應的子詞。編碼與解碼是 2 個完全可逆（invertable）的操作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Taiwan is beautiful.'&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;decoded_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;decoded_string&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;sample_string&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;decoded_string&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;('Taiwan is beautiful.', 'Taiwan is beautiful.')
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;酷！接著讓我們如法炮製，為中文也建立一個字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
try:
  subword_encoder_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)
  print(f"載入已建立的字典： {zh_vocab_file}")
except:
  print("沒有已建立的字典，從頭建立。")
  subword_encoder_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(
      (zh.numpy() for _, zh in train_examples), 
      target_vocab_size=2**13, # 有需要可以調整字典大小
      max_subword_length=1) # 每一個中文字就是字典裡的一個單位
  
  # 將字典檔案存下以方便下次 warmstart 
  subword_encoder_zh.save_to_file(zh_vocab_file)

print(f"字典大小：{subword_encoder_zh.vocab_size}")
print(f"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}")
print()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;載入已建立的字典： /content/gdrive/My Drive/nmt/zh_vocab
字典大小：4201
前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']

CPU times: user 27.6 ms, sys: 121 &amp;micro;s, total: 27.7 ms
Wall time: 337 ms
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在使用 &lt;code&gt;build_from_corpus&lt;/code&gt; 函式掃過整個中文資料集時，我們將 &lt;code&gt;max_subword_length&lt;/code&gt; 參數設置為 1。這樣可以讓每個漢字都會被視為字典裡頭的一個單位。畢竟跟英文的 abc 字母不同，一個漢字代表的意思可多得多了。而且如果使用 n-gram 的話可能的詞彙組合太多，在小數據集的情況非常容易遇到不存在字典裡頭的字。&lt;/p&gt;
&lt;p&gt;另外所有漢字也就大約 4000 ~ 5000 個可能，作為一個分類問題（classification problem）還是可以接受的。&lt;/p&gt;
&lt;p&gt;讓我們挑個中文句子來測試看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_examples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;多劳应多得
[48, 557, 116, 48, 81]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好的，我們把中英文斷詞及字典的部分都搞定了。現在給定一個例子（example，在這邊以及後文指的都是一組包含同語義的中英平行句子），我們都能將其轉換成對應的索引序列了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"The eurozone&amp;rsquo;s collapse forces a major realignment of European politics."&lt;/span&gt;
&lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"欧元区的瓦解强迫欧洲政治进行一次重大改组。"&lt;/span&gt;

&lt;span class="c1"&gt;# 將文字轉成為 subword indices&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"[英中原文]（轉換前）"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"[英中序列]（轉換後）"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[英中原文]（轉換前）
The eurozone&amp;rsquo;s collapse forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。

--------------------

[英中序列]（轉換後）
[17, 965, 11, 6, 1707, 676, 8, 211, 2712, 6683, 249, 3, 85, 1447, 7925]
[45, 206, 171, 1, 847, 197, 236, 604, 45, 90, 17, 130, 102, 36, 7, 284, 80, 18, 212, 265, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們針對這些索引序列（index sequence）做一些前處理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="前處理數據"&gt;前處理數據&lt;a class="anchor-link" href="#前處理數據"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在處理序列數據時我們時常會在一個序列的前後各加入一個特殊的 token，以標記該序列的開始與完結，而它們常有許多不同的稱呼：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;開始 token、&lt;strong&gt;B&lt;/strong&gt;egin &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;S&lt;/strong&gt;entence、BOS、&lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;結束 token、&lt;strong&gt;E&lt;/strong&gt;nd &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;S&lt;/strong&gt;entence、EOS、&lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這邊我們定義了一個將被 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 使用的 &lt;code&gt;encode&lt;/code&gt; 函式，它的輸入是一筆包含 2 個 &lt;code&gt;string&lt;/code&gt; Tensors 的例子，輸出則是 2 個包含 BOS / EOS 的索引序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 因為字典的索引從 0 開始，&lt;/span&gt;
  &lt;span class="c1"&gt;# 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值&lt;/span&gt;
  &lt;span class="c1"&gt;# 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值&lt;/span&gt;
  &lt;span class="n"&gt;en_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="c1"&gt;# 同理，不過是使用中文字典的最後一個索引 + 1&lt;/span&gt;
  &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 裡頭都是在操作 Tensors（而非 Python 字串），所以這個 &lt;code&gt;encode&lt;/code&gt; 函式預期的輸入也是 TensorFlow 裡的 &lt;a href="https://www.tensorflow.org/guide/eager"&gt;Eager Tensors&lt;/a&gt;。但只要我們使用 &lt;code&gt;numpy()&lt;/code&gt; 將 Tensor 裡的實際字串取出以後，做的事情就跟上一節完全相同。&lt;/p&gt;
&lt;p&gt;讓我們從訓練集裡隨意取一組中英的 Tensors 來看看這個函式的實際輸出：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'英文 BOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'英文 EOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'中文 BOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'中文 EOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;輸入為 2 個 Tensors：'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'輸出為 2 個索引序列：'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文 BOS 的 index： 8135
英文 EOS 的 index： 8136
中文 BOS 的 index： 4201
中文 EOS 的 index： 4202

輸入為 2 個 Tensors：
(&amp;lt;tf.Tensor: id=306, shape=(), dtype=string, numpy=b'Making Do With More'&amp;gt;,
 &amp;lt;tf.Tensor: id=307, shape=(), dtype=string, numpy=b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97'&amp;gt;)
---------------
輸出為 2 個索引序列：
([8135, 4682, 19, 717, 7911, 298, 2701, 7980, 8136],
 [4201, 48, 557, 116, 48, 81, 4202])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到不管是英文還是中文的索引序列，前面都加了一個代表 BOS 的索引（分別為 8135 與 4201），最後一個索引則代表 EOS（分別為 8136 與 4202）&lt;/p&gt;
&lt;p&gt;但如果我們將 &lt;code&gt;encode&lt;/code&gt; 函式直接套用到整個訓練資料集時會產生以下的錯誤訊息：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/tf-dataset-map-error.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是因為目前 &lt;code&gt;tf.data.Dataset.map&lt;/code&gt; 函式裡頭的計算是在&lt;a href="https://www.tensorflow.org/guide/graphs"&gt;計算圖模式（Graph mode）&lt;/a&gt;下執行，所以裡頭的 Tensors 並不會有 &lt;a href="https://www.tensorflow.org/alpha/guide/eager"&gt;Eager Execution&lt;/a&gt; 下才有的 &lt;code&gt;numpy&lt;/code&gt; 屬性。&lt;/p&gt;
&lt;p&gt;解法是使用 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/py_function"&gt;tf.py_function&lt;/a&gt; 將我們剛剛定義的 &lt;code&gt;encode&lt;/code&gt; 函式包成一個以 eager 模式執行的 TensorFlow Op：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors&lt;/span&gt;
  &lt;span class="c1"&gt;# 要到 `tf.py_funtion` 裡頭才是&lt;/span&gt;
  &lt;span class="c1"&gt;# 另外因為索引都是整數，所以使用 `tf.int64`&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，&lt;/span&gt;
&lt;span class="c1"&gt;# 我們會從頭建立一個正式的 `train_dataset`&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stderr output_text"&gt;
&lt;pre&gt;W0616 23:46:10.571188 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.573221 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tf.Tensor([8135 4682   19  717 7911  298 2701 7980 8136], shape=(9,), dtype=int64)
tf.Tensor([4201   48  557  116   48   81 4202], shape=(7,), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有點 tricky 但任務完成！注意在套用 &lt;code&gt;map&lt;/code&gt; 函式以後，&lt;code&gt;tmp_dataset&lt;/code&gt; 的輸出已經是兩個索引序列，而非原文字串。&lt;/p&gt;
&lt;p&gt;為了讓 Transformer  快點完成訓練，讓我們將長度超過 40 個 tokens 的序列都去掉吧！我們在底下定義了一個布林（boolean）函式，其輸入為一個包含兩個英中序列 &lt;code&gt;en, zh&lt;/code&gt; 的例子，並在只有這 2 個序列的長度都小於 40 的時候回傳真值（True）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# en, zh 分別代表英文與中文的索引序列&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logical_and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;簡單檢查是否有序列超過我們指定的長度，順便計算過濾掉過長序列後剩餘的訓練集筆數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 因為我們數據量小可以這樣 count&lt;/span&gt;
&lt;span class="n"&gt;num_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cond1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;
  &lt;span class="n"&gt;cond2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;
  &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;cond1&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;cond2&lt;/span&gt;
  &lt;span class="n"&gt;num_examples&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"訓練資料集裡總共有 {num_examples} 筆數據"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;訓練資料集裡總共有 29914 筆數據
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;過濾掉較長句子後還有接近 3 萬筆的訓練例子，看來不用擔心數據太少。&lt;/p&gt;
&lt;p&gt;最後值得注意的是每個例子裡的索引序列長度不一，這在建立 batch 時可能會發生問題。不過別擔心，輪到 &lt;code&gt;padded_batch&lt;/code&gt; 函式出場了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="c1"&gt;# 將 batch 裡的所有序列都 pad 到同樣長度&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"英文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"中文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stderr output_text"&gt;
&lt;pre&gt;W0616 23:46:10.753194 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.760091 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.768630 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文索引序列的 batch
tf.Tensor(
[[8135 4682   19 ...    0    0    0]
 [8135   17  965 ... 8136    0    0]
 [8135 6602    2 ...    0    0    0]
 ...
 [8135 1097  270 ...    0    0    0]
 [8135 1713   70 ...    0    0    0]
 [8135 2731 4553 ...    0    0    0]], shape=(64, 34), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201   48  557 ...    0    0    0]
 [4201   45  206 ...    0    0    0]
 [4201   58    5 ...  683    3 4202]
 ...
 [4201   29  120 ...    0    0    0]
 [4201  297  161 ...    0    0    0]
 [4201  279  149 ... 4202    0    0]], shape=(64, 40), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;padded_batch&lt;/code&gt; 函式能幫我們將每個 batch 裡頭的序列都補 0 到跟當下 batch 裡頭最長的序列一樣長。&lt;/p&gt;
&lt;p&gt;比方說英文 batch 裡最長的序列為 34；而中文 batch 裡最長的序列則長達 40 個 tokens，剛好是我們前面設定過的序列長度上限。&lt;/p&gt;
&lt;p&gt;好啦，現在讓我們從頭建立訓練集與驗證集，順便看看這些中英句子是如何被轉換成它們的最終形態的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15000&lt;/span&gt;

&lt;span class="c1"&gt;# 訓練集&lt;/span&gt;
&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;  &lt;span class="c1"&gt;# 輸出：(英文句子, 中文句子)&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 輸出：(英文索引序列, 中文索引序列)&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 同上，且序列長度都不超過 40&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# 加快讀取數據&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 將例子洗牌確保隨機性&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;# 將 batch 裡的序列都 pad 到一樣長度&lt;/span&gt;
                               &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prefetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;experimental&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AUTOTUNE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 加速&lt;/span&gt;
&lt;span class="c1"&gt;# 驗證集&lt;/span&gt;
&lt;span class="n"&gt;val_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val_examples&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                             &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;建構訓練資料集時我們還添加了些沒提過的函式。它們的用途大都是用來提高輸入效率，並不會影響到輸出格式。如果你想深入了解這些函式的運作方式，可以參考 &lt;a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn"&gt;tf.data 的官方教學&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在讓我們看看最後建立出來的資料集長什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"英文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"中文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文索引序列的 batch
tf.Tensor(
[[8135  222    1 ...    0    0    0]
 [8135 3812  162 ...    0    0    0]
 [8135 6267  838 ...    0    0    0]
 ...
 [8135   17 1042 ...    0    0    0]
 [8135 7877 1165 ...    0    0    0]
 [8135 6414 7911 ...    0    0    0]], shape=(128, 40), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201  109   54 ...    3 4202    0]
 [4201   30    4 ...    0    0    0]
 [4201  402    4 ...    0    0    0]
 ...
 [4201  626  515 ...    0    0    0]
 [4201   49  249 ...    0    0    0]
 [4201  905  209 ...    0    0    0]], shape=(128, 40), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嘿！我們建立了一個可供訓練的輸入管道（Input pipeline）！&lt;/p&gt;
&lt;p&gt;你會發現訓練集：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一次回傳大小為 128 的 2 個 batch，分別包含 128 個英文、中文的索引序列&lt;/li&gt;
&lt;li&gt;序列開頭皆為 BOS，英文的 BOS 索引是 8135；中文的 BOS 索引則為 4201&lt;/li&gt;
&lt;li&gt;兩語言 batch 裡的序列都被「拉長」到我們先前定義的最長序列長度：40&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;驗證集也是相同的輸出形式。&lt;/p&gt;
&lt;p&gt;現在你應該可以想像我們在每個訓練步驟會拿出來的數據長什麼樣子了：2 個 shape 為 (batch_size, seq_len) 的 Tensors，而裡頭的每一個索引數字都代表著一個中 / 英文子詞（或是 BOS / EOS）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這一節我們建立了一個通用資料集。「通用」代表不限於 Transformer，你也能用&lt;a href="https://www.tensorflow.org/beta/tutorials/text/nmt_with_attention"&gt;一般搭配注意力機制的 Seq2Seq 模型&lt;/a&gt;來處理這個資料集並做中英翻譯。&lt;/p&gt;
&lt;p&gt;但從下節開始讓我們把這個數據集先擺一邊，將注意力全部放到 Transformer 身上並逐一實作其架構裡頭的各個元件。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="理解-Transformer-之旅：跟著多維向量去冒險_1"&gt;理解 Transformer 之旅：跟著多維向量去冒險&lt;a class="anchor-link" href="#理解-Transformer-之旅：跟著多維向量去冒險"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實作 Transformer 及注意力機制這種高度平行運算的模型時，你將需要一點「空間想像力」，能夠想像最高高達 4 維的向量是怎麼在 Transformer 的各個元件被處理與轉換的。&lt;/p&gt;
&lt;p&gt;如果你跟我一樣腦袋並不是那麼靈光的話，這可不是一件簡單的事情。不過別擔心，從這節開始我會把 Transfomer （主要針對注意力機制）裡頭的矩陣運算過程視覺化（visualize）出來，讓你在這個多維空間裡頭也能悠遊自在。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/the-matrix-world.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Welcome to matrix, 準備進入多維空間
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就好像一般你在寫程式時會追蹤某些變數在函式裡頭的變化，一個直觀理解 Transformer 的方法是將幾個句子丟入其中，並觀察 Transformer 對它們做了些什麼轉換。&lt;/p&gt;
&lt;p&gt;首先讓我們建立兩個要拿來持續追蹤的中英平行句子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;demo_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"It is important."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"这很重要。"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"The numbers speak for themselves."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"数字证明了一切。"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[('It is important.', '这很重要。'),
 ('The numbers speak for themselves.', '数字证明了一切。')]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著利用&lt;a href="#建立輸入管道"&gt;之前建立資料集的方法&lt;/a&gt;將這 2 組中英句子做些前處理並以 Tensor 的方式讀出：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;demo_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_tensor_slices&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）&lt;/span&gt;
&lt;span class="c1"&gt;# 並添加 padding token: &amp;lt;pad&amp;gt; 來確保 batch 裡的句子有一樣長度&lt;/span&gt;
&lt;span class="n"&gt;demo_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

&lt;span class="c1"&gt;# 取出這個 demo dataset 裡唯一一個 batch&lt;/span&gt;
&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;demo_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'inp:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tar:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)

tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上節建立的數據集屍骨未寒，你應該還記得 &lt;code&gt;inp&lt;/code&gt;  shape 裡頭第一個維度的 &lt;code&gt;2&lt;/code&gt; 代表著這個 batch 有 2 個句子，而第二維度的 &lt;code&gt;8&lt;/code&gt; 則代表著句子的長度（單位：子詞）；&lt;code&gt;tar&lt;/code&gt; 則為中文子詞序列（subword sequence），不過因為中文我們以漢字為單位作斷詞，長度一般會比對應的英文句子來的長（shape 中的 &lt;code&gt;10&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;2 維矩陣還很容易想像，但我擔心等到你進入 3 維空間後就會想放棄人生了。所以還是先讓我們用人類比較容易理解的方式來呈現這些數據。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="視覺化原始句子"&gt;視覺化原始句子&lt;a class="anchor-link" href="#視覺化原始句子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們把這 2 個 batch 用你比較熟悉的方式呈現的話會長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/inp_tar.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/inp_tar.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣清楚多了不是嗎？現在點擊播放鍵，將索引序列還原成原始的子詞序列。&lt;/p&gt;
&lt;p&gt;你可以清楚地看到每個&lt;strong&gt;原始&lt;/strong&gt;句子前後都有 &lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt; 與 &lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt;。而為了讓同個 batch 裡頭的序列長度相同，我們在較短的序列後面也補上足夠的 0，代表著 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;這個視覺化非常簡單，但十分強大。我現在要你記住一些本文會使用的慣例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不管&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F"&gt;張量（Tensor）&lt;/a&gt;變幾維，其第一個維度 &lt;code&gt;shape[0]&lt;/code&gt; 永遠代表 &lt;code&gt;batch_size&lt;/code&gt;，也就代表著句子的數目&lt;/li&gt;
&lt;li&gt;不同句子我們用不同顏色表示，方便你之後對照這些句子在轉換前後的差異&lt;/li&gt;
&lt;li&gt;x 軸（橫軸）代表張量的最後一個維度 &lt;code&gt;shape[-1]&lt;/code&gt;，以上例來說分別為 &lt;code&gt;8&lt;/code&gt; 和 &lt;code&gt;10&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;x, y 軸上的標籤分別代表倒數兩個維度 &lt;code&gt;shape[-2]&lt;/code&gt; 及 &lt;code&gt;shape[-1]&lt;/code&gt; 其所代表的物理含義，如圖中的&lt;strong&gt;句子&lt;/strong&gt;與&lt;strong&gt;子詞&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;圖中張量的 &lt;code&gt;name&lt;/code&gt; 會對應到程式碼裡頭定義的變數名稱，方便你對照並理解實作邏輯。我也會秀出張量的 shape  幫助你想像該向量在多維空間的長相。一個簡單的例子是：&lt;code&gt;(batch_size, tar_seq_len)&lt;/code&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些準則與資訊現在看似多餘，但我保證你很快就會需要它們。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="視覺化-3-維詞嵌入張量"&gt;視覺化 3 維詞嵌入張量&lt;a class="anchor-link" href="#視覺化-3-維詞嵌入張量"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在將索引序列丟入神經網路之前，我們一般會做&lt;a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B5%8C%E5%85%A5"&gt;詞嵌入（word embedding）&lt;/a&gt;，將一個維度為字典大小的高維離散空間「嵌入」到低維的連續空間裡頭。&lt;/p&gt;
&lt;p&gt;讓我們為英文與中文分別建立一個詞嵌入層並實際對 &lt;code&gt;inp&lt;/code&gt; 及 &lt;code&gt;tar&lt;/code&gt; 做轉換：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# + 2 是因為我們額外加了 &amp;lt;start&amp;gt; 以及 &amp;lt;end&amp;gt; tokens&lt;/span&gt;
&lt;span class="n"&gt;vocab_size_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;vocab_size_zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="c1"&gt;# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer_zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size_zh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;emb_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer_en&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;emb_tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer_zh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意你的詞嵌入層的隨機初始值會跟我不同，結果可能會有一點差異。&lt;/p&gt;
&lt;p&gt;但重點是你能在腦海中理解這兩個 3 維張量嗎？花了幾秒鐘？我相信在座不乏各路高手，而且事實上在這一行混久了，你也必須能直覺地理解這個表示方式。&lt;/p&gt;
&lt;p&gt;但如果有更好的呈現方式幫助我們理解數據，何樂而不為呢？讓我們再次視覺化這兩個 3 維詞嵌入張量：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/emb_inp_tar.jpeg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/emb_inp_tar.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照前面提過的準則，張量中第一個維度的 &lt;code&gt;2&lt;/code&gt; 代表著句子數 &lt;code&gt;batch_size&lt;/code&gt;。在 3 維空間裡頭，我會將不同句子畫在 z 軸上，也就是你現在把臉貼近 /  遠離螢幕這個維度。你同時也能用不同顏色來區分句子。&lt;/p&gt;
&lt;p&gt;緊跟著句子的下一個維度則一樣是本來的子詞（subword）。只是現在每個子詞都已從一個索引數字被轉換成一個 4 維的詞嵌入向量，因此每個子詞都以 y 軸來表示。最後一維則代表著詞嵌入空間的維度，一樣以 x 軸來表示。&lt;/p&gt;
&lt;p&gt;現在再次點擊播放鍵。&lt;/p&gt;
&lt;p&gt;在學會怎麼解讀這個 3 維詞嵌入張量以後，你就能明白為何 &lt;code&gt;emb_tar&lt;/code&gt; 第一個中文句子裡頭的倒數 3 行（row) 都長得一樣了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar[0]:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar[0]:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)
--------------------
emb_tar[0]: tf.Tensor(
[[-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]], shape=(3, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;它們都是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token（以 &lt;code&gt;0&lt;/code&gt; 表示），理當有一樣的詞嵌入向量。&lt;/p&gt;
&lt;p&gt;不同顏色也讓我們可以很直觀地理解一個句子是怎麼從一個 1 維向量被轉換到 2 維的。你後面就會發現，你將需要能夠非常直覺地理解像是 &lt;code&gt;emb_tar&lt;/code&gt; 這種 3 維張量裡頭每個維度所代表的意義。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="遮罩：Transformer-的祕密配方"&gt;遮罩：Transformer 的祕密配方&lt;a class="anchor-link" href="#遮罩：Transformer-的祕密配方"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在前面並沒有仔細談過遮罩（masking）的概念，但事實上它可以說是在實作 Transformer 時最重要卻也最容易被搞砸的一環。它讓 Transformer 在進行自注意力機制（Self-Attention Mechanism）時不至於偷看到不該看的。&lt;/p&gt;
&lt;p&gt;在 Transformer 裡頭有兩種 masks：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;padding mask&lt;/li&gt;
&lt;li&gt;look ahead mask&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;padding mask 是讓 Transformer 用來識別序列實際的內容到哪裡。此遮罩負責的就是將序列中被補 0 的地方（也就是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;）的位置蓋住，讓 Transformer 可以避免「關注」到這些位置。&lt;/p&gt;
&lt;p&gt;look ahead mask 人如其名，是用來確保 Decoder 在進行自注意力機制時每個子詞只會「往前看」：關注（包含）自己之前的字詞，不會不小心關注「未來」Decoder 產生的子詞。我們後面還會看到 look ahead mask 的詳細介紹，但不管是哪一種遮罩向量，那些值為 1 的位置就是遮罩存在的地方。&lt;/p&gt;
&lt;p&gt;因為 padding mask 的概念相對簡單，讓我們先看這種遮罩：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# padding mask 的工作就是把索引序列中為 0 的位置設為 1&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;#　broadcasting&lt;/span&gt;

&lt;span class="n"&gt;inp_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;inp_mask&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193029, shape=(2, 1, 1, 8), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],


       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;登登！我們的第一個 4 維張量！不過別緊張，我們在中間加了 2 個新維度是為了之後可以做 &lt;a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html"&gt;broadcasting&lt;/a&gt;，現在可以忽視。喔！不過如果這是你第一次聽到 broadcasting，我強烈建議你現在就閱讀 &lt;a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html"&gt;numpy 官方的簡短教學&lt;/a&gt;了解其概念。我們後面也會看到實際的 broadcasting 例子。&lt;/p&gt;
&lt;p&gt;回到我們的 &lt;code&gt;inp_mask&lt;/code&gt; 遮罩。現在我們可以先將額外的維度去掉以方便跟 &lt;code&gt;inp&lt;/code&gt; 作比較：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tf.squeeze(inp_mask):"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
tf.squeeze(inp_mask): tf.Tensor(
[[0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到 &lt;code&gt;inp_mask&lt;/code&gt; 將 &lt;code&gt;inp&lt;/code&gt; 裡頭為 &lt;code&gt;0&lt;/code&gt; 的對應位置設為 1 凸顯出來，這樣之後其他函式就知道要把哪邊「遮住」。 讓我們看看被降到 2 維的 &lt;code&gt;inp_mask&lt;/code&gt; 是怎麼被套用在 &lt;code&gt;inp&lt;/code&gt; 身上的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/padding_mask.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很好懂，不是嗎？但這只是小暖身，等到之後要將遮罩 broadcast 到 3、4 維張量的時候你可能會黑人問號，所以最好做點心理準備（笑&lt;/p&gt;
&lt;p&gt;至於另外一種遮罩 look ahead mask，等我們說明完下節的注意函式以後你會比較容易理解它的作用，所以先賣個關子。現在讓我們進入 Tranformer 最核心的部分：注意力機制。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Scaled-dot-product-attention：一種注意函式"&gt;Scaled dot product attention：一種注意函式&lt;a class="anchor-link" href="#Scaled-dot-product-attention：一種注意函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在文中以及教授的影片已經多次看到，所謂的注意力機制（或稱注意函式，attention function）概念上就是拿一個查詢（query）去跟一組 key-values 做運算，最後產生一個輸出。只是我們會利用矩陣運算同時讓多個查詢跟一組 key-values 做運算，最大化計算效率。&lt;/p&gt;
&lt;p&gt;而不管是查詢（query）、鍵值（keys）還是值（values）或是輸出，全部都是向量（vectors）。該輸出是 values 的加權平均，而每個 value  獲得的權重則是由當初 value 對應的 key 跟 query 計算匹配程度所得來的。（&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文原文&lt;/a&gt;稱此計算匹配程度的函式為 compatibility function）&lt;/p&gt;
&lt;p&gt;將此運算以圖表示的話則會長得像這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/scaled-dot-product.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        左右兩邊大致上講的是一樣的事情，不過右側省略 Scale 以及 Mask 步驟，而左側則假設我們已經拿到經過線性轉換的 Q, K, V
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們是第一次秀出論文裡頭的圖片（左），但右邊你應該不陌生才對。&lt;/p&gt;
&lt;p&gt;Scaled dot product attention 跟以往 multiplicative attention 一樣是先將維度相同的 Q 跟 K 做&lt;a href="https://zh.wikipedia.org/wiki/%E7%82%B9%E7%A7%AF"&gt;點積&lt;/a&gt;：將對應維度的值兩兩相乘後相加得到單一數值，接著把這些數值除以一個 scaling factor &lt;code&gt;sqrt(dk)&lt;/code&gt; ，然後再丟入 &lt;a href="https://www.youtube.com/watch?v=mlaLLQofmR8"&gt;softmax 函式&lt;/a&gt;得到相加為 1 的注意權重（attention weights）。&lt;/p&gt;
&lt;p&gt;最後以此權重對 V 作加權平均得到輸出結果。&lt;/p&gt;
&lt;p&gt;除以 scaling factor 的目的是為了讓點積出來的值不會因為 Q 以及 K 的維度 &lt;code&gt;dk&lt;/code&gt; 太大而跟著太大（舌頭打結）。因為太大的點積值丟入 softmax 函式有可能使得其梯度變得極小，導致訓練結果不理想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/softmax-function.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Softmax 函式讓某個 Q 與多個 K 之間的匹配值和為 1
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;說完概念，讓我們看看 Transformer 論文中的這個注意函式怎麼運作吧！首先我們得先準備這個函式的輸入 Q, K, V 才行。我們在 &lt;a href="#Multi-head-attention：你看你的，我看我的"&gt;Multi-head attention&lt;/a&gt; 一節會看到，在進行 scaled dot product attention 時會需要先將 Q、K 以及 V 分別做一次線性轉換，但現在讓我們先忽略這部分。&lt;/p&gt;
&lt;p&gt;這邊我們可以拿已經被轉換成詞嵌入空間的英文張量 &lt;code&gt;emb_inp&lt;/code&gt; 來充當左圖中的 Q 以及 K，讓它自己跟自己做匹配。V 則讓我隨機產生一個 binary 張量（裡頭只有 1 或 0）來當作每個 K 所對應的值，方便我們直觀解讀 scaled dot product attention 的輸出結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 設定一個 seed 確保我們每次都拿到一樣的隨機結果&lt;/span&gt;
&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9527&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`&lt;/span&gt;
&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="c1"&gt;# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193043, shape=(2, 8, 4), dtype=float32, numpy=
array([[[1., 0., 0., 0.],
        [0., 1., 0., 1.],
        [0., 0., 0., 1.],
        [1., 0., 1., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [0., 0., 1., 0.],
        [0., 1., 0., 1.]],

       [[1., 0., 1., 1.],
        [1., 0., 1., 0.],
        [1., 0., 0., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [1., 1., 1., 1.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，我想你現在應該能快速地解讀 3 維張量了，但還是讓我雞婆點，將現在的 Q, K, V 都畫出來讓你參考：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/q_k_v.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意顏色。雖然我們將拿 Q 跟 K 來做匹配，這個匹配只會發生在同個句子（同個顏色）底下（即 &lt;code&gt;shape[1:]&lt;/code&gt;）。在深度學習世界，我們會為了最大化 GPU 的運算效率而一次將 64 個、128 個或是更多個 &lt;code&gt;batch_size&lt;/code&gt; 的句子丟入模型。習慣 batch 維度的存在是非常實際的。&lt;/p&gt;
&lt;p&gt;接著讓我們看看 scaled dot product attention 在 TensorFlow 裡是&lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#scaled_dot_product_attention"&gt;怎麼被實作&lt;/a&gt;的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;"""Calculate the attention weights.&lt;/span&gt;
&lt;span class="sd"&gt;  q, k, v must have matching leading dimensions.&lt;/span&gt;
&lt;span class="sd"&gt;  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.&lt;/span&gt;
&lt;span class="sd"&gt;  The mask has different shapes depending on its type(padding or look ahead) &lt;/span&gt;
&lt;span class="sd"&gt;  but it must be broadcastable for addition.&lt;/span&gt;
&lt;span class="sd"&gt;  &lt;/span&gt;
&lt;span class="sd"&gt;  Args:&lt;/span&gt;
&lt;span class="sd"&gt;    q: query shape == (..., seq_len_q, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    k: key shape == (..., seq_len_k, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    v: value shape == (..., seq_len_v, depth_v)&lt;/span&gt;
&lt;span class="sd"&gt;    mask: Float tensor with shape broadcastable &lt;/span&gt;
&lt;span class="sd"&gt;          to (..., seq_len_q, seq_len_k). Defaults to None.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;  Returns:&lt;/span&gt;
&lt;span class="sd"&gt;    output, attention_weights&lt;/span&gt;
&lt;span class="sd"&gt;  """&lt;/span&gt;
  &lt;span class="c1"&gt;# 將 `q`、 `k` 做點積再 scale&lt;/span&gt;
  &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transpose_b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, seq_len_k)&lt;/span&gt;
  
  &lt;span class="n"&gt;dk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 取得 seq_k 的序列長度&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# scale by sqrt(dk)&lt;/span&gt;

  &lt;span class="c1"&gt;# 將遮罩「加」到被丟入 softmax 前的 logits&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均&lt;/span&gt;
  &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, seq_len_k)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 以注意權重對 v 做加權平均（weighted average）&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, depth_v)&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別被嚇到了。除了遮罩的運算部分我們還沒解釋，這 Python 函式事實上就是用 TensorFlow API 來實現剛剛才說的注意力機制邏輯罷了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將 &lt;code&gt;q&lt;/code&gt; 和 &lt;code&gt;k&lt;/code&gt; 做點積得到 &lt;code&gt;matmul_qk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將 &lt;code&gt;matmul_qk&lt;/code&gt; 除以 scaling factor &lt;code&gt;sqrt(dk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;有遮罩的話在丟入 softmax &lt;strong&gt;前&lt;/strong&gt;套用&lt;/li&gt;
&lt;li&gt;通過 softmax 取得加總為 1 的注意權重&lt;/li&gt;
&lt;li&gt;以該權重加權平均 &lt;code&gt;v&lt;/code&gt; 作為輸出結果&lt;/li&gt;
&lt;li&gt;回傳輸出結果以及注意權重&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;扣掉註解事實上也就只有 8 行代碼（當然有很多實作細節）。現在先讓我們實際將 &lt;code&gt;q&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; 輸入此函式看看得到的結果。假設沒有遮罩的存在：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;output: tf.Tensor(
[[[0.37502408 0.37503672 0.37488326 0.49993956]
  [0.37513658 0.37514552 0.37500778 0.49994028]
  [0.37483314 0.37482613 0.3749625  0.50006175]
  [0.37516367 0.37501514 0.3750258  0.49997073]
  [0.37503195 0.3751256  0.3750621  0.49998796]
  [0.37512696 0.37512186 0.37502852 0.49996266]
  [0.3748441  0.3749599  0.37492597 0.50001484]
  [0.3748441  0.3749599  0.37492597 0.50001484]]

 [[0.62516296 0.2500847  0.6250717  0.37522966]
  [0.62490153 0.24994145 0.62504375 0.37497035]
  [0.62509674 0.2501282  0.6249581  0.37518966]
  [0.62518024 0.25003165 0.6250133  0.37507355]
  [0.6250232  0.25011832 0.62486345 0.37516582]
  [0.6251376  0.25018096 0.625095   0.37525034]
  [0.62478966 0.24995528 0.6248975  0.37490302]
  [0.62492853 0.24997747 0.62507135 0.37497336]]], shape=(2, 8, 4), dtype=float32)
--------------------
attention_weights: tf.Tensor(
[[[0.12517719 0.12502946 0.12490283 0.12493535 0.12491155 0.12497091
   0.12503636 0.12503636]
  [0.12505189 0.12512855 0.12479477 0.1250193  0.12506542 0.12509388
   0.12492308 0.12492308]
  [0.12497574 0.12484524 0.1252356  0.12496044 0.12489695 0.1248758
   0.12510511 0.12510511]
  [0.12500346 0.12506503 0.1249556  0.12519364 0.12496658 0.12508455
   0.12486558 0.12486558]
  [0.12494988 0.12508136 0.12486238 0.12493681 0.12514524 0.12506418
   0.12498005 0.12498005]
  [0.12500885 0.12510943 0.12484082 0.12505434 0.12506378 0.12510203
   0.12491038 0.12491038]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;scaled_dot_product_attention&lt;/code&gt; 函式輸出兩個張量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;output&lt;/code&gt; 代表注意力機制的結果&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attention_weights&lt;/code&gt; 代表句子 &lt;code&gt;q&lt;/code&gt; 裡頭每個子詞對句子 &lt;code&gt;k&lt;/code&gt; 裡頭的每個子詞的注意權重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而因為你知道目前的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都代表同個張量 &lt;code&gt;emb_inp&lt;/code&gt;，因此 &lt;code&gt;attention_weights&lt;/code&gt; 事實上就代表了 &lt;code&gt;emb_inp&lt;/code&gt; 裡頭每個英文序列中的子詞對其他位置的子詞的注意權重。你可以再次參考之前 Transformer 是如何做 encoding 的動畫。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;output&lt;/code&gt; 則是句子裡頭每個位置的子詞將 &lt;code&gt;attention_weights&lt;/code&gt; 當作權重，從其他位置的子詞對應的資訊 &lt;code&gt;v&lt;/code&gt; 裡頭抽取有用訊息後匯總出來的結果。你可以想像 &lt;code&gt;ouput&lt;/code&gt; 裡頭的每個子詞都獲得了一個包含自己以及周遭子詞語義資訊的新 representation。而因為現在每個字詞的注意權重都相同，最後得到的每個 repr. 都長得一樣。&lt;/p&gt;
&lt;p&gt;下面則是我們實作的注意函式的所有輸入與輸出張量。透過多次的矩陣運算，注意力機制能讓查詢 Q 跟鍵值 K 做匹配，再依據此匹配程度將值 V 做加權平均獲得新的 representation。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/scaled_dot_product_attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/scaled_dot_product_attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Scaled dot product attention 的實際運算過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別只聽我碎碎念，自己點擊播放鍵來了解背後到底發生什麼事情吧！&lt;/p&gt;
&lt;p&gt;動畫裡包含許多細節，但只要有矩陣運算的基本概念，你應該已經能夠直觀且正確地理解注意函式是怎麼運作的了。在真實世界裡我們當然會用更長的序列、更大的 &lt;code&gt;batch_size&lt;/code&gt; 來處理數據，但上面呈現的是程式碼的實際結果，而非示意圖而已。這是注意力機制真正的「所見即所得」。&lt;/p&gt;
&lt;p&gt;一般來說注意函式的輸出 &lt;code&gt;output&lt;/code&gt;張量維度會跟 &lt;code&gt;q&lt;/code&gt; 張量相同（假設圖上的 &lt;code&gt;depth_v&lt;/code&gt; 等於 &lt;code&gt;depth&lt;/code&gt;）。此張量也被稱作「注意張量」，你可以將其解讀為 &lt;code&gt;q&lt;/code&gt; 在關注 &lt;code&gt;k&lt;/code&gt; 並從 &lt;code&gt;v&lt;/code&gt; 得到上下文訊息後的所獲得的新 representation。而注意權重 &lt;code&gt;attention_weights&lt;/code&gt; 則是 &lt;code&gt;q&lt;/code&gt; 裡頭每個句子的每個子詞對其他位置的子詞的關注程度。&lt;/p&gt;
&lt;p&gt;P.S. 一般注意函式只需輸出注意張量。而我們在這邊將注意權重 &lt;code&gt;attention_weights&lt;/code&gt; 也輸出是為了方便之後觀察 Transformer 在訓練的時候將「注意力」放在哪裡。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="直觀理解遮罩在注意函式中的效果"&gt;直觀理解遮罩在注意函式中的效果&lt;a class="anchor-link" href="#直觀理解遮罩在注意函式中的效果"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剛剛為了讓你消化注意函式裡頭最重要的核心邏輯，我刻意忽略了遮罩（masking）的存在。現在讓我們重新把 &lt;code&gt;scaled_dot_product_attention&lt;/code&gt; 裡頭跟遮罩相關的程式碼拿出來瞧瞧：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="c1"&gt;# 將 `q`、 `k` 做點積再 scale&lt;/span&gt;
&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將遮罩「加」到被丟入 softmax 前的 logits&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 取 softmax 是為了得到總和為 1 的比例做加權平均&lt;/span&gt;
&lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你剛剛有仔細看上面的動畫的話（17 秒之後），應該能想像 &lt;code&gt;scaled_attention_logits&lt;/code&gt; 的 shape 為 （batch_size, seq_len_q, seq_len_k）。其最後一個維度代表某個序列 &lt;code&gt;q&lt;/code&gt; 裡的某個子詞與序列 &lt;code&gt;k&lt;/code&gt; 的&lt;strong&gt;每個&lt;/strong&gt;子詞的匹配程度，但加總不為 1。而為了之後跟與 &lt;code&gt;k&lt;/code&gt; 對應的 &lt;code&gt;v&lt;/code&gt; 做加權平均，我們針對最後一個維度做 softmax 運算使其和為 1，也就是上圖 &lt;code&gt;axis=-1&lt;/code&gt; 的部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/softmax.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/softmax.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        對最後一維做 softmax。模型還沒經過訓練所以「注意力」非常平均
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果序列 &lt;code&gt;k&lt;/code&gt; 裡頭的每個子詞 &lt;code&gt;sub_k&lt;/code&gt; 都是實際存在的中文字或英文詞彙，這運算當然沒問題。我們會希望序列 &lt;code&gt;q&lt;/code&gt; 裡頭的每個子詞 &lt;code&gt;sub_q&lt;/code&gt; 都能從每個 &lt;code&gt;sub_k&lt;/code&gt; 獲得它所需要的語義資訊。&lt;/p&gt;
&lt;p&gt;但李組長眉頭一皺，發現案情並不單純。&lt;/p&gt;
&lt;p&gt;回想一下，我們的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都是從 &lt;code&gt;emb_inp&lt;/code&gt; 來的。&lt;code&gt;emb_inp&lt;/code&gt; 代表著英文句子的詞嵌入張量，而裡頭的第一個句子應該是有 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 的。啊哈！誰會想要放注意力在沒有實際語義的傢伙上呢？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 是 -1e9 不是 1e-9&lt;/span&gt;

&lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因此在注意函式裡頭，我們將遮罩乘上一個接近&lt;strong&gt;負&lt;/strong&gt;無窮大的 &lt;code&gt;-1e9&lt;/code&gt;，並把它加到進入 softmax &lt;strong&gt;前&lt;/strong&gt;的 logits 上面。這樣可以讓這些被加上極小值的位置變得無關緊要，在經過 softmax 以後的值趨近於 0。這效果等同於序列 &lt;code&gt;q&lt;/code&gt; 中的某個子詞 &lt;code&gt;sub_q&lt;/code&gt; 完全沒放注意力在這些被遮罩蓋住的子詞 &lt;code&gt;sub_k&lt;/code&gt; 之上（此例中 &lt;code&gt;sub_k&lt;/code&gt; 指是的 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;（動腦時間：為何遮罩要放在 softmax 之前而不能放之後？）&lt;/p&gt;
&lt;p&gt;聽我說那麼多不如看實際的運算結果。讓我們再次為英文句子 &lt;code&gt;inp&lt;/code&gt; 產生對應的 padding mask：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# padding mask 的工作就是把索引序列中為 0 的位置設為 1&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;#　broadcasting&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;inp_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
inp_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，&lt;strong&gt;第一個&lt;/strong&gt;英文序列的最後 2 個位置是不具任何語義的 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;（圖中為 &lt;code&gt;0&lt;/code&gt; 的部分）。而這也是為何我們需要將遮罩 &lt;code&gt;inp_mask&lt;/code&gt; 輸入到注意函式，避免序列中的子詞關注到這 2 個傢伙的原因。&lt;/p&gt;
&lt;p&gt;我們這次把 &lt;code&gt;inp_mask&lt;/code&gt; 降到 3 維，並且將其跟剛剛的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt; 一起丟進注意函式裡頭，看看注意權重有什麼變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 這次讓我們將 padding mask 放入注意函式並觀察&lt;/span&gt;
&lt;span class="c1"&gt;# 注意權重的變化&lt;/span&gt;
&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (batch_size, 1, seq_len_q)&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;attention_weights: tf.Tensor(
[[[0.16691911 0.1667221  0.16655324 0.16659662 0.1665649  0.16664404
   0.         0.        ]
  [0.16670164 0.16680385 0.1663589  0.16665822 0.16671969 0.16675764
   0.         0.        ]
  [0.16668104 0.16650699 0.16702762 0.16666064 0.16657597 0.16654775
   0.         0.        ]
  [0.16661155 0.16669361 0.16654776 0.16686502 0.16656238 0.16671962
   0.         0.        ]
  [0.16659099 0.16676629 0.16647433 0.16657357 0.16685146 0.16674338
   0.         0.        ]
  [0.16663864 0.16677272 0.16641466 0.16669929 0.16671185 0.16676286
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;加了 padding mask 後，第一個句子裡頭的每個子詞針對倒數兩個字詞的「注意權重」的值都變成 0 了。上句話非常饒舌，但我相信已經是非常精準的說法了。讓我把這句話翻譯成 numpy 的 slice 語法：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 事實上也不完全是上句話的翻譯，&lt;/span&gt;
&lt;span class="c1"&gt;# 因為我們在第一個維度還是把兩個句子都拿出來方便你比較&lt;/span&gt;
&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193086, shape=(2, 8, 2), dtype=float32, numpy=
array([[[0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ]],

       [[0.1248794 , 0.12493874],
        [0.12507208, 0.12507817],
        [0.12491715, 0.12492047],
        [0.12487733, 0.12489669],
        [0.12496544, 0.12490314],
        [0.12488527, 0.12499221],
        [0.12514311, 0.12506206],
        [0.12505081, 0.12508905]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一個英文句子的最後 2 個位置因為是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; 所以被遮罩「蓋住」而沒有權重值（上方 2 維陣列）；第二個句子的序列（下方 2 維陣列）則因為最後 2 個位置仍是正常的英文子詞，因此都有被其他子詞關注。&lt;/p&gt;
&lt;p&gt;如果聽完我的碎碎念你還是無法理解以上結果，或是不確定有遮罩的注意函式到底怎麼運作，就實際看看其中的計算過程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        將 padding mask 應用到自注意力機制運算（q = k）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一張圖勝過千言萬語。在 padding mask 的幫助下，注意函式輸出的新序列 &lt;code&gt;output&lt;/code&gt; 裡頭的每個子詞都只從序列 &lt;code&gt;k&lt;/code&gt; （也就是序列 &lt;code&gt;q&lt;/code&gt; 自己）的前 6 個實際子詞而非 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; 來獲得語義資訊（最後一張圖的黑框部分）。&lt;/p&gt;
&lt;p&gt;再次提醒，因為我們輸入注意函式的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都是同樣的英文詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt;，事實上這邊做的就是讓英文句子裡頭的每個子詞都去關注同句子中其他位置的子詞的資訊，並從中獲得上下文語義，而這就是所謂的自注意力機制（self-attention）：序列關注自己。&lt;/p&gt;
&lt;p&gt;當序列 &lt;code&gt;q&lt;/code&gt; 換成 Decoder 的輸出序列而序列 &lt;code&gt;k&lt;/code&gt; 變成 Encoder 的輸出序列時，我們就變成在計算一般 Seq2Seq 模型中的注意力機制。這點觀察非常重要，且&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;我們在前面就已經提過了&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;打鐵趁熱，讓我們看看前面提過的另一種遮罩 look ahead mask：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立一個 2 維矩陣，維度為 (size, size)，&lt;/span&gt;
&lt;span class="c1"&gt;# 其遮罩為一個右上角的三角形&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;band_part&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;  &lt;span class="c1"&gt;# (seq_len, seq_len)&lt;/span&gt;

&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 注意這次我們用中文的詞嵌入張量 `emb_tar`&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"look_ahead_mask"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
look_ahead_mask tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們已經知道 demo 用的中文（目標語言）的序列長度為 &lt;code&gt;10&lt;/code&gt;，而 look ahead 遮罩就是產生一個 2 維矩陣，其兩個維度都跟中文的詞嵌入張量 &lt;code&gt;emb_tar&lt;/code&gt; 的倒數第 2 個維度（序列長度）一樣，且裡頭是一個倒三角形（1 的部分）。&lt;/p&gt;
&lt;p&gt;我們&lt;a href="#%E9%81%AE%E7%BD%A9%EF%BC%9ATransformer-%E7%9A%84%E7%A5%95%E5%AF%86%E9%85%8D%E6%96%B9"&gt;前面曾經說過&lt;/a&gt; &lt;code&gt;look_ahead_mask&lt;/code&gt; 是用來確保 Decoder 在進行自注意力機制時輸出序列裡頭的每個子詞只會關注到自己之前（左邊）的字詞，不會不小心關注到未來（右邊）理論上還沒被  Decoder 生成的子詞。&lt;/p&gt;
&lt;p&gt;運用從 padding mask 學到的概念，想像一下如果把這個倒三角的遮罩跟之前一樣套用到進入 softmax &lt;strong&gt;之前&lt;/strong&gt;的 &lt;code&gt;scaled_attention_logits&lt;/code&gt;，輸出序列 &lt;code&gt;output&lt;/code&gt; 裡頭的每個子詞的 repr. 會有什麼性質？&lt;/p&gt;
&lt;p&gt;溫馨小提醒：&lt;code&gt;scaled_attention_logits&lt;/code&gt; 裡頭的每一 row 紀錄了某個特定子詞對其他子詞的注意權重。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 讓我們用目標語言（中文）的 batch&lt;/span&gt;
&lt;span class="c1"&gt;# 來模擬 Decoder 處理的情況&lt;/span&gt;
&lt;span class="n"&gt;temp_q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp_k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;
&lt;span class="n"&gt;temp_v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 look_ahead_mask 放入注意函式&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;temp_q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;temp_k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;temp_v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;attention_weights: tf.Tensor(
[[[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.49974996 0.50025004 0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33338806 0.33309633 0.3335156  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24980238 0.2497976  0.25013384 0.25026616 0.         0.
   0.         0.         0.         0.        ]
  [0.19975185 0.19982941 0.19989952 0.199991   0.20052823 0.
   0.         0.         0.         0.        ]
  [0.16658378 0.16686733 0.16656147 0.16657883 0.1664059  0.16700274
   0.         0.         0.         0.        ]
  [0.14259693 0.1427213  0.14279391 0.1429158  0.14314583 0.14267854
   0.14314772 0.         0.         0.        ]
  [0.12491751 0.12487698 0.12503591 0.12508857 0.12503389 0.12487747
   0.12507991 0.12508978 0.         0.        ]
  [0.11102892 0.1109929  0.11113416 0.11118097 0.11113235 0.11099333
   0.11117328 0.11118205 0.11118205 0.        ]
  [0.09991965 0.09988723 0.10001437 0.10005648 0.10001273 0.09988762
   0.10004956 0.10005745 0.10005745 0.10005745]]

 [[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.4994912  0.5005088  0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33261845 0.33340293 0.3339786  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24919374 0.25002357 0.25033304 0.25044966 0.         0.
   0.         0.         0.         0.        ]
  [0.19997214 0.19964042 0.20002526 0.19986893 0.20049322 0.
   0.         0.         0.         0.        ]
  [0.16662474 0.16674054 0.16659829 0.16668092 0.16645522 0.16690029
   0.         0.         0.         0.        ]
  [0.14276491 0.14288287 0.14274995 0.14281946 0.1427529  0.14282054
   0.14320944 0.         0.         0.        ]
  [0.12491003 0.1250709  0.12497466 0.12504703 0.12481265 0.1251362
   0.12493407 0.12511446 0.         0.        ]
  [0.11102156 0.11105824 0.11103692 0.11106326 0.11112017 0.11104742
   0.11128615 0.11106552 0.11130078 0.        ]
  [0.09983386 0.10001399 0.10016464 0.10015456 0.09999382 0.09989963
   0.0998925  0.09993652 0.099891   0.10021948]]], shape=(2, 10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案呼之欲出，套用 look ahead mask 的結果就是讓序列 &lt;code&gt;q&lt;/code&gt; 裡的每個字詞只關注包含自己左側的子詞，在自己之後的位置的字詞都不看。比方說兩個中文句子的第一個字詞都只關注自己：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193126, shape=(2, 10), dtype=float32, numpy=
array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意到了嗎？兩個句子的第一個子詞因為自己前面已經沒有其他子詞，所以將全部的注意力 &lt;code&gt;1&lt;/code&gt;都放在自己身上。讓我們看看第二個子詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193131, shape=(2, 10), dtype=float32, numpy=
array([[0.49974996, 0.50025004, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ],
       [0.4994912 , 0.5005088 , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;兩個句子的第 2 個子詞因為只能看到序列中的第一個子詞以及自己，因此前兩個位置的注意權重加總即為 1，後面位置的權重皆為 0。而現在 2 個值都接近 0.5 是因為我們還沒開始訓練，Transformer 還不知道該把注意力放在哪裡。&lt;/p&gt;
&lt;p&gt;就跟一般的 &lt;a href="#%E7%A5%9E%E7%B6%93%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%EF%BC%9AEncoder-Decoder-%E6%A8%A1%E5%9E%8B"&gt;Seq2Seq 模型&lt;/a&gt;相同，Transformer 裡頭的 Decoder 在生成輸出序列時也是一次產生一個子詞。因此跟輸入的英文句子不同，中文句子裡頭的每個子詞都是在不同時間點產生的。所以理論上 Decoder 在時間點 &lt;code&gt;t - 1&lt;/code&gt; （或者說是位置 &lt;code&gt;t - 1&lt;/code&gt;）已經生成的子詞 &lt;code&gt;subword_t_minus_1&lt;/code&gt; 在生成的時候是不可能能夠關注到下個時間點 &lt;code&gt;t&lt;/code&gt;（位置 &lt;code&gt;t&lt;/code&gt;）所生成的子詞 &lt;code&gt;subword_t&lt;/code&gt; 的，儘管它們在 Transformer 裡頭同時被做矩陣運算。&lt;/p&gt;
&lt;p&gt;一個位置的子詞不能去關注未來會在自己之後生成的子詞，而這就像是&lt;a href="https://zh.wikipedia.org/wiki/%E7%A5%96%E7%88%B6%E6%82%96%E8%AB%96"&gt;祖父悖論&lt;/a&gt;一樣有趣。&lt;/p&gt;
&lt;p&gt;實際上 look ahead mask 讓 Decoder 在生成第 1 個子詞時只看自己；在生成第 2 個子詞時關注前 1 個子詞與自己； 在生成第 3 個子詞時關注前兩個已經生成的子詞以及自己，以此類推。透過 look ahead mask，你可以想像 Transformer 既可以平行運算，又可以像是 RNN 一樣，在生成子詞時從前面已生成的子詞獲得必要的語義資訊。&lt;/p&gt;
&lt;p&gt;挺酷的，不是嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        look ahead mask 讓每個子詞都只關注序列中自己與之前的位置
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實際做矩陣運算的時候我們當然還是會讓注意權重為 0 的位置跟對應的 &lt;code&gt;v&lt;/code&gt; 相乘，但是上圖的黑框才是實際會對最後的 &lt;code&gt;output&lt;/code&gt; 值造成影響的權重與 &lt;code&gt;v&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;我們在這節了解 Transformer 架構裡頭的兩種遮罩以及它們的作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;padding mask：遮住 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 不讓所有子詞關注&lt;/li&gt;
&lt;li&gt;look ahead mask：遮住 Decoder 未來生成的子詞不讓之前的子詞關注&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你現在應該能夠想像遮罩在注意力機制裡頭顯得有多麽重要了：它讓注意函式進行高效率的矩陣平行運算的時候不需擔心會關注到不該關注的位置，一次獲得序列中所有位置的子詞各自應有的注意權重以及新的 reprsentation。&lt;/p&gt;
&lt;p&gt;如果 Transformer 是&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A"&gt;變形金剛&lt;/a&gt;的話，注意力機制跟遮罩就是&lt;a href="https://www.easyatm.com.tw/wiki/%E7%81%AB%E7%A8%AE%E6%BA%90"&gt;火種源&lt;/a&gt;了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-movie.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Multi-head-attention：你看你的，我看我的"&gt;Multi-head attention：你看你的，我看我的&lt;a class="anchor-link" href="#Multi-head-attention：你看你的，我看我的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有好好聽教授講解 Transformer 的話，你應該還記得所謂的多頭注意（multi-head attention）概念。如果你到現在還沒看課程影片或者想複習一下，我把 multi-head attention 的開始跟結束時間都設置好了，你只需觀看大約 1 分半左右的影片：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA?start=1526&amp;amp;end=1676"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        李宏毅教授講解 multi-head attention 的概念
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;複習完了嗎？mutli-head attention 的概念本身並不難，用比較正式的說法就是將 Q、K 以及 V 這三個張量先&lt;strong&gt;個別&lt;/strong&gt;轉換到 &lt;em&gt;d_model&lt;/em&gt; 維空間，再將其拆成多個比較低維的 &lt;em&gt;depth&lt;/em&gt; 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出&lt;/p&gt;
&lt;p&gt;而為何要那麼「搞剛」把本來 &lt;code&gt;d_model&lt;/code&gt; 維的空間投影到多個維度較小的子空間（subspace）以後才各自進行注意力機制呢？這是因為這給予模型更大的彈性，讓它可以同時關注不同位置的子詞在不同子空間下的 representation，而不只是本來 &lt;code&gt;d_model&lt;/code&gt; 維度下的一個 representation。&lt;/p&gt;
&lt;p&gt;我們在文章最開頭看過的英翻中就是一個活生生的 mutli-head attention 例子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在經過&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt;前面 2 節注意函式&lt;/a&gt;的洗禮之後，你應該已經能夠看出這裏每張小圖都是一個注意權重（為了方便渲染我做了 transpose）。而事實上每張小圖都是 multi-head attention 裡頭某一個 head 的結果，總共是 8 個 heads。&lt;/p&gt;
&lt;p&gt;你會發現每個 head 在 Transformer 生成同樣的中文字時關注的英文子詞有所差異：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Head 4 在生成「們」與「再」時特別關注「renewed」&lt;/li&gt;
&lt;li&gt;Head 5 在生成「必」與「須」時特別關注「must」&lt;/li&gt;
&lt;li&gt;Head 6 &amp;amp; 8 在生成「希」與「望」時特別關注「hope」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這樣同時關注多個不同子空間裡頭的子詞的 representation，Transformer 最終可以生成更好的結果。&lt;/p&gt;
&lt;p&gt;話是這麼說，但程式碼該怎麼寫呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/multi-head-imagining.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了要實現 multi-head attention，得先能把一個 head 變成多個 heads。而這實際上就是把一個 &lt;code&gt;d_model&lt;/code&gt; 維度的向量「折」成 &lt;code&gt;num_heads&lt;/code&gt; 個 &lt;code&gt;depth&lt;/code&gt; 維向量，使得：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;num_heads * depth = d_model
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;讓我們實作一個可以做到這件事情的函式，並將英文詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt; 實際丟進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# x.shape: (batch_size, seq_len, d_model)&lt;/span&gt;
  &lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度&lt;/span&gt;
  &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;  &lt;span class="c1"&gt;# 這是分成多頭以後每個向量的維度 &lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將最後一個 d_model 維度分成 num_heads 個 depth 維度。&lt;/span&gt;
  &lt;span class="c1"&gt;# 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維&lt;/span&gt;
  &lt;span class="c1"&gt;# (batch_size, seq_len, num_heads, depth)&lt;/span&gt;
  &lt;span class="n"&gt;reshaped_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量&lt;/span&gt;
  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len, depth)&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshaped_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

&lt;span class="c1"&gt;# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="c1"&gt;# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;

&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"x:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;x: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
output: tf.Tensor(
[[[[ 0.00695511 -0.03370368]
   [-0.02707888 -0.03917687]
   [ 0.0355427   0.04111305]
   [ 0.02443342 -0.03273199]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]
   [-0.00680635  0.02136201]
   [-0.00680635  0.02136201]]

  [[-0.03656032 -0.03336458]
   [-0.01213828  0.00909697]
   [ 0.00751223 -0.01974255]
   [ 0.01267544  0.03127003]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]
   [-0.02036932 -0.04211974]
   [-0.02036932 -0.04211974]]]


 [[[ 0.00695511 -0.03370368]
   [-0.0325227  -0.03433502]
   [ 0.00144588 -0.00377025]
   [ 0.04524285  0.02524642]
   [-0.0159062   0.01108797]
   [ 0.00240784 -0.04652226]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]]

  [[-0.03656032 -0.03336458]
   [-0.01849879  0.01439226]
   [-0.00798036 -0.04099905]
   [-0.00924555 -0.01368124]
   [-0.0177028  -0.0435766 ]
   [ 0.01821991 -0.04349295]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]]]], shape=(2, 2, 8, 2), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;觀察 &lt;code&gt;output&lt;/code&gt; 與 &lt;code&gt;emb_inp&lt;/code&gt; 之間的關係，你會發現 3 維詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt; 已經被轉換成一個 4 維張量了，且最後一個維度 &lt;code&gt;shape[-1] = 4&lt;/code&gt; 被拆成兩半。&lt;/p&gt;
&lt;p&gt;不過如果你不熟 TensorFlow API 或是矩陣運算，或許無法馬上理解 head 的維度在哪裡、還有不同 heads 之間有什麼差異。為了幫助你直觀理解 &lt;code&gt;split_heads&lt;/code&gt; 函式，我將運算過程中產生的張量都視覺化出來給你瞧瞧：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/split_heads.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/split_heads.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        split_heads 函式將 3 維張量轉換為 multi-head 的 4 維張量過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;觀察 &lt;code&gt;split_heads&lt;/code&gt; 的輸入輸出，你會發現序列裡每個子詞原來為 &lt;code&gt;d_model&lt;/code&gt; 維的 reprsentation 被拆成多個相同但較短的 &lt;code&gt;depth&lt;/code&gt; 維度。而每個 head 的 2 維矩陣事實上仍然代表原來的序列，只是裡頭子詞的 repr. 維度降低了。&lt;/p&gt;
&lt;p&gt;透過動畫，你現在應該已經能夠了解要產生 multi-head 就是將輸入張量中本來是 &lt;code&gt;d_model&lt;/code&gt; 的最後一個維度平均地「折」成想要的 head 數，進而產生一個新的 head 維度。一個句子裡頭的子詞現在不只會有一個 &lt;code&gt;d_model&lt;/code&gt; 的 repr.，而是會有 &lt;code&gt;num_heads&lt;/code&gt; 個 &lt;code&gt;depth&lt;/code&gt; 維度的 representation。&lt;/p&gt;
&lt;p&gt;接下來只要把 3 維的 Q、K 以及 V 用 &lt;code&gt;split_heads&lt;/code&gt; 拆成多個 heads 的 4 維張量，利用 broadcasting 就能以之前定義的&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt; Scaled dot product attention&lt;/a&gt; 來為每個句子裡頭的每個 head 平行計算注意結果了，超有效率！&lt;/p&gt;
&lt;p&gt;在明白如何產生 multi-head 的 4 維張量以後，multi-head attention 的實現就比較容易理解了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 實作一個執行多頭注意力機制的 keras layer&lt;/span&gt;
&lt;span class="c1"&gt;# 在初始的時候指定輸出維度 `d_model` &amp;amp; `num_heads，&lt;/span&gt;
&lt;span class="c1"&gt;# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`&lt;/span&gt;
&lt;span class="c1"&gt;# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：&lt;/span&gt;
&lt;span class="c1"&gt;# output.shape            == (batch_size, seq_len_q, d_model)&lt;/span&gt;
&lt;span class="c1"&gt;# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 在初始的時候建立一些必要參數&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="c1"&gt;# 指定要將 `d_model` 拆成幾個 heads&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="c1"&gt;# 在 split_heads 之前的基底維度&lt;/span&gt;
    
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="c1"&gt;# 前面看過，要確保可以平分&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt;  &lt;span class="c1"&gt;# 每個 head 裡子詞的新的 repr. 維度&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 分別給 q, k, v 的 3 個線性轉換 &lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 注意我們並沒有指定 activation func&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dense&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 多 heads 串接後通過的線性轉換&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 這跟我們前面看過的函式有 87% 相似&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Split the last dimension into (num_heads, depth).&lt;/span&gt;
&lt;span class="sd"&gt;    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="c1"&gt;# multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_q, depth)&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_k, depth)&lt;/span&gt;
    &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_v, depth)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸出會多一個 head 維度&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)&lt;/span&gt;
    &lt;span class="c1"&gt;# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape&lt;/span&gt;
    &lt;span class="c1"&gt;# 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;# (batch_size, seq_len_q, num_heads, depth)&lt;/span&gt;
    &lt;span class="n"&gt;concat_attention&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
    &lt;span class="c1"&gt;# (batch_size, seq_len_q, d_model)&lt;/span&gt;

    &lt;span class="c1"&gt;# 通過最後一個線性轉換&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;concat_attention&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len_q, d_model)&lt;/span&gt;
        
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;是的，就算你有自己實作過 keras layer，multi-head attention layer 也不算短的實作。如果這是你第一次碰到客製化的 keras layer，別打退堂鼓，你可以多看幾次我寫給你的註解，或是參考等等下方的動畫來加深對 multi-head attention 的理解。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;split_heads&lt;/code&gt; 函式我們在前面就已經看過了，你應該還有印象。&lt;code&gt;call&lt;/code&gt; 函式則定義了這個 multi-head attention layer 實際的計算流程，而這流程跟我在本節開頭講的可以說是有 87% 相似：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        將 Q、K 以及 V 這三個張量先個別轉換到 d_model 維空間，再將其拆成多個比較低維的 depth 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;差別只在於實際上我們是利用矩陣運算以及 broadcasting 讓 GPU 一次計算整個 batch 裡所有句子的所有 head 的注意結果。&lt;/p&gt;
&lt;p&gt;定義了一個新 layer 當然要實際試試。現在讓我們初始一個 multi-head attention layer 並將英文詞嵌入向量 &lt;code&gt;emb_inp&lt;/code&gt; 輸入進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# emb_inp.shape == (batch_size, seq_len, d_model)&lt;/span&gt;
&lt;span class="c1"&gt;#               == (2, 8, 4)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"d_model: {d_model}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"num_heads: {num_heads}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 multi-head attention layer&lt;/span&gt;
&lt;span class="n"&gt;mha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 簡單將 v, k, q 都設置為 `emb_inp`&lt;/span&gt;
&lt;span class="c1"&gt;# 順便看看 padding mask 的作用。&lt;/span&gt;
&lt;span class="c1"&gt;# 別忘記，第一個英文序列的最後兩個 tokens 是 &amp;lt;pad&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="n"&gt;padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"q.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"k.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"v.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"padding_mask.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;d_model: 4
num_heads: 2

q.shape: (2, 8, 4)
k.shape: (2, 8, 4)
v.shape: (2, 8, 4)
padding_mask.shape: (2, 1, 1, 8)
output.shape: (2, 8, 4)
attention_weights.shape: (2, 2, 8, 8)

output: tf.Tensor(
[[[ 0.00862424  0.00463534  0.00123856  0.01982255]
  [ 0.00860434  0.00464583  0.00125165  0.01984711]
  [ 0.00863869  0.00461318  0.00122942  0.01981261]
  [ 0.00858585  0.00465442  0.00125683  0.0198578 ]
  [ 0.0086211   0.00462923  0.0012448   0.01983759]
  [ 0.00860078  0.00464716  0.00125472  0.01985404]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]]

 [[-0.00233657  0.02963993  0.01171194  0.03959805]
  [-0.00234752  0.02964369  0.01171828  0.03960991]
  [-0.00232748  0.02962957  0.01170804  0.03959192]
  [-0.00233163  0.02963142  0.0117076   0.03959151]
  [-0.00231678  0.02962143  0.01170276  0.03957902]
  [-0.00234718  0.02964409  0.01171941  0.03961902]
  [-0.00233476  0.029631    0.01171241  0.03959794]
  [-0.00235306  0.02964601  0.01172148  0.03961948]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該明白為何&lt;a href="#遮罩：Transformer-的祕密配方"&gt;我們當初要在 padding mask 加入兩個新維度了&lt;/a&gt;：一個是用來遮住同個句子但是不同 head 的注意權重，一個則是用來 broadcast 到 2 維注意權重的（詳見&lt;a href="#直觀理解遮罩在注意函式中的效果"&gt;直觀理解遮罩&lt;/a&gt;一節）。&lt;/p&gt;
&lt;p&gt;沒意外的話你也已經能夠解讀 mutli-head attention 的輸出了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;output&lt;/code&gt;：序列中每個子詞的新 repr. 都包含同序列其他位置的資訊&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attention_weights&lt;/code&gt;：包含每個 head 的每個序列 &lt;code&gt;q&lt;/code&gt; 中的字詞對序列 &lt;code&gt;k&lt;/code&gt; 的注意權重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你還無法想像每個計算步驟，讓我們看看 multi-head attention 是怎麼將輸入的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;v&lt;/code&gt; 轉換成最後的 &lt;code&gt;output&lt;/code&gt; 的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/multi-head-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/multi-head-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Multi-head attention 完整計算過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這應該是你這輩子第一次看到 multi-head 注意力機制是怎麼處理 4 維張量的。&lt;/p&gt;
&lt;p&gt;細節不少，我建議將動畫跟程式碼比較一下，確保你能想像每一個步驟產生的張量以及其物理意義。到此為止，我們已經把 Transformer 裡最困難的 multi-head attention 的概念以及運算都看過一遍了。&lt;/p&gt;
&lt;p&gt;如果你腦袋還是一團亂，只要記得最後一個畫面：在 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;v&lt;/code&gt; 的最後一維已經是 &lt;code&gt;d_model&lt;/code&gt; 的情況下，multi-head attention 跟 scaled dot product attention 一樣，就是吐出一個完全一樣維度的張量 &lt;code&gt;output&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;multi-head attention 的輸出張量 &lt;code&gt;output&lt;/code&gt; 裡頭每個句子的每個字詞的 repr. 維度 &lt;code&gt;d_model&lt;/code&gt; 雖然跟函式的輸入張量相同，但實際上已經是從同個序列中&lt;strong&gt;不同位置且不同空間&lt;/strong&gt;中的 repr. 取得語義資訊的結果。&lt;/p&gt;
&lt;p&gt;要確保自己真的掌握了 multi-head attention 的精神，你可以試著向旁邊的朋友（如果他 / 她願意聽的話）解釋一下整個流程。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/explain-mha.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;喔對了，不用擔心我們做 multi-head 以後計算量會大增。因為 head 的數目雖然變多了，每個子空間的維度也下降了。跟 single-head attention 使用的計算量是差不多的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="打造-Transformer：疊疊樂時間_1"&gt;打造 Transformer：疊疊樂時間&lt;a class="anchor-link" href="#打造-Transformer：疊疊樂時間"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;以前我們曾提到&lt;/a&gt;深度學習模型就是一層層的幾何運算過程。Transformer 也不例外，剛才實作的 mutli-head attention layer 就是一個最明顯的例子。而它正好是 Transformer 裡頭最重要的一層運算。&lt;/p&gt;
&lt;p&gt;在這節我們會把 Transformer 裡頭除了注意力機制的其他運算通通實作成一個個的 layers，並將它們全部「疊」起來。&lt;/p&gt;
&lt;p&gt;你可以點擊下方的影片來了解接下來的實作順序：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/steps-to-build-transformer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/steps-to-build-transformer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        一步步打造 Transformer
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果這是你第一次看到 Transformer 的架構圖 ... 代表你沒認真上教授的課，等等別忘記&lt;a href="#師傅引進門，修行在個人_1"&gt;去前面領補課號碼牌&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;影片中左側就是我們接下來會依序實作的 layers。&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;Transformer 是一種使用自注意力機制的 Seq2Seq 模型&lt;/a&gt; ，裡頭包含了兩個重要角色，分別為 Encoder 與 Decoder：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最初輸入的英文序列會通過 Encoder 中 N 個 Encoder layers 並被轉換成一個&lt;strong&gt;相同長度&lt;/strong&gt;的序列。每個 layer 都會為自己的輸入序列裡頭的子詞產生&lt;strong&gt;新的&lt;/strong&gt; repr.，然後交給下一個 layer。&lt;/li&gt;
&lt;li&gt;Decoder 在生成（預測）下一個中文子詞時會一邊觀察 Encoder 輸出序列裡&lt;strong&gt;所有&lt;/strong&gt;英文子詞的 repr.，一邊觀察自己前面已經生成的中文子詞。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值得一提的是，N = 1 （Encoder / Decoder layer 數目 = 1）時就是最陽春版的 Transformer。但在深度學習領域裡頭我們常常想對原始數據做多層的轉換，因此會將 N 設為影片最後出現的 2 層或是 Transformer 論文中的 6 層 Encoder / Decoder layers。&lt;/p&gt;
&lt;p&gt;Encoder 裡頭的 Encoder layer 裡又分兩個 sub-layers，而 Decoder 底下的 Decoder layer 則包含 3 個 sub-layers。真的是 layer layer 相扣。將這些 layers 的階層關係簡單列出來大概就長這樣（位置 Encoding 等實作時解釋）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer&lt;ul&gt;
&lt;li&gt;Encoder&lt;ul&gt;
&lt;li&gt;輸入 Embedding&lt;/li&gt;
&lt;li&gt;位置 Encoding&lt;/li&gt;
&lt;li&gt;N 個 Encoder layers&lt;ul&gt;
&lt;li&gt;sub-layer 1: Encoder 自注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 2: Feed Forward&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Decoder&lt;ul&gt;
&lt;li&gt;輸出 Embedding&lt;/li&gt;
&lt;li&gt;位置 Encoding&lt;/li&gt;
&lt;li&gt;N 個 Decoder layers&lt;ul&gt;
&lt;li&gt;sub-layer 1: Decoder 自注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 2: Decoder-Encoder 注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 3: Feed Forward&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Final Dense Layer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不過就像影片中顯示的一樣，實作的時候我們傾向從下往上疊上去。畢竟地基打得好，樓才蓋得高，對吧？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Position-wise-Feed-Forward-Networks"&gt;Position-wise Feed-Forward Networks&lt;a class="anchor-link" href="#Position-wise-Feed-Forward-Networks"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同影片中所看到的， Encoder layer 跟 Decoder layer 裡頭都各自有一個 Feed Forward 的元件。此元件構造簡單，不用像前面的 multi-head attention 建立&lt;a href="https://www.tensorflow.org/beta/tutorials/eager/custom_layers"&gt;客製化的 keras layer&lt;/a&gt;，只需要寫一個 Python 函式讓它在被呼叫的時候回傳一個&lt;strong&gt;新的&lt;/strong&gt; &lt;a href="https://www.tensorflow.org/beta/tutorials/quickstart/beginner"&gt;tf.keras.Sequential 模型&lt;/a&gt;給我們即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
      &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, dff)&lt;/span&gt;
      &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
  &lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;此函式在每次被呼叫的時候都會回傳一組新的全連接前饋神經網路（Fully-connected &lt;strong&gt;F&lt;/strong&gt;eed &lt;strong&gt;F&lt;/strong&gt;orward &lt;strong&gt;N&lt;/strong&gt;etwork，FFN），其輸入張量與輸出張量的最後一個維度皆為 &lt;code&gt;d_model&lt;/code&gt;，而在 FFN 中間層的維度則為 &lt;code&gt;dff&lt;/code&gt;。一般會讓 &lt;code&gt;dff&lt;/code&gt; 大於 &lt;code&gt;d_model&lt;/code&gt;，讓 FFN 從輸入的 &lt;code&gt;d_model&lt;/code&gt; 維度裡頭擷取些有用的資訊。在論文中 &lt;code&gt;d_model&lt;/code&gt; 為 512，&lt;code&gt;dff&lt;/code&gt; 則為 4 倍的 2048。兩個都是可以調整的超參數。&lt;/p&gt;
&lt;p&gt;讓我們建立一個 FFN 試試：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2048&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"x.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"out.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;x.shape: (64, 10, 512)
out.shape: (64, 10, 512)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在輸入張量的最後一維已經是 &lt;code&gt;d_model&lt;/code&gt; 的情況，FFN 的輸出張量基本上會跟輸入一模一樣：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：（batch_size, seq_len, d_model）&lt;/li&gt;
&lt;li&gt;輸出：（batch_size, seq_len, d_model） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FFN 輸出 / 輸入張量的 shape 相同很容易理解。比較沒那麼明顯的是這個 FFN  事實上對序列中的所有位置做的線性轉換都是一樣的。我們可以假想一個 2 維的 &lt;code&gt;duumy_sentence&lt;/code&gt;，裡頭有 5 個以 4 維向量表示的子詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;# FFN 的輸入輸出張量的最後一維皆為 `d_model`&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;

&lt;span class="c1"&gt;# 建立一個小 FFN&lt;/span&gt;
&lt;span class="n"&gt;small_ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 懂子詞梗的站出來&lt;/span&gt;
&lt;span class="n"&gt;dummy_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;small_ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193585, shape=(5, 4), dtype=float32, numpy=
array([[ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現同一個子詞不會因為&lt;strong&gt;位置的改變&lt;/strong&gt;而造成 FFN 的輸出結果產生差異。但因為我們實際上會有多個 Encoder / Decoder layers，而每個 layers 都會有不同參數的 FFN，因此每個 layer 裡頭的 FFN 做的轉換都會有所不同。&lt;/p&gt;
&lt;p&gt;值得一提的是，儘管對所有位置的子詞都做一樣的轉換，這個轉換是獨立進行的，因此被稱作 Position-wise Feed-Forward Networks。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder-layer：Encoder-小弟"&gt;Encoder layer：Encoder 小弟&lt;a class="anchor-link" href="#Encoder-layer：Encoder-小弟"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了 &lt;strong&gt;M&lt;/strong&gt;ulti-&lt;strong&gt;H&lt;/strong&gt;ead &lt;strong&gt;A&lt;/strong&gt;ttention（MHA）以及 &lt;strong&gt;F&lt;/strong&gt;eed-&lt;strong&gt;F&lt;/strong&gt;orward &lt;strong&gt;N&lt;/strong&gt;etwork（FFN），我們事實上已經可以實作第一個 Encoder layer 了。讓我們複習一下這 layer 裡頭有什麼重要元件：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/encoder-layer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/encoder-layer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Encoder layer 裡的重要元件
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想上面的動畫已經很清楚了。一個 Encoder layer 裡頭會有兩個 sub-layers，分別為 MHA 以及 FFN。在 Add &amp;amp; Norm 步驟裡頭，每個 sub-layer 會有一個&lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf"&gt;殘差連結（residual connection）&lt;/a&gt;來幫助減緩梯度消失（Gradient Vanishing）的問題。接著兩個 sub-layers 都會針對最後一維 &lt;code&gt;d_model&lt;/code&gt; 做 &lt;a href="https://arxiv.org/abs/1607.06450"&gt;layer normalization&lt;/a&gt;，將 batch 裡頭每個子詞的輸出獨立做轉換，使其平均與標準差分別靠近 0 和 1 之後輸出。&lt;/p&gt;
&lt;p&gt;另外在將 sub-layer 的輸出與其輸入相加之前，我們還會做點 regularization，對該 sub-layer 的輸出使用 &lt;a href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf"&gt;dropout&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;總結一下。如果輸入是 &lt;code&gt;x&lt;/code&gt;，最後輸出寫作 &lt;code&gt;out&lt;/code&gt; 的話，則每個 sub-layer 的處理邏輯如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Sublayer&lt;/code&gt; 則可以是 MHA 或是 FFN。現在讓我們看看 Encoder layer 的實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA &amp;amp; FFN&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# Transformer 論文內預設 dropout rate 為 0.1&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 一樣，一個 sub-layer 一個 dropout layer&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
  &lt;span class="c1"&gt;# 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 1: MHA&lt;/span&gt;
    &lt;span class="c1"&gt;# Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己&lt;/span&gt;
    &lt;span class="c1"&gt;# 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 &amp;lt;pad&amp;gt; token&lt;/span&gt;
    &lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="n"&gt;attn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    
    &lt;span class="c1"&gt;# sub-layer 2: FFN&lt;/span&gt;
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 記得 training&lt;/span&gt;
    &lt;span class="n"&gt;out2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟當初 MHA layer 的實作比起來輕鬆多了，對吧？&lt;/p&gt;
&lt;p&gt;基本上 Encoder layer 裡頭就是兩個架構一模一樣的 sub-layer，只差在一個是 MHA，一個是 FFN。另外為了方便 residual connection 的計算，所有 sub-layers 的&lt;strong&gt;輸出&lt;/strong&gt;維度都是 &lt;code&gt;d_model&lt;/code&gt;。而 sub-layer 內部產生的維度當然就隨我們開心啦！我們可以為 FFN 設置不同的 &lt;code&gt;dff&lt;/code&gt; 值，也能設定不同的 &lt;code&gt;num_heads&lt;/code&gt; 來改變 MHA 內部每個 head 裡頭的維度。&lt;/p&gt;
&lt;p&gt;論文裡頭的 &lt;code&gt;d_model&lt;/code&gt; 為 512，而我們 demo 用的英文詞嵌入張量的 &lt;code&gt;d_model&lt;/code&gt; 維度則為 4：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 之後可以調的超參數。這邊為了 demo 設小一點&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="c1"&gt;# 新建一個使用上述參數的 Encoder Layer&lt;/span&gt;
&lt;span class="n"&gt;enc_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 建立一個當前輸入 batch 使用的 padding mask&lt;/span&gt;
&lt;span class="n"&gt;enc_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在本來的輸入維度即為 &lt;code&gt;d_model&lt;/code&gt; 的情況下，Encoder layer 就是給我們一個一模一樣 shape 的張量。當然，實際上內部透過 MHA 以及 FFN sub-layer 的轉換，每個子詞的 repr. 都大幅改變了。&lt;/p&gt;
&lt;p&gt;有了 Encoder layer，接著讓我們看看 Decoder layer 的實作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Decoder-layer：Decoder-小弟"&gt;Decoder layer：Decoder 小弟&lt;a class="anchor-link" href="#Decoder-layer：Decoder-小弟"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個 Decoder layer 裡頭有 3 個 sub-layers：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Decoder layer 自身的 &lt;strong&gt;Masked&lt;/strong&gt; MHA 1&lt;/li&gt;
&lt;li&gt;Decoder layer 關注 Encoder 輸出序列的 MHA 2&lt;/li&gt;
&lt;li&gt;FFN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你也可以看一下影片來回顧它們所在的位置：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/decoder-layer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/decoder-layer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Decoder layer 中的 sub-layers
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟實作 Encoder layer 時一樣，每個 sub-layer 的邏輯同下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Decoder layer 用 MHA 1 來關注輸出序列，查詢 Q、鍵值 K 以及值 V 都是自己。而之所以有個 masked 是因為（中文）輸出序列除了跟（英文）輸入序列一樣需要 padding mask 以外，還需要 look ahead mask 來避免 Decoder layer 關注到未來的子詞。look ahead mask 在&lt;a href="#直觀理解遮罩在注意函式中的效果"&gt;前面章節&lt;/a&gt;已經有詳細說明了。&lt;/p&gt;
&lt;p&gt;MHA1 處理完的輸出序列會成為 MHA 2 的 Q，而 K 與 V 則使用 Encoder 的輸出序列。這個運算的概念是讓一個 Decoder layer 在生成新的中文子詞時先參考先前已經產生的中文字，並為當下要生成的子詞產生一個包含前文語義的 repr. 。接著將此 repr. 拿去跟 Encoder 那邊的英文序列做匹配，看當下字詞的 repr. 有多好並予以修正。&lt;/p&gt;
&lt;p&gt;用簡單點的說法就是 Decoder 在生成中文字詞時除了參考已經生成的中文字以外，也會去關注 Encoder 輸出的英文子詞（的 repr.）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Decoder 裡頭會有 N 個 DecoderLayer，&lt;/span&gt;
&lt;span class="c1"&gt;# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA &amp;amp; FFN&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# 3 個 sub-layers 的主角們&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 
    &lt;span class="c1"&gt;# 定義每個 sub-layer 用的 LayerNorm&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 定義每個 sub-layer 用的 Dropout&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)&lt;/span&gt;

    &lt;span class="c1"&gt;# sub-layer 1: Decoder layer 自己對輸出序列做注意力。&lt;/span&gt;
    &lt;span class="c1"&gt;# 我們同時需要 look ahead mask 以及輸出序列的 padding mask &lt;/span&gt;
    &lt;span class="c1"&gt;# 來避免前面已生成的子詞關注到未來的子詞以及 &amp;lt;pad&amp;gt;&lt;/span&gt;
    &lt;span class="n"&gt;attn1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;attn1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 2: Decoder layer 關注 Encoder 的最後輸出&lt;/span&gt;
    &lt;span class="c1"&gt;# 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 &amp;lt;pad&amp;gt;&lt;/span&gt;
    &lt;span class="n"&gt;attn2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;attn2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 3: FFN 部分跟 Encoder layer 完全一樣&lt;/span&gt;
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;

    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;out2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Decoder layer 的實作跟 Encoder layer 大同小異，不過還是有幾點細節特別需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在做 Masked MHA（MHA 1）的時候我們需要同時套用兩種遮罩：&lt;strong&gt;輸出&lt;/strong&gt;序列的 padding mask 以及 look ahead mask。因此 Decoder layer 預期的遮罩是兩者結合的 &lt;code&gt;combined_mask&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MHA 1 因為是 Decoder layer 關注自己，multi-head attention 的參數 &lt;code&gt;v&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;q&lt;/code&gt; 都是 &lt;code&gt;x&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MHA 2 是 Decoder layer 關注 Encoder 輸出序列，因此，multi-head attention 的參數 &lt;code&gt;v&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 為 &lt;code&gt;enc_output&lt;/code&gt;，&lt;code&gt;q&lt;/code&gt; 則為 MHA 1 sub-layer 的結果 &lt;code&gt;out1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;產生 &lt;code&gt;comined_mask&lt;/code&gt; 也很簡單，我們只要把兩個遮罩取大的即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"look_ahead_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"combined_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)
--------------------
look_ahead_mask: tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意 &lt;code&gt;combined_mask&lt;/code&gt; 的 shape 以及裡頭遮罩所在的位置。利用 broadcasting 我們將 &lt;code&gt;combined_mask&lt;/code&gt; 的 shape 也擴充到 4 維：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(batch_size, num_heads, seq_len_tar, seq_len_tar)
= (2, 1, 10, 10)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這方便之後 multi-head attention 的計算。另外因為我們 demo 的中文 batch 裡頭的第一個句子有 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;，&lt;code&gt;combined_mask&lt;/code&gt; 除了 look ahead 的效果以外還加了 padding mask。&lt;/p&gt;
&lt;p&gt;因為剛剛實作的是 Decoder layer，這次讓我們把中文（目標語言）的詞嵌入張量以及相關的遮罩丟進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;dec_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 來源、目標語言的序列都需要 padding mask&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算&lt;/span&gt;
&lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_self_attn_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_enc_attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_self_attn_weights.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_self_attn_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_enc_attn_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_enc_attn_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.4073423  -1.3681166   0.4482983   1.3271605 ]
  [ 0.9023904  -1.6660724   0.1386456   0.6250363 ]
  [-0.68705463  0.04485544 -0.9672582   1.6094574 ]
  [ 0.40446007  0.7378753  -1.7199682   0.5776328 ]
  [ 0.66626793 -0.7429294  -1.1866593   1.2633208 ]
  [ 1.3847514   0.0595071  -0.00241444 -1.441844  ]
  [ 0.77179515 -0.15832207 -1.5698854   0.9564123 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]]

 [[-0.35176337 -1.3861214   0.39734656  1.3405383 ]
  [ 1.0155624   0.28156188 -1.6605129   0.36338854]
  [ 0.9295503  -0.96635836 -1.0307404   1.0675484 ]
  [ 1.2389433  -0.7855455  -1.1608163   0.70741844]
  [ 0.11645091 -1.565496    0.23167732  1.2173678 ]
  [-0.44791234 -1.3678643   1.2819183   0.53385824]
  [-0.05676413  0.90384555  0.7641177  -1.611199  ]
  [-0.4362856  -1.3157362   1.397403    0.35461882]
  [ 0.21431251 -0.8140781   1.5471766  -0.94741106]
  [ 0.4220932  -0.4875322  -1.3055642   1.3710032 ]]], shape=(2, 10, 4), dtype=float32)
--------------------
dec_self_attn_weights.shape: (2, 2, 10, 10)
dec_enc_attn_weights: (2, 2, 10, 8)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟 Encoder layer 相同，Decoder layer 輸出張量的最後一維也是 &lt;code&gt;d_model&lt;/code&gt;。而 &lt;code&gt;dec_self_attn_weights&lt;/code&gt; 則代表著 Decoder layer 的自注意權重，因此最後兩個維度皆為中文序列的長度 &lt;code&gt;10&lt;/code&gt;；而 &lt;code&gt;dec_enc_attn_weights&lt;/code&gt; 因為 Encoder 輸出序列的長度為 &lt;code&gt;8&lt;/code&gt;，最後一維即爲 &lt;code&gt;8&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;都讀到這裡了，判斷每一維的物理意義對你來說應該是小菜一碟了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Positional-encoding：神奇數字"&gt;Positional encoding：神奇數字&lt;a class="anchor-link" href="#Positional-encoding：神奇數字"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;透過多層的自注意力層，Transformer 在處理序列時裡頭所有子詞都是「天涯若比鄰」：想要關注序列中&lt;strong&gt;任何&lt;/strong&gt;位置的資訊只要 O(1) 就能辦到。這讓 Transformer 能很好地 model 序列中長距離的依賴關係（long-range dependencise）。但反過來說 Transformer 則無法 model 序列中字詞的順序關係，所以我們得額外加入一些「位置資訊」給 Transformer。&lt;/p&gt;
&lt;p&gt;這個資訊被稱作位置編碼（Positional Encoding），實作上是直接加到最一開始的英文 / 中文詞嵌入向量（word embedding）裡頭。其直觀的想法是想辦法讓被加入位置編碼的 word embedding 在 &lt;code&gt;d_model&lt;/code&gt; 維度的空間裡頭不只會因為&lt;strong&gt;語義相近&lt;/strong&gt;而靠近，也會因為&lt;strong&gt;位置靠近&lt;/strong&gt;而在該空間裡頭靠近。&lt;/p&gt;
&lt;p&gt;論文裡頭使用的位置編碼的公式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/position-encoding-equation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯 ... 第一次看到這函式的人會黑人問號是很正常。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文裡頭提到&lt;/a&gt;他們之所以這樣設計位置編碼（&lt;strong&gt;P&lt;/strong&gt;ositional &lt;strong&gt;E&lt;/strong&gt;ncoding, PE）是因為這個函數有個很好的特性：給定任一位置 &lt;code&gt;pos&lt;/code&gt; 的位置編碼 &lt;code&gt;PE(pos)&lt;/code&gt;，跟它距離 &lt;code&gt;k&lt;/code&gt; 個單位的位置 &lt;code&gt;pos + k&lt;/code&gt; 的位置編碼 &lt;code&gt;PE(pos + k)&lt;/code&gt; 可以表示為 &lt;code&gt;PE(pos)&lt;/code&gt; 的一個線性函數（linear function）。&lt;/p&gt;
&lt;p&gt;因此透過在 word embedding 裡加入這樣的資訊，作者們認為可以幫助 Transformer 學會 model 序列中的子詞的相對位置關係。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        子曰：「由！誨女知之乎？知之為知之，不知為不知，是知也。」
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ 《論語 為政篇》&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就算我們無法自己想出論文裡頭的位置編碼公式，還是可以直接把 &lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer#positional_encoding"&gt;TensorFlow 官方&lt;/a&gt;的實作搬過來使用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 以下直接參考 TensorFlow 官方 tutorial &lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_angles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;angle_rates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;angle_rates&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;angle_rads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_angles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                          &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:],&lt;/span&gt;
                          &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# apply sin to even indices in the array; 2i&lt;/span&gt;
  &lt;span class="n"&gt;sines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle_rads&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="c1"&gt;# apply cos to odd indices in the array; 2i+1&lt;/span&gt;
  &lt;span class="n"&gt;cosines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle_rads&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;sines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cosines&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;

&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pos_encoding&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=194541, shape=(1, 50, 512), dtype=float32, numpy=
array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,
          0.99998724,  0.99998814],
        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,
          0.9999867 ,  0.9999876 ],
        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,
          0.9999861 ,  0.9999871 ]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一路看下來你應該也可以猜到位置編碼的每一維意義了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第 1 維代表 batch_size，之後可以 broadcasting&lt;/li&gt;
&lt;li&gt;第 2 維是序列長度，我們會為每個在輸入 / 輸出序列裡頭的子詞都加入位置編碼&lt;/li&gt;
&lt;li&gt;第 3 維跟詞嵌入向量同維度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為是要跟詞嵌入向量相加，位置編碼的維度也得是 &lt;code&gt;d_model&lt;/code&gt;。我們也可以把位置編碼畫出感受一下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'RdBu'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'d_model'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Position'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;colorbar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/positional-encoding.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這圖你應該在很多教學文章以及教授的影片裡都看過了。就跟我們前面看過的各種 2 維矩陣相同，x 軸代表著跟詞嵌入向量相同的維度 &lt;code&gt;d_model&lt;/code&gt;，y 軸則代表序列中的每個位置。之後我們會看輸入 / 輸出序列有多少個子詞，就加入幾個位置編碼。&lt;/p&gt;
&lt;p&gt;關於位置編碼我們現在只需要知道這些就夠了，但如果你想知道更多相關的數學計算，可以參考&lt;a href="https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb"&gt;這個筆記本&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder"&gt;Encoder&lt;a class="anchor-link" href="#Encoder"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Encoder 裡頭主要包含了 3 個元件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入的詞嵌入層&lt;/li&gt;
&lt;li&gt;位置編碼&lt;/li&gt;
&lt;li&gt;N 個 Encoder layers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大部分的工作都交給 Encoder layer 小弟做了，因此 Encoder 的實作很單純：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：&lt;/span&gt;
  &lt;span class="c1"&gt;# - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`&lt;/span&gt;
  &lt;span class="c1"&gt;# - input_vocab_size: 用來把索引轉成詞嵌入向量&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 建立 `num_layers` 個 EncoderLayers&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enc_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
                       &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸入的 x.shape == (batch_size, input_seq_len)&lt;/span&gt;
    &lt;span class="c1"&gt;# 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;input_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# 再加上對應長度的位置編碼&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;input_seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;

    &lt;span class="c1"&gt;# 對 embedding 跟位置編碼的總合做 regularization&lt;/span&gt;
    &lt;span class="c1"&gt;# 這在 Decoder 也會做&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 通過 N 個 EncoderLayer 做編碼&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enc_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="c1"&gt;# 以下只是用來 demo EncoderLayer outputs&lt;/span&gt;
      &lt;span class="c1"&gt;#print('-' * 20)&lt;/span&gt;
      &lt;span class="c1"&gt;#print(f"EncoderLayer {i + 1}'s output:", x)&lt;/span&gt;
      
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較值得注意的是我們依照論文將 word embedding 乘上 &lt;code&gt;sqrt(d_model)&lt;/code&gt;，並在 embedding 跟位置編碼相加以後通過 dropout 層來達到 regularization 的效果。&lt;/p&gt;
&lt;p&gt;現在我們可以直接將索引序列 &lt;code&gt;inp&lt;/code&gt; 丟入 Encoder：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 2 層的 Encoder&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 記得加上 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 Encoder&lt;/span&gt;
&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 2 維的索引序列丟入 Encoder 做編碼&lt;/span&gt;
&lt;span class="n"&gt;enc_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意因為 Encoder 已經包含了詞嵌入層，因此我們不用再像呼叫 &lt;a href="#Encoder-的小弟"&gt;Encoder layer&lt;/a&gt; 時一樣還得自己先做 word embedding。現在的輸入及輸出張量為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：（batch_size, seq_len）&lt;/li&gt;
&lt;li&gt;輸出：（batch_size, seq_len, d_model）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了 Encoder，我們之後就可以直接把 2 維的索引序列 &lt;code&gt;inp&lt;/code&gt; 丟入 Encoder，讓它幫我們把裡頭所有的英文序列做一連串的轉換。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Decoder"&gt;Decoder&lt;a class="anchor-link" href="#Decoder"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Decoder layer 本來就只跟 Encoder layer 差在一個 MHA，而這邏輯被包起來以後呼叫它的 Decoder 做的事情就跟 Encoder 基本上沒有兩樣了。&lt;/p&gt;
&lt;p&gt;在 Decoder 裡頭我們只需要建立一個專門給中文用的詞嵌入層以及位置編碼即可。我們在呼叫每個 Decoder layer 的時候也順便把其注意權重存下來，方便我們了解模型訓練完後是怎麼做翻譯的。&lt;/p&gt;
&lt;p&gt;以下則是實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 為中文（目標語言）建立詞嵌入層&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dec_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
                       &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 呼叫時的參數跟 DecoderLayer 一模一樣&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="n"&gt;tar_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;  &lt;span class="c1"&gt;# 用來存放每個 Decoder layer 的注意權重&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 這邊跟 Encoder 做的事情完全一樣&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;tar_seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dec_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      
      &lt;span class="c1"&gt;# 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察&lt;/span&gt;
      &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;_block1'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block1&lt;/span&gt;
      &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;_block2'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block2&lt;/span&gt;
    
    &lt;span class="c1"&gt;# x.shape == (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們初始並呼叫一個 Decoder 看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 2 層的 Decoder&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 記得加上 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;

&lt;span class="c1"&gt;# 遮罩&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 Decoder&lt;/span&gt;
&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 2 維的索引序列以及遮罩丟入 Decoder&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"combined_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp_padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;block_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{block_name}&lt;/span&gt;&lt;span class="s2"&gt;.shape: &lt;/span&gt;&lt;span class="si"&gt;{attn_weights.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
inp_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.5437632  -1.055963    1.6090912  -0.0093651 ]
  [-0.35729456 -1.2363737   1.5295789   0.06408926]
  [ 0.35950443 -1.4217519   1.3327445  -0.27049693]
  [ 0.00910451 -1.3681054   1.4556323  -0.09663116]
  [-0.39842203 -1.0891637   1.6237149  -0.13612938]
  [-0.41910946 -1.0254465   1.6521797  -0.20762381]
  [-0.36797434 -1.036104    1.6521349  -0.2480565 ]
  [-0.19375193 -1.1218892   1.6165614  -0.30092025]
  [ 0.40127647 -1.3597702   1.3540744  -0.39558053]
  [ 0.17590097 -1.419068    1.3905344  -0.14736754]]

 [[-0.54991776 -1.0509207   1.6102997  -0.00946123]
  [-0.3790077  -1.2450974   1.514628    0.10947719]
  [ 0.1746773  -1.3877552   1.415193   -0.20211506]
  [-0.03870562 -1.3375971   1.4825788  -0.10627584]
  [-0.43508232 -1.067575    1.6293938  -0.12673649]
  [-0.41048303 -1.0317237   1.6503688  -0.20816201]
  [-0.3626595  -1.0360833   1.652463   -0.25372016]
  [-0.24817836 -1.1092765   1.6238651  -0.26641032]
  [ 0.1850568  -1.3670969   1.4271388  -0.2450987 ]
  [ 0.09142628 -1.3988855   1.4218552  -0.11439597]]], shape=(2, 10, 4), dtype=float32)
--------------------
decoder_layer1_block1.shape: (2, 2, 10, 10)
decoder_layer1_block2.shape: (2, 2, 10, 8)
decoder_layer2_block1.shape: (2, 2, 10, 10)
decoder_layer2_block2.shape: (2, 2, 10, 8)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;麻雀雖小，五臟俱全。雖然我們是使用 demo 數據，但基本上這就是你在呼叫 Decoder 時需要做的所有事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始時給它中文（目標語言）的字典大小、其他超參數&lt;/li&gt;
&lt;li&gt;輸入中文 batch 的索引序列&lt;/li&gt;
&lt;li&gt;也要輸入兩個遮罩以及 Encoder 輸出 &lt;code&gt;enc_out&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Decoder 的輸出你現在應該都可以很輕鬆地解讀才是。基本上跟 Decoder layer 一模一樣，只差在我們額外輸出一個 Python dict，裡頭存放所有 Decoder layers 的注意權重。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第一個-Transformer"&gt;第一個 Transformer&lt;a class="anchor-link" href="#第一個-Transformer"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒錯，終於到了這個時刻。在實作 Transformer 之前先點擊影片來簡單回顧一下我們在這一章實作了什麼些玩意兒：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-imple.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-imple.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Transformer 本身只有 3 個 layers
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在我們前面已經將大大小小的 layers 一一實作並組裝起來以後，真正的 Transformer  模型只需要 3 個元件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Encoder &lt;/li&gt;
&lt;li&gt;Decoder&lt;/li&gt;
&lt;li&gt;Final linear layer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;馬上讓我們看看 Transformer  的實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 初始參數包含 Encoder &amp;amp; Decoder 都需要超參數以及中英字典數目&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                           &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                           &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;final_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，&lt;/span&gt;
  &lt;span class="c1"&gt;# 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;enc_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, inp_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# dec_output.shape == (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;dec_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將 Decoder 輸出通過最後一個 linear layer&lt;/span&gt;
    &lt;span class="n"&gt;final_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;final_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, tar_seq_len, target_vocab_size)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;final_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;扣掉註解，Transformer 的實作本身非常簡短。&lt;/p&gt;
&lt;p&gt;被輸入 Transformer 的多個 2 維英文張量 &lt;code&gt;inp&lt;/code&gt; 會一路通過 &lt;strong&gt;Encoder&lt;/strong&gt; 裡頭的詞嵌入層，位置編碼以及 N 個 Encoder layers 後被轉換成 Encoder 輸出 &lt;code&gt;enc_output&lt;/code&gt;，接著對應的中文序列 &lt;code&gt;tar&lt;/code&gt; 則會在 &lt;strong&gt;Decoder&lt;/strong&gt; 裡頭走過相似的旅程並在每一層的 Decoder layer 利用 MHA 2 關注 Encoder 的輸出 &lt;code&gt;enc_output&lt;/code&gt;，最後被 Decoder 輸出。&lt;/p&gt;
&lt;p&gt;而 Decoder 的輸出 &lt;code&gt;dec_output&lt;/code&gt; 則會通過 &lt;strong&gt;Final linear layer&lt;/strong&gt;，被轉成進入 Softmax 前的 logits &lt;code&gt;final_output&lt;/code&gt;，其 logit 的數目則跟中文字典裡的子詞數相同。&lt;/p&gt;
&lt;p&gt;因為 Transformer 把 Decoder 也包起來了，現在我們連 Encoder 輸出 &lt;code&gt;enc_output&lt;/code&gt; 也不用管，只要把英文（來源）以及中文（目標）的索引序列 batch 丟入 Transformer，它就會輸出最後一維為中文字典大小的張量。第 2 維是輸出序列，裡頭每一個位置的向量就代表著該位置的中文字的機率分佈（事實上通過 softmax 才是，但這邊先這樣說方便你理解）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：&lt;ul&gt;
&lt;li&gt;英文序列：（batch_size, inp_seq_len）&lt;/li&gt;
&lt;li&gt;中文序列：（batch_size, tar_seq_len）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;輸出：&lt;ul&gt;
&lt;li&gt;生成序列：（batch_size, tar_seq_len, target_vocab_size）&lt;/li&gt;
&lt;li&gt;注意權重的 dict&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們馬上建一個 Transformer，並假設我們已經準備好用 demo 數據來訓練它做英翻中：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="c1"&gt;# + 2 是為了 &amp;lt;start&amp;gt; &amp;amp; &amp;lt;end&amp;gt; token&lt;/span&gt;
&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;output_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="c1"&gt;# 重點中的重點。訓練時用前一個字來預測下一個中文字&lt;/span&gt;
&lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

&lt;span class="c1"&gt;# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化我們的第一個 transformer&lt;/span&gt;
&lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                          &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_real:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predictions:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_inp: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0]
 [4201  162  467  421  189   14    7  553    3]], shape=(2, 9), dtype=int64)
--------------------
tar_real: tf.Tensor(
[[  10  241   80   27    3 4202    0    0    0]
 [ 162  467  421  189   14    7  553    3 4202]], shape=(2, 9), dtype=int64)
--------------------
predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了前面的各種 layers，建立一個 Transformer 並不難。但要輸入什麼數據就是一門大學問了：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;為何是丟少了尾巴一個字的 &lt;code&gt;tar_inp&lt;/code&gt; 序列進去 Transformer，而不是直接丟 &lt;code&gt;tar&lt;/code&gt; 呢？&lt;/p&gt;
&lt;p&gt;別忘記我們才剛初始一個 Transformer，裡頭所有 layers 的權重都是隨機的，你可不能指望它真的會什麼「黑魔法」來幫你翻譯。我們得先訓練才行。但訓練時如果你把整個正確的中文序列 &lt;code&gt;tar&lt;/code&gt;都進去給 Transformer 看，你期待它產生什麼？一首新的中文詩嗎？&lt;/p&gt;
&lt;p&gt;如果你曾經實作過序列生成模型或是看過&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;我之前的語言模型文章&lt;/a&gt;，就會知道在序列生成任務裡頭，模型獲得的正確答案是輸入序列往左位移一個位置的結果。&lt;/p&gt;
&lt;p&gt;這樣講很抽象，讓我們看個影片了解序列生成是怎麼運作的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/how-sequence-generation-work.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/how-sequence-generation-work.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        了解序列生成以及如何訓練一個生成模型
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該明白 Transformer 在訓練的時候並不是吃整個中文序列，而是吃一個去掉尾巴的序列 &lt;code&gt;tar_inp&lt;/code&gt;，然後試著去預測「左移」一個字以後的序列 &lt;code&gt;tar_real&lt;/code&gt;。同樣概念當然也可以運用到以 RNN 或是 CNN-based 的模型上面。&lt;/p&gt;
&lt;p&gt;從影片中你也可以發現給定 &lt;code&gt;tar_inp&lt;/code&gt; 序列中的任一位置，其對應位置的 &lt;code&gt;tar_real&lt;/code&gt; 就是下個時間點模型應該要預測的中文字。&lt;/p&gt;
&lt;p&gt;序列生成任務可以被視為是一個分類任務（Classification），而每一個中文字都是一個分類。而 Transformer 就是要去產生一個中文字的機率分佈，想辦法跟正解越接近越好。&lt;/p&gt;
&lt;p&gt;跟用已訓練的 Transformer 做&lt;strong&gt;預測&lt;/strong&gt;時不同，在&lt;strong&gt;訓練&lt;/strong&gt;時為了穩定模型表現，我們並不會將 Transformer 的輸出再度丟回去當做其輸入（人形蜈蚣？），而是像影片中所示，給它左移一個位置後的序列 &lt;code&gt;tar_real&lt;/code&gt; 當作正解讓它去最小化 error。&lt;/p&gt;
&lt;p&gt;這種無視模型預測結果，而將正確解答丟入的訓練方法一般被稱作 &lt;a href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/"&gt;teacher forcing&lt;/a&gt;。你也可以參考教授的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=1952"&gt;Sequence-to-sequence Learning 教學&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="定義損失函數與指標_1"&gt;定義損失函數與指標&lt;a class="anchor-link" href="#定義損失函數與指標"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為被視為是一個分類任務，我們可以使用 cross entropy 來計算序列生成任務中實際的中文字跟模型預測的中文字分佈（distribution）相差有多遠。&lt;/p&gt;
&lt;p&gt;這邊簡單定義一個損失函式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;loss_object&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SparseCategoricalCrossentropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;from_logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reduction&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'none'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label&lt;/span&gt;
&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;loss_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=197487, shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你曾做過分類問題，應該能看出預測序列 &lt;code&gt;pred&lt;/code&gt; 裡頭的第 3 個預測結果出錯因此 entropy 值上升。損失函數 &lt;code&gt;loss_object&lt;/code&gt; 做的事情就是比較 2 個序列並計算 cross entropy：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;real&lt;/code&gt;：一個包含 N 個正確 labels 的序列&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pred&lt;/code&gt;：一個包含 N 個維度為 label 數的 logit 序列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們在這邊將 &lt;code&gt;reduction&lt;/code&gt; 參數設為 &lt;code&gt;none&lt;/code&gt;，請 &lt;code&gt;loss_object&lt;/code&gt; 不要把每個位置的 error 加總。而這是因為我們之後要自己把 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 出現的位置的損失捨棄不計。&lt;/p&gt;
&lt;p&gt;而將 &lt;code&gt;from_logits&lt;/code&gt; 參數設為 &lt;code&gt;True&lt;/code&gt; 是因為從 Transformer 得到的預測還沒有經過 softmax，因此加總還不等於 1：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predictions:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
--------------------
tf.Tensor(
[[1.4971986 3.1899047 4.1454954 3.7353938 2.869739  1.8605256 1.3746347
  2.2779167 3.8190796]
 [1.4881071 3.303587  4.0757227 3.7524652 2.836317  1.9132937 1.4376438
  2.3432927 3.8689976]], shape=(2, 9), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了 &lt;code&gt;loss_object&lt;/code&gt; 實際算 cross entropy 以後，我們需要另外一個函式來建立遮罩並加總序列裡頭不包含 `&lt;pad&gt; token 位置的損失：&lt;/pad&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loss_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 &lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logical_not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# 照樣計算所有位置的 cross entropy 但不加總&lt;/span&gt;
  &lt;span class="n"&gt;loss_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loss_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;loss_&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;  &lt;span class="c1"&gt;# 只計算非 &amp;lt;pad&amp;gt; 位置的損失 &lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我另外再定義兩個 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics"&gt;tf.keras.metrics&lt;/a&gt;，方便之後使用 &lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard?hl=zh-cn"&gt;TensorBoard&lt;/a&gt; 來追蹤模型 performance：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'train_loss'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SparseCategoricalAccuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'train_accuracy'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設置超參數"&gt;設置超參數&lt;a class="anchor-link" href="#設置超參數"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前面實作了那麼多 layers，你應該還記得有哪些是你自己可以調整的超參數吧？&lt;/p&gt;
&lt;p&gt;讓我幫你全部列出來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;num_layers&lt;/code&gt; 決定 Transfomer 裡頭要有幾個 Encoder / Decoder layers&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d_model&lt;/code&gt; 決定我們子詞的 representation space 維度&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_heads&lt;/code&gt; 要做幾頭的自注意力運算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dff&lt;/code&gt; 決定 FFN 的中間維度&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dropout_rate&lt;/code&gt; 預設 0.1，一般用預設值即可&lt;/li&gt;
&lt;li&gt;&lt;code&gt;input_vocab_size&lt;/code&gt;：輸入語言（英文）的字典大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_vocab_size&lt;/code&gt;：輸出語言（中文）的字典大小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;論文裡頭最基本的 Transformer 配置為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;num_layers=6&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d_model=512&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dff=2048&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有大量數據以及大的 Transformer，你可以在很多機器學習任務都達到不錯的成績。為了不要讓訓練時間太長，在這篇文章裡頭我會把 Transformer 裡頭的超參數設小一點：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; 
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dropout_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;  &lt;span class="c1"&gt;# 預設值&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"input_vocab_size:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"target_vocab_size:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;input_vocab_size: 8137
target_vocab_size: 4203
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;4 層 Encoder / Decoder layers 不算貪心，小巫見大巫（笑&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設置-Optimizer"&gt;設置 Optimizer&lt;a class="anchor-link" href="#設置-Optimizer"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這邊跟&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文&lt;/a&gt;一致，使用 &lt;a href="optimization-6be9a291375c"&gt;Adam optimizer&lt;/a&gt; 以及自定義的 learning rate scheduler：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/lr-equation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這 schedule 讓訓練過程的前 &lt;code&gt;warmup_steps&lt;/code&gt; 的 learning rate 線性增加，在那之後則跟步驟數 &lt;code&gt;step_num&lt;/code&gt; 的反平方根成比例下降。不用擔心你沒有完全理解這公式，我們一樣可以直接使用 &lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#optimizer"&gt;TensorFlow 官方教學的實作&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;schedules&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LearningRateSchedule&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 論文預設 `warmup_steps` = 4000&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;
    
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;arg1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;arg2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
&lt;span class="c1"&gt;# 將客製化 learning rate schdeule 丟入 Adam opt.&lt;/span&gt;
&lt;span class="c1"&gt;# Adam opt. 的參數都跟論文相同&lt;/span&gt;
&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.98&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                     &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以觀察看看這個 schedule 是怎麼隨著訓練步驟而改變 learning rate 的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;d_models&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;schedules&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;colors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"blue"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"red"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"black"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d_models&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;schedules&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"d_model: {d}, warm: {s}"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedule&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedules&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; 
           &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Learning Rate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Train Step"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-custom-lr.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        不同 d_model 以及 warmup_steps 的 learning rate 變化
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以明顯地看到所有 schedules 都先經過 &lt;code&gt;warmup_steps&lt;/code&gt; 個步驟直線提升 learning rate，接著逐漸平滑下降。另外我們也會給比較高維的 &lt;code&gt;d_model&lt;/code&gt; 維度比較小的 learning rate。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實際訓練以及定時存檔"&gt;實際訓練以及定時存檔&lt;a class="anchor-link" href="#實際訓練以及定時存檔"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，什麼都準備齊全了，讓我們開始訓練 Transformer 吧！記得使用前面已經定義好的超參數來初始化一個全新的 Transformer：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dropout_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"""這個 Transformer 有 &lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt; 層 Encoder / Decoder layers&lt;/span&gt;
&lt;span class="s2"&gt;d_model: &lt;/span&gt;&lt;span class="si"&gt;{d_model}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;num_heads: &lt;/span&gt;&lt;span class="si"&gt;{num_heads}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;dff: &lt;/span&gt;&lt;span class="si"&gt;{dff}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;input_vocab_size: &lt;/span&gt;&lt;span class="si"&gt;{input_vocab_size}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;target_vocab_size: &lt;/span&gt;&lt;span class="si"&gt;{target_vocab_size}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;dropout_rate: &lt;/span&gt;&lt;span class="si"&gt;{dropout_rate}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;這個 Transformer 有 4 層 Encoder / Decoder layers
d_model: 128
num_heads: 8
dff: 512
input_vocab_size: 8137
target_vocab_size: 4203
dropout_rate: 0.1


&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;打遊戲時你會記得要定期存檔以防任何意外發生，訓練深度學習模型也是同樣道理。設置 &lt;a href="https://www.tensorflow.org/beta/guide/checkpoints"&gt;checkpoint&lt;/a&gt; 來定期儲存 / 讀取模型及 optimizer 是必備的。&lt;/p&gt;
&lt;p&gt;我們在底下會定義一個 checkpoint 路徑，此路徑包含了各種超參數的資訊，方便之後比較不同實驗的結果並載入已訓練的進度。我們也需要一個 checkpoint manager 來做所有跟存讀模型有關的雜事，並只保留最新 5 個 checkpoints 以避免佔用太多空間：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 方便比較不同實驗/ 不同超參數設定的結果&lt;/span&gt;
&lt;span class="n"&gt;run_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt;layers_&lt;/span&gt;&lt;span class="si"&gt;{d_model}&lt;/span&gt;&lt;span class="s2"&gt;d_&lt;/span&gt;&lt;span class="si"&gt;{num_heads}&lt;/span&gt;&lt;span class="s2"&gt;heads_&lt;/span&gt;&lt;span class="si"&gt;{dff}&lt;/span&gt;&lt;span class="s2"&gt;dff_&lt;/span&gt;&lt;span class="si"&gt;{train_perc}&lt;/span&gt;&lt;span class="s2"&gt;train_perc"&lt;/span&gt;
&lt;span class="n"&gt;checkpoint_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;checkpoint_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;run_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;log_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;run_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取&lt;/span&gt;
&lt;span class="c1"&gt;# 一般來說你會想存下模型以及 optimizer 的狀態&lt;/span&gt;
&lt;span class="n"&gt;ckpt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Checkpoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西&lt;/span&gt;
&lt;span class="c1"&gt;# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除&lt;/span&gt;
&lt;span class="n"&gt;ckpt_manager&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CheckpointManager&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;checkpoint_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_to_keep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 如果在 checkpoint 路徑上有發現檔案就讀進來&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;ckpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;restore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 用來確認之前訓練多少 epochs 了&lt;/span&gt;
  &lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'已讀取最新的 checkpoint，模型已訓練 &lt;/span&gt;&lt;span class="si"&gt;{last_epoch}&lt;/span&gt;&lt;span class="s1"&gt; epochs。'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"沒找到 checkpoint，從頭訓練。"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;已讀取最新的 checkpoint，模型已訓練 50 epochs。
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/am-i-a-joke-to-you.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;「誒！？ 你不當場訓練嗎？」「直接載入已訓練的模型太狗了吧！」&lt;/p&gt;
&lt;p&gt;拜託，我都訓練 N 遍了，每次都重新訓練也太沒意義了。而且你能想像為了寫一個章節我就得重新訓練一個 Transformer 來 demo 嗎？這樣太沒效率了。比起每次重新訓練模型，這才是你在真實世界中應該做的事情：盡可能回復之前的訓練進度來節省時間。&lt;/p&gt;
&lt;p&gt;不過放心，我仍會秀出完整的訓練程式碼讓你可以執行第一次的訓練。當你想要依照本文訓練自己的 Transformer 時會感謝有 checkpoint manager 的存在。現在假設我們還沒有 checkpoints。&lt;/p&gt;
&lt;p&gt;在實際訓練 Transformer 之前還需要定義一個簡單函式來產生所有的遮罩：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 為 Transformer 的 Encoder / Decoder 準備遮罩&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的&lt;/span&gt;
  &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 &lt;/span&gt;
  &lt;span class="c1"&gt;# 關注 Encoder 輸出序列用的&lt;/span&gt;
  &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# Decoder layer 的 MHA1 在做自注意力機制用的&lt;/span&gt;
  &lt;span class="c1"&gt;# `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加&lt;/span&gt;
  &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="n"&gt;dec_target_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_target_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果沒有本文前面針對遮罩的詳細說明，很多第一次實作的人得花不少時間來確實地掌握這些遮罩的用途。不過對現在的你來說應該也是小菜一碟。&lt;/p&gt;
&lt;p&gt;一個數據集包含多個 batch，而每次拿一個 batch 來訓練的步驟就稱作 &lt;code&gt;train_step&lt;/code&gt;。為了讓程式碼更簡潔以及容易優化，我們會定義 Transformer 在一次訓練步驟（處理一個 batch）所需要做的所有事情。&lt;/p&gt;
&lt;p&gt;不限於 Transformer，一般來說 &lt;code&gt;train_step&lt;/code&gt; 函式裡會有幾個重要步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;對訓練數據做些必要的前處理&lt;/li&gt;
&lt;li&gt;將數據丟入模型，取得預測結果&lt;/li&gt;
&lt;li&gt;用預測結果跟正確解答計算 loss&lt;/li&gt;
&lt;li&gt;取出梯度並利用 optimizer 做梯度下降&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了這個概念以後看看程式碼：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;  &lt;span class="c1"&gt;# 讓 TensorFlow 幫我們將 eager code 優化並加快運算&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 前面說過的，用去尾的原始序列去預測下一個字的序列&lt;/span&gt;
  &lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 建立 3 個遮罩&lt;/span&gt;
  &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 紀錄 Transformer 的所有運算過程以方便之後做梯度下降&lt;/span&gt;
  &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientTape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tape&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loss_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數&lt;/span&gt;
  &lt;span class="n"&gt;gradients&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tape&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainable_variables&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
  &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_gradients&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainable_variables&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要&lt;/span&gt;
  &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你曾經以TensorFlow 2 實作過稍微複雜一點的模型，應該就知道  &lt;code&gt;train_step&lt;/code&gt; 函式的寫法非常固定：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對輸入數據做些前處理（本文中的遮罩、將輸出序列左移當成正解 etc.）&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;tf.GradientTape&lt;/code&gt; 輕鬆記錄數據被模型做的所有轉換並計算 loss&lt;/li&gt;
&lt;li&gt;將梯度取出並讓 optimzier 對可被訓練的權重做梯度下降（上升）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你完全可以用一模一樣的方式將任何複雜模型的處理過程包在 &lt;code&gt;train_step&lt;/code&gt; 函式，這樣可以讓我們之後在 iterate 數據集時非常輕鬆。而且最重要的是可以用 &lt;a href="https://www.tensorflow.org/beta/tutorials/eager/tf_function"&gt;tf.function&lt;/a&gt; 來提高此函式裡頭運算的速度。你可以點擊連結來了解更多。&lt;/p&gt;
&lt;p&gt;處理一個 batch 的 &lt;code&gt;train_step&lt;/code&gt; 函式也有了，就只差寫個 for loop 將數據集跑個幾遍了。我之前的模型雖然訓練了 50 個 epochs，但事實上大概 30 epochs 翻譯的結果就差不多穩定了。所以讓我們將 &lt;code&gt;EPOCHS&lt;/code&gt; 設定為 30：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 定義我們要看幾遍數據集&lt;/span&gt;
&lt;span class="n"&gt;EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"此超參數組合的 Transformer 已經訓練 &lt;/span&gt;&lt;span class="si"&gt;{last_epoch}&lt;/span&gt;&lt;span class="s2"&gt; epochs。"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"剩餘 epochs：{min(0, last_epoch - EPOCHS)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="c1"&gt;# 用來寫資訊到 TensorBoard，非必要但十分推薦&lt;/span&gt;
&lt;span class="n"&gt;summary_writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_file_writer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_epoch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 重置紀錄 TensorBoard 的 metrics&lt;/span&gt;
  &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_states&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_states&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 &lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss&lt;/span&gt;
    &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  

  &lt;span class="c1"&gt;# 每個 epoch 完成就存一次檔    &lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;ckpt_save_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Saving checkpoint for epoch &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; at &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                         &lt;span class="n"&gt;ckpt_save_path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
  &lt;span class="c1"&gt;# 將 loss 以及 accuracy 寫到 TensorBoard 上&lt;/span&gt;
  &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;summary_writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train_loss"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train_acc"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Epoch &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; Loss &lt;/span&gt;&lt;span class="si"&gt;{:.4f}&lt;/span&gt;&lt;span class="s1"&gt; Accuracy &lt;/span&gt;&lt;span class="si"&gt;{:.4f}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; 
                                                &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Time taken for 1 epoch: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; secs&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;此超參數組合的 Transformer 已經訓練 50 epochs。
剩餘 epochs：0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如訊息所示，當指定的 &lt;code&gt;EPOCHS&lt;/code&gt; 「落後」於之前的訓練進度我們就不再訓練了。但如果是第一次訓練或是訓練到指定 &lt;code&gt;EPOCHS&lt;/code&gt; 的一部分，我們都會從正確的地方開始訓練並存檔，不會浪費到訓練時間或計算資源。&lt;/p&gt;
&lt;p&gt;這邊的邏輯也很簡單，在每個 epoch 都：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（非必要）重置寫到 TensorBoard 的 metrics 的值&lt;/li&gt;
&lt;li&gt;將整個數據集的 batch 取出，交給 &lt;code&gt;train_step&lt;/code&gt; 函式處理&lt;/li&gt;
&lt;li&gt;（非必要）存 checkpoints&lt;/li&gt;
&lt;li&gt;（非必要）將當前 epoch 結果寫到 TensorBoard&lt;/li&gt;
&lt;li&gt;（非必要）在標準輸出顯示當前 epoch 結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是的，如果你真的只是想要訓練個模型，什麼其他事情都不想考慮的話那你可以：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 87 分，不能再高了。&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/go-home-every-body.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯 ... 話是這麼說，但我仍然建議你至少要記得存檔並將訓練過程顯示出來。我知道你會好奇訓練一個這樣的 Transformer 要多久時間，讓我把之前訓練的一些 log 顯示出來給你瞧瞧：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;

Saving checkpoint for epoch 1 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-1
Epoch 1 Loss 5.2072 Accuracy 0.0179
Time taken for 1 epoch: 206.54558181762695 secs

Saving checkpoint for epoch 2 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-2
Epoch 2 Loss 4.2652 Accuracy 0.0560
Time taken for 1 epoch: 68.48831677436829 secs

Saving checkpoint for epoch 3 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-3
Epoch 3 Loss 3.7987 Accuracy 0.0910
Time taken for 1 epoch: 68.41022562980652 secs


...


Saving checkpoint for epoch 29 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-29
Epoch 29 Loss 1.2693 Accuracy 0.3929
Time taken for 1 epoch: 69.18679404258728 secs

Saving checkpoint for epoch 30 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-30
Epoch 30 Loss 1.2426 Accuracy 0.3965
Time taken for 1 epoch: 68.7313539981842 secs



&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上我們定義的 4 層 Transformer 大約每 70 秒就可以看完一遍有 3 萬筆訓練例子的數據集，而且你從上面的 loss 以及 accuracy 可以看出來 Transformer 至少在訓練集裡頭進步地挺快的。&lt;/p&gt;
&lt;p&gt;而就我自己的觀察大約經過 30 個 epochs 翻譯結果就很穩定了。所以你大約只需半個小時就能有一個非常簡單，有點水準的英翻中 Transformer（在至少有個一般 GPU 的情況）。&lt;/p&gt;
&lt;p&gt;但跟看上面的 log 比起來，我個人還是比較推薦使用 TensorBoard。在 TensorFlow 2 裡頭，你甚至能直接在 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;Jupyter Notebook 或是 Colab&lt;/a&gt; 裡頭開啟它：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;load_ext&lt;/span&gt; &lt;span class="n"&gt;tensorboard&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;tensorboard&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;logdir&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;your_log_dir&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline=""&gt;
&lt;source src="https://leemeng.tw/images/transformer/tensorboard.mp4" type="video/mp4"/&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    使用 TensorBoard 可以讓你輕鬆比較不同超參數的訓練結果
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過 TensorBoard，你能非常清楚地比較不同實驗以及不同點子的效果，知道什麼 work 什麼不 work，進而修正之後嘗試的方向。如果只是簡單寫個 &lt;code&gt;print&lt;/code&gt;，那你永遠只會看到最新一次訓練過程的 log，然後忘記之前到底發生過什麼事。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實際進行英翻中"&gt;實際進行英翻中&lt;a class="anchor-link" href="#實際進行英翻中"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了已經訓練一陣子的 Transformer，當然得拿它來實際做做翻譯。&lt;/p&gt;
&lt;p&gt;跟訓練的時候不同，在做預測時我們不需做 teacher forcing 來穩定 Transformer 的訓練過程。反之，我們將 Transformer 在每個時間點生成的中文索引加到之前已經生成的序列尾巴，並以此新序列作為其下一次的輸入。這是因為 Transformer 事實上是一個&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B"&gt;自迴歸模型（Auto-regressive  model）&lt;/a&gt;：依據自己生成的結果預測下次輸出。&lt;/p&gt;
&lt;p&gt;利用 Transformer 進行翻譯（預測）的邏輯如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將輸入的英文句子利用 Subword Tokenizer 轉換成子詞索引序列（還記得 &lt;code&gt;inp&lt;/code&gt; 吧？）&lt;/li&gt;
&lt;li&gt;在該英文索引序列前後加上代表英文 BOS / EOS 的 tokens&lt;/li&gt;
&lt;li&gt;在 Transformer 輸出序列長度達到 &lt;code&gt;MAX_LENGTH&lt;/code&gt; 之前重複以下步驟：&lt;ul&gt;
&lt;li&gt;為目前已經生成的中文索引序列產生新的遮罩&lt;/li&gt;
&lt;li&gt;將剛剛的英文序列、當前的中文序列以及各種遮罩放入 Transformer&lt;/li&gt;
&lt;li&gt;將 Transformer 輸出序列的最後一個位置的向量取出，並取 argmax 取得新的預測中文索引&lt;/li&gt;
&lt;li&gt;將此索引加到目前的中文索引序列裡頭作為 Transformer 到此為止的輸出結果&lt;/li&gt;
&lt;li&gt;如果新生成的中文索引為 &lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt; 則代表中文翻譯已全部生成完畢，直接回傳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;將最後得到的中文索引序列回傳作為翻譯結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是的，一個時間點生成一個中文字，而在第一個時間點因為 Transformer 還沒有任何輸出，我們會丟中文字的 &lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt; token 進去。你可能會想：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        為何每次翻譯開頭都是 start token，Transformer 還能產生不一樣且正確的結果？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案也很簡單，因為 Decoder 可以透過「關注」 Encoder 處理完不同英文句子的輸出來獲得語義資訊，了解它在當下該生成什麼中文字作為第一個輸出。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在讓我們定義一個 &lt;code&gt;evaluate&lt;/code&gt; 函式實現上述邏輯。此函式的輸入是一個完全沒有經過處理的英文句子（以字串表示），輸出則是一個索引序列，裡頭的每個索引就代表著 Transformer 預測的中文字。&lt;/p&gt;
&lt;p&gt;讓我們實際看看 &lt;code&gt;evaluate&lt;/code&gt; 函式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 準備英文句子前後會加上的 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;
  &lt;span class="n"&gt;start_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;end_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列&lt;/span&gt;
  &lt;span class="c1"&gt;# 並在前後加上 BOS / EOS&lt;/span&gt;
  &lt;span class="n"&gt;inp_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start_token&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;end_token&lt;/span&gt;
  &lt;span class="n"&gt;encoder_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入&lt;/span&gt;
  &lt;span class="c1"&gt;# 是一個只包含一個中文 &amp;lt;start&amp;gt; token 的序列&lt;/span&gt;
  &lt;span class="n"&gt;decoder_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;decoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 增加 batch 維度&lt;/span&gt;
  
  &lt;span class="c1"&gt;# auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 每多一個生成的字就得產生新的遮罩&lt;/span&gt;
    &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;encoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
    &lt;span class="c1"&gt;# predictions.shape == (batch_size, seq_len, vocab_size)&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                 &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    

    &lt;span class="c1"&gt;# 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, 1, vocab_size)&lt;/span&gt;

    &lt;span class="n"&gt;predicted_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 遇到 &amp;lt;end&amp;gt; token 就停止回傳，代表模型已經產生完結果&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
    
    &lt;span class="c1"&gt;#將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生&lt;/span&gt;
    &lt;span class="c1"&gt;# 下個中文字的時候關注到最新的 `predicted_id`&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_id&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 將 batch 的維度去掉後回傳預測的中文索引序列&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道這章節程式碼很多很長，但搭配註解後你會發現它們實際上都不難，而且這也是你看這篇文章的主要目的：實際了解 Transformer 是怎麼做英中翻譯的。你不想只是紙上談兵，對吧？&lt;/p&gt;
&lt;p&gt;有了 &lt;code&gt;evaluate&lt;/code&gt; 函式，要透過 Transformer 做翻譯非常容易：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 要被翻譯的英文句子&lt;/span&gt;
&lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"China, India, and others have enjoyed continuing economic growth."&lt;/span&gt;

&lt;span class="c1"&gt;# 取得預測的中文索引序列&lt;/span&gt;
&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 過濾掉 &amp;lt;start&amp;gt; &amp;amp; &amp;lt;end&amp;gt; tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;
&lt;span class="n"&gt;predicted_seq_without_bos_eos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;predicted_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq_without_bos_eos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_seq:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
predicted_sentence: 中国、印度和其他国家都享受了经济增长的持续发展。
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;考慮到這個 Transformer 不算巨大（約 400 萬個參數），且模型訓練時用的數據集不大的情況下，我們達到相當不錯的結果，你說是吧？在這個例子裡頭該翻的詞彙都翻了出來，句子本身也還算自然。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Model: "transformer_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_2 (Encoder)          multiple                  1834624   
_________________________________________________________________
decoder_2 (Decoder)          multiple                  1596288   
_________________________________________________________________
dense_137 (Dense)            multiple                  542187    
=================================================================
Total params: 3,973,099
Trainable params: 3,973,099
Non-trainable params: 0
_________________________________________________________________
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="視覺化注意權重"&gt;視覺化注意權重&lt;a class="anchor-link" href="#視覺化注意權重"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了其運算高度平行以及表現不錯以外，Transformer 另外一個優點在於我們可以透過視覺化注意權重（attention weights）來了解模型實際在生成序列的時候放「注意力」在哪裡。別忘記我們當初在 Decoder layers 做完 multi-head attention 之後都將注意權重輸出。現在正是它們派上用場的時候了。&lt;/p&gt;
&lt;p&gt;先讓我們看看有什麼注意權重可以拿來視覺化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 在這邊我們自動選擇最後一個 Decoder layer 的 MHA 2，也就是 Decoder 關注 Encoder 的 MHA&lt;/span&gt;
&lt;span class="n"&gt;layer_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt;_block2"&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_seq:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights.keys():"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{layer_name}&lt;/span&gt;&lt;span class="s2"&gt;.shape: &lt;/span&gt;&lt;span class="si"&gt;{attn.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"layer_name:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
attention_weights.keys():
decoder_layer1_block1.shape: (1, 8, 25, 25)
decoder_layer1_block2.shape: (1, 8, 25, 15)
decoder_layer2_block1.shape: (1, 8, 25, 25)
decoder_layer2_block2.shape: (1, 8, 25, 15)
decoder_layer3_block1.shape: (1, 8, 25, 25)
decoder_layer3_block2.shape: (1, 8, 25, 15)
decoder_layer4_block1.shape: (1, 8, 25, 25)
decoder_layer4_block2.shape: (1, 8, 25, 15)
--------------------
layer_name: decoder_layer4_block2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;block1&lt;/code&gt; 代表是 Decoder layer 自己關注自己的 MHA 1，因此倒數兩個維度都跟中文序列長度相同；&lt;code&gt;block2&lt;/code&gt; 則是 Decoder layer 用來關注 Encoder 輸出的 MHA 2 ，在這邊我們選擇最後一個 Decoder layer 的 MHA 2 來看 Transformer 在生成中文序列時關注在英文句子的那些位置。&lt;/p&gt;
&lt;p&gt;但首先，我們得要有一個繪圖的函式才行：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mpl&lt;/span&gt;
&lt;span class="c1"&gt;# 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文&lt;/span&gt;
&lt;span class="n"&gt;zhfont&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mpl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;font_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FontProperties&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'/usr/share/fonts/SimHei/simhei.ttf'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"seaborn-whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 這個函式將英 -&amp;gt; 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_attention_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
  &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 只顯示中文序列前 `max_len_tar` 個字以避免畫面太過壅擠&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;predicted_seq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;max_len_tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將某一個特定 Decoder layer 裡頭的 MHA 1 或 MHA2 的注意權重拿出來並去掉 batch 維度&lt;/span&gt;
  &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
  &lt;span class="c1"&gt;# (num_heads, tar_seq_len, inp_seq_len)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將每個 head 的注意權重畫出&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# [注意]我為了將長度不短的英文子詞顯示在 y 軸，將注意權重做了 transpose&lt;/span&gt;
    &lt;span class="n"&gt;attn_map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:])&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn_map&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'viridis'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (inp_seq_len, tar_seq_len)&lt;/span&gt;
    
    &lt;span class="n"&gt;fontdict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"fontproperties"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;zhfont&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticklabels&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt; 
                        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                       &lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'&amp;lt;start&amp;gt;'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'&amp;lt;end&amp;gt;'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
        &lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Head &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"x"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"y"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tight_layout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個函式不難，且裡頭不少是調整圖片的細節設定因此我將它留給你自行參考。&lt;/p&gt;
&lt;p&gt;比較值得注意的是因為我們在這篇文章是做英文（來源）到中文（目標）的翻譯，注意權重的 shape 為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(batch_size, num_heads, zh_seq_len, en_seq_len)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你直接把注意權重繪出的話 y 軸就會是每個中文字，而 x 軸則會是每個英文子詞。而英文子詞繪在 x 軸太佔空間，我將每個注意權重都做 transpose 並呈現結果，這點你得注意一下。&lt;/p&gt;
&lt;p&gt;讓我們馬上畫出剛剛翻譯的注意權重看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plot_attention_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                       &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABMUAAAHvCAYAAABUoWiWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;很美，不是嗎？&lt;/p&gt;
&lt;p&gt;如果你還記得，我在本文開頭就曾經秀過這張圖甚至開玩笑地跟你說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        好黑魔法，不學嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我不知道你當初跟現在的感受，但我相信在你閱讀完本文，尤其是對自注意機制以及 Transformer 有了深刻理解之後，這之間的感受肯定是有不少差異的。&lt;/p&gt;
&lt;p&gt;儘管其運算機制十分錯綜複雜，閱讀本文後 Transformer 對你來說不再是黑魔法，也不再是遙不可及的存在。如果你現在覺得「Transformer 也不過就這樣嘛！」那就達成我寫這篇文章的目的了。&lt;/p&gt;
&lt;p&gt;自注意力機制以及 Transformer 在推出之後就被非常廣泛地使用並改進，但在我自己開始接觸相關知識以後一直沒有發現完整的繁中教學，因此寫了這篇當初的我殷殷期盼的文章，也希望能幫助到更多人學習。&lt;/p&gt;
&lt;p&gt;在進入結語之前，讓我們看看文中的 Transformer 是怎麼逐漸學會做好翻譯的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline=""&gt;
&lt;source src="https://leemeng.tw/images/transformer/attention_weights_change_by_time.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：S
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    Transformer 在訓練過程中逐漸學會關注在對的位置
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在你離開之前"&gt;在你離開之前&lt;a class="anchor-link" href="#在你離開之前"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        這篇是當初在學習 Transformer 的我希望有人分享給自己的文章。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我相信人類之所以強大是因為集體知識：我們能透過書籍、影片以及語言將一個人腦中的知識與思想共享給其他人，讓寶貴的知識能夠「scale」，在更多人的腦袋中發光發熱，創造更多價值。&lt;/p&gt;
&lt;p&gt;我希望你有從本文中學到一點東西，並幫助我將本文的這些知識「scale」，把文章分享給更多有興趣的人，並利用所學應用在一些你一直想要完成的任務上面。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        以 Transformer 為基礎的語言代表模型 BERT
                        （&lt;a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你想要了解更多 Transformer 的相關應用，我推薦接著閱讀&lt;a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html"&gt;進擊的 BERT：NLP 界的巨人之力與遷移學習&lt;/a&gt;，了解現在 NLP 領域裡頭知名的語言代表模型 BERT。&lt;/p&gt;
&lt;p&gt;最後一點提醒，就算 Transformer 比古早時代的方法好再多終究也只是個工具，其最大價值不會超過於被你拿來應用的問題之上。就好像現在已有不少超越基本 Transformer 的翻譯方法，但我們仍然持續在追尋更好的機器翻譯系統。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        工具會被淘汰，需求一直都在。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="自然語言處理"></category><category term="NLP"></category><category term="Tensorflow"></category></entry><entry><title>用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫</title><link href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html" rel="alternate"></link><published>2019-05-05T02:20:00+09:00</published><updated>2019-05-05T02:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-05-05:/generate-anime-using-cartoongan-and-tensorflow2.html</id><summary type="html">&lt;p&gt;本文展示 3 種可以讓你馬上運用 CartoonGAN 來生成動漫的方法。其中包含了我們的 Github 專案、TensorFlow.js 應用以及一個事先為你準備好的 Colab 筆記本。有興趣的同學還可學習如何利用 TensorFlow 2.0 來訓練自己的專屬 CartoonGAN。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link href="https://leemeng.tw/tfjs-apps/cartoongan/cartoongan.css" rel="stylesheet"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如果你能用 AI 為圖片添加新海誠或是宮崎駿等人的動漫風格，你會選擇什麼圖片？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇文章將簡單介紹最近我與夥伴 &lt;a href="https://github.com/mnicnc404"&gt;mnicnc404&lt;/a&gt; 以 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0 Alpha&lt;/a&gt; 實作的 CartoonGAN（&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;Github 連結&lt;/a&gt;）。我們同時也會展示一個 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 應用，讓你可以直接在瀏覽器上產生動漫。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;CartoonGAN（原論文）&lt;/a&gt; 於 2018 &lt;a href="http://cvpr2019.thecvf.com/"&gt;CVPR&lt;/a&gt; 推出，是一個嘗試將真實世界圖片轉換成動漫的&lt;a href="https://youtu.be/yFBFl1cLYx8?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=1879"&gt;對抗生成網路（Generative Adversarial Network，以下簡稱 GAN）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/cat_cover.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/cat_cover.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        左上為原圖，其餘三圖則為我們使用 CartoonGAN 將不同動漫風格套用到原圖上的結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當初看到這篇&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;論文&lt;/a&gt;覺得很有趣，且裡頭正好展示了我喜愛的兩位日本動畫作家：&lt;a href="https://zh.wikipedia.org/wiki/%E6%96%B0%E6%B5%B7%E8%AA%A0"&gt;新海誠&lt;/a&gt;及&lt;a href="https://zh.wikipedia.org/zh-tw/%E5%AE%AB%E5%B4%8E%E9%AA%8F"&gt;宮崎駿&lt;/a&gt;的風格轉換結果，因此決定寫個 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 應用，讓更多人可以實際體驗這個有趣的 CartoonGAN。&lt;/p&gt;
&lt;p&gt;使用方法很直覺，選擇風格並上傳照片，完成！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/tfjs-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow.js 在瀏覽器裡運行，其背後處理主要分為兩個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下載模型&lt;/li&gt;
&lt;li&gt;轉換圖片&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因手機的運算能力有限，強烈建議：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用桌筆電等&lt;strong&gt;計算能力&lt;/strong&gt;強的設備開啟本頁面&lt;/li&gt;
&lt;li&gt;並在網速快的環境測試（減少&lt;strong&gt;載入模型&lt;/strong&gt;時間）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="動手玩-CartoonGAN"&gt;動手玩 CartoonGAN&lt;a class="anchor-link" href="#動手玩-CartoonGAN"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以下就是實際的應用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="row" id="container"&gt;
&lt;div class="column50"&gt;
&lt;div&gt;
&lt;img class="cartoongan_image" id="input" src="https://leemeng.tw/tfjs-apps/cartoongan/cat.png"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="column50"&gt;
&lt;div&gt;
&lt;img class="cartoongan_image" id="pregenerated_output" src="https://leemeng.tw/tfjs-apps/cartoongan/cat_shinkai.jpg"/&gt;
&lt;canvas id="output" style="display:none"&gt;&lt;/canvas&gt;
&lt;/div&gt;
&lt;div id="app-status" style="display:none;padding:70px 0"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="row" style="margin-bottom:6rem;"&gt;
&lt;div class="column50"&gt;
&lt;label class="btn" style="margin-top: 2rem;height: 3rem;line-height:2.8rem;color:white;padding: 0 1rem"&gt;
            選擇圖片
            &lt;input id="files" multiple="" name="files[]" style="display:none" type="file"/&gt;
&lt;/label&gt;
&lt;/div&gt;
&lt;div class="column50"&gt;
&lt;select id="styles" name="styles" style="margin: auto;display: block;margin-top: 0.8rem"&gt;
&lt;option selected="selected" value="shinkai"&gt;&lt;b&gt;新海誠&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="hayao"&gt;&lt;b&gt;宮崎駿&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="hosoda"&gt;&lt;b&gt;細田守&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="paprika"&gt;&lt;b&gt;盜夢偵探&lt;/b&gt;風格&lt;/option&gt;
&lt;/select&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;結果出來了嗎？如果上傳圖片後一直停在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Loading Models&lt;/code&gt;：代表仍在下載模型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cartoonizing images&lt;/code&gt;：代表設備運算資源的不足&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也先別走開！你可以使用下一節介紹的方法來生成動漫，保證有效。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="TensorFlow-2-畫動漫"&gt;TensorFlow 2 畫動漫&lt;a class="anchor-link" href="#TensorFlow-2-畫動漫"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;適逢 &lt;a href="https://tensorflow.devpost.com/"&gt;PoweredByTF 2.0 挑戰&lt;/a&gt;，我們也用 TensorFlow 2.0 Alpha 完整地實作了 CartoonGAN 的訓練以及推論邏輯。如果你想要轉換大張圖片或是動圖，可以執行&lt;a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX"&gt;這個 Colab 筆記本&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/colab-demo.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/colab-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        執行我們準備的 Colab 筆記本可以讓你用 CartoonGAN 轉換任何圖片（上圖顯示該筆記本的部分內容）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://colab.research.google.com/"&gt;Google Colaboratory&lt;/a&gt; 是一個雲端 &lt;a href="https://jupyter.org/"&gt;Jupyter 筆記本&lt;/a&gt;環境，提供 GPU 讓任何人都可以立即開始一個深度學習專案。&lt;/p&gt;
&lt;p&gt;在&lt;a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX"&gt;這個筆記本&lt;/a&gt;裡頭，以下步驟都幫你寫好了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;建置 TensorFlow 2.0 環境&lt;/li&gt;
&lt;li&gt;下載&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案及預訓練模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下載任意網路圖片 / gif&lt;/li&gt;
&lt;li&gt;使用 CartoonGAN 轉換圖片&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你只需打開筆記本並依照指示一步步執行，即可為你的圖片添加動漫風格。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一些轉換後的動漫結果"&gt;一些轉換後的動漫結果&lt;a class="anchor-link" href="#一些轉換後的動漫結果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;獨樂樂不如眾樂樂。這一節和你分享一些我們用 CartoonGAN 得到的結果。&lt;/p&gt;
&lt;p&gt;以下每張圖片都分為四個區塊，從左到右、由上而下分別為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始圖片&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E6%96%B0%E6%B5%B7%E8%AA%A0"&gt;新海誠&lt;/a&gt;風格&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/zh-tw/%E5%AE%AB%E5%B4%8E%E9%AA%8F"&gt;宮崎駿&lt;/a&gt;風格&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%B4%B0%E7%94%B0%E5%AE%88"&gt;細田守&lt;/a&gt;風格&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;點擊下圖左右兩側的小箭頭可以切換不同圖片：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;style&gt;
&lt;!-- https://www.w3schools.com/w3css/w3css_slideshow.asp --&gt;
.w3-content,
.w3-auto {
    margin-left: auto;
    margin-right: auto
}

.w3-content {
    max-width: 980px
}

.w3-display-container:hover .w3-display-hover {
    display: block
}

.w3-display-container:hover span.w3-display-hover {
    display: inline-block
}

.w3-display-container {
    position: relative
}

.w3-button:hover {
    color: #000!important;
    background-color: inherit;
}

.w3-button {
    border: none;
    display: inline-block;
    padding: 8px 16px;
    vertical-align: middle;
    overflow: hidden;
    text-decoration: none;
    color: inherit;
    background-color: inherit;
    text-align: center;
    cursor: pointer;
    white-space: nowrap
}

.w3-button {
    -webkit-touch-callout: none;
    -webkit-user-select: none;
    -khtml-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none
}

.w3-button:disabled {
    cursor: not-allowed;
    opacity: 0.3
}

.w3-display-left {
    position: absolute;
    top: 50%;
    left: 0%;
    transform: translate(0%, -50%);
    -ms-transform: translate(-0%, -50%)
}

.w3-display-right {
    position: absolute;
    top: 50%;
    right: 0%;
    transform: translate(0%, -50%);
    -ms-transform: translate(0%, -50%)
}

.mySlides {display:none;}
&lt;/style&gt;&lt;div class="w3-content w3-display-container"&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/dance.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--marvel--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/iron-man-face.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/iron-man.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;img class="mySlides" src="https://leemeng.tw/images/cartoongan/gallery/static-woman-face.jpg" style="width:100%"/&gt;
&lt;img class="mySlides" src="https://leemeng.tw/images/cartoongan/gallery/static-temple.jpg" style="width:100%"/&gt;
&lt;!--cat--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-shake-meme.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-being-poked.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-computer.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--scenary--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/big-ben.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/city-street.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/church.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--idol--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/demo.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/arakaki.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/harry-potter.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--virtual character--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/pikachu.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/kumamon.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;button class="w3-button w3-black w3-display-left" onclick="plusDivs(-1)"&gt;❮&lt;/button&gt;
&lt;button class="w3-button w3-black w3-display-right" onclick="plusDivs(1)"&gt;❯&lt;/button&gt;
&lt;/div&gt;&lt;script&gt;
var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("mySlides");
  if (n &gt; x.length) {slideIndex = 1}
  if (n &lt; 1) {slideIndex = x.length}
  for (i = 0; i &lt; x.length; i++) {
    x[i].style.display = "none";  
  }
  x[slideIndex-1].style.display = "block";  
}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;從漫威電影到可愛貓咪，從自然風景到人氣偶像，任何你想得到的圖片都可以拿來進行轉換。一旦訓練完成，我們就能使用 CartoonGAN 在彈指之間將各式各樣的圖片跟動漫做連結。&lt;/p&gt;
&lt;p&gt;在&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;裡頭，你甚至只需要執行一個指令就能取得上面展示的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python cartoonize.py &lt;span class="se"&gt;\&lt;/span&gt;
    --styles shinkai hayao hosoda
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;當然，接下來數年類似應用的效果會更加卓越。未來誰都能用這些 apps 來創造自己的動漫，而動漫作家可以據此更快速地畫出草稿、測試新點子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如 CartoonGAN 這樣的生成模型能讓我們看到未來更多的可能性。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;順帶一提，我們在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部&lt;/a&gt;也已經看過類似的概念。只是在該篇裡頭，我們是讓機器生成武俠小說而非動漫圖片。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="訓練你自己的-CartoonGAN"&gt;訓練你自己的 CartoonGAN&lt;a class="anchor-link" href="#訓練你自己的-CartoonGAN"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可能發現本文非常注重在 CartoonGAN 的實際應用而非演算法細節。這是因為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比起&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;論文細節&lt;/a&gt;，多數人應該都對如何生成有趣的動漫比較感興趣&lt;/li&gt;
&lt;li&gt;網上已有不少 &lt;a href="#推薦的-GAN-學習資源"&gt;CartoonGAN 的介紹文章以及 GAN 的學習資源&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對 CartoonGAN 的實作細節有興趣的讀者可以參考&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;。基本上只要依照指示裝好開發環境以及準備好資料集，你甚至可以一鍵訓練 CartoonGAN：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/train-demo.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們的 Python 腳本提供了詳盡訊息，方便你理解訓練過程究竟發生了什麼事情
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為所有邏輯皆以 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0 Alpha&lt;/a&gt; 實作，非常適合想要跟上最新 TensorFlow 發展的讀者學習：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/alpha/guide/keras/overview"&gt;tf.keras&lt;/a&gt; 實作 Layers 以及 GAN&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/alpha/guide/data_performance"&gt;tf.data&lt;/a&gt; 讀取大量圖片並進行前處理&lt;/li&gt;
&lt;li&gt;寫訓練邏輯並使用 &lt;a href="https://youtu.be/Up9CvRLIIIw?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;tf.function&lt;/a&gt; 加快處理速度&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;TensorBoard&lt;/a&gt; 來即時觀測模型表現&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;訓練 GAN 本身並不是一件非常容易的事情。你會需要時時觀察模型的表現以評估如何調整超參數。因此我們的&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow/blob/master/train.py"&gt;訓練腳本&lt;/a&gt;也整合了 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;TensorBoard&lt;/a&gt;，讓你可以在執行後即時地監控模型表現：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tensorboard-metrics.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們訓練 CartoonGAN 的其中一次實際結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了指標與損失函數以外，在訓練 GAN 的過程中觀察模型生成的圖片也是一件非常重要的事情。因此我們也將 CartoonGAN 生成的圖片寫入 TensorBoard 以方便你觀測比較：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tensorboard-image-demo.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在腳本執行的過程中可以直接在 TensorBoard 上觀察 CartoonGAN 當下生成的圖片
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們只紀錄專屬於 CartoonGAN 的指標以及生成圖片，你完全可以運用類似的方法來監測任何想要訓練的模型。&lt;/p&gt;
&lt;p&gt;最後，為了方便了解 CartoonGAN 在訓練過程的表現，我們可以事先存一組真實世界的圖片當作驗證集（Validation Set），並固定讓模型在訓練一段時間後都試著將其轉換成動漫。&lt;/p&gt;
&lt;p&gt;我們可以用驗證集的轉換結果來評估模型在當下的表現。將這些圖片依時間排序後可以得到這樣的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/training_progress.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/training_progress.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        CartoonGAN 學習將真實世界圖片轉換為動漫的過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管尚未訓練完成，你可以看到模型逐漸學會將原始圖片轉換成簡單的動漫：線條變得清晰、顏色變得平滑。&lt;/p&gt;
&lt;p&gt;跟訓練一個&lt;a href="https://www.tensorflow.org/tutorials/keras/basic_classification"&gt;簡單分類器&lt;/a&gt;比起來，訓練一個 GAN 的難度可說是完全不同級別。但我們盡量讓&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt; Github 專案&lt;/a&gt;裡頭的程式碼邏輯簡單易懂，希望能讓更多人入門 TensorFlow 2.0 以及 GAN 的實作。&lt;/p&gt;
&lt;p&gt;當然，具備理論基礎能讓你更容易理解 TensorFlow 2 的程式碼。下節將列出推薦的學習資源供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="推薦的-GAN-學習資源"&gt;推薦的 GAN 學習資源&lt;a class="anchor-link" href="#推薦的-GAN-學習資源"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;近年以深度學習為基礎的生成模型（Generative Models）領域蓬勃發展，其中最亮眼的發展之一當屬對抗生成網路了。而本文的 CartoonGAN 也是&lt;a href="https://github.com/hindupuravinash/the-gan-zoo"&gt;眾多 GANs&lt;/a&gt; 裡頭的其中一個小夥子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tf-dcgan.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        對抗生成網路 GAN 實際上由兩個獨立的神經網路相互「對抗」
                        （&lt;a href="https://www.tensorflow.org/alpha/tutorials/generative/dcgan" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對 GAN 的理論 &amp;amp; 基礎知識有興趣的讀者，我推薦以下的學習資源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DQNNMiAP5lw&amp;amp;list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw"&gt;李宏毅教授在 Youtube 上的 GAN 教學影片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=yFBFl1cLYx8&amp;amp;index=1&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI"&gt;MIT 6.S191 的 Deep Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab 讓你在瀏覽器上訓練並學習 GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/gan/"&gt;Andrej Karpathy 的簡單 GAN Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/generative/dcgan"&gt;TensorFlow 官方教學帶你生成 MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jiqizhixin.com/articles/CVPR2018-CartoonGAN"&gt;機器之心講解 CartoonGAN 運作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/syncedreview/reproducing-japanese-anime-styles-with-cartoongan-ai-cf30d583736e"&gt;Synced: Reproducing Japanese Anime Styles With CartoonGAN AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://distill.pub/2019/gan-open-problems/"&gt;Open Questions about Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/mit-gan.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        MIT 6.S191 的 Deep Generative Models 適合入門
                        （&lt;a href="https://www.youtube.com/watch?v=yFBFl1cLYx8&amp;amp;index=1&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;生成模型及 GAN 的研究領域博大精深，但我相信參考過以上資源，你將具備實作一個簡單 GAN 所需的基礎知識。&lt;/p&gt;
&lt;p&gt;更多學習資源則請參閱&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;由淺入深的深度學習資源整理&lt;/a&gt;。另外如果你有其他推薦的學習資源，還請不吝留言與我及其他讀者分享，謝謝！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        要讓深度學習、人工智慧等研究與應用的發展加快，我們應該想辦法先讓更多人實際體驗其應用，進而理解其運作原理，最後參與其中。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以 CartoonGAN 為例，本文先專注在&lt;strong&gt;如何讓每個人都能實際體驗並應用此技術&lt;/strong&gt;，接著才簡單介紹讀者可以如何使用&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;來訓練自己的模型。最後我也附上了一些實用的學習資源供對背後原理有興趣的讀者做些參考。&lt;/p&gt;
&lt;p&gt;這是我第一次用 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0&lt;/a&gt; 以及 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 實作 GAN，感謝 CartoonGAN 原作者的研究、TensorFlow / TensorFlow.js 團隊的努力、夥伴 &lt;a href="https://github.com/mnicnc404"&gt;mnicnc404&lt;/a&gt; 強大的實作支援以及許多寶貴見解，獲益良多。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望透過此文能讓更多人進一步探索 GAN 以及生成模型的相關知識，嘗試更多新的可能性，做出更多有趣的 AI 應用。&lt;/p&gt;
&lt;p&gt;也別忘了跟我分享你生成的動漫！你可以在 &lt;a href="https://twitter.com/leemengtw"&gt;Twitter&lt;/a&gt; 或是 &lt;a href="https://www.facebook.com/LeeMengTaiwan"&gt;Facebook&lt;/a&gt; 上標註我：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/cartoongan/dist/tf.js"&gt;&lt;/script&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/cartoongan/cartoongan.js"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="GAN"></category><category term="TensorFlow"></category><category term="TensorFlow.js"></category></entry><entry><title>讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部</title><link href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html" rel="alternate"></link><published>2019-03-27T09:00:00+09:00</published><updated>2019-03-27T09:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-03-27:/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html</id><summary type="html">&lt;p&gt;這篇文章展示一個由 TensorFlow 2.0 以及 TensorFlow.js 實現的文本生成應用。本文也會透過深度學習專案常見的 7 個步驟，帶領讀者一步步了解如何實現一個這樣的應用。閱讀完本文，你將對開發 AI 應用的流程有些基礎的了解。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link href="https://leemeng.tw/tfjs-apps/lstm-text-generation/index.css" rel="stylesheet"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote style="margin-bottom: 1rem"&gt;
&lt;p&gt;
        木婉清轉頭向他，背脊向著南海鱷神，低聲道：「你是世上第一個見到我容貌的男子！」緩緩拉開了面幕。段譽登時全身一震，眼前所見，如新月清暉，如花樹堆雪，一張臉秀麗絕俗。
        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;第四回：崖高人遠&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bit.ly/2TUycBQ"&gt;《天龍八部》&lt;/a&gt;一直是我最喜歡的&lt;a href="https://zh.wikipedia.org/wiki/%E9%87%91%E5%BA%B8%E4%BD%9C%E5%93%81"&gt;金庸著作&lt;/a&gt;之一，最近重新翻閱，有很多新的感受。&lt;/p&gt;
&lt;p&gt;閱讀到一半我突發奇想，決定嘗試用&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;深度學習&lt;/a&gt;以及 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0&lt;/a&gt; 來訓練一個能夠生成《天龍八部》的&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF"&gt;循環神經網路&lt;/a&gt;。生成結果仍不完美，但我認為已經很有娛樂性質，且有時能夠產生令人驚嘆或是捧腹大笑的文章了。&lt;/p&gt;
&lt;p&gt;因此我決定使用 &lt;a href="https://www.tensorflow.org/js"&gt;Tensorflow.js&lt;/a&gt; 將訓練出來的模型弄上線，讓你也能實際看看這個 AI 嗑了什麼藥。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/dali-old-castle.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        大理古城一隅，段譽出身之地
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 demo 之後，我將以此文的 AI 應用為例，用 TensorFlow 2.0 帶你走過深度學習專案中常見的 7 個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#1.-定義問題及要解決的任務"&gt;定義問題及要解決的任務&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2.-準備原始數據、資料清理"&gt;準備原始數據、資料清理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3.-建立能丟入模型的資料集"&gt;建立能丟入模型的資料集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4.-定義能解決問題的函式集"&gt;定義能解決問題的函式集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5.-定義評量函式好壞的指標"&gt;定義評量函式好壞的指標&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6.-訓練並選擇出最好的函式"&gt;訓練並選擇出最好的函式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7.-將函式-/-模型拿來做預測"&gt;將函式 / 模型拿來做預測&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;希望閱讀本文後能讓你學到點東西，從中獲得些啟發，並運用自己的想像力創造點新的東西。&lt;/p&gt;
&lt;p&gt;前言夠長了，讓我們馬上進入 demo 吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="生成新的天龍八部橋段"&gt;生成新的天龍八部橋段&lt;a class="anchor-link" href="#生成新的天龍八部橋段"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本篇使用一個十分簡單的&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶 RNN&lt;/a&gt; 來生成文章。在多次「閱讀」天龍八部之後，這個模型可以在給定一段文本的情況下，逐字產生類似天龍八部小說的文章。&lt;/p&gt;
&lt;p&gt;比方說給定書中的一個橋段：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;烏老大偏生要考一考慕容復，說道：「慕容公子，你瞧這不是大大的
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你會怎麼接下去？&lt;/p&gt;
&lt;p&gt;本文的模型順著上面的話生成的其中一次結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;不算？」馬夫人道：「不錯，咱們非要尋死不可。」

段譽大喜，說道：「小姑娘，你待我這麼好，鬼鬼祟祟，一切又不聽你的話，你管甚麼老兄弟不相干，我去幫過彥之。」

王夫人哼了一聲，說道：「這裏是甚麼話？」段譽道：「不行！你別過來。用真蠻子，我便將這件事了，一大惡人擠在地下，立時便會斃命，那便如何是好？」
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;文章內容很ㄎ一ㄤ，惹人發笑，但用詞本身很天龍八部。（至少我自己寫不出這樣的內容）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/antony-xia-522590-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        姑蘇慕容家所在的蘇州
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在馬上就讓我們產生一些新的橋段吧！首先將已經訓練好的模型載入你的瀏覽器。&lt;/p&gt;
&lt;p&gt;（建議在網速快的地方載入模型以減少等待時間，或者點擊載入後先閱讀&lt;a href="#模型是怎麼被訓練的"&gt;模型是怎麼被訓練的&lt;/a&gt;，等等再回來查看）&lt;/p&gt;
&lt;p&gt;成功載入模型後，你將可以用它不斷地產生新的橋段：&lt;/p&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;button id="load-model" style="display:inline-block"&gt;載入模型&lt;/button&gt;
&lt;div id="app-status" style="display:inline-block"&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你會發現有 2 個可供你調整的參數：&lt;/p&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成長度（字單位）&lt;/span&gt;
&lt;input id="generate-length" value="150"/&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成溫度（隨機度）&lt;/span&gt;
&lt;input id="temperature" value="0.6"/&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;p&gt;第一次可以直接使用預設值。現在點擊&lt;strong&gt;生成文章&lt;/strong&gt;來產生全新的天龍八部橋段：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;button disabled="true" id="generate-text"&gt;生成文章&lt;/button&gt;
&lt;button disabled="true" id="initialize-seed"&gt;重置輸入&lt;/button&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;起始句子：&lt;/span&gt;
&lt;span id="text-generation-status" style="display: none"&gt;&lt;/span&gt;
&lt;textarea id="seed-text" rows="1" style="min-height: 6em" value=""&gt;蕭峯吃了一驚，心想：「哥哥大喜之餘，說話有些忘形了，眼下亂成&lt;/textarea&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成結果：&lt;/span&gt;
&lt;textarea id="generated-text" readonly="true" rows="10" value=""&gt;&lt;/textarea&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如何？希望模型產生的結果有成功令你嘴角上揚。當初它可快把我逗死了。&lt;/p&gt;
&lt;p&gt;現在你可以嘗試幾件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;點&lt;strong&gt;生成文章&lt;/strong&gt;來讓模型依據同輸入產生新橋段&lt;/li&gt;
&lt;li&gt;點&lt;strong&gt;重置輸入&lt;/strong&gt;來隨機取得一個新的起始句子&lt;/li&gt;
&lt;li&gt;增加模型生成的&lt;strong&gt;文章長度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;調整&lt;strong&gt;生成溫度&lt;/strong&gt;來改變文章的變化性&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/chris-rhoads-254898-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;生成溫度是一個實數值，而當溫度越高，模型產生出來的結果越隨機、越不可預測（也就越ㄎㄧㄤ）；而溫度越低，產生的結果就會越像天龍八部原文。優點是真實，但同時字詞的重複性也會提升。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        機器並沒有情感，只有人類可以賦予事物意義。我們無法讓機器自動找出最佳的生成溫度，因為人的感覺十分主觀：找出你自己覺得最適合的溫度來生成文章。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你沒有打算深入探討技術細節，那只需要記得在這篇文章裡頭的模型是一個以「字」為單位的語言模型（Character-based Language Model）即可：給定一連串已經出現過的字詞，模型會想辦法去預測出下一個可能出現的字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/raychan-1229841-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得注意的是，我們並不單純是拿出現機率最高的字出來當生成結果，這樣太無趣了。&lt;/p&gt;
&lt;p&gt;每次機器做預測前都會拿著一個包含大量中文字的機率分布 p，在決定要吐出哪個字時，會對該機率分佈 p 做抽樣，從中隨機選出一個字。&lt;/p&gt;
&lt;p&gt;因此就跟你在上面 demo 看到的一樣，就算輸入的句子相同，每次模型仍然會生成完全不同的文章。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/max-felner-448887-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        抽樣的過程類似擲骰子，儘管有些結果較易出現，你還是有機會骰到豹子
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為隨機抽樣的關係，每次模型產生的結果基本上都是獨一無二的。&lt;/p&gt;
&lt;p&gt;如果你在生成文章的過程中得到什麼有趣的虛擬橋段，都歡迎與我分享：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/chris-ried-512801-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文接著將詳細解說此應用是怎麼被開發出來的。如果你現在沒有打算閱讀，可以直接跳到&lt;a href="#結語"&gt;結語&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="模型是怎麼被訓練的"&gt;模型是怎麼被訓練的&lt;a class="anchor-link" href="#模型是怎麼被訓練的"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在看完 demo 以後，你可能會好奇這個模型是怎麼被訓練出來的。&lt;/p&gt;
&lt;p&gt;實際的開發流程大致可以分為兩個部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;用 TensorFlow 2.0 訓練一個 LSTM 模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;使用 TensorFlow.js 部屬該模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些在 TensorFlow 以及 TensorFlow.js 的官網都有詳細的教學以及程式碼供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tf-demo.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這篇文章參考了不少 TensorFlow 官網（左）及 TensorFlow.js 線上 demo（右）的程式碼
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你也想開發一個類似的應用，閱讀官方教學中你所熟悉的語言版本（Python / JavaScript）是最直接的作法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;TensorFlow 2.0 Alpha - Text generation with an RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;TensorFlow.js Example: Train LSTM to Generate Text&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為官方已經有提供能在 &lt;a href="https://colab.research.google.com/"&gt;Google Colab&lt;/a&gt; 上使用 GPU &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;訓練 LSTM 的教學筆記本&lt;/a&gt;，本文便不再另行提供。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/simon-abrams-286276-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外，具備以下背景可以讓你更輕鬆地閱讀接下來的內容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;熟悉 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;碰過 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 或是 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;具備&lt;a href="https://leemeng.tw/deep-learning-resources.html#courses"&gt;機器學習 &amp;amp; 深度學習基礎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;了解何謂&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF"&gt;循環神經網路&lt;/a&gt;以及&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你是喜歡先把基礎打好的人，可以先查閱我上面附的這些資源連結。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="TensorFlow-2.0-開發"&gt;TensorFlow 2.0 開發&lt;a class="anchor-link" href="#TensorFlow-2.0-開發"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;平常有在接觸深度學習的讀者或許都已經知道，最近 TensorFlow 隆重推出 &lt;a href="https://www.tensorflow.org/alpha"&gt;2.0 Alpha 預覽版&lt;/a&gt;，希望透過全新的 API 讓更多人可以輕鬆地開發機器學習以及深度學習應用。&lt;/p&gt;
&lt;p&gt;當初撰寫本文的其中一個目的，也是想趁著這次大改版來讓自己熟悉一下 TensorFlow 2.0 的開發方式。&lt;/p&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube.com/embed/TTQQiJ-mHYA"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 值得關注的&lt;a href="https://youtu.be/YzLnnGiLNRE?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;更新&lt;/a&gt;不少，但以下幾點跟一般的 ML 開發者最為相關：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/guide/keras/overview"&gt;tf.keras&lt;/a&gt; 被視為官方高級 API，強調其地位&lt;/li&gt;
&lt;li&gt;方便除錯的 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb"&gt;Eager Execution&lt;/a&gt; 成為預設值&lt;/li&gt;
&lt;li&gt;負責讀取、處理大量數據的 &lt;a href="https://www.tensorflow.org/alpha/guide/data_performance"&gt;tf.data&lt;/a&gt; API&lt;/li&gt;
&lt;li&gt;自動幫你建構計算圖的 &lt;a href="https://youtu.be/Up9CvRLIIIw?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;tf.function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇文章裡頭會看到前 3 者。下節列出的程式碼皆在 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;Google Colab&lt;/a&gt; 上用最新版本的 TensorFlow 2.0 Nightly 執行。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install tf-nightly-gpu-2.0-preview
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果有 GPU 則強烈建議安裝 GPU 版本的 TF Nightly，訓練速度跟 CPU 版本可以差到 10 倍以上。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="深度學習專案步驟"&gt;深度學習專案步驟&lt;a class="anchor-link" href="#深度學習專案步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好戲終於登場。&lt;/p&gt;
&lt;p&gt;如同多數的深度學習專案，要訓練一個以 LSTM 為基礎的語言模型，你大致需要走過以下幾個步驟：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/deep-learning-pj-steps-menglee.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        開發一個 DL 專案時我常用的流程架構
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個流程是一個大方向，依據不同情境你可能需要做些調整來符合自己的需求，且很多步驟需要重複進行。&lt;/p&gt;
&lt;p&gt;這篇文章會用 TensorFlow 2.0 簡單地帶你走過所有步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="1.-定義問題及要解決的任務"&gt;1. 定義問題及要解決的任務&lt;a class="anchor-link" href="#1.-定義問題及要解決的任務"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，在訓練模型前首先得確認我們的問題（Problem）以及想要交給機器解決的任務（Task）是什麼。&lt;/p&gt;
&lt;p&gt;前面已經提過，我們的目標就是要找出一個天龍八部的語言模型（Language Model），讓該模型在被餵進一段文字以後，能吐出類似天龍八部的文章。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube.com/embed/f1KUUz7v8g4?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9"&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;center&gt;
    十分推薦李宏毅教授講解序列生成的影片
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這實際上是一個&lt;a href="https://youtu.be/f1KUUz7v8g4?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9"&gt;序列生成（Sequence Generation）&lt;/a&gt;問題，而機器所要解決的任務也變得明確：給定一段文字單位的序列，它要能吐出下一個合理的文字單位。&lt;/p&gt;
&lt;p&gt;這邊說的文字單位（Token）可以是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字（Character，如劍、寺、雲）&lt;/li&gt;
&lt;li&gt;詞（Word，如吐蕃、師弟、阿修羅）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文則使用「字」作為一個文字單位。現在假設有一個天龍八部的句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;『六脈神劍經』乃本寺鎮寺之寶，大理段氏武學的至高法要。
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這時候句子裡的每個字（含標點符號）都是一個文字單位，而整個句子就構成一個文字序列。我們可以擷取一部份句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;『六脈神劍經』乃本寺鎮寺之寶，大理段氏武
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著在訓練模型時要求它讀入這段文字，並預測出原文裡頭出現的下一個字：&lt;code&gt;學&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;一旦訓練完成，就能得到你開頭看到的那個語言模型了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="2.-準備原始數據、資料清理"&gt;2. 準備原始數據、資料清理&lt;a class="anchor-link" href="#2.-準備原始數據、資料清理"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;巧婦難為無米之炊，沒有數據一切免談。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/caroline-attwood-243834-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我在網路上蒐集天龍八部原文，做些簡單的數據清理後發現整本小說總共約含 120 萬個中文字，實在是一部曠世巨作。儘管因為版權問題不宜提供下載連結，你可以 Google 自己有興趣的文本。&lt;/p&gt;
&lt;p&gt;現在假設我們把原文全部存在一個 Python 字串 &lt;code&gt;text&lt;/code&gt; 裡頭，則部分內容可能如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 隨意取出第 9505 到 9702 的中文字&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9505&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;9702&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;咱們見敵方人多，不得師父號令，沒敢隨便動手。」左子穆道：「嗯，來了多少人？」干光豪道：「大約七八十人。」左子穆嘿嘿冷笑，道：「七八十人，便想誅滅無量劍了？只怕也沒這麼容易。」

龔光傑道：「他們用箭射過來一封信，封皮上寫得好生無禮。」說著將信呈上。

左子穆見信封上寫著：「字諭左子穆」五個大字，便不接信，說道：「你拆來瞧瞧。」龔光傑道：「是！」拆開信封，抽出信箋。

那少女在段譽耳邊低聲道：
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們也可以看看整本小說裡頭包含多少中文字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"天龍八部小說共有 &lt;/span&gt;&lt;span class="si"&gt;{n}&lt;/span&gt;&lt;span class="s2"&gt; 中文字"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"包含了 &lt;/span&gt;&lt;span class="si"&gt;{w}&lt;/span&gt;&lt;span class="s2"&gt; 個獨一無二的字"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;天龍八部小說共有 1235431 中文字
包含了 4330 個獨一無二的字
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;相較於英文只有 26 個簡單字母，博大精深的中文裡頭有非常多漢字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/raychan-1061280-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;裡頭說過的，要將文本數據丟入只懂數字的神經網路，我們得先做些前處理。&lt;/p&gt;
&lt;p&gt;具體來說，得將這些中文字對應到一個個的索引數字（Index）或是向量才行。&lt;/p&gt;
&lt;p&gt;我們可以使用 &lt;code&gt;tf.keras&lt;/code&gt; 裡頭的 &lt;code&gt;Tokenizer&lt;/code&gt; 幫我們把整篇小說建立字典，並將同樣的中文字對應到同樣的索引數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個以字為單位的 Tokenizer&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;char_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 讓 tokenizer 讀過天龍八部全文，&lt;/span&gt;
&lt;span class="c1"&gt;# 將每個新出現的字加入字典並將中文字轉&lt;/span&gt;
&lt;span class="c1"&gt;# 成對應的數字索引&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_on_texts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;text_as_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 隨機選取一個片段文本方便之後做說明&lt;/span&gt;
&lt;span class="n"&gt;s_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;21004&lt;/span&gt;
&lt;span class="n"&gt;e_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;21020&lt;/span&gt;
&lt;span class="n"&gt;partial_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;s_idx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;e_idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;partial_texts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;partial_indices&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 渲染結果，可忽略&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"原本的中文字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"轉換後的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;原本的中文字序列：

['司', '空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前', '。']

--------------------

轉換後的索引序列：

[557, 371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111, 2]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，現在整部天龍八部都已經被轉成一個巨大的數字序列，每一個數字代表著一個獨立的中文字。&lt;/p&gt;
&lt;p&gt;我們可以換個方向再看一次：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;人類看的中文字   機器看的輸入索引  
------------------------------
司                557
空                371
玄                215
雙                214
掌                135
飛                418
舞               1209
，                  1
逼                837
得                 25
牠               1751
無                 49
法                147
近                537
前                111
。                  2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="3.-建立能丟入模型的資料集"&gt;3. 建立能丟入模型的資料集&lt;a class="anchor-link" href="#3.-建立能丟入模型的資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;做完基本的數據前處理以後，我們需要將 &lt;code&gt;text_as_int&lt;/code&gt; 這個巨大的數字序列轉換成神經網路容易消化的格式與大小。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[1639, 148, 3, 3, 280, 5, 192, 819, 374, 800]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"text_as_int 是一個 &lt;/span&gt;&lt;span class="si"&gt;{_type}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"小說的序列長度： &lt;/span&gt;&lt;span class="si"&gt;{n}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"前 5 索引："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;text_as_int 是一個 &amp;lt;class 'list'&amp;gt;

小說的序列長度： 1235431

前 5 索引： [1639, 148, 3, 3, 280]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在建立資料集時，你要先能想像最終交給模型的數據長什麼樣子。這樣能幫助你對數據做適當的轉換。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照當前機器學習任務的性質，你會需要把不同格式的數據餵給模型。&lt;/p&gt;
&lt;p&gt;在本文的序列生成任務裡頭，理想的模型要能依據前文來判斷出下一個中文字。因此我們要丟給模型的是一串代表某些中文字的數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"實際丟給模型的數字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"方便我們理解的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;實際丟給模型的數字序列：
[557, 371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111]

方便我們理解的文本序列：
['司', '空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而模型要給我們的理想輸出應該是向左位移一個字的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"實際丟給模型的數字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"方便我們理解的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;實際丟給模型的數字序列：
[371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111, 2]

方便我們理解的文本序列：
['空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前', '。']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為什麼是這樣的配對？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/bruce-mars-559223-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們將輸入序列及輸出序列拿來對照看看：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;司 空 玄 雙 掌 飛 舞 ， 逼 得 牠 無 法 近

空 玄 雙 掌 飛 舞 ， 逼 得 牠 無 法 近 前
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;從左看到右你會發現，一個模型如果可以給我們這樣的輸出，代表它：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;看到第一個輸入字 &lt;code&gt;司&lt;/code&gt; 時可以正確輸出 &lt;code&gt;空&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司&lt;/code&gt;，且新輸入字為 &lt;code&gt;空&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;玄&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司空&lt;/code&gt;，且新輸入字為 &lt;code&gt;玄&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;雙&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司空玄雙掌飛&lt;/code&gt;，且新輸入字為 &lt;code&gt;舞&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;，&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當一個語言模型可以做到這樣的事情，就代表它已經掌握了&lt;strong&gt;訓練文本&lt;/strong&gt;（此文中為天龍八部）裡頭用字的統計結構，因此我們可以用它來產生新的天龍八部文章。&lt;/p&gt;
&lt;p&gt;你現在應該也可以了解，這個語言模型是專為天龍八部的文本所誕生的。畢竟日常生活中，給你 &lt;code&gt;舞&lt;/code&gt; 這個字，你接 &lt;code&gt;，&lt;/code&gt; 的機率有多少呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/niketh-vellanki-202943-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你加深印象，讓我把序列擺直，再次列出模型的輸入以及輸出關係：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;時間點 輸入字  輸入索引   輸出字  輸出索引  
-------------------------------------
   1    司     557      空      371
   2    空     371      玄      215
   3    玄     215      雙      214
   4    雙     214      掌      135
   5    掌     135      飛      418
   6    飛     418      舞      1209
   7    舞     1209     ，      1
   8    ，     1        逼      837
   9    逼     837      得      25
  10    得     25       牠      1751
  11    牠     1751     無      49
  12    無     49       法      147
  13    法     147      近      537
  14    近     537      前      111
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;每一列（row）是一個時間點，而&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;輸入索引&lt;/strong&gt;代表模型在當下時間吃進去的輸入&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;輸出索引&lt;/strong&gt;則代表我們要模型輸出的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;輸入字・輸出字則只是方便我們理解對照，實際上模型只吃數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/pop-zebra-754186-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在我們了解一筆輸入・輸出該有的數據格式了。兩者皆是一個固定長度的數字序列，而後者是前者往左位移一個數字的結果。&lt;/p&gt;
&lt;p&gt;但這只是一筆數據（以下說的一筆數據，都隱含了輸入序列以及對應的輸出序列的 2 個數字序列）。&lt;/p&gt;
&lt;p&gt;在有 GPU 的情況下，我們常常會一次丟一批（batch）數據，讓 GPU 可以平行運算，加快訓練速度。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/gpu.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在假設我們想要一個資料集，而此資料集可以一次給我們 128 筆長度為 10 的輸入・輸出序列，則我們可以用 &lt;code&gt;tf.data&lt;/code&gt; 這樣做：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 方便說明，實際上我們會用更大的值來&lt;/span&gt;
&lt;span class="c1"&gt;# 讓模型從更長的序列預測下個中文字&lt;/span&gt;
&lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;  &lt;span class="c1"&gt;# 數字序列長度&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt; &lt;span class="c1"&gt;# 幾筆成對輸入/輸出&lt;/span&gt;

&lt;span class="c1"&gt;# text_as_int 是一個 python list&lt;/span&gt;
&lt;span class="c1"&gt;# 我們利用 from_tensor_slices 將其&lt;/span&gt;
&lt;span class="c1"&gt;# 轉變成 TensorFlow 最愛的 Tensor &amp;lt;3&lt;/span&gt;
&lt;span class="n"&gt;characters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_tensor_slices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將被以數字序列表示的天龍八部文本&lt;/span&gt;
&lt;span class="c1"&gt;# 拆成多個長度為 SEQ_LENGTH (10) 的序列&lt;/span&gt;
&lt;span class="c1"&gt;# 並將最後長度不滿 SEQ_LENGTH 的序列捨去&lt;/span&gt;
&lt;span class="n"&gt;sequences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;characters&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;drop_remainder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 天龍八部全文所包含的成對輸入/輸出的數量&lt;/span&gt;
&lt;span class="n"&gt;steps_per_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt;

&lt;span class="c1"&gt;# 這個函式專門負責把一個序列&lt;/span&gt;
&lt;span class="c1"&gt;# 拆成兩個序列，分別代表輸入與輸出&lt;/span&gt;
&lt;span class="c1"&gt;# （下段有 vis 解釋這在做什麼）&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_seq_pairs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;input_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;target_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;input_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_text&lt;/span&gt;

&lt;span class="c1"&gt;# 將每個從文本擷取出來的序列套用上面&lt;/span&gt;
&lt;span class="c1"&gt;# 定義的函式，拆成兩個數字序列&lt;/span&gt;
&lt;span class="c1"&gt;# 作為輸入／輸出序列&lt;/span&gt;
&lt;span class="c1"&gt;# 再將得到的所有數據隨機打亂順序&lt;/span&gt;
&lt;span class="c1"&gt;# 最後再一次拿出 BATCH_SIZE（128）筆數據&lt;/span&gt;
&lt;span class="c1"&gt;# 作為模型一次訓練步驟的所使用的資料&lt;/span&gt;
&lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequences&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_seq_pairs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;drop_remainder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這段建構 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 的程式碼雖然不短，但有超過一半是我寫給你的註解。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上用 &lt;code&gt;tf.data&lt;/code&gt; 架構一個資料集並不難，且學會以後你每次都可用類似的方式呼叫 &lt;a href="https://www.tensorflow.org/guide/datasets"&gt;TensorFlow Data API&lt;/a&gt; 來處理&lt;strong&gt;任何&lt;/strong&gt;文本數據，而不需要每次遇到新文本都從頭開始寫類似的功能（&lt;code&gt;batch&lt;/code&gt;、&lt;code&gt;shuffle&lt;/code&gt; etc）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/avi-richards-183715-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再次提醒，如果你想自己動手可以參考&lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;官方用 TensorFlow 2.0 訓練 LSTM 的 Colab 筆記本&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;雖然我不是酷拉皮卡，但如果要把上面 &lt;code&gt;build_seq_pairs&lt;/code&gt; 的處理具現化的話，大概就像是下面這樣（假設序列長度為 6）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;擷取的片段序列       輸入/輸出序列
-------------------------------
                 -&amp;gt; 烏老大拱手還
                 |
烏老大拱手還禮 -----
                 |
                 -&amp;gt; 老大拱手還禮


                 -&amp;gt; 星宿派人數遠
                 |
星宿派人數遠較 -----
                 |
                 -&amp;gt; 宿派人數遠較


                 -&amp;gt; 過不多時，賈
                 |
過不多時，賈老 -----
                 |
                 -&amp;gt; 不多時，賈老
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現針對序列長度 &lt;code&gt;SEQ_LENGTH&lt;/code&gt; 為 6 的情況，我會刻意將天龍八部文本切成長度為 &lt;code&gt;SEQ_LENGTH + 1&lt;/code&gt;：7 的句子，再從這些句子建立出輸入及輸出序列。&lt;/p&gt;
&lt;p&gt;到此為止，我們已經用 &lt;code&gt;tf.data&lt;/code&gt; 建立出一個可以拿來訓練語言模型的資料集了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mika-baumeister-703680-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 預設就是 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb"&gt;Eager Execution&lt;/a&gt;，因此你不再需要使用老朋友 &lt;code&gt;tf.Session()&lt;/code&gt; 或是 &lt;code&gt;tf.placeholder&lt;/code&gt; 就能非常直覺地存取數據：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# print 是用來幫你理解 tf.data.Dataset&lt;/span&gt;
&lt;span class="c1"&gt;# 的內容，實際上存取資料集非常簡單&lt;/span&gt;
&lt;span class="c1"&gt;# 現在先關注下面的 print 結果&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"起始句子的 batch："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"目標句子的 batch："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個起始句子的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個目標句子的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個起始句子的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;first_i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個目標句子的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;first_t&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;起始句子的 batch：
tf.Tensor(
[[1440   10   12 ... 1882   15  175]
 [ 157   16  212 ...   11  206   92]
 [  36   14   36 ...  368  384   63]
 ...
 [  61    8    3 ...   11    5  219]
 [ 123  189  587 ...   65  120   51]
 [   1    5  620 ...    2    8 1272]], shape=(128, 10), dtype=int32) 

目標句子的 batch：
tf.Tensor(
[[  10   12    7 ...   15  175   99]
 [  16  212   67 ...  206   92    1]
 [  14   36   36 ...  384   63    2]
 ...
 [   8    3    3 ...    5  219    1]
 [ 189  587  884 ...  120   51  196]
 [   5  620  597 ...    8 1272 1275]], shape=(128, 10), dtype=int32) 

-------------------- 

第一個起始句子的索引序列：
[1440   10   12    7   63   19   17 1882   15  175] 

第一個目標句子的索引序列：
[  10   12    7   63   19   17 1882   15  175   99] 

-------------------- 

第一個起始句子的文本序列：
['陵', '道', '：', '「', '想', '來', '他', '嫌', '你', '本']

第一個目標句子的文本序列：
['道', '：', '「', '想', '來', '他', '嫌', '你', '本', '事']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你理解資料集回傳的內容，上面用了不少 &lt;code&gt;print&lt;/code&gt;。但事實上這個資料集 &lt;code&gt;ds&lt;/code&gt; 負責的就是每次吐出 2 個 128 筆數據的 Tensor，分別代表輸入與輸出的批次數據（Batch）。&lt;/p&gt;
&lt;p&gt;而每筆數據則包含了一個長度為 10 的數字序列，代表著天龍八部裡頭的一段文本。&lt;/p&gt;
&lt;p&gt;減少一些 &lt;code&gt;print&lt;/code&gt;，你要從資料集 &lt;code&gt;ds&lt;/code&gt; 取得一個 batch 的輸入／輸出非常地簡單：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 蒙多想去哪就去哪&lt;/span&gt;
    &lt;span class="c1"&gt;# 想怎麼存取 b_iup, b_tar 都可以&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"b_inp 是個 Tensor：&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;b_tar 也是個 Tensor，"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"只是每個數字序列都是"&lt;/span&gt;
          &lt;span class="s2"&gt;"對應的輸入序列往左位"&lt;/span&gt;
          &lt;span class="s2"&gt;"移一格的結果&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;b_inp 是個 Tensor：

tf.Tensor(
[[   2  953 1214 ...    1   52  219]
 [   6    2   15 ...   36  189    5]
 [2456 1167 3142 ...  110 1186   56]
 ...
 [ 422  244   19 ...    2    8   46]
 [ 254   51  237 ...  123   64   27]
 [1561   25   55 ...   66    2    3]], shape=(128, 10), dtype=int32)

b_tar 也是個 Tensor，
只是每個數字序列都是對應的輸入序列往左位移一格的結果

tf.Tensor(
[[ 953 1214   41 ...   52  219   52]
 [   2   15  189 ...  189    5  189]
 [1167 3142 1294 ... 1186   56    5]
 ...
 [ 244   19  145 ...    8   46   41]
 [  51  237  202 ...   64   27  569]
 [  25   55    9 ...    2    3    3]], shape=(128, 10), dtype=int32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="4.-定義能解決問題的函式集"&gt;4. 定義能解決問題的函式集&lt;a class="anchor-link" href="#4.-定義能解決問題的函式集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;呼！我們花了不少時間在建構資料集，是時候捲起袖子將這些資料丟入模型了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/How_to_Roll_Up_Sleeves_01.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回想資料集內容，你現在應該已經很清楚我們想要模型解決的問題是什麼了：丟入一個數字序列，模型要能產生包含下個時間點的數字序列，最好是跟當初的&lt;strong&gt;輸出&lt;/strong&gt;序列一模一樣！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在 &lt;a href="https://demo.leemeng.tw/"&gt;AI 如何找出你的喵&lt;/a&gt;裡頭說過的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        任何類型的神經網路本質上都是一個映射函數。它們會在內部進行一連串特定的數據轉換步驟，想辦法將給定的輸入數據轉換成指定的輸出形式。 
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們現在要做的就是定義一個神經網路架構，讓這個神經網路（或稱函式）幫我們把輸入的數字序列轉換成對應的輸出序列。&lt;/p&gt;
&lt;p&gt;我們期待這個模型具有「記憶」，能考慮以前看過的所有歷史資訊，進而產生最有可能的下個中文字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        循環神經網路非常適合處理具有順序關係的數據
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;自然語言處理與深度學習入門指南&lt;/a&gt;我們也已經看到，循環神經網路中的 LSTM 模型非常適合拿來做這件事情。&lt;/p&gt;
&lt;p&gt;因此雖然理論上你可以用任意架構的神經網路（如基本的前饋神經網路）來解決這個問題，使用 LSTM（或 GRU，甚至是 1D CNN）是一個相對安全的起手式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/playing-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用 Keras 開發深度學習模型
                        （&lt;a href="https://youtu.be/Lx3l4lOrquw?t=277" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 TensorFlow 裡頭，使用 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"&gt;Keras API&lt;/a&gt; 建立一個神經網路就像是在疊疊樂，一層一層蓋上去：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;

&lt;span class="c1"&gt;# 使用 keras 建立一個非常簡單的 LSTM 模型&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="c1"&gt;# 將每個索引數字對應到一個高維空間的向量&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;output_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;batch_input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="c1"&gt;# 負責將序列數據依序讀入並做處理&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;return_sequences&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;stateful&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;recurrent_initializer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'glorot_uniform'&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層&lt;/span&gt;
&lt;span class="c1"&gt;# 負責 model 每個中文字出現的可能性&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/model_summary.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們建立了一個由&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/word_embeddings"&gt;詞嵌入層&lt;/a&gt;、LSTM 層以及全連接層組成的簡單 LSTM 模型。此模型一次吃 128 筆長度任意的數字序列，在內部做些轉換，再吐出 128 筆同樣長度，4330 維的 Tensor。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/yifeng-lu-1230629-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你還記得，4330 實際上是天龍八部裡頭所有出現過的中文字數目。&lt;/p&gt;
&lt;p&gt;&lt;div id="supervised" style="display: inline"&gt;因此&lt;/div&gt;事實上我們已經把本來看似沒有正解的生成問題轉變成一個&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式&lt;/a&gt;且有 4330 個&lt;a href="https://en.wikipedia.org/wiki/Statistical_classification"&gt;分類的問題&lt;/a&gt;了。我們希望訓練模型，使得其每次預測出來的字都跟正確解答（即輸出序列裡的字）一樣。&lt;/p&gt;
&lt;p&gt;值得一提的是，儘管這個神經網路（或稱映射函數）看起來非常有希望能解決我們的序列生成問題，我們並不僅僅是建立了 1 個映射函數而已。事實上，我們用 &lt;code&gt;tf.keras&lt;/code&gt; 定義了一個有接近 1,300 萬參數的函式&lt;strong&gt;集合&lt;/strong&gt;（Function set）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/antoine-dautry-428776-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這跟你懷疑一個資料集的特徵 &lt;code&gt;x&lt;/code&gt; 跟目標值 &lt;code&gt;y&lt;/code&gt; 成線性關係，然後想用 &lt;code&gt;a * x + b = y&lt;/code&gt; 的直線去 fit &lt;code&gt;y&lt;/code&gt; 的道理是一樣的。&lt;/p&gt;
&lt;p&gt;你相信 &lt;code&gt;a * x + b = y&lt;/code&gt; 形式的映射函數能幫你把輸入 &lt;code&gt;x&lt;/code&gt; 有效地對應到目標 &lt;code&gt;y&lt;/code&gt;，你只是還不知道最佳的參數組合 &lt;code&gt;(a, b)&lt;/code&gt; 該設多少罷了。&lt;/p&gt;
&lt;p&gt;同理，很多研究結果顯示 LSTM 模型能很好地處理序列數據，我們只是還不知道最適合生成天龍八部文章的參數組合是什麼而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/backpropagation-example.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        深度學習中我們常使用梯度下降與反向傳播來從函數集合中找出最好的函數（某個特定參數組合的神經網路架構）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;參數 &lt;code&gt;a&lt;/code&gt; 以及 &lt;code&gt;b&lt;/code&gt; 有無限多種組合，而每一組 &lt;code&gt;a&lt;/code&gt; 與 &lt;code&gt;b&lt;/code&gt; 的組合都對應到一個實際的&lt;strong&gt;函數&lt;/strong&gt;。每個函數都能幫你把 &lt;code&gt;x&lt;/code&gt; 乘上 &lt;code&gt;a&lt;/code&gt; 倍再加上 &lt;code&gt;b&lt;/code&gt; 去 fit 目標值 &lt;code&gt;y&lt;/code&gt;，只是每個函數的表現不一而已。而把所有可能的函數放在一起，就是所謂的函數集合。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/jeremy-thomas-99326-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文的 LSTM 模型架構因為參數組合無窮無盡，本身就像是一個巨大的函數空間。而我們得從裡頭找出能解決問題的特定函數（參數組合）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對 &lt;code&gt;a * x + b = y&lt;/code&gt; 這個簡單例子，我們可以直接用線性代數從整個函式集合裡頭瞬間找出最佳的函數 &lt;code&gt;f&lt;/code&gt;（即最佳的 &lt;code&gt;(a, b)&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;而在深度學習領域裡頭，我們會透過&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"&gt;梯度下降（Gradient Descent）&lt;/a&gt;以及&lt;a href="https://www.youtube.com/watch?v=ibJpTrp5mcE"&gt;反向傳播算法（Backpropagation）&lt;/a&gt;來幫我們在浩瀚無垠的函式集合（如本文中的 LSTM 網路架構）裡頭找出一個好的神經網路（某個 1,300 萬個參數的組合）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/deep-learning-framework.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        深度學習框架
                        （&lt;a href="https://agi.io/2018/02/09/survey-machine-learning-frameworks/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;幸好我們後面會看到，像是 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;、&lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 等深度學習框架幫我們把這件事情變得簡單多了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="5.-定義評量函式好壞的指標"&gt;5. 定義評量函式好壞的指標&lt;a class="anchor-link" href="#5.-定義評量函式好壞的指標"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;有了&lt;a href="#建立能丟入模型的資料集"&gt;資料集&lt;/a&gt;以及 &lt;a href="#定義能解決問題的函式集"&gt;LSTM 模型架構&lt;/a&gt;以後，我們得定義一個&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%B1%BA%E5%AE%9A%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8F%BE"&gt;損失函數（Loss Function）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在監督式學習裡頭，一個損失函數評估某個模型產生出來的預測結果 &lt;code&gt;y_pred&lt;/code&gt; 跟正確解答 &lt;code&gt;y&lt;/code&gt; 之間的差距。一個好的函式／模型，要能最小化損失函數。&lt;/p&gt;
&lt;p&gt;有了損失函數以後，我們就能讓模型計算當前預測結果與正解之間的差異（Loss），據此調整模型內的參數以降低這個差異。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/robot_thinking.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        機器學習模型或 AI 不會幫我們定義損失函數，因為只有我們能決定什麼是對的，什麼是錯的（至少在 2019 年是這樣）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照不同情境、不同機器學習任務你會需要定義不同的損失函數。&lt;/p&gt;
&lt;p&gt;如同&lt;a href="#supervised"&gt;前述&lt;/a&gt;，其實我們要 LSTM 模型做的是一個分類問題（Classification Problem）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        給定之前看過的文字序列以及當下時間點的新輸入字，從 4330 個字裡頭預測下一個出現的字。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此本文的問題可以被視為一個有 4330 個分類（字）的問題。而要定義分類問題的損失相對簡單，使用 &lt;a href="https://keras.io/zh/losses/#sparse_categorical_crossentropy"&gt;sparse_categorical_crossentropy&lt;/a&gt; 是個不錯的選擇：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數，決定模型一次要更新的步伐有多大&lt;/span&gt;
&lt;span class="n"&gt;LEARNING_RATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt;

&lt;span class="c1"&gt;# 定義模型預測結果跟正確解答之間的差異&lt;/span&gt;
&lt;span class="c1"&gt;# 因為全連接層沒使用 activation func&lt;/span&gt;
&lt;span class="c1"&gt;# from_logits= True &lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;from_logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 編譯模型，使用 Adam Optimizer 來最小化&lt;/span&gt;
&lt;span class="c1"&gt;# 剛剛定義的損失函數&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;\
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LEARNING_RATE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;model.compile&lt;/code&gt; 讓我們告訴模型在訓練的時候該使用什麼&lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers"&gt;優化器（optimizers）&lt;/a&gt;來最小化剛剛定義的&lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses"&gt;損失函數&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;完成這個步驟以後，我們就能開始訓練模型了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="6.-訓練並選擇出最好的函式"&gt;6. 訓練並選擇出最好的函式&lt;a class="anchor-link" href="#6.-訓練並選擇出最好的函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在完成前 5 個步驟以後，訓練一個 Keras 模型本身是一件非常簡單的事情，只需要呼叫 &lt;code&gt;model.fit&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="c1"&gt;# 決定看幾篇天龍八部文本&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;# 前面使用 tf.data 建構的資料集&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/fit-logging.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Keras 模型在訓練時就會不斷吐出結果供你參考
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很多時候你需要跑很多次 &lt;code&gt;fit&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;一般來說，你事先並不知道要訓練多少個 epochs 模型才會收斂，當然也不知道怎麼樣的超參數會表現最好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/diz-play-31367-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;大多時候，你會想要不斷地驗證腦中的點子、調整超參數、訓練新模型，並再次依照實驗結果嘗試新點子。&lt;/p&gt;
&lt;p&gt;這時候 TensorFlow 的視覺化工具 &lt;a href="https://www.tensorflow.org/tensorboard"&gt;TensorBoard&lt;/a&gt; 就是你最好的朋友之一：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tensorboard.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 TensorBoard 記錄下實驗結果，方便記錄自己做了什麼實驗，什麼 work 什麼不 work
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 新增了 &lt;a href="https://github.com/tensorflow/tensorboard/blob/master/docs/r2/tensorboard_in_notebooks.ipynb"&gt;JupyterNotebook 的 Extension&lt;/a&gt;，讓你可以直接在筆記本或是 &lt;a href="https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/r2/tensorboard_in_notebooks.ipynb"&gt;Google Colab&lt;/a&gt; 上邊訓練模型邊查看結果。&lt;/p&gt;
&lt;p&gt;跟以往使用 TensorBoard 一樣，你需要為 Keras 模型增加一個 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TensorBoard"&gt;TensorBoard Callback&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt;\
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TensorBoard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"logs"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="c1"&gt;# 你可以加入其他 callbacks 如&lt;/span&gt;
    &lt;span class="c1"&gt;# ModelCheckpoint,&lt;/span&gt;
    &lt;span class="c1"&gt;# EarlyStopping&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;callbacks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著在訓練開始之後（之前也行）載入 Extension 並執行 TensorBoard 即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;load_ext&lt;/span&gt; tensorboard.notebook
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;tensorboard&lt;/span&gt; --logdir logs
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tensorboard-demo2.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了確保模型有一直努力在降低損失函數以外，我們也可以觀察模型在訓練過程中生成的文章內容。比方說給定一個句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;模型在完全沒有訓練的情況下生成的結果為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，鑠淆孤癸抑私磚簧麥笠簸殯膽稼匿聲罪殖省膻臆啟殖
》斥酒燥弄咪薔鬃衝矚理蝗驗吞柢舌滴漂撿毛等櫈磁槃鞭爛辣諱輝母犢楊拜攜戛婉額虐延久鋒幟懸質迸飭南軌忸瑩娘檔麵獎逍菌包怖續敗倨凍赭彈暖顴衽劑街榻裝貨啕畿驛吳
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/black-man-question.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這模型並沒有中邪。只不過模型中 1,300 萬個參數的值完全隨機，你可不能期待模型能做什麼有意義的數據處理。&lt;/p&gt;
&lt;p&gt;而在模型看了 20 遍天龍八部以後產生的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，說道：「我不知道，不是你的好人，你就是你的好。」木婉清道：「他&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;師父是誰？」

段正淳道：「王姑娘，你還是不是？」段譽道：「你說過的話，他&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;」

那女郎道：「嗯
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;結果差強人意，「你我他」後面只會加一大堆點點點。&lt;/p&gt;
&lt;p&gt;但如果你仔細觀察，其實也已經有不少值得注意的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型已經知道怎麼產生正確的人名&lt;/li&gt;
&lt;li&gt;知道 &lt;code&gt;道&lt;/code&gt; 後面要接冒號以及上括號&lt;/li&gt;
&lt;li&gt;知道有上括號時後面應該要有下括號&lt;/li&gt;
&lt;li&gt;知道要適時加入換行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這其實已經是不小的成就了！&lt;/p&gt;
&lt;p&gt;而在看過 100 遍天龍八部以後產生的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，往前走去。

段譽見到這等慘狀，心下大驚，當即伸手去撫摸她的頭髮，心想：「我想叫你滾出去！」一面說，一面擤了些鼻涕拋下。

那大漢掙扎著要站起身來，只見一條大漢身披獸皮，眼前青光閃閃，雙手亂舞
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;擤了些鼻涕拋下&lt;/code&gt; 很不段譽，但我還是笑了。&lt;/p&gt;
&lt;p&gt;文章本身順暢很多，而且內容也豐富不少。另外用字也挺天龍八部的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/theodor-lundqvist-438530-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你應該也已經注意到，句子之間沒有太大的故事關聯性。而這邊帶出一個很重要的概念：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        這個語言模型只能學會天龍八部裡頭字與字之間的統計關係，而無法理解金庸的世界觀。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此不要期待模型每次都能產生什麼深具含義的結果。&lt;/p&gt;
&lt;p&gt;儘管還不完美，到此為止我們手上已經有訓練過的模型了。讓我們拿它來產生新的文本了吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="7.-將函式-/-模型拿來做預測"&gt;7. 將函式 / 模型拿來做預測&lt;a class="anchor-link" href="#7.-將函式-/-模型拿來做預測"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;大部分你在深度學習專案裡頭訓練出來的模型可以直接拿來做預測。&lt;/p&gt;
&lt;p&gt;不過因為循環神經網路傳遞狀態的方式，一旦建好模型，&lt;code&gt;BATCH_SIZE&lt;/code&gt; 就不能做變動了。但在實際生成文章時，我們需要讓 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 等於 1。&lt;/p&gt;
&lt;p&gt;因此在這邊我們會重新建立一個一模一樣的 LSTM 模型架構，將其 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 設為 1 後讀取之前訓練時儲存的參數權重：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 跟訓練時一樣的超參數，&lt;/span&gt;
&lt;span class="c1"&gt;# 只差在 BATCH_SIZE 為 1&lt;/span&gt;
&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# 專門用來做生成的模型&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;output_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;batch_input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;return_sequences&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;stateful&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 讀入之前訓練時儲存下來的權重&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TensorShape&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation#restore_the_latest_checkpoint"&gt;讀取權重&lt;/a&gt;，這段程式碼對你來說應該已經十分眼熟。有了 &lt;code&gt;infer_model&lt;/code&gt; 以後，接著我們要做的就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將起始文本丟入模型&lt;/li&gt;
&lt;li&gt;抽樣得到新的中文字&lt;/li&gt;
&lt;li&gt;將新得到的字再丟入模型&lt;/li&gt;
&lt;li&gt;重複上述步驟&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而實際預測的流程大概就長這個樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/sampling.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        重複抽樣取得新的中文字
                        （&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation#the_prediction_loop" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="#生成新的天龍八部橋段"&gt;生成新的天龍八部橋段&lt;/a&gt;所看到的，依照你設定的&lt;strong&gt;生成長度&lt;/strong&gt;，我們需要重複上述步驟數次。&lt;/p&gt;
&lt;p&gt;而要執行一次的抽樣也並沒有非常困難：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 代表「喬」的索引&lt;/span&gt;
&lt;span class="n"&gt;seed_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;234&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 

&lt;span class="c1"&gt;# 增加 batch 維度丟入模型取得預測結果後&lt;/span&gt;
&lt;span class="c1"&gt;# 再度降維，拿掉 batch 維度&lt;/span&gt;
&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;seed_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 利用生成溫度影響抽樣結果&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="n"&gt;temperature&lt;/span&gt;

&lt;span class="c1"&gt;# 從 4330 個分類值中做抽樣&lt;/span&gt;
&lt;span class="c1"&gt;# 取得這個時間點模型生成的中文字&lt;/span&gt;
&lt;span class="n"&gt;sampled_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;抽樣的程式碼為了方便解說有稍作刪減，如果你要實際動手跑看看，請參考官方的 &lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;Text generation with an RNN&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;這邊我想要你看到的重點是如何利用&lt;strong&gt;生成溫度&lt;/strong&gt; &lt;code&gt;temperature&lt;/code&gt; 的概念來影響最後的抽樣結果。&lt;/p&gt;
&lt;p&gt;如同 demo 時說明的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        生成溫度是一個實數值，而當溫度越高，模型產生出來的結果越隨機、越不可預測
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;模型的輸出為一個 4330 維度的 Tensor，而其中的每一維都對應到一個中文字。維度值越大即代表該字被選到的機會越大。&lt;/p&gt;
&lt;p&gt;而當我們把整個分佈 &lt;code&gt;predictions&lt;/code&gt;除以一個固定值 &lt;code&gt;temperature&lt;/code&gt; 時，越大的值被縮減的程度越大，進而讓各維度之間的絕對差異變小，使得原來容易被選到的字被抽到的機會變小，少出現的字被選到的機會稍微提升。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/temperature_dist.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        溫度越高，分佈會變得越平滑，罕見字被選到的機會上升，生成結果越隨機
                        （&lt;a href="https://www.manning.com/books/deep-learning-with-python" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是為何我們會想手動調整生成溫度的原因。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何使用-TensorFlow.js-跑模型並生成文章_1"&gt;如何使用 TensorFlow.js 跑模型並生成文章&lt;a class="anchor-link" href="#如何使用-TensorFlow.js-跑模型並生成文章"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;雖然本文以天龍八部為例，事實上你已經了解如何使用 TensorFlow 2.0 來架構出一個能產生任意文本的 LSTM 模型了。&lt;/p&gt;
&lt;p&gt;一般而言，只要你把剛剛生成文本的 Keras 模型儲存下來，接著就可以在任何機器或雲端平台（如 GCP、AWS）上進行生成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"model.h5"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最近適逢 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt; 推出 &lt;a href="https://github.com/tensorflow/tfjs/releases/tag/v1.0.0"&gt;1.0.0 版本&lt;/a&gt;，我決定嘗試使用 &lt;a href="https://github.com/tensorflow/tfjs-converter"&gt;tfjs-converter&lt;/a&gt; 將 Keras 模型轉換成 TensorFlow.js 能夠運行的格式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensorflowjs_converter &lt;span class="se"&gt;\&lt;/span&gt;
    --input_format&lt;span class="o"&gt;=&lt;/span&gt;keras &lt;span class="se"&gt;\&lt;/span&gt;
    model.h5 &lt;span class="se"&gt;\&lt;/span&gt;
    tfjs_model_folder
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;轉換完成後會得到 tfjs 的模型，接著只要把它放到伺服器或是 Github 上就能在任何靜態網頁上載入模型：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nx"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;loadLayersModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"url"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kr"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;input&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在&lt;a href="https://leemeng.tw/deep-learning-resources.html#tensorflow.js"&gt;由淺入深的深度學習資源整理&lt;/a&gt;就曾介紹過 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;，他們有很多有趣的 &lt;a href="https://www.tensorflow.org/js/demos/"&gt;Demos&lt;/a&gt;，想要在瀏覽器上實作 AI 應用的你可以去了解一下。&lt;/p&gt;
&lt;p&gt;使用 TensorFlow.js 好處在於：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隱私有保障。使用者上傳、輸入的內容不會被上傳到伺服器&lt;/li&gt;
&lt;li&gt;開發者不需租借伺服器或是建置 API 端點，無部署成本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當你能把模型讀入瀏覽器以後，只要將我們剛剛在前面介紹過的 Python 邏輯利用 &lt;a href="https://js.tensorflow.org/api/latest/"&gt;TensorFlow.js API&lt;/a&gt; 實現即可。&lt;/p&gt;
&lt;p&gt;熟悉 JavaScript 的你甚至還可以&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;直接在瀏覽器上訓練類似本文的 LSTM 模型並生成文章&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;感謝你花費那麼多時間閱讀本文！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/matt-jones-42954-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回顧一下，我們在文中談了非常多的東西：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何利用深度學習 7 步驟開發 AI 應用&lt;ol&gt;
&lt;li&gt;定義問題及要解決的任務&lt;/li&gt;
&lt;li&gt;準備原始數據、資料清理&lt;/li&gt;
&lt;li&gt;建立能丟入模型的資料集&lt;/li&gt;
&lt;li&gt;定義能解決問題的函式集&lt;/li&gt;
&lt;li&gt;定義評量函式好壞的指標&lt;/li&gt;
&lt;li&gt;訓練並選擇出最好的函式&lt;/li&gt;
&lt;li&gt;將函式 / 模型拿來做預測&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;了解如何利用深度學習解決序列生成任務&lt;/li&gt;
&lt;li&gt;熟悉 TensorFlow 2.0 的重要功能&lt;ul&gt;
&lt;li&gt;tf.keras&lt;/li&gt;
&lt;li&gt;tf.data&lt;/li&gt;
&lt;li&gt;TensorBoard&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們也看到你可以如何運用 &lt;a href="https://github.com/tensorflow/tfjs-converter"&gt;tfjs-converter&lt;/a&gt; 將 Python 與 JavaScript 這兩個世界結合起來，建立可以給任何人在任何裝置上執行的 AI 應用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/robin-worrall-749755-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了可以被用來解決「被動」的分類、迴歸問題，近年深度學習在「主動」的&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"&gt;生成任務&lt;/a&gt;上也展現了卓越的成果。&lt;/p&gt;
&lt;p&gt;廣為人知的應用有 Google 的 &lt;a href="https://en.wikipedia.org/wiki/DeepDream"&gt;DeepDream&lt;/a&gt;、神經風格轉換以及最近 &lt;a href="https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/"&gt;NVIDIA 將塗鴉轉成風景照&lt;/a&gt;的例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/nvidia_gaugan_gif.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        將塗鴉轉成風景照的 GauGAN 能讓沒有美術背景的人繪出美麗圖片，也能幫助藝術家更快將點子實現出來
                        （&lt;a href="https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就像本文的天龍八部生成，儘管還未臻完美，讓機器自動生成全新、沒人看過的事物一直是人類追求的夢想之一。&lt;/p&gt;
&lt;p&gt;但這些人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence）的研究並不是一味地追求如何&lt;strong&gt;取代&lt;/strong&gt;人類智慧；反之，AI 更像是&lt;strong&gt;增強&lt;/strong&gt;我們的智慧（&lt;strong&gt;A&lt;/strong&gt;ugmented &lt;strong&gt;I&lt;/strong&gt;ntelligence）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        最好的 AI 是為了讓我們的生活充滿更多智慧，而非取代我們的智慧。AI 能擴充我們對世界的想像，讓我們看到更多不同的可能性。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文已經很長，我就不再佔用你的時間了。&lt;/p&gt;
&lt;p&gt;能一路聽我碎碎唸到這裡，代表你對 AI 以及深度學習的應用是抱持著很大的興趣的。希望在此之後你能運用本文學到的知識與技術，實踐你的瘋狂點子並分享給我以及更多人知道。&lt;/p&gt;
&lt;p&gt;現在我得回去看還沒看完的天龍八部了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="致敬"&gt;致敬&lt;a class="anchor-link" href="#致敬"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;僅用這篇微不足道的文章向&lt;a href="https://zh.wikipedia.org/wiki/%E9%87%91%E5%BA%B8"&gt;金庸&lt;/a&gt;致敬，感謝他帶給我們那麼多膾炙人口的故事。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/lstm-text-generation/dist/lstm-text-generation.03657dc5.js"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="TensorFlow"></category><category term="TensorFlow.js"></category><category term="自然語言處理"></category></entry><entry><title>我從 AI For Everyone 學到的 10 個重要 AI 概念</title><link href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html" rel="alternate"></link><published>2019-03-05T08:00:00+09:00</published><updated>2019-03-05T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-03-05:/10-key-takeaways-from-ai-for-everyone-course.html</id><summary type="html">&lt;p&gt;AI For Everyone 是由吳恩達教授開授的一堂線上課程，這篇文章則記錄了我個人在修習完這堂線上課程後整理出的 10 個最重要 AI 概念。除了將這些概念條列出來以外，本文也將逐一介紹每個概念所代表的涵意，幫助讀者快速掌握該課程裡頭的重要 AI 概念，並開始自己的 AI 之旅。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在這個人機共存的年代，每個人都應該去嘗試瞭解並運用人工智慧這個超能力。思考自己未來在這個變化快速的世界的定位。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;曾經領導 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授這幾天公開了新的 &lt;a href="https://www.coursera.org/"&gt;Coursera&lt;/a&gt; 課程：&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;。這堂課不談技術術語，專注在與非技術人士以及企業經理人說明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;何謂 AI&lt;/li&gt;
&lt;li&gt;如何建立 AI 專案&lt;/li&gt;
&lt;li&gt;如何在企業內部建立 AI 基礎&lt;/li&gt;
&lt;li&gt;AI 與社會的關係&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;課程內容精要，總結了不少他多年在 Google Brain、百度裡領導 AI 團隊所累積的寶貴經驗。這堂課也提到了不少 &lt;a href="https://landing.ai/ai-transformation-playbook/"&gt;AI Transformation Playbook&lt;/a&gt; 裡頭的內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/course.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Coursera 上的 AI For Everyone
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然課程中很多時候是以 CEO 或是企業管理者的角度說明 AI 概念，但我認為每個人都可以用&lt;strong&gt;個人&lt;/strong&gt;角度，從本課學到不少有用的建議以及思考框架。有了這些概念，可以幫助我們在這個變化快速的 AI 潮流中掌握好自己手上的船舵並順利航行。&lt;/p&gt;
&lt;p&gt;本文將列舉出我認為本課中最值得記住的 10 個 AI 概念，希望能讓你馬上學到些東西。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/kaleidico-754605-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，這篇不少概念是我自己的心得總結，而你在上完課後肯定會有其他重要見解。事實上，我會推薦你在閱讀本文後就找時間實際去上這堂課，或是透過&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;其他方式&lt;/a&gt;進一步了解 AI。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="30-秒-AI-大局觀"&gt;30 秒 AI 大局觀&lt;a class="anchor-link" href="#30-秒-AI-大局觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以下就是 10 個我認為 AI For Everyone 這堂課傳達的重要概念懶人包。如果你一秒鐘幾十萬上下，可以只看這節就好：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;/li&gt;
&lt;li&gt;多數 AI 應用是讓機器學會一個對應關係&lt;/li&gt;
&lt;li&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;/li&gt;
&lt;li&gt;只需花費你 1 秒的任務，大都可由 AI 自動化&lt;/li&gt;
&lt;li&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;/li&gt;
&lt;li&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;/li&gt;
&lt;li&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;/li&gt;
&lt;li&gt;機器學習和資料科學的產出分別是系統和洞見&lt;/li&gt;
&lt;li&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;/li&gt;
&lt;li&gt;終身學習在這個年代前所未有地重要&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ben-white-131241-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;是的，既然是 AI For Everyone，自然沒有什麼艱深內容。但就像吳恩達教授在課程裡頭所說的，我相信這些基本的核心思想可以引導我們在這個 AI 時代更有方向且順利地前進。&lt;/p&gt;
&lt;p&gt;本文接著會搭配課程投影片，針對上面提到的一些概念做點簡單的補充說明，供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="講到-AI，我們通常是指狹義的-AI-而非終結者"&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;a class="anchor-link" href="#講到-AI，我們通常是指狹義的-AI-而非終結者"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在媒體整天報導的人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence, AI）應用如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;智慧音響&lt;/li&gt;
&lt;li&gt;自動駕駛&lt;/li&gt;
&lt;li&gt;人臉辨識&lt;/li&gt;
&lt;li&gt;圖像分類&lt;/li&gt;
&lt;li&gt;推薦系統&lt;/li&gt;
&lt;li&gt;機器翻譯&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;背後皆是狹義的 AI（&lt;strong&gt;A&lt;/strong&gt;rtificial &lt;strong&gt;N&lt;/strong&gt;arrow &lt;strong&gt;I&lt;/strong&gt;ntelligence, ANI）。&lt;/p&gt;
&lt;p&gt;儘管很多 AI 應用的表現甚至已經比人類還優秀，這些 AI 基本上都專注在完成「特定」的任務；這跟科幻電影如魔鬼終結者裡頭，能跟人類以一樣的方式思考並做「任何」事情的通用 AI（&lt;strong&gt;A&lt;/strong&gt;rtificial &lt;strong&gt;G&lt;/strong&gt;eneral &lt;strong&gt;I&lt;/strong&gt;ntelligence, AGI）是有很大差異的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ani-vs-agi.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        ANI 與 AGI 的差異
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管開發出 AGI 是很多研究者的終極夢想，但事實上現行的科技離實現 AGI 還有好一段距離。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="多數-AI-應用是讓機器學會一個對應關係"&gt;多數 AI 應用是讓機器學會一個對應關係&lt;a class="anchor-link" href="#多數-AI-應用是讓機器學會一個對應關係"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在以前的文章裡頭看過的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://demo.leemeng.tw/"&gt;AI 如何找出你的喵：直觀理解卷積神經網路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大部分的機器學習以及 AI 應用本質上都是讓電腦學會一個映射函數（Mapping Function），幫我們將輸入的數據 A 對應到理想的輸出 B：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;郵件分類：電子郵件 -&amp;gt; 是否為垃圾郵件&lt;/li&gt;
&lt;li&gt;語音辨識：音訊檔案 -&amp;gt; 文本&lt;/li&gt;
&lt;li&gt;機器翻譯：英文文本 -&amp;gt; 中文文本&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/learning-a-to-b.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        抽離技術細節，許多 AI 應用事實上就是一個個幫我們將輸入 A 轉換成輸出 B 的映射函數
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要實現這種 AI 應用，最常被使用的方法是&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式學習（Supervised Learning）&lt;/a&gt;：給予機器大量的成對數據，告訴它什麼樣的 A 要對應到什麼樣的 B，並讓機器最後自己學會如何將任意的 A 轉換成理想的 B，達到自動化的目的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-data-source-nn.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        現在多數的 AI 應用是透過人工神經網路，讓機器學會如何將輸入 A 轉成輸出 B
                        （&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="大數據、神經網路及運算能力是-AI-成功關鍵"&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;a class="anchor-link" href="#大數據、神經網路及運算能力是-AI-成功關鍵"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要實現能幫助人類做複雜判斷的 AI 技術有很多種，但近年真正讓 AI 大紅大紫的是&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;以及&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;人工神經網路（Artifical Neural Network）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/neural-network-plyaground.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Google 的 TensorFlow 團隊讓你可以在瀏覽器裡頭體驗深度學習以及神經網路
                        （&lt;a href="https://playground.tensorflow.org" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，你或許常聽到「神經網路跟人腦運作方式相同」的這種說法，但事實上如果你問相關人士對這種意見的看法的話，得到的答案常常是「兩者天差地遠」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管神經網路的運作方式跟我們神奇的大腦不完全一致，搭配大量數據以及前面提到的監督式學習，越大的神經網路通常可以在特定任務有越好的表現。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/big-data-and-deep-neural-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        先不論所需的計算資源，「越大量的數據以及越大型的神經網路能帶來更好的表現」這件事情對許多大企業來說，是件美好到不行的事情
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然這樣的現象令人振奮，但別忘記&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大型神經網路的運作&lt;/li&gt;
&lt;li&gt;大量數據的處理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩件事情都意味著需要更大量的電腦運算能力。而很多時候一般人是沒有這樣的運算資源的。&lt;/p&gt;
&lt;p&gt;值得慶幸的是，很多以深度學習為基礎的 AI 常常有個很好的特性：透過&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習（Transfer Learning）&lt;/a&gt;，我們能將事先已經用大量計算資源做訓練，並在任務 A 表現優異的 AI 做些簡單修改，就能讓修改過後的 AI' 能在相似的任務 B 也表現不錯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/cnn-with-pretrained-model.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一個利用遷移學習，把在圖像辨識中表現優異的 AI 拿來辨識貓咪的例子
                        （&lt;a href="https://demo.leemeng.tw/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這時候就算你只有少量數據以及不多的計算資源，也能利用 AI 完成以往難以想像的任務。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="只需花費你-1-秒的任務，（未來）大都可由-AI-自動化"&gt;只需花費你 1 秒的任務，（未來）大都可由 AI 自動化&lt;a class="anchor-link" href="#只需花費你-1-秒的任務，（未來）大都可由-AI-自動化"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這項概念是吳恩達教授在課程裡所提到的「一秒原則」，可以讓你用來判斷一個任務是否能用 AI 做自動化的準則。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/one-second-rule.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一秒原則
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過監督式學習以及大量成對 A &amp;amp; B 數據，我們可以讓很多以往被認為非常複雜，但人腦僅需 1 秒鐘就能解決的任務透過 AI 來自動化，讓我們的生活更加輕鬆。&lt;/p&gt;
&lt;p&gt;當然，這個簡化的原則並不是放諸四海皆準，但可以做為一個不錯的參考基準。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="對-AI-的態度不應過度樂觀，但也不必太悲觀"&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;a class="anchor-link" href="#對-AI-的態度不應過度樂觀，但也不必太悲觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;儘管我們已經清楚現代 AI 的威力，仍需注意 AI 並不是萬能藥，無法（完美地）解決或自動化所有人類的課題。&lt;/p&gt;
&lt;p&gt;比方說&lt;a href="https://demo.allennlp.org/atis-parser/NjMwMzQw/"&gt;有研究嘗試把自然語言轉成 SQL&lt;/a&gt;，但短期內一個資料科學家自己寫 SQL 查詢數據可能還是比較有效率。儘管 AI 不能（完美地）做到任何事情，我們也不該對 AI 失望，斷定下一個 AI 冬天必定會到來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/goldilocks-rule-for-ai.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        AI 的金髮女孩原理：對 AI 的態度不要過熱（樂觀），也不要過冷（悲觀），而是要剛剛好
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在可以肯定的是 AI 已經，而且也會繼續改變我們未來以及下一代的生活型態。&lt;/p&gt;
&lt;p&gt;最重要的是理性地理解 AI 能做到什麼，在能活用的時候善加利用它，同時不抱著「 AI 能解決所有問題」的不切實際幻想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/goldilocks.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;小知識：著名格林童話故事「金髮女孩與三隻熊」，講述金髮小女孩走進了三隻熊的房子，她發現當中有三碗粥，一碗太熱，一碗太冷，最後她揀選了不冷不熱的第三碗。之後她又試了三張椅子及睡床，最後她揀選了最合適的小椅子及睡床坐下及睡覺。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AI-偏見難解，但或許比消除人類偏見簡單"&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;a class="anchor-link" href="#AI-偏見難解，但或許比消除人類偏見簡單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在利用監督式學習的方式訓練 AI 的時候，我們常常會使用現實世界的資料讓機器學習。&lt;/p&gt;
&lt;p&gt;好消息是因為現在數位化以及網際網路的發達，我們有非常多數據可以交給 AI 學習；壞消息是這些數據時常反映了人類數十年甚至幾個世紀的偏見。&lt;/p&gt;
&lt;p&gt;用這些數據訓練出來的 AI 系統就像是面照妖鏡，也會不可避免地學會這些偏見（Bias）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/ai-for-everyone/human-bias-to-technology.jpg"&gt;
&lt;source src="https://leemeng.tw/images/ai-for-everyone/human-bias-to-technology.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在我們將具有人類偏見的數據交給 AI 學習時，不可避免地會創造出具有偏見的系統
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;知名的例子有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以白人照片訓練出來的人臉辨識系統在辨識深色膚色的人種時表現很差&lt;/li&gt;
&lt;li&gt;自動化雇用的 AI 系統對女性存有偏見&lt;/li&gt;
&lt;li&gt;銀行的自動信用評比 AI 系統對某些族群產生偏見&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下則是另一個課堂中提出的例子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ai-bias-word-embedding.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        讓 AI 從維基百科學習英文詞彙之間的統計關係後，發現 AI 認為「男人之於電腦工程師」的關係等於「女人之於家庭主婦」
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上例或許稱不上歧視，但很明顯是偏見，一種長久存在於人類社會的性別偏見。&lt;/p&gt;
&lt;p&gt;因為很多時候這些 AI 系統是學習一種統計關係，因此在此例中，AI 只是忠誠地呈現我們社會的用字習慣罷了。&lt;/p&gt;
&lt;p&gt;要消除 AI 的這些偏見並不容易，但仔細想想，這可能比消除人們腦中數十年的偏見要來的簡單，而且振奮人心。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/ai-for-everyone/remove-human-bias-from-technology.jpg"&gt;
&lt;source src="https://leemeng.tw/images/ai-for-everyone/remove-human-bias-from-technology.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在享有強大 AI 科技的同時，我們希望最終也能將人類的偏見從這些 AI 系統中摒除
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這件事情當然不簡單，但卻非常值得一試。&lt;/p&gt;
&lt;p&gt;當然，你可以選擇不思考這些 AI 倫理、偏見問題，相信建立 AI 系統的這些工程師們立意良善以及夠細心，能幫我們將 AI 系統裡的偏見移除，並讓其做出最合適的判斷。&lt;/p&gt;
&lt;p&gt;儘管如此，意識到再厲害的 AI 系統內部也可能存在如同人類的偏見，進而導致各種不公平的社會問題這件事情也是很有幫助的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="擁抱-AI-的最好方法是將其與領域專業結合"&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;a class="anchor-link" href="#擁抱-AI-的最好方法是將其與領域專業結合"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;想要學習 AI，不需要打掉重練。&lt;/p&gt;
&lt;p&gt;雖然現在 AI 相關領域十分熱門，究其根本也就只是一種工具/技術。而且 AI 技術接下來會越來越平民化，上手的門檻會越來越低。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/rawpixel-633846-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此比起現在轉行當 AI 工程師，你要先做的應該是想辦法利用自己工作累積的領域知識（Domain Knowledge）以及洞見（Insight），找出能應用 AI 改善的地方，進而創造出專屬於你或企業的競爭優勢。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器學習和資料科學的產出分別是系統和洞見"&gt;機器學習和資料科學的產出分別是系統和洞見&lt;a class="anchor-link" href="#機器學習和資料科學的產出分別是系統和洞見"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;機器學習（&lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;L&lt;/strong&gt;earning, ML）以及資料科學（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cience, DS）這兩個詞彙常常結伴出現，且依照不同企業其定義都有所不同。因此，不在這塊領域裡的人常常不知道兩者的差異。&lt;/p&gt;
&lt;p&gt;一般來說，在企業內的 ML 專案大都分為 3 個階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集數據&lt;/li&gt;
&lt;li&gt;訓練模型&lt;/li&gt;
&lt;li&gt;部署模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ml-project-key-steps.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一般的 ML 專案的最終產物為機器學習模型，或是能夠持續運作的 AI 系統
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而 DS 專案的步驟則為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集數據&lt;/li&gt;
&lt;li&gt;分析數據&lt;/li&gt;
&lt;li&gt;建議行動/假說&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ds-project-key-steps.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一般的 DS 專案的最終產物為有用的假說或是洞見
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;兩者皆需原始數據做為輸入，且皆有機會使用 AI / ML 技術來解決、分析問題，但最終的產出形式時常不同。&lt;/p&gt;
&lt;p&gt;總結來說，ML 專案較注重在軟體工程方面，且最終希望產出一個以 AI 為基礎的線上系統；DS 專案的結果則可能是一份幫助經營者做重大投資決策的投影片報告。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ml-vs-ds.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AI-時代，你得思考未來自己想要扮演的角色"&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;a class="anchor-link" href="#AI-時代，你得思考未來自己想要扮演的角色"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;AI 目前正是顯學，不少人決定進入這塊領域，而現在跟 AI 相關的職業就有好多種，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家&lt;/li&gt;
&lt;li&gt;機器學習工程師&lt;/li&gt;
&lt;li&gt;機器學習研究者&lt;/li&gt;
&lt;li&gt;軟體工程師&lt;/li&gt;
&lt;li&gt;資料工程師&lt;/li&gt;
&lt;li&gt;AI 專案管理人&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等。而且隨著 AI 的影響力持續擴大，未來可能還會出現新的相關職業。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/diablo-3-characters.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        AI 時代裡有各式各樣的相關職業，找尋最適合你的職業很重要
                        （&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這邊不會一一列出每個職業的工作內容，但忠實讀者會發現，事實上我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html"&gt;數據科學 MMORPG 上線！你，選好自己的角色了嗎？&lt;/a&gt;一文中就已經討論過類似的話題了。&lt;/p&gt;
&lt;p&gt;要踏入 AI 這塊領域，除了資料科學家以外，你還有很多選擇。思考你的強處以及興趣所在，選擇最適合的職業發揮所長是最理想的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="終身學習在這個年代前所未有地重要"&gt;終身學習在這個年代前所未有地重要&lt;a class="anchor-link" href="#終身學習在這個年代前所未有地重要"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;如同課程中吳恩達教授所說的，你並不需要取得一個 AI master 才能開始進行 AI 專案。很多時候利用&lt;a href="https://leemeng.tw/deep-learning-resources.html#xian%20shang%20ke%20cheng_1"&gt;線上課程&lt;/a&gt;或是&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;網路上的深度學習資源&lt;/a&gt;就可以開始你的第一個 AI 專案了。&lt;/p&gt;
&lt;p&gt;事實上，學習 &lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt; 這堂課就是一個不錯的開始。網路上也有很多優質的部落格或教學文章等待你的探索。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/le-tan-674393-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 領域近年發展神速，要學習 AI，用上一代「讀幾年書，出來用一輩子」的概念是行不通的。台大電機系的&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/"&gt;李宏毅教授&lt;/a&gt;就曾說過：「在深度學習的領域，超過五年就是遠古時代了」。&lt;/p&gt;
&lt;p&gt;因此如果你決定踏上學習 AI 的這條路，就做好跟我一起終身學習的心理準備吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;看到這裡，相信你已經了解 AI For Everyone 裡頭 10 個最重要的概念了，恭喜！&lt;/p&gt;
&lt;p&gt;這些概念大多是我將課程裡頭擷取出的核心概念，佐以自己從事資料科學家以來的心得感想。希望閱讀完此文的你有學到點東西，或是獲得些啟發。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/fabrizio-magoni-219347-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        課堂內容是主菜，我的個人心得是調味料，希望你喜歡這道菜，並分享給朋友知道
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了幫助你回憶，現在讓我再次將本文提到的概念一一列出：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;/li&gt;
&lt;li&gt;多數 AI 應用是讓機器學會一個對應關係&lt;/li&gt;
&lt;li&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;/li&gt;
&lt;li&gt;只需花費你 1 秒的任務，大都可由 AI 自動化&lt;/li&gt;
&lt;li&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;/li&gt;
&lt;li&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;/li&gt;
&lt;li&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;/li&gt;
&lt;li&gt;機器學習和資料科學的產出分別是系統和洞見&lt;/li&gt;
&lt;li&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;/li&gt;
&lt;li&gt;終身學習在這個年代前所未有地重要&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 當然有其侷限性，但只要你能找出應用它的任務，就能將其轉換成你的超能力，可能性無窮大。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟隨完我的思路歷程，現在輪到你動腦回答下面問題了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你有什麼個人或是企業的課題，是可以透過 AI 改善或是提升價值的呢？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="人工智慧"></category><category term="資料科學"></category><category term="機器學習"></category></entry><entry><title>由淺入深的深度學習資源整理</title><link href="https://leemeng.tw/deep-learning-resources.html" rel="alternate"></link><published>2019-01-08T08:00:00+09:00</published><updated>2019-01-08T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-01-08:/deep-learning-resources.html</id><summary type="html">&lt;p&gt;這裡紀錄了我在學習深度學習時蒐集的一些線上資源。內容由淺入深，而且會一直被更新，希望能幫助你順利地開始學習：）&lt;/p&gt;</summary><content type="html">&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                            不聞不若聞之，聞之不若見之，見之不若知之，知之不若行之，學至於行之而止矣。
                            &lt;br/&gt;
&lt;span style="float:right"&gt;── 《荀子．儒效》&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem"&gt;
&lt;p&gt;
        這段話翻成白話文就是「沒聽過比不上聽過；聽過比不上實際看過；看過則比不上實際了解；而了解又不如動手實踐。唯有身體力行才能真正地學到東西。」
    &lt;/p&gt;
&lt;p&gt;
        這句古老的諺語向我們傳達了「實踐」的重要以及學習的幾個過程。
    &lt;/p&gt;
&lt;p&gt;
        做為一門學問，&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" target="_blank"&gt;深度學習&lt;/a&gt;也是同樣道理。
        僅說自己對深度學習有興趣或是有關注（聞、見），但卻沒有實際花時間去深入了解或實際應用（知、行）是無法真正學會深度學習的。
    &lt;/p&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="/images/patrick-tomasso-71909-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
        雖說如此，不了解深度學習能拿來做什麼的人或許還不少。
    &lt;/p&gt;
&lt;p&gt;
        我嘗試將自己在學習過程中蒐集到的重要資源由淺入深地做些整理。
        希望透過此文，能讓在各個學習階段的你都能從這裡獲得些什麼，並實際動手學習、探索發展快速的深度學習世界。
    &lt;/p&gt;
&lt;p&gt;
        本文內容會持續被更新，你可以定期回來看看或是關注這個 
        &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank"&gt;Github Repo&lt;/a&gt;。
    &lt;/p&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/general/paper-ball.jpg"/&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;這裡紀錄了我在學習&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;時蒐集的一些線上資源。內容由淺入深，而且會不斷更新，希望能幫助你順利地開始學習：）&lt;/p&gt;
&lt;h2 id="ben wen zhang jie"&gt;本文章節&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#playground"&gt;遊玩空間&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#courses"&gt;線上課程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools"&gt;實用工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tutorials"&gt;其他教材&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#blogs"&gt;優質文章&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#papers"&gt;經典論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#collections"&gt;其他整理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="you wan kong jian"&gt;&lt;div id="playground"&gt;遊玩空間&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這節列舉了一些透過瀏覽器就能馬上開始遊玩 / 體驗深度學習的應用。作為這些應用的使用者，你可以先高層次、直觀地了解深度學習能做些什麼。之後有興趣再進一步了解背後原理。&lt;/p&gt;
&lt;p&gt;這小節最適合：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想要快速體會深度學習如何被應用在真實世界的好奇寶寶&lt;/li&gt;
&lt;li&gt;想要直觀理解&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;類神經網路（Artifical Neural Network）&lt;/a&gt;運作方式的人&lt;/li&gt;
&lt;li&gt;想從別人的深度學習應用取得一些靈感的開發者&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;Deep Playground&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html"&gt;ConvNetJS&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/deep-playground.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/convnetjs.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="deep playground"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;Deep Playground&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 &lt;a href="https://github.com/tensorflow/playground"&gt;Tensorflow 團隊&lt;/a&gt;推出，模擬訓練一個類神經網路的過程並了解其運作原理&lt;/li&gt;
&lt;li&gt;可以搭配這篇 &lt;a href="https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises"&gt;Introduction to Neural Networks: Playground Exercises&lt;/a&gt; 學習&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="convnetjs"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/"&gt;ConvNetJS&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;訓練類神經網路來解決經典的 &lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html"&gt;MNIST 手寫數字辨識問題&lt;/a&gt;、&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html"&gt;圖片生成&lt;/a&gt;以及&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html"&gt;增強式學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;由 Tesla 的 AI 負責人 &lt;a href="https://cs.stanford.edu/people/karpathy/"&gt;Andrej Karpathy&lt;/a&gt; 建立&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;Magenta&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;Google AI Experiments&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/magenta.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/google-ai-experiment.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="magenta"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;Magenta&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個利用&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;來協助人們進行音樂以及藝術創作的開源專案&lt;/li&gt;
&lt;li&gt;可以在網站上的 &lt;a href="https://magenta.tensorflow.org/demos"&gt;Demo 頁面&lt;/a&gt;嘗試各種由深度學習驅動的音樂 / 繪畫應用（如彈奏鋼琴、擊鼓）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="google ai experiments"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;Google AI Experiments&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;這邊展示了接近 40 個利用圖片、語言以及音樂來與使用者產生互動的機器學習 Apps，值得慢慢探索&lt;/li&gt;
&lt;li&gt;知名例子有 &lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt; 以及 &lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;，將在下方介紹&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/quickdraw.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/teachable-machine.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="quick draw"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 Google 推出的知名手寫塗鴉辨識，使用的神經網路架構有常見的&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;卷積神經網路 CNN &lt;/a&gt;以及&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1"&gt;循環神經網路 RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;該深度學習模型會不斷將最新的筆觸當作輸入來預測使用者想畫的物件。你會驚嘆於她精準且即時的判斷&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="teachable machine"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;利用電腦 / 手機上的相機來訓練能將影像對應到其他圖片、音訊的神經網路，饒富趣味&lt;/li&gt;
&lt;li&gt;透過這例子，你將暸解機器學習的神奇之處以及其侷限所在&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;Fast Neural Style&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/fast-neural-style.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://js.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/human-pose-estimation.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="fast neural style"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;Fast Neural Style&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;展示如何使用 WebGL 在瀏覽器快速地進行&lt;a href="https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398"&gt;神經風格轉換 Neural Style Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;你可以選擇任何一張圖片，並在此網站上將其畫風轉變成指定的藝術照&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deepart.io/"&gt;Deepart.io&lt;/a&gt; 也提供類似服務&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="tensorflow.js"&gt;&lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow.js 頁面有多個利用 JavaScript 實現的深度學習應用，如上圖中的&lt;a href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5"&gt;人類姿勢估計 Human Pose Estimation&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;你可以在該應用裡頭打開自己的攝影機，看該應用能不能偵測到你與朋友的姿勢。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://talktotransformer.com/"&gt;Talk to Transformer&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/gan-lab.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://talktotransformer.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/talk_to_transformer.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="gan lab"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"&gt;對抗生成網路（&lt;strong&gt;G&lt;/strong&gt;enerative &lt;strong&gt;A&lt;/strong&gt;dversarial &lt;strong&gt;N&lt;/strong&gt;etwork，簡稱GAN）&lt;/a&gt;是非監督式學習的一種方法，通過讓兩個神經網路相互博弈的方式進行學習。此網站以 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt; 實作 GAN 中兩個神經網路的學習過程，幫助有興趣的你更直觀地理解神奇的 GAN 的運作方式&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="talk to transformer"&gt;&lt;a href="https://talktotransformer.com/"&gt;Talk to Transformer&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;展示了一個由 OpenAI 推出，名為 &lt;a href="https://openai.com/blog/better-language-models/"&gt;GPT-2 的無監督式語言模型&lt;/a&gt;。該模型以 Google 發表的神經網路架構 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Transformer&lt;/a&gt; 為基底，在給定一段魔戒或是復仇者聯盟的文字內容，該模型可以自己生成唯妙唯俏的延伸劇情。&lt;/li&gt;
&lt;li&gt;想要深入了解 Transformer，推薦閱讀：&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html"&gt;淺談神經機器翻譯 &amp;amp; 用 Transformer 與 TensorFlow 2 英翻中&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jalammar.github.io/illustrated-transformer/"&gt;The Illustrated Transformer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;你也可以參考&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部&lt;/a&gt;來看如何使用 LSTM 達到類似的文本生成效果&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://www.nvidia.com/en-us/research/ai-playground/"&gt;NVIDIA AI PLAYGROUND&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://grover.allenai.org/"&gt;Grover&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://www.nvidia.com/en-us/research/ai-playground/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/nvidia-ai-playground.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://grover.allenai.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/grover.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="nvidia ai playground"&gt;&lt;a href="https://www.nvidia.com/en-us/research/ai-playground/"&gt;NVIDIA AI PLAYGROUND&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;提供 &lt;a href="https://arxiv.org/abs/1903.07291"&gt;GauGAN&lt;/a&gt; 的線上展示，讓你可以利用簡單的筆觸來生成真實世界的風景圖片，也能上傳自己的圖片做風格轉換&lt;/li&gt;
&lt;li&gt;提供 &lt;a href="https://arxiv.org/abs/1804.07723"&gt;Image Impainting&lt;/a&gt; 服務，讓使用者自由抹去部分圖片並讓 AI 自動生成被抹去的區塊&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="grover"&gt;&lt;a href="https://grover.allenai.org/"&gt;Grover&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個偵測 / 生成神經假新聞（Neural Fake News）的研究，其網頁展示如何自動生成假新聞。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="xian shang ke cheng_1"&gt;&lt;div id="courses"&gt;線上課程&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;看完&lt;a href="#playground"&gt;遊玩空間&lt;/a&gt;的大量實際應用，相信你已經迫不及待地想要開始學習強大的深度學習技術了。&lt;/p&gt;
&lt;p&gt;這節列舉了一些有用的線上課程以及學習教材，幫助你掌握深度學習的基本知識（沒有特別註明的話皆為免費存取）。&lt;/p&gt;
&lt;p&gt;另外值得一提的是，大部分課程都要求一定程度的 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 程式能力。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;李宏毅教授的機器學習 / 深度學習課程&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning Specialization @ Coursera&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/Hung-Yi-Lee-ml-courses.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/deep-learning-specification-coursera.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="li hong yi jiao shou de ji qi xue xi  / shen du xue xi ke cheng"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;李宏毅教授的機器學習 / 深度學習課程&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;大概是全世界最好、最完整的 Deep Learning &lt;b&gt;中文&lt;/b&gt;學習資源。&lt;/li&gt;
&lt;li&gt;影片內容涵蓋基本理論（約 10 小時觀看時間）一直到進階的&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"&gt;生成對抗網路 GAN&lt;/a&gt; 以及&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"&gt;強化學習 RL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;你也可以從&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists"&gt;這邊&lt;/a&gt;看到教授的 Youtube 課程清單&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning specialization @ coursera"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning Specialization @ Coursera&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;原 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授開授的整個深度學習專項課程共分五堂課，從&lt;a href="https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning"&gt;神經網路的基礎&lt;/a&gt;到能夠進行機器翻譯、語音辨識的&lt;a href="https://www.coursera.org/learn/nlp-sequence-models"&gt;序列模型&lt;/a&gt;，每堂課預計 1 個月完成，收費採訂閱制&lt;/li&gt;
&lt;li&gt;程式作業會交互使用 &lt;a href="http://www.numpy.org/"&gt;Numpy&lt;/a&gt;、&lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 以及 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt; 來實作深度學習模型&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;Practical Deep Learning For Coders @ fast.ai&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;Deep Learning @ Kaggle Learn&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/fast-ai.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/kaggle-learn-dl.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="practical deep learning for coders @ fast.ai"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;Practical Deep Learning For Coders @ fast.ai&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;7 週課程，一週約需安排 10 小時上課。該課程由&lt;a href="https://www.kaggle.com/jhoward"&gt;傑里米&amp;middot;霍華德&lt;/a&gt;來講解深度學習，其在知名數據建模和數據分析競賽平台 &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 維持兩年的世界第一&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning @ kaggle learn"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;Deep Learning @ Kaggle Learn&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;14 堂課程，主要使用 TensorFlow 實作深度學習模型&lt;/li&gt;
&lt;li&gt;內容主要專注在&lt;a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"&gt;電腦視覺（Computer Vision）&lt;/a&gt;以及如何應用&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習（Transfer Learning）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://www.elementsofai.com/"&gt;Elements of Artificial Intelligence&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://deeplearning.mit.edu/"&gt;MIT Deep Learning&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://www.elementsofai.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/elementsofai.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/mlt-deep-learning.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="elements of artificial intelligence"&gt;&lt;a href="https://www.elementsofai.com/"&gt;Elements of Artificial Intelligence&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;芬蘭最高學府&lt;a href="https://zh.wikipedia.org/wiki/%E8%B5%AB%E5%B0%94%E8%BE%9B%E5%9F%BA%E5%A4%A7%E5%AD%A6"&gt;赫爾辛基大學&lt;/a&gt;推出的 AI 課程。此課程目的在於讓所有人都能了解 AI，不需要任何程式經驗。這堂課非常適合完全沒有接觸過深度學習或是相關領域的人&lt;/li&gt;
&lt;li&gt;課程分 6 個部分，包含「何謂 AI ？」、「真實世界的 AI」、「機器學習」以及「神經網路」等章節&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="mit deep learning"&gt;&lt;a href="https://deeplearning.mit.edu/"&gt;MIT Deep Learning&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;麻省理工學院推出的深度學習課程，內容包含深度學習基礎、深度強化學習以及自動駕駛相關知識。&lt;a href="https://github.com/lexfridman/mit-deep-learning"&gt;Github Repo&lt;/a&gt; 包含了多個教學筆記本，值得參考&lt;/li&gt;
&lt;li&gt;上圖是 &lt;a href="https://selfdrivingcars.mit.edu/deeptraffic/"&gt;DeepTraffic&lt;/a&gt;，由 MIT 的研究科學家 &lt;a href="https://lexfridman.com/"&gt;Lex Fridman&lt;/a&gt; 推出的一個深度強化學習競賽。此競賽目標是建立一個可以在高速公路上駕駛汽車的神經網路。你可以在&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic/"&gt;這裡&lt;/a&gt;看到線上 Demo 以及詳細說明&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://introtodeeplearning.com"&gt;6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://introtodeeplearning.com"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/intro-to-deeplearning-mit.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/ai-for-everyone.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="6.s191: introduction to deep learning"&gt;&lt;a href="http://introtodeeplearning.com"&gt;6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;麻省理工學院推出的另一堂基礎深度學習課程，介紹深度學習以及其應用。內容涵蓋機器翻譯、圖像辨識以及更多其他應用。此課程使用 Python 以及 TensorFlow 來實作作業，並預期學生具備基礎的微積分（梯度 &amp;amp; Chain Rule）以及線性代數（矩陣相乘）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="ai for everyone"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Coursera 課程。&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授在這堂簡短的課程裡頭，針對非技術人士以及企業經理人說明何謂 AI、如何建立 AI 專案以及闡述 AI 與社會的關係。此課程十分適合沒有技術背景的讀者。&lt;a href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html"&gt;從 AI For Everyone 學到的 10 個重要 AI 概念&lt;/a&gt;則是我個人上完課後整理的心得分享。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="shi yong gong ju_1"&gt;&lt;div id="tools"&gt;實用工具&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這節列出一些在你的深度學習路上可以幫得上些忙的工具。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;TensorBoard&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/colab.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/tensorboard.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="colaboratory"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 Google 提供的雲端 &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; 筆記本環境，讓你只要用瀏覽器就能馬上開始訓練深度學習模型。你甚至還可以使用一個免費的 &lt;a href="https://www.nvidia.com/en-gb/data-center/tesla-k80/"&gt;Tesla K80&lt;/a&gt; GPU 或 &lt;a href="https://colab.research.google.com/notebooks/tpu.ipynb"&gt;TPU&lt;/a&gt; 來加速訓練自己的模型&lt;/li&gt;
&lt;li&gt;該計算環境也能與自己的 &lt;a href="https://colab.research.google.com/notebooks/io.ipynb"&gt;Google Drive&lt;/a&gt; 做連結，讓運算雲端化的同時將筆記本 / 模型結果都同步到自己的筆電上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="tensorboard"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;TensorBoard&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TensorBoard 是一個視覺化工具，方便我們了解、除錯並最佳化自己訓練的深度學習模型&lt;/li&gt;
&lt;li&gt;除了 TensorFlow 以外，其他基於 Python 的機器學習框架大多也可以透過 &lt;a href="https://github.com/lanpa/tensorboardX"&gt;tensorboardX&lt;/a&gt; 來使用 TensorBoard&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;Lucid&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/embedding-projector.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/lucid.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="embedding projector"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;我們時常需要將圖片、文字轉成&lt;a href="https://en.wikipedia.org/wiki/Tensor"&gt;高維數字向量 Embedding&lt;/a&gt; 以供神經網路處理，而 Projector 能將此高維向量投影到 2、3 維空間上方便我們理解這些數據&lt;/li&gt;
&lt;li&gt;Projector 網站讓你在線上探索幾個常見的資料集，但事實上你也可以&lt;a href="https://www.tensorflow.org/guide/embedding"&gt;利用 Tensorboard 來視覺化自己的數據&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="lucid"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;Lucid&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Lucid 是一個嘗試讓神經網路變得更容易解釋的開源專案，裡頭包含了很多視覺化神經網路的筆記本&lt;/li&gt;
&lt;li&gt;你可以直接在 Colab 上執行這些筆記本並了解如何視覺化神經網路&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://paperswithcode.com/"&gt;Papers with Code&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;What-If Tool&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://paperswithcode.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/papers-with-code.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/what-if-tool.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="papers with code"&gt;&lt;a href="https://paperswithcode.com/"&gt;Papers with Code&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;將機器學習的學術論文、程式碼實作以及 SOTA 的評價排行榜全部整理匯總在一起的網站，非常適合想要持續追蹤學術及業界最新研究趨勢的人&lt;/li&gt;
&lt;li&gt;在這邊可以瀏覽包含電腦視覺、自然語言處理等各大領域在不同任務上表現最好的論文、實作以及資料集&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="what-if tool"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;What-If Tool&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個與 &lt;a href="#tensorboard"&gt;TensorBoard&lt;/a&gt; 以及 Jupyter Notebook 整合的探索工具，讓使用者不需寫程式碼就能輕鬆觀察機器學習模型的內部運作以及嘗試各種 What-if 問題（如果 ~ 會怎麼樣？）&lt;/li&gt;
&lt;li&gt;基本上就是用來觀察&lt;strong&gt;已訓練&lt;/strong&gt;的模型在測試資料集上的表現。利用此工具，使用者可以了解（不僅限於）以下的問題：模型在各類別數據上的表現有無差距？模型是否存在偏見？應該如何調整 Native / Positive False 的比例？&lt;/li&gt;
&lt;li&gt;此工具的一大亮點在於讓非專業領域人士也能探索、理解 ML 模型表現。且只要給定模型與資料集, 就不需要每次為了 What-if 問題就寫用過即丟的程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="qi ta jiao cai_1"&gt;&lt;div id="tutorials"&gt;其他教材&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;除了&lt;a href="#courses"&gt;線上課程&lt;/a&gt;以外，網路上還有無數的學習資源。&lt;/p&gt;
&lt;p&gt;這邊列出一些推薦的深度學習教材，大多數皆以數據科學家常用的 &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; 筆記本的方式呈現。&lt;/p&gt;
&lt;p&gt;你可以將感興趣的筆記本導入&lt;a href="#tools"&gt;實用工具&lt;/a&gt;裡提到的 &lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory（Colab）&lt;/a&gt;，馬上開始學習。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;Seedbank&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;Deep Learning with Python&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/seedbank.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/fchollet-deep-learning-with-python.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="seedbank"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;Seedbank&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;讓你可以一覽 Colab 上超過 100 個跟機器學習相關的筆記本，並以此為基礎建立各種深度學習應用&lt;/li&gt;
&lt;li&gt;熱門筆記本包含&lt;a href="https://research.google.com/seedbank/seed/5695159920492544"&gt;神經機器翻譯&lt;/a&gt;、&lt;a href="https://research.google.com/seedbank/seed/5681034041491456"&gt;音樂生成&lt;/a&gt;以及 &lt;a href="https://research.google.com/seedbank/seed/5631986051842048"&gt;DeepDream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;因為是 Google 服務，筆記本大多使用 TensorFlow 與 Keras 來實現模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning with python"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;Deep Learning with Python&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 作者 &lt;a href="https://ai.google/research/people/105096"&gt;Fran&amp;ccedil;ois Chollet&lt;/a&gt; 在 &lt;a href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438"&gt;Deep Learning with Python&lt;/a&gt; 一書中用到的所有筆記本。每個筆記本裡頭都清楚地介紹該如何使用 Keras 來實現各種深度學習模型，十分適合第一次使用 Python 實現深度學習的讀者 &lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#top"&gt;進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;一文的 Keras 程式碼大多基於此&lt;/li&gt;
&lt;li&gt;繁體中文的翻譯書籍則為 &lt;a href="https://www.tenlong.com.tw/products/9789863125501?list_name=i-r-zh_tw"&gt;Deep learning 深度學習必讀 - Keras 大神帶你用 Python 實作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Keras 在 TensorFlow 2.0 中&lt;a href="https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a"&gt;為其最重要的高層次 API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;Stanford CS230 Cheatsheets&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;practicalAI&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/cs230-deep-learning-cheatsheet.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/practical-ai-pytorch.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="stanford cs230 cheatsheets"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;Stanford CS230 Cheatsheets&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;史丹佛大學的&lt;a href="http://cs230.stanford.edu/"&gt;深度學習課程 CS230&lt;/a&gt; 釋出的深度學習小抄總結了目前最新的&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;卷積神經網路&lt;/a&gt;及&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks"&gt;循環神經網路&lt;/a&gt;知識，還包含了&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks"&gt;訓練深度學習時需要使用到的技巧&lt;/a&gt;，十分強大&lt;/li&gt;
&lt;li&gt;此小抄最適合已經熟悉基礎知識的同學隨時複習運用。你也可以從他們的 &lt;a href="https://github.com/afshinea/stanford-cs-230-deep-learning"&gt;Github Repo&lt;/a&gt; 下載包含上述所有內容的&lt;a href="https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/super-cheatsheet-deep-learning.pdf"&gt;超級 VIP 小抄&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;除了深度學習以外，你也可以查看 &lt;a href="https://stanford.edu/~shervine/teaching/cs-229.html"&gt;CS229 機器學習課程的小抄&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="practicalai"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;practicalAI&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 Github 上超過 1 萬星的 Repo。除了深度學習，也有介紹 &lt;a href="https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/01_Python.ipynb"&gt;Python 基礎&lt;/a&gt;及 &lt;a href="https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/03_Pandas.ipynb"&gt;Pandas&lt;/a&gt; 的使用方式&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 框架來實現深度學習模型，且所有內容都是 Jupyter 筆記本，可以讓你在 Colab 或本地端執行&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://demo.allennlp.org/"&gt;AllenNLP Demo&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;To Be Updated&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://demo.allennlp.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/allennlp-demo.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href=""&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/general/to-be-updated.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="allennlp demo"&gt;&lt;a href="http://demo.allennlp.org/"&gt;AllenNLP Demo&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;清楚地展示了如&lt;a href="https://demo.allennlp.org/machine-comprehension"&gt;機器理解&lt;/a&gt;、&lt;a href="https://demo.allennlp.org/named-entity-recognition"&gt;命名實體識別&lt;/a&gt;等多個自然語言處理任務的情境。每個任務的情境包含了任務所需要的輸入、SOTA 模型的預測結果以及模型內部的注意力機制，對理解一個 NLP 任務的實際應用情境有很大幫助&lt;/li&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/"&gt;AllenNLP&lt;/a&gt; 是一個由 &lt;a href="https://allenai.org/"&gt;AI2&lt;/a&gt; 以 &lt;a href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt; 實現的自然語言處理函式庫&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="you zhi wen zhang_1"&gt;&lt;div id="blogs"&gt;優質文章&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊列舉了一些幫助我釐清重要概念的部落格以及網站，希望能加速你探索這個深度學習世界。&lt;/p&gt;
&lt;p&gt;只要 Google 一下就能發現這些部落格裡頭很多文章都有中文翻譯。但為了尊重原作者，在這邊都列出原文連結。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://distill.pub/about/"&gt;Distill&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;用非常高水準且互動的方式來說明複雜的深度學習概念。&lt;a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html"&gt;Yoshua Bengio&lt;/a&gt;、&lt;a href="http://www.iangoodfellow.com/"&gt;Ian Goodfellow&lt;/a&gt; 及 &lt;a href="http://cs.stanford.edu/people/karpathy/"&gt;Andrej Karpathy&lt;/a&gt; 等知名人士皆參與其中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.r2d3.us/%E5%9C%96%E8%A7%A3%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AC%AC%E4%B8%80%E7%AB%A0/"&gt;R2D3: 圖解機器學習&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;利用非常直覺易懂的視覺化來說明機器學習，連結為中文版&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/"&gt;Christopher Olah's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;詳細解釋不少深度學習概念。作者在&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;這篇&lt;/a&gt;就詳細地解釋了&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶 LSTM&lt;/a&gt; 的概念與變形；在&lt;a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/"&gt;這篇&lt;/a&gt;則解釋何為 CNN 的卷積運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jalammar.github.io/"&gt;Jay Alammar's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;以清楚易懂的視覺化解釋深度學習概念。&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"&gt;這篇&lt;/a&gt;用大量易懂的動畫說明&lt;a href="https://en.wikipedia.org/wiki/Neural_machine_translation"&gt;神經機器翻譯&lt;/a&gt;，而在&lt;a href="https://jalammar.github.io/illustrated-bert/"&gt;這篇&lt;/a&gt;則介紹如何利用如 &lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt;、&lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt; 等預先訓練過的強大模型在自然語言處理進行&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://karpathy.github.io/"&gt;Andrej Karpathy's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;現為 Tesla AI 負責人的 Andrej Karpathy 在&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;這篇&lt;/a&gt;明確說明何謂循環神經網路 RNN。文中提供不少應用實例及視覺化來幫助我們理解 RNN 模型究竟學到了什麼，是學習 RNN 的朋友幾乎一定會碰到的一篇文章&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="jing dian lun wen"&gt;&lt;div id="papers"&gt;經典論文&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊依發表時間列出深度學習領域的經典 / 重要論文。&lt;/p&gt;
&lt;p&gt;為了幫助你快速掌握論文內容以及歷年的研究趨勢，每篇論文下會有非常簡短的介紹（WIP）。&lt;/p&gt;
&lt;p&gt;但我們推薦有興趣的人自行閱讀論文以深入了解。&lt;/p&gt;
&lt;h3 id="zi ran yu yan chu li  natural language processing (nlp)"&gt;自然語言處理 Natural Language Processing (NLP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"&gt;2003/02 A Neural Probabilistic Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1301.3781"&gt;2013/01 Efficient Estimation of Word Representations in Vector Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1308.0850"&gt;2013/08 Generating Sequences With Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.0473"&gt;2014/09 Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1508.04025"&gt;2015/08 Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1511.01432"&gt;2015/12 Semi-supervised Sequence Learning&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;推出一套無監督式的預訓練方法。使用無標籤數據訓練後的 RNN 模型在之後的監督式任務表現更好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.03762"&gt;2017/06 Attention Is All You Need&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Google 推出新的神經網路架構 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Transformer&lt;/a&gt;。這個基於自注意力機制的架構特別適合語言理解任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.05137"&gt;2017/06 One Model To Learn Them All&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1708.00107"&gt;2017/08 Learned in Translation: Contextualized Word Vectors&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;監督式預訓練。透過 BiLSTM 與 Encoder-Decoder 架構預先訓練機器翻譯任務並將訓練後的 Encoder 拿來做特徵擷取。將 Encoder 的輸出作為語境向量（Context Vectors, CoVe）處理下游任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1801.06146"&gt;2018/01 Universal Language Model Fine-tuning for Text Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1802.05365"&gt;2018/02 Deep contextualized word representations&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/elmo"&gt;ELMo 詞向量&lt;/a&gt;，利用兩獨立訓練的 LSTM 獲取雙向訊息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf"&gt;2018/06 Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.openai.com/language-unsupervised/"&gt;OpenAI&lt;/a&gt; 利用無監督式預訓練以及 Transformer 架構訓練出來的模型表現在多個 NLP 任務表現良好。約使用 8 億詞彙量的資料集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;2018/10 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Google 暴力美學。利用深層 Transformer 架構、2 個精心設計的預訓練任務以及約 33 億詞彙量的資料集訓練後，得到表現卓越的語言代表模型，打破 11 項 NLP 任務紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1905.02450"&gt;2019/05 MASS: Masked Sequence to Sequence Pre-training for Language Generation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Microsoft 利用 Encoder-Decoder 架構以及連續遮罩（consecutive mask）將 BERT 推廣到自然語言生成（NLG）類型任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1905.03197"&gt;2019/05 Unified Language Model Pre-training for Natural Language Understanding and Generation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;預訓練階段利用不同遮罩控制 context，同時訓練雙向 LM、單向 LM 以及 Seq2Seq LM。其產生的預訓練模型可以處理 NLU 以及 NLG 任務，並在不加入外部數據的情況下打敗 BERT 在 GLUE 的紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="dian nao shi jue  computer vision (cv)"&gt;電腦視覺 Computer Vision (CV)&lt;/h3&gt;
&lt;h4 id="lei shen jing wang lu jia gou  neural network architecture"&gt;類神經網路架構 Neural Network Architecture&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"&gt;1998/01 Gradient-Based Learning Applied to Document Recognition (LeNet-5)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"&gt;2012/12 ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf"&gt;2014/06 DeepFace: Closing the Gap to Human-Level Performance in Face Verification (DeepFace)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.1556"&gt;2014/09 Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.4842"&gt;2014/09 Goint deeper with convolutions (GoogLeNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1411.4038"&gt;2014/11 Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1505.04597"&gt;2015/05 U-Net: Convolutional Networks for Biomedical Image Segmentation (U-Net)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1512.03385"&gt;2015/12 Deep Residual Learning for Image Recognition (ResNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1704.04861"&gt;2017/04 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (MobileNets)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1707.01083"&gt;2017/07 ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices (ShuffleNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="zi liao ji  dataset"&gt;資料集 Dataset&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.image-net.org/papers/imagenet_cvpr09.pdf"&gt;2009/06 ImageNet: A Large-Scale Hierarchical Image Database (ImageNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="wu ti zhen ce yu qie ge  object detection and segmentation"&gt;物體偵測與切割 Object Detection and Segmentation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1311.2524"&gt;2013/11 Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1312.6229"&gt;2013/12 OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks (OverFeat)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1504.08083"&gt;2015/04 Fast R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1506.01497"&gt;2015/06 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1506.02640"&gt;2015/06 You Only Look Once: Unified, Real-Time Object Detection (YOLO)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1512.02325"&gt;2015/12 SSD: Single Shot MultiBox Detector (SSD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1612.08242"&gt;2016/12 YOLO9000: Better, Faster, Stronger (YOLOv2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1703.06870"&gt;2017/03 Mask R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.02767"&gt;2018/04 YOLOv3: An Incremental Improvement (YOLOv3)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="sheng cheng mo xing  generative models"&gt;生成模型 Generative Models&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1406.2661"&gt;2014/06 Generative Adversarial Networks (GAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1511.06434"&gt;2015/13 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1701.07875"&gt;2017/01 Wasserstein GAN (WGAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1703.10593"&gt;2017/03 Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="qi ta zheng li_2"&gt;&lt;div id="collections"&gt;其他整理&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊列出其他優質的資源整理網站 / Github Repo，供你繼續探索深度學習。&lt;/p&gt;
&lt;h3 id="deep-learning-ocean"&gt;&lt;a href="https://github.com/osforscience/deep-learning-ocean"&gt;deep-learning-ocean&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;整理了不少深度學習資源，但最值得參考的是數據集以及論文的分類整理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dai ban shi xiang_1"&gt;待辦事項&lt;/h2&gt;
&lt;p&gt;還有不少內容正在整理，以下是目前我們打算增加的一些項目：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;深度學習中英術語對照表&lt;/li&gt;
&lt;li&gt;值得追蹤的業界 / 學界影響人物清單&lt;/li&gt;
&lt;li&gt;無圖的資源列表版本&lt;/li&gt;
&lt;li&gt;一些 Jupyter Notebook 範例&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而我們也會持續將新資源加入如&lt;a href="#tools"&gt;實用工具&lt;/a&gt;、&lt;a href="#blogs"&gt;優質文章&lt;/a&gt;等列表裡頭。&lt;/p&gt;
&lt;h2 id="ru he gong xian"&gt;如何貢獻&lt;/h2&gt;
&lt;p&gt;非常歡迎你一起加入改善這個 Repo，讓更多人有方向地學習 Deep Learning：）&lt;/p&gt;
&lt;p&gt;如果你有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他值得推薦的深度學習資源&lt;/li&gt;
&lt;li&gt;針對此 Repo 內容的改善建議&lt;/li&gt;
&lt;li&gt;其他任何你想得到的東西&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都歡迎你&lt;a href="https://github.com/leemengtaiwan/deep-learning-resources/issues/new"&gt;提出新的 Issue&lt;/a&gt; 來讓我們知道。&lt;/p&gt;
&lt;p&gt;如果是想增加新資源的話，只附上連結也是沒有問題的，謝謝！
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 2rem"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="/images/general/maxwell-ridgeway-685077-unsplash.jpg"&gt;
&lt;br/&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
        最後，如果你覺得本文實用，還請幫我分享此文並給 &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank"&gt;Github Repo&lt;/a&gt; 一個小星星。
        這樣可以讓更多人注意到這些寶貴資源的存在並開始有方向的學習，謝謝！
    &lt;/p&gt;
&lt;p&gt;
        有再多資源，沒有親自動手做都是無法真正地學到東西的。因此，最後的最後讓我再次強調主動學習的重要：
    &lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                            告訴我資訊，我只會忘記；教導我知識，我會記得；讓我實際參與，我將能真正地學到東西。
                            &lt;br/&gt;
&lt;span style="float:right"&gt;── 班傑明&amp;middot;富蘭克林&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem"&gt;
&lt;p&gt;
        所以，現在就開始學習吧！
    &lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;</content><category term="深度學習"></category><category term="Python"></category><category term="Keras"></category><category term="TensorFlow"></category></entry><entry><title>進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南</title><link href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" rel="alternate"></link><published>2018-12-24T08:00:00+09:00</published><updated>2018-12-24T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-12-24:/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html</id><summary type="html">&lt;p&gt;在此文中，我們以一個假新聞分類的 Kaggle 競賽做為引子，不用深奧的數學計算式，而是直觀且高層次地理解目前常見的 NLP 手法以及基本的深度學習、機器學習概念。透過建立一個能夠分類假新聞的神經網路，你將會學到如文本數據前處理、循環神經網路以及深度學習 3 步驟等基礎知識，並在未來利用此基礎進一步探索 NLP 世界。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        希望這篇文章能成為你前往自然語言處理世界的最佳橋樑。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;自從&lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html"&gt; 11 月從比利時 EMNLP&lt;/a&gt; 回來後，最近工作之餘都在學習&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"&gt;自然語言處理&lt;/a&gt;（Natural Language Processing, 後簡稱為 NLP）。&lt;/p&gt;
&lt;p&gt;上上週陰錯陽差地參加了一個 &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 競賽。在該比賽中，我實際應用到不少前陣子所學的 NLP 知識，也獲得不少心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/nlp-word-cloud.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此我想借此機會，在文中鉅細靡遺地介紹自己在這次比賽運用以及學到的 NLP 概念，希望能幫助更多對人工智慧、&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;或是 NLP 有興趣但卻不知如何開始的你，在閱讀本故事之後能得到一些啟發與方向，並展開自己的 NLP 之旅。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/chris-ried-512801-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然不是必備，但有點程式經驗會讓你比較好理解本文的內容，因為在文中有不少 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 程式碼；另外，如果你熟悉&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;以及&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;神經網路（Neural Network）&lt;/a&gt;，那你可以趁機複習一些以前學過的東西。&lt;/p&gt;
&lt;p&gt;依據維基百科，NLP 的定義為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        自然語言處理（NLP）是計算機科學以及人工智慧的子領域，專注在如何讓計算機處理並分析大量（人類的）自然語言數據。NLP 常見的挑戰有語音辨識、自然語言理解、機器翻譯以及自然語言的生成。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文章裡頭，我將描述如何利用最近學到的 NLP 知識以及深度學習框架 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 來教會神經網路如何辨別眼前的假新聞。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/robot-read.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管此文的 NLP 任務是假新聞分類，你將可以把從此文學到的基礎知識運用到如機器翻譯、教機器寫詩、語音辨識等大部分的 NLP 任務。我也會在文末附上&lt;a href="#3-門推薦的線上課程"&gt;推薦的學習資源以及文章&lt;/a&gt;供你進一步探索。&lt;/p&gt;
&lt;p&gt;如果你已經準備好展開一趟刺激的 NLP 冒險之旅的話，就繼續往下閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本文章節"&gt;本文章節&lt;a class="anchor-link" href="#本文章節"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="toc-href" href="#30-秒重要訊息" title="30 秒重要訊息"&gt;30 秒重要訊息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#意料之外的-Kaggle-競賽" title="意料之外的 Kaggle 競賽"&gt;意料之外的 Kaggle 競賽&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#假新聞分類任務" title="假新聞分類任務"&gt;假新聞分類任務&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#用直覺找出第一條底線" title="用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a class="toc-href" href="#資料前處理：讓機器能夠處理文字" title="資料前處理：讓機器能夠處理文字"&gt;資料前處理：讓機器能夠處理文字&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#有記憶的循環神經網路_1" title="有記憶的循環神經網路"&gt;有記憶的循環神經網路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#記憶力好的-LSTM-細胞" title="記憶力好的 LSTM 細胞"&gt;記憶力好的 LSTM 細胞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#詞向量：將詞彙表達成有意義的向量" title="詞向量：將詞彙表達成有意義的向量"&gt;詞向量：將詞彙表達成有意義的向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#一個神經網路，兩個新聞標題" title="一個神經網路，兩個新聞標題"&gt;一個神經網路，兩個新聞標題&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a class="toc-href" href="#深度學習-3-步驟" title="深度學習 3 步驟"&gt;深度學習 3 步驟&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#進行預測並提交結果_1" title="進行預測並提交結果"&gt;進行預測並提交結果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#我們是怎麼走到這裡的" title="我們是怎麼走到這裡的"&gt;我們是怎麼走到這裡的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#3-門推薦的線上課程" title="3 門推薦的線上課程"&gt;3 門推薦的線上課程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#結語：從掌握基礎到運用巨人之力" title="結語：從掌握基礎到運用巨人之力"&gt;結語：從掌握基礎到運用巨人之力&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文編排已將手機讀者放在第一位，但我仍然建議你使用較大的螢幕閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/toc-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用畫面左側的章節傳送門能讓你更輕鬆地在各章節之間跳轉（目前手機不支援，抱歉）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="30-秒重要訊息"&gt;30 秒重要訊息&lt;a class="anchor-link" href="#30-秒重要訊息"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;沒錯，光看上面的章節數，你應該了解無法在 10 分鐘內 KO 這篇文章，但我相信這篇文章會是你學習 NLP 基礎的最短捷徑之一。&lt;/p&gt;
&lt;p&gt;針對那些時間寶貴的你，我在這邊直接列出本文想傳達的 3 個重要訊息：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;深度學習發展神速，令人不知從何開始學習。但你總是要&lt;a href="#3-門推薦的線上課程"&gt;從某個地方開始好好地學習基礎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NLP 接下來的發展只會更加快速，就連一般人也能弄出厲害的語言處理模型&lt;/li&gt;
&lt;li&gt;站在巨人的肩膀之上，活用前人成果與經驗能讓你前進地更快，更有效率&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這些陳述看似陳腔濫調，但希望好奇心能讓你實際閱讀本文，找出構成這些結論的蛛絲馬跡。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="意料之外的-Kaggle-競賽"&gt;意料之外的 Kaggle 競賽&lt;a class="anchor-link" href="#意料之外的-Kaggle-競賽"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 是一個資料科學家以及機器學習愛好者互相切磋的數據建模和數據分析競賽平台。&lt;/p&gt;
&lt;p&gt;本文提到的 Kaggle 競賽是 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge"&gt;WSDM - Fake News Classification&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;此競賽的目的在於想辦法自動找出假新聞以節省人工檢查的成本。資料集則是由中國的手機新聞應用：&lt;a href="https://www.toutiao.com/"&gt;今日頭條&lt;/a&gt;的母公司&lt;a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8"&gt;字節跳動&lt;/a&gt;所提出的。（知名的抖音也是由該公司的產品）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/wsdm-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文的 Kaggle 競賽
                        （&lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而因為我所任職的 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 主打產品也是手機新聞應用（主要針對日本與美國用戶），像是這種哪個企業又辦了 Kaggle 競賽、又開發什麼新功能等等的消息都會在公司內部流動。&lt;/p&gt;
&lt;p&gt;話雖如此，在我從同事得知這個為期一個月的競賽時，事實上離截止時間只剩一個禮拜了！（傻眼）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-entrance.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        今年 10 月底參加的 EMNLP
                        （&lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但心念一轉，想說從 &lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html"&gt;EMNLP 會議&lt;/a&gt;回來後也學了一些不少 NLP 知識，不仿就趁著這個機會，試著在一週內兜出個模型來解決這個問題。&lt;/p&gt;
&lt;p&gt;名符其實的「志在參加」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="假新聞分類任務"&gt;假新聞分類任務&lt;a class="anchor-link" href="#假新聞分類任務"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;既然決定要參加了，當然得看看資料集長的什麼樣子。訓練資料集（Training Set）約有 32 萬筆數據、測試資料集（Test Set）則約為 8 萬筆。而訓練資料集一部份的內容如下所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/view-data-on-kaggle.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要了解此資料集，讓我們先專注在第一列（Row），大蒜與地溝油新聞的每一個欄位。&lt;/p&gt;
&lt;p&gt;（部分讀者可能會對簡體中文表示意見，但請體諒我沒有辦法事先將此大量數據全部轉為繁體）&lt;/p&gt;
&lt;p&gt;第一欄位 &lt;code&gt;title1_zh&lt;/code&gt; 代表的是「已知假新聞」 A 的中文標題：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;用大蒜鉴别地沟油的方法,怎么鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而第二欄位 &lt;code&gt;title2_zh&lt;/code&gt; 則是一筆新的新聞 B 的中文標題，我們還不知道它的真偽：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;翻炒大蒜可鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要判斷第二欄中的新聞標題是否為真，我們可以把它跟已知的第一篇假新聞做比較，分為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;unrelated&lt;/code&gt;：B 跟 A 沒有關係&lt;/li&gt;
&lt;li&gt;&lt;code&gt;agreed&lt;/code&gt;：B 同意 A 的敘述&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disagreed&lt;/code&gt;：B 不同意 A 的敘述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果新聞 B 同意假新聞 A 的敘述的話，我們可以將 B 也視為一個假新聞；而如果 B 不同意假新聞 A 的敘述的話，我們可以放心地將 B 新聞釋出給一般大眾查看；如果 B 與 A 無關的話，可以考慮再進一步處理 B。（這處理不在本文討論範疇內）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/chris-liverani-552022-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        如果 B 新聞「同意」假新聞 A 的話，我們大可將 B 新聞也視為假新聞，最後將其屏除
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著看到資料集（下圖）第一列最右邊的 &lt;code&gt;label&lt;/code&gt; 欄位為 &lt;code&gt;agreed&lt;/code&gt;，代表 B 同意 A 的敘述，則我們可以判定 B 也是假新聞。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/view-data-on-kaggle.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是一個簡單的「假新聞分類問題」：給定一個成對的新聞標題 A &amp;amp; B，在已知 A 為假新聞的情況下，預測 B 跟 A 之間的關係。其關係可以分為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unrelated&lt;/li&gt;
&lt;li&gt;agreed&lt;/li&gt;
&lt;li&gt;disagreed&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;順帶一提，上圖同時包含了 3 個類別的例子供你了解不同分類的實際情況。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第 3、 4 欄位則為新聞標題的英文翻譯。而因為該翻譯為機器翻譯，不一定能 100% 正確反映本來中文新聞想表達的意思，因此接下來的文章會忽視這兩個欄位，只使用簡體中文的新聞標題來訓練 NLP 模型。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;a class="anchor-link" href="#用直覺找出第一條底線"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在任務目標很明確了，我們就是要將有 32 萬筆數據的訓練資料集（Training Set）交給我們的 NLP 模型，讓它「閱讀」每一列裡頭的假新聞 A 與新聞 B 的標題並瞭解它們之間的關係（不相關、B 同意 A、B 不同意 A）。&lt;/p&gt;
&lt;p&gt;理想上，在看過一大堆案例以後，我們的模型就能夠「學會」一些法則，讓它在被給定一組從來沒看過的假新聞標題 A 以及新聞標題 B 的情況下，也能正確判斷新聞 A 與新聞 B 的關係。&lt;/p&gt;
&lt;p&gt;而所謂的「模型從來沒看過的數據」，指的當然就是 8 萬筆的測試資料集（Test Set）了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/Train-Test-Split-Diagram.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們利用訓練資料集教模型學習，並用測試資料集挑戰模型
                        （&lt;a href="https://elitedatascience.com/model-training" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣的陳述是一個非常典型的&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習（Machine Learning, ML）&lt;/a&gt;問題。我們當然希望不管使用什麼樣的模型，該模型都能夠幫我們減少人工檢查的成本，並同時最大化分類的準確度。&lt;/p&gt;
&lt;p&gt;但在開始使用任何 ML 方法之前，為了衡量我們的自動化模型能提供多少潛在價值，讓我們先找出一個簡單方法作為底線（Baseline）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAB7HUlEQVR4nO3dd3xW5f3/8de5d+4kZCfMhD3CEIKICIoKWnEB7m1b66rfWrW29ds97U/br53O2traOqqigCBSQFxMAQEhjISVkEASsuc9z+8Pek7vkDBsUQL3+9mHj5J7nPucc5+c8851fa7rGKZpmoiIiIjEEceJXgERERGRz5sCkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbijACQiIiJxRwFIRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3HGd6BU4UaLRKNFo9Jhf73A4cDj+87wYDoftfzudTgzD+I+X9Z+yttkwDEzTPOI2xe6f/3bbTyamadr7yNrmzh47VCQSwTRN4OTaX9a2WRwOR4djMxqNYpqm/bhhGPYxZL33SPvmRDqW7ROR+GSY1llb4lLshS3eRaPRY7qIH+vrTgUnw/FxsoZPETmx4i4AWSf0hQsXsm3bNrxe7xFbghwOB21tbYwePZrJkyd/qguC9dqWlhZee+01wuEw4XCYKVOmMGDAgM/tQmp9zrp161i6dCmJiYm0tLQwatQopk6d2m6brH+/9dZbFBUVYZomQ4YMYdq0aSfFxfA/ZW1bbW0tCxYsYOvWrdTX1xOJROjWrRvp6elMmjSJM888s93rLbNnz6akpIRIJMKoUaOYMmVKl95f1rqVl5fz97//3W4pufrqqxk4cGC7dd+1axcLFiygvr6e1tZWTjvtNK688ko2bNjAm2++idvtxu12c8cdd5CUlNQltvvTbJ+IxKe47QKbM2cOr7/+OikpKUQikcMGEZfLRU1NDbfddtunDkCWhoYGHn30Udra2mhrayMzM5MBAwbweWVPKwCtXLmShx9+mOzsbFpbW8nJyWHIkCH07t27QxibPXs28+fPxzRNZsyYwbRp0z6XdT0RrG2fM2cOv//97yktLcXhcOByuTAMg0gkQjgc5vnnn2fcuHE89NBDDBo0qN0+e/XVV/nggw8IBoPccsstJ00AOnDgAH/5y18wTZNwOMyECRMYOHAgkUgEl8vFtm3buP322ykvL8fr9VJXV8dVV13FlVdeSVFREc8++ywJCQn4fD5uuukmkpKSPvdtefvtt9m9ezfRaJSRI0dy9tlnE41GcTqdh92+rvzdiMjnI24DULdu3cjKyqJbt26Ew2FaWlo6DSROpxOv14vT6ezwnGma7d4TWyMRyzAM0tPTCQaDtLW14fF4Oizn0Ncfy2d92hN4QkICWVlZpKenA1BdXc3TTz/Nz372sw7rkJycTFZWFqZpkpyc3OnyDl0noNMg2dk+6uy5Q58/2n6xPr+z+pRjZYWY559/np///Of4fD4yMjJoa2ujpaWFaDSKy+UiJSUFwzBYtmwZd999N0899VS7C2lKSgqZmZmEQqHDhoBjPV6O9J5j3cZD982n3S/WZ7788suUl5eTk5NDMBgkFArh9/s7vO5Y1uU/Wf+jvcc0TV5++WUWL15MOBzm1ltvZdKkSXYAOlax+yv28w63np19j8fjd1REPj9xG4Csv+pDoRCGYXDBBRfg8/nsYleL1YU1atQo++dDT5KdLfvQk6/1eeFwuN1J8mh/iR7ps2KfOxbRaJRwOGyvS3JyMvPnz+eKK66goKCgXUuY9dpDi0hjl3W4gtJDW5OOtH7/yXPWheZwn9/Z/u+MtZ4rVqzgl7/8JcnJybhcLmpraxk8eDBnnXUWSUlJVFVVsXjxYhoaGkhPT2fv3r389Kc/5dlnn8XlctmfaX2/h+6vY1nfzp6ztuNw+7izYyL2ezlcYIz9rIyMDG655Rb783r16gVgb1dJSQkJCQm0tLTQr18/Hn30Ufr27QvA4MGDufPOO+0usNhgdLTtjn3ucNt1LN+tFT6zsrLsY9owDPs1GRkZ3HrrrZim2W77Ypd9pGM59vlYR9rvR3uviHQNcRuA4OBJLBqNkpCQwM9+9rMOJ/AjvQ+goqKCqqoqWlpa8Pl8pKam0rt372P+y9MKP5FIhLa2NhwOhz3iJikpqd3Jc//+/ZSVlREIBEhISKBnz57k5OS0W86n5XQ6aW5u5vHHH+eZZ575VLVNDoeDlpYWdu7cSWNjIw6Hg8zMTPr374/D4bDXKRAI0NLSYgfHpKQk3G63vZz6+noA+3tISEiwP6e1tZXW1lZ7H1itMNZ/1dXVVFRUUFlZSUJCAmlpaeTm5uLz+Y5pn1j7/tlnnyUSieB2u2lqamLSpEk8/PDDZGVl2a+99tpr+eY3v0lZWRmZmZmsXbuWJUuWcNFFFx2xhiy2BcZa36amJjweD6mpqfTs2bNDi6D1PqfTSSAQYO/evVRWVhIKhUhPTycnJ8det0Prt6x9VVpaSmVlJQ0NDaSlpZGRkUGfPn3s78F6T8+ePXnggQfsz7WCj2matLa2sm/fPjweD83NzRQUFHDeeefZrx01apT9h8Gh+zV2u6uqqti3bx9tbW1069aNtLQ0cnJyOqxL7PqXl5dz4MABWltbSUxMbPe7Zb3HCuehUMgOn6FQyC6Kdjgc9OzZk/vvv7/D9h36ma2trRQXF7Nv3z5aW1tJT0+nT58+9O3bt93xbGlubiYSiQDg9Xrxer3U19dTWlpKOBymW7du5OXltVtfEela4joAxWppacHtdnd6soodWWIYBqWlpfzud79j2bJlRCKRds3tAwYM4PLLL+fqq68+6knP5XJRUVHBvffeS0VFBW63m8bGRn74wx8ybdo0HA4HFRUV/O53v2Pp0qWEQiH7hO3xeDjnnHP42te+Ro8ePT71Sda6wCUnJ7NixQoWLFjApZdeesTWk9gWp5dffpnnn3+eqqoq+3nDMBg0aBB33303kyZNwjRN1qxZw4MPPojP56Ouro4HH3yQG2+8ETh4kbvlllsIhUI0NTVxzTXX8NBDD9nB7zvf+Q7Lli3D6XSSn5/PM888g9PppKmpiT/96U+8/vrrBAIBgsGgfWHr0aMH119/Pdddd90RW8iszygqKmL9+vUkJiba9VmPPPII6enphMNh+0I7bNgw7rnnHu6++26CwSDV1dW8++67XHTRRe32zaH7y+FwUFNTwx/+8AcWL15MIBCwHzdNk969e3PxxRdzww03kJCQ0G6d33nnHR5//HFKS0vti73T6cTv93POOedwzz33kJOT0+49W7Zs4Xe/+x0ff/yxHQ48Hg8Oh4MxY8Zwxx13MHr0aPt73rJlC3feeafd4vfYY48xceJEfvOb37Bs2TJqa2sxDAO/38/SpUtZv349Y8aM4bvf/S5vv/02P/rRj/D5fHg8Hv7617/So0cPe99WVVXx+OOPs2TJknbb7XK5mDBhArfeeisjR45st/5bt27l97//PevWrbOnYnA6nTgcDoYOHcqVV17JJZdcAsDf//53Xn/9daqqqvB6vbjdbt5//32uu+46Jk6cyH333UdhYSF33nmn3QL02GOPcdZZZ7VrdXv11Vd57rnnqKioIBKJ2GHY5XIxZswY7r//foYOHWpvl2ma3HfffWzevJmWlhbuvfdeevfuzSOPPEJjY6P93ffv358HHniA8ePHKwSJdEEKQBw88WZkZBy1K8owDOrr6/n617/Ohg0bSE9Pp7W1lUAggMPhwO/388knn7B8+XIOHDjAPffc0+myrFaehoYG7rvvPjZs2EBSUhL19fXce++9dsHx/v37ueuuu9i0aROpqam0tbURDAbtkWuvvPIKmzdv5umnn6Z79+7HfJKNRCIkJyfTt29f1q9fj8fj4emnn+bcc88lMTHxqPvq0Ucf5ZlnniEpKcnuInQ4HCQmJrJhwwbuuOMOfv7znzNz5kz69++PYRg0NDTQ2NjI9u3b7WXt3LmTyspKPB4PgUCAdevWEQqFcLvd1NbWsmbNGkKhEDU1NQwcONBuEfnud7/L3LlzSU1NtT87HA6TmJjInj17+N73vkdjYyO33377YWtUrMdXrlxJc3Mz6enpNDQ0cMMNN5Cenm4XAVuvjUajTJ48mf/3//4fkUiEUChE//79gc7rnqx9FQwGefDBB1m6dCkZGRkEg0FaW1vtULFjxw5+8pOfUFxczMMPP2xf8OfMmcO3v/1tPB6PHWQAu0Xh73//Ozt27OCJJ56gW7duGIZBUVERd911FxUVFXi9XlpbW3E6nbS0tJCUlMSSJUv45JNPePrppxk2bJh9LDQ3N9tFwtZ8VYWFhbz33nv069fP/tyqqio2bNiA1+sFDrbQ1dbWkpCQgMfjsVtErFafu+++m48//pi0tDTC4TCBQAC3243H4+HNN9/k/fff58knn2Ts2LHAwe62e+65h9LSUrp160ZLSwuhUMgOfatWreL999+nsbGR6667ju3bt/POO+8wcOBAu9urrq6OjRs3kpGRAdCuvi92+6zflSeeeIJf//rXJCYm4na7aWtrs8OR0+nkvffeo7CwkKeeeorhw4fbXXfNzc3U19fjcrmYPXs2+/bto7a2Frfbjc/nw+VysXHjRr7+9a/z/PPPM3jwYHWHiXQxcR2ArJNgMBjkt7/9LX6/v8Okaa2trYwbN44JEyYAMGvWLD755BO6d+9OY2MjBQUFjBkzxm4RsE7yr776KjfccANpaWkdan6suo7vfe97rF27lqysLKqrq7ntttv42te+Zr/+4YcfZvPmzWRnZ9PU1ERBQQHDhg1j48aNbNq0iZycHAoLC3n00Uf5v//7v2Pa5tgapvvvv59vf/vbVFZWUlRUxAsvvMCdd9552Pc6HA7eeust/vSnP5GZmUlraytZWVlMnDiRxsZG3n33XRISEgiHwzzyyCOMGTOGvn37MmbMGN577z2SkpLYsmULgUAAr9fLhg0baGtrs+s2SktLqaiooHfv3pSWltLW1obb7SYpKYmzzjoLgMWLF7Nw4UK75ePSSy9l2LBh1NTU8Oabb1JRUUFycjLPPPMMM2bMsAu5OytMB9i7d6/d0uD1eu2/1g99rRVYrrvuusPu187219tvv82HH35Iz549aWxsZPDgwZx55pm0tLTw3nvvUVdXR05ODosXL+auu+4iLy+P+vp6fvvb3+Lz+eyWD6ul6cMPP2TFihXk5OSwfPly5s+fzw033ADAH//4R/bv309KSgoZGRlcdtllpKSksGXLFhYsWEBqairl5eW88MIL/PznP7fX0+Vy2dtsXaAvvPBCevTowfvvv09TUxOhUIihQ4dyzTXX2DVATqfTrv+xujWtffHYY4+xfv16unfvTkNDA7169WL06NFs3bqVXbt2kZ2dTU1NDU8++SRPP/00TqeTv//975SUlJCdnU1LSwuTJ09myJAhlJWV8d577+HxeHA6nbz88stcddVVTJo0iXA4zMcff0xlZSXRaJT+/ftz+eWXk5+fb29P7PZZ35PL5WLZsmX84Q9/IC0tzW4Bmzp1KtnZ2axbt45t27aRnp5OdXU1P/7xj/nrX/9KQkKCHVKdTicJCQns2bMHgHPOOYesrCxWrlxJfX09aWlpVFVV8cYbb/Dtb3/7cxv1KSLHJq4DEBw8QYZCIZ588skOJyiXy8WBAwf42te+Zl+AN2zYYHdrjBgxgmeeeQafzwfAs88+y6OPPmq31tTV1ZGWlmYvz1q+1+vl6aefZsGCBWRnZ1NVVcUVV1zBt771LbtrYuvWrSxfvpz09HTq6+uZPn06P/nJT3C5XAQCAb7//e/z1ltvkZ6ezgcffEBxcXGHodlH2ubW1lb69evHl7/8Zb7//e/TrVs3/v73v3PxxRfbw+IPXe9IJMI//vEP3G43oVCI7t2789RTT9mtBPPnz+d73/sePp+P6upq3njjDe6//35GjRrF4sWLSUhIoKSkhMrKSvr06UN5ebm9PYZh0NbWxs6dO+nduzcff/wxjY2NJCUlkZ6ezogRIwBYv349AKFQiKysLH7605/a61lQUMDXv/51uzWiqKjoqAEoEAjgdDrtAGS1BB5uxJG1X6zunKPt63Xr1hGJRGhoaCArK4unn37abp1YsmQJ9913n12zVFVVRV5eHjt27KChoQG3200gEODOO+9k8uTJANx8881cffXVlJSUkJKSYreoNTQ0sH79epKTk6mvr+fKK6/kq1/9qr0eTqeTN954g+zsbLZu3Upzc7Pd2nfoCCiAa665hmuuuYZrr72W7du309rayvjx4/nGN77RYZ8c+v7du3fzzjvvkJaWRmNjI/n5+fzmN7+hR48e1NXV8bWvfY0PPviAxMREVqxYQUlJCf369WPdunV4vV4qKyu58MILefzxx+3P+cUvfsFzzz1HSkoKVVVVNDQ08IUvfIEvfOELfO1rX6OsrIxwOExBQQHf+9732n3Pna1jNBrl73//O/Dvc8BPfvITLrvsMnt/fuc732Hp0qWkpqayceNGFi1axOWXX24H5thlfvOb3+Smm27CMAzWrFnDV7/6VcLhMG632+4mVuuPSNcS9wEIDp4kY+t/rJOky+XC4/G0G+nz5S9/meuvvx6fz0f37t3ti31FRQVr1qyxu6esgmb4d4AwTRO/389zzz1HUVERaWlpNDQ0cP755/PDH/7QLsqGg10zTU1NdOvWDb/fz6233moXHickJHDLLbewZMkSABobG1m5ciWDBg065r8yrQLoGTNm8Morr1BcXExTU5M9LD6WtcyKigq2b9+O3++nrq6Om266iX79+tHW1obL5eKSSy7h9ddfZ/Xq1Xi9XjZv3gzAxIkTefrpp+26o927d9OnTx82bdqEYRj07NmT+vp6ysrK2LBhA+eccw47duzAMAxaW1s599xz7dBgFbhaF5avfOUrTJw4kYKCAvLz81myZAkOh4PGxka6desGHPnCE9slYnW1HOk4+TQXMdM0ue6667jwwgtJTEy0i5Hr6uo4cOAAH3zwQYfbbcC/u0it1otf/vKXrFq1inHjxpGfn8+f//xnu2vLen8kErG7epKSkpg/fz6NjY2MGzeO0047jQceeIBvfvObdpeQ1Y11OFaLSOy2WwXGoVDIDv2Hvgdg1apV9v43TZPbb7+dHj16EAwGSU1N5c4776Rbt24kJSXZNTcA3/jGN3C5XLhcLnJzc4lEItTW1rJ3714KCwvtUZpWHU5nwc0ahWfV8RzOvn372LBhA4mJidTX13PJJZdw2WWX2e/t1q0b3/jGN1i5cqW9H1atWsXll1/ebvqC1tZWCgoKuPnmm+19cPrppzN27Fg++OADe1Sh9XoR6TriPgBZF76LL764wzB4wzBobm5uN9LltNNOIxwOM3/+fObOncuuXbvYs2cPjY2NtLS0kJiYaJ/QD2fTpk323ELBYJBhw4aRkJBAJBJpN8LM+tk0Tb773e+2a36vq6vD6XTak/VVVFR86m0Ph8N4PB7uuece7r33XpKTk5k3bx7XXXcdycnJHaYEqKmpsYfGJyYmsmjRIrtY1QpvZWVldldiSUkJbW1tDBo0iF69elFeXk5zczObNm3itNNOY//+/ZimycyZM1myZAklJSX2Y9Ys3cFg0K4RARgzZgx//etf7QvcypUr+fDDD0lKSiI1NZUJEybwhS98gUmTJh31ez80+IbDYRoaGo74vk9zEYtGowwdOhQ4OFnf/Pnz2bVrF7t377Zrovx+v30Rt5bdv39/e7i91W317LPP8uKLL5KQkMCIESM4//zzmTFjhn1MpKWlMXbsWObOnUtOTg6tra289tprzJkzB7/fT9++fTnnnHOYPn06vXv3blevc7jt7Gzot9PpPOrxXVpaSigUIhqNkpyczODBgzFN0+6KmjRpUofvxzRNJkyYQHNzMwsWLGDOnDkUFxezd+9eGhoaCAaD+P3+dtNIdNZSZ6334UbmxYb5YDBob8/IkSPtlh3rmMjNzaV///5s27YNt9ttH5vWfrFmibfmg4oNZ1b4E5GuK64DUOww+B//+MfthmAfygoeW7Zs4cEHH2Tbtm1207nT6SQtLY20tDQCgcBRPzchIcF+XXJyMi+88ALTpk1j8ODB9l+b4XC43Zw8H330UYf6JJfLhdPppKamxh598mlYyz/33HM5//zzWbx4MQ6Hg9///vd2vUXsfZba2trssONyuSguLmbjxo3tLkLWOllFry0tLaSnpzN27FiKi4vxeDzs27ePLVu20NbWRmJiIpMnT6a0tJRly5bZNSJlZWX2/rFuPxGNRpk2bRqFhYW8+OKLNDc34/f77Ykaa2treeWVV3j11Ve55ppr+N73vofb7T5sdxaA3++3ux2bm5vZt28fo0aN6vTiFY1G2b9/v91Ck5CQQGZm5hH3b2lpKQ8++CBr1qzB6XTa806lpqaSnp5OW1ub/XprPdPT0/nf//1ffvrTn1JWVobT6bQLncPhMCtWrOCdd97h5Zdf5rHHHmPAgAFEIhHuv/9+ampq+Oijj+yQahVNb926lbVr1/K3v/2NH/zgB1x88cXHfqAcI2v9Q6GQHQQcDgder7fdHxWH1uNY4e+9997jBz/4AeXl5fZy3G43GRkZ+Hw+gsHgf72O1me3trbaxc5er5esrCx7na11czqddO/encLCQvv46Kw79dC5mmK3UUS6rrgOQLHa2trwer2HrRexiqV//OMfU1xcTGZmJtFolHPPPZeRI0cyduxYtmzZwo9//ONO53WJXVZrays9e/bkwIEDuFwuGhoa+MMf/sDvfvc7+3Wxzfwej4f777/frhWBf7dcWfU8Y8aMsd/3aRmGwT333MPy5csxTZOPPvrIHtXW0NBg7w9rODUcvDhdfvnldmizTvrWxSAajeL3++1QOXbsWGbNmoVhGBQWFpKQkEBraysZGRnk5eXZcxo1NDTw4Ycf2nO6jBw5kj59+rSrufn2t7/Nddddx1tvvcVHH33Etm3baGxsJBQKkZqaChwcIj1y5EiuvvrqIw7tHzJkiN1VEo1GWbx4cYeh7dZf9oWFhdx+++24XC7q6uq45ZZb+OY3v3nY1gbDMPjNb37DRx99RPfu3QmFQpx11lmMHj2a0aNH09zczAMPPNCu5c9y/vnnM2nSJBYsWMAHH3zAhg0bqK6utmt3unXrRmFhYbsJGfv27cvf/vY3Vq5cyeLFi1m9ejX79u2jsbERt9tNdnY2DQ0NPPLIIxQUFNC9e/cjzmH0aVn7yxq5Zj0WG6Jjf79iW77q6+v5+c9/zoEDB0hLS8PlcjFlyhSGDRvGmWeeyezZs3nqqadISUn5r9bR+uyEhAT7WA0EAlRVVdnB1lo3K/BaNWKJiYkKNyKnEAWgf7GazjsLQNYFcN++fezcuZPU1FQaGxv56le/2m6o++rVq2ltbe20PgKwa3gmTpzIj370Ix566CHWrFlDSkoKS5YsYdGiRVxwwQUApKWltVuP22677bC3pDh0Oz6tSCTC4MGDueaaa3j22WftYcuHSklJsfdRc3Mzp512ml37cDSnn346ycnJtLa22t0aDoeD4cOH43K5GDlyJCkpKbS0tPDiiy/atSYFBQV210kwGGTdunV2d8oNN9zAXXfdxd69e9m0aRNLlizh/fffxzAMvF4va9euPex8TFaQGz9+PGlpabS1tZGUlMQ777zD8uXL7aJ3wA5Pf/3rX6mpqSElJcXusumMdYG0hvJnZGRQW1vLlVde2a6+aunSpbS0tNitUJbt27fbQ9nz8/OZPn06tbW1FBcXs2zZMt566y2qqqpITU1ly5Ytdo3Jli1b8Hg8JCUl8b3vfY+Wlhb27NnD6tWrmTdvHkVFRSQlJVFbW8vmzZvtqROOtz59+uByuXA4HDQ3N1NSUkLPnj3t0X/z58/n+eefJzk5mXA4zC9+8QvKysrYv3+/fYx861vf4qqrruqwT4/GCt9HCqUA2dnZuN1uwuEwTqeTTz75pF24d7vdlJSUsGvXLrxeLw0NDfbkjUfrAhSRk4OGJXwKdXV1wL8D0ejRo+3nWlpaWLJkiV1HBIefHO+yyy6jR48e3H777XYXhdPp5PHHH6epqQnTNBk3bhwJCQl2Qe/DDz/crgvg2WefZezYsUyePJmCggK7IPo//YveNE2+/OUvk5uba89KbYmdNbhPnz4EAgGSk5PtuWgsW7Zs4cILL2TSpEmMHj2ahx56yF6nnJwchg8fTjAYJBqNUltbSzQatUeQ5eXl4ff7aW1tpbKyEjjYPWWFDKv75wc/+AF33XUXN954I9/97ncxDIM+ffowbdo0fvWrX5Gbm0swGGxXB9JZALIulD179mTKlCk0NDTYxe4PPvggr732mt3isnv3br7//e+zcOFCOywNHDjQrk06tNXN+t7r6+vtdQmFQgwaNKjda2bPnm13KVrz1AC89tprfPGLX+Tuu+/m2muvZceOHaSlpTFu3Djuu+8+Lr30UpqamuzPdblcFBUV2YH86quvtmt/hg0bxq233sp3vvMd+7uwhnAfbt/8p6z1yc/PJzEx0W79+cMf/kBdXZ1d0/XKK6+wZs0aVq5cyaZNm0hLS6O2ttZ+vdvtpqCgwF6uVTAeO03F4QKR1f12pFZYODhh5siRI2lubqZbt24sWbKEefPm4XA47AlJ/+///o+Wlhb7uBg/fvwRP1tETi5x2wJkdWsdbshzZ6ybiFr1Ab/+9a+prq7G7XYza9Ys1qxZQ3Jyst2lceg9i2ILNK1i0KlTp7JgwQLS0tLYsmWLPRfPyJEjGTNmDMuWLSMzM5P58+dz4MABTjvtNPbs2cPixYvtyen69u1rX4yPtC2H22arVScjI4PbbrvNnt039j0Abrebq6++mu985ztkZ2ezf/9+7rnnHs4//3xM02TJkiXs378fr9dLU1MT55xzDvDvYuvRo0fz3nvv2Z+XkJDAyJEjAcjJyaFfv35s2rQJv99PIBAgOzub4cOHAwdbqfx+v92VlpmZybJly7j33nspKCjA6/WyadMmSktL8fl8NDQ02AXIR7oxpmma3HPPPaxevdoeWt7a2sqPf/xjuxaqsbGRxsZGu8XCMAweeughuwA59t5bsfsrNTUVt9tNS0sLycnJvPrqq/j9flJTU5k/fz5Lliyxb3kSW3R8+umn87e//Q2Px0NbWxsPPPAAU6dOJSsri6qqKt5++217Esjhw4eTmppK//79SU5OJhgMkpiYyP/93/+xefNm8vLyCIVC/POf/7SPPY/Hw8CBA9sdF4c7do72O9LZdufn53PWWWfxz3/+k/T0dNavX8+tt97K+PHjKS4uZsOGDfTs2ZP9+/fzpS99yb4BrRXMWltb+dGPfsT1119PIBDghRdeYOvWraSmphIMBjsUaFufm5iYyMqVK/nhD39IQUEB06dPb9eiG7uOTqeTm2++mQ8//ND+A+QHP/gBixYtIjMzkw0bNrB161ZSUlKoq6tj5MiRXHjhhfbvy+Hut3ak/SIiXUvcBqDYm1d21t0Ty7pw9OjRgzPOOIN58+aRnZ3Ntm3b+N///V+7u2bw4MFUVVXZQ5L37t1rt3DEflbsSfmuu+7ivffeo7W1lYSEBP785z9z/vnnM2jQIH7wgx/w9a9/na1bt5KcnMzy5ct59913cblcJCYm2rey+OEPf0hqaupR5wCy1jN26LfFaoWYOXMmc+bMYf369SQlJbW7uWc0GuXKK69ky5YtvPTSS/h8Pvbv38+zzz6LYRycKNAaofbVr36Viy++2O6uAjjzzDN55plnCAaDRCIRvF6vHVLcbjdDhgxh1apVJCQk2PO8HDoa7fbbb2fVqlWUlZWRnJzMokWLWLhwof0dJSYmUldXx7hx45g5c2a7UTudfa+maZKTk8Njjz3GN77xDYqLi0lOTiYhIYGmpiZ73yQmJtLU1EQkEuH73/8+Z555Zrv9Hfv9WvsrNTWVadOm8dRTT5GdnU1paak93UFjYyPDhg2jurqaaDRKS0sLu3fv5owzzuD888/nsssu49VXXyUjI4Pdu3fz+9//HpfLZd+N3Qpid955J4Zh0L17d+655x5+/OMf4/f7aWpq4i9/+YtdyG4VtdfX1/O///u/9O7d294265g89Ea9h9suizVUPrZg39qvd999N6tXr6a2tpbk5GT27NnDtm3bcLlcJCQkUF5ezhlnnMGXv/xlotEogwcPZtiwYXz00Uekp6ezbt06Pv74Y1pbW/F4PPTt25f9+/cDBwuYKyoq7D9IMjMzqauro3v37tTU1PDMM88wc+ZMpk+f3u6mvrHbFw6HOfvss7nnnnv4zW9+g9/vx+12s3jxYnt/JSQkUF1dTXZ2Nj/4wQ/sW5VY++xw+8X6XYv9XBHpeuK2C8wqJE1OTiY1NfWoxcPWyKcf/OAHTJ8+HcA+SWZkZPDggw/y5JNPkp6eTkpKCj6fjzfeeAM42EVhfZb1HGCHphtvvBGn00lWVhahUIhXXnkFgH79+vH8889z11132aOdkpOTSUxMxOFwcOaZZ/LHP/6R8ePHHzH8WOEhKSmJtLQ0kpOT6datmx1MrNeYponX6+V//ud/SE9Pt9fXmjDP2gc/+tGP+O1vf0v//v3xer32nC7WqJmf/OQnPPDAAx1G+wwZMoT+/fvj9/tJTExk4MCB7e5lNWTIEFJTU0lOTiY9Pb1dl4MVVvr3788TTzzB+eefj8vlIikpyb6JalpaGklJSXzxi1/kt7/9rT0J5dFaxaLRKPn5+fzlL3/hi1/8IikpKUQiEYLBIC0tLfaFrKCggGeeeYYbbrihwxQB1j6N3V/RaJT/+Z//4ZZbbrFH7Vnf4x133MGf//xn+vfvT0JCAunp6cyaNYvW1lZcLhc//OEPue+++0hMTMTr9ZKYmIjH4yEjI4OEhATGjx/PM888w3nnnWfvv5tuuonf/OY3DBgwwB6Z6PV6SU1NJTExkb59+/LII4/wla98xb5ou91uunXrZq97bNeRYRjtnjt0jiSfz0dKSor9GquVLRKJMGzYMPs2F9a+sm4a6nQ6ueaaa/jd735nf0dJSUk8/PDDnH322XY49nq99O7dmx/96Ec89thjpKam2kXus2fPto+NL3/5y8yYMcO+I32PHj3scHS47bOO93vuuYeHH37YDoTW57rdbhwOB+effz5//OMf7WHyVovOkfYL/Pv8Yv0nIl2PYcZph3YgELCHJBuGQUJCwqdqqt65c6c9QiQvL4/u3bsDB+8SbbFaRawJAK1d7fP57NofS3Nzc7umeqvewQo1NTU1VFRUsG/fPnw+Hz169LBblzor3O6MNTTd+ozOttlaVmtrq91V53a7O504LxgMUlZWRnl5OcFgkKysLDvgHG6dAoGAHSg8Hk+7C240GqW1tbXdPjhU7HLLy8vZu3cvNTU1+P1+MjMzyczMJDs7+1PtF+uzrX1dW1vLrl27qKiooLGxkczMTHJzc+1uo86Wa91DKna7Yl9XUlJCeXk5pnnwBqh9+vSx94dVtxI70shSV1dHWVkZ+/btwzRNsrKySE1NtW9HceioKmtUU1lZGTU1NdTU1NhD7nv16tWuFePQfQ7/PjaPtF2WIx1P1meYpklxcbE9B1Rqaiq5ubl24Ih9nfXebdu2UVVVhc/ns+dEAuyJHq0uq0OnrbDuHg8HA0h6evpRt8/63La2Nnbs2EFFRQWBQICUlBR69epFXl5ep9/5kfZL7PdqdYUfbmCEiJw4cRuA/lOHtmpYYv86PN6fd6RunM/iBovHEhyONLT8s77p49GW/59+F0fb18fy2Z0tEzoeL4d7/L9dlyN9L8fy/PF0pH3V2fYf7vVH+z6Pti//2/U82vcgIienuA1Ah272pz15xvb7x56cD7fcQ+ttPu36WCdiK5z8p2HraOtxrOsT+5pPs17Hsp3Hsn6xn3u4Qtf/VOxyY9flSBfBY/l+Yy/URzteDrcux7qPY7+bo+2bI637pzluj7Tdx7r+ne33//Z36FiOqf9kPY9lmUd7jYicOHEbgERERCR+qV1XRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbijACQiIiJxRwFIRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbjjOtEr0BWYpolhGPb/H4toNIphGPbrTdNst5zDcTgc9vs7E7vMY1332PWOXZ/Y/z/ScmNfc6ys9be2p7P1OZblHWlffZr1ERER+TQM80hXoDhwaOjpbHeciAuxaZpEo1GcTudhnz8e63W8lvNZfLYVpg4NWSIiIv+tuA5A0WgUh8PBhg0bePXVV5k8eTIXXHDBUd8XDAbZsWMHubm5vP3227S1tXHRRRexa9cu0tLS2LdvX4fgEolESE1NZcSIEYRCIbZt29bu4m4YBqFQiOTkZPr379/uvdu3b+fVV1/loosuYuzYse2CQ0tLCxs2bODjjz/mkksuIS8vj3A4TCQSoaWlhT179rBx40ZCoRC33HILbre7XbB49913WbVqFddeey19+/YlGAzyxBNPkJSUxJe+9KUO4cMwDKLRKHPnzsXpdHLJJZfgcDjsfVlcXMySJUuYPHkyQ4cOtR/vbL8vW7aMVatWMWPGDHr16kUoFLL3m2EY+Hw+e/tfeeUVpk2bxtixYztdpoiIyKcRt11g1kW0pqaGv/3tb+zdu5fm5mZ27txJOBzG4XDgcDgwDIMZM2aQnZ1tv6eqqopf/OIXTJ8+ne3bt1NbW0tzczNr164lPz+f5cuXk5CQ0K5LLBAIkJ+fz4gRI2hoaOCJJ56gqamJUCgEYH/esGHD+M53vsO2bdsoLS1l8uTJNDQ0sGLFCkaOHMnYsWMJh8PMnTuXwsJCSktLqaurw+Fw0Lt3b+rq6njppZdobm6mqamJ1tZWHA4HKSkpnH322QwePNgOP+FwmPfff5+NGzcydepU+vbtSyQSYfPmzWRkZBy29SkSibBgwQISExO5+OKLgX+3nJWVlfHGG2/Qp08fhg4desQWtdWrV7NmzRr2799PY2MjHo+HYDBIMBgkIyODG264AZfLRVNTE6tWrWLUqFF2ABQREflvxGUAsgJAW1sbf/rTnzhw4AC9evUiGo2yevVqfD4foVCI1tZWAKZNmwZgh5levXoxadIktmzZgsvlwuv14na7mTp1Kueffz6TJ0/G5XLx2muvUVVVxW233Ybb7cbv99vLiUaj9O/fnwkTJtjdXbNnz7bX8f3332fhwoWcfvrpeDwe/H4/brcbOBhA3n33XUKhEGeccQa5ubmMHDmSHj16sGjRInbv3s2YMWPo3r076enpDBo0iD59+uD1etvth8LCQrZt28bIkSMZPXo0cDCIJSQk4HQ627VkWfssKysLgKSkJPx+v10LZf2/2+0mJSUFt9tNNBptV+sU29pVXV1NYWEhw4YN47zzzuP111+nvr6egQMHkpCQQLdu3Zg7dy6tra1Mnz6dxMREe/tFRET+W3EZgAzD4MCBA/zpT39iw4YNOJ1OUlJSuP322+nRowelpaX8+c9/Ztu2bVxxxRX06dOnXU3OihUr2Lx5M8nJyTQ2NhIIBEhOTqaoqIju3buza9cuSktLKSsro62tjbfffhvDMLj88suBg2EiGAySl5fHF77wBXu9FixYYLdueDweEhMT7ddHo9F2xcoul4tBgwbxla98BTgYiiKRCC6XC7fbzTXXXEO/fv0Ouw9M02TRokVEIhGmTJnSLug4nU7279/Pd7/7XbsVKxwOk5GRwS9/+UscDgeRSATADiVWuDFNk3A4jMvlslu1YllBac2aNdTV1XHppZcyadIktm/fzrJly7jvvvtISEgA4Fe/+hWhUMgOWGr5ERGR4yUuA1AkEuHpp59m1apVTJkyhdTUVBYuXMizzz7LBRdcwLx589ixYwdTpkxhxowZnY6S6t27N4mJiWzduhWPx4NpmqSkpBCNRlm7di3hcJiJEyficrnYvXs369evZ8KECcDBkODxeCgvL2fFihV2d1QoFGoXJA43Usx6/yeffMKDDz4IQCgUYuLEieTk5BCNRqmpqSEzM5NAIGAHEafTSWJiIg6Hg7fffpu1a9cycOBAzjjjjHbhIhqNkpCQwKhRo+xtjkajJCUltav3aW5u5oMPPsDhcBAMBsnOzsY0TVwuF3v37mXDhg3U19fT2tpKW1sbZ599Nunp6dTX1/PPf/6Tbt26MXLkSOBg15nD4eCVV14hGo0ycODAo46oExER+U/FXQCyLqjnnnsuOTk5dgtKNBpl6dKl7Ny5k2g0ytSpU7nttts6vNc0TSZMmEBDQwM7d+4kKyuLpqYmgsEgI0eOZPLkycyaNYvMzEyGDh1qh49t27bhcrnsz4pEIhQXF1NcXExrayuGYRCJRMjJyTnmi77L5bK71Xbu3El9fT05OTk4HA6eeeYZotEoLpcLj8dDc3MziYmJ/PrXv6aoqIjZs2fj9XrtrjUr6LhcLiKRCOnp6dxxxx2dfq7VwlNVVcXjjz8OHCzGnjBhAhMnTsTv97NkyRLmzZtnb4vT6WT48OGkp6czb948KisrSU5Oxuv1Ul9fT1lZGQDLli2jtraWs846q8OQfhERkeMl7gKQYRg4nU4mTpzI+PHj2bx5M8uXL2fjxo2YpklSUhL19fV8/PHH/PGPf+T0009n0KBBdusHwPz58/nLX/7C2WefbV+chw4dyssvv0xzczMJCQmUlpbypz/9CcMw7BBkvdYaYbVgwQIOHDjAXXfdhcfjIRQKkZqaetQ5iQzDoK2tjaFDh3LPPfcQCoX41re+ZT9nmib9+vUjPT2dkpISysrKGDBgALm5uZimyezZs2lqasLr9dp1Os3NzUSj0XZdTjU1NTidTiKRCA6Hg27dutmF4ZFIhLS0NHukWDAYJCcnh9raWgKBAOPGjWPo0KH4/X6SkpJISEggNzeXhoYGli1bhtvtJhKJ4PF42LBhA9XV1dx1112MGDGC//3f/yUjI4Pa2lqFHxER+UzEXQCKRqMsXLiQLVu2UFpaSm1tLQD9+/fnqquuYuzYsRQWFrJ48WI+/PBDli1bRmJiIj169GDEiBHMmDGDXbt2MWbMGO6++26efvppkpKSOP/882loaCA7O5tgMEj//v258cYb8Xg8fPzxx7z00kt2gEpISOCss87iww8/pLKyEq/Xi8vlwuVy0djYSGNjI06n86gXf7fbbb8vttbGNE1mzJjB0KFDefPNN/nb3/7GzJkzGT58OADp6emcccYZ7NixA4DW1lZ+9rOf0djYSDgcJhgM0tjYyLe+9S07vKWnp/PDH/4Qr9drd88lJSVxzjnntFunZcuWEQgEKCgoYPLkyZ2ud9++famoqKC5uZn6+nref/99/H4/+fn5NDc309jYSI8ePWhqajqh8xSJiMipK64CkHUx3bt3L2vXriUnJ4fs7GzGjx9Pfn4+SUlJVFRU0KNHD6644go2b97MJ598QigUori4mD59+gBw11132d1ZW7ZsYcyYMTz11FOkpqZywQUX8NZbb7Fr1y5+8Ytf2EXFLperXaAJBoPU19cTCAR45JFH7NcBfP/737fn6zl0/eHfhcQlJSXMmjWLcDhMU1NTu5qZSCTSro7I+hlg+vTpeL1evve979nLbmlpwTAMRo8e3a61yjRNNm3aRFtbW4f9abUYWa1EsXP4BAKBdoXZ1jLdbje33347s2bNYs2aNfzzn/9kx44dRCIR/vCHP5CSkoLP56N3795s3br1v/zGRUREOhdXAQgOXpyvv/56pk+fzoEDB3jiiSdYtGgRs2bNIhKJ2CHCGhnmdDr5yle+woABA+wLfFlZGXv37iUUChEIBDhw4ADJycl89NFHfPLJJzidTnJycjjvvPMAKCkpYenSpe1uVxEMBqmtrbVHgjkcDtasWcOqVavsmpzDzcPT1NREOBymqqqKN9980+6y8nq9BAIBe/0PbTmxXpeZmUkoFLLnILIe7927N/fcc0+Hz/ve975Hc3Nzpy0xVguRFcpiP8taB2t7rWLxtLQ0OxClpaWRk5PDhAkTWLRoESUlJXTv3p1+/fq1mxhRRETkeIqrAGRdoJOSkkhKSqKhoYHGxkaGDBnCyJEjO9wTbMuWLWzYsAHDMEhOTrZbU1asWMHrr79OWloaTqeTPXv22BfqnTt32sPErVFdVkuI9X7TNNm3bx91dXVMnDiRs846C4DKyko+/PBD3G43bW1tNDQ0dNoN1tLSQmNjI1OmTOGSSy4hFAoRDodJS0tj4cKFOBwOPB5Pu22OZbUMHXoLkNgWI2sfxLYcdcaaGsBqETt0eVb4eeSRRxgxYgQzZ85s9/gZZ5zBWWedRV5eHtFolBdeeIERI0bg8/nsiRxFRESOt7gKQBarqBcODh8fOXIkl112WYfXeTwe1qxZY4ciKwhceOGFnHPOObz55pt88MEHdO/eneuvv57s7GxcLhdr166lvLycV1991f6c9PR0OyQYhsHKlSsJhULk5eXZ69PW1mYHqZEjRxKNRvH5fB1usrpv3z6CwSBDhw4lIyOj3TrX1tbidrtJSko67PYf7kalVsF2LKvo+dDHrP+35gGqqamhqanJfo3L5WrX4rVnzx68Xm+7xyKRCG63m9zcXCorK1m2bBmpqal2y9nIkSMJh8OqARIRkeMuLgOQFQCsOWv27dtn3wLD6g5yu92UlZW1Cy3We9LT06moqGDTpk2kpqbS3NzMK6+8wr333kuPHj245ZZbeOyxxzj99NMZO3Ysv/rVr7jgggvseYB27NjBBx98QJ8+fRg7dqxdQ1NSUmIXRI8dO5axY8cC2N1aVhBYv349brebnj172q02VkvTjh07SElJITk5+VPtEyuA7d69G2jfAhQIBNoFsIaGBkKhEG1tbSxYsIDt27ezadMmvF4vU6dOxev1UlVVRUtLCwCbNm0iGAzSu3fvDp/rcrmoqanhj3/8I3v27OHqq6+2R6vNnDkTgHXr1mk0mIiIHFdxGYAsVgvLypUree+99zo8b82TE9st5HA4WL58OS+++CLV1dU88MADpKWl8bOf/YyHH36YmTNnsnjxYurr6xk5ciT9+vVj1KhRzJ49G8MwuPLKK3nxxRepqqrixhtvpLi4mMWLF9PW1sbGjRvp1asXmZmZtLa28txzz+F2uyktLcU0TRISEohEIqxZs4Z+/frRo0cPO5hZXXY7duzgrLPOsm8keqTJBGMLnV0uF6WlpfzgBz9o1z1mzTqdkZFh74cdO3ZQX19PfX09f/7zn0lKSqJXr16cfvrpZGVl4XK5mD9/PkuWLAEOBrhgMEjfvn3bfbY1nP8vf/kLH330EZMnT2bGjBl2QfWGDRtYsWIFNTU1ugGqiIgcV3EdgBwOB6FQiIEDBzJ8+HC7BcgarbR161Y2b97coVZm9+7dtLS0cPvttzNu3DgA7r77bnbt2oVpmlRXV3Pvvffaz91333089thj1NfX43Q6mTBhAsnJyUyePJmNGzdSXFyMx+NhzJgxXHLJJXg8HrvIedeuXSQkJHD66adz2mmn4XA4mDx5Munp6TidznazRbtcLrKzsxk6dGi7ANNZQbS1/bEtW6mpqYwbN65dHZRpmqxcubLdKLWBAwcycuRIunfvTv/+/enfvz/du3e3A0pjY6M9xN4yZMgQxo8fby/XWrbf7ycvLw+fz8edd96Jx+Oxt8nlcrF69WpcLhfDhw9n1KhR9nqLiIj8NwwzDvsWrItwIBCgpKSE7OxsUlJSOryusbGR8vJy+vTpg9/vb9cNVVVVRVZWVqe3yaipqSE9Pb3dc6FQqN3NPGNbNKyZoQ+92adV3Gy1/sR+hjWq6lBW0bB1P62GhgZqa2vJzs7ucIf6kpIS3G433bt3p6SkhISEBHJycjoss6ysjGg0ak8DELsPY32aVpoDBw5QX19PXl6e3QLV2QSQzc3NRCIR/H5/h0JrERGR/1RcBqDOWEPgLbEtHocTe7E+NAgd+tyxFvIe6bVHW87xmDSws/uPHS7UWK89tKj60BFm1rodLRx9HtsnIiICCkD2xfpww8UPd+H+tEHlP724d9bCdCSHLudI74997lhfd7wc6zI/i88WERGJ+wAkIiIi8SfuqkmV90REROSkDECHu0fWsVBXioiIiJw0ASg25FghJvZeVsciGo2yd+/eTgt9RUREJH50uXHFoVCIF154gZaWFpxOZ7sbe/br148pU6ZQV1fHwoULKS8vx+/3M27cOAoKCo667Gg0yq5du9rNWSMiIiLxp8sFIIfDwcCBAwkGg/borLa2NpYtW8aQIUMAeOONN6itrWXq1KlUVVUxd+5cfD4f+fn5Rx1t1dncOSIiIhJfulwAcjqdTJo0qd1j8+bNY/DgwZx99tmUlpayd+9errvuOgYNGgRARUUFq1atIj8//6jLVxG0iIiIdMl+IGtmZNM02bhxIx9//DFf+MIXgIOzElt3EI9Go5imSV5eHtXV1R0mMzyUCqBFREQEumALEPx75uFwOMy7777LGWecQXZ2NnDwxpputxu32213kfl8PiKRCKFQqMPszVaYMgyDcDj8uW+LiIiIdD1dMgBZdTybN2+mpaWFiRMntruJ5qEFzNaortjHrdeXlZWxe/duPB4PkUik09s0iIiISHzpkgHIujXDihUrGDx4MElJSUQiEZxOJ36/n2AwaN8M1DAMmpub8fl87W4maoWcXr160b17d7sFaP369aoDEhERiXNdrgbICicHDhygtraW4cOHt3s+Ly+PYDBIYWEhDocD0zQpLCykb9++7e5pZXE4HLjdblwuV4e7rYuIiEh86nItQFbX1bZt2wgGg/Tp0wfAnhMoKyuLgoIC5s+fz/79+6msrKS+vp6ZM2e2e//hli0iIiLS5QKQFV5ycnKYNm0afr+/w3PTpk0jMzOToqIikpKSuPnmm+nRoweAJjgUERGRozpl7gZ/tAkQ4eCosjVr1nD66afjcnW57CciIiKfky6bAkzTxDTNw7boRKNRuwYIjm2On89q9JfJKZEhuzwDjd4TEZHjo8sGIGvI++FYwejThBprcsXjTRdmERGRk0uXDUDHk9U9VlFRQSAQOK51QqFoiEAkoBD0GTIxcRkufC7fiV4VERE5RcRFAIotrN67d6/dffbfCEfDuBwuXt76Mr9Y9QvSEtKIRCPHY3UlhsNw0Bxs5vy88/n1ub8+0asjIiKniLgIQBan03nc64CCkSD1gXqcTqcC0GfAYThoCjTREmo50asiIiKnkLgKQJ9J/Y9h4HK4cBku3WLjM+AwHLgcLpyG8+gvFhEROUZxFYA+K2bM/+T40r4VEZHPgmYNFBERkbgTVwFIXVQiIiICcRaAPqt5gEREROTkEhcByAo9n8U8QCIiInLyiYskEDsPkNfrJRqNnuA1EhERkRMpLgKQ5bOYB0hEREROPnEVgFT/IyIiIhBnAUhEREQEFIBEREQkDsVVAFL9j4iIiECcBSDNAyQiIiIQJwFI8wCJiIhIrLhIApoHSERERGLFRQCyaB4gERERgTgLQKr/EREREYizACQiIiICCkAiIiIShxSAREREJO7EVQBSAbSIiIhAnAUgTYQoIiIiECcBSBMhioiISKwumwQObamJ/flIz3VGEyGKiIhIrC4bgKzQEggEiEaj7ep3rH+HQqF2Px+NJkIUERERANeJXoHDKS4uZvHixbS0tOB2uzn77LMZPXo0pmlSX1/PwoULKS8vx+/3M27cOAoKCo66TNX/iIiICHSxFiAroFRVVfHKK6+Qnp7OZZddRm5uLq+99hrl5eUYhsEbb7xBWVkZU6ZMYeDAgcydO5fCwsJ2yxARERE5nC7ZArRu3Tq6devGNddcA8CgQYPweDwA7N+/n9LSUq6//noGDRoEHCxuXrVqFfn5+SdsnUVEROTk0aUCkFWfU1JSQv/+/dm4cSM7duwgKyuL8847D5/Px8qVK/F4POTm5tq1QXl5eaxYsYJIJILT6Tzq8kVERCS+dakuMIBwOEwkEmHz5s2sWLGCcDjM8uXLeeaZZ2hrayMUCuF2u3G73RiGgWEY+Hw+IpGIXRQdKxqNEgqFCIfDnT4vIiIi8adLtQBZwuEwycnJ3Hrrrfh8Pg4cOMDjjz/O9u3b8fl8HV5vDWuPnd/HNE0Mw6CsrIzdu3fj8XiIRCIdRpSJiIhI/OlyAcjlcuF0OsnNzbVbdjIzM8nKyqK2tpbMzEyCwSDBYBCPx4NhGDQ3N+Pz+XC73fZyrJDTq1cvunfvjmEYhMNh1q9fr0JpERGRONelusCsYNKjRw/27NmDaZo4nU4aGxupra0lNTWV3NxcgsEghYWFOBwOTNOksLCQvn37YhhGh3DjcDhwu924XK52AUlERETiV5drAQKYOHEif/nLX/jzn//MgAED2LhxI5mZmQwdOhSv18vYsWOZP38++/fvp7Kykvr6embOnAn8u+urM2r5EREREehiAcgKLllZWdx6662sWrWK0tJShg8fzvjx4/F6vQBcfPHFZGVlUVRURFJSEjfffDM9evQA0H2+RERE5Ki6VACymKZJdnY2l112WafPOxwOxo8fz/jx49u9R8XNIiIiciy6ZHOJVctjdVlFo9EO3VfWyC/rdccSfhSQREREBLpoCxC0DyuddWtZj32aUBOJRFQHJCIiIl2zBeh4s0JPRUUFgUBAdUIiIiJxLi6SgNVKlJOTg9frtbvPREREJD7FRQCyOJ1O1QGJiIhIfAUg1f+IiIgIxFkAEhEREQEFIBEREYlDcRWAVP8jIiIiEGcBSPMAiYiICMRJANI8QCIiIhIrLpKA5gESERGRWHERgCyaB0hEREQgzgKQ6n9EREQE4iwAiYiIiIACkIiIiMShuApAqv8RERERiLMApHmAREREBOIkAGkeIBEREYkVF0lA8wCJiIhIrLgIQBbNAyQiIiIQZwFI9T8iIiICcRaAREREREABSEREROKQApCIiIjEnbgKQCqAFhEREYizAKSJEEVERATiJABpIkQRERGJdVImgUNbcY7WqqOJEEVERCRWlw1ARwo1VqAJhULtfj4aTYQoIiIiAK4TvQKxTNPEMAza2tqYNWsWjY2NGIZBNBrF6/Vyww034PP5qKurY+HChZSXl+P3+xk3bhwFBQXHtHwRERGRLhWALDU1NZSWljJu3Dg8Hg+RSAS3243T6SQajTJnzhyqq6uZOnUqVVVVzJ07F5/PR35+vh2iRERERA6nywagtLQ0pkyZ0uG50tJSSkpKuO666xg0aBBwsLh51apV5Ofnf96rKiIiIiehLhWArNabpqYmgsEgixYtorq6mp49ezJmzBiSk5MpLy/H7XaTm5tLNBrFMAzy8vJYsWIFkUgEp9N52OWrZUhERESgixZBV1dXU1FRQVVVFX6/nw8++ICXXnqJcDhMIBDA7XbjdrsxDAPDMPD5fEQiEbsoOlY0GiUUChEOhzt9XkREROJPl2oBsubnGT58OAMGDGDo0KEAjB07lmeeeYaioiISEhI6FDNbw9pj5/exWpPKysrYvXu3XUtktRqJiIhI/OpSAcjSu3dvXC4X0WgU0zTp1asXKSkp1NXVkZKSQigUIhgM4vF4MAyD5uZmfD4fbrfbXoYVcnr16kX37t0xDINwOMz69es1GkxERCTOdbkusGg0yuOPP87ixYtxOBw4nU727dtHY2Mj6enp9O7dm2AwSGFhIQ6HA9M0KSwspG/fvhiG0SHcOBwO3G43LperXUASERGR+NWlWoBM08ThcDB69GiWLl1KU1MTycnJrF27lr59+zJgwABcLhdjx45l/vz57N+/n8rKSurr65k5c6a9jMN1canlR0RERKCLBSAruEyePJm0tDQKCwtpbW1l4sSJjB07Fpfr4OpefPHFZGVlUVRURFJSEjfffDM9evQA0H2+RERE5Ki6VACKNWrUKEaNGtXpcw6Hg/HjxzN+/Hj7MU2AKCIiIseqyzaXWAXQpmna/z70ecB+zbGEHwUkERERgS7cAhTbldVZcLGe/zShJhKJqA5IREREum4L0PFkhZ6KigoCgYDqhEREROJcXCQBq5UoJycHr9drd5+JiIhIfIqLAGRxOp2qAxIREZH4CkCq/xERERGIswAkIiIiAgpAIiIiEofiKgCp/kdEREQgzgKQ5gESERERiJMApHmAREREJFZcJAHNAyQiIiKx4iIAWTQPkIiIiECcBSDV/4iIiAjEWQASERERAQUgERERiUNxFYBU/yMiIiIQZwFI8wCJiIgIxEkA0jxAIiIiEisukoDmARIREZFYcRGALJoHSERERCDOApDqf0RERATiLACJiIiIgAKQiIiIxCEFIBEREYk7cRWAVAAtIiIiEGcBSBMhioiICMRJANJEiCIiIhKryyeBzlpsDn3saK06mghRREREYnXpAGSaJoZhEAqF2oUWK9CEQqF2Px+NJkIUERERANeJXoHDscLP3r17efnll5k+fTqDBg3CNE3q6+tZuHAh5eXl+P1+xo0bR0FBwTEtU0RERKRLBiArqLS1tfHmm2/S1NREJBKxn5szZw7V1dVMnTqVqqoq5s6di8/nIz8/3w5OIiIiIofTZQOQw+FgwYIFGIZBSkqKHYBKS0spKSnhuuuuY9CgQcDB4uZVq1aRn59/IldbREREThJdrgbICj/r1q1j586dTJ8+HdM07Rqgffv24Xa7yc3NJRqNYpomeXl5VFdXE4lEjtj6o5YhERERgS4WgKzuq+rqav75z39y2WWXkZOTQygUsoeut7S04Ha7cbvdGIaBYRj4fD4ikYhdFB0rGo0SCoUIh8OdPi8iIiLxp8t0gVl1P6FQiNmzZzNo0CAGDhxIfX09DoeDUChEJBLB6XR2mMfHah2KfdwKU2VlZezevRuPx0MkEiEajaolSEREJM51mQAEB7uo6uvrqayspKmpiccff9wOMgsWLKC+vp6UlBSCwSDBYBCPx4NhGDQ3N+Pz+XC73e2WBdCrVy+6d++OYRiEw2HWr1+v0WAiIiJxrssEICuwpKSkcMMNNxAOhzEMg0AgwIIFCxg/fjwjRowgEokQDAYpLCykoKAA0zQpLCykb9++GIbRYRSYw+GwW4bU8iMiIiLQhQKQxe12k5eXZ/8cDod55ZVX6NGjBxkZGQAUFBQwf/589u/fT2VlJfX19cycORPgiMPg1fIjIiIi0AUDEBwMKlaQMU2TCy64gIyMDPuxadOmkZmZSVFREUlJSdx888306NEDQPf5EhERkaPqkgHIGt0FB1uEzjrrrHbPOxwOxo8fz/jx4+3HNAGiiIiIHKuTornEmu/n0MegfWvR0SggiYiICHTRFqBDddat9Z8UNkciEdUBiYiIyMnRAvTfskJPRUUFgUBAdUIiIiJxLi6SgNVKlJOTg9frtbvPREREJD59LgHo0BqeExVAnE6n6oBERETk8wlADocDwzA6vWXF50n1PyIiIgKfQRF07Igs69/FxcUsWLCAyspKEhMTOeecczoMbRcRERH5vBz3phirpccKP7W1tfz+97/n448/xjRNysrKePLJJ/nkk0+AE9cdJiIiIvHruLYAtbW14Xa7cTqddgjas2cPgUCAX/3qV6SnpwPwwx/+kA0bNjBy5MjPtVtK9T8iIiICxykARaNRHA4HO3bs4Pnnn+eqq65i3LhxAGRmZhIOh3n55ZfJy8ujoaGB0tJSJk6cCHy+oUTzAImIiAgcpwBkhZg+ffowcOBA/vCHPzBw4ECuuOIKhg8fzjXXXMMLL7zAhx9+iMPh4Mwzz+Tss89u997PktUdp3mAREREBI5zAOrWrRu33347U6ZMYdasWfy///f/GD16NNdeey1PPvkkVVVVuN1uevbs2eG9n6XYeYD27t1rt1iJiIhIfDruKSAajdK/f3+++c1v8qMf/YiWlha+853v8PLLL5OammqHnxNR/Kx5gERERASOcwAyTROHw0FtbS2ffPIJDoeDb3/729x///1s3bqVBx54gJdeeonGxsYT0gKj+h8RERGB4zgKzKqzWbFiBc8++ywtLS1EIhF69uzJQw89xCOPPMKSJUt48803ee+997j++uuZPHnyMd/JXUREROR4OS7NMFaICQaDvPrqqwwdOpTbb7+dO+64A5/Px4svvohhGEydOpVHHnmEc889lw0bNij8iIiIyAlxXOcBikQitLS0tBvlVV5eTnFxMXCw7sfn83HdddcRDAaP50cfE4UtERERgeM4Csw0TRISEhgzZgy///3v+cc//kEkEqG6uppbbrml3etM08Tj8RyPj/5UNA+QiIiIwGdwL7CbbrqJrKwsdu7cicPh4Morr+S8886znzcM43NvidE8QCIiIhLruAUgK9QkJiZyxRVXHPE1nzfNAyQiIiKxjnsKME2z3Rw/Xelmp5oHSEREROAz6AI7tIurK7W0qP5HRERE4DNoARIRERHp6hSAREREJO4oAImIiEjciasApAJoERERgTgLQJoIUURERCBOApAVejQRooiIiEAXDkCHttTE/nyk5zoTOxGi1+vtUnMTiYiIyOevywYgwzCIRqOEw2H759jnAEKhUIfnjkQTIYqIiAh8BhMhHg+RSIR3332XwsJCQqEQ6enpTJ06ld69ewNQV1fHwoULKS8vx+/3M27cOAoKCo66XNX/iIiICHSxFiAroHz44YcsX76csWPHcv7559PW1sasWbMIBoMAzJ49m7KyMqZMmcLAgQOZO3cuhYWF7ZYhIiIicjhdqgXI6p765JNPOP300znrrLMASE9P569//StNTU0EAgFKSkq4/vrrGTRoEHCwuHnVqlXk5+efsHUXERGRk0eXagGyXHbZZUyYMIFQKER9fT0bN24kJSWFbt26UVZWhsfjITc3l2g0imma5OXlUV1dTSQSOWKNj+p/REREBLpYC5AlLy8PgKVLl7J8+XLa2tqYOnUqLpeLxsZG3G43brfbvvGqz+cjEokQCoVwOp3tlhWNRu1gZBVUi4iISHzrkgHIctppp9GzZ0+Ki4v58MMPGTx4MAkJCR1eZw1rj53fxzRNDMOgrKyM3bt34/F4iEQiRKNRtQSJiIjEuS4TgKzA0tLSwpo1axgxYgTp6emkp6czZMgQNm7cyJ49e+jWrRvBYJBgMIjH48EwDJqbm/H5fLjdbnt5Vsjp1asX3bt3t1uA1q9fr0JpERGRONflaoAcDgdLlixhw4YN9mM1NTVEIhESEhLo06cPwWCQwsJCHA4HpmlSWFhI3759MQyjQ7hxOBy43W5cLle7gCRyKjJNMK3/13/H979/7VcROTV0mRYgK7z4fD4mT57M+++/T0NDA4mJiaxfv57MzEwGDhxIYmIiY8eOZf78+ezfv5/Kykrq6+uZOXMm8O+WpM6o5UdOdfahr17ez4b2q8gpo8sEIPh3t9V5551HSkoK27dvp7GxkYKCAs444wwSExMBuPjii8nKyqKoqIikpCRuvvlmevToAaD7fEncCoSjBMNRVOL22TFN8LgceF06z4ic7LpUALIYhsHYsWMZO3Zsp887HA7Gjx/P+PHj7ceO1PIjciqLRE2cDoNH397KHz/YSbrfQziq1s7jzeUwqGkJcvvZ/fn+pfn2fheRk1OXDECAPVrLuieY9e/Y560aIDi2OX4UkORU1hqKUNsSwmkYCkCfAZfDoLYlRGsocqJXRUSOgy4bgGK7sjrr1rIe+zShJhKJqA5ITlkOw8DtNHA5DNWqfAZc/9q/Dv0hJXJK6LIB6HiyuscqKioIBAKqE5JTlkYrfXZMQ/tV5FQSF0nAaiXKycnB6/XaEyeKiIhIfIqLAGRxOp2qAxIREZH4CkCq/xERERGIswAkIiIiAgpAIiIiEofiKgCp/kdEREQgzgKQ5gESERERiJMAZIUezQMkIiIiECcBSPMAiYiISKy4CEAWzQMkIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETikAKQiIiIxJ24CkAqgBYRERGIswCkiRBFREQE4iQAaSJEERERiRUXSUATIYqIiEisuAhAFk2EKCIiIhBnAUj1PyIiIgJxFoBEREREQAFIRERE4lBcBSDV/4iIiAjEWQDSPEAiIiICcRKANA+QiIiIxOqySeDQlprYn4/0XGc0D5CIiIjE6rIByAotoVCo3c9He+5INA+QiIiIALhO9AoczurVq1mzZg3BYBCv18vZZ5/NiBEjME2T+vp6Fi5cSHl5OX6/n3HjxlFQUHDUZar+R0RERKCLtQBZAWXTpk0sWLCAQYMGcdFFF5GZmcnrr7/O3r17MQyD2bNnU1ZWxpQpUxg4cCBz586lsLCw3TJEREREDqdLtgCtXr2a3r17c8EFFwAwZMgQHn30UXbv3o3P52PPnj3ccMMNDBo0CDhY3Lxq1Sry8/NP5GqLiIjISaJLBSCrPqegoICkpCQikQhOp5OmpiaCwSBJSUns27cPt9tNbm4u0WgUwzDIy8tjxYoV9uuPtnwRERGJb10qAFlGjx5t/3vfvn28/vrrJCYmMnToUD766CO8Xi9utxvDMDAMA5/PRyQSIRQKdQhA0WiUSCSCYRiEw+HPeUtERESkK+qSAQigtbWVd999l7Vr15KXl8dFF12Ez+cjGo12mMfHGtYe+7hpmhiGQVlZGbt378bj8RCJROxWIxEREYlfXSoAWaGlsbGRF198kcbGRmbOnMnw4cPt5xMTEwkGgwSDQTweD4Zh0NzcjM/nw+1228uyQk6vXr3o3r273QK0fv16FUqLiIjEuS41CsyyfPlyAoEA//M//2OHH8Cu9wkGgxQWFuJwODBNk8LCQvr27YthGB3CjcPhwO1243K52gUkERERiV9dqgXIMAyi0Sjbt28nGAzy6quvEggEcDqdtLa2cuaZZ1JQUMDo0aOZP38++/fvp7Kykvr6embOnAn8uxWpM2r5EREREehiAQgO1vOcccYZBAIBu3jZMAyCwSCpqakAXHzxxWRnZ1NUVERSUhI333wzPXr0ANB9vkREROSoulwAcrlcjB8//oivcTqdjB8/vt3rjtTyIyIiIhKrywUg4LA3K7Vag6zXWDVA1nNHo4AkIiIi0EUD0LF0Y1mv+TShJhKJqA5IREREuuYosOPNCj0VFRUEAgHVCYmIiMS5uEgCVitRTk4OXq/3sF1sIiIiEh/iIgBZnE6n6oBEREQkvgKQ6n9EREQE4iwAiYiIiIACkIiIiMShuApAqv8RERERiLMApHmAREREBOIkAGkeIBEREYkVF0lA8wCJiIhIrLgIQBbNAyQiIiIQZwFI9T8iIiICcRaAREREREABSEREROKQApCIiIjEnbgKQCqAFhEREYizAKSJEEVERATiJABpIkQRERGJFRdJQBMhioiISKy4CEAWTYQoIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETiUFwFINX/iIiICMRZANI8QCIiIgJxEoA0D5CIiIjEOimTwKGtOEdr1dE8QCIiIhKrywYg0zQxTZNoNNohsFiBJhQKtfv5aDQPkIiIiAC4TvQKHI4VVP72t78xYsQICgoKiEQiOJ1O6urqWLhwIeXl5fj9fsaNG0dBQcFRl6n6HxEREYEuGoACgQC7d+9m586dFBcXM2zYMOBgKIpGo8yZM4fq6mqmTp1KVVUVc+fOxefzkZ+fj2maauURERGRI+pSAcgKL3V1dbzzzjuEw2E8Ho8daBwOByUlJZSUlHDdddcxaNAg4GBx86pVq8jPzz+Rqy8iIiIniS5VA2QFnezsbO644w7uvPNOPB5Puxqgffv24Xa7yc3NJRqNYpomeXl5VFdXE4lEjtj6o5YhERERgS7WAmQxDAOn09npc21tbbjdbtxuN4ZhYBgGPp+PSCRCKBTq8L5oNGoHo3A4/HmsvoiIiHRxXTIAWTorWjYMo8M8PlYLUezjVndaWVkZu3fvxuPxEIlEiEajagkSERGJc106AHXG7/cTDAYJBoN2fVBzczM+nw+3222/zgo5vXr1onv37nYL0Pr16zUaTEREJM51qRqgzjgcjnYtNnl5eQSDQQoLC3E4HJimSWFhIX379sUwjA7hxuFw4Ha7cblc7QKSiIiIxK8u3wLU1NRkT3gYiUTIysqioKCA+fPns3//fiorK6mvr2fmzJkARxwGr5YfERERgS4egBwOBxdccAF5eXn2zwDTpk0jMzOToqIikpKSuPnmm+nRo0e714iIiIgcTpcPQBMnTrR/jp0PaPz48YwfP95+ThMgioiIyLHq8s0l1lw/nT0O/75n2LGEHwUkERERgS7eAgSH79KyHv80oSYSiagOSERERLp+C9DxYIWeiooKAoGA6oRERETiXFwkAauVKCcnB6/X2+7WGiIiIhJ/4iIAWZxOp+qAREREJL4CkOp/REREBOIsAImIiIiAApCIiIjEobgKQKr/EREREYizAKR5gERERATiJABpHiARERGJFRdJQPMAiYiISKy4CEAWzQMkIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETikAKQiIiIxJ24CkAqgBYRERGIswCkiRBFREQE4iQAaSJEERERiRUXSUATIYqIiEgs14legc+TJkIUEfkcmFEwTdDp9rNjAoYDdE37j8VVAFL9j4jI58BwKPx81rR//2txFYBERORzsG89NFWCQ5eYz4YBkSBkD4XUvH+1tikRfVo6OkVE5DgxAQMW/xg2zwZvNzAjJ3qlTj0OFzTXw/THYNL9B/exocv5pxVXe0z1PyIinwPDAQ4HOJwHM5EcXw7nwSFMRlyMY/rMxNXe0zxAIiIiAnESgDQPkIiIiMQ6KZPAoa04R2vV0TxAIiIiEuukDEBWoAmFQu1+PhrNAyQiIiJwkhVBm6aJYRjU1dWxcOFCysvL8fv9jBs3joKCgmN6v4iIiMhJFYAAotEoc+bMobq6mqlTp1JVVcXcuXPx+Xzk5+fbIUlERETkcE6aAGQFm9LSUkpKSrjuuusYNGgQcLC4edWqVeTn55+QdTNi/ifHl/brp2PE/CfHl/brp6Wj8bOj/Xo8nHQBaN++fbjdbnJzc4lGoxiGQV5eHitWrCASieB0Og+7DKtl6Hi0ENnLMCAS8z85vkxMIkQwNZnIYVnHoolBxMT+T44v41/71eT4nUdOPdY+MQ9Ozmf9d1L41ySOJwPTODj7s0XH4n/kpAlAlra2NtxuN263G8MwMAwDn89HJBIhFAp1CEDRaJRIJIJhGITDYUzTJBQK/df1QOFoGNNhYkQM/IafBCOBiHFy/KIbhnHS1EM5DAdRI4rbdBMOh0/06nRJkaiJ02HgIoLfBQkuiJwkAx1PpmPR6QC/C1xECIfD9n6XWP8KEYYHXIng9AMnx8FocBLN2Wg4wRUA0wHhMETD4Pjv1t40TZxOZ1xNE3PSBSDDMDp8Qdaw9tjHrRajsrIydu/ejcfjwTRNotEo69evP27rMzAykCeGPHHwRH4y/PqYEIlGcDqcJ8UfOwYHL5Auh4s1a9ac6NXp0s7PiDDp8oyDLRMnwaEIHLXVtksxDp5XPM5GHYtHk3sH9P4yJ8VJ5l9OqmMR/nX/Lx8ch2PRMAyCwSB9+/alT58+cVNLe9IFIL/fTzAYJBgM4vF4MAyD5uZmfD4fbrfbfp315fXq1Yvu3bu36/46nn9xGhg4TqLpyMPhMB9//DFjxozB5Tp5vn4Tk6h5cvwleaI4jJOrW+akPRZNk+hJEjBPGMPxr9s0nBw7KhyO8PHH6xg9pgCX62QJQca/uhiPzz62WoDg5DqP/DdOmrOO9YXk5eURDAYpLCykoKAA0zQpLCykb9++driJ/fIcDkdcNekdjYGBaZgYLgPDefIc5AYGjpNz2io5DMN5sJ7GcLowHCfLRedgm4aOxGN1cpxjDCc4iOJ2cpJ1a548vzdd0UkVgEzTJCsri4KCAubPn8/+/fuprKykvr6emTNnAsRN091/yoyaBINBzKip3x05ocxo9F/HYhROpq4HOeVEoybBYIho1NShGEcM82SpQIwRjUb56KOPKCoqwufzceaZZ9K7d+8TvVonhWg0Snl5OT179lTLmJxQOhalq9CxGJ9OygDUGbX8iIiIyLE6aaOuNfLLNE2Fn0/pFMm8cgrQsShdhY7F+HPKtADJZ0PhUkRETkUnbQuQfD4UfkRE5FSkANSFHNoYF/uz9W+ry+/Q5472eKwFCxawYcOGTt8b+9pwOExDQwORSPsZrg+33NjnAObPn9/uc+TUYU0qeqRjIPaYPfTxYzlOD33+aM/peDv1mKZJJBLBNE22bNnC7NmzAVixYgVvvfVWu9cdy/F4tHPWkc65nS3vSJ/VGWtbSkpKeOWVVzS7/QmmANSFHNraEvtz7ESO1n/WL1nsY/Z9of7VdXXoYwDFxcVUVlYC2PdTi/3Pqq/at28fzz77LE1NTfZrD7cOsetpfd6ePXuorq5u99lyarBmZD/0mO3suOvs2D2W4/TQ4zv2sdj10PF2arKODafTiWEY1NbWsmvXrnbPx74u9ng89LnOzlmdHV9HOufGPt7Z+e9YjmVrWxobG9m5c6d9TpUTQwHoBLN+MZqbm+2TNxwMG1VVVQfnSTFNDhw4AMCBAwcoKiqiqanJ/iWrq6ujtbWVpqYmdu3aZf8itrS0UFxcTEVFBfDvX2iPx2PPvOt0OmltbWX79u1s27aNxsZGHA4HkUiEyspKQqEQ+/fvJxQK2cNDy8vL2bFjB4FAoMMF8MCBA+zZs4dIJEJCQsLJNbW8HLOSkhIKCwvZt2+f/Zh13DU2NlJcXExjYyPRaNQO0I2NjTQ2NtLW1saOHTvs8N3c3NzpcWr9f2lpKbt27SIcDut4iyOGYdjHSmtrK16vF6/XC8Bpp53GOeecY7+uqamJLVu2sGPHDkKhULtjqLGxka1bt1JUVERra2uH42vv3r2UlJQAB8/D1j0jDxw4QDQaZe/evVRVVdnrdbjz35HOuYZhEAqF2LlzJw0NDbjdbntb5MQ5aSZCPFVZF421a9eyadMm7r77bvui8Ne//pUrrriC7OxsXnjhBTIyMqiurrZ/wa+++mpyc3NZvHgxTU1NNDY24na7ueuuu/jkk094++23cbvdBAIB+vbty2WXXYbf72/XVFxSUsKsWbNwOp32DWVnzJhBRkYGH3zwAYZhsGDBAq666ioyMzN57bXXKC8vx+PxEIlEmDZtGvn5+UQiERYuXMiGDRtISEjA7/fT0NDAwIEDT/AeluPBOk6DwSCvv/46JSUlJCQk0NDQwMiRI7nkkktwOp2sW7eOxYsX43Q6SUhIwO12k5KSwjXXXMPKlSvZuXMnAE1NTXzjG99g06ZNLFiwoN1xeumll+L3+6mrq2PWrFnU1dXZN2mcPn06ffv21fF2CrOOtW3btvHmm2/icDjwer04nU77D7f33nuPyspKbr31Vnbs2MGcOXPsc1hCQgJXXnkl2dnZFBYWMn/+fHw+H8FgEMMwuOKKK+jbty+NjY288cYb7Nu3D7fbTUZGBvX19VxxxRVkZGTw0ksvkZWVxZYtW5g2bRopKSn84x//YN++fR3OfwAbN25k4cKFHY7lxMRE9u7dy+uvv04wGLSDnMvlUkvlCaYA1EVYfd2xrP5ih8NBc3MzCQkJ3HTTTXi9Xv74xz/y0UcfkZubi8PhYPfu3VxwwQXk5+dTWVnJ/PnzOfvss5k4cSIHDhzgueeeY+XKlZx//vntPmPp0qXk5ORwww03APDqq6/y/vvvc9tttzFt2jTmzJnDtddeS/fu3Zk3bx41NTXceeedpKSksHjxYubOncuAAQMoKipi1apVXH311QwePJg1a9Ywf/58/UV+irAuSlu3bmXXrl3ccccdZGRksGXLFmbNmsWkSZNwOBy89dZbnHHGGUyePJk9e/bw8ssv061bN+DgbWn27t3L5MmTOe2006isrGTevHmdHqdTpkxh3rx5GIbBPffcg9frZfbs2cyePZv77ruPwsJCVq9ezVVXXaXj7RQS23o9b948O0QcOHCAf/zjHyQnJwMHz43W+fK9996je/fu3HDDDQSDQf70pz/x8ccf84UvfIF33nmHYcOGcemll2KaJs8++yxr1qyhb9++LF26lIqKCm655RaSk5OZP38+u3fvBg4eqy0tLdTU1HDjjTfSv39/Fi5cSG1tbbvz35tvvkm/fv1obW1l/vz5nHPOOe2O5VWrVnHeeecxe/ZsunXrxpVXXkkgEODVV18lGAxq0sUTTHu/CzlSDRDAOeecQ0ZGBklJSfTv35/m5mbgYLHygAEDmDhxImlpaRQVFQHQu3dv9uzZQzAYpFevXhQWFtqBynLZZZdx4YUXsmfPHjZs2EB9fb3dh2010fr9fgC2bNnCwIEDaWpqYs+ePfTs2ZNAIMCOHTsoKipi0KBBjBgxAo/Hw1lnnUV2draK/E4R1jEzePBgbrvtNsLhMFu2bGHXrl04nU5M02THjh243W6mTJmC1+tl8ODBDB8+nFAoBBy8aOXk5DB16lSysrLYvn070P447dmzJ0VFRdTV1VFWVsbAgQOprq5m79699O7d235827ZtOt5OQVaLyM6dOwkGg3zhC1/A5/PRu3dvTj/9dNra2oD2dTmJiYmUlpayfPlyamtrue2225g6dSoA119/PWeeeSa7du1i/fr1tLW12cfy9u3bmTBhAj169CApKYnzzz/fPudZtZATJ05k8ODB9j0nY89/vXr1oqWlxe6iNU2zw7FcXFzM3r17aWxsZMqUKSQnJ5OZmcmECRM6/MErnz+1AHUxhxuN4HQ6cbvd9uMOh8P+dzQaJTEx0f65paWFaDTKwoUL7cdcLhc9e/bs0OS6Y8cOPvjgA5xOJ+np6YRCIfskEDvZZHNzMw6Hg507d1JaWmqvU+/evTEMg/r6erKzs9sVSiclJanI7xQRW98zb948qqurSU1Ntbsm4OBxl5SUhMPhsL93v99vB/VDj9PW1tYOx6nD4aBXr15UV1fjdDrZvHkzW7dutZ/r168foVCIxsZGcnJydLydopqamnC73fj9fntUld/vb/fHm3XMzJgxg0WLFrFy5Uree+89UlJSuPjii+nbty+bN29m1apV+Hw+UlNTiUajOBwOQqEQ0WiUbt262ceM2+22u6Wi0ajdjRuNRu3ayM7Of06nk6ampsMeyzU1NbhcLpKSkuxtSUhIUBdYF6AA1EVYIwqsX/CmpqZ2hcexr+uMdYGCg0XOPp+P2267zR4dUVJSQlNTkx2cXC4XgUCABQsWMGnSJM455xxcLhcLFy60m4GtZbpcLvx+P+FwmDPOOIMzzjiDaDRKJBJh06ZN9OzZE4/HQ21tbbv1tU4acupYtGgRbW1t3HnnnXTr1o19+/bx3HPP4XQ68fl8tLW1tfvrvKqqql231NGO0z179tDa2kpaWhqhUIjzzjuPYcOGYZomLS0tbNu2jR49euD1eqmrq9Pxdory+/0Eg0FaWlpITk62w3dsYLCOq507d3LBBRdwySWXUF5ezltvvcXSpUuZMmUK7777LhdffDFjxozB6XTy8ssvEw6HcbvddpG1dczU1tYSCAQ6HEMOh4PExETC4TBnn312u/Pfxo0bycnJYd++fSQkJHQ4ltva2uz6o+bmZtLS0uyi7XA4rOP1BNPe7yJSU1OpqamhuLiYqqoqFi9eTDAYtJ8/dI4L668U69+xzw0aNIjm5maWL19u3+TvxRdfpLS0FPh3bZH1HrfbDUBhYSHr1q2zR4G53W6CwSClpaUYhsGgQYNYsWIFNTU1RKNRFi9ezFtvvYXb7SY/P5/t27dTWFhIMBjk/fffp6Kiwi5alFNDJBLB5XLhdrupqqpi0aJFhEIhmpqa6NevH01NTSxevJiamho++OADdu7cicfjAdofs9D5cfrSSy+xZ88e0tPTyc7OZtmyZTQ2NhIIBJg/fz7vvPMObrebYcOGsW3bNh1vpxgrHPft2xeXy2UH7tLSUtasWWOfq2KPpQULFjB37ly7izUlJcXuloWD57doNMqaNWvYtm0b0WiUaDTKgAEDeP/999m7dy+lpaUsWrSo3Xk09pzr9XoZMGBAh/Pf22+/jWEYDB48mJaWlg7n3D179tC7d2+Sk5NZsmQJzc3NVFZWsmLFinYtpXJi6Gxxglm/8AMHDmTgwIG89tpreDwecnNzycrKsl9z6BBft9uNz+cD2g9rN02Tnj17Mm3aNJYuXcratWsJBoP069ePc889F8B+n8/n44wzzuCDDz5gzZo1JCcnM27cOFavXs3y5cuZMGECOTk5zJ07l5SUFC666CJeffVV/vSnP9knlZkzZ+L3+xkxYgR79+5lzpw5eL1eMjIy6Nev3+e1G+VzMnHiRN544w0ef/xx3G43Q4cOJRAIMG/ePO666y6uvfZa3n77bTZu3EhaWhq5ubl2rcOhQ38Pd5xOnjwZ0zSZPn06r7/+Os888wwOhwOn08nVV1+Nw+Fg5MiRlJWV6Xg7xVgt4d26dePSSy/lrbfe4vHHHychIYE+ffrYfxS63W47DF1yySXMmzePJ554wm5VueKKK8jNzWX48OG89dZbvPPOO2RkZHDmmWeyevVqNm3axPTp05k1axYvv/wyHo+Hnj170tzcbE/P4PP57HOuaZpceOGFzJ49u8P5LzExkcTExA7H8oABAzjnnHNwOp1Mnz6d2bNn89RTT+HxeMjKyqKhoUFdYCeY7gXWxVRWVmIYBllZWYRCIXv4bzAYxOVy2U2m1lwVbrfbHhZ/6F+/zc3N7N+/n6SkJHJycuzHD339/v37CYfD9OzZE4fDQVVVFT6fj+TkZILBIE1NTfZfVXBwHoy2tjZ69uyJz+dr161RWVlJW1sbffr0sf9K01/lp5ampiYOHDhAZmYmSUlJNDc309LSgsfjobq6mry8PEKhED6fjxdffBG/38+MGTPsYmjrwmU53HEKBy88e/fuJRKJ0Lt37w7Hko63U5N1TmlubqaiooKcnBwSExMJBoN4PJ525z84eAzt27cPh8Nhn5csZWVlOBwOevToAUBFRQXJyclUVFSQkpJCcnIybreb8vJy/va3v/GVr3yFjIwMAoEAbre7QzfVkc5/nR3L1vOBQIDy8nLS0tJITU21t0VOHAWgU1TsL+Xxel9nz/2nnyMnp0O/79if9+3bx1NPPcWZZ55Jfn4+RUVFrFy5khtuuIH+/fsf0/KO9pyOt/hxrN/1pzlOYh+fNWsWxcXFXHHFFUQiERYtWkRaWho33njjUd/b2WOf9liWE08BqIuJnZ79eC3raMs79DM7+/nQi97hlns811+6pkO//9jvfNOmTSxfvpxQKERCQoIdhj7N8g73/Kd9Tk5+n/Yc1tlrDz1GrC6upqYmlixZwt69e+1RslOnTrVHnh0pzBxunf7T5+TEUAASkeMuFAp16OoS6YqsuiGNyIo/CkAictwcqYtMpCs5Wsu3nPoUgERERCTuqM1PRERE4o4CkIgcV4dOzPl5LeNI7zke6yQipxZ1gYlIp6xZag8tDj3SEGPoOALn09ZUHGnU4aHLj0Qi9q0HYtc79jWq6RCRzqgFSEQ6sO5L19nImNih74c+bhgGtbW1HDhwwH7s07DCS2VlJbt27bIn7Yz9L5Y1USgcvBdYa2srDoejw+vD4TAHDhwgEAh8qvURkVOXpkwVkQ4Mw+DDDz8kJSWFESNGMHv2bLZu3YrD4WDixIlMmjSpXUtNKBTi+eefZ/To0axevZrGxkbGjh3L1q1bSUhIYPfu3fj9frxeL4FAgNbWVrKzs7nrrrvs+zZZd+A+cOAAv/rVr2hpaeGBBx6gR48e7e7LlJiYaM8SvHLlSqqrq6mqqmLdunWMHj2a7Oxsqqur7Xs+1dTUUFVVRVNTExdffDHXXnutRqeJiAKQiPxbNBq172T9xBNPMGTIEIYPH05jYyPV1dVUV1dTUVFBQUEBCQkJ7W442dbWxty5c+1p/lesWEHPnj3JzMwkEolQW1vL2rVrGTlyJHl5efbtCqww4nQ62bt3L0888QS7du3C5/Pxi1/8gkgkgsPhwO/343Q6+eY3v0nPnj0JBAK89NJLtLa24nQ6GTZsGGPGjGHjxo3s2rWLhIQEmpqa6NWrFwMHDqSkpMS+9YDCj4ioC0xEgPa1NrNmzbJvSOpwOLjhhhv45S9/yW233UZZWRmzZs2yu8JM06SxsZFu3boBB+/P1dzcTHZ2Nunp6YwcOZK+ffuSlpaGw+EgIyODnJwcxo8fj9PpxDAMgsEgixYt4uc//zk1NTVcffXVzJgxg/POO49p06YxefJkWlpaCAQCdnBKTU3ll7/8JV/72tcwDIOrrrqKSZMmEQwGOfPMM/nSl75EXV0d55xzDjfddBMVFRU0Nzd32FYRiU9qARIR4N81PHPnzmX58uWcd955jBo1yp4pNxqNMmHCBFatWsXcuXPJysrioosuAuDAgQOsW7cOv99PXV0dpmnS1tbG7t27CQaDzJ49m7S0NPLy8tiyZQtz5szhpptuYsCAAWzfvp1nnnmGkpISevbsybBhwxg4cCAFBQX2uv3jH/+gqamJL3/5y6SnpwPQ2trKnj17KCkpweFwsHr1agKBAKZpsnTpUs477zx69OhBeXk58+bNo6amhqlTp56QfSsiXY8CkIhgmibBYJA5c+bwxhtvMGbMGO66665OC6Hvvvtu6urqeP7556mpqeGyyy6jX79+3Hnnnaxdu5bS0lIaGxvJyMjgsssuIxqNsmDBAi655BL69+9PQ0MDTz75pN2Sk5WVRXp6OgUFBUycOJF//OMfPPzww0ydOpULLriAefPmsXTpUm644QYuvPBCIpEITqeTqqoqfv3rX+NwOPB6vbz99tts2rSJyy+/nD59+lBeXo7D4aC2tpaMjAzOPPNMdYGJiE3D4EXinFWDs3PnTn7605+SmJjI8OHD6dWrF8FgEIfD0W4eHbfbTWNjI5s3b6a8vJxHH32UtrY2fvGLX9C9e3fcbjfBYJDMzEy2bdvGOeecw9KlS3E4HPb9waqqqrjmmmuYPn16pwXJzz//PIsWLbJD0syZM7n44ovbvcZqAZozZw4bN27k4osv5uyzz+all15iz549GIZBW1sbDoeDlJQU6urquOCCC7j22mvtWicRiV9qARKJc1b46N+/Pw899BCmafLEE0+wbNkynE4n4XDYHm5u3UV76NCh3HvvvVRUVJCTk8N7771HcnIyDzzwAP/4xz8IhUJcdNFF+P1+3G43kUiEiy66iGHDhlFVVcXTTz/dYd6gpqYmioqK2LBhA0VFRfj9flJSUrjyyisZMmQI+/fvJxqNkpiYSEpKCgkJCeTm5lJRUYHX62X9+vWcfvrpdvi68cYb+f3vf8/gwYO58MILefjhh1X7IyI2tQCJSAfV1dW43W6ef/55PvnkEx566CHS0tKIRqM88cQThMNhfvSjHwEdJy584IEHGDFiBHv27GHChAkMGDCAn//85yQnJ9shqqqqimuvvZbLL7+c2bNnU1hYSElJCa2trUSjUXvkl8fjsUeYuVwuIpEIU6dO5aabbgLghRdeYMGCBaSnp9Pa2kpmZibJycns2rWL5ORkmpubcblcJCQkUFFRwWWXXcY111yjFiARUQuQiPybNftzRkYGra2tbNmyhX79+tGvXz/7NcFgkMTExHZz91RUVPD+++8TiURoaWmhvLycYDDIO++8g8/nw+12M3nyZAYMGEB9fT3PPfec/VkNDQ1s376d008/naqqKiorK7n00kvxeDz2/D8Oh4PW1lZmzZpFKBQCYP369SxdupSzzjqLwsJCLr30Uk477TRefPFF0tPTueiii3jttdfIzc1l/PjxPPfcc6r9ERGbApCI2AzDsIPJ/Pnz2b9/v91iYgWe2tpaunfv3m6m5draWlasWEEwGCQcDlNVVUV6ejoej4eamhpCoRDbtm1jz549OBwOAoGAPSvztddey4wZM+jWrRt//etfKSsr45JLLumwbpFIhLlz59rdWBUVFfTu3ZuzzjqLlStXMmDAAHbv3k1xcTFZWVns2LGD5uZmDhw4QFFREW63m40bN3LppZfacxgpEInELwUgEbFZExK+8847vPHGG4waNYrJkyfbz9fV1VFfX28PRbcMGTKExx57jJdffpnZs2fj9Xq59NJLGTt2LBUVFezYsYPi4mKGDx/Ojh076NevH6NGjQLA4/Hg9XoxTdNu3amvr8fv97erE6qvr7dbgwBOP/10BgwYYA99D4fDNDc343Q6CQQC1NTUMHbsWOBgK5MV7tTrLyKgACQi/2KaJgcOHGDBggW89dZb9OnTh9tuu41t27bhcDgIh8MsWbKEQCBAbm6u/R7rv1WrVjFv3jzGjRuHy+XiV7/6FXfddRfDhg2zg8l1113Hs88+S0VFBT6fr937rVFikUiEn/3sZ50GFavLDSA9PZ2MjAzWr1+Py3XwVHbJJZewatUqUlNTeeCBB4CDXXalpaX89Kc/ZdSoUfj9ftUAiYgCkIj8+xYY69atY9asWUyYMIEvfvGLdO/enfvvv5/KykqcTifBYJBhw4Zx2mmnAf+ePHHVqlU8+uijDB06lNtuu42UlBQaGxtZsWIFy5YtY9u2bdx3331kZWXx5S9/mV/+8pc8+eST/OxnP7NrfQCam5tpaGjgtNNOs+8RZn1OKBRi586dtLa2AtjzAUUiERoaGgiHw/bjVkuPYRgUFRXxy1/+EoC+fft+zntWRLoqjQITETssBINB1q5da7fimKZJYWGhHYC8Xi/5+fkkJye3e19LSwvLli3j9NNPJy0tDTg4rN3r9bJjxw7C4TAjRoywg9a+fftobm5m4MCB7ULOunXrKCsr49JLL+1QnxOJRJg/fz65ubmMHj3aXlZFRQVr1qzhjDPOICsri+LiYrxeL3369AEgEAjw8ccfk5GRwaBBgz7HvSoiXZkCkIh06khFwv/Jc9bjx1p8fOipSQXLInI8KQCJSDvRaLTdCC+re8oS+9yR3hcbeGKLl63nrGUdugzTNO06n0NFIhEMw+iwLKs1yPq8Q5dtbYPqfkTEogAkIiIicUd/DomIiEjcUQASERGRuKMAJCIiInFHAUhERETijgKQiIiIxB0FIBEREelyPutB6gpAIiIi0qXEziMWiUQ+k89QABIREZETxmrpWbFiBatXr7bDz5o1a3jppZdoaWlp1xrU2b8P97w1Ceru3btZtGhRu+cVgEREROSEsQLJgQMHOHDgAIZhsGLFCt555x3OPPNMkpOTMQyDSCRCMBhsN8u7daPkQ2egj0aj9gzxcPDehPv377ffY5qm7gYvIiIiJ57T6SQxMZEtW7awcuVKbrzxRnr16gXAmjVr2LRpEw6Hg5ycHC644ALC4TBvv/02VVVVZGVlEY1GmTFjBjt27OCdd94hNTUV0zQpKCjA7/fbt9gpKirigw8+UAuQiIiInHher5cNGzbwxhtvkJubS69evYhGo4RCIXbu3Mmll17KjBkz2LRpE9XV1axZs4YDBw5wzTXXkJyczO7du2loaGDBggVMnDiR888/n5KSEurr6+17CDY3N/P2229z9tlnKwCJiIhI1xAOh7n66qspLS1l7dq1OBwO3G43p512GitXrmThwoU4nU7a2tooKytj7NixJCcnM27cODIyMigtLSU5OZn8/HwyMjI47bTTCIfDALhcLsrKygiFQhQXFysAiYiIyIkXDAYZOXIkgwYN4rzzzuOf//wnTU1N1NbWsmjRIgYMGMAFF1xAUlISbrcbh8Nhh5vGxkaCwSAul8t+DKCurg6Hw2G3ABmGgcvlYsSIEaoBEhERkRMvEAgQiUQwTZPTTjuN4uJiXnjhBc477zy70PmTTz5h37597N+/n0GDBvHhhx8SDAYpKiqitbWV3NxcHA4H8+fPJzU1lW3btjF48GBCoRANDQ306dMHn8/Hzp07MczPeqYhERERkcOwRm4VFxdjGAYDBgwAoK2tjdWrV5Ofn09ZWRlFRUUMGDAAn89HfX09Y8eOZevWrVRXV+P3+9m4cSNf+tKXqKmpobCwkKSkJIqLi+nbty9DhgyhpKSEUaNGUVVVxapVqxSARERE5OSzbNkyqqqqmDJlCh999BH19fVcfPHFvPjii5x77rkkJSUxZ84cLrjgAvLy8jq8//8DAufHVGOz5J4AAAAASUVORK5CYII=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖顯示了訓練資料集（Training Set）裏頭各個分類所佔的比例。是一個常見的 Unbalanced Dataset：特定的分類佔了數據的大半比例。&lt;/p&gt;
&lt;p&gt;我們可以看到接近 70 % 的「成對新聞」都是不相關的。這邊的「成對新聞」指的是資料集裡，每一行的假新聞標題 A 以及對應的標題 B 所組成的 pairs。&lt;/p&gt;
&lt;p&gt;現在假設測試資料集（Test Set）的數據分佈跟訓練資料集相差不遠，且衡量一個分類模型的指標是準確度（Accuracy）：100 組成對新聞中，模型猜對幾組。&lt;/p&gt;
&lt;p&gt;這時候如果要你用一個簡單法則來分類所有成對新聞，並同時最大化準確度，你會怎麼做？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對沒錯，就是全部猜 &lt;code&gt;unrelated&lt;/code&gt; 就對了！&lt;/p&gt;
&lt;p&gt;事實上，此競賽在 Evaluation 階段使用 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge#evaluation"&gt;Weighted Categorization Accuracy&lt;/a&gt;，來稍微調降猜對 &lt;code&gt;unrelated&lt;/code&gt; 的分數。畢竟（1）能正確判斷出兩個新聞是 &lt;code&gt;unrelated&lt;/code&gt; 跟（2）能判斷出新聞 B &lt;code&gt;disagreed&lt;/code&gt; 假新聞 A 的價值是不一樣的。（後者的價值比較高，因為比較稀有）&lt;/p&gt;
&lt;p&gt;但使用&lt;a href="https://en.wikipedia.org/wiki/Majority_rule"&gt;多數票決（Majority Votes）&lt;/a&gt;的簡單方法還是能得到 0.666 的成績（滿分為 1）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/major-baseline.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過當你前往該 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/leaderboard"&gt;Kaggle 排行榜&lt;/a&gt;的時候，卻會發現不少人低於這個標準：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/find-the-baseline-for-ml.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一次參加 Kaggle 的人可能會覺得這現象很奇怪。&lt;/p&gt;
&lt;p&gt;但這是由於 Kaggle 競賽 1 天只能提交 2 次結果，因此通常不會有人浪費提交次數來上傳「多數票決」的結果（儘管分數會上升，大家還是會想把僅僅 2 次的上傳機會用來測試自己的 ML 模型的準確度）；另外也是因為不少人是上傳 1、2 次就放棄比賽了。&lt;/p&gt;
&lt;p&gt;但如果你的 ML 或深度學習模型怎樣都無法超過一個簡單法則的 baseline 的話，或許最後上傳該 baseline 的結果也不失為提升排名的最後手段（笑）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        找出 Baseline，可以讓我們判斷手上訓練出來的機器學習模型有多少潛在價值、值不值得再繼續花費自己的研究時間與電腦計算能力。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在我們知道，要保證做出來的模型有點價值，最少要超過 baseline 才可以。以本文來說，就是多數票決法則得到的 0.666 準確度。&lt;/p&gt;
&lt;p&gt;（ baseline 的定義依照研究目的以及比較方法而有所不同）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料前處理：讓機器能夠處理文字"&gt;資料前處理：讓機器能夠處理文字&lt;a class="anchor-link" href="#資料前處理：讓機器能夠處理文字"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要讓電腦或是任何 NLP 模型理解一篇新聞標題在說什麼，我們不能將自己已經非常習慣的語言文字直接扔給電腦，而是要轉換成它熟悉的形式：數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mika-baumeister-703680-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此這章節就是介紹一系列的數據轉換步驟，來將人類熟悉的語言如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;用大蒜鉴别地沟油的方法,怎么鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;轉換成人腦不易理解，但很「機器友善」的數字序列（Sequence of Numbers）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[217, 1268, 32, 1178, 25, 489, 116]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你對此步驟已經非常熟悉，可以假設我們已經對數據做完必要的處理，直接跳到下一章的&lt;a href="#有記憶的循環神經網路_1"&gt;有記憶的循環神經網路&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;這章節的數據轉換步驟包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#文本分詞"&gt;文本分詞（Text Segmentation）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#建立字典並將文本轉成數字序列"&gt;建立字典並將文本轉成數字序列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#序列的-Zero-Padding"&gt;序列的 Zero Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你現在不知道上述所有詞彙的意思，別擔心！&lt;/p&gt;
&lt;p&gt;你接下來會看到文字數據在丟入機器學習 / 深度學習模型之前，通常需要經過什麼轉換步驟。搭配說明，我相信你可以輕易地理解以下每個步驟的邏輯。&lt;/p&gt;
&lt;p&gt;在這之前，先讓我們用 &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; 將訓練資料集讀取進來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;TRAIN_CSV_PATH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;tid1&lt;/th&gt;
&lt;th&gt;tid2&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title1_en&lt;/th&gt;
&lt;th&gt;title2_en&lt;/th&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;There are two new old-age insurance benefits f...&lt;/td&gt;
&lt;td&gt;Police disprove "bird's nest congress each per...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;"If you do not come to Shenzhen, sooner or lat...&lt;/td&gt;
&lt;td&gt;Shenzhen's GDP outstrips Hong Kong? Shenzhen S...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;"If you do not come to Shenzhen, sooner or lat...&lt;/td&gt;
&lt;td&gt;The GDP overtopped Hong Kong? Shenzhen clarifi...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟我們在 Kaggle 預覽的數據一致。不過為了畫面簡潔，讓我們只選取 2 個中文新聞標題以及分類結果（Label）的欄位：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s1"&gt;'label'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了必要的欄位以後，我們可以開始進行數據的前處理了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="文本分詞"&gt;文本分詞&lt;a class="anchor-link" href="#文本分詞"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Text_segmentation"&gt;文本分詞（Text Segmentation）&lt;/a&gt;是一個將一連串文字切割成多個有意義的單位的步驟。這單位可以是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個中文漢字 / 英文字母（Character）&lt;/li&gt;
&lt;li&gt;一個中文詞彙 / 英文單字（Word）&lt;/li&gt;
&lt;li&gt;一個中文句子 / 英文句子（Sentence）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照不同的 NLP 任務會有不同切割需求，但很常見的切法是以單字（Word）為單位，也就是 Word Segmentation。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/word-segmentation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以英文來說，Word Segmentation 十分容易。通常只要依照空白分割，就能得到一個有意義的詞彙列表了（在這邊讓我們先無視標點符號）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'I am Meng Lee, a data scientist based in Tokyo.'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['I', 'am', 'Meng', 'Lee,', 'a', 'data', 'scientist', 'based', 'in', 'Tokyo.']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很明顯地，中文無法這樣做。這時候我們將藉助 &lt;a href="https://github.com/fxsjy/jieba"&gt;Jieba&lt;/a&gt; 這個中文斷詞工具，來為一連串的文字做有意義的切割：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jieba.posseg&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pseg&lt;/span&gt;

&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'我是李孟，在東京工作的數據科學家'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[pair('我', 'r'),
 pair('是', 'v'),
 pair('李孟', 'nr'),
 pair('，', 'x'),
 pair('在', 'p'),
 pair('東京', 'ns'),
 pair('工作', 'vn'),
 pair('的', 'uj'),
 pair('數據', 'n'),
 pair('科學家', 'n')]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如上所示，Jieba 將我們的中文文本切成有意義的詞彙列表，並為每個詞彙附上對應的詞性（Flag）。&lt;/p&gt;
&lt;p&gt;假設我們不需要標點符號，則只要將 &lt;code&gt;flag == x&lt;/code&gt; 的詞彙去除即可。&lt;/p&gt;
&lt;p&gt;我們可以寫一個很簡單的 Jieba 斷詞函式，此函式能將輸入的文本 &lt;code&gt;text&lt;/code&gt; 斷詞，並回傳除了標點符號以外的詞彙列表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以利用 Pandas 的 &lt;code&gt;apply&lt;/code&gt; 函式，將 &lt;code&gt;jieba_tokenizer&lt;/code&gt; 套用到所有新聞標題 A 以及 B 之上，做文本分詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
         &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
         &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新聞標題 A 的斷詞結果如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title1_tokenized&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;"用大蒜鉴别地沟油的方法,怎么鉴别地沟油&lt;/td&gt;
&lt;td&gt;用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新聞標題 B 的結果則為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title2_tokenized&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;警方 辟谣 鸟巢 大会 每人 领 5 万 仍 有 老人 坚持 进京&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;深圳 GDP 首 超 香港 深圳 统计局 辟谣 只是 差距 在 缩小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;GDP 首 超 香港 深圳 澄清 还 差 一点点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;去年深圳GDP首超香港？深圳统计局辟谣：还差611亿&lt;/td&gt;
&lt;td&gt;去年 深圳 GDP 首 超 香港 深圳 统计局 辟谣 还 差 611 亿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;吃了30年食用油才知道，一片大蒜轻松鉴别地沟油&lt;/td&gt;
&lt;td&gt;吃 了 30 年 食用油 才 知道 一片 大蒜 轻松 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;太棒了，將新聞標題切割成一個個有意義的詞彙以後，我們就能進入下一個步驟了！&lt;/p&gt;
&lt;p&gt;另外值得一提的是，不管最後是使用哪種切法，切完之後的每個文字片段在 NLP 領域裡頭習慣上會被稱之為 Token。（如上例中的警方、GDP）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建立字典並將文本轉成數字序列"&gt;建立字典並將文本轉成數字序列&lt;a class="anchor-link" href="#建立字典並將文本轉成數字序列"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當我們將完整的新聞標題切成一個個有意義的詞彙（Token）以後，下一步就是將這些詞彙轉換成一個數字序列，方便電腦處理。&lt;/p&gt;
&lt;p&gt;這些數字是所謂的索引（Index），分別對應到特定的詞彙。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/erik-mclean-1118005-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了方便你理解這小節的概念，想像個極端的例子。假設我們現在就只有一個新聞標題：「狐狸被陌生人拍照」。&lt;/p&gt;
&lt;p&gt;這時候要怎麼將這個句子轉成一個數字的序列呢？跟上一小節相同，我們首先會對此標題做斷詞，將句子分成多個有意義的詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'狐狸被陌生人拍照'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['狐狸', '被', '陌生人', '拍照']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了詞彙的列表以後，我們可以建立一個字典 &lt;code&gt;word_index&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;該 dict 裏頭將上面的 4 個詞彙當作鍵值（Key），每個鍵值對應的值（Value）則為不重複的數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;  
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;word_index&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;{'狐狸': 0, '被': 1, '陌生人': 2, '拍照': 3}&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這個字典以後，我們就能把該句子轉成一個數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['狐狸', '被', '陌生人', '拍照']
[0, 1, 2, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;簡單明瞭，不是嗎？&lt;/p&gt;
&lt;p&gt;如果來了一個新的句子：「陌生人被狐狸拍照」，我們也能利用手上已有的字典 &lt;code&gt;word_index&lt;/code&gt; 如法炮製：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'陌生人被狐狸拍照'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['陌生人', '被', '狐狸', '拍照']
[2, 1, 0, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個簡單的狐狸例子裡頭，&lt;code&gt;word_index&lt;/code&gt; 就是我們的字典；我們利用該字典，將 1 句話轉成包含多個數字的序列，而每個數字實際上代表著一個 Token。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同理，我們可以分 4 個步驟將手上的新聞標題全部轉為數字序列：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將已被斷詞的新聞標題 A 以及新聞標題 B 全部倒在一起&lt;/li&gt;
&lt;li&gt;建立一個空字典&lt;/li&gt;
&lt;li&gt;查看所有新聞標題，裏頭每出現一個字典裡頭沒有的詞彙，就為該詞彙指定一個字典裡頭還沒出現的索引數字，並將該詞彙放入字典&lt;/li&gt;
&lt;li&gt;利用建好的字典，將每個新聞標題裡頭包含的詞彙轉換成數字&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/text-corpus.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這種文字前處理步驟因為出現頻率實在太過頻繁，Keras 有專門的文字前處理模組來提升我們的效率：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt;
&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Tokenizer 顧名思義，即是將一段文字轉換成一系列的詞彙（Tokens），並為其建立字典。這邊的 &lt;code&gt;num_words=10000&lt;/code&gt; 代表我們限制字典只能包含 10,000 個詞彙，一旦字典達到這個大小以後，剩餘的新詞彙都會被視為 Unknown，以避免字典過於龐大。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同上述的步驟 1，我們得將新聞 A 及新聞 B 的標題全部聚集起來，為它們建立字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;corpus_x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title1_tokenized&lt;/span&gt;
&lt;span class="n"&gt;corpus_x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title2_tokenized&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="n"&gt;corpus_x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;corpus_x2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(641086,)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為訓練集有大約 32 萬列（Row）的成對新聞（每一列包含 2 筆新聞：A &amp;amp; B），因此將所有新聞放在一起的話，就有 2 倍的大小。而這些文本的集合在習慣上被稱作語料庫（Text Corpus），代表著我們有的所有文本數據。&lt;/p&gt;
&lt;p&gt;以下是我們語料庫的一小部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
             &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了語料庫以後，接下來就是呼叫 &lt;code&gt;tokenizer&lt;/code&gt; 為我們查看所有文本，並建立一個字典（步驟 2 &amp;amp; 3）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_on_texts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以我們的語料庫大小來說，這大約需時 10 秒鐘。而等到 &lt;code&gt;tokenizer&lt;/code&gt; 建好字典以後，我們可以進行上述第 4 個步驟，請 &lt;code&gt;tokenizer&lt;/code&gt; 利用內部生成的字典分別將我們的新聞標題 A 與 新聞 B 轉換成數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_x2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們看看結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;320543&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[[217, 1268, 32, 1178, 5967, 25, 489, 2877, 116, 5559, 4, 1850, 2, 13]]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;x1_train&lt;/code&gt; 為一個 Python &lt;code&gt;list&lt;/code&gt;，裡頭包含了每一筆假新聞標題 A 對應的數字序列。&lt;/p&gt;
&lt;p&gt;讓我們利用 &lt;code&gt;tokenizer.index_word&lt;/code&gt; 來將索引數字對應回本來的詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['2017', '养老保险', '又', '新增', '两项', '农村', '老人', '人人', '可', '申领', '你', '领到', '了', '吗']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;輕鬆寫意，不是嗎？&lt;/p&gt;
&lt;p&gt;到此為止，我們已經將所有新聞標題轉換成電腦容易處理的數字序列，進入下個步驟！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="序列的-Zero-Padding"&gt;序列的 Zero Padding&lt;a class="anchor-link" href="#序列的-Zero-Padding"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們已經將每個新聞標題的文本轉為一行行的數字序列，你會發現每篇標題的序列長度並不相同：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;' ...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;14 [217, 1268, 32, 1178, 5967]  ...
19 [4, 10, 47, 678, 2558]  ...
19 [4, 10, 47, 678, 2558]  ...
19 [4, 10, 47, 678, 2558]  ...
9 [31, 320, 3372, 3062, 1]  ...
19 [4, 10, 47, 678, 2558]  ...
6 [7, 2221, 1, 2072, 7]  ...
19 [4, 10, 47, 678, 2558]  ...
14 [1281, 1211, 427, 3, 3244]  ...
9 [31, 320, 3372, 3062, 1]  ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最長的序列甚至達到 61 個詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;max_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;max_seq_len&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;61&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而為了方便之後的 NLP 模型處理（見&lt;a href="#有記憶的循環神經網路"&gt;循環神經網路&lt;/a&gt;一章），一般會設定一個 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt; 來讓所有序列的長度一致。&lt;/p&gt;
&lt;p&gt;長度超過此數字的序列尾巴會被刪掉；而針對原來長度不足的序列，我們則會在詞彙前面補零。Keras 一樣有個方便函式 &lt;code&gt;pad_sequences&lt;/code&gt; 來幫助我們完成這件工作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                   &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;x2_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                   &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt; 可以設定成最長序列的長度（此例中的 61）。但這邊為了讓模型可以只看前 20 個詞彙就做出判斷以節省訓練時間，我們先暫時使用 20 這個數字。&lt;/p&gt;
&lt;p&gt;讓我們看看經過 Zero Padding 的第一篇假新聞標題 A 變成什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([   0,    0,    0,    0,    0,    0,  217, 1268,   32, 1178, 5967,
         25,  489, 2877,  116, 5559,    4, 1850,    2,   13], dtype=int32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以清楚看到，因為該新聞標題原本的序列長度並沒有達到剛剛設定的 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt;，因此在總長度為 20 的序列中，前面 6 個值被 Keras 補上 0 以說明該序列中的前 6 個詞彙並不存在。&lt;/p&gt;
&lt;p&gt;我們還可以發現，所有的新聞標題都被轉成長度為 20 的數字序列了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
    
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"所有新聞標題的序列長度皆為 20 !"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;所有新聞標題的序列長度皆為 20 !
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再看一次轉換後的新聞標題：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[   0,    0,    0,    0,    0,    0,  217, 1268,   32, 1178, 5967,
          25,  489, 2877,  116, 5559,    4, 1850,    2,   13],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
          31,  320, 3372, 3062,    1,   95,   98, 3372, 3062]],
      dtype=int32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，可以看到前 5 個新聞標題都已經各自被轉換為長度為 20 的數字序列，而序列裡頭的每個數字則對應到字典裡頭一個特定的 Token，整整齊齊。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/pop-zebra-754186-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，我們已經將原本以自然語言呈現的新聞標題轉換成機器容易理解的數字序列了。很神奇，不是嗎？&lt;/p&gt;
&lt;p&gt;喔不過，別忘了還有 &lt;code&gt;label&lt;/code&gt; 這個文字欄位等著我們的處理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;a class="anchor-link" href="#將正解做-One-hot-Encoding"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到目前為止，我們已經將所有的新聞標題以數字型態表示，只剩分類欄位 &lt;code&gt;label&lt;/code&gt; 要進行從文本到數字的轉換了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;id
0    unrelated
3    unrelated
1    unrelated
2    unrelated
9       agreed
Name: label, dtype: object&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過 &lt;code&gt;label&lt;/code&gt; 的處理相對簡單。跟新聞標題相同，我們一樣需要一個字典將分類的文字轉換成索引：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt; 

&lt;span class="c1"&gt;# 定義每一個分類對應到的索引數字&lt;/span&gt;
&lt;span class="n"&gt;label_to_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'unrelated'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'agreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'disagreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# 將分類標籤對應到剛定義的數字&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;label_to_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'float32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([0., 0., 0., 0., 1.], dtype=float32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在每個分類的文字標籤都已經被轉成對應的數字，接著讓我們利用 Keras 做 &lt;a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f"&gt;One Hot Encoding&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utils&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[1., 0., 0.],
       [1., 0., 0.],
       [1., 0., 0.],
       [1., 0., 0.],
       [0., 1., 0.]], dtype=float32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上述矩陣的每一列即為 1 個 label，而你可以看到現在每個 label 都從 1 個數字變成一個 3 維的向量（Vector）。&lt;/p&gt;
&lt;p&gt;每 1 維度則對應到 1 個分類：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[1, 0, 0]&lt;/code&gt; 代表 label 為 &lt;code&gt;unrelated&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[0, 1, 0]&lt;/code&gt; 代表 label 為 &lt;code&gt;agreed&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[0, 0, 1]&lt;/code&gt; 代表 label 為 &lt;code&gt;disagreed&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用這樣的方式表達 label 的好處是我們可以把分類結果想成機率分佈。&lt;code&gt;[1, 0, 0]&lt;/code&gt; 就代表一組新聞標題 A、B 為 &lt;code&gt;unrelated&lt;/code&gt; 的機率等於 100 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-encoding.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        One Hot Encoding 示意圖
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="#決定如何衡量模型的表現"&gt;決定如何衡量模型的表現&lt;/a&gt;一節我們會看到，給定一組新聞標題 A、B，我們的模型會預測此成對標題屬於每個分類的機率值，比方說 &lt;code&gt;[0.7,  0.2, 0.1]&lt;/code&gt;。而此預測結果代表模型認為這 2 個新聞標題的關係有 70 % 的機率為 &lt;code&gt;unrelated&lt;/code&gt;、20 % 的機率是 &lt;code&gt;agreed&lt;/code&gt; 而 10 % 為 &lt;code&gt;disagreed&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，如果正解也事先用同樣的方式表達的話，會讓我們比較好計算以下兩者之間的差距：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正確的分類的機率分佈（&lt;code&gt;[1, 0, 0]&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;模型預測出的機率分佈（&lt;code&gt;[0.7,  0.2, 0.1]&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在知道預測結果跟正確解答之間差距多少之後，深度學習模型就會自動修正學習方向，想盡辦法拉近這個差距。&lt;/p&gt;
&lt;p&gt;好，到此為止所有的數據都已經被我們轉換成方便機器使用的格式了。最後，讓我們將整個資料集拆成&lt;a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets"&gt;訓練資料集 &amp;amp; 驗證資料集&lt;/a&gt; 以方便之後測試模型的效能。&lt;/p&gt;
&lt;p&gt;（別哀號，我保證這是最後的前處理步驟了！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="切割訓練資料集-&amp;amp;-驗證資料集"&gt;切割訓練資料集 &amp;amp; 驗證資料集&lt;a class="anchor-link" href="#切割訓練資料集-&amp;amp;-驗證資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這部分很簡單，我們只需決定要將整個訓練資料集（Training Set）的多少比例切出來當作驗證資料集（Validation Set）。此例中我們用 10 %。&lt;/p&gt;
&lt;p&gt;但為何要再把本來的訓練資料集切成 2 個部分呢？&lt;/p&gt;
&lt;p&gt;一般來說，我們在訓練時只會讓模型看到訓練資料集，並用模型沒看過的驗證資料集來測試該模型在真實世界的表現。（畢竟我們沒有測試資料集的答案）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/train-valid-test-split.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們會反覆在 Train / Valid Set 上訓練並測試模型，最後用 Test Set 一決生死
                        （&lt;a href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;等到模型在驗證資料集也表現得夠好後，便在最終的測試資料集（Test Set）進行最後一次的預測並將該結果上傳到 Kaggle。&lt;/p&gt;
&lt;p&gt;要了解為何我們需要驗證資料集可以查看&lt;a href="https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set"&gt;這邊的討論&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;簡而言之，當你多次利用驗證資料集的預測結果以修正模型，並讓它在該資料集表現更好時，&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適（Overfitting）&lt;/a&gt;的風險就已經產生了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/cat-peep.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        反覆利用驗證資料集的結果來修正模型表現，事實上就等於讓模型「偷看」到驗證資料集本身的資訊了
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管你沒有直接讓模型看到驗證資料集（Validation Set）內的任何數據，你還是間接地洩漏了該資料集的重要資訊：你讓模型知道怎樣的參數設定會讓它在該資料集表現比較好，亦或表現較差。&lt;/p&gt;
&lt;p&gt;因此有一個完全跟模型訓練過程獨立的測試資料集（Test Set）就顯得重要許多了。（這也是為何我到現在都還沒有碰它的原因）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        機器學習模型努力從夏令營（訓練及驗證資料集）學習技能，並在真實世界（測試資料集）展示其學習結果。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回歸正題，要切訓練資料集 / 驗證資料集，&lt;a href="https://scikit-learn.org/stable/documentation.html"&gt;scikit-learn&lt;/a&gt; 中的 &lt;code&gt;train_test_split&lt;/code&gt; 函式是一個不錯的選擇：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; \
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;train_test_split&lt;/span&gt;

&lt;span class="n"&gt;VALIDATION_RATIO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;
&lt;span class="c1"&gt;# 小彩蛋&lt;/span&gt;
&lt;span class="n"&gt;RANDOM_STATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;9527&lt;/span&gt;

&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x1_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
&lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;VALIDATION_RATIO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RANDOM_STATE&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，我們分別將新聞標題 A &lt;code&gt;x1_train&lt;/code&gt;、新聞標題 B &lt;code&gt;x2_train&lt;/code&gt; 以及分類標籤 &lt;code&gt;y_train&lt;/code&gt; 都分成兩個部分：訓練部分 &amp;amp; 驗證部分。&lt;/p&gt;
&lt;p&gt;以假新聞 A 的標題 &lt;code&gt;x1_train&lt;/code&gt; 為例，本來完整 32 萬筆的 &lt;code&gt;x1_train&lt;/code&gt; 會被分為包含 90 % 數據的訓練資料集 &lt;code&gt;x1_train&lt;/code&gt; 以及 10 % 的驗證資料集 &lt;code&gt;x1_val&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Training Set"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x1_train: &lt;/span&gt;&lt;span class="si"&gt;{x1_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x2_train: &lt;/span&gt;&lt;span class="si"&gt;{x2_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"y_train : &lt;/span&gt;&lt;span class="si"&gt;{y_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x1_val:   &lt;/span&gt;&lt;span class="si"&gt;{x1_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x2_val:   &lt;/span&gt;&lt;span class="si"&gt;{x2_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"y_val :   &lt;/span&gt;&lt;span class="si"&gt;{y_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Test Set"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training Set
----------
x1_train: (288488, 20)
x2_train: (288488, 20)
y_train : (288488, 3)
----------
x1_val:   (32055, 20)
x2_val:   (32055, 20)
y_val :   (32055, 3)
----------
Test Set
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以看到，切割後的訓練資料集有 288,488 筆資料。每一筆資料裡頭，成對新聞標題 A &amp;amp; B 的長度皆為 20 個 Tokens，分類結果則有 3 個；驗證資料集的內容一模一樣，僅差在資料筆數較少（32,055 筆）。&lt;/p&gt;
&lt;p&gt;到此為此，資料前處理大功告成！&lt;/p&gt;
&lt;p&gt;既然我們已經為機器準備好它們容易理解的數字序列資料，接著就讓我們來看看要使用怎麼樣的 NLP 模型來處理這些數據。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="有記憶的循環神經網路_1"&gt;有記憶的循環神經網路&lt;a class="anchor-link" href="#有記憶的循環神經網路"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對這次的 Kaggle 競賽，我們將使用&lt;a href="https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;循環神經網路（Recurrent Neural Network, 後簡稱 RNN）&lt;/a&gt;來處理剛剛得到的序列數據。&lt;/p&gt;
&lt;p&gt;RNN 是一種有「記憶力」的神經網路，其最為人所知的形式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同上圖等號左側所示，RNN 跟一般深度學習中常見的&lt;a href="https://en.wikipedia.org/wiki/Feedforward_neural_network"&gt;前饋神經網路（Feedforward Neural Network, 後簡稱 FFNN）&lt;/a&gt;最不一樣的地方在於它有一個迴圈（Loop）。&lt;/p&gt;
&lt;p&gt;要了解這個迴圈在 RNN 裏頭怎麼運作，現在讓我們想像有一個輸入序列 X（Input Sequence）其長相如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = [ x0, x1, x2, ... xt ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;不同於 FFNN，RNN 在第一個時間點 &lt;code&gt;t0&lt;/code&gt; 並不會直接把整個序列 X 讀入。反之，在第一個時間點 &lt;code&gt;t0&lt;/code&gt;，它只將該序列中的第一個元素 &lt;code&gt;x0&lt;/code&gt; 讀入中間的細胞 A。細胞 A 則會針對 &lt;code&gt;x0&lt;/code&gt; 做些處理以後，更新自己的「狀態」並輸出第一個結果 &lt;code&gt;h0&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在下個時間點 &lt;code&gt;t1&lt;/code&gt;，RNN 如法炮製，讀入序列 X 中的下一個元素 &lt;code&gt;x1&lt;/code&gt;，並利用剛剛處理完 &lt;code&gt;x0&lt;/code&gt; 得到的細胞狀態，處理 &lt;code&gt;x1&lt;/code&gt; 並更新自己的狀態（也被稱為記憶），接著輸出另個結果 &lt;code&gt;h1&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剩下的 &lt;code&gt;xt&lt;/code&gt; 都會被以同樣的方式處理。但不管輸入的序列 X 有多長，RNN 的本體從頭到尾都是等號左邊的樣子：迴圈代表細胞 A 利用「上」一個時間點（比方說 &lt;code&gt;t1&lt;/code&gt;）儲存的狀態，來處理當下的輸入（比方說 &lt;code&gt;x2&lt;/code&gt; ）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但如果你將不同時間點（&lt;code&gt;t0&lt;/code&gt;、&lt;code&gt;t1&lt;/code&gt; ...）的 RNN 以及它的輸入一起截圖，並把所有截圖從左到右一字排開的話，就會長得像等號右邊的形式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將 RNN 以右邊的形式表示的話，你可以很清楚地了解，當輸入序列越長，向右展開的 RNN 也就越長。（模型也就需要訓練更久時間，這也是為何我們在資料前處理時&lt;a href="#序列的-Zero-Padding"&gt;設定了序列的最長長度&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;為了確保你 100 % 理解 RNN，讓我們假設剛剛的序列 X 實際上是一個內容如下的英文問句：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = [ What, time, is, it, ? ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而且 RNN 已經處理完前兩個元素 &lt;code&gt;What&lt;/code&gt; 和 &lt;code&gt;time&lt;/code&gt; 了。&lt;/p&gt;
&lt;p&gt;則接下來 RNN 會這樣處理剩下的句子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 一次只讀入並處理序列的「一個」元素
                        （&lt;a href="https://www.youtube.com/watch?time_continue=2&amp;amp;v=LHXXI4-IEns" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你可以想像為何 RNN 非常適合拿來處理像是自然語言這種序列數據了。&lt;/p&gt;
&lt;p&gt;就像你現在閱讀這段話一樣，你是由左到右逐字在大腦裡處理我現在寫的文字，同時不斷地更新你腦中的記憶狀態。&lt;/p&gt;
&lt;p&gt;每當下個詞彙映入眼中，你腦中的處理都會跟以下兩者相關：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前面所有已讀的詞彙&lt;/li&gt;
&lt;li&gt;目前腦中的記憶狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然，實際人腦的閱讀機制更為複雜，但 RNN 抓到這個處理精髓，利用內在迴圈以及細胞內的「記憶狀態」來處理序列資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/thought-catalog-196661-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 按照順序，處理一連串詞彙的機制跟我們理解自然語言的方式有許多相似之處
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，你應該已經了解 RNN 的基本運作方式了。現在你可能會問：「那我們該如何實作一個 RNN 呢？」&lt;/p&gt;
&lt;p&gt;好問題，以下是一個簡化到不行的 RNN 實現：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;input_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;output_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output_t&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在 RNN 每次讀入任何新的序列數據前，細胞 A 中的記憶狀態 &lt;code&gt;state_t&lt;/code&gt; 都會被初始化為 0。&lt;/p&gt;
&lt;p&gt;接著在每個時間點 &lt;code&gt;t&lt;/code&gt;，RNN 會重複以下步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;讀入 &lt;code&gt;input_sequence&lt;/code&gt; 序列中的一個新元素 &lt;code&gt;input_t&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;f&lt;/code&gt; 函式將當前細胞的狀態 &lt;code&gt;state_t&lt;/code&gt; 以及輸入 &lt;code&gt;input_t&lt;/code&gt; 做些處理產生 &lt;code&gt;output_t&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;輸出 &lt;code&gt;output_t&lt;/code&gt; 並同時更新自己的狀態 &lt;code&gt;state_t&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不需要自己發明輪子，在 Keras 裏頭只要 2 行就可以建立一個 RNN layer：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;rnn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SimpleRNN&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用深度學習框架可以幫我們省下非常多的寶貴時間並避免可能的程式錯誤。&lt;/p&gt;
&lt;p&gt;我們後面還會看到，一個完整的神經網路通常會分成好幾層（layer）：每一層取得前一層的結果作為輸入，進行特定的資料轉換後再輸出給下一層。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/nn-layers.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        常見的神經網路形式。中間紅框內有迴圈的就是 RNN 層
                        （&lt;a href="https://www.slideshare.net/microlife/from-neural-networks-to-deep-learning" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，相信你現在已經掌握基本 RNN 了。事實上，除了 &lt;code&gt;SimpleRNN&lt;/code&gt; 以外，Keras 裡頭還有其他更常被使用的 Layer，現在就讓我們看看一個知名的例子：長短期記憶。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="記憶力好的-LSTM-細胞"&gt;記憶力好的 LSTM 細胞&lt;a class="anchor-link" href="#記憶力好的-LSTM-細胞"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們再看一次前面的簡易 RNN 實作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="c1"&gt;# 細胞 A 會重複執行以下處理&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;input_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;output_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output_t&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在了解 RNN 的基本運作方式以後，你會發現 RNN 真正的魔法，事實上藏在細胞 A 的 &lt;code&gt;f&lt;/code&gt; 函式裏頭。&lt;/p&gt;
&lt;p&gt;要如何將細胞 A 當下的記憶 &lt;code&gt;state_t&lt;/code&gt; 與輸入 &lt;code&gt;input_t&lt;/code&gt; 結合，才能產生最有意義的輸出 &lt;code&gt;output_t&lt;/code&gt; 呢？&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;SimpleRNN&lt;/code&gt; 的細胞 A 裡頭，這個 &lt;code&gt;f&lt;/code&gt; 的實作很簡單。而這導致其記憶狀態 &lt;code&gt;state_t&lt;/code&gt; 沒辦法很好地「記住」前面處理過的序列元素，造成 RNN 在處理後來的元素時，就已經把前面重要的資訊給忘記了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/forget-what-had-said-before.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就好像一個人在講了好長一段話以後，忘了前面到底講過些什麼的情境。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6"&gt;長短期記憶（Long Short-Term Memory, 後簡稱 LSTM）&lt;/a&gt;就是被設計來解決 RNN 的這個問題。&lt;/p&gt;
&lt;p&gt;如下圖所示，你可以把 LSTM 想成是 RNN 中用來實現細胞 A 內部處理邏輯的一個特定方法：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/lstm-cell.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        以抽象的層次來看，LSTM 就是實現 RNN 中細胞 A 邏輯的一個方式
                        （&lt;a href="https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基本上一個 LSTM 細胞裡頭會有 3 個閘門（Gates）來控制細胞在不同時間點的記憶狀態：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forget Gate：決定細胞是否要遺忘目前的記憶狀態&lt;/li&gt;
&lt;li&gt;Input Gate：決定目前輸入有沒有重要到值得處理&lt;/li&gt;
&lt;li&gt;Output Gate：決定更新後的記憶狀態有多少要輸出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這些閘門控管機制，LSTM 可以將很久以前的記憶狀態儲存下來，在需要的時候再次拿出來使用。值得一提的是，這些閘門的參數也都是神經網路自己訓練出來的。&lt;/p&gt;
&lt;p&gt;下圖顯示各個閘門所在的位置：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/lstm-cell-detailed.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        LSTM 細胞頂端那條 cell state 正代表著細胞記憶的轉換過程
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想像 LSTM 細胞裡頭的記憶狀態是一個包裹，上面那條直線就代表著一個輸送帶。&lt;/p&gt;
&lt;p&gt;LSTM 可以把任意時間點的記憶狀態（包裹）放上該輸送帶，然後在未來的某個時間點將其原封不動地取下來使用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/accumulation-conveyor-101.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為這樣的機制，讓 LSTM 即使面對很長的序列數據也能有效處理，不遺忘以前的記憶。&lt;/p&gt;
&lt;p&gt;因為效果卓越，LSTM 非常廣泛地被使用。事實上，當有人跟你說他用 RNN 做了什麼 NLP 專案時，有 9 成機率他是使用 LSTM 或是 &lt;a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit"&gt;GRU（LSTM 的改良版，只使用 2 個閘門）&lt;/a&gt; 來實作，而不是使用最簡單的 &lt;code&gt;SimpleRNN&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，在這次 Kaggle 競賽中，我們的第一個模型也將使用 LSTM。而在 Keras 裡頭要使用 LSTM 也是輕鬆寫意：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;lstm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在，既然我們已經有了在&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理步驟&lt;/a&gt;被轉換完成的序列數據，也決定好要使用 LSTM 作為我們的 NLP 模型，接著就讓我們試著將這些數據讀入 LSTM 吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="詞向量：將詞彙表達成有意義的向量"&gt;詞向量：將詞彙表達成有意義的向量&lt;a class="anchor-link" href="#詞向量：將詞彙表達成有意義的向量"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在將序列數據塞入模型之前，讓我們重新檢視一下數據。比方說，以下是在訓練資料集裡頭前 5 筆的假新聞標題 A：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"新聞標題 {i + 1}: "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題 1: 
[   0    0    0  185  300   72 4029   37    1  121  250   95   30  511
   92 2358   33 2565   19   55]

新聞標題 2: 
[   0    0    0    0    0    0    0    0    0    0    0    0    0 7149
   54  130 8454 3404 6172   66]

新聞標題 3: 
[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0   87 6339   59 5236 2848]

新聞標題 4: 
[   0    0    0    0    0    0    0   59   18 1780    1   63   30 2526
 1017 1466   25   11  139   50]

新聞標題 5: 
[   0    0    0    0    0   25    9   24 1402   12  667   63   64  483
 9523  303 1402   18  332 3258]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到，每個新聞標題都被轉成長度為 20 的數字序列。裡頭的每個數字都代表著一個詞彙（ &lt;code&gt;0&lt;/code&gt; 代表 &lt;a href="#序列的-Zero-Padding"&gt;Zero Padding&lt;/a&gt;）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(288488, 20)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而我們在訓練資料集則總共有 288,488 筆新聞標題，每筆標題如同剛剛所說的，是一個包含 20 個數字的序列。&lt;/p&gt;
&lt;p&gt;當然，我們可以用 &lt;code&gt;tokenizer&lt;/code&gt; 裡頭的字典 &lt;code&gt;index_word&lt;/code&gt; 還原文本看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"新聞標題 {i + 1}: "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題 1: 
['', '', '', '皮肤', '白', '到', '逆', '天', '的', '范冰冰', '美白', '方法', '大', '揭秘', '做', '面膜', '个', '小动作', '就', '可以']

新聞標題 2: 
['', '', '', '', '', '', '', '', '', '', '', '', '', '张家口', '一个', '男子', '持', '猛', '踹', '孩子']

新聞標題 3: 
['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '种', '杂草', '农民', '年收入', '几十万']

新聞標題 4: 
['', '', '', '', '', '', '', '农民', '能', '享受', '的', '10', '大', '政府', '特别', '补助', '农村', '人', '得', '知道']

新聞標題 5: 
['', '', '', '', '', '农村', '这', '3', '类人', '有', '近', '10', '万', '宅基地', '补偿款', '还有', '类人', '能', '免费', '住房']

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其他新聞標題像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;訓練資料集中的新聞標題 B &lt;code&gt;x2_train&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;驗證資料集中的新聞標題 A &lt;code&gt;x1_val&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;驗證資料集中的新聞標題 B &lt;code&gt;x2_val&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也都是以這樣的數字序列形式被儲存。&lt;/p&gt;
&lt;p&gt;但事實上要讓神經網路能夠處理標題序列內的詞彙，我們要將它們表示成向量（更精準地說，是&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F"&gt;張量：Tensor&lt;/a&gt;），而不是一個單純數字。&lt;/p&gt;
&lt;p&gt;如果我們能做到這件事情，則 RNN 就能用以下的方式讀入我們的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-process-vectors.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        注意：在每個時間點被塞入 RNN 的「詞彙」不再是 1 個數字，而是一個 N 維向量（圖中 N 為 3）
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以現在的問題變成：&lt;/p&gt;
&lt;p&gt;「要怎麼將一個詞彙表示成一個 N 維向量 ？」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其中一個方法是我們隨便決定一個 N，然後為語料庫裡頭的每一個詞彙都指派一個隨機生成的 N 維向量。&lt;/p&gt;
&lt;p&gt;假設我們現在有 5 個詞彙：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;野狼&lt;/li&gt;
&lt;li&gt;老虎&lt;/li&gt;
&lt;li&gt;狗&lt;/li&gt;
&lt;li&gt;貓&lt;/li&gt;
&lt;li&gt;喵咪&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照剛剛說的方法，我們可以設定 N = 2，並為每個詞彙隨機分配一個 2 維向量後將它們畫在一個平面空間裡頭：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些代表詞彙的向量被稱之為詞向量，但是你可以想像這樣的隨機轉換很沒意義。&lt;/p&gt;
&lt;p&gt;比方說上圖，我們就無法理解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何「狗」是跟「老虎」而不是跟同為犬科的「野狼」比較接近？&lt;/li&gt;
&lt;li&gt;為何「貓」的維度 2 比「狗」高，但卻比「野狼」低？&lt;/li&gt;
&lt;li&gt;維度 2 的值的大小到底代表什麼意義？&lt;/li&gt;
&lt;li&gt;「喵咪」怎麼會在那裡？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這是因為我們只是將詞彙隨機地轉換到 2 維空間，並沒有讓這些轉換的結果（向量）反應出詞彙本身的語意（Semantic）。&lt;/p&gt;
&lt;p&gt;一個理想的轉換應該是像底下這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAAIcCAYAAAA5Xcd7AADqIklEQVR4nOzdd5gV5fn/8feU0/ZsZztt6UjvCqJosCBobOjXbtRYMWqaJSbxZxJjTWI0GntM1NgQRQUbgtI7SGeXZRfYBbb33dNm5vfH2Rl2l6VqRD3367q4hHNm5swp657P3M9zP4plWRZCCCGEEEIIIcQPnHqsT0AIIYQQQgghhPg2SAAWQgghhBBCCBETJAALIYQQQgghhIgJEoCFEEIIIYQQQsQECcBCCCGEEEIIIWKCBGAhhBBCCCGEEDFBArAQQgghhBBCiJggAVgIIYQQQgghREyQACyEEEIIIYQQIiZIABZCCCGEEEIIERMkAAshhBBCCCGEiAkSgH8ALMvCsqxvfNvW+3yd+4UQQgghhBDiu0CxJL106EiDoqIoKIpyyGOpattrDqZpHtbx2+/3XWFZFoqiOM/vQK+BEEIIIYQQQhxrMRmALcs6aPBUVfU7H+Rav212wG4dwjs6f9M0MQwDAF3XD+s5RiIR59i6ru93DoqiUF9fT0JCAgCGYbQ57sEuDAghhBBCCCHEt0k/9CY/PIqioGnaQbfZvn07kUikTXhrHTpb3x6JREhPTyctLc3ZpnUonT17NkuXLiUpKYnrr7+exMREFEUhHA6zfft2TNM8aPVYVVV69+7dJoDa21dUVPCrX/2K+vp67rzzTo4//vgOj6EoCjNmzOCZZ54hKyuLJ554gtTU1EO+Vn/605+YP38+kyZN4s4773SOZRgGmqYxd+5c7rvvPgYOHMjNN9/M0KFDD3lMIYQQQgghhDgWYioAm6aJqqosXLiQL774Ar/f71REIVr5bW5u5sQTT+SVV15h5cqV+Hw+p1rcURjWdZ2qqipuuukm7rjjDkzTRNO0NtuuWrWKZ599lm7dunH99dc7w5mrq6u5/vrraW5uRlXV/arS9m0+n4/p06eTmZnpBOtAIICiKNTU1LBhwwZqa2upqKigubkZgJKSEh577DFne13X2bFjByUlJVRWVvLLX/4Sj8eDZVlEIhGys7P5f//v/6HruhNyAfbu3cumTZsYPnz4fq9jRUUFjzzyCLW1tSxYsADTNOnbty/BYNAJyRdffDH9+vVz9hFCCCGEEEKIYyUmA/CyZcv4y1/+QkZGhlN9tUNfRUUFqqridrsJBoN4PB4gGnhbh2VN05zwGIlEnPvsULpjxw4gGpAbGhrIyMggPj6edevWkZSURFJSEj6fD8MwnGHD7efS2o/Z+nEVRSEvL49bb73VGdKsKArJyck88sgjPPbYYyQkJHD55ZezcuVKAoGAEzw1TSMhIQHLsli5cqUTcsPhMFlZWYTDYafKbJ+Hy+XC5/PhcrmcoeP2uf75z39m586dzmv10Ucf8cEHH5CQkOBcTBg9ejT9+vWTRllCCCGEEEKIYy6mArAtOTmZnj17kpqaSmNjI5FIBE3T8Pv9pKSk0LVrV3bs2EEgEGDSpEncfPPN1NbW8utf/5qysjJOPfVUbrvtNmpqarjrrrvaVExVVWXDhg3ceuutTmgE8Pl8NDY28stf/tIJhg888ABut5uysjKuueYabr75ZqeC6/P5ePbZZ3nppZdITExsc/7hcJjS0lIn0LvdbizLorq6GsuyqKmpITc3l2effZba2lpUVSU+Pp6ZM2fy9ttvk5qayj333EN2djbBYBDTNElMTHTCfvvh2K0r4PbQ8ccff5w5c+agKApDhw5l5MiRqKpKTU0NH374IaFQiJycHKf6K/OAhRBCCCGEEMdaTAVgu7p5xRVXcNFFF6EoCnfccQfz589nzJgxPP3002iahsvl4uOPP8Y0TbKzs+nXrx8QraCGQiG6dOlC//79gWjgbV/dbB327PvtkGz/2w6VpmnidrvJy8vjzTffJBwOA9HK65YtW3C73W2GRluWRY8ePXj33XfRdZ3S0lJ+/vOfU11dza9+9SvOOOMMmpub6d69O3/84x/58ssv0XWdQCCAYRj4/X5CoRCPPfYYiqIQHx9PTU0Nd9xxB6NGjQIgPz+ff/7zn6iqyubNm0lKSuKrr75i2rRp/OhHP2Lnzp08++yzuN1uhg0bxgsvvIDL5QLg3nvvpbGxEZfLxf3330+PHj3+F2+lEEIIIYQQQhyxmArANo/H41Q77TmvLpeLpKQkAGfYsc/nY926dfz73/8mGAwSDAbx+XysX7+ef//73zQ3NxMOh9vMbTVNk0GDBvHyyy+j6zq7d+/mt7/9LYZh4HK5eOCBB8jNzXWqooZhEBcXx9KlS/nwww+d8GyaJmlpaSQmJrYZAg0QFxdHYWEhwWCQiooKIpEIbrebmpoavvrqK3Rdp3v37uzevZtdu3YxcuRIevfuzfbt29m6dStxcXGMHj0aTdNYt24dxcXF1NTUOMevqqri7bffRlVVkpKS8Hq9FBcXs2HDBj7++GN8Ph/Jyck0Njaiqip/+ctfCAaD7Ny5k6VLl+L3+/F4PMybN4/PPvsM0zS55ppr6NWrV5tquRBCCCGEEEJ8m2IyALevwNr/tcOsaZpYloXH42HdunUsWLAAVVXp1KkTcXFxrF+/nkWLFqGqKhkZGfs1x0pKSmLYsGEAvPnmmzQ2NhIfH08wGOQ///kPv/nNb+jfvz/l5eUoikJzczNjx45l/PjxhMNh57EXL17MkiVL8Pl8zvHt7e+//35KSkoIhUKkpaXhcrn4+9//jq7rJCQkMHv2bOLj4zFNk1NOOYVLL72UefPmcf/99+PxeLjlllvw+/384Q9/YMuWLU4FFyAjI4NLLrkEgLVr11JaWkqXLl2YNGkScXFxLFmyhOLiYhITE1m2bBkff/wxqqoSFxdHUlISdXV1hMNh/vnPfzoB/swzz5QALIQQQgghhDimYjIAt57Las/TtYc+2/dDdHmjzp07M2rUKEKhEPn5+YTDYTIzMxk9ejTBYJDt27fvd/xIJIKu68yYMYPp06cTFxeHYRjous7SpUu57LLLuOOOOzj11FNRVZVQKERubi5nnnkmwWAQiFapd+3axfz58/cLjKqqkpCQQGpqKpMnT2bJkiVUV1dz9dVXs2jRIqertGEYxMfH89xzz/HEE0+g6zp+v5+6ujrOOeccJ6x7vV7nQkAkEqFHjx48+uijAPzsZz8jLy+PyZMn89BDDwHRUPyb3/yGwsJCxo8fz4knnohpmuTl5VFcXEyfPn3o3LkzdXV1vPvuuwSDwTYBWwghhBBCCCGOhZgKwHb1MRAIsHbtWsLhMLt378bj8VBTU8PChQvRNI3+/fvjdrtpampi3Lhx/P73v6e2tpYLL7yQ4uJipkyZwv33309VVRUXXXRRmyHK9pJDc+fO5YEHHiAuLg6/3099fT3x8fHk5uayefNm/vSnP1FVVYXP5yMuLo7333+fGTNmtJlPrOt6h0OgITpMW1VV7rnnHm699Vaqqqr4/e9/z1VXXcWWLVuc+caBQIDTTjuNMWPGsG3bNj7++GP8fj9XXXUVbrebOXPmUFZWtl/Ibr2eMdBmHvKwYcPo378/a9euZfTo0Vx33XUA/PnPf+ajjz7iZz/7GePGjaO6upr33nuPSCTyzb2JQgghhBBCCHGUYnJh1rKyMm677TamTZvGzp078fv97Nq1i2nTpnHrrbdSUlLSpjKsaZozDLmj21rTdZ158+bxm9/8hurqas455xwmT55MbW0tbrebhx9+mP79+zNgwACmTJnirOfr9XpJT08nMzPT+eP3+/dbG9g+B0VRiEQi/P3vf6e4uBhFUfjrX/9KaWmpc+723OTc3FyOP/54+vbt66xTPHr0aI4//nhnWaSO2EPB7TnStbW1zJ8/n0gk4gwXb2xsBGD16tW88847qKrK1q1bAWhqaurw/IUQQgghhBDiWIipCrDNDrG6rjvr+SqKgq7r6LrurHMbHx/P6tWruffeewkEAjQ3N+P3+1m1ahX33nsvTU1NGIaB2+1uU0H95JNP2LNnDwMHDuT222/nxRdfRFEUQqEQmZmZPPbYYzQ2NpKVlYVhGDQ0NHDFFVdw2223OdVSXdd56qmn+Mc//rHfMkiAE4CffPJJOnXqhNvt5vHHH6dTp04kJSVhmiZVVVU0NTXx3HPP8Y9//AOv10tqair19fVceumlWJZFVlYWHo8HwzDaBGF7mLimaXi9XtavX89ll12G3+/npJNOAqIBOS4ujpKSEn7/+987naYfeugh9uzZw9SpU53XVwghhBBCCCGOtZgMwBkZGTzzzDOYpskjjzzCmjVrGDhwIPfeey+aptG5c2fKy8tpaGhgw4YNLF++HE3TSE9Px+PxUFhYyOrVq525uFVVVc76vQBnnHEGs2bN4v777yclJYVgMIiu67hcLhoaGpylgfbu3YumaSQkJLB48WL27NnTJgAXFhaSmJjYYdMoe6j1jTfeyBdffEF9fT233HILH3/8sTMH+fbbb+eCCy5A13VUVWXVqlW89dZbJCQk8NBDDxEMBnnuuefQdZ2cnBwn+ANUVFSwZs0aCgoK8Pv9lJSUUFpayimnnIKiKE5VeO/evfziF79g9erVnHzyyZx//vm8+OKLPPnkk5SVleHz+aitrZUQLIQQQgghhDjmYioA2+HO5/MxdOhQAJKSkgiHwyQmJjJixAggWtk866yzGD58OG63G1VVCQaDfPzxxzQ2NtK3b19OOOEEp2ra1NTEyJEjnccZMWIE//jHPxg9ejSGYRAMBqmursbn82GaJoZhOEsg1dTUUF9fz5o1a1i6dKlzDNM08fl8ztrDrYcS2wFU13XuvPNOioqK+Oqrr7j77rvZsGEDhYWFlJSUsG3bNgzDwDRNdF2nsbERTdMwTZPCwkJniLPL5eLdd99l4sSJ+P1+nn/+eV588UWCwaCzTjHA+eefz1VXXdVmCHZaWhppaWlUVlZyww03MHLkSDIzM3nrrbe45JJLuOuuu5zXXUKwEEIIIYQQ4liKqQDcmh0oW4fRcDiMy+VCVVVuuumm/fb58ssvKSsrY/To0dx1110HPHZycjITJkwAQNM0xowZQzAYpEuXLuTk5Djb5eTkcOmllxIfHw/gVGAty8Ln89HU1EQgECA+Pt7Zxqbr0bfuL3/5C7t37wbgkUceobKyEr/fT21tLT//+c+pq6tD13UMw8Dv95OamophGLz00ktomkZSUhIej4ePPvqIf/3rX9x6660Eg0EKCwvJysrC6/VSX1/PxIkTefLJJ/d7/TRNY9q0aVx22WXcddddXH/99dx55508/fTTVFRUEA6HURQFl8vlPDchhBBCCCGEOBZiMgC37nDcuprqcrkoLy9HVVU2btxIJBJxQmlTUxPhcNgZAv3FF19gmqaz3FBiYiKjRo1yjmdZFkVFRYRCISZPnszkyZP517/+xYMPPsiYMWM4+eSTmT59OosWLeKWW27hrLPOanOOe/bs4S9/+QsJCQn86le/co6pKIozv3f37t08+eSTZGVl4XK5ePrpp1EUhaSkJDp37sxjjz1Gc3MzXq8XTdPw+/0kJiaSlpbGjBkz+M9//kN6ejrXXnstc+fO5fTTTwdg4sSJbN++nQkTJjBjxgzmz59PXFwclmWxZcsWXnjhBdavX09mZiafffYZe/bsobm5ma+++oq4uDg+/fRTSkpKqKmpwbIsvF4vTzzxBOeccw4XXXSRrAUshBBCCCGEOCZiMgC3nutqN78qKyvj7rvvZv369fzyl7/kN7/5DfX19ei67gRmt9uN3+9n5cqVLFu2DMDphDxmzBheffXVNo/z8MMPM3/+fIYNG8b999/PU089RVFREbfccgsjRozgqaeeorS0lDvvvBOv18spp5zidG++9957mTNnDnFxceTm5nL11VdjGAaapuHxeLjttttobGwkEAjw2muv0dTUxE9+8hN69+6Nqqp4PB5CoRCGYRAIBNA0jUAgwN69eykqKmLnzp243W7q6uooKiqic+fOzjzmvn378te//hWAzz//HNM0MU0TRVHYuXMnr7zyCsnJyaiqytq1a1m9ejV+v5/4+Hh0XWfNmjUsWbIEwLntgw8+ICkpSQKwEEIIIYQQ4piJyQBcXl5Ofn4+a9euZceOHSQkJLBnzx42bNhAUlISiqLg9/sxDMMZamxZFpFIxJkz6/V62yw11HqZJEVR2Lt3r1NFTktLIyMjg+TkZDIyMtB1nZSUFB566CFuv/12QqEQv/3tb3n33XedtXt/97vfkZ+fT0NDA08++SQjRoxg8ODBADQ3NzNx4kS8Xi9FRUW89tprGIbBqFGjmDhxIpFIhLy8PH772986Xa3r6uoAnDnAqamppKSk0NTUxBNPPMGePXvQdZ1hw4Y5lW17vjLsmz+dm5vL7bff7swBjo+Pp7i4mPnz5xMKhejRowdjxoxB13Vn+LSiKITDYYYPH97mWEIIIYQQQgjxbYqpAGxXUF944QVeeuklVFVF0zQMw8Dr9TJ8+HAmTJjA0KFDeemll5z5q4qi0NDQwK233kpZWRlnnXUWt99+uzNE2rIsPB4PsC8Af/nll9TW1uJyuZgwYQJxcXFORdYOl+PHj+fGG2/kL3/5C2eddRYJCQm8/fbbPPjgg1x99dVceOGF/Otf/yISifDII4/w0ksv4XK5WL58Obfffjtut9t5Tl6vlz/96U888MADNDQ0MG3aNO68805effVVEhISOPPMM1EUhUAggNvtZu3atWzYsIH4+Hiuu+46wuEwY8eOBXDOr32lHKBfv37ce++9zmtqmia/+MUvCIfDRCIRbrvtNtauXUtRURE33ngjAwcO3O99kAAshBBCCCGEOBZiKgDbjjvuOCKRCNnZ2XTr1o3hw4dz0kknMWLECLxeLwCpqalt9rGrwZFIhJSUFHJzczs8tqIoNDc38/bbb2NZFsnJyZx44okEAgEURUFVVerr653K8Q033MBJJ53EcccdB8D27dsJBoO88cYbfPjhh2zdupVFixaxatUqnnvuOaZNm4aiKLjdbjweD6ZpEolEnMDq9XqdTtWaplFaWoqqqkQiEW666Sbneb3wwgssWbKE9PR07rnnHqfTM0SrxIdiGAYLFy7kySefZOvWrTQ2NnLllVdiWRZ/+9vfcLlcLFiwgHHjxnH99dczbNiwI32bhBBCCCGEEOIbFVMB2A6d48aN46GHHmLkyJHk5uY6w5whuv7to48+SjAYdLa3h/AGAgESExNZtmwZv/zlL9tUSZuamhg3bhxXXnkl7777LqtXr8bn83HqqaeSnZ1NdXU1EJ0Tu3jxYu6++24SExMxTROv18uMGTOoqalh4cKFJCcnk52dTZcuXZg2bRoLFixwqtUAY8aMYebMmbhcLkpKSrj11luprq7m7rvvZsqUKTQ1NZGVlUVRURFTp07ls88+44knnqCmpob7778fTdOoqalxhkM3NjY6r4GqqtTU1LBixQoMwyAvL8+5KACwbds2li1bxpw5c1i7di3BYBDDMJg4cSK//OUv0TSNRx55hDfffJOtW7fy+eefs2LFCq688kquuOIKkpOTpQIshBBCCCGEOCZiKgDbwSsjI4P/+7//c26357mqqko4HGbmzJk0NTWhaZrTAEtRFHw+H4qisG3bNjZu3Ojsr2ka1dXV+P1+rrzySkaNGsVZZ53F4sWLueKKKwBITExk0KBBzJ49m5SUFN555x3nce1h03an5vLycs4++2wABg0axC9+8Qu6d+/OxIkTsSyLuLg44uLi2jwvXdfp0aMHnTp1olOnTgD06dOHv/zlL7z66qu88sorTJkyhSuuuAK3282ePXuIj493mmrZw54hOsf47rvvprm5Gb/fTzgcduY433///XzxxRf4fD5UVSUnJ4dLLrmEa665BpfLBcCll17KOeecwxtvvMGLL75IY2Mjjz32GFVVVdx3333OHGMhhBBCCCGE+DbFVAC2WZbVpnprB11FUfB4PJx11lltKsC21g2hWt9nd4IeMmQIEO2i/PTTT7N27Vr69esHREPyXXfdRUJCAlu3bqW5uRlVVdsEbNM0SUxMZMqUKVx//fXO0kfXXnutc952iLfPPxgMEggEaGpqoqmpCcuynOHa9rGvuOIKJk+eTGJiIg899BBLliwhOTmZcDjMKaec4ixxZB87KyuLUaNGsWzZMjRNo2/fvpx33nkAnHvuuaxbt46hQ4cyYcIEJk+eTHZ2dpvzMwyD+Ph4fvrTn3LCCSfwhz/8gYKCAqZOnfqNv5dCCCGEEEIIcbgUy05J4htzqGV+QqGQ00Cr/X4ul8uppNrsymzr0G0/RlNTE4sWLSIUCjF8+HBycnL2e/zW/166dCnbt29H13UyMjIYO3YsHo9nv31KS0udYdKZmZkkJCQAEAwGKS4upkePHs75tG+YZT+maZrOcOutW7dy/PHHH9HrKIQQQgghhBDfJAnA/0Pth/q2rvYear/2gfLr+rpr73a0v93R+mDHbf0ayPq/QgghhBBCiGNJAvAxcKiX/EhDYus5zIcTrls//oH2sYdf2+djb2PffiQB3d5H5v0KIYQQQgghjiUJwEIIIYQQQgghYoKU5IQQQgghhBBCxAQJwEIIIYQQQgghYoIEYCGEEEIIIYQQMUECsBBCCCGEEEKImCABWAghhBBCCCFETJAALIQQQgghhBAiJkgAFkIIIYQQQggREyQACyGEEEIIIYSICRKAhRBCCCGEEELEBAnAQgghhBBCCCFiggRgIYQQQgghhBAxQQKwEEIIIYQQQoiYIAFYCCGEEEIIIURM0I/1CRwLlmVhWRaKoqAoivP39tu0v639/UCbbezjHoj9eB09zsH27Wi/g51T6/1a32Yf42jO83/NNE1Udd/1mNbvkX1O3zTLsjBNc7/30D6Pju5TFKXNebY+/wO9bvZz6Wg/e98jcaDjtD/P/7WOPkft30M48OfwmzqHI/kZbH+Orffr6NwO9t4d6mf2QPcd7HPQ/r5v4+dACCGEECKWKNahvi3GmI6+ULfWUWA+0JfnI32sw2WaJpZloWlah//+JhwqtB1sP/h2vqjbz7v9Y7UO+h35Xwb8byt8/q99H55HRz+HR/Mz2P5zfrDb/tcXh1qH6iP92RNCCCGEEIcWUwHY/gJbU1NDXl4e/fr1Y+fOncyaNYupU6fSs2dPVFXFsiz+/e9/U1lZybXXXktKSsp+x6ioqOCNN96gf//+nHbaaQDs3LmT0tJSdF3fL3yFw2G6d+9OVlZWm5C4Zs0aZs6cSe/evencuXObfVwuF6Zp0rdvX2e/1l++FyxYwJIlS/jVr36Fqqo0NjbS1NSE1+tl1apVLFq0iAsuuICcnBzC4TB+vx+fz8fu3bupqKhAVVWn6mQHe9M0SUtLIycnx3mcdevWMXPmTM4++2yGDx9+wEqV/ZxsHW3XXiAQ4Nlnn6V3795MmjQJTdOwLIs33ngDt9vN+PHjee+998jOzuacc85pc74dqa2t5amnniIlJYWbb775oI+9c+dOtm3b5rxfiqIQiUTo0qULKSkprF+/3vk82M8xLi6OMWPGtLk9EonwySefoCgKU6ZMaROWqqurmT59OiNGjGDkyJH7vUaNjY1s3br1gJXl9lRVZcCAAc7Fjtavu12FzsvL45133mHgwIH8+Mc/3u89PliAMwyDl156idraWm677TbcbvcBt922bRs1NTXouo5hGKiqyrBhw5g1axYbN27koosuIisry3mtDMNwXkNN05zzff/998nLy+Oqq64iIyMDRVEIh8M89dRTxMfH85Of/MT5XNivgf08Fi9ezNy5c/npT39KVlYWNTU1bNu2rU0Ftv3z7devH/Hx8W1u27NnD6+//jpjxoxh/PjxADQ0NPDyyy8zYMAAfvSjHznb2o+9a9cuSkpKnJ8j+7FSUlJITk6mqKgI2FfhV1UVXdcZNGgQbrfbOU5tbS3//Oc/GTt2LBMmTGhzXmVlZSxZsoTCwkLOPvtsevfu/b24OCGEEEII8V0VU0Og7S+OBQUFPPjgg9x9990EAgEWLlzIpEmTUFWVsrIy3nrrLZYtWwbAyy+/TEJCAqFQiGHDhjFu3DjC4TCWZbF+/Xp2797N2LFjcbvdfPDBB3z00UfEx8e3Gdbq8XgIBoNceeWVnHPOOUQiEVRVJRAI8Prrr1NRUeGcl32eqqqyd+9eKisrufPOO0lPT8eyLHRdZ+XKlRQVFbF582a2bt3K66+/TqdOnSgqKmLlypX4/X6am5sJBoM8+eSTuFwuampqmDp1Kueccw4ffPABs2bNolOnTrhcLgKBAJFIBK/XS3l5ORdeeCFnn302W7ZsYeTIkdTU1LB06VLGjBnjnF979hfy5uZmDMPA5/MdtCJth7L8/Hzmz5+Py+Vytq+treWTTz6hd+/eTJkyhfXr17N582bOOeecNsdcv3495eXlbS44NDc3s2PHDgoLC5k9ezbx8fFtzteyLAYMGEBGRgZr167l5ZdfJi0tzQljNTU1nH766QwfPpznnnsOn8/nVP2CwSApKSkMHz4cj8fTptK8cOFCiouL6d+/P7169XJeky+++IKZM2fi9/sZNWrUfp/F0tJSnn76aUKhEIFA4IBDZ1VVJRKJEB8fz9NPP01cXBy1tbU8++yzBAIBDMMAohdNysvLKSsrY+fOnaxevdq5kGIYBpFIhEsvvZRBgwYxf/58Fi5ciKZpGIbhhOi8vDxCoRAPPPAAPp/PeW00TSMuLo5rr72WuLg43n//fVatWoXL5cKyLJKSkrj11luZM2cOe/bsoaCgAE3TOPXUU1m2bBkNDQ243W5uvvlmBgwY4AT+xYsXU1tbS0pKivOalpSUsHz5ckaPHo2u620+YxAN6oFAgNraWr766is+//xzLrjgAjZt2sQTTzyBqqq43W7n56z1z9Xvfvc7+vfvz6ZNm5g7dy5+v5+dO3fy1VdfUVhYSF5eHm63mx07drBmzRpWr17Ntm3bMAzDuRCjaRqLFy9mxowZdO3a1Tm30tJSBgwYwOjRo3nxxRfJyMjA5XI5n2tFUXj44Ydxu92YpommaaxatYqlS5ficrkYPnw4hYWFFBUVkZ+fz/bt2zEMg27dutHU1HTI4d1CCCGEEOLgYioA2xRFcb6UappGYmIilZWVvPvuu3z00UfU1dXRqVMnunXrRiAQYOfOnWzfvp2kpCTGjRvH3XffTUNDA4ZhsGPHDu644w50Xeess87i7rvvBtpWqQoKCpg1a5YT3uzHnjdvHtXV1WRlZbUJanYl0jRNxowZ41QObevWreOLL74gPj6ehIQE5s2bR2JiIueeey5erxe328327dvZvn07ffv2JSMjg1AoxHHHHQfAuHHj6N69O5s3b2blypUcf/zx9O/fn6KiIrKyshgwYADLly/nmWee4fHHH8fn8+Hz+Zwg0pr9HKuqqnj77bfZsmUL4XCYlJQURo8ezVlnneUEpNYBxv77woUL8fl8TJkyhfz8fLp3705hYSGhUIjs7GwqKys57rjjWLZsGQsXLiQrK4vk5GTS09P5+OOPWblyJW63G8Mw0DQNl8vlvPZvvvkmpmm2qcBZlsUvf/lLMjIy0HUdj8fD6NGj6dOnD1VVVXzwwQe4XC7cbje6rjNixAiGDh1KU1MTc+bMafM8wuGwE2IuvfRSHn30UT766CNuuOEG5zX58ssv6d27N6effrpz4cR+/+3PH0SrksOGDTtgdc8Op/b7az9+fn4+mqaRkZFBJBKhsrKSrKwsfD4fzc3NAOzatQufz0dGRkabY9oh8/jjjychIYFIJIJlWZxwwgmoqkpzc3Ob8JuXl0dDQwNXXnml83omJCRw7bXXMnPmTKqrq3n99dcpKytj3LhxqKrK0qVLycvL48QTT2T58uWUlZU51dfS0lJ27NhBTU0Nffv2pbi4mEgkQt++fcnPzycSiZCRkcGOHTsIh8NA9MJJ9+7daW5u5q677iIcDuPz+Zg9ezaffPIJF110Effddx+apvHRRx+xfv16br/9dpKTk7Esi3A47Iy0aGxsZPfu3fh8PlwuF+PHj8cwDFasWEF9fT29e/fmxBNPxDAMSktLCQaD+713brebrl274vF4ME2TxsZGNE1D0zQ8Hg/Z2dkkJCSgKAqFhYU0NjY6wd+uHC9cuJDk5GQGDBjAfffdx65du/D7/XTr1g23282QIUO48sorO/w5EkIIIYQQRyYmAzBEg5vX60VRFAzDwDRN1q5dS9++ffF6vSxevJiBAwdy7rnn8sILL9CpUydOOukkAAYOHIhhGOi63mb/AQMGOMe2A4tdfWs9t2/9+vXk5+ezbds2cnNzAaivr3eqf5qmUVVVRW1tLQAfffQRzc3NHHfccRx33HGce+65nHbaacyePZsVK1Zw880306NHD7Zs2cLy5cvJzs6mvr4eTdOorKykvLycYDDIpEmTABg8eDCDBw9m4cKF+P1+brjhBtatW8fKlSu57bbb6N27N5s2bXKqnPbQ6ANVnwzD4IUXXmD16tXOMOvi4mLy8/OpqanhqquuarO9Xf3dvXs3ixcv5rzzzqOpqYn77ruPqVOnOmF28eLFfP755/h8PuLi4nj++eeprq7myiuv5OKLL0bXdeLj47nqqqvIyspi8+bNzJgxg0GDBnH66afz0ksvER8fz9SpU3G73Xz55ZcsW7bMCfL2eWzevJm8vDxM0yQSiTjPSdd1tm3bxq5du7Asi7q6OhITE53X4YUXXmDVqlVOldjn87Fp0yZ+/etfOxXVQCCAZVn86U9/cm6744476N27N4BTWe7ZsydTpkw5os+wPay5f//+3HHHHSxfvpynn36aH//4x6xevZpFixYxefJk3nvvPbp37865554LQJcuXQBITk4mNzeX888/nw8//JBQKITH46G6utoZEaBpGg0NDaSnp3P88cezbt06J4AbhoHH46Fv375OsCsvL6dHjx6UlZU5gb2wsNAJkjk5Oc7jv/POOyxZssSZCrBhwwYSExN58MEHWbt2LW63m48//piPP/4Y0zTxeDzous6vf/1rcnNznakHmqahKArNzc0MGjSIhoYGioqKqKmpcc6poaGBYDBI//79SUhIwDRNRo8eTXV1NcuXL8ftdhMOh1FVFb/fj2VZzm0AXq8Xj8fD6aefvt/IBntos30xxP582J8vj8fj/Fy3bwa2Zs0atmzZwpAhQ5g0aRJxcXGoqkq3bt344osvmDNnjnP+Lpdrv6HbQgghhBDiyMRkADZN0wlEkUgEl8tFcnIyJ598MgUFBQQCAaZOncrSpUv5+9//zo4dO7j22mvp1q0bAGeccQYLFixo88V7zJgx1NbW8sc//hGv1+sERrvC6PV6nWGqhYWFzJs3j7S0NOe21kNfI5EISUlJpKSkUFVVxfz582loaEDTNKca+vbbbztV2WeeeYb+/fszePBg6uvrOe200ygrK2PZsmUMGzaMvXv3snLlSufLPMBrr73mzLu05yOGQiH++c9/8sgjjzjP4VCvo6qqFBQUsGXLFhISErj00ksZPXo07777LnPnzmXJkiWceeaZZGZmtqlwNzY28uabb+JyuUhMTOStt94iISGBHj168Pbbb6MoCgMGDKB///6sXr2aoqIizjjjDHw+n3OhAaLh56STTqKmpobXXnsNRVG47LLL6NKlC5ZlkZiY6FTQd+7cyfLly5197YsXgwcPpk+fPpSXl/P+++87FU/DMOjZsydDhgyhubmZzz//3Hm/ADIyMujdu7dT/auqqmLPnj2kpaWRlJREYWEhmqbRq1cvVFVF0zTC4XCbKqI9LNeev22HsPZVPrsSawck+347hEYiEWbOnElSUhKWZbF69Wo0TeOTTz7Bsiy2bt3K3//+d9xuN/feey9utxtFUcjJyWHevHl89dVX5Obm0rt3bzZv3kx+fj5jxowhJSWFVatWsXfvXgYPHkxWVha1tbX4fD4nJC5btoza2lomTZrEokWLSElJwev1MnfuXC699FL27t3LM888Q2JiIjfeeGOboeMul4vJkyfj8XhYsGABhmGwcuVK1q9fT+/evRk4cKDzM7plyxYKCgowDAOXy8WQIUNYuXIlPp+PUChEeno6PXr04NFHH2XJkiV06tQJRVGckQB1dXWcf/755ObmtplP7PV68fl8zgUKu0Lrdrvxer0ddgtv/f7t2LEDl8uFruvU1NTQtWtXp5peXl5OZWUlmqZRW1uLqqrOZ6impoa33noLRVEYO3YsiqIwYcIECgoKeOWVV9i+fTvnnXce5557LrNmzeK9995zpidIJVgIIYQQ4ujEZAAGiIuLY926dZim6QwXXbNmDfX19aSlpVFbW0t9fT3hcJhp06Zx8sknO5XJ3bt3M3fuXDweD6qqUldXR1xcHKeffjq/+93vnKGK9pfUPXv2sGTJEueLddeuXUlPT8flcrVZ3qR9dcgOGHZ1sWvXrkB0nqsd7LZs2ULv3r0pKChA13VcLhebNm2iqakJXdfZuHEjzc3NznEAXn/9dT777DMSExNZvnw5n332GU1NTbhcLqqqqpg+fTppaWkHXcoF9s0F3rt3L5FIhOzsbCZMmICmaUyYMIFFixYRiUQoLS11ArA9n7a2tpYVK1bg8/mYPn069fX1/PSnP6Wuro7S0lIsy2LQoEGceeaZVFVVkZ+fz2mnnUZWVpbz+BdffDHFxcW89957fPrpp9TW1nLzzTfTpUsXmpqanGZlixYtckL+BRdc4FTdIRqgly1bxuLFi4FoKAkEAoRCIZqbm1m7di0bN24EomGzdUO0Cy+8kEAgQHNzMykpKXz00Ue89NJLnH/++QwfPpw//OEPlJaW8otf/IJwOExtbS3p6elthsfbn7/ly5ezevVq3G43oVDIqUTb3G43brebu+++u81QZkVRCIVC/Oc//yEvL4+zzz6bFStWUF5ezuDBg+nbty+LFi1CVVVGjBhBcnIyfr8fgO3bt7N582ZcLhc+nw+/3095eTk1NTUkJCRgWRZVVVWEw2EikQhr1651GntlZWU5F38WL15M165dycnJITMzk/r6ejZt2sSQIUO46KKLqKuro6CgANM0ycnJaROAdV3nwgsvdIYIb9y4kdmzZ6OqKtdff32bxnDvvvsumzdvdvbfsmULn376KcnJyQQCAbKysjjttNP49a9/zcaNG3nooYc4++yzmTp1KiUlJdx3330kJyc7IfTJJ590hkDbFWxd12lqaqK+vp76+npnfrU9j//vf/87l112GaNGjXIucv34xz+mrq6ON954g1NOOYXjjz+eLl26sG7dOjZt2sSUKVNISUlhyZIlFBUVOe//66+/zt69e/F4PHg8HgAeeeQRFi9ejMvlIjc3l+rqav70pz+xbds2TjnlFEaNGiXhVwghhBDia4ipAGwH0FGjRtG7d2+8Xi9z5szhtddew+v10qdPH6fhUl1dHePGjSM7O5u8vDx69erlfBnv1q0bF110kVMBtoewJiYmEg6HaWpqcpoWderUiYyMDKcDLkB1dTXr1693mikFg0GnmmpXHu1qlMfjobm5mfXr1zvdaTVNIxQKOUObS0tLneDU0NBA7969qaiooLS0lP79+1NWVkZ5eblT0bUbR2VnZ+P1esnIyCArK4ucnBzee+89ysvL8fv9h1xWyX49R4wYwQMPPOBUywAKCgoIh8POMGWb/cU9PT2d6667jqqqKj766CM6d+5MWlqaU2VNSEhg5syZfPDBB848zz/84Q+43W7uueceMjMz2bx5M9OnT6e6uppu3bpx4403Mnz4cGd4e+fOnVm/fj3PPPOMM6962LBhzlBgew7mqFGjyM7OdirCPXv2JCsri+uuuw7Y18X3888/368q/sQTT1BVVcVDDz203/JL9kUQTdNYvnw5Tz75JLfccosz11TXdSKRCKFQiM6dO+NyucjPz6dXr15kZmY6nwGATZs2tZk/CtFA7vV62bhxI4FAgKSkJLZv386ePXuIi4ujoqICwzAIh8MoisKmTZvo27evU4G+7rrruO6663j33XeZNWuW04jMfgx7iH9TUxMnnngiP/nJT4hEIs4QaDtIBoNBAoEAvXv3pqGhgZkzZzrN0J599lmnYrt7927+8Ic/cMUVVzB+/Hjn9amrqyM+Pp5wOIzH42Hw4MEMGzbM+ezb87pDoVCbz93QoUNJSEjA7XYTiURITU1lx44d5OXlsXfvXqep2fz586mrq0PTNDZu3EifPn0YOHCgc0HJ5XIRCoVobGxk7969dO7cmbFjx7Jx40an8deWLVuc/28kJyc776/H4yEzM5MvvviCHj16kJyczAcffMDIkSPJz89n5MiR7Nmzh+bmZrp160ZeXh4+n4+tW7eyZMkSvF4voVDICdODBw8mMzMTr9fLkiVLmD17Nunp6Zx++un86Ec/atNFXgghhBBCHLmYCsC2jRs3Ultbi9vtprS0FEVRcLvdlJWVUVJSwrhx4xgzZgz9+vXjgw8+4L333mPMmDFkZ2ejqipFRUW88sorTgW4traWc889l65du/LPf/6TUCiEy+WiqamJ/v37M2XKlDbrh8bHxzsBvKCggOTkZOLj46mrq6O6upqkpCSSkpJoaGiguLiY3r1706tXL3w+HxANwPX19ezatYtQKMSOHTvIzs6ma9eujB8/nvLycvbu3YuqqmzdutVZqsbe//rrr3ca+JSUlPDwww8zaNAgxo0bR69evUhNTXWC6MEqTa2fT+uQu3r1at577z2CwSB9+/alW7dubdZVtYe+Tpw4kccff5yEhATGjx/PCy+8QL9+/TjhhBP46quvSE9PJysri+LiYifkJiQkOAEuJyeH7Oxspk6dyrhx44iLi2sztPXmm28mPz/feVzDMJwO3Xa4j0QijBs3jgEDBvDvf/+bpqYm8vLyCIfDJCYmYhgGZ555Jn379mXlypVUVVW1eU0yMzNZvXo1NTU1TuW/I4WFhZimSXp6epvbg8EgDQ0NnHDCCZx00knceuutZGVlcdNNNznb7Nmzh1WrVjFo0CA6derUpnocCoXIzc0lISGBNWvWkJmZSXp6OmvXriUuLo6cnBwqKyud4c6dOnVyjmtXHTMzMznhhBOIRCI0NjbSo0cP58KOoiiMGDGCrKwsZ16wzTRN4uLiuOCCC3j66ad5+eWXKSgooF+/fmRmZrJu3TpnyHJSUhI33XQT06dPZ/v27YwfP95Z7uixxx5DVVVnaa5LL72UpUuX8vOf/5wLL7yQ8847r8PXdM2aNbz55pskJyfT2NjIgAEDGDp0KC+88AIJCQnOXP4vv/wSRVFISEhgw4YNpKWlMXjwYM477zwee+wx8vPznW7X9vt+0UUXsXz5cnr27Enfvn3ZunUrpaWlnHLKKW3mb7tcLrZu3Up1dTWGYTBz5kwmTZpEdXU1lmWxYcMGGhsbuf3229m0aZMznDopKYkePXrQuXNn5s+f7/z/4ayzzmLHjh3Mnj2bcDjM5MmTOffcc3njjTd46KGH+NOf/kRKSopUgYUQQgghjlJMBuDp06ezZcsWpzlNSkoKK1euJC8vD6/XS1FREdu2bSMUCtHU1ESXLl14+eWXSU1N5Z577qFPnz5MmzbNqYQFg0E6d+7sNP0ZPXo05557Ls8995yzFAvsq1wNGzaM4cOHM2/ePFavXk12djZJSUk0NzcTCARIT08nOTkZwzDYuXMnAwcO5NZbb3Wqj4Zh0KVLF44//njWrFnDyJEjWbRoEXV1daSmpuL1eqmtraW2tpakpCQURaG4uJhVq1Y5jbA2bNiAZVns2rWLiooKp4GVoiikpqYecv5va61D33vvvcfs2bNpamqiW7duXH311W2WKbL/W19fz/PPP8+KFSvo0qWLs6TUhAkTGDhwIPPmzWPq1KmceeaZ/Oc//2HOnDlcd911zhBoezmj8847j48++oiVK1cSCoWcKrodDuxh5uFwmMzMTH7yk5/s99zsauXChQsxTZPBgwfjdrspLy9n7dq1zgUIe1hy6+AxaNAgZs2aRX5+focB2K7WFxQUOJ3FWx+jtrbWaZaWmJjImDFj+PLLL5kwYQLHHXcclmUxY8YM6uvrmTBhglPJtqvHgUCAbt26OY2vOnXqxOTJk9m0aROmaRIIBDBNE13XnaHd7d+3/Px8NmzYQO/evZ3GXfY52k2k7Pv79+/fZl3hYDDIsGHDyMnJIRAIcNFFF5GRkUFSUhIjR45sc+EnLi7OWYKp9WtgN9uyhwZHIhH69OlDeno67777Ln379mXAgAHO/Gi7idmYMWPo0qWLUwGOi4sjMzOTPn36OOsMt58vbZqmU8EtKSlxhnKXlJRQU1PDqaeeSm5uLnl5eRiGQV5eHuPHj2fy5Mm88847zJ07lx49ejgXAgKBAEOHDiUYDDJ79myysrJYt24d11xzDbt27SIvL4+EhASWLVvmrH8cDofJyMjg9ttvZ+PGjXz22We43W5qamr4xz/+QV5envP/FL/fz6xZs9ixYwd79+7lv//9LzfeeOMhR2cIIYQQQoiOxWQAvuiii3j88cfp06cPaWlpLFy4EIDU1FQikQiRSMRpOGQPadY0DZ/Ph6qqrFu3jg8//NBpfmSaJsOHD+ecc84hHA6TnJxM165dnfV427O/xNvDOsPhsDPv0w4BwWDQGVqqqioul6tNh+ItW7Y46/e+//77pKSksHv3br766iuSkpKIi4tjypQpbN26lfLycgYOHMjWrVuZNGkSpaWlPProo07wSkpKYv369SxfvpxwOMyTTz7pdIA+VJXJDlHBYJCXX36ZBQsWoKoqxx9/PJdffnmbiqXNrl5u376d1NRU4uLi6NKlC6FQiJqaGpqamvD7/SxYsICtW7eyc+dOPB4PL730EnFxcVxyySVOEA4Gg5SUlDjVX3t+cSAQIDU11QkK4XAYTdOc17j9+6FpGl6vl/T0dM477zx0XXe6Q3s8njahurVu3brh9XrZuXMnqampbV4Tu9K9a9cuCgsLGT58uNM8ylZSUoKmac46z+eccw7r1q3jn//8J3fddRdfffUVX3zxBaNHj2bw4MFtKukNDQ2EQiHi4uKc523PV21oaCAxMdG5iAOQm5tLQUEBO3fubFOVt7exP9/tz7+qqopQKNTh87eH7nbq1ImdO3eyY8cOXnjhBdxutzO3OBAIOPOIU1NT+dvf/ubs63K5uP3224mPj+dvf/ubs4xWeno611xzDQ8//DD/+te/+OMf/+i8l/bzX7JkCcuWLXPeG5/Px5133snmzZtZs2aN04Hd/sxZlkXXrl2dJlIvvPACu3btIiEhgUAggMvlYuXKlaxdu5aGhgbC4TDhcJi//e1veL1ekpOT2bBhA4WFhRx33HHO+ZeUlLBo0SLS09NJTU2lrKyM1157jZKSEnJyckhKSqKgoMBZesseFp+amuq8rnY1ubS0lNzcXHRdp66ujg8++IBu3boxZMgQunXrxuLFizn55JMZPHiwE/CFEEIIIcThi6kAbAekrl27EgqF6NmzJ9nZ2cyaNYsxY8bQo0cP/va3v9GzZ0+uvvpqAN5//33++9//cscddzBw4EAA6urq2LlzJyNHjnQaGNmVPTs4vfPOO+zZs4fU1NT9qoKWZTkNlYYNG9ZmHVt7iKQ9THL48OGkpKS06T5sB6l169aRn5/PGWecQffu3Z2mRHZXYJ/PR2JiIhUVFcTHx9OjRw8nrNxwww1AtIHVJ598wqBBg5xuyRkZGc5aqO2bMXVEURTeeOMNvvzyS9LT07ngggs45ZRT2tzf/u9JSUlcddVVpKSk4HK58Hg8TJ8+neHDhzsNu6qrq6mpqcEwDFRVpbi4GE3TCAaDQDRAjRw5khEjRrR5f1988UWWLVvG7bffTufOnds037Ln/XZE0zR27NjBH//4RyAatFoHwvYsy3KGr2/bto3Bgwc776H9R9d11q1bR1VVFUOGDHHeXzvMFRUVkZCQ4MxH7d69O9OmTeMf//gHjz76KI2NjfTp04drr722TfdogKqqKiKRCMnJyXg8Hs466ywyMzMpKSnhlFNOYfPmzei6zqmnnophGKxfv57OnTsTFxe33/unqqozd711ANZ13Xn9O3q9AoEA999/Pzt27KBXr16MGjWKuLg4JxAvWrSI4cOH069fPyoqKsjJydmvetl6aL/9X3s+7KmnnsquXbsIh8POkHx7u+rqaoqLixk3bhw7duygvLwcwzDYsGED8+bNo3v37m3Oe/fu3fTp08eZknDJJZdQV1eHZVl89tlnFBYWMmLECHbs2MGIESMwDINPP/2UKVOmsG3bNjZt2sQFF1xATk6Oc57hcJjc3FwGDBhAnz59iIuL4/XXX2fQoEFUVVVx6623OlXsuro6tmzZ0mauuP33UCiE3+/n/vvvZ9WqVc40gGeeeYYrrrgCn89HUVERp512Gr169XI+n0IIIYQQ4sjEZAAuLi6mqamJlJQUJwzZw5d1Xef9998nPj6e888/39m39ZdNVVVxu93ceOONpKSkMG3atDbzYSsqKpg9ezaKorTpYms/1urVq/n3v//tDP30eDy4XC6am5tRVZVAIOB0oA6FQrz22mu89NJL3HjjjQwZMoTCwkIaGxvbrDVbXl7Ojh07WLhwIcnJybjdbqdpkt38JxKJcM4555CQkMCpp54KRCuQ77//Pn369HGCUnNzMz169OC8884jNTWV8vLyAy4BY3fvXbp0KUlJSSQkJFBRUcGrr74KRKvVEyZMcJaeaX2cpUuX4na7qaysJDk5mZKSElatWsXYsWNpbGzksssu48wzz+SVV17hs88+45FHHmnTBfpAAcAOufb72d6BqtqRSISuXbty6aWXous6W7Zs4bXXXnOea0fHcblc/PSnPyUlJYX8/HynamqHykAgwIQJE8jOzmbw4MFtAlxpaSl5eXl06dKF5ORk57w6d+5MTk4ORUVFWJZF//79SUtLcx7XDqS7d+9G0zSys7N57733UFWVyspKZsyYwXnnneesZX355ZdTUFDAwoULGTt2LGlpaW3WqrUvriQkJOx3gcDtdjvDtO0/rWmaRkpKCllZWZx11lnk5uby/vvv061bN0455RQ+/fRTxowZg8vlYv78+Vx44YXOe2I30bKbQVVVVTmvjV2xvfzyy9E0DZfLRTAYRNO0Nvv7fD5+9rOf8e677zJz5kxnbntqaip/+MMfnLnplmXx29/+tk039JKSEvLy8mhubnbmSS9fvpzq6mrOOOMMhg0bxvz581m3bh0VFRVMmDCB8847r8NlrEpKSti1axfZ2dkATgOv+fPnM2fOHK699lpnnnFHn0P7/Vi8eDHPP/+8s5SU3WTsww8/ZMOGDTzwwAPO1A2ZAyyEEEIIceRiKgDbCgsLgejw1T179jhDcl0uF9OmTeOhhx5yqn/2HMKOqoZz584lJSWFcDiMZVn4/X5+97vfOeHHbv6zcuXKNuuI9ujRg8mTJxOJRKisrGT9+vWUlpYSHx+Py+WioaGB3bt3k5WVxeDBg0lNTUXXdafKXFBQwMqVK9F1HV3XWb58OX6/n4svvpjNmzcTHx/P1VdfzYABA3j//fd5++23uf/++51hr/bc0ObmZrZu3UpcXBxr1qxhx44drF27ltGjR3PzzTczZMgQgIMOf9U0jTVr1rBnzx6SkpKoqalhw4YNbQJgjx49OgzA27dvZ9iwYWRmZlJRUcGwYcP47LPP6N69O36/n4KCAhYtWsSePXvQdZ2lS5eSnJxMdnY2/fr1o7a2ts252WHEDkqlpaW4XK42zbwURSE+Pt5pANWaYRhUV1ezYsUKZ+6rPRy+o+dfVlaGZVn07NkTl8vFqlWrnCHDlZWVTufvUCjE4MGDaW5upr6+Hr/fT0JCAkuWLKG6utoJhZWVlSxZsoSPP/6Yqqoq+vbtS3NzMx999BG7du1i8uTJDBkyxBlGW1RURHJyMgkJCSxYsICuXbs6zdT69evH6NGj2bFjB3PmzHEaQb3//vv07t2bIUOGtKnGq6rKjh07nNfK/szb83zdbjfx8fFtArK9nvYdd9zhhMLnn3+e1atXc/rppzvzjQOBAMnJyeTl5fHMM8/w85//vE11/bnnnmszD7r1z5o919Y0TcrKynC5XM5j2ecyZ84cCgoKnKWu7M94Y2OjMxfYDvr2kG1FUcjLy2PVqlX07dvX+eycfvrpDB06lLi4OD799FNUVWXnzp2MGzeO008/nd///vdMnjyZk046qc1FkaFDhzJv3jy2bdvGyJEj8fv9GIbB6tWrGThwIN26dWPr1q37fYZsHo+HwsJC3n77bYYNG8aoUaNYvny502n6uuuu49577+Xxxx/n3nvvdS5iSAgWQgghhDgyMRWA7VC6ePFiEhIS6NatGzt27ADaDs295557+OSTT3jjjTfYvHlzm6VhYN8Q5g8++ADTNIlEIk5waL1O7Pbt23nvvffYtWsXgPPFfeXKlZSXl1NcXExlZSWqqnLhhRfi8/n473//y5VXXolhGHz++eds2LCBlJQUcnJyWLJkCZMmTeK6667jpz/9Kf/973+ZM2cOjz32GJ06dcIwDK6++mpnLu6ePXvYvHkzqqri8XjQdR3TNHnppZdYuXKlU+3VdZ2dO3eye/duMjIy6NevH42NjTz//PN4PB52797tBNr2rydA//79ufrqq53KVPulevr06eO8xvaX9r1797J37166du1KbW0tixYtYtKkSeTk5DhDb5ctW8aCBQucoP/2229TX1/P6aefTr9+/fjXv/7lNBdqPdfTDjp//etfOxzC/Otf/5oBAwY4YcjWtWtXGhoaWLt2rXMO/fr1Y+3atRQVFTkXKeyQfd9997VZmsie2/nyyy87y2AB3H333U7Aq66u5uqrr2bixIm8//775OTkkJub67wnZWVlpKenc/HFF3PWWWdRX1/P9OnTWbRoERs2bKBHjx5MnTqV3r17s2bNGkaMGMHWrVvZvn07l112GXV1dTQ2NvLOO+84F2U++eQTKioquOyyy3jllVdYs2YNQ4YMoaSkhG3bttHQ0ICiKE6jrp/+9Kekpqby6aef8sUXXzjz4T/77DNGjRrF4MGD2/wc2K/jrFmz+PDDD5kwYQInnngiq1atctYpHjhwIJMnT+b9999n7NixjBs3joaGBgKBADfddBM+n4/Zs2dTUVHR5mLFggULnHWMN27cSFZWlrOOMUSr9q+++iqGYTih035/7r333v0+F/3793fO/ZprrmHEiBEUFhY6a09PnDiRmTNn8sUXX1BXV0evXr2c1+aJJ56gpKTEeV9bz3+3/22H6NraWoLBILfeeiulpaUUFBSwdu3aNmt/tz5GKBRi+vTpQLRHwaxZs1i/fr1zESk9PZ0rrriCxx9/nGXLljFlyhQJwEIIIYQQRyGmArBdHcrOzqZTp0643W5M03QaPkG00pSYmMiWLVvYvHkzfr+fAQMGONVTe8kkn8/HtddeS3Z2Nv/+97/bNEBqPed04cKFKIrCwIEDnYqqHbIGDhzI+PHjGTp0KKmpqSxfvhzTNElNTWXMmDGccMIJbN68mU2bNvHVV185a9XCvmHYLpfLWa9V13XGjBlD7969qa6u5qGHHiIcDjNw4ECnYqSqKgkJCaSmptKjRw9SUlJIS0ujc+fOZGVlOQEvHA5TXl7Onj178Hq9DBs2zDl/O/DZ5zJgwAAGDBhwyNffDsCAMwe7S5cu9OzZk9TUVGcO7erVqwmHw5xyyikMGTLEWcfWbmJlLyU0cOBAfD6f04ys9eMcqGoPkJiYCOAMrbXP6de//rVTmQScixrLli3jmWeewev1MnbsWGet5vHjxzudp9uHkdb/br00U1NTE7m5uXi9XoYMGUKXLl3o3r07L774Im63m8svv5yxY8c6Q709Hg833XQTEyZMYO7cuaxYscJZzmnixIl06dKFIUOGcO655zJo0CCampoYMWIEeXl5beY9n3baaUycOJH09HTngkRlZSUvvvgiPp+Pvn370r9/f4YNG+aMNLjmmms4+eSTycvLIz8/n88++wzA+RzYTa7sxxkwYABnnHEGF154ofO87eHKlmUxadIkZ84s4CyvNGHCBAB69epFc3Ozs560oigkJiayc+dOFEUhNzeX8847z6kK2xd27rjjDtauXcvWrVudKrDL5eKkk05q8/4uXry4zRJSHo+H2tpaZsyYQVJSEqNGjXJu6969O2eeeSbDhw9n06ZNvPLKKwSDQa6//npn+kDr5lv19fV07tyZm266iUGDBvHll1+SlpZGUlISq1at4r///S/JycmceOKJTlC397eH0l955ZWUlZUxaNAg/vWvf1FZWUn//v3p1asXlmUxbtw44uPjnV4EMgdYCCGEEOLIKdaBOvx8h9kh066ydTTP81Dq6+tJSEigsbGR+vp6kpOT23zxbmhocDo4p6SktHmMcDhMIBAgISEBwJlD2dHSJHYTp6SkpDbH6CgwNTQ0UFlZSXp6utORt6PtW59jY2MjaWlpzmO37gxrV7XS0tL2e2w48FxY+/h2517Lspyg05H2ldT2Wi9F09F+rV83e23b6upq5yLF/0pjYyNVVVWkpaU5jZgOpKqqCsC50PFNCYVCuN1uZ/5rUlISsO99bP9elZaWkpmZ6ewfDof3a45lD7tu/Zof6HXcuXMnKSkpzmfZ3r/1Y9oqKytxu93Otg0NDc4Fo440NTWxd+9e0tLSDriN/XjtRw60Zo+wcLlcbS421NbW0tDQ4Myzt1+LsrIympub6d69e5vjFBcXo6qq08TK3qe2thZFUZw1kjv6f4rdEbp1t/Hq6mpqa2vp2rVrm8+wPQTbMAxniaa6uro2I0TsY9TV1VFeXt6msm1ZlrMkWmJi4lH9/00IIYQQQnTsexmAbVu2bGHRokX85Cc/OSbrYh7qi3tH27cOFa2HZx6oyVTr6uGRnNfhDI1sffyDnceRHvdIHex17KiKa5/n0X50v6nncDSP33p0QEfsebft7+/odvtYrQProd6jAx3/QPfZr//hfP4OdWGl/Tbt3/fD3b/9/Qd6zu0/30daMbUvQrS+qHQ4r+/RVmYP9HPQ+jFl6SMhhBBCiK/ne1VasL8IlpWVsXPnTpYuXXrI6uOhjtX+763vtx2sA/KhwlTrL/Xtt+3oi27rxzucQNrR+bUfenugYxzu8Q9n26+jo2Pbr+/Bvux/E+dzJBcL2j/m0Tz+warucPDO1vZ2rT8fBzqn9j8TrYfOd/S4B3qt249C6OgxOjqPA+3T/lwP5/U80M/QgT7fX2f71uzn3lEl/kD7HWzUxoEe2w69rc/3QM9Bwq8QQgghxNfzvQrAtrVr17Jx40ZM09xvTdPDdagv3ocKN4cbfo4kJB1poPqmzvF/tf/34bH/F+/jd+E8vo3P5+Hs+028bge7gPO/vP1Q2xzJz9+RXoQ6lj97QgghhBA/ZN/LIdCRSARVVVm0aBErVqzgjjvukMqIEEIIIYQQQoiD+l5WgO3uqYcTeu1mNPacw/YNg4QQQgghhBBCxIbvZQBu3/znYNuUlJRQVFTkdGNNSkpiwIABUjEWQgghhBBCiBjzvQzAh8OeQ2evb6soCpFIhFWrVkknVSGEEEIIIYSIQd/rAHw4w6BVVXW2URRF1tQUQgghhBBCiBj1vS6DhkIhGhsbD3v79uuCCiGEEEIIIYSIHd/Lcqg9vLlXr154vV5ZMkQIIYQQQgghxCF9rwNwt27d6Nat2zE+GyGEEEIIIYQQ3wff6yHQlmVhmuaxPg0hhBBCCCGEEN8D38sKsE1RFBn+LIQQQgghhBDisHyvK8BCCCGEEEIIIcThkgAshBBCCCGEECImSAAWQgghhBBCCBETJAALIYQQQgghhIgJEoCFEEIIIYQQQsQECcBCCCGEEEIIIWJCTAVgWTJJCCGEEEIIIWJXTAVgwzCwLOtYn4YQQgghhBBCiGMgJgKwHXpLS0sJBoOoakw8bSGEEEIIIYQQrcREErSHPmdmZuLxeDBN8xifkRBCCCGEEEKIb1tMBGCbpmkyD1gIIYQQQgghYlRMBWCZ/yuEEEIIIYQQsSumArAQQgghhBBCiNglAVgIIYQQQgghREyQACyEEEIIIYQQIiZIABZCCCGEEEIIERMkAAshhBBCCCGEiAkSgIUQQgghhBBCxAQJwEIIIYQQQgghYoIEYCGEEEIIIYQQMUECsBBCCCGEEEKImCABWAghhBBCCCFETIipAKwoyrE+BSGEEEIIIYQQx0hMBWDDMLAs61ifhhBCCCGEEEKIYyAmArAdektLSwkGg6hqTDxtIYQQQgghhBCtxEQStIc+Z2Zm4vF4ME3zGJ+REEIIIYQQQohvW0wEYJumaTIPWAghhBBCCCFiVEwFYJn/K4QQQgghhBCxSz/WJyCEEEKIg7OAg41fMi0L04puo6ky0kkIIYQ4EAnAQgghYp55hCOEFBQUBQzzyEcWqaqyX5i12DdKSW03VccOv6ZloSj772vvY+feQ4VlIYQQIpZJABZCCBHz2ofOw/VNVVsV9jVsNC2rzfkogGUd+BwN02Lhtgq+2lVLVpKHi0d1lRAshBBCHIAEYCGEEDEtYloUlDdgmHYQjVZRaVXctW9TgLBhkp3kJTnOzcJtFZimddCw2b5GPLxrMil+N1bLAe19H/xoMwOykzh3WA6GabVUdBXqA2Euf2EZpw3I5NoTe+D3aM65WFb0/B+cvZnPNpXSKyOeCX3TSU/wYFjQPp8fbdAXQgghfigkAAshhIhJlhUNtlWNIS7852IaAhF0VYnOpVU63lZXFUrrg/zhxwO5/qReXPXScsJhA01V9gu6NrMliCooWFi8eeNYxvdOi1Z6UQiZJj/990reXV1CWoKbRJ/Oqf0yCEVM3LrCA7M2s2BbBZ9vKSXV7+bKE7rvO7gSrUL//PS+bNpTR01TiA/W7ean43vuF36FEEIIIQFYCCGEIGJYhA0T01TQVAWjZbl4CwvLigZfwwSs6LaGZaGp4HdpNFvREGpYForStspqWeDSFMKGhYVFKGLhUtsuwKCrCqO7pzJnUynhiMnNr65m+s3jGJSTyFsrd/HK0h34XBon9krj/OGdmbe1jDdX7CLR68ICNAUCYZM4t45lwb8WFbGttAHD2lddDhkmqX43d0/qj1tXZYi0EEKImCUBWAghRMzTVYVgxOSO0/pw3rDOVDeFue311eysaub20/pw/vDONAYj/Obd9eyuDWCaFm5d5Z1bxhE2TFQUEnw6wbBJMGKiKmBYFi5NZX1xLXfPWE9D0ODUvukM6ZKEZVn75g9b8LOJvYn3atz73gYqG4Pc++56bjq5J/e+uwFFAZ9L48/nDyLeo7N6RzXPfllAeryH2kAEq6U5VoJHR1UVNu6uY0VhVXTYtgUeXUVTVRJ9Oj+f2Be3rkqnLCGEEDFLArAQQoiYF+3CDIM6JzGocxKhiIlLUzFMi/5ZiQzunAQWxLk1TMtyhjsPyE50jvH55jKOy06gX7LPuc204N731tMYDJMe7+XPFwzG13IMO38qioJhWlxzYg8KK5p4+ottrN1Zww2vrEJRonOOH71oKEO7JmMBfo9Oit9NWoKHyUOy8ejR45lm9LzsjtAW4NJU8krr2bynjlS/Z7+h3UIIIUSskQAshBBCtIgY0Wjbenkj+++GZdF+EaKIYVHTHOLXb3/FjDUljO6eyls3jSXR50JTFX799lcsyKtAAe6Z3J/eGfEYptVh92jDtPjDuQNZUVTFV7tqiHNrNIUN7p50HJeN6UYwYuLRVSwLwhETXVX5+yXDSfK5Dvqc/v55PosLKklP8HzNV0cIIYT4/lMPvYkQQgjxw6coUFYfZE9tgO0VjYQME1VRKK8PsKc2QH5ZA3WBcNslihTwubWWcKqxrqSWX7y1Fiz422dbeXXpDizL4qJRXbnyhO7R7s7twq8diDVV4dWlO9hV3YTPrdEUMhjcOYlfnNG3ZRmk/c/5YMsX2xneOmB7LiGEECL2xFQFWJGxX0IIITpgWhY+l8ZfP93K43PyMC2LiGGR6NP5++f5/GPetujQZzPa1MoOnqZl4XfrvHj1aC55filLCiqYu6WMi55dzIaSOoIRk9MHZPLo1CFYLev7tv5NZBFtoFVc3cxjn27ljeU7UZRoZdnn1iisaGTznjqOy07cL+xaQGMo4lSF2/+Ki5gWuqoQipgy3VcIIYRoEVMB2DAMrINdLhdCCBGzLKLzbXVLxWypmlpEw6hlRSupWusOz0SrrBHTxOvSeOaKEZz/9GIKKxpZXliFZcHYXqk8dfkI4tw6hhUNotG1hluCsAXPzC/gmS8L2FMTwLQsuqb4mDI0h7dWFrOnprllbnEipmWfU7SKHAhHOPcfCw+4tq/d56oxZJAc53KGdwshhBCxLCYCsN0hs7S0lGAwiKrKyG8hhBD7qIpCU8jgrkn9mDqyK9WNIW54ZSWFFY38+sz+/N+orjQEw/zira8ormkGouHSo+/7fZKd5OM/146JrikcNAhGDO456zgyWube6sq+baNNtywsFL7YWk5eaQNJPhdje3Ti4QuH0C8rgZVFVeyuaWZZYSXT6I3eagy0QjR876xqbhXV96eg4NaUDuccCyGEELEoJgKwPfQ5MzOT4uJiTNOUECyEEKINBeiTGU+vdD+BZB+aGh3q3CvdT68MP6YJPreKaYJLV6luCrFoWyUeV3RZoYhpEe/RGdMjlQ/X7UFXFZ7+ooDmsImiRBtoGaZFqt/NmB6pmETn9T504WB2VDZy+QndueWUXqgtXaHH9kpjQX4FW/bW0xiI4PfqLeepYFoWHl3l4ctHkOhzdTi6ybAs3JrKe2tLeHXpTlLi3N/uCyqEEEJ8B8VEALZpmibzgIUQQhyQ2jJbVlcVZx1de4ixqkbDp2FZ+F0aa3ZWc+lzS0mKcznDk7Gi4djn0lCAL/PKmZ9X3rK/QlMwwkl905k57URURcECcjv5+fyXpxDn1gAIRUzcusqgnEQ8ukp1U5iiyiYGdd635JJlga6qTB6c7ex3IJv3Ruciy68/IYQQIsYCsMz/FUIIcSCaqrCuuJbUeA/1gTCBkIFbV1hfUktWkpfGYISqxhAuVcEE3JqKx6Xi1tR9AbgVE/C2VIcVRUFVFCIRc7/hyBb71hdWiA5XNi14b20JLk2lOWSwo7KxTQCGaMXapR061WqKcqAR0kIIIUTMiakALIQQQrRnN79yaQrPzS/gmfkF0UquphLv0XlpUSEvLNiOBbg1BV1TqA+EOb5XGu/fOh5diwZMBTCx+M2MDazaUc05Q3O4bWJvFEVhybYKHvlkKxHT4oSenYDoEGW7qZZdabY7Nz83fzuz1+0lNd5NRX2Q0rpAmzNWlOg5Pz2vgDi35jS8as20olXrJdsr8Xu0gy6ZJIQQQsQKCcBCCCFimq4qJHpd0bm9LRVV07IIRsyWKq6GW4tWZXVVoTkcXR/YpSqM69Vpv+Mlel0EIyZZSR5G56YC8OL8QhqDEbqmxnHVCd2BtoHVXvpI1xQ+21TKn2ZtwuNSCUdMTMuirD7obGsRDcvBiMm976131vt17m+pJNuFX59LdSrJQgghRKyTACyEECIm2XNiU/1uZt02nnDLMkGaqrCrqomrXlpGaV2Q3589gCtO6E5T2EBXonOAk30uIFrFVdi35JBpWdGhzAoEwyYAc7eU8f663aDAecM7k5XkxWxZE9hmh99l2yu57Y01NIdM+mfHg6VQ0RCkPhBuc+72+sEju6e0GVJtmBbulnWBnWWTLItQxMLvOfhcYSGEECIWSAAWQggR0yzLIjPR2+Y2O6CaFiTHuUhP8ESHFLdkTbvo6gxhpm1F17LAravUByI8MGszIcMgJzmO68b3aDMd1wIsMxp+52wu5dbXVlMTiNAp3s0/LhvBE5/ns6ywkmBk314KYJoWXpfGmzeMJdXvjg5vVqLLMpXWBXFpCn6P3up8otvb5yYNsYQQQsQqWQtICCFETFM7SIPxHj1a2bXAq2st2+27/1D50bSiSyJ9tGEPiwoqME342Y960S01DqtV9Vch2h36hQWF3PCfldQHI4DFY1OHMLRLMmHDQlMVAuFIh4/jdWm49WgzLo+uMmN1Caf99UveWrkLjx5t0OXWVbwujbdX7mJhfoXT3VoIIYSIRVIBFkIIEZPsiu6andV8mVeOz61jmtHhyzXNYUKGhc+tMmdLKbWBsLN9dA1ejcuO74bP1fGwYlVRqA9EmDIkh1tO6UVeaQPXjOsRrb4SXf4IC4IRk5+/uYZ3Vkc7PquKwkMXDuHsoTlYFm2WRuqIYVlY4Jz32yt3sXVvHa8v38VVY7vjc0WD/BvLd/Gz11eT5HPx4tWjmdAvHdO0UFUpBQshhIgtEoCFEELEJHuY89wtZfzq9TUkJ3iJmKYzvzbZ5ybOrfH+2t28tWIXdnQNmxYJXp0fD83B59Kc4cetKUo0nPrdGn+9eBh1gXB0bm7Lpi2zc9E1haaQQWMwQo90P49fPIzTBmQ63aCN9h2u2lHs41nRc572oz4sKqhg4+5aXl5UxC2n9ubJudt49JMteFwaoYhJICzNsIQQQsQuCcBCCCFiWnKci+6ZCXTyu4m0VFINExoCYUwT0uI9eOzw2tKtOS3eg8eu/h6giGqPrDYti0Svq8084eiSSdGu0g9fOITmsMG9U45jaJdkjJbwCxA2ohVezwEqzTZNVbAsi3G9OjEqN5V5W8p4YWEh8/Mq+HxLKYoSnRP8/FUjOe24zJYlkqT6K4QQIvZIABZCCBGT7JB5xQm5XDSyK4qiRNfjVWFXdTMXPL2IPbUB7prUn6vGdSdsRIOpRXRert8d/RW6r6J7YB01nrLnAWcleXnrxrFAS1VatdcGtmgMRuf+2kOhD8YENAV+9qPeLCmopLIxxLy8MvwenT4Z8Txw/mDG9EjdrwO1EEIIEUskAAshhIhpHj3aQKq1JN++JlhxbpV4j45hWU7X5yN1sN1aL6GkKooTpsOmRUVDEFVRDjjXuM1jAGHD5NR+GVw3vgfPfFFAgk+nc7KP9382Hp9Lc4ZWCyGEELEqprpAK3LFWwghRDumZWGYFhHTIhQxCRtmu6ZT0d8dRxt+D8WuIDtV2ZYEXN8coaoxhKZAeoJnv/OBaECPmJazv0uLDtW+c1I/BnZOpClkUFzdzMMfb3GegyktoIUQQsSwmKoAG4aBJb/4hRBCtKIqyr5M2VIdjffuG97cGIpQXN3M1r317KpuYldVExt313HV2FzOHBhtWKWqCipgcXTDiy3LwrSi2dcwLdyayrayeqqbQsR7dbp3iotu124/j0t1Krp5pfW8vnwXTaEID184hH9cNoJLnl1KdXOIp+YWYFlw/48HoqDIMGghhBAxKyYCsGVZKIpCaWkpwWAQVY2pwrcQQogDCEVMCsobqGwIUdEYpKwuSE1TiF3VTYQMk1S/m6fmbeMf87ZRH4jQEIhgWCYN9SFG90hl8uAstDZDihWqm0LRavERXG9tHcLtQPvOmhIagwZp8W76ZyW2HL1l6aOWOcV5pQ1s3F3LnE2lLCusori6ieQ4N784rS+DOyfx4k9GceWLy2hWTJ75ooDtZQ08etFQspK8dNC8WgghhPjBi4kAbA99zszMpLi4GNM0JQQLIUQMswPk3roAF/5zCfWBMOGISXPYcDpB+1wahmURbrDw6NF5wDnJXjqn+MhJjmNcz068t6aEbWUNpPrd+NwaG0pqKa5uwq0raC2/Zw6Wg+21hT/asIcvt1aQnuBBVWHLnno+31KGqkK/rAR6pvsBqGoMMXPNbpLiXATCBpc8t4SyuiDNYYN4j0b31DhO6puOoioYlsUJPTvxwtWjuemVVdSYYT7bUsqUJxfyj8uGM7ZnJ6kECyGEiDkxEYBtmqbJPGAhhBCOVL8bwzIJRAySvC5S4914XRrpCR7S4z1kJfnISfbSLTWOrqlxdEv10cnvwd3SNOuql5bzyoLtJCV4sIgG63iPTnPYYHi3ZGi57UClVjuAllQHePjDTXh9OoZp4dKijbk8LpWf/ahPm5BaUtNEIGzSFAzican0TPczpkcqJ/ZO45R+6XRNiXO2NUyLCX3TeXfaifz8zbUs2V5JeX2AiNESy6UMLIQQIsbEVACW+b9CCCEAJ/TFuTX+ctEwFAWyk3yk+d2k+N14XSou7cAjhSJGdCmkMwdmsW5XDUk+F4ZpgQJel8aZAzK5aFQXLA7ePMu+75yh2Vx+Yi6BsIEF+Nwa2Yk+LhzZmRN6dor+/lIUUv1uzhiQRV5ZPaf0y2BE12SGd0uhU7zbOaYduBWi6wObpkX/rASm3zSO3763nlP7Z3BSnzRZC1gIIURMUqwYSoWRSISVK1cyatQodD2msr8QQoijYLY0p1KIDplWWpKl4twPoYjRZh+XprabF3z47Cpy693bryEcNsz9wrll4SzT1FHebj/UuaN1iYUQQohYIClQCCFETDPM6HVgJ+CCE3JVReFgWVZtqfi2d7Rza+2gbR8D2O84dvi1z1ttCb36QR5PVRQsK9qlWqHjkCyEEELEAgnAQgghvoeOdvLq/vsdbbW29RHbO9rGUvax7PB9sG2O9LzbBHwhhBAiRkkAFkII8T2kgGWCcgQd/Y90+8M/k2/1WBJhhRBCiKMnawEJIYT4fjHDYEaiYdYyD28fO/yakej+QgghhIhJ35kA3L4X18F6cx3JtkIIIX4g7LBbVQQvnAbVhS0h2DjoblhGdLvqwuh+VUVtjyeEEEKImPGdCcD2+rzhcLjNvw+1rWEYsravEELEArvi26kXDL4IXj67JQRrBw7BlhG9v7owuv3gi6L7/4+GQwshhBDiu+2YzwG2LAtFUSgrK+Pjjz+msrKShIQExo8fT//+/Z37W2+7Z88ePv30U6qqqlAUhcGDBzNhwgR0XW+zvRBCiB8YRY2u4TN2Gqh6NNT+5ENI6bEv7Nrah99xt8HxN8oaQEIIIUQMO+aXvxVFIRgM8vbbb9PY2Mhpp51GZmYm06dPZ8eOHSiKgmmazrbhcJh33nmHYDDIWWedxciRI1mwYAHLly8HZDi0EEL84ClKdC7v8TdGQ21HleADhV8zIuFXHDHTsoiYlrP01LFgmBYR49iegxBC/BAc0wBsB9v8/Hyqqqq48MILGTx4MOeccw6dOnVi9erVQDT42sG2vLycqqoqzjjjDPr3789JJ51Ejx49KCoqcrYVQgjxA6fqBw7BRujA4Vc95gOfxPeQqijoqvK1l8z6OjRVQdeO7TkIIcQPwXfim8CePXtITEwkPT0d0zRRFIXu3buzc+dOoG0ATkpKIi0tjVWrVqHrOvX19ZSXl3PiiSce8nEkHAshxA9I6xAM0bB71Uzo1Bsqt8F/zpXwK74W07JQFYV5W8v5YmsZqXFurj+5J3Fu7bBG0puWhYLytQYd2CtXz91SxoaSWvpnJXD6wKzD3l+++QghRFvH9NuAHUgbGhrw+/1O0FUUhbi4OAKBgPNv+z6/38+IESP44IMPKCoqorGxkYSEBAYPHtzhY5im6TTKikQi3+bTE0II8b/WOgRbBrxxOUx6ED6+JzpPWMKv+BqslvQ5d3Mpf5q5ga7pCVx2fHfi3Nph7au2fM+xg/TX8fyC7byxeAfnjurCGUcQgIUQQrT1nfhGoGnaftXZSCSCpu37BWOaJqqqsmvXLr788kvGjh3LyJEjqa+vZ/bs2cyePZuLL77Y2d4OziUlJRQVFeF2uzEMw6kwCyGE+IFQ9eiw5xNugVADPDoRLns4+m8jBJr7WJ+h+A6zrOj82o5KpYZpYVngc2skJ3rpFO/GsqJzcS3aVYBbKsKaqjjV4YLyRjITPcR7dKeSe7Ti3BrpyT5Kapq58ZVVh9xeAUKGybRTezOyewqmBTJ6WgghjnEAtkNqfHw827dvb3NffX098fHxTlhV1eh05cLCQkzT5OyzzwYgOzubmpoa5syZQygUwu2OftGx9+vcuTNZWVlOBXjt2rXSKEsIIX5ILCMacisLYOtHcMrV0f8OvLBlyaN23aGFaEVRQNc6ToZ6S2L0ujSCERPTsugU70E7SAcVw7LQFIWdVU1c8PQiuqXG8eAFgxnYOQmL6JDooxEN6RZ7agO8uLDwsJ5XJGwwZXA2I7unRL/7SAFACCG+G0Ogu3fvzoIFC9i+fTs9e/YkGAySn5/PmDFjAAgEAgSDQZKSkvD5fEQiEaqqqkhNTQWgtrYWr9fbpmJsU1XVCc9S+RVCiB+Y1t2e//PjaNV37DRY8lT03wdaIknEPDsPbt5Tx4fr9uDSVKJ13bbbaKrCom0VxHt0AmGThz/ejN+tY1r7qsYKChHTJD3ew1Vju9MQjHDjf1ZRXh8kv6yBTzftZVDnJAyT/cKzBZimdcAKsdnq9lDE4rgsP/dM7n/I56cAEdNiSJdkDNOS7CuEEC2OeQC2LIvc3Fz69u3Lm2++yciRI9m+fTsul4thw4YBMHfuXNasWcM999zDcccdx7Jly3j55ZcZMWIEtbW1rF27ljPOOANN0w66DrBUfoUQ4gfkQEsdRUKHt06wiGlmS6V27a4a7nxnHfF2qG3HAuI9eksANnhw9mbar0SkKgqNoQjDu6Zw5dju3P3OOlbuqEZV4MKRXbj11D4HnAeswEE7O9ufWI+uEYwY9EjzM+2U3kf/xIUQIsZ9Z+YAX3DBBSxfvpyioiKysrI48cQTSU5OBqBfv34kJSUBEB8fzxVXXMGKFSvYuXMnbrebCy64wGmCJVVeIYSIAQdb51d3798dWkKwOIAEr4s+GfHEHSAAqwo0hwwCYRNVhdw0P6qitKkVqyg0hMIc3zOVv32Wz1sri/HoKt06xfHXi4fi1tWWC/T79rEv2Fc0hHhx4XYipoWudNwxWlEUtuytI9HrYtPeeh6YtfmwKrpmy9xmr0vj+vE9SYpzfe25yEII8X2nWN+zsujBKryHEolEWLlyJaNGjULXvxPZXwghxJGyTFDUQ6/za/972bOw+IlWIbhlfyGAUMSkIdjxKhGGaeFzazzy8RYen5NP905xvHfLeDrFu9sMKzYtC79H54UFhTz40WZ0Nbpu8PSbT2REt2RM00JtV+W1K8Jb99Zz4sNzCUUMQhGLYMTsMNymJ0SbaTWHDPbWBQ75vCwLfC4Vl6aiaSqL7/4R/bMSvpGO1EII8X32nUqBdqdnO5PbQdeyLCzLQlVVZ9i0/e/WfxdCCPFDZ0XDa9V2+Pc5B1/nt6N1gq/+AFJ7gtTBYp599d+tq6TqB+8UbleHFRQ6xbtJjnPtt82zX27nwY82o6kKpmXxxKUjGNEtmYhhoWnKAT9xuqqQnuChMRhhVPdUemXEE94vBCssLqhgV1UTafFupo7qEq1CtzwJ+3uT/RiqoqBrCl8V17KxpJbuneLonOKLHknCrxAixn2nAvCBmlXZ6wB39O/29wkhhPihavm2X7sLXrng4OHX1j4Ev3IB/OQDSOqChODYdjjvvN0oq3VzrI7GzT3y8RYe+WQrfreGBfzjspGcPSQHOHCHaed4RIcqNwYNLju+G1NHdulwu+v+vZL1JbWcPiCTJy4ZfhhnDxc/u4Ta5jCDOieR4NGRRtBCCPEdC8BCCCHEwSmg++Dsv0KvH0WHMx8o/NpUPbrd8TdCWp/o/ijA92oGkPiGNYcNZ47sgdhDl0MtFVkLaAhGcLuUaCMsy+Kvn+XzxOf5JMW5CEdM7v/xQKYMyaYuEEZTFOejpigKPrd20OAdipgHvCxj32ZZ0XMPhk3qA2Fqm/f92VsbINXv5txhnVmyvYKF2yrwujSO79kJiC7RpEsCFkLEOAnAQgghvidavrj70/aF38Ody6uo0e17/Wj/44mYYYdL07K4/j8r+WpXDT6XfsBVIuztm8IGGQlemkMRznlyASj2caCiIUiq342Fhc+l8eLCQp6aty06Qo3oASKmRYrPxYe3jSfOrXd46cUi2g06Ypgs3lZJXSBMZWOImsYQ9cEIG3fXkuxzsWpnFaf99UtqmsKEIiZhwyQUMQkZJlWNIXqlx/PjYTmU1YeI9+gkeRXOGJAJEA3kQggR4yQACyGE+J6xWsamHmHvBzsEKwoSfkVhWSMbS2rxe1wYh+gHavev0lWVprDhNJHS1Og83NK6gDOmYFd1U5upWaoSrexmJno7HD5tsywLl65S2xzmkueX0hSKEIqYBCMmlgUZiR78bp2apjBldUE8Lg23puLRNZJ9LtISPCTHuchK9NIUNDhvWA4T+qaxq6qZrilxgAx/FkIIkAAshBDie0c5+m/y0v05ptmfGkVRuOmUXpwzLAeXpraZ49ueZUUrvYk+ncqGENNX7qKmOYymKlQ1hhjbsxOnDcjEMO0Gnu0fUyFiWqTFu/G6NOc82j+iokDEMEmL99A/KwFNVchM8JAc5ybF7+bLvHI276ljTG4qt5/WhySfy/nj9+i49WjHZ12NPl7EtEiJc5MSd/AGX0IIEWskAAshhBAipijAlWO7H9E+G0pq+fPszTQEIwTCBoqicOPJPbl3ygASvF//65SC4oToWbedhFtT2zTQuuGVlazaUU2iz8WZA7MOeixdlVKvEEIciARgIYQQQsQcw+yg7mtFOz6bFnj06GiBbWUNPPXFNt5asYumkIGiwIhuKfz27OM4pW8GEK3cHmpUgkJ0yPTh8Lm0VmsMR08sEDZJ8Ois2VnN//tgI91T47DAGY7d/siKPfc4zs2Ph+XI/F8hhGgRUwFYlksSQgghBLQNo/ZSRKq6b2nFXVVNvLy4iLdW7qKkuhlFUchO8nHtibnccmov4tw6hmmhKKCpaqtjtYrVLV201IN8/wiETUwrOldY16LHMSwLraWJlmVFz6tLio+KhhAo8ODsLfu6QrNvHWCn8RbRx2wOGwzKSWTKkOyDrkUshBCxJKYCsGEYB+z0KIQQQojYYYdeiIZhOxBv2VvP9FW7eGvFLkpqmrFQSI13c+GILtx4ci96pvuj+1sdV3SV1hHzYGmzJY3WBcKEIgYuTXWGUrdu06a2dJz+9Zn98bk0tpbWoyuKE7MVBVyaigKETct5TooSXb6pa4rvgFViIYSIRTERgC3LQlEUSktLCQaDqKo0QRFCCCFiWeshyYGwwdytZcxYVcKC/HLK6oMkeHX8Hp0zB2Zx16T+9M6IB3Dm6ZqWhWFamJZFxIBQxCBomATDJsGIQciwaAiEyUz00jsjPtq4vFUCtQNsXXOYsGmhayrxnpYA3DpDKwp1gTDBsMHdZ/XHpbX9DmNaFntqAkRMi/QED3Fu7X/yegkhxA9FTARgezhTZmYmxcXFmKYpIVgIIYSIUZYFjaEISwoqmZ9XzoJtFWzdW099IIxbV0lP8BAxLEJGdBmiFxZup6wuGF1vN2ISiBgEwiaBsEFz2CAUMZ1AbJgWhmWholBWH+TmU3vx4PmDMVuGNTvn0PLfysYgwbBJXJyO3932a5lpWaiKwqOfbOXJz7dx5qBM3rj+BBRFce4rrm7mnCcXUlof4O//N5z/G90Vw7QOe76xEELEmpgIwDZN02QesBBCCBGj7NBYUN7AZS8sY3d1Mw3BMKYFPrfGqO6pXD0uF11V+M2763FpCjPXlNAcNg4YKBVFQVXsYdQqWsucYI+uYGG1HRLder+W/xaUNRIyTNy6QnqCp8NtAyGTpnCE5pCBCbSu8ZpEK9iBkOFUp4UQQhxYTAVgmf8rhBBCxC5FUbAs6JziI9Grs74xSM90P8f36MT5wzvzo+My8bs1vthajmlZmCac0LMTXVJ96KqK16Xi0VXcuoZbb/m7puJ1aXhdGj6Xhte1798uTaFbahyGabVphGWxb/h1flkDKtA52UdWksc5z9b/DUQMXKqKW1f3a6ilAJoSncN8oGv8pmUdcM6yEELEmpgKwEIIIYSIXQrRiqnPpXHPWcexZHsFl47pRq/06Pxey4rO8Q1FTBRFIWxY/Py0vkwafPB1dw/GaDf0ubXGoEFeWT0A/bIS0FXVmStsd2y2LIuiikZUVSHR6+qwnmzB/ks6taIqinTAEkKIFhKAhRBCCBEz7CLoxOMymHhcdB1fy2qpkgJ6u0qqHS4NIzqv1iJaTbXva83ezZ6D+97aEh6cvYXzh3fmpgk96RTvwbKi6wyrqsKqHVXsrQmgqooTwg3LinZ5bjmf8vogRZWNKEBOss85/qFmdNnDr3dUNvLUvALG9+nE6QOy8Lm0/RpyCSFELJFOUEIIIYSIOXa117TstXw7nq1r2Qm4ZW0iRVFQ1egfTVXQW/2xl1NSW0L0zqom1hfX8tS8bdQFItHjsW9Jok83lVIXCJMc52ZC32gYt6u/9rDpN1cWU1obIM6tcXyPVOe8Ojrb1oHcDumldUGem7+dG/+ziq1761u2kylhQojYJRVgIYQQQsQcReGAQ5Nbc2ktFWHr8EcR6y1l5lVF1fi9Gr3S48lO8jr3q6pCY8jgi61lqIrCcVkJDO2aFK36toRtl6ayeU8dLy0sxAKGdU3m9AGZzvzhjtqa6C23m5YFFqiaQnl9EJ9LJdnvJiXOfZjPQAghfrikAiyEEEII0Y6qQMgwWVtcg2FaTqg9HMGIyRvLd7KooAJNUeiblYC3ZeixZUVrwO+sKia/rAGwmHhcRksTq2gl2TQt3lyxk8ueX0ZlQxDDsrjl1N54XVo03LZiEQ3zpgkVDSGUlvBsrxf8xdYyGkMGyT6X02X6QJ2phRAiFkgFWAghhBCCffNiO/ndmBYkel08+2UBC/LLSfW7McxDz52NGCa7a5oprGhE11SCEZNT+6UD0WHNuqZQ2RDi2fkFqIpCRoKX84d3BiC/tIHPN5fywbrdrN5Zg2GamBbcflpfzhmSs99awgB+l0bEsEj06by4YDsbd9fi1lRUBfbWBVlRVIVLU+mbmUCcW4sGcJkALISIYRKAhRBCCCHYt0zScdmJjOyWwmebSonzaMzdUnbYa+wqioKmKOhaNGSeOSiL84d3diq1AHll9RRWNNIQjHDjhJ70bGmANXdrGdP+u5pEnwtNVeiTkcAvTu/DRaO6Ylm0XQJJiVaTO/ndjO6RyjuriqkPRNiwuxb7VHVVwevS0FSFC0d2AdhvHWEhhIg1ihVDi+NGIhFWrlzJqFGj0HXJ/kIIIYRoy+6QXFYf5N+Li9hZ2YRhWYc9aNgCvC6NRK/O0K7JnD0kB5emtFrWKHr86SuLeeSTLbx7y4nkpES7O4fCJle8uIzGYISLR3flguFdSPTpB+zabFdzyxuCvLyoiJKaZrtXV8vjKfi9GhP7Z3JKv3TnHIQQIpZJABZCCCGEaOWbDooHOl5NU5jkOFeb2wJhA5emorXMObaXVBJCCPHNkBQohBBCCNGKXam1l0g60qZRrdcKVg+wvJJpWfuFX7t6DPuWQTqc8Nv6XDu6D5AQLYQQLWIqAEvTByGEEEIcjsNdJqnDfVEOWUJWW+Ybt5vW66zQeySB9aDnKl99hBCijZhaBskwDGJoxLcQQgjxw3Okv8e/w7/3O8qs9hxeIYQQ/xsxEYDt0FtaWkowGERVY+JpCyGEED88inL4ofZA3aOEEELErJhIgvbQ58zMTDweD6ZpHuMzEkIIIcThaQm7Ffnw6lRorm4JwYf4XW61LNrbXB3dryK/7fGEEELEpK8dgC3LwjTN/f4YhuH8sW871jRNk3nAQgghxPdKy8zYlO6Q3hf+NbklBKsHDsGWGb2/uTq6fXrf6P6yEJAQQsS8rx2AFUVBVdX9/mia5vyxbzvWZP6vEEII8X2kgOaGM/8MfU4/eAhuH377nB7dT3Mj4VcIIcRRd4G2F18vKChg2bJlqKqKZVlO+FUUBV3Xcbvd+Hw+srOz6dev3zd57kIIIYSIJZYBp/8h+vd/TYZrZoMvZV/o7Sj8nv6H6H6KdmzPXQghxHfC1w7A27dvZ/r06eTk5KAoCqFQiEgkQiQSwTAMVFXFMAwALrroIs477zxnXyGEEEKIw6ZoBw7BZgRUXcKvEEKIg/ra6wC73W4SExPp378//fr1IzMzk/T0dOLj41FVlcbGRoqLi3nrrbf44osvmDx5Mm63+5s4dyGEEELEmo5C8NUfgD8NGivg3+dI+BVCCHFAX6sCbDe3siyLbdu2sXnzZoLBIB6Ph+OOO47Ro0czevRoMjIyyM/PZ8aMGUQiEdxut1SBhRBCCHF0Wodgy4LXpsK5T8HMadD7NAm/QgghDuioA7CmRX+p6LqOZVmMGjWKnj17EgqF2L17N8uXL2fu3Ln07duXSy65hN69e3PBBRfg9XoBJPwKIYQQ4ugpGphhOOOPMOc++PMgOOf3cNr90dtV17E+QyGEEN9BinWErZHtyu2uXbsoKyujpKSEGTNmEB8fTygUokuXLowbN46hQ4dSVFTEq6++SmlpKRdeeCEXXXRRm2N82yKRCCtXrmTUqFHo+tce/S2EEEKIY8VueNVUCdOvhUAAvF6Y+hLEddp3vxBCCNHKEf9msNfzXbp0KX/84x957733UFWVESNGcPnll+N2u3n++ee57777iEQiPPjgg4wbN45XXnmFf/7zn05DLCGEEEKIo+J0e66Bl8+GrMFwwyfR/758dvT2g60TLIQQImYdcRnUHvp88sknk5qaSn5+PkVFRSxZsoSKigp+8pOfcPHFF/P222/z5z//mQsuuIBbbrmFpKQk+vTp851YD1gIIYQQ31MHWurIjMAZf4re96+z9l8iSQghhOBrzAHOzMwkMzOTiRMnsnDhQl599VUURSE1NZVIJMJJJ51Eeno6Xbp0Qdd1rr766m/yvIUQQggRaw61zu+h1gkWQggR8444ANvzd7ds2UJBQQEej4cFCxagaRpDhw5lyZIlLFq0iLy8PKZOnYrP5+Pzzz/Hsiw0TWPs2LF4vV7pAi2EEEKIw3eo8AuAhGAhhBAHd9QBeNmyZcyaNYu0tDRnXu/rr7+OYRi43W7cbjdvvfUWdo8ty7Jwu90MGDDA6QT9bZPALYQQQnwPWdZhhN8WB60EWyDfBYQQIqYdcQBWFAXLspg8eTK5ubns2rWLTZs20dzczLRp0/D7/QDMmjWLTZs2ceuttxIXF4dpmqiqSmpqqnOcb5thGBxh02shhBBCHEv27+2GMvjPuQcPv7aOQvBVM8GfLiFYCCFi3FEFYMMwSE9Px7IsPvnkE3w+H8FgkKeeeooTTjiBa665hhEjRjBnzhxCoRCDBg36X5z7YbOr1qWlpQSDQWnEJYQQQnyfKEq0ydXYaTD8ipYQe4Dw6+yjRbc7/Q+Q1je6v6LsC9RCCCFi0hGvAww4VdSGhgbKysoIBoOUl5ezdetWcnJyOPvss6msrGThwoWMGDGCLl26YBgGiqI4XaSPhVAoxKpVqxg9erSsAyyEEEJ8Hx1pBVcqvkIIIVo5qgB8KIZhoKrqd27OrWEYrFixglGjRkkAFkIIIb5XLDBNUI/iQrppgKoC363vJUIIIb59R50C7dwcCoV47LHH2Lt3rzPUWNM0VFVFVVU8Hg9xcXGkpqZy5pln0rNnz2PWAVrm/wohhBDfV8rRhV84+v2EEEL84Bx1ALYDrMvlory8nPj4eAYMGEAoFMI0TSKRCOFwGMMwqKurY/78+ZSXl3Pvvfce02HQQgghhBBCCCFi01EH4EAgQCgUwjAMQqEQw4cP58orrzzg9i+99BKLFi3CMAw0TZN1gIUQQgghhBBCfKuOOADbyxm9++67zJgxg6SkJDRNY+HChcybNw+Xy0V8fDzZ2dl06dKFfv36MXz4cDIzM+nSpYvMvRVCCCGEEEIIcUwc1TJIAAMGDHDm+M6aNYvOnTszdOhQ6uvraWxsZNeuXWzevJmZM2fSuXNnxo4dy5133omqqlL9FUIIIYQQQgjxrTvqADx06FCGDh0KQH5+PqNGjeLUU09ts21tbS0bNmxg7ty5zJgxg927d3PLLbdIFVgIIYQQQgghxLfuiJOoXb1dv349W7duZdCgQdTU1BAKhfjb3/6GYRjouk4gEOCUU06htraWMWPGsHfvXrKystB1XSrAQgghhBBCCCG+dUc1B1jTNDZt2sSCBQsYNGgQTU1NVFZWsm3bNrxeL5FIhKamJrp168batWsZNGgQXq+XxMREFEXBNM3/xXMRQgghhBBCCCEO6KiHQOfm5jJ//nw2b96MqqpUVlbSvXt3MjIyqKurwzAMqqqqcLlcRCIRACorK9scQwghhBBCCCGE+LYcdQDOyMjAMAw++OADdF1n7dq1aJrGtm3bnG0Nw0BVVcrKymhqaiIUCrU5hhBCCCGEEEII8W056m5UcXFxuFwu+vXrR3FxMWlpaRiGQVpaGvX19c4839LSUnr16kVFRQXV1dWABGAhhBBCCCGEEN8+9Wh3dLlcAGRlZeHz+ejevTu1tbXs3buXmpoadu/eTffu3dF1nR49etC7d29qamq+qfM+KhK8hRBCCCGEECJ2HXUA1nWdhIQE3G43oVDIqQg3NTVhmiamaZKQkEDnzp1JSEjAMAynMnysGIZxTB9fCCGEEEIIIcSxo1hHmQgNw6C5uRlN0ygpKaFLly7O+r6WZWFZFpqmoSiKMw+4sbGRHj16fKNP4HDYw7F37dpFQUEBJ598Mqp61NlfCCGEEEIIIcT30FGnQE3TiI+Px+fz0bt3b7xeL7quo+s6LpcLt9uNpmmoqkowGGTu3LnOHOBvuwprD33OzMzE4/HIMkxCCCGEEEIIEYOOOgDbVd6mpiaeffZZli9f7ty+fv16VqxY4QTdQCDAu+++y6pVq5xtjgW7Ii2EEEIIIYQQIvZ8rXHAiqIQCAT4/PPPKSgocG77+OOPee2115xKq6IoJCYm4vP5vv4Zfw0y/1cIIYQQQgghYtdRL4ME++bWxsfH43a7nYDp8XjweDxOldiyLEzTlAAqhBBCCCGEEOKYOeoAbA8lVlW1TaXXZlmW0xTL/q8QQgghhBBCCHGsHHUyDYfDGIZBU1OT8+9QKIRhGEQiESzLoqGhAZfLRUNDg1R/hRBCCCGEEEIcU0ccgA3DQNM0PvroI15//XWSkpLweDzMnTuXuXPnOsOiFUXh5z//ufP3cDgsDaiEEEIIIYQQQhwzRxyA7RDbpUsXxo0bh6ZprFmzhuzsbHJzczEMg7y8PJqbmxkyZAiqqhKJRFiyZMk3fvJCCCGEEEIIIcThOuIArKrRxtEjRoxgxIgRBAIBbrrpJoYNG8YFF1wAwJNPPklxcTE33HADEF0GqfWySB2xK8cH+vfX3V4IIYQQQgghRGw76jnAkUiEbdu24XK5nGHO7bs9RyIRNE0jGAwe8nh2eA2Hw84xD7W9Pdf4cLYXQgghhBBC/P/27jy+ivpu//9rZs6SfSEJIWwJ+yYIAqIiuCGKuLVaW22tWrVql7t3l/vX3l1vbet9t19v77Z3d21vba0tarVWVFxRFnFhFVkDIRAIJGTfzzIzvz9O5pgAYUkiCZzr+XjEkHPmzPnMZDwn13l/FpHEdsIB2Ku0NjY28pOf/AS/34/rulRXV+O6LpZl0dbWRigUigfj46nkVlZWsmTJEqqrq0lPT+f8889n/PjxnSq7XrAOh8O88sorFBcX47ouQ4cO5YorriAtLU2VYBERERERETkis7sP9Pv9XH311RQUFBAMBnnzzTe5//772b59OxMmTGDs2LGdgqhlWfHu0x0ZhkEoFOLJJ5+kubmZefPmkZ+fz1NPPcXu3bsxDCO+zJK3/SuvvMKGDRu46KKLuPzyy9m+fTvPP/98dw9FREREREREEkC3J8FKS0vjYx/7GFdffTWlpaW8/PLLLFu2jPvuu4/bb7+dL3zhC/Hg6rouDQ0NtLa2dtqX4ziYpklxcTE1NTXcddddDBw4kMmTJ7N3717Wrl1LYWFhvHu1YRg0NDTw/vvvc80113DGGWcAkJSUxM6dOzu1T0RERERERKSjbo8Bdl03viTSqFGjuOeeezjjjDN45ZVXyMrK6rRtMBjk6quvZsyYMcDhIXX//v1kZGSQl5eH4zgYhkFhYSF79uyJb+/dXlZWRjAYJCkpiVdeeYW2tjYmTZrEpZdeesw2KxyLiIiIiIgkrm4HYMMw8PliD/fC6Zw5c5gzZ06nbSBWob3pppsOu9373tTURGpqaqdKb0pKCm1tbYeN6W1tbaWtrY0XXniBnJwcotEojz76KPPnz2f27NmHbe84DrZtxyfNEhERERERkcTU7Umw6uvreeGFFxgxYgTnnHMOAIsXL2bDhg3MnDmTCy64gGAwGJ+4yuvufKQqrGVZh93uzSDd8Xk9bW1tXHbZZcyYMQOA5557jlWrVjFr1qx4KPfauW/fPkpLSwkEAti2HQ/rIiIiIiIikli6XQGur6/nxRdfJBqNsmnTJj73uc9RW1vL+vXr2bZtG0uXLuWee+5h+PDhAJ3CrMcLqWlpaZSUlHS6r7GxkbS0tHhY9R4fDAZJTU1l7Nix8TA7evRoPvjgA1pbW0lPT+9UBR4yZAiDBg2KV4DXr19/1PWIRURERERE5PTU7VmgLcsiLS2NsWPH8tZbb/GLX/yCvXv3MmjQIC6//HJaWlpoamqipqaGqqoq6urqDtuHF1ILCwupr6+npKQE0zQJhUIUFxczYsQIIFbxbWhoAGDQoEHYtk1paWm8orxnzx6Sk5NJTU3ttF8A0zTx+/34fD78fn93D1dEREREREROcT0aA9zU1MRNN91EdXU1f/rTn0hPTyc5OZk33niDSCTCgw8+SDQaxTAMTNPkiiuu4Lrrruu0D9d1KSoqYuzYsSxatIjp06dTUlKC3+9n6tSpALz++uusX7+e/+//+//Iy8tj+vTpPPvss+zfv5+2tjY2bNjAlVdeiWmaR10HWJVfERERERGRxNWjWaBTUlL44IMP2LJlC8OGDSMzM5OKigouuugi/H5/fPIpn8/HmjVrWLFiBVdffTV+v79TULUsi49//OO8++67lJaWMmjQIGbPnh2fTXrcuHFkZmbG1xG+7LLLyMvLY9u2bfh8Pj75yU8ybty4o4ZfERERERERSWw9CsBNTU1kZ2czadIkLr/8ct58803Kysq48cYbD9s+EomwZMmSwwKq93MwGDxsFmnPqFGjGDVqVKfHTJ8+nenTpx9xXyIiIiIiIiKH6nYATk5OZvr06UycOJHJkycDkJqayvDhw2lpaSEYDNLU1EQwGKShoYFoNMpnPvOZ+CzNRwqr3kzRXldlbxvXdXFdN14B9rbteH/H+0REREREREQO1e0AHIlEaGxs5NFHH8V1XYLBIC0tLTiOw7PPPsuVV17J17/+dW666Sai0ShLly7lN7/5DUCXXZW9EHukKvGht3UMvKr8ioiIiIiIyLF0u2wajUYpKSlh+PDhDB48mPLycs455xwcx6Guro6UlBRaWloAGDFiBK2trYctdSQiIiIiIiJysnQ7ABuGEV9eKBAIEAgEMAyDlJQU9uzZw1/+8hdSUlJ49913eeONN7Asi4MHDwKajVlEREREREROvh5NguXz+di6dWu8i/I777xDW1sbkUiEN998E7/fz86dOyktLcW2bWpqanqz7SIiIiIiIiLHrUcV4FAoxOzZs5k1axa2bXPdddeRmZnJ5MmTuf/++2lra+Pyyy/ngQceIBgM0tjY2JttFxERERERETluPaoABwIBXnrpJUzTxDRNHnnkEVpbWxk5ciQZGRlEIhF8Ph9paWlYlsXevXsBTVolIiIiIiIiJ1+3A3Bubi5f/epXD7vdtm2ys7Px+/187WtfY/DgwTiOw1VXXUVWVhagACwiIiIiIiInn+Em0IxUtm3z3nvvMWPGjPh6xCIiIiIiIpIYepQCHcc54u3epFiO43T6N3Rev/dks21bM1CLiIiIiIgkqB4F4I5h1nXdTl2bDw3HfRl8vbZVVFQQCoX6tC0iIiIiIiLSN3qcBF3XPSz8AvGJsQzD6POqq9e2/Px8gsFgl5VrEREREREROX31eCCsFy5bWlrw+/34/X4ANm3aRE1NDUOGDGHkyJE9fZpeYVmWJuASERERERFJUD1aBskwDJqbm3niiSfYtGkTX/nKVxg6dCgPPfQQq1atwrZt/H4/8+bN41Of+hTQtzNA93UlWkRERERERPpOj7pAu67Ln/70J1588UUOHjxIcnIymzdvZtmyZQQCAQYPHozf7+e5555jzZo1/aI7tIiIiIiIiCSmbgVgr/pbVlbG2rVryc3N5dOf/jS5ubmsX7+ecDjM2LFjuffee7n66quxbZv169f3ctNFREREREREjl+3AzDAvn37aGxs5Mwzz2T+/PnYts2uXbuwLIvp06cTDAaZPHkyaWlp1NTUAH3bBVpEREREREQSV4+6QDuOg+M4pKSkAFBTU8O+ffvIyMigsLCw03Y+X4/n2xIRERERERHpth4F4NzcXFJSUti8eTOVlZWsWrWKpqYmcnJyGDJkCM3NzSxdupSWlhZycnKAw9cHFhERERERETkZulWW9SazKioqoqioiO3bt3PfffcRiUQIhUJMmTKFQCDAL3/5S9auXUtycjIzZszo7baLiIiIiIiIHLduVYC9cbzBYJDPfe5zjBkzhnA4DMCsWbNYsGABruvS2NiI3+/n+uuvZ9KkSbiui2n2qOgsIiIiIiIi0i2G24N1ibzZoAEOHDiA4zgUFBTEK8Tbtm0jPT2dIUOG9FqDeyIajbJ69WpmzJihMckiIiIiIiIJplsp0Au+VVVVPP3000yZMoVp06aRlJTUabvx48d32l5ERERERESkr/SoDBqJRHjzzTdZvnw5eXl5TJw4kTPPPJOJEyeSlpYW384rMisEi4iIiIiISF/p9iRYAOnp6Zx//vls27aNmpoalixZwptvvkl+fj5nnHEGU6ZMYcKECfFlkvqaAriIiIiIiEji6tEYYE99fT3bt29n+/btbNmyhfLychobG0lOTmbQoEGMHz+eCy+8kJEjR/Zpd+hwOMyaNWuYOXOmxgCLiIiIiIgkmB6nQMdxyMzMZObMmcycOROITYi1Zs0ali1bRm1tLc8//zzBYLDPArD3nBUVFYRCIc1ELSIiIiIikoB6HIA7hsmGhgZKSkooLS1lx44d1NfXEw6HCQaDJCcn9/Spus0L3Pn5+ezduxfHcRSCRUREREREEkyPArDruuzbt48tW7ZQXFzMzp07qa6upr6+nqSkJAoKCpg5cyaTJ09m8uTJQN+Ow7UsS+OARUREREREElSPlkE6ePAgP/3pT6mqqiIajZKUlERubi5z5sxh8uTJh80GDX0bgHthuLOIiIiIiIiconq8DFJTUxP5+flMnDgxHnozMjLi27iui+u66nIsIiIiIiIifapHyyBlZGTw+c9/ngkTJpCZmRm/3wu9hmHEv0RERERERET6Uo8qwOnp6ZxzzjmAQq+IiIiIiIj0b72yDJJCr4iIiIiIiPR3PQ7AXug91gRTCsciIiIiIiLSl3otAB8Pr4u0iIiIiIiIyMnW7QDshdnGxkYqKyvx+WK7Mk0z/uXz+fD5fAQCAZKTkzUTtIiIiIiIiPSZHgfgtWvX8sc//pFgMEgkEsG2bRzHiS99ZFkWfr+fQYMGceONNzJx4kRVgkVEREREROSk63EXaNd1sW2bqVOnMnLkyHjF17ZtWlpaCIVCVFZWsnLlSv72t7/xgx/8AMuyeqPtIiIiIiIiIsetRwHYm/jKsiy2bt3Kzp07KSgooKioiAkTJjBp0qT4toFAgGXLlhEKhUhJSVEVWERERERERE6qbgfgjsseua7LWWedRWpqKvv37+e1117jiSeeICsri8suu4yrr76aIUOGkJubSyAQiD9eRERERERE5GTpdgAOh8P4fL54kF2/fj3Dhw9nwoQJLFy4kMbGRl577TUef/xx3nvvPW644QYeeOCBXmt4dyh0i4iIiIiIJC7DPdYCvodwHAfTNFm8eDHPP/88ubm5HDhwgKlTpxIKhVi/fj1+v58LL7yQK664grKyMn7zm98QjUa59dZbOf/882NP3AdhNBwOs2bNGmbOnBmftVpEREREREQSQ7fXJcrPz6egoIDq6mqi0Sjl5eVMnTqV//iP/+CCCy5gyZIlfPe73yUYDPLv//7vpKamsn37dk4wb/cK7zkrKioIhUJajklERERERCQBnXAF+FBNTU0sW7aMp59+GsMwuP/++8nLy+P999/n4YcfprCwkK9//eu0traSnJzcW+3uFlWARUREREREEle3U2BrayvhcJhgMEhlZSU+n4877riDjIwM/vSnP7F582ZuueUWioqKaGhowLIsmpqaSE1N7bOxuJZlaRywiIiIiIhIgur2GODHHnuMxYsXk5GRgW3b+P1+XNclHA7jui6O45CVlUVrayu2beO6LoFAgB/+8IcMHDiwT5ZBikajrF69mhkzZqgCLCIiIiIikmBOOAV6oXXcuHG0trYSDAbZsmULTU1NzJ07F5/PRygU4oMPPqCyspILLrgA0zRxHAefz9fn3aBFREREREQkMXUrANu2zcyZMwmHwzzyyCPxam44HGbEiBHMmDGD559/nj/96U/MnTuX4cOHH3E/IiIiIiIiIidLt/oBG4aB67pkZWVxzjnnYBgGtbW1LFmyhH379nHWWWcxduxYRowYwcGDBxk6dCi2bWOaJpZl9fYxiIiIiIiIiBxTj2eB7qilpQXXdUlNTe2tXfYqjQEWERERERFJXN1KgV6X57fffptdu3ZRUFDAqFGjGDZsGBCbKMtxnPj6uy0tLTz++OOcffbZTJ8+vU8mwBIREREREZHE1u0u0AArVqzgrbfeIi8vj7Fjx5Kdnc2WLVsYPXo0Pp+PtrY2UlNTaWxsZNWqVVRVVTF9+nSFXxERERERETnpzJ482DAM5s6dy4033kgkEqGyspLW1lb2799PY2MjLS0tNDQ00Nrayrx58zBNE9u2e6vtIiIiIiIiIsetRwE4EomQnJxMdnY2tm0TDAY555xzSE1NjU94ZVkWPp8Pv9+vyq+IiIiIiIj0mR4FYNM0iUajhEIhIDY22LZtXNeNj//1vofDYVV/RUREREREpM/0aCrkQCDA9u3b2bx5M83NzZimyWWXXcbOnTtpbW3FNGP52jAMWltbmTx5cvw2ERERERERkZPphAOwN4Pzyy+/zPvvvx+f/bmuro68vDxSU1OZP39+fN1f7zGO4zBr1qz4GsJ90R1aXbBFREREREQS1wmXY70uzbW1tdTV1TFs2DDOO+88amtrGTNmDKtXryY9PZ09e/awe/du9u7dS0VFBXv27KG4uBjouyDqdc8WERERERGRxHPCAdgLr9dccw1nnXUWLS0t2LZNSUkJ//M//0NrayvFxcXs2LGDYDBIVVUVGzZsoKWlhSeeeILm5maAkxpEveeqqKggFAqpG7aIiIiIiEgC6nYATkpKIj09ndLSUv7+97+Tn5/Ppz71KSzLwnVdpk2bRlFREdnZ2eTl5XHOOedQUFCA4zi9fhDH2+b8/HyCwWCftEFERERERET6VrcnwfLG9VqWRXNzM9FolJ07d8Z26vPR0NBAXV0do0aNIhqNkpuby7333ht/fF90g7YsS+OARUREREREElS3A7A3mRXAyJEjWb58OY7jkJycDMDq1atJTU1l+/btpKens2nTJoYNG0Zubm6fhVCN/xUREREREUlcPVoGKRgMUlpaSnV1NXPmzOGiiy7ioYce4uyzz2bMmDH4fD7C4TDl5eW89tpr7Ny5k+9+97sagysiIiIiIiInneH2oCxaWVlJU1MTmZmZ5OTkEI1Gqa+vJycn57Btd+/eTSQSYfTo0X22DFI0GmX16tXMmDEDn69H2V9EREREREROMT1KgQMHDmTgwIEf7sznIycnJz4+uGPILSwsjP9b43BFRERERETkZOtRAO5YPPZCrVfdtSzriNsq/IqIiIiIiEhf6FEAPlKY7SrgKviKiIiIiIhIX+o3s1EdOhRZMzaLiIiIiIhIb+qVAOy6bvzraLcdjVchjkQinX4+Ht5jRERERERERLrSK1Mhn0hX6EN5Y4YrKytZsmQJ1dXVpKenc/755zN+/PguZ4x2HAfTNHnqqadoa2vjM5/5TI+PQ0RE5ES4gAb4iIiInDp6VAH2qrtbtmzhl7/8JcXFxfH7GhsbeeSRR3jppZeOWgU2DINQKMSTTz5Jc3Mz8+bNIz8/n6eeeordu3djGAaO4xz2vKZpsnr1atatW6fu0iIi0mNdvZW4btf3KfyKiIicWnqlC/Sbb77JokWLWLFiRfy2HTt28NRTT8UrtHD4uF4v2BYXF1NTU8N1113H5MmTueqqq8jJyWHt2rVA52qyt7xSeXk5K1eupLCw8LCALCIiciIc1+VIHZdcwDBiX7bT+T3MdlzCUb3/iIiInEp6pQv0/PnzSU5O5qKLLorfNm7cOG655RYGDRpEcnIy0HW36P3795ORkUFeXl484BYWFrJnz55Oj/O6Q0ciEZ5++mlmzJiB4zhs3rz5uNqpmahFRORITMOgsS1CatCHgYFhxKq+hgEVDW2YhkFeehCIBV/LNPj1Gzt5ZOUuzhiayb1XT6IoJzX+GBEREemfemUZpJEjRzJy5MhO96WkpPCJT3ziuB7f1NREamoqhmHEQ25KSgptbW2HjQE2DIOXX36ZQCDA7NmzefXVV48abB3HwbZtDMMgGo1291BFROQ0FCvqury3q5Z/+ds6rpg8iB9cNQnbiVWEw1GXz/9pDWW1Ldx3zSSunDIY0zBwHJeXNx1gW0UjYdshM9mP64KDi+kePQErIIuIiPSdXqkAe7M9G4ZxWHdlANM8ek9ry7IOC7HRaBTLsjrtyzRNtmzZwsaNG/nMZz5DJBIhEongui6RSASfz3dYtXjfvn2UlpYSCASwbTteYRYRkcTmVWsb26J86fG17DjYRGlVM4OzkrlzTuxD3Qde2spbO6toizq89EEFV04ZDAbsqGxiW0UjAcvk2qlDyE4JAGBpVLCIiEi/1muzQB8pVB4r+HohNS0tjZKSkk73NTY2kpaWFt+vt68dO3YQiUR47rnnsG2bcDhMNBrlt7/9LTfccAP5+fmdqsZDhgxh0KBB8Qrw+vXrNWmWiIhgGLEKcEaSn//51FTufHQ1jaEoP3h2E1OHZdEWcfjf14sJ+ExG56dx37VnxN9f/rG+nNrmCEG/xdABKZTXtRGK2lhm1wHYdcFvGRRkJSsmi4iI9JFeCcDd5YXUwsJCli9fTklJCSNHjiQUClFcXMzZZ58NQGtrK9FolLS0NM477zwmTpyI67r4fD7WrVvHgQMHuOyyy8jMzDzsOUzTjIdnVX5FRKQjsz0Enz86l19+ehq3/OFdXODLf12H0z7WN+q43HvVJLJT/DiuS31LhCfeKyPoN0n2WfzPK9v5+avFx/xwNWI7pCX5WPKvcxmUkaTxwiIiIn2g17tAH6krdFdr+XrbFxUVMXbsWBYtWsT06dMpKSnB7/czdepUAJYuXcr69ev55je/SU5ODjk5OfF9bN++nUgk0mkMcldBV5VfERE5lGlA1Ha5ZHw+3144kR8u3kx5XSsGBqGow7evmMD8SYMI2w4By+Rv75VRWt1MepKP2tZw+3sgR1wTybspYJn4LBNCNlFb70UiIiJ9pccB+NDAe+gY3I63dcWyLD7+8Y/z7rvvUlpayqBBg5g9ezZZWVlAbEbpzMzMeGDuuP/Ro0eTk5PTZcgWERE5GqdDJXbWiAEk+Uws06ShLcINM4bxtUvHErFd/KbJ3tpWfvPGDvyWSWaSnx9cNYmgr+vhPo7j4rMMXttSydPr9pGR5FfVV0REpA/1KAB7oXPPnj28/fbbNDc3k5uby9y5c+Pdkbdv384zzzzDnDlzOO+88444qzNAMBhkzpw5zJkz57DnGTVqFKNGjep0W8cZqEVERLrLNADD4Om1e/nOPz7Adl0M1yXaPrszgEvsvetHizezvz62tv2/XDKGW88rOq7nqGuN8tg7exR+RURE+li3A7AXZLdv387PfvYzqqqqcBwHn8/HqlWr+PKXv0xBQQEVFRUsX76cYcOGHTEAd+TN9OxVeTtWk13XPeKkWke7T0REpCsusfeQkoPN/M8r2/nHhn3YjkvAMkkOWISiPp5dv49/nTeG/Iwk/m9lKc9u2IcBzBo5gM+cU0g4Glvt4Ehva4ZhYNuxCnBLKBrvDm1qCiwREZE+0+Mu0C+++CJ1dXWcddZZFBUV8f7771NSUsLDDz/Md77zHYLBICkpKQQCgWPuq6vJqrqaZfpY94mIiByJNwHVwaYw1//2LfbWtOKzDFICPv77hikEfRa3P7qa6uYwG/bWkxZo5rv/2IjPNElJsvjpdVMIHKXrc0eWaXQeH6y3LBERkT7TrQDsVXHD4TC7d+8mPz+ff/3XfyUpKYlLLrmE//3f/2Xjxo28+OKLDBs2DMdxNAGViIj0G7ElkFxy0wJcfkYBP3+1mAWTB/GDqyZy5tAs6lsjDM5KZtuBBlbtrGJ7ZRNNoSipQR93XTAKv89iU3nD4cseubHKss80GJWXGs+6XuD2vkRERKRv9KgCbJomwWCQ+vp6amtrKSgoIC8vj9tuu43//M//ZPHixYwaNYpgMKgALCIi/Ups6K/B1+ePZVx+Gp89twjLNLAdl8xkPzMKs9m8r569ta18bd5Y3thayTcvH8/eulbO/c/XyErxYztuPNy6bmw8se26pAZ8vPb1C8jPSALAdtxOzysiIiJ9o1sDZ73ZmH0+H2PHjqW6upqf/OQnLFq0CMdxGDFiBLfccgtNTU1s3rwZn8+nMboiItKveMNn8tKC3DZ7RCz8xlcagKZQlKSAxfqyOqYMzeTFr8zlSxeNpr4lQtRxCEed9gDsxgOu7cQmz4rYDh0yb6d/myoBi4iI9JkezwJ97bXXUl1dzbp169i4cSM33HADrusye/ZsIpEIzz77LLt376a1tbW32iwiItJrXDfWHdo0DVwHfJbBI2+V8sqmA2Qm+6lribCvtpUpQ2OrGxhAxHaYNiybe6+ZhGFA1HFJ8pk8//5+fvLSVjKSzEOeo31yRwzMQ7tNi4iIyEnT7QDsfXKenZ3NN77xDXbs2EFLS0unmZsvvPBCpkyZwurVqykoKOj0OBERkf7AMMAyDKLta/a+u6uGHy7eTHIg9hYZtV2qmyMMz3Ex2ydeDNsuBZlJ8VDs2VTe0Km7s8erLGO0L7skIiIifaLHs0B7E2KNHj260+1eN+kBAwYwf/78TreLiIj0J1HHxWca7Khs4u7H1tAcipLkt7BMg9awTVVTG6aRFd8+VgV2cVwXl1jXZ59pxJdFOpRtu7Exx4ClIUEiIiJ9psfvwl6gdRwHx3EOu891XWzbPuy+vqDwLSIih/LC76byBj7zh3coq21hQGqAe6+eRFqSj7aoTWNr5LDHGUZsPG/Hr67eZmJV4Vj12NJbkYiISJ/pUQB2XffDcU1drMdrGAaWZWEYRp+HYNu2NRu1iIh04jMNXttayY2/f5vd1S0YwI8/Npnrpw8lFLFxXWiJHP7+5RIbO9zxq6u3mKgbe7zfND6cBVpBWERE5KTrURfojoH3WNXVrgLyyeB1066oqCAUCmlGahGRBOfl1NZQlP9duoNfLd2B7YDtOHxn4UQ+Nm0IlY0h/JZF1HZpDkUPe7zPNOIzOlvtZd2g3+RIGThqx271+wwMDQIWERHpMz0KwA0NDYTDYXJycqiqqiIpKYm0tDSgc9do0zTZt28fLS0tjBo16qQHUK8t+fn57N27N94mERFJXAZQ0xLh98tKaAnbpCf5+On10/j0rOG4LvgtA9OIVXnDducKsN80ONgYYuWOalxcHMcl4DPZXN6A/wgBN2y7uLgELFNdoEVERPpQtwKwFyCfeeYZ1q1bx09+8hN+9KMfMWvWLG666ab4uF/TNDFNE9d1Wb9+PYsWLeL//b//R35+frwqezJ5XbFFRCSxGcTG5Q7NTua7CyfywMvb+P3N05k9Ojc+JjjquNiui2UYJPut+GMjjkPAZ7J6dw2f/N2q9ls/fE8L+Ewihwz5iURsAII+vQ+JiIj0pR5VgG3bJhKJEIlECIfD8X8bhsGSJUtYsWIF99xzD4WFhVRUVJCRkcGAAQN6q+0nTON/RUTEY7VXaj9zTiELpxQwMD2I48QCL0Ak6uI6se2SOgTglICPJJ9FcsA6bMkjg9iSR0k+q9MQ37b22aGTA5ZmgRYREelDPQrAlmVh2zYPPvgg0WiU9957j9WrV3PmmWeSkpLC9u3b+fWvf81Xv/pViouLGTNmDH6/v0+qvyIiIkfit4xY+HVdTNPAcV0MDOpaw4RtG8sySA7EQqvjwr1XTeRfLxmDZXLE8b4ABgY5acH4z83h2Bji5IAVXwdY74IiIiInX48nwTIMg6KiIvbs2UNOTg7Nzc0cPHiQoqIicnNzqa2t5ec//zmVlZXMmzcPQAFYRET6FdclPqGVF2or6ttojdgkByzy0pPat3PJTg2QnRo47n1HbIeDjSFMwyAt4Is/h94FRURETr5u9cMyDAPbtmlqasLv93PjjTfi9/s566yzOP/88wmHw9i2TX5+Ptdeey1lZWVkZ2czc+bM+ONFRET6E9eNfTlObDmjbRWNNLZFSfZbDM6MBWDDaN+mfcmjjksg2Y57xJ8rG0Psq2vFMAzSk/3tz6UhOSIiIn3hhAOwV71dtGgRK1asICUlpdP6vl649babMmUKSUlJpKenk56e3mkbERGR/sAwPvzyWyaGAa9trcQ0DPLSggwbkBLbDgPDiFWLve/el2UaR/z5n+vLqW2OELAMxg2KvQ8q/4qIiPSNE+4C7QXbjIwM0tPTcRyHsrIyXNeltrYW13Xx+/2YpklzczOPPfYY4XCY8vJytm/fzrhx47QMkYiI9Cv76loBSPZb1LVE+Ou7e3hvVw2WYTBzxACS/VZsjHAXH+A2h6K0RR2CPjMWjoFQ1OHFD/bz81eLCfoMwMfs0TlALGiLiIjIyXfCAdhb1mjhwoVUVVXx9ttv8/vf/55oNMrKlSupra1l+vTp+Hw+9u3bR2trK7fffjuPPfYYa9asYdy4cR/FcYiIiJww70Pd+57bxPMb9zMgNUhr2Ka+NYLZXg3+9Kzh7Rtz2MBd23GxTIPfLyvhv1/ZTn56EMs08FsmzWGbyoY2LNOgpjnMFy4axRmDM3Fd9YQSERHpK90qw3acxMo0TS6//HJ8Ph8jRozg1ltv5dJLLyUajeK6LrfffjsXXHABhYWF7NixI/4YERGRvma3d0WeNSKHupYIVY0hWsM2GUk+xgxM41efPouZRQNik2SZXYfWcYPSaWiNsKuqma0HGllfVsfOykYwIOgz+eJFo/j+lZPiXZ8Vf0VERPpGj2aBdl0Xy7K4+OKLefrppxkzZgxXXnklAJWVlZx55plMnz4dgBEjRvDcc89RV1dHVlaWZoIWEZE+5635e930oRTlphK1XZL8JrnpQUblpRH0mbHCbxdvV95awheMzePPt8+iJRwlFHUIRR0MXAoykxk3KJ2x+ekn6YhERETkaHoUgE3TpKGhgT/84Q9EIhE2bNhAKBTCsixSUlK46KKL2LNnDwUFBYwdO5Y5c+bEQ6/Cr4iI9DXvrSgz2c/F4wcedv/Rxv12lBr0cc3UwV3e760trLc+ERGRvtWjABwIBPD5fLz99tskJSVRXV3Na6+9huM4uK6LaZrYtk12djZTpkzhggsuIDMzs7faLiIi0itcYssfeWIzQhvHFX4PfXzHCZ6N9n0d735ERETko9WtAOyN4b322mtZsGABpmniOE58fWDbtmlpaaGyspIDBw6wY8cO3njjDcLhMOPHj8eyrD6pAKvqLCJyOnDBccC0Tvyhjg2myaGjcA0+7M7cHT19vIiIiJwcPaoAJycnk5yc3OX9hYWF8X8fOHCA7OxsfD4fbh8tgGjbdp89t4iI9BYjFn5j0ykf/8Nct3uhWURERE4b3Z6O2XEcbNumrKyMX/7ylxQXF9PS0sI777xDbW0tNTU1vPbaa9TW1lJWVsZDDz3E9u3bAU56CPWer6KiglAopFmoRURORd57R0M5rHssFn6P9/3EC8vrHos9vuP+REREJGF0OwmapollWUQiEZYuXUpLSwutra08+OCDVFVVUVtby29/+1va2trw+Xy8//771NfX92bbj5vX9Tk/P59gMIjjOH3SDhER6SHXBdMHq34Fr3y/PQTbx3iMHdvule/HHmf6FH5FREQSVLe7QDc3N7N9+3befvttsrOzWb58OSkpKaSnp/Pqq69iGAaZmZk8//zzGIZBamoqltW3Xc/6auyxiIj0Aq/imzYQbnsB/u+K2O2X3tceco/wHuPd/sr3ofiV2OOSs0+8+7SIiIicFk44ANu2jWVZPP/88/z5z38mLy+PQCDA2rVrcRyHpKQk3n33XQCCwSArV66Mh86+Hn/b188vIiI9ZBjgOrEQe6wQ3GX4dcDQUBjpPu+via4+QjnW/dKZy9HP1bHu7+22cBKfT0ROvhMOwN742WnTplFYWEhycjL//d//zec//3kGDhzID3/4Q/7lX/4F0zT5+c9/zje/+U0Mw+D+++/H5+vRnFsiIiKx8Hq0EIwJOAq/0m2uCy5dr918rHCk8HRi+tP51O9O5PTXozHAbW1t1NbWYpomoVCIpqYmAMLhcHyyqXA4TGtrK5ZlUVNTg+u66oYsIiI9c2gILn6lfUywpcqvdJsL2I4bX7u5q3nWHNc96jBy13XV6+w4ua6Lc4xzdaz7u/W8Xdweijq0hm2izuFbuG7s+hCRU5vhnuArtNcF+h//+Ad//OMfycjIwLIskpKSsCwrvgZwNBqNPYFh4PP5iEQiJCcn8+CDD5KVldUnQTgajbJ69WpmzJiharSIyOnAC7WtdfB/C2D0JTD/R/Dyd2HHa3Dbi5CcpfArR+W6sZDlreVc0dDGfc9t5uPTh3LJ+IE47UPGDaC+JcLdj61hf30r/zpvLNdOG4LtuJhG7G+ePTUtfHXRehrbInz3yknMHZOL47qYCfDhv+O4XQZLANM0MPiwS3PUcfnK39bx/t46bjlvBHecPwKn/e9D72z9aPFmXtx0gIWTC/j2FROO2h36WH/Rer8C23E7rdvt7bOhLcoNv13FrqomvnDRaL5yyZjDthWRU98Jp0BvIqsFCxYwadIkduzYwY4dO9i0aRN1dXWkp6ezcOFCcnNziUaj+Hw+6uvrcV2XpKQkgsFgrx+EiIgkqHglOAtuXQxPfQ5+fxkkJcV+VviVLjiui+OC1V7ptQyD1ojNk6vL+O0bO9lY3sCrWyt48V/mUpSbgm27mKZB2HZYs7uW4somFk4eHNuPA5hg4FLfGuHdXTXUtobZX9f6YdXQ5LQPweZxBEWX2Lk3ANtx2FhWz8od1Zw9Iqe9sh77tMGrz3xQ3sBbO6spykmN3U8srB6pe/rxnt5Dw6+300jUYXd1M6U1LVQ2huLbeKF818Fmdh5s4tKJ+cf3RCLSL3W7DBoMBhkzZgyjRo2ira2NmTNnUlJSQllZGSkpKbS0tDBw4EBaWlp4++23WbBgARdffHH8BU3doEVEpFcYJjgRSMmBwVPhufvgqu/HfnYiYPr7uoXSD5mGgZeD9lS38MIH+3ly9V4+2FeP47qkB32cNzIXn2XEtrViGyf7LVICPtKCFqlBX6yrtPVh+EoOxO4P2w6pQR+GAX7r9P0AxgukEdth1c5qou1dyI+03dShWQxIDWC1bxD0WaQEY19p7ecy/uD276kBi5TAh+e6K7bjsr++7cgTvLvg4DIwIwnHcVm0uozH397NV+aN5copBURdF1/7ByEBn0nQZ+K3OoRkF0wDHlq+i5+/up2PnTWE33z6LDKS/Sd1gi4R6R3dDsCO42CaJnv27GHRokUMGjSIz372swSDQf7+97/jOA5z585l7969jB8/nqSkJFpaWkhOTu7N9ouISKJz7VjIffl7ULocvv0BPPvF2M/zf9j1EkmSsBzXZUdlE2/vrGZZcRVvl1RzoKGNaHuVd+zANL5x2Tiunz4UgLLaVtrCNj7LoKopRMRxMAyDysY2SqubSQv6AIP61jAllU3tVWGXnQebKKtpoTViY5kGw7JTCPhOszDcngCbQzZ3/mkNDW0RLKPzGFvTMAhFHf565zmcM2oAe6pbCPoswnZsvK1lGFQ0tLGrqhlwyUkLcrAxhIFBQ1sUn2FQ1djGjsomDCPW1To92c+gjKR44K1pDnPl/y6nqS2K3zIP6Yrt0hq2efiWmZw9YgA/XryZ8vo2DKOYeRMGdvqduO6HX97PPsvgYGOIlzbtJzloUd0UIui3Ytso/Yqcck44AHvBd9myZSxbtoyFCxfyH//xH/zlL3/hgQceYNy4cVx11VW89dZbXH311bz44ovs2rWLVatW8elPf5qLLroovg8REZEe6Tjh1Y5X4ZbnIDUXPv0UPHpV7C/jo60TLAkpHHX4wl/WsmpndXtYckkN+Jg1IpvPnDOcy88YRHZKAIhVFr/817WsKa0lJeDDdh2itsuA1AB/eWcPv35jJ3dfOJLUgJ8HXtrKgNQAEdshJeDjZ69u59dLd2A74PPBP794PmPz00/bMcF+08BnGvgtE7M9BLvtfYwjNqQn+fjzqt38+9MbGZSRRNRxidoO2akBXt50gCUfHKAgM4lvLRjPvz31Po4b6yadnRpg7Z46Fvx8OZZpUNcS4ZNnD+Xnn5wWG7ttGLhAa8SOfYVtHIjPNxPwGbRGHFpCNpnJfr526VjuXbyZ9WW1/PW9Mm47r6jLY3LaU+4/1u2jrLYFn2HwufNHEPSZsfHBp+HvUeR0d8IB2Ou6HA6H2bVrFz/96U+56KKLKCws5MCBA1RVVfHGG28QiUTYs2cP2dnZWJbFJZdcwuTJkzvtQ0REpNu6mu3ZicZC8LHWCZaE5LguSX6LL140mo176xmdn8bs0blcOjGfUblpNIej8fBb1RQiNy2I0T4+2DSMTpNlRR2XtvbA5bdMWiM2oagDxD57sR2XNsfGdiDAh12uT1emZdDYFuHLl4zhprMLsR2HnQeb+PoTG+ITiYWjDm0Rm7ZIbKZlb2Isx4HWqE3Eic2w3RaxO43RdondZplG7L4jzMbst0xCEYdbZxex4IxB2C7sr2vlR89vIWQ6WO3dmm85r4i/r93L+rJ6Hl5WwvVnDSU96ch/EvtMg+awzV/e3YPrwoi8VC6fVBA7Xv09K3JK6nYAnj9/PjNmzODtt9/m9ddfp7y8nNTUVO644w5eeuklli9fzs6dOwmHw6xbt46amhrq6upYuHBhfCItERGRbjnaUkem7+jrBCsEJzQvtFwzdTBj8tOZMCgdyzTYX9/GFT9fzsGmNpb928Vkp/q5/GfLmT06h69fOo5vXDoWv2VS1xLhq4vWs6+ulc/PHcl104cyICWA32dwyfh8ympb+PbTG2kORfna/HFcPH4goYhDkt+kKDe1UxtONwYQcVyGZiczoSAdiI2JhliQbWqLcsPMYZw5LItkv0XEdvjmU+/zQXkD108fyp1zR5Ac8DE0K5kn7joXw4D7n9/Cm9uruGhcHt+6YgIAUdth2ICU2HMeci7DtsOZwzK5ZEJsoqryulZ+/MKWWFfp9m1Sgz6+cNFovviXtRRXNvH8xv18auawIy5xZJoGj7+zm83lDQBcN30oGcm+07aKL5IIerQW0IABA7jiiiuYP38+ixcv5sCBA4wePZqxY8eSkZHB6NGj4y9Me/bsoby8XF2fRUSk5461zu+h6wR3DMGS8GKdWg0sA/7fS9v46qVjCfhMhmQls62ika89sR6/ZbCruonS6iZuOa+Is4ZnA9AStgn6TBzXZWRuKrNGDIjvtygnlV1VSbFJrww4Y3AmMwqz++go+4YBRKIfru3bGrFjtxuxcDwoI4lBGUnx7dPbw+TQAcnMGpETv/2ckbF/56UnYbuxCaw6nuuOz3foz60ROx5mm0LRwx7jOC4LJw/mlwU7WF9WxxOry/jkzGH4OpTovSxc3RTi/1bswgBG5KbyudlFR13qSUT6vx4FYG+hd5/Px7XXXtvpvrvvvjv+7+nTp/fkaXqNul6LiJzqXLAj8Op/wM6lRw6/niOFYCcK8/4DLD+avSYxeZW7zfsbWPiLFexvaCU16OPLF4/mwU9O5ZO/W8XKnVUk+WKTHH37igmcNTybcNTBNA0aWiNUN4dpbApR2xIh6rjtSyTF/s6ob41Q0xymtiVMXUs4dr/j4m+fTToRGMaHVe6Ox2wQGxMcsR0s0yBiO9Q2R2hsClPXEsF2YsHZ9AYQA3UtYZqaYufSdj5cBsk0Dl8GyWMaRryb+pHOedRxSfKbfHLGMNbuqeX1rZW8U1LNtOHZ2O3B3Vu15A8rSlm7p5a0oJ+75o4kJy2otYFFTnE9CsCGYWB0WKut4+1eOPb0h8qvbduHtVVERE4V7X/61u6Gg9uPHn49h4bgv98Ze3zumA/3JwnF+xtlVF4aF4zL47kN+/jZq9u5bNIg8jOCZKf6qW6yaA7bXH3mYL4ybyyO68ZnCh6QGuD280dQ2RjivFE5+NonfvIMzU7m83NH0hK2mTwk87D7E523LJRhgGVafGLGUKYNz2LumFws08Dy/p9s/7ZgcgG56UFmjcjpldDpurH/823H5dppQ/jz27uZMzaPYdkptIZtvFcSo32bSyYMZMPeYVQ1hrjx7OHxyvIRl1sSkVNCjwKw50iVVS8c9wfeLIAVFRWEQqF+EcZFROREtb+n5I6BzzwV+7frdh1+4w8zY9slZ3/4uI77k4RiAA4Q8Jv86Noz2FLewM6DTXztifW0hW02lTfgMw2uPnMwv/r0WfFZfqubw9Q0hfFZBnfOGYFhxCqYJQdjS/d4TMPgixeNxgBCUYedlU2xJZAGpKhq2M6bAMsw4CvzxmIaELXdI3ZX/uy5hXxudhFRJ3a/6364Vu+JcomFVu+xgzKTWPmtizu1yzQNXBeCfgvLNJhemM1f7pilj8tETiO9EoD7Oy+I5+fns3fvXi3DJCJyOjiREoxhqGQjcV632KHZySyYUsCvXt/Bxr31tEVj43tTAhb/fcOZpARiEzX5LZPfL9vJgy9vJzctSMT2Zno24qHIC0ixpX/c+PPYrkuyz2LxV86nKCc1oSdPirZXTx9esYv/enELeenBDt2aY7NkO64b/1/Vm3U73u3ZNKhtDnPreUXcd80ZOK6LcZyx1HEh2W+y82ATv31zJyl+Hw6xrsyRqIvPNOJLKKUFLZYXH+S+xS6h9lBsmUZ82aOWiM0nzhrGzBHZOC6n/ezeIqebhAjAHsuy+k1VWkREeuhEX8/1+i98+DnI61sr+e2bO9m4r56UgElzOEpBZjJtkSg1zWFe/GA/n55ViDdyKmq7tEVjy/d4Sx152cs0DKz2sBvrYuvGAhsGruHGx75KTFvEpq4lgt9nUt8S6fTZlFfdjS2X5MQ/VMCIrSNc3xKJT6x1IlzXJeA32by/gQde3EpqUgDbdTptY5oGualBUgI+1u+pY9n2gxgYuMRCuAlYlklTS5ixeenMHJEd+7BDry0ip5SECsAa/ysiIpLYHDdWxduwt44nV+9lQGqAjGQfN80azrcXTOD/vbyNXy/dwR9X7OLjZw2Nd5eNVQBhTH4a/75gIobx4bq233nmA3ZUNnLn3JFcdeZg2iI2ST6LFTsO8vPXdqjr8yEsMzZMLi3g43sLJ5LsN7Hb1/z954ZyXtl8gClDs7j9/BHxbOm48PtlJaxvqcPXjV58BrEPMYYPSOGCCfkk+y1cNzZBmdE+aVbUcdhZ2UzEdhiclcz0rGyi7esSm0as4m8ZBk2hCAVZScd8ThHpnxIqAIuIiEhi87of33beCN7cfpApQ7K4YeZQzhicyY7KJt4pqWFgehJb9jeyamc1F48fGH+s7bhkpgS4aHxep33+9KVttIZtxg9K5/zRufHbm0KRI64tK7EPIvw+g9vPH9Hp9pKqZv6+towRual85pzCTvc9vXZvvPv5iTJNg5aQzUXjsnjpX+diGuAzzXjAth2X6qYw8x58k13Vzdw6u4gfXDWp0wRmEduJV4S9DzX04YbIqUcBWERERBKGF3iyUvw88flz47M7v/TBAb759/fZXdNCWtBHKOrw6paKTgEYYkEparvx/YSjDrYb+7mtff3ZUNQh6DO71VU3kbgu1LREyEjyEXVi43DbIjamYRCOOrHqKx/OyBx13F6ZiMrXPqa3rLaFZ9eVM2tEDmcVZhH0mfHpzEwjNnv39opGnl67j6DP5KuXjm2/V6FX5FSmACwiIiIJKeAzqWwI8culxTz61m5qW8KcOzKHlKCPN7ZVsqK4ipaQTUrQigcjbzImLwKZHSbCMozYWr8dv+ToLDPWrdg1Yl2gvXNmtP8cn33Z6L3YGXViE5G99MEB/uWv6xiZl8br37iAnJRA+2hf4uH7sXf28MPnNscmTJtcwLj89Fg3elV+RU5ZmgpZREREEooL1LaE+cOKXVz765X85o2d1LdGmFk0gD/dfjZ3zhmJ60JFQxv76lpjj+nQk9lsH/9rGLEQ7U3U5DOND28zPpx8XLoWaF8T2G8Z8XMGH55f71z72u8/Xm6Hr0NZ7b+n1btrSU/2Mb4gnWHZKYQd58MPNtrnl75h+lDG5afTErb56zu7Y+3q0RGLSF9TBVhEREQSQrw7re1y8x/eYUVxNT7LIOgz+dhZg/nRtWcwMD3Ie6U1JAUsmsM22ysbGZOfhuO6BHwGxZVN3PXnNZhmbIeOC/vr28hKDvDkmr28376cUpLPYntFIz5LcelILAPaIg5ffnwtfp+J27481PqyOrJTgmza18A9j62J/84cYHd1CwHLPOaHCh1DqnWE1OxrX07pvdJaHBfOHZWD0b4WsVfP9+bZOmNIJueOzuGZtftYvHE/X75kDLlpwYRezkrkVKcALCIiIgnBG0tqWQZXnFHAG1sPcu6oPP513hgumzQIgF+/sZPfvLGT9CQflY1tFFc0wWRwnFi31/r2ynFHgzKSSAlavLurhlc2V8SXRMpI8pGZ4k/IKrB7yPdO97mx7uIR2+bPb+9uX883dnt2qp/0JD/l9W08vGJXvLpuAAVZyVimEe+m3JWo7RKxHVwgFD3yOOxlxVXsrWkhM9nPeaNyjrq/T80cxksfHGB3dQt/X7uPu+bGegioFCxyalIAFhERkYThjdm97fwR5KYHWTi5gNRg7M+hHz2/hV8t3QG47TP+Qn1rBGgPbFGXwVnJfH7uSGjfj+24/H3NXsrr25g/MZ+ZIwbQErZJ9lts2d/Akg8OkJRgf20dqwJrGLRX1C2+fPFogj4T23Hx+0ze3lnNhr31jMxN5bbZRfE1gqOOy4sb91PXEsboInk6jkta0MfDy3bx9zX7cF2XsB0LywHL7BRYX9l8gNaITVFuKtOHZ8faeoRxvY7rcuG4gZwxJJN3d9XwzNp93D67CJ+lUYQip6oEe0kWERGRROblsSSfxQ0zhgGwq6qZHz63mec37ifquMwZk0NDW5R3S0K0hKMAWCZEHYdhA1L4zsKJnfa5rLiKbQcauWJyAbecVxS//eXNB3ju/f0n5bj6C4PYzNit4Vjl1Tt/h3JcSPKZ/Nd1UzotNXTf4s28uf0g4wsGcf/HJnd6zNb9DeyobOpyLLAL+CyTXVXNvL+vPh7EAz6TtohDW3ubyutaWbGjCtMwmFGYTUayv8vjidouQZ/JVWcOZnVpDVsPNLC+rJ4ZRdmx3gSaDEvklKMALCIiIgnHqyouem8P//3SdvbVtWI7LpefMYjffPosvvbkBlbsqKYpFAtwBga4scccugyS074MUks4StRxCUcdAj6T5lA0oXrJRh2XjGQ/f1xRyhOr9wKxpaGi7efn0L7gLtAUisaXQbLaq+ze78ZxOy+DdCyWaRCK2iyYPIiZRQNoizjx31PUdhlfkAHA8xv3s6+2lSS/xSUT84+6T6N9B5dOzOcXrxVzsDHES5sPMKMo+0ROjYj0IwrAIiIiklBcYMkHB/j10h3tEyHFwtWnZg3ngU9MIcln0Ra2OXT+Kjf+n0Nu73Cbccj3hOKCzzTZX99KU2XsgwO/ZZKTFuj6Ie6HX51Omnd7x+2O/tS0RWyqGkNcMmEgt5434ojbRR2Xf6wvx3ZdRuemcOmEowdgM/a5B2Pz05g0OIM3th9k6dZK/r/LxuPXBGcip6SECsCGZusTERFJaLEJlwwee3s3L28+QFZKgNED0/j6pWO5bvpQACK2Q01LGNOAJL8FtIev9uV6Os7snBywsCwD13VJCfiwTIOUQOwxacGE+jML0zRoCUe5dGI+s0bm4LoulY0hnlqzF9txD/s7zAAykvxY5ofjbwPtM0L7LaNT92JvveCuBEyDmUUDGJmbSn5GMlHbxe6wXq/txLoyv7mtkvfL6jAwuGzSINLbq8++o3Rl9iZAu3BcHit2VLGrqpk1u2s5Z+QAdYMWOQUl1Cuzbdu4iTgVo4iIiMS4YJjw3YUTeX9vHR+bNpSvzhtDdmoA142FtNrmCKVVzZiGSXZKrHrpuA5+06C8ro0nV+/FyzxRx6W+JUJK0Md7u2rISPYTijoEfSZvl1Qn1FI5Zns38HkT8/nc7FgFdndNC79/s4SWsE2kQzdmw4CI4/LS5gOkBaxYCLUMdlQ2kRLwUV7fxtJtlfHzZzsu9a2R2CzQHSvu7ac3OzXA43ec02l8sK+9pOwSW3Yp6rj89KVt1DSHKchM4qazh8f2cZzHd8mEfH66ZBslB5tZ/H4554wc0K3zJCJ9KyECsPeGVlFRQSgUwjQ1c5+IiEgiMtuT64SCdF77+oUMTA8Csaqv40J1UxsPvLSdhtYoKUGLsflpQGzSJr9lUlbbwt2Prem0zyS/SWrQx5Nr9/K31WWx7ruA3zQI+I+9bu3pwMALowZNbVGidmwMb5LP5McfOwPbcZk8OCO+rWUYtEVs7nz0vUP2Y5CVEmBTeQOfefidTvcl+S38ltnlMkhH+6zBMAxwXT41cziO43LGkEzGDkrHdTnmhxRW/JrJ4I45I0gOWPFls1T9FTn1JEQA9rrc5Ofns3fvXhzHUQgWERFJYC4wMD2I47q8tbOa+1/YguO4lNW2UtcSJhx1GJSZxNwxeUBsbKthGCT7rcO6Njvtg4PTkz5coMc0DKK2Q0vEPq2rwN6hZST7+fPts6hriTAqLxWfFavU5mckcdcFozo9xjJj3ZvN9vMZX+y3nQuHdUl2Ozy2qyFt3jaH3uv97DMNbptdxC3nFRK12yfYMjqP4bZMA1972w7lMw3uu+aMLs6EiJwqEiIAeyzL0jhgERERwSAWXE3DYGx+OpvK6ymraSUr2U9q0MeI3FTu/9hkBmUmAbElkOoaQ5w9YkC8q+2h8zZ5bMclOWDx9Nq9fPEv68hO9Z/2VWDDgMlDMg+5zcDlwxmcXQf8PoNQxKGuOUxOWoC/3nUuGUEfdvt6v52Ku+3n2CQ22/btj75HycEmwlHnyG04jnZ6Y3YDvsO3dl2obQlT1xTucvkm1wXbdTGNY1eORaR/SqgArPG/IiIi4vGKjAPTg/zqpulsO9BIblqAwpxUZhRlkxb0xQPTmIHpXDqlgHNH5hx1VuOORuWlMXdsHulJFkn+WM+z0zkyOa4b71LsZUODD6u5dnu6nTg4gyvOHMzgzCTOGpZ13N2Ir502hOzUABMK0uP7PlGWaXRZKU7yW9w2u4iqpjCzR+fGtjlkI8MAn4KvyCnNcBMoFUajUVavXs2MGTPw+RIq+4uIiEgXuqrkOq57xCrfifzlpKx0dM4JnExVXEWkNygFioiISEIziHWN9daiNYiFra4Cl3JYz3T8wOFEQm1XH1T0piNVsUXk9KIALCIiIqcAN1Z6NboxiaXrtKfWrhPN8XTD7U4AOxmhrXs+2vN5NN09H94Q4Y/yfJqG0V9/YSLSSzQVsoiIiJwCjFhYc488AVKXXKc95PU81XRnD/03S/X9+eyO/ns+ReRUoQAsIiIi/Vj7GNHmKtj5+omFNi+s7Xw99viO+0tYOp8iktj6TQA+dC6uo83NdaRtE2guLxERkQTjQrQVFn8N3vldLIQ5R16mJs6JxrZ753exx0VbUVjz6HyKSOLqNwHYW583Eol0+vlo20ajUaLRKIbR9aLoIiIiciprf3/PHAY3Pw1v/SIWwkxf16HNicbuf+d3se1vfjr2+I77S1g6nyKS2Pp8EizXdTEMg8rKSpYsWUJ1dTXp6emcf/75jB8/Pn5/R7W1tbz00ktUVFTgOA5FRUVceumlpKWlHXF7EREROZUZse63A0bCrYvhkStjN8+668Nw5jk0rN26GLJHdBi7KjqfIpLI+vyVyzAMQqEQTz75JM3NzcybN4/8/Hyeeuopdu/ejWEYOM6HY1Oi0ShPPfUUVVVVXHLJJVxwwQVs2bKFJUuW9OFRiIiIyEfKMMG1Y+Hr1sVHrlx2GdZshbVD6XyKSILq0wqw4ziYpklxcTE1NTXcddddDBw4kMmTJ7N3717Wrl1LYWFhPASbpklZWRmlpaXccccdjBgxAoBQKMTSpUsJhUIEg8G+PCQRERH5qBhW59DWsXIZDYMv0EVYs/q23f2VzqeIJKB+8fHd/v37ycjIIC8vD8dxcF2XwsJCKioqADqN8c3IyGDhwoUMGjQoPvFVQ0MDfr8f0zz64ahrtIiIyCnu0ND21i9g1a9iYW3VrxTWTpTOp4gkmD6tAHuBtKmpidTUVAzDiI/hTUlJoa2tLf6zt21OTg7nnXceEKsgL1u2jJUrVzJ//nz8fv9hY4Adx8G2bQzDIBo9xgyHIiIi0v91DG2f/Sc8fQfsfg8ad8d+Vlg7MTqfIpJA+nwSLADLsg6rzkajUSzrwxdaL9h630tKSliyZAkNDQ0sXLiQWbNmdQq/3r/37dtHaWkpgUAA27ZxHEeVYBERkVOdYYEdhpxRMG4BPP5NuOknsZ/tMFiBvm7hqUXnU0QSRJ8GYC+kpqWlUVJS0um+xsZG0tLS4mG1Y/h95513WLJkCVOmTOHTn/40mZmZh1V+vX8PGTKEQYMGxSvA69ev15rBIiIipzonGgtlb/8aNv4d/u01WPLvEEiDc75w+GzGcnQ6nyKSIPp0DLAXUgsLC6mvr6ekpATTNAmFQhQXF8cnuWpra6OhoQHDMKivr+fNN9/ksssu42Mf+xiZmZmd9nUo0zTx+/34fD78fv/JOTARERH56HScnXjVr+BTf4FRF8e+r/rVsde1lc50PkUkgfT5GGDXdSkqKmLs2LEsWrSI6dOnU1JSgt/vZ+rUqQC8/vrrrF27lu9+97uUlJRQX1/Pli1b2LRpExCrJAeDQW644QaCwWCXawGr8isiInKK62ppHjsMOaOPva6tdKbzKSIJpl+8glmWxcc//nHeffddSktLGTRoELNnzyYrKwuAcePGkZGRAUBubi6XXnppPDxDLNj6fL5jzgItIiIip7CjrUtrBbpe0keh7ch0PkUkARluApVFo9Eoq1evZsaMGfh8euEWERE5ZbguGMax16X1fq7dFQtt5/1LLLR5j5cYnU8RSVD9KgU6joNpmvHKbscZnV3Xjd/XVWZXBVhEROQ05Dqx76t+HZuk6Wjr0h66ru0jV8Yqlufc0x7a9LeCzqeIJLJ+9arlBdiO6/56P3e8zzTNI36JiIjIacZ1YiGreidsfPLoYc1zaGjb+GTs8Yb5YfhLVDqfIpLg1AVaRERE+j8nAhixsadeiDsWbzsnCrhgajWIOJ1PEUlQSoEiIiLS/3lh63jDGnxYodSETYfT+RSRBKV+wyIiInKK6MaYU8OMPU6OQOdTRBKPArCIiIicIro767BmKz4ynU8RSTwKwCIiIiIiIpIQFIBFREREREQkISRUADa0YLuIiIiIiEjCSqgAbNs2CbTqk4iIiIiIiHSQEAHYC70VFRWEQiFMMyEOW0RERERERDpIiCTodX3Oz88nGAziOE4ft0hEREREREROtoQIwB7LsjQOWEREREREJEElVADW+F8REREREZHElVABWERERERERBKXArCIiIiIiIgkBAVgERERERERSQgKwCIiIiIiIpIQFIBFREREREQkISgAi4iIiIiISEJQABYREREREZGEoAAsIiIiIiIiCUEBWERERERERBKCArCIiIiIiIgkhIQKwIZh9HUTREREREREpI8kVAC2bRvXdfu6GSIiIiIiItIHEiIAe6G3oqKCUCiEaSbEYYuIiIiIiEgHCZEEva7P+fn5BINBHMfp4xaJiIiIiIjIyZYQAdhjWZbGAYuIiIiIiCSohArAGv8rIiIiIiKSuBIqAIuIiIiIiEjiUgAWERERERGRhKAALCIiIiIiIglBAVhEREREREQSggKwiIiIiIiIJAQFYBEREREREUkICsAiIiIiIiKSEBSARUREREREJCEoAIuIiIiIiEhCUAAWERERERGRhJBQAdgwjL5ugoiIiIiIiPSRhArAtm3jum5fN0NERERERET6QEIEYC/0VlRUEAqFMM2EOGwRERERERHpICGSoNf1OT8/n2AwiOM4fdwiEREREREROdkSIgB7LMvSOGAREREREZEElVABWON/RUREREREEldCBWARERERERFJXArAIiIiIiIikhAUgEVERERERCQhKACLiIiIiIhIQlAAFhERERERkYSgACwiIiIiIiIJQQFYREREREREEoICsIiIiIiIiCQEBWARERERERFJCArAIiIiIiIikhASKgAbhtHXTRAREREREZE+klAB2LZtXNft62aIiIiIiIhIH0iIAOyF3oqKCkKhEKaZEIctIiIiIiIiHSREEvS6Pufn5xMMBnEcp49bJCIiIiIiIidbQgRgj2VZGgcsIiIiIiKSoBIqAGv8r4iIiIiISOJKqAAsIiIiIiIiiUsBWERERERERBKCArCIiIiIiIgkBAVgERERERERSQgKwCIiIiIiIpIQTskAfOhszprdWURERERERI7llAzA3lq+kUik088iIiIiIiIiXfH1dQNOhOu6GIZBXV0dL730EuXl5aSkpDBz5kzOOuusvm6eiIiIiIiI9GOnVAAGcByHZ599lurqaubNm8fBgwf55z//SVJSEhMnToyHZBEREREREZGOTpkA7AXbsrIy9uzZw6c+9SnGjBkDQEVFBe+88w4TJ07s41aKiIiIiIhIf3XKjAH2Jrrav38/fr+f4cOH4zgOrutSWFhIdXU1tm0ftfrr3acKsYiIiIiISOI5ZSrAnra2Nvx+P36/H8MwMAyDpKQkbNsmEolgWVan7R3HiQfjaDQKxCbP6uuZo03TxHGchG9Df2lHf2gDxD6c6etrE/rH+egPbegv7egPbQBdn/2tDf2lHf2hDaDrs7+1ob+0oz+0AXR99rc29Jd29Ic2uK6L3+/v0zacbKdcADYMA9PsXLj2LpyOt3tdpvft20dpaSmBQADHcYhEIqxbt65Pq8Cu6xIKhQgGg33Wjv7Qhv7Sjv7QBo9t24d9iHOy9Yfz0R/a0F/a0R/a4NH12X/a0F/a0R/a4NH12X/a0F/a0R/a4NH12X/a0F/a0R/aALFrMzMzk4kTJx6WsU5Xp1wATklJIRwOEw6HCQQCGIZBc3MzSUlJnT698C6kIUOGMGjQoHgFeP369UydOhWfr+8O3XEcKioqyM/P77MLrT+0ob+0oz+0ASAajbJu3Tpdn/2kDf2lHf2hDaDrs7+1ob+0oz+0AXR99rc29Jd29Ic2gK7P/taG/tKO/tAGiF2fa9aswXEcBeD+xgu0hYWFhMNhNm/ezFlnnYXrumzevJmioqJ495KOn6KYphn/ZXpdpv1+f59/Cjds2LA+ff7+0gboH+3oD23wejfo+uw/bYD+0Y7+0AZdn/2vDdA/2tEf2qDrs/+1AfpHO/pDG3R99r82QP9oR39og5eNEskpFYBd1yUvL4+zzjqL559/ngMHDlBZWUl9fT0f+9jHAA4LwB05jkM4HMZxnD5/AeoPyzX1hzb0l3b0hzbo+ux/begv7egPbdD12f/a0F/a0R/aoOuz/7Whv7SjP7RB12f/a0N/aUd/aIPjOIRCoT5tw8l2ygRg+LAKvGDBAnJzcykuLiYtLY2bb76ZgoICgKOW7i3LYsSIEX3+4gP9Yybq/tAG6B/t6A9t0PXZ/9oA/aMd/aENuj77Xxugf7SjP7RB12f/awP0j3b0hzbo+ux/bYD+0Y7+0Abv+kyU7s8AhtsfpqTrBf3hExQRERERERHpv07ZqO/N/Oy67gmF39Mk78tpSten9Ge6PqU/0/Up/ZmuT+nPEu36PG0qwMfDC83eZFgifcH70AaOfS2eyLYivaE715z3mETqPiV9o7uvn3D0IVIivUHv73Kq6ngtJoKECsAife1IvRW66sGgbv1ysp3I9Slysun1U/ozvX7KqSoRr9OECcC2bbNp0yYaGxsZOnQohYWFfd0kSTDeC0xFRQU7duwgJSWFsWPHkpqa2uVjqqqqKCkpoa2tjcGDBzN69OiT2GJJJN25Pr3HVFdXs3XrVs4++2z8fn9CvpnKR6s712dLSwsffPABzc3N5OfnM2HCBF2X8pHozvV54MABdu7cieu6jBgxgiFDhpzEFovEeNfujh074pNhJcJ7+GkdgL1fYDgc5sknn6S0tJTc3Fyqq6s5++yzmTdvXkL8kqXvedfZli1bePrpp8nKysK2bQBuvPFG8vLy4tt433fu3MlTTz1FamoqwWCQ/fv3M2vWLC677LI+Pho53ZzI9dnxMRAbWvLnP/+Z0tJSvvGNb5CWlqbXVelV3Xn9rK+v589//jOhUIgBAwZQVlbGzJkzWbBgga5P6VXduT4/+OAD/vnPf5KTk4PjOFRVVbFw4ULOOussXZ9y0jU2NvLb3/6WyZMnc/nll+M4zmk/ZOS0PjrvD7SNGzdSXFzMzTffzF133cUVV1zBypUr2bNnT/wFSeSjZBgG0WiUl19+mdGjR/PFL36Ru+++G7/fzyuvvBLfruOb5JIlSxgyZAh33303d955JxdffDHvvvsuFRUV8W1FesPxXp8dedfqsmXL2L17Nzk5OSe51ZIounN9vvHGG0QiEe655x5uu+025s+fz/r162lqatL7vvSq7ry/L1u2jNGjR3PXXXdxzz33MHnyZJYvX47jOAq/8pHzXv9aW1t5/PHH+d3vfkdTUxPJycl93LKT57QOwN6LyLZt2xg1ahTDhw8H4MwzzyQtLY2dO3cCChLy0fKur/Lycpqampg1axYAgUCA6dOns2fPHkKhUKc3vXA4TCQSYerUqfh8seW6x4wZg2ma1NbWdtqvSE+cyPXpbetNeFVcXMy6deuYM2cO0WhU16T0uhO9Pr0wsmPHDubOnUtycjI1NTVMnz6dL3zhCwSDQSBxJnqRj1Z33t9d16WtrY20tLT4bcFgMD5Rq8jJYlkWY8aM4cILLyQjI4NoNNrXTTppfH3dgI+S94ZYW1vLyJEjO81wlpmZSWNjY/xnkY+K90dZTU0NlmWRlZUVvy8jIwOIdT/x/jCD2JvnF77wBSzLiu9jxYoV+Hw+Bg8eDGhGU+kdJ3p9ets3NzfzzDPPcMkllzBgwADee++9w2bdFempE7k+vW1ra2vjw0hWrVpFa2srycnJXHnllWRmZvbRkcjpqDuvn6Zpcumll7J48WKqq6sJBALs3LmTq666CtM01QVaPnLe9RUIBJg5cyYA77zzTkJ9CJMQf0FHo1ECgUA8ELuui8/nS6hPOqTveWOCOgZdL8RGIpFO2xqGQSAQwLIsdu/ezcMPP8z27du56qqryMjIUMiQXnci16frujz//POMGjWK6dOnx7vtpaWl6Q83+UicyPUZCoUIh8McOHCASy65hJtuuonMzEwWLVpEQ0PDyWu0JIwTuT4B6urqMAwDn88XH29ZWVmp93Y56RzHwXGchLv2TvsA7AWJSCQS/1TNMIz4J8KgrqRycngfwoTD4fgHMeFwGICUlJT4bd5XNBrlxRdf5JFHHiEtLY3bb7+diRMn6tNh+Ugcz/Vp2zaGYbB161Y2btxISkoKy5cvZ8OGDRiGwSuvvEJ5ebnGWEqvO57r06teBINBotEos2fPZsKECQwZMoQFCxbgOA7l5eUACVXpkI/eibx+VlZW8vrrrzN37lxuvPFGbrzxRi6++GJWrFjBgQMH9PopJ5VpmgnZo/C07gLtBYXc3Nz4H2UQ+3S4oaGB3NzcPm6hJALvusvJySEajVJZWRnvhnfw4EGSk5NJT0+Pfzjjee2119i4cSM333wzI0eOPGx/Ir3hRK5Pbzx6IBBg4sSJ1NTUUF1dTWtrK4ZhsHv3bgoLCxk8eLA+qJFe0Z3rMzMzE5/P1+n68/7AS8Q/9OSj053rs7GxEb/fT1FRUXw/I0eOJBAI0NzcDCTmuqwiJ9NpHYA9kydP5q9//SvvvvsuEydO5PXXXwdg7NixgAKFfLS866ugoID8/HxeffVVBgwYQEtLC2+//TYzZszANE3279/P+vXrOe+880hLS2PDhg2MHz8en8/H1q1b4/sZOnQoqampeoOUXnEi1+eGDRuYNWsWo0aNYtSoUfF9FBcX8/TTT3PzzTeTnJwcH+cm0lMn+vo5a9YsBgwYwJgxY3jjjTcYMmQI6enpvPbaayQlJcUnw9T1Kb2hO+/vQ4YMwefz8cYbb3DllVdiWRbLli3D7/dTUFAA6PqUky/RukGf1gHY60Yyfvx4LrjgAl5//XWWL1+ObdtcccUVZGZmKkTISeFdZ9dccw1PPvkkf/zjH4lGoxQWFjJ79mwAampqeO+995g6dSrhcBi/309JSQnFxcVA7Hq2bZuPf/zjncKHSE+dyPU5adIksrOz4938vD/UkpOT4+PgRHrT8V6fq1evZtKkSQwYMIBLL72UZ599lkcffRSfz4fP5+NjH/sYSUlJet+XXnUi1+fEiRMpLCzk6quv5sUXX+Shhx6KT3x11VVX6cNt6TPJyckEAoG+bsZJY7gJFPfr6+upqqoiPz+ftLQ0vchIn3Ach3379mEYBkOHDo3f7o379SbFiEajR7w+fT6fPh2Wj8zxXJ+HXpfe9er3+/WaKh+pE70+Dxw4QDgcZvDgwfEuqCIflRO5PsPhMPv378dxHAoKCvThjPSpcDiMZVnx1UdOdwkVgDvSi4z0hSNdd7oWpb/Q9Sn92Ylcn7qW5WTT9Sly6kioANzxUPUiI32p45rUIv2Nrk/pz07k+tS1LCfb8V5zh/75rWtU5ORJqAAsIiIiIiIiiUsDCUVERERERCQhKACLiIiIiIhIQlAAFhERERERkYSgACwiIifFoVNOeGsJH/rv4+E4zglt3xdO9Ji8x/TWvj4qh7blRH+Pp8IxiojI6UuTYImISL/lhaKOM6R2/PehQcwwjH43m6rXriMtc+IFecMwDlvf23Gcj3zN7xNZesX7XZxom/r6GEVERDrSu46IiHzkQqEQ+/btIxqNxkNrU1MT9fX1RKNRamtrqampOawK6IUmL9gahkEkEmHr1q3U1dV1ut3b7lgcx8G27Y+02hiNRjl48CDNzc3xNnkhuCPTNLEsC9M0cRyHuro6otFo/D6IBc+6ujr27t2L4zhdPmdXFdSjVWy9th1PRd07x83NzbS0tOA4DqFQiLKyMhoaGnAch5qaGvbu3dvp/PbmMYqIiPSUr68bICIipy/btrEsiw0bNvDzn/+cL37xi5x77rm4rsvixYtZvnw53/72t/nZz37G8OHD+fKXv9zp8bW1tRw8eBCfz4fjOBiGwbZt23j88ceZO3cu8+bNIxKJxO/PzMxk4MCBXbbnRCuYJ7qOrFfprKys5Dvf+Q7XX38906dP5+GHH+b6669n/Pjx8apnOBzm3XffpaqqioaGBsrKyti0aRO33XYbl156KcXFxYwYMQKfz8ff//533n33XR588EFSU1OPWLntqo2HVsy9n6PRKNFoFL/fj2VZh91/qJaWFtatW8eiRYsYMmQI3/zmN6mvr+e73/0un/3sZ7nkkktYsmQJS5cu5Xe/+x2GYRAKhXjvvfd67RhFRER6SgFYREQ+Ml7YfPPNN0lJSWHcuHHxULNlyxbS09MZMmQIo0ePZs2aNTQ2NpKenh4PzsuXL2fRokUEg0EikQgZGRnxAPnmm2/y1ltvkZ6eTigUoqqqigULFnDnnXd2GZ4Mw2DNmjUUFxdzySWXkJeXd9SgdTwBzHXdeDj3vkejUdra2uJtLSkp4de//jXf/va3ycvLA2JV17/97W9UVVXh9/tJTU1l1qxZDBw4kPXr13P//fczZ84c7rzzTkzTJBKJdNmG5557juLiYiZMmMCCBQvixxQKhfjrX/9KXV0dF154IVOnTmXPnj0sWbKE0tJSmpqayM7OZvz48SxYsICsrKxO58P7AOCxxx5j2bJltLW1MXjwYC6++GKWL1/OmjVrsCyLdevWYVkWH3zwAaZp8pvf/IaZM2cydepU/vrXv1JdXd3jYxQREekNCsAiIvKR8MLfnj17WLduHZ/97GfZuHEj69atY+HChVRXV+O6Lvfeey/Nzc04jsOPf/xjgsEgN998M6NHj8a2bQA++9nPkp2dzeLFi8nMzGTOnDkA1NfX8/zzz3P++eczduxYBgwYAHQdXHfv3s3//d//cfDgQaZMmXLMAFxeXk44HKaoqKjL4zQMI15B9QJ/JBLBNE1ycnIYOHAg3/ve97j33ntZsWIF119/Pa7rkpSUxH333YdlWfzsZz/DMAy+8pWvALHK91VXXcUzzzxDW1sb6enp+HyHv2V75zgUCrF8+XLKysq44IILSElJAWDnzp289tprAHz84x+nqqqKBx98kP3795Oenk5SUhK7d+9m+/bt7Nq1i6985Svxx8KHFfP8/HzGjx+PaZqMHDkSwzB4/fXXKS8vxzAMDhw4wPr166moqCAQCLB69WoGDhzI2WefzX333YfP5+v2MYqIiPQmvdOIiMhHwquEvvDCC+Tl5TFkyBB+/etfM3jwYDZu3Eh9fT15eXmkpKTQ2NiIaZpkZGTEx4t23E9lZSUtLS0cOHCAlpYW9u7dC0BDQwOVlZWUl5eTlpaGYRgUFhbGH+sFxHXr1vHss8+yf/9+HMdhwIAB8dB6KC8QNzY28pOf/ISmpia+973vUVRUdFh11DAMSktL2bp1K4FAoFPF1+/3s2PHDlpaWrAsiwkTJhAOh1mxYgXnnXce4XCYbdu2EY1GaWpqwjAMXnrpJQoLCxk/fjw333wz2dnZmKZJRUXFUcfGnnvuubz++us0NjZSUlLCGWecAcC2bduIRCJMnTqV4cOH88wzz7Bv3z5mzZrF9ddfT05ODlu3buWRRx5h1apVTJ8+ncsuuyxegffk5uaSmZnJgAEDePrpp2ltbeW73/0uRUVFfPWrX+XKK6/kwgsvZNGiRSxbtoyHHnoIn89Ha2sr27dv75VjFBER6Q0KwCIi0uu8cFhWVsabb75Jamoqv/nNb3Bdl+uvv56nnnqKSCTCuHHjuOuuu3jqqadYvHgxX/rSl8jIyIhXfk3TxHVdXnnllfh41aqqKp599tn4cwWDQbZs2cKqVau47LLLmDp1aqeZlwHa2toIhUIUFRVRVlZGJBI55qRPfr+fnJwc/H5/p6qox3EcLMti/fr1PProo2RlZWHbdrwinJSUxNKlS+MTQqWkpLB582ZSUlI499xzaW5u5ve//z3RaJTk5GQsy+Khhx7i8ssvZ9u2bWzevJkvfelLpKen8/DDDx+xjd4HBQUFBRQWFrJmzRq2bdvGGWecgW3bbNu2Ddd1mTx5MhCrmBuGwYABA+JV7ZkzZ2LbNps2bYp3zz50nLRhGKxcuZK8vDx8Ph+33noro0eP5q233mLatGnU1NSwcuVKACZOnMjy5cuZNm0aruv2+BhFRER6kwKwiIj0Oq9Kmp+fz0033cSuXbtYuXIl8+fPp7GxkV27dpGens6WLVv40Y9+RG1tLcFgkP/6r/9ixIgR3HbbbQDxMbXf+c53GDRoEN/+9rfJycnhpptuine9/eUvf8knPvEJFixYEK8ges/vVTHPPfdczj33XNra2vjmN79JKBQ6ZtuTkpL41re+RTQajQfgjl2lvZB44YUXMnny5PhztbS08NBDD1FbW0tGRgZ33XUXqamp8WPxKtxpaWn84Ac/YMuWLTzxxBOkpqbyve99jyFDhvDyyy+zdu1a7rvvPr70pS/h8/niY40PDe5e1Xny5MmsXbuWrVu3AlBVVcXu3bvJysqKB+ChQ4diWRZvv/02+/btY/z48QwfPpxJkyZxzjnnHHYOvO+lpaVEIhGam5uxLItZs2bFu5NnZmayfv16IpEIgUAAv9/PW2+9xTe+8Q2mTZvG97//fbZu3dqjYxQREektWgZJREQ+El7V8/LLL6eqqorp06cTiUR47rnnuPjii0lOTgYgIyMj3n04JSWlU7U1EolgWRbZ2dkkJSWRlpbGnj17+MUvfsHPfvYznnjiCUzTJDU1lUAgQDAY7LIt3REIBEhJSTni471wmJWVxahRoygqKqKoqIjW1lZqa2sZMmQITU1N1NXVUVRUxMiRIxkxYgTDhw/HMAz8fj9FRUXs3LkT13VpaGjghRdeAOCmm27i7rvvZu/evezatQu/3w9Aampql7M/T5kyhaysLHbv3k1DQwM7d+6kurqa0aNHM2zYMFzXZfbs2cydOxfbttm8eTN/+9vf+NWvfsW///u/84c//IH6+vojnq/CwkLmz5/P2LFjqaurY+XKlfh8Pvx+P7fccgv33HMPlmXx+c9/ns9+9rP4/f549X7EiBE9PkYREZHeogqwiIj0Oi9A1dTU8OCDD7J161aKiorYs2cPtm3z5S9/mffee4/Ro0fzpS99iSeffJLnn3+eL33pS/GuxBBbP9jn89HU1ERjYyMXXnghra2tnQKS4zhkZ2fT2NhIWlpary+fc6z9eevquq5LNBrln//8J0lJSdx555388pe/5O9//ztTpkwhNTUV6FxdXbp0KatXryYpKYmsrCz27t3L/fffzwMPPMAll1zCuHHjGDp0aLx78MqVK5k2bVqnZYK8rt5Dhgxh1KhRrF69mk2bNlFaWko0GuXMM8+Mz1CdnJzMPffcQ3l5Oe+//z5lZWXs2LGDgwcP8tJLL+Hz+bjlllvix+btOxgMUl5eTmlpKYMGDWL9+vUMGzYM0zTJzc2N73/AgAFEo9F4FdcwDF577bUeH6OIiEhvUQAWEZGPRMf1ZmfOnMmIESMwTZPNmzfT2NhIUlISGzdu5N/+7d9obW0lGAzy/e9/n7y8PL75zW9iWRY1NTXk5eWxfv16Hn/8cXJzc/H7/di2jW3bBAIBDMPg4MGD3HTTTcyfP/+wCZxOlBe6wuEwDz30EI2Njdx9992HLRHU8Ti98cBLlizhgw8+4Nprr6WoqIiLLrqIP/7xjyxatIg77rgDx3Hi227evJk//OEPzJo1i7q6Onw+HzfffDMrVqzgrbfeory8nIaGBnbt2kV1dTU+ny9erT3zzDPjXaq9NpumyZQpU1izZg1vvfUWlZWV5ObmMmXKlHg7161bx4EDB5g2bRqXX345AK2trfzjH//gxRdfjE+a5ff7O1WBX3zxRUpLS7n88st57733qKmpoaWlhUAgwI9//GMgNhb7xz/+MaZp4vP5CAaDlJSU8Ic//IFzzz23x8coIiLSGxSARUSk13mhZcCAASxcuJCsrCza2tpobW1lx44d5OfnE41GSUtLY9KkSZSUlLB//35GjRrFwIEDsSwL13U5cOAAWVlZnH322SQnJ/PUU0/R3NzMJz7xCQYNGsTSpUtZtWoVQ4YMYdKkSfEgeKy2HU+oam1tZcOGDTQ2NlJVVUVWVtYRt/MC7Zo1a3jyyScZOXIk11xzDY7jMG/ePN5//31effVVBg4cyNVXXx2vjnpLBl133XU8+uijNDc3M2nSJLKzs/nWt74V7xI+dOhQ0tPT40G8sLDwsCDu/Xvy5MkMGDCA7du309bWxuTJk8nPz49vv3z5cl555RXmzJnDF77wBdLS0khOTiYlJYVoNEogEIifP6/6axgGt956K+vXr+f111+ntLSUgoICamtrAZg7d25833PnzsV1Xd544w38fj+VlZW9dowiIiK9QQFYREQ+MpFIhL/97W9Mnz6djRs3MnXqVHbv3s369esBGDlyJLfeeivPPPMMZWVl3HHHHfGuwrW1tezfv5+JEyeSl5fHxRdfzKRJk3jggQdYsWIFgwcPZsuWLcyYMYPPf/7zZGZmHlebvOpxV+OCvdCVmZnJV77yFVpaWhg9enSn+zoyTZO1a9fyu9/9DsMwuPnmm8nIyMBxHILBILfeeisPPPAAf/3rXwmFQnz84x/HNE2mTZtGeno6gwcPpq2tLR76c3Nz+frXv05ubi4DBgwgOTmZP/7xj7z11lvMnTs3Prb20ADsui6DBw+msLCQrVu34jhOvPtzNBrF5/NxwQUXsG7dOjZt2sR//ud/MmTIEGpraykpKcFxHM4777x4Ozp2r3755Zd57rnnGDNmDFdccQVvv/02oVAIx3G46qqrME2TpUuXcvXVVxOJRHj99dcJhUKceeaZfPGLX+yVYxQREekNCsAiItLrvPBSXV1NW1sbo0ePprS0FMMwGDVqFPv37yc1NZXNmzdz3333UVVVhW3b/Nd//RfhcJhbbrkl3s125MiRNDU1UVpaSllZGZZlsW3bNnbt2oXruqSmplJcXMzQoUPJysoiGAweNTh5k1r5fMd+C5w0adJRjy8UCvHCCy/wz3/+E9d1ufvuu5kyZUp8ZmbXdSkoKOCrX/0qv/jFL3jyyScpLi7mhhtuYPTo0cyYMQPXdTuFzkAgwJlnntnp+bzZo5ubm0lLS+uyTaZpMnPmTHbu3EleXh5Tp04FiO//zDPP5O6772bx4sUcOHCAsrIyfD4f2dnZXHfddVx66aWdgqfXBTk1NZXJkydz4403smzZMtra2khLS8Pv9/PII4/Eq9oPP/wwlmURDAaxbZvk5GRmzpzZa8coIiLSUwrAIiLS67ygU1FRgeM4DBs2jFGjRpGVlcUnP/lJbNvmlVdewTAMgsEgw4cPZ8SIEUQiEVpbW/H7/dTV1TFkyBAcx+HLX/5yfImjoqIibr/9dgYPHsyGDRt46623eOedd4hEIkyaNIlvfetbh40B7ri00b333gvEZniGw9e87ch7zq62aW1t5bXXXiM1NZU77riDqVOnxsOv97yO4zB06FD+7d/+jccff5yVK1cyZ84cRo8eHd+2qanpsOf1qq+madLS0kJdXV2nquyhvOe8+OKLOe+88zBNMz4rdsexwrNmzWL69OlUVVXFx2Ln5ubGZ+U+dJ+u63LNNdcwc+ZMfvjDH1JTU8PcuXPJzc2luroay7LIyMhg5MiRNDQ0xCcsi0aj8WPprWMUERHpKcPVO4yIiHxE2tra2LFjB2PGjIkvjQOx8PPyyy+Tn5/PtGnTjvjYSCRCWVkZBQUFvPDCCwwZMoRx48aRlZXVqcLb2trK3r17+eCDDxg6dGi84vhRd5/1nqO4uJiUlJR4WD9SWPa2dRyHrVu3MnHixE73L1u2DNM0Of/884/4uLVr17J3714WLFgQn6Cqu8fXVRu7ut1j2zarVq0iKSmJqVOnUl1dzdKlS7n44osZOHBgfPKs8vJy3njjDS688EIGDx4cb+vJPEYREZGuKACLiMhJ1RvBxqvMwtEruF09Pxx5PG9P23S0tpzMQHc8x+gt3dRxWSYREZHTnQKwiIh8pLoKhrZtYxjGcYVGL/AeaQbnjuvwmqZ50oOc15X3eJ/3SOfjWF2tvTG2PVneqTd0bGfHAN3x2Lu6/VQ5RhEROb0pAIuIiIiIiEhCOLF+YyIiIiIiIiKnKAVgERERERERSQgKwCIiIiIiIpIQFIBFREREREQkISgAi4iIiIiISEJQABYREREREZGEoAAsIiIiIiIiCUEBWERERERERBKCArCIiIiIiIgkBAVgERERERERSQgKwCIiIiIiIpIQFIBFREREREQkISgAi4iIiIiISEJQABYREREREZGEoAAsIiIiIiIiCUEBWERERERERBLC/w82lNUt3HSwbwAAAABJRU5ErkJggg==
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;在這個 2 維空間裡頭，我們可以發現一個好的轉換有 2 個特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;距離有意義：「喵咪」與意思相近的詞彙「貓」距離接近，而與較不相關的「狗」距離較遠&lt;/li&gt;
&lt;li&gt;維度有意義：看看（狗, 貓）與（野狼, 老虎）這兩對組合，可以發現我們能將維度 1 解釋為貓科 VS 犬科；維度 2 解釋為寵物與野生動物&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/dog-and-cat.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們能把語料庫（Corpus）裏頭的每個詞彙都表示成一個像是這樣有意義的詞向量，神經網路就能幫我們找到潛藏在大量詞彙中的語義關係，並進一步改善 NLP 任務的精準度。&lt;/p&gt;
&lt;p&gt;好消息是，大部分的情況我們並不需要自己手動設定每個詞彙的詞向量。我們可以隨機初始化所有詞向量（如前述的隨機轉換），並利用平常訓練神經網路的&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"&gt;反向傳播算法（Backpropagation）&lt;/a&gt;，讓神經網路自動學到一組適合當前 NLP 任務的詞向量（如上張圖的理想狀態）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/backpropagation-example.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        反向傳播讓神經網路可以在訓練過程中修正參數，持續減少預測錯誤的可能性
                        （&lt;a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 NLP 裏頭，這種將一個詞彙或句子轉換成一個實數詞向量（Vectors of real numbers）的技術被稱之為&lt;a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B5%8C%E5%85%A5"&gt;詞嵌入（Word Embedding）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;而在 Keras 裡頭，我們可以使用 &lt;code&gt;Embedding&lt;/code&gt; 層來幫我們做到這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;MAX_NUM_WORDS&lt;/code&gt; 是我們的字典大小（10,000 個詞彙）、&lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 則是詞向量的維度。常見的詞向量維度有 128、256 或甚至 1,024。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Embedding&lt;/code&gt; 層一次接收 k 個長度任意的數字序列，並輸出 k 個長度相同的序列。輸出的序列中，每個元素不再是數字，而是一個 &lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 維的詞向量。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假如我們將第一筆（也就是 k = 1）假新聞標題 A 丟入 &lt;code&gt;Embedding&lt;/code&gt; 層，並設定 &lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 為 3 的話，原來的標題 A：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題:
[
	0,
	0,
	0,
	185,
	300,
	72,
	4029,
	37,
	1,
	121,
	250,
	95,
	30,
	511,
	92,
	2358,
	33,
	2565,
	19,
	55,

]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就會被轉換成類似以下的形式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題:
[
	[0.212, 0.111, 0.666], 
	[0.212, 0.111, 0.666], 
	[0.212, 0.111, 0.666], 
	[0.528, 0.344, 0.452], 
	[0.163, 0.93, 0.58], 
	[0.527, 0.262, 0.246], 
	[0.077, 0.695, 0.776], 
	[0.624, 0.962, 0.96], 
	[0.456, 0.927, 0.404], 
	[0.353, 0.119, 0.108], 
	[0.805, 0.969, 0.725], 
	[0.379, 0.265, 0.473], 
	[0.436, 0.186, 0.738], 
	[0.923, 0.287, 0.967], 
	[0.477, 0.614, 0.838], 
	[0.089, 0.328, 0.993], 
	[0.887, 0.913, 0.885], 
	[0.604, 0.118, 0.646], 
	[0.907, 0.52, 0.437], 
	[0.443, 0.432, 0.498], 
]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;序列裡頭的每個數字（即詞彙）都被轉換成一個 3 維的詞向量，而相同數字則當然都會對應到同一個詞向量（如前 3 個 &lt;code&gt;0&lt;/code&gt; 所對應到的詞向量）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-process-vectors.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Keras 的 Embedding Layer 讓我們可以輕鬆地將詞彙轉換成適合神經網路的詞向量
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這樣的轉換，我們就能將轉換後的詞向量丟入 RNN / LSTM 裏頭，讓模型逐步修正隨機初始化的詞向量，使得詞向量裡頭的值越來越有意義。&lt;/p&gt;
&lt;p&gt;有了兩個新聞標題的詞向量，接著讓我們瞧瞧能夠處理這些數據的神經網路架構吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一個神經網路，兩個新聞標題"&gt;一個神經網路，兩個新聞標題&lt;a class="anchor-link" href="#一個神經網路，兩個新聞標題"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說，多數你見過的神經網路只會接受一個資料來源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入一張圖片，判斷是狗還是貓&lt;/li&gt;
&lt;li&gt;輸入一個音訊，將其轉成文字&lt;/li&gt;
&lt;li&gt;輸入一篇新聞，判斷是娛樂還是運動新聞&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-data-source-nn.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;單一輸入的神經網路架構可以解決大部分的深度學習問題。但在這個 Kaggle 競賽裡頭，我們想要的是一個能夠讀入成對新聞標題，並判斷兩者之間關係的神經網路架構：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不相關（unrelated）&lt;/li&gt;
&lt;li&gt;新聞 B 同意 A（agreed）&lt;/li&gt;
&lt;li&gt;新聞 B 不同意 A（disagreed）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要怎麼做到這件事情呢？&lt;/p&gt;
&lt;p&gt;我們可以使用&lt;a href="https://www.coursera.org/lecture/convolutional-neural-networks/siamese-network-bjhmj"&gt;孿生神經網路（Siamese Network）&lt;/a&gt;架構：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用孿生神經網路架構來處理同類型的 2 個新聞標題
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖是本文最重要的一張圖，但現在你只需關注紅框的部分即可。剩餘細節我會在後面的&lt;a href="#定義神經網路的架構"&gt;定義神經網路的架構&lt;/a&gt;小節詳述。&lt;/p&gt;
&lt;p&gt;重複觀察幾次，我相信你就會知道何謂孿生神經網路架構：一部份的神經網路（紅框部分）被重複用來處理多個不同的資料來源（在本篇中為 2 篇不同的新聞標題）。&lt;/p&gt;
&lt;p&gt;而會想這樣做，是因為不管標題內容是新聞 A 還是新聞 B，其標題本身的語法 &amp;amp; 語義結構大同小異。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        神經網路說到底，就跟其他機器學習方法相同，都是對輸入進行一連串有意義的數據轉換步驟。神經網路將輸入的數據轉換成更適合解決當前任務的數據格式，並利用轉換後的數據進行預測。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以這樣的觀點來看的話，我們並不需要兩個不同的 LSTM 來分別將新聞 A 以及新聞 B 的詞向量做有意義的轉換，而是只需要讓標題 A 與標題 B 共享一個 LSTM 即可。畢竟，標題 A 跟標題 B 的數據結構很像。&lt;/p&gt;
&lt;p&gt;如果我們只寫一個 Python 函式就能處理 2 個相同格式的輸入的話，為何要寫 2 個函式呢？&lt;/p&gt;
&lt;p&gt;孿生神經網路也是相同的概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-cats.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Siamese 事實上代表暹羅貓。就像是這邊的暹羅貓雙胞胎一樣，你可以想像孿生神經網路架構裡頭也有 2 個一模一樣的神經網路雙胞胎
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好了，在了解如何同時讀入 2 個資料來源後，就讓我們實際用 Keras 動手將此模型建出來吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="深度學習-3-步驟"&gt;深度學習 3 步驟&lt;a class="anchor-link" href="#深度學習-3-步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;深度學習以及 NLP 領域的學問博大精深，但一般來說，當你想要實際動手寫出一個神經網路的時候，有 3 個基本步驟可以 follow：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deep-learning-three-steps-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        用深度學習框架 Keras 來實作深度學習的基本 3 步驟
                        （&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017_2/Lecture/keras.pdf" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;定義神經網路的架構&lt;/li&gt;
&lt;li&gt;決定如何衡量模型的表現&lt;/li&gt;
&lt;li&gt;訓練模型並挑選最好的結果&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;接下來你會看到，大約 80 % 的程式碼會花在實作第一個步驟。剩餘 2 個步驟在使用 Keras 的情況下非常容易就能實現；但後面我們也會談到，你將花 80 % 的時間在最後一個步驟上面。&lt;/p&gt;
&lt;p&gt;首先，先讓我們進入第一步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="定義神經網路的架構"&gt;定義神經網路的架構&lt;a class="anchor-link" href="#定義神經網路的架構"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實作之前，先讓我們回顧一下前面段落看到的模型架構：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文用來實現假新聞分類的神經網路架構
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從左到右掃過一遍，你可以很清楚地發現我們需要以下 5 個元素來完成這個模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;兩個新聞標題（兩個長度為 20 的數字序列）&lt;/li&gt;
&lt;li&gt;一個詞嵌入層：將數字序列轉換為詞向量序列&lt;/li&gt;
&lt;li&gt;一個 LSTM 層：讀入前層的詞向量並萃取標題語義&lt;/li&gt;
&lt;li&gt;一個串接層：將兩個新聞標題的處理結果（也是向量）串接成一個向量&lt;/li&gt;
&lt;li&gt;一個全連接層：將前層的向量轉換為 3 個分類的預測機率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有些層我們已經在前面章節看過 Keras 的實現，比方說&lt;a href="#詞向量：將詞彙表達成有意義的向量"&gt;詞嵌入層&lt;/a&gt;以及 &lt;a href="#記憶力好的-LSTM-細胞"&gt;LSTM 層&lt;/a&gt;。剩下的串接層以及全連結層在 Keras 也都有現成的模組可供使用。&lt;/p&gt;
&lt;p&gt;另外值得一提的是，圖上的每個層（Layer）以及向量右下的灰字都對應了底下 Python 程式碼裡頭的變數名稱：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        灰字代表程式碼裡頭對應的變數名稱
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此，如果等等你不了解底下某個特定的變數所代表的意義，可以回來利用這張架構圖來釐清概念。&lt;/p&gt;
&lt;p&gt;以下就是此模型的 Keras 實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 基本參數設置，有幾個分類&lt;/span&gt;
&lt;span class="n"&gt;NUM_CLASSES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="c1"&gt;# 在語料庫裡有多少詞彙&lt;/span&gt;
&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;

&lt;span class="c1"&gt;# 一個標題最長有幾個詞彙&lt;/span&gt;
&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;

&lt;span class="c1"&gt;# 一個詞向量的維度&lt;/span&gt;
&lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 輸出的向量維度&lt;/span&gt;
&lt;span class="n"&gt;NUM_LSTM_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立孿生 LSTM 架構（Siamese LSTM）&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
    &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.models&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;

&lt;span class="c1"&gt;# 分別定義 2 個新聞標題 A &amp;amp; B 為模型輸入&lt;/span&gt;
&lt;span class="c1"&gt;# 兩個標題都是一個長度為 20 的數字序列&lt;/span&gt;
&lt;span class="n"&gt;top_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'int32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'int32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="c1"&gt;# 經過詞嵌入層的轉換，兩個新聞標題都變成&lt;/span&gt;
&lt;span class="c1"&gt;# 一個詞向量的序列，而每個詞向量的維度&lt;/span&gt;
&lt;span class="c1"&gt;# 為 256&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;top_embedded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;top_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_embedded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;bm_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="c1"&gt;# 兩個新聞標題經過此層後&lt;/span&gt;
&lt;span class="c1"&gt;# 為一個 128 維度向量&lt;/span&gt;
&lt;span class="n"&gt;shared_lstm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_LSTM_UNITS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;top_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared_lstm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top_embedded&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared_lstm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bm_embedded&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 串接層將兩個新聞標題的結果串接單一向量&lt;/span&gt;
&lt;span class="c1"&gt;# 方便跟全連結層相連&lt;/span&gt;
&lt;span class="n"&gt;merged&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bm_output&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層搭配 Softmax Activation&lt;/span&gt;
&lt;span class="c1"&gt;# 可以回傳 3 個成對標題&lt;/span&gt;
&lt;span class="c1"&gt;# 屬於各類別的可能機率&lt;/span&gt;
&lt;span class="n"&gt;dense&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;NUM_CLASSES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'softmax'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;merged&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 我們的模型就是將數字序列的輸入，轉換&lt;/span&gt;
&lt;span class="c1"&gt;# 成 3 個分類的機率的所有步驟 / 層的總和&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bm_input&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這段程式碼的確不短，但有將近一半是我寫給你的註解。而且這段程式碼的邏輯跟上面的架構圖一模一樣，只差架構圖是從左到右、程式碼是從上到下而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了確保用 Keras 定義出的模型架構跟預期相同，我們也可以將其畫出來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.utils&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plot_model&lt;/span&gt;
&lt;span class="n"&gt;plot_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;to_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'model.png'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;show_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;show_layer_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;rankdir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'LR'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/model.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了模型架構以外，我們還可以看到所有層的輸入 / 輸出張量（Tensor）的維度。在 Keras 裏頭，張量的第 1 個維度通常為樣本數（比方說 5 則新聞標題），而 &lt;code&gt;None&lt;/code&gt; 則代表可以指定任意值。&lt;/p&gt;
&lt;p&gt;最重要的是，這個用 Keras 定義出來的模型，跟我們之前想像中的孿生神經網路可以說是一模一樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我沒有騙你，對吧？&lt;/p&gt;
&lt;p&gt;現在你應該發現，只要擁有前面幾章學到的 NLP 知識以及基礎 Python 程式能力，要建立一個像這樣看似複雜的孿生 LSTM（Siamese LSTM）神經網路其實也並沒有那麼困難。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，使用 Keras 建立深度學習模型這件事情感覺上就像是在玩疊疊樂一樣，一層加上一層：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/playing-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一位研究生利用 Keras 做深度學習的心得
                        （&lt;a href="https://youtu.be/Lx3l4lOrquw?t=277" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="全連接層"&gt;全連接層&lt;a class="anchor-link" href="#全連接層"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;唯一沒有在前面章節提到的是&lt;a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/fc_layer.html"&gt;全連接層（Fully Connected Layer）&lt;/a&gt;以及其使用的 &lt;a href="https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0"&gt;Softmax 函式&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;全連接層顧名思義，代表該層的每個神經元（Neuron）都會跟前一層的所有神經元享有連結：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/fully-connected.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        因為只需要預測 3 個分類，本文的全連接層只有 3 個神經元
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而為了確認我們計算的參數量無誤，還可以使用 &lt;code&gt;model.summary()&lt;/code&gt; 來看每一層的參數量以及輸出的張量（Tensor）長相：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/model-summary.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;全連接層在最下面。而因為其與前一層「緊密」連接的緣故，它在 Keras 裏頭被稱為 &lt;code&gt;Dense&lt;/code&gt; 層。它也是最早出現、最簡單的神經網路層之一。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Param #&lt;/code&gt; 則紀錄了每一層所包含的模型參數（Parameters）。在機器學習的過程中，這些參數都會不斷地被調整，直到能讓模型能做出很好的預測。詞嵌入層有最多的參數，因為我們要為 字典裡頭的每個詞彙都建立一個 256 維度的詞向量，因此參數量為 10,000 * 256。&lt;/p&gt;
&lt;p&gt;這張表另外一個值得注意的地方是所有層的 Output Shape 的第一個維度都是 &lt;code&gt;None&lt;/code&gt;。而 &lt;code&gt;None&lt;/code&gt; 代表著可以是任意的數字。&lt;/p&gt;
&lt;p&gt;在 Keras 裡頭，第一個維度代表著樣本數（#Samples），比方說前 9,527 筆新聞標題 A 的數字序列的 &lt;code&gt;shape&lt;/code&gt; 應該要是 &lt;code&gt;（9527, 20）&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;9527&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(9527, 20)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯，結果跟我們想像的一樣。&lt;/p&gt;
&lt;p&gt;而之所以每層的樣本數為 &lt;code&gt;None&lt;/code&gt; 是因為 Keras 為了因應在不同場合會丟入不同數量的樣本需求。比方說，在訓練時你可能會一次丟 32 筆資料給模型訓練，但在預測的時候一次只丟 16 筆資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Softmax-函式"&gt;Softmax 函式&lt;a class="anchor-link" href="#Softmax-函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Softmax 函式一般都會被用在整個神經網路的最後一層上面，比方說我們這次的全連接層。&lt;/p&gt;
&lt;p&gt;Softmax 函式能將某層中的所有神經元裡頭的數字作正規化（Normalization）：將它們全部壓縮到 0 到 1 之間的範圍，並讓它們的和等於 1。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/softmax-and-fully-connectead.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Softmax 能將多個數字作正規化，讓它們的值為 1
                        （&lt;a href="https://towardsdatascience.com/deep-learning-concepts-part-1-ea0b14b234c8" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有數值都位於 0 到 1 之間&lt;/li&gt;
&lt;li&gt;所有數值相加等於 1&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這兩個條件恰好是機率（Probability）的定義，Softmax 函式的運算結果可以讓我們將每個神經元的值解釋為對應分類（Class）的發生機率。&lt;/p&gt;
&lt;p&gt;以我們的假新聞分類任務來說的話，每個值就各代表以下分類的發生機率：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不相關： 0.46&lt;/li&gt;
&lt;li&gt;新聞 B 同意新聞 A：0.34&lt;/li&gt;
&lt;li&gt;新聞 B 不同意新聞 B：0.20&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果現在是在做預測且我們只能選出一個分類當作答案的話，我們可以說這次的分類結果最有可能是「不相關」這個類別，因為其發生機率最高。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在定義好模型以後，我們就可以進入下個步驟：定義衡量模型好壞的指標。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="決定如何衡量模型的表現"&gt;決定如何衡量模型的表現&lt;a class="anchor-link" href="#決定如何衡量模型的表現"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓機器自動「學習」，我們得給它一個&lt;a href="https://zh.wikipedia.org/wiki/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"&gt;損失函數（Loss Function）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;給定一個正確解答 &lt;code&gt;y&lt;/code&gt; 以及模型預測的結果 &lt;code&gt;y_head&lt;/code&gt;，我們的模型透過損失函數就能自動計算出現在的預測結果跟正解的差距為多少。&lt;/p&gt;
&lt;p&gt;透過損失函數的回饋，模型會盡全力修正參數，以期將此損失函數的值下降到最低（也就是讓預測結果 &lt;code&gt;y_head&lt;/code&gt; 跟正解 &lt;code&gt;y&lt;/code&gt; 越來越接近）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/loss-function.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        圖中的拋物線即為損失函數 J(w)。當參數 w 有不同值時，損失函數的值也有所不同。模型會持續修正參數 w 以期最小化損失函數
                        （&lt;a href="https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;那你會問，在假新聞分類裡頭，我們應該使用什麼損失函數呢？&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;/a&gt; 一節有稍微提到，我們會希望&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正確的分類的機率分佈 P1（例：&lt;code&gt;[1, 0, 0]&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;模型預測出的機率分佈 P2（例：&lt;code&gt;[0.7, 0.2, 0.1]&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這 2 個機率分佈的「差距」越小越好。而能計算 2 個機率分佈之間的差距的&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E7%86%B5"&gt;交叉熵（Cross Entropy）&lt;/a&gt;就是這次的分類問題中最適合的損失函數。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/cross-entropy.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        交叉熵能幫我們計算兩個機率分佈的差距，適合作為分類問題的損失函數
                        （&lt;a href="https://youtu.be/tRsSi_sqXjI?t=44" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Keras 裏頭，我們可以這樣定義模型的損失函數：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'rmsprop'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'accuracy'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;categorical_crossentropy&lt;/code&gt; 即是我們剛剛所說的交叉熵，而 &lt;code&gt;accuracy&lt;/code&gt; 則是準確度，會被我們用來在訓練過程中了解模型的表現情況。&lt;/p&gt;
&lt;p&gt;精準度的定義為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 模型預測正確的樣本數
-------------------
#     總樣本數
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;雖然有了交叉熵來當作我們模型的損失函數，但是實際上模型要如何更新裡頭的參數呢？我們需要一個&lt;a href="https://keras-cn.readthedocs.io/en/latest/other/optimizers/"&gt;優化器（Optimizer）&lt;/a&gt;來做到這件事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/loss-function-learning.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        不同優化器透過調整參數來降低損失函數的情形，就像是在想辦法往溜滑梯的低處滑一樣
                        （&lt;a href="https://stats.stackexchange.com/questions/357449/two-large-decreses-in-loss-function-with-adam-optimizer" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們有很多種優化器，但它們基本上都是從&lt;a href="https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"&gt;梯度下降法（Gradient Descent）&lt;/a&gt;延伸而來。&lt;/p&gt;
&lt;p&gt;在上圖的不同位置，梯度下降法會重新計算每個參數對損失函數的梯度（斜率）。接著梯度下降法會利用該梯度來修正參數，使得使用新參數算出來的損失函數的值能夠持續往下降。&lt;/p&gt;
&lt;p&gt;不同優化器則有各自往下滑的秘方，比方說自動調整 &lt;a href="https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10"&gt;Learning rate&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;現在就先讓我們使用 &lt;a href="https://keras-cn.readthedocs.io/en/latest/other/optimizers/"&gt;RMSProp 優化器&lt;/a&gt;。而在有了損失函數以及優化器以後，我們就可以正式開始訓練模型了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="訓練模型並挑選最好的結果"&gt;訓練模型並挑選最好的結果&lt;a class="anchor-link" href="#訓練模型並挑選最好的結果"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟很直觀，我們就是實際使用 &lt;code&gt;model.fit&lt;/code&gt; 來訓練剛剛定義出來的孿生 LSTM 模型：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 決定一次要放多少成對標題給模型訓練&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;

&lt;span class="c1"&gt;# 決定模型要看整個訓練資料集幾遍&lt;/span&gt;
&lt;span class="n"&gt;NUM_EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="c1"&gt;# 實際訓練模型&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸入是兩個長度為 20 的數字序列&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;NUM_EPOCHS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="c1"&gt;# 每個 epoch 完後計算驗證資料集&lt;/span&gt;
    &lt;span class="c1"&gt;# 上的 Loss 以及準確度&lt;/span&gt;
    &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_val&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
        &lt;span class="n"&gt;y_val&lt;/span&gt;
    &lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="c1"&gt;# 每個 epoch 隨機調整訓練資料集&lt;/span&gt;
    &lt;span class="c1"&gt;# 裡頭的數據以讓訓練過程更穩定&lt;/span&gt;
    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊特別值得拿出來提的是以下兩個參數：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BATCH_SIZE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NUM_EPOCHS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照我們前面對損失函數（Loss Function）的說明，理論上模型是把訓練資料集裡頭的 32 萬筆資料全部看完一遍之後，再更新一次參數以降低損失函數。&lt;/p&gt;
&lt;p&gt;但是這樣太曠日廢時，訓練可能要花很久才能完成。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rawpixel-584290-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實務上都是每次只放入幾筆訓練數據，讓模型看完這些資料後就做一次參數的更新。而這個「幾筆」，就是 &lt;code&gt;BATCH_SIZE&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;依照 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 的大小，梯度下降（Gradient Descent, 後稱 GD）可以概括為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; = 訓練資料集大小，且這時不稱為 batch）&lt;/li&gt;
&lt;li&gt;Mini-batch GD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; 通常為一個較小的 2 的倍數）&lt;/li&gt;
&lt;li&gt;SGD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; = 1）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/sgd-vs-mini-batch.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        想像損失函數是個越往裡面值就越低的碗，梯度下降就是要想辦法到達中心點
                        （&lt;a href="https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如上圖所示，下方的 GD 因為在每次更新參數前都會看完訓練資料集裡頭所有的數據，因此它更新參數的方向是最可靠的。但要往前走一步就就得看完 32 萬筆數據，未免成本也太大。&lt;/p&gt;
&lt;p&gt;另一個極端是上方的 SGD：模型每看完 1 個訓練數據就嘗試更新權重，而因為單一一筆訓練數據並不能很好地代表整個訓練資料集，前進的方向非常不穩定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mini-batch.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        隨機梯度下降（SGD）與 Mini-batch 梯度下降的比較
                        （&lt;a href="https://datascience-enthusiast.com/DL/Optimization_methods.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此我們常常採用的是中庸之道： Mini-batch GD 的方式來訓練模型，而這靠的是指定 &lt;code&gt;model.fit&lt;/code&gt; 函式裡頭的 &lt;code&gt;batch_size&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;NUM_EPOCHS&lt;/code&gt; 則很容易理解：你希望模型不只將 32 萬筆的訓練數據都看過一遍，而是每一筆資料還要多看過好幾次，以讓模型確確實實地從它們身上學到東西。&lt;code&gt;NUM_EPOCHS&lt;/code&gt; = 10 的意思就代表模型會重複看整個訓練資料集 10 次。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們看看 Keras 的訓練過程：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/training-process.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Keras 訓練神經網路的過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為模型的目標就是要最小化損失函數（Loss Function），你可以觀察到當模型看過越多訓練資料集（Training Set）的數據以後，損失值（loss）就越低，分類的準確度（acc）則越高。&lt;/p&gt;
&lt;p&gt;這代表我們的模型越來越熟悉訓練資料集裡頭的數據，因此在訓練資料集裡頭的表現越來越好。&lt;/p&gt;
&lt;p&gt;如果依照準確度以及損失值分別畫圖的話則會長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/training-result.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，我們的神經網路有過適（Overfittng）的問題：儘管在訓練資料集表現得非常好（準確度超過 90 %、損失小於 0.2），在從沒看過的驗證資料集的表現就相對遜色不少。且在第 6 個 epoch 之後驗證資料集的準確度 &lt;code&gt;val_acc&lt;/code&gt; 就沒什麼在上升，驗證集的損失 &lt;code&gt;val_loss&lt;/code&gt; 則已經逐漸上升。&lt;/p&gt;
&lt;p&gt;這代表模型利用從訓練資料集學到的模式（Pattern）還無法非常精準地預測沒見過的事物。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deep-learning-three-steps-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        用 Keras 來實作深度學習的基本 3 步驟
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="#深度學習-3-步驟"&gt;這章節一開頭&lt;/a&gt;所說的，雖然第 3 步驟：「訓練模型並挑選最好的結果」的 Keras 實作非常簡單（基本上就是 &lt;code&gt;model.fit( ...)&lt;/code&gt;），但實際上在一個機器學習 / 深度學習專案裡頭，你將會花 80 % 的時間在這個步驟裡頭調整參數，想辦法找到一個最棒的模型。&lt;/p&gt;
&lt;p&gt;儘管如此，我們現在最想知道的還是這個模型在真實世界（也就是測試資料集）到底能表現多好，因此先讓我們試著拿這個簡單模型來做預測吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="進行預測並提交結果_1"&gt;進行預測並提交結果&lt;a class="anchor-link" href="#進行預測並提交結果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就跟我們對訓練 / 驗證資料集做的&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理&lt;/a&gt;一樣，要對測試資料集（Test Set）做預測，我們得先將裡頭的文本數據通通轉換成能夠丟進模型的數字序列資料。&lt;/p&gt;
&lt;p&gt;首先，讓我們把測試資料集讀取進來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;TEST_CSV_PATH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;tid1&lt;/th&gt;
&lt;th&gt;tid2&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title1_en&lt;/th&gt;
&lt;th&gt;title2_en&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;321187&lt;/th&gt;
&lt;td&gt;167562&lt;/td&gt;
&lt;td&gt;59521&lt;/td&gt;
&lt;td&gt;萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大&lt;/td&gt;
&lt;td&gt;辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？&lt;/td&gt;
&lt;td&gt;egypt 's presidential election failed to win m...&lt;/td&gt;
&lt;td&gt;Lyon! Lyon officials have denied that Felipe F...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;321190&lt;/th&gt;
&lt;td&gt;167564&lt;/td&gt;
&lt;td&gt;91315&lt;/td&gt;
&lt;td&gt;萨达姆被捕后告诫美国的一句话，发人深思&lt;/td&gt;
&lt;td&gt;10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国&lt;/td&gt;
&lt;td&gt;A message from Saddam Hussein after he was cap...&lt;/td&gt;
&lt;td&gt;The Top 10 Americans believe that the Lizard M...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;321189&lt;/th&gt;
&lt;td&gt;167563&lt;/td&gt;
&lt;td&gt;167564&lt;/td&gt;
&lt;td&gt;萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗&lt;/td&gt;
&lt;td&gt;萨达姆被捕后告诫美国的一句话，发人深思&lt;/td&gt;
&lt;td&gt;Will the United States wage war on Iraq withou...&lt;/td&gt;
&lt;td&gt;A message from Saddam Hussein after he was cap...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;測試資料集跟訓練資料集的唯一差別只在沒有 &lt;code&gt;label&lt;/code&gt; 欄位，因此我們只需要將當初在&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理&lt;/a&gt;章節使用的步驟原封不動地套用在測試資料集即可。&lt;/p&gt;
&lt;p&gt;你可以趁機複習一下有哪些步驟：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 以下步驟分別對新聞標題 A、B　進行&lt;/span&gt;
&lt;span class="c1"&gt;# 文本斷詞 / Word Segmentation&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將詞彙序列轉為索引數字的序列&lt;/span&gt;
&lt;span class="n"&gt;x1_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title1_tokenized&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title2_tokenized&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 為數字序列加入 zero padding&lt;/span&gt;
&lt;span class="n"&gt;x1_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x1_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    

&lt;span class="c1"&gt;# 利用已訓練的模型做預測&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_test&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些步驟現在對你來說應該都已經不再陌生。&lt;/p&gt;
&lt;p&gt;讓我們看一下從模型得到的預測結果長什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/test-predictions.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟我們之前討論過的一樣，模型針對每一筆成對新聞標題的輸入，會回傳給我們 3 個分類的機率值。&lt;/p&gt;
&lt;p&gt;現在，我們只要將機率值最大的類別當作答案，並將這個結果轉回對應的文本標籤即可上傳到 Kaggle：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;index_to_label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;label_to_index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()}&lt;/span&gt;

&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index_to_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;submission&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;submission&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Id'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;submission&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/submission.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;得到上面的 DataFrame 以後，我們可以將其儲存成 CSV 並上傳到 kaggle，而結果如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/first-submission-result.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們的 NLP 模型第一次的結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你還記得我們在&lt;a href="#用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;/a&gt;的章節內容的話，就會知道這並不是應該多好的預測結果，但的確比多數票決好了一點點。&lt;/p&gt;
&lt;p&gt;不過不需要操之過急，因為任何機器學習專案都是一個持續重複改善的迴圈。在第一次預測就做出完美結果的情況很少，重點是持續改善。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/thor-alvis-754589-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在第一次提交結果以後，我們還可以做非常多事情來嘗試改善模型效能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;改變字典詞彙量、序列長度&lt;/li&gt;
&lt;li&gt;改變詞向量的維度&lt;/li&gt;
&lt;li&gt;嘗試&lt;a href="https://ithelp.ithome.com.tw/articles/10194633"&gt;預先訓練的詞向量&lt;/a&gt;如 &lt;a href="https://zhuanlan.zhihu.com/p/38254332"&gt;ELMo&lt;/a&gt;、&lt;a href="https://nlp.stanford.edu/projects/glove/"&gt;GloVe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;調整 LSTM 層的輸出維度&lt;/li&gt;
&lt;li&gt;使用不同優化器、調整 Learning rate&lt;/li&gt;
&lt;li&gt;改變神經網路架構如使用 GRU 層&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;能改善準確度的方式不少，但因為牽涉範圍太廣，請容許我把它們留給你當做回家作業。&lt;/p&gt;
&lt;p&gt;走到這裡代表你已經完整地經歷了一個 NLP 專案所需要的大部分步驟。在下一節．讓我們回顧一下在這趟旅程中你所學到的東西。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="我們是怎麼走到這裡的"&gt;我們是怎麼走到這裡的&lt;a class="anchor-link" href="#我們是怎麼走到這裡的"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這趟 NLP 旅程裏頭，我們學會了不少東西。&lt;/p&gt;
&lt;p&gt;現在的你應該已經了解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NLP 中常見的數據前處理以及實踐方法&lt;/li&gt;
&lt;li&gt;詞向量以及詞嵌入的基本概念&lt;/li&gt;
&lt;li&gt;神經網路常見的元件如全連接層、簡單 RNN 以及 LSTM&lt;/li&gt;
&lt;li&gt;能讀多個資料來源的孿生神經網路架構&lt;/li&gt;
&lt;li&gt;如何用 Keras 建構一個完整的神經網路&lt;/li&gt;
&lt;li&gt;深度學習 3 步驟：建模、定義衡量指標以及訓練模型&lt;/li&gt;
&lt;li&gt;梯度下降、優化器以及交叉熵等基本概念&lt;/li&gt;
&lt;li&gt;如何利用已訓練模型對新數據做預測&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;呼，這可真了不起，值得慶祝！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/wil-stewart-24562-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;能閱讀到這裡，我相信你對深度學習以及 NLP 領域是抱著不少興趣的。而為了讓你在閱讀本文以後能夠繼續探索這個世界，在下一章節我則會介紹 3 門非常推薦的線上課程。&lt;/p&gt;
&lt;p&gt;最後，我則會在文末總結一下自己的心得。&lt;/p&gt;
&lt;p&gt;現在，先看看有哪些課程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="3-門推薦的線上課程"&gt;3 門推薦的線上課程&lt;a class="anchor-link" href="#3-門推薦的線上課程"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;為了奠定 NLP 的基礎，這一個月我一邊複習舊教材，一邊看了不少教學文章以及線上課程。&lt;/p&gt;
&lt;p&gt;截至目前，我認為有 3 個 CP 值十分高的課程值得推薦給你：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;台大電機系李宏毅教授的&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html"&gt;深度學習課程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;奠定理論基礎&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Coursera 的&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt; Deep Learning 專項課程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;理論 70 % + 實作 30 %&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.oreilly.com/library/view/deep-learning-with/9781617294433VE/"&gt;Deep Learning with Python&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;注重程式實作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這邊說的 CP 值高（對，我知道你最愛 CP 值）指的是能用最少的時間、精力以及金錢來確確實實地學好 NLP 的理論及實作基礎。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/Hung-yi-Lee-ml-courses.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        李宏毅教授的 Youtube 播放清單
                        （&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://www.ee.ntu.edu.tw/profile?id=1020908"&gt;李宏毅教授&lt;/a&gt;的機器學習課程內行的都知道，大概是全世界最好、最完整的 Deep Learning 中文學習資源。李教授在課程中廣徵博引學術論文，但卻同時非常淺顯易懂。你可以在這邊看到&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists"&gt;教授所有的 Youtube 課程播放清單&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;就我所知，教授在台大上課很注重實作，有不少作業需要完成，但因為線上只有影片可以查看，因此我將其分類為「奠定理論基礎」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deeplearning-ai-courses.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Deep Learning Specialization
                        （&lt;a href="https://www.coursera.org/specializations/deep-learning" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;原 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達教授&lt;/a&gt;的 &lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning 專項課程&lt;/a&gt;則是 Coursera 上最受歡迎的深度學習課程。跟我們這篇文章最相關的 NLP 技術則被涵蓋在該專項課程的最後一堂課：&lt;a href="https://www.coursera.org/learn/nlp-sequence-models"&gt;Sequence Models&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我在大約一年前完成包含&lt;a href="https://www.coursera.org/learn/convolutional-neural-networks"&gt;卷積神經網路 CNN&lt;/a&gt; 的前四堂課，而因為課程上線已有一段時間，現在影片大都有簡體或繁體中文的字幕，不太需要煩惱聽不懂英文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deeplearning-with-python.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://www.oreilly.com/library/view/deep-learning-with/9781617294433VE/"&gt;Deep Learning with Python Video Edition&lt;/a&gt; 的作者 &lt;a href="https://ai.google/research/people/105096"&gt;Fran&amp;ccedil;ois Chollet&lt;/a&gt; 為軟體工程師出身，設計出知名深度學習框架 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt;，目前則在 Google AI 工作。&lt;/p&gt;
&lt;p&gt;該書以 Programmer 的角度出發，提供了利用 Keras 實現各種 NLP 任務的範例，十分適合在熟悉深度學習理論後想要實作的人閱讀。&lt;/p&gt;
&lt;p&gt;就算你不想花錢買書或是訂閱 &lt;a href="https://www.safaribooksonline.com"&gt;O'Relly Online&lt;/a&gt;，你也可以在他有 5,000 多顆星的 Github Repo &lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;deep-learning-with-python-notebooks&lt;/a&gt; 看到跟該課程相關的所有 Jupyter Notebooks。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/maxwell-ridgeway-685077-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些課程可以說是幫助我完成這篇文章以及 Kaggle 競賽的最大功臣，而我也希望能透過這篇文章的微薄之力讓你知道他們的存在，並隨著他們繼續你從這裏開始的 NLP 探險。&lt;/p&gt;
&lt;p&gt;當然，除了以上 3 堂課程，你還可以在&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;由淺入深的深度學習資源整理&lt;/a&gt;一文看到更多我整理的深度學習資源。你也可以直接前往 &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources"&gt;Github Repo&lt;/a&gt; 查看。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語：從掌握基礎到運用巨人之力"&gt;結語：從掌握基礎到運用巨人之力&lt;a class="anchor-link" href="#結語：從掌握基礎到運用巨人之力"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;網路上多的是專業的 NLP 教學文章或論文探討，但平易近人的中文文章卻少之又少。&lt;/p&gt;
&lt;p&gt;在文章開頭我說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        希望這篇文章能成為你前往自然語言處理世界的最佳橋樑。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這野心聽起來很狂妄，但至少我已經嘗試用最平易近人的詞彙向你介紹這個 NLP 世界的一丁點基礎知識，而我也希望你真的學到了些什麼、獲得些啟發。&lt;/p&gt;
&lt;p&gt;現在深度學習以及 NLP 領域實在發展太快，就算一個人有興趣也常常不知從何開始學起。&lt;/p&gt;
&lt;p&gt;事實上，NLP 的發展速度還在加快，而這既是好消息也是壞消息。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/jack-anstey-383370-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        NLP 如果是輛衝往未來的火車的話，深度學習就是它的引擎，而我們的數據是它的燃料。另外，多數人還沒有登上這台火車
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊說的 NLP，其實更適合用人工智慧取代。&lt;/p&gt;
&lt;p&gt;對還沒掌握機器學習 / 深度學習 / NLP 知識的人來說，這些技術只會離自己越來越遠，最後遠到只會在&lt;a href="https://buzzorange.com/techorange/2018/12/22/ai-breakthrough-in-2018/"&gt;新聞報導&lt;/a&gt;或科幻小說上看到，儘管被這些技術驅動的龐大系統每天影響著他們的生活。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rawpixel-780496-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;至於那些已經掌握這些知識的人，透過運用&lt;a href="https://github.com/google-research/bert"&gt;如遷移學習等巨人之力&lt;/a&gt;，就連一般人也能做到以前憑自己力量做不到的事情。&lt;/p&gt;
&lt;p&gt;比方說利用 Google 在今年 11 月公開的龐大&lt;a href="https://github.com/google-research/bert"&gt;語言代表模型 BERT&lt;/a&gt;，我不費吹灰之力就在本文的 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/leaderboard"&gt;Kaggle 競賽&lt;/a&gt;達到 85 % 的正確率，距離第一名 3 %，總排名前 30 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/kaggle-final-result.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們之前設計的 LSTM 模型則僅有 67 % 準確度。&lt;/p&gt;
&lt;p&gt;並不是說只要用新的語言代表模型就好，這篇學的東西都不重要。事實上正好相反：正是因為有了此篇的 NLP 基礎知識，才讓我得以順利地運用該巨人之力。如果你有興趣深入了解，可以接著閱讀&lt;a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html"&gt;進擊的 BERT：NLP 界的巨人之力與遷移學習&lt;/a&gt;，用最直觀的方式理解並實際運用這個巨人之力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/bert/bert-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        BERT 是在 NLP 領域裡家喻戶曉的語言代表模型
                        （&lt;a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;深度學習以及 NLP 領域發展快速，但你總要從某個地方開始好好地學習基礎，而且越快開始越好。&lt;/p&gt;
&lt;p&gt;所以我留給你的最後一個問題就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你，打算什麼時候出發？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="自然語言處理"></category><category term="Keras"></category><category term="Python"></category><category term="深度學習"></category></entry><entry><title>我在比利時 EMNLP 之旅中學到的 3 堂課</title><link href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html" rel="alternate"></link><published>2018-11-19T08:00:00+09:00</published><updated>2018-11-19T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-11-19:/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html</id><summary type="html">&lt;p&gt;這是一個 NLP 初心者勇闖自然語言處理的頂級學術會議 EMNLP 的故事。在這篇文章裡，我想跟你分享 3 個這次旅行中帶給我最重要的體悟。這些體悟改變了我的人生，而我也希望你能從這個故事裡頭獲得些啟發，重新思考你自己的學習，並做一些好的改變。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想將最近在比利時&lt;a href="https://zh.wikipedia.org/wiki/%E5%B8%83%E9%B2%81%E5%A1%9E%E5%B0%94"&gt;布魯塞爾&lt;/a&gt;參加自然語言處理的頂級會議 &lt;a href="http://emnlp2018.org/"&gt;EMNLP 2018&lt;/a&gt; 的心得記錄下來並與你分享。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-entrance.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 2018 會場門口
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇文章會把我數天參加會議時所感受到的個人想法總結成最重要的 3 個 lessons。希望你在閱讀我的故事以後，一樣也能從中獲得一些啟發。&lt;/p&gt;
&lt;p&gt;最後在文末，我則會說明這些想法將如何影響今後部落格的走向。如果你是忠實讀者，或許也會有興趣了解這個故事：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="計畫之外的-NLP-之旅"&gt;計畫之外的 NLP 之旅&lt;a class="anchor-link" href="#計畫之外的-NLP-之旅"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今年 10 月底，我跟公司請了一個禮拜的假參加在布魯塞爾舉辦的 &lt;a href="http://emnlp2018.org/"&gt;EMNLP 會議&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;EMNLP 作為世界頂尖的&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"&gt;自然語言處理&lt;/a&gt;會議之一，每年都有無以數計的專業人士聚集在此，與他人分享自己最新的研究成果。與大多數國際會議相同，&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;的蹤影基本上無所不在。&lt;/p&gt;
&lt;p&gt;你可以在&lt;a href="http://emnlp2018.org/schedule"&gt;這邊看到所有議程以及論文&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-line-up.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Workshops / Tutorials 第一天報到的人龍
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過老實說，在同事提及此會議之前，我並沒有聽過它的名號，更不用說考慮報名參加了。我本來預計是要參加跟資料工程相關的 &lt;a href="https://www.dataengconf.com/"&gt;DataEngConf&lt;/a&gt; 會議。（你可能已經從&lt;a href="https://leemeng.tw/tag/zi-liao-gong-cheng.html"&gt;我寫過的幾篇資料工程文章&lt;/a&gt;了解我對 DE 的興趣）&lt;/p&gt;
&lt;p&gt;但想説難得有機會深入了解現在 NLP 的研究趨勢，況且人多有個照應，稍微衡量一下就決定參加 EMNLP 了。&lt;/p&gt;
&lt;p&gt;當時的我還不曉得，這趟旅程為自己帶來的收穫，比原先預想地來得多。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="幾萬呎高空上的兩本書"&gt;幾萬呎高空上的兩本書&lt;a class="anchor-link" href="#幾萬呎高空上的兩本書"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這趟旅行從我坐上飛機就開始了。&lt;/p&gt;
&lt;p&gt;從東京到比利時，飛行距離大約有 1 萬公里，直飛也需快 12 小時。在長途飛行中沒有網路，因此我這次決定帶兩本買了好一陣子都沒翻開的書，計畫去程與回程各看一本。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;中途因為沒有任何如 Facebook 通知的干擾，我在飛機快抵達布魯塞爾時消化完《你要如何衡量你的人生？》的內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/two-books.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這次跟我一起去比利時的兩本書
                        （&lt;a href="https://leemeng.tw/books.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過此書我學到，那些你在職場或人生中設定的策略以及計劃，在實際展開行動去執行它們之前，什麼都不是。為了達成你要的目標，你得實際分配精力、時間等資源在上面，而非只是空想或說大話。&lt;/p&gt;
&lt;p&gt;在回東京時，我則閱讀了&lt;a href="https://gettingmore.com/"&gt;《華頓商學院最受歡迎的談判課》&lt;/a&gt;。戴蒙教授用深入淺出的說明以及大量真實案例，再次提醒我在進行溝通或談判時，以「人」為本、設身處地的重要性。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/aaron-burden-236415-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這兩本書值得推薦，但在這裏，重點其實並不在於這兩本書的內容。在閱讀完《你要如何衡量你的人生？》時飛機正好抵達比利時，我則驚覺：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        為何我當初在買書時早已預感能從此書獲得許多寶貴的思想，卻拖到現在才閱讀？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這正是「沒有下定決心分配資源以執行策略」的活生生例子。&lt;/p&gt;
&lt;p&gt;你的書櫃上是否也放了不少買了卻沒看的書？當初買書時你期望透過書本學到什麼？沒看完的原因又是什麼呢？&lt;/p&gt;
&lt;p&gt;如果「沒時間」是你的理由，那麼正說明了你跟當時的我一樣，沒有下定決心將自己的資源（時間）花在執行策略上面（看書變聰明、豐富人生）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/chuttersnap-412981-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資訊爆炸時代，我們的閱讀時間變得極度零碎，也難以長時間集中自己的注意力。很多時候跟看 Youtube 影片比起來，我們會覺得讀一本書的「投資報酬率」太低：花費時間太多，帶來的刺激太少。&lt;/p&gt;
&lt;p&gt;但其實並不是那麼一回事。好的書籍能改變你的一生，讓你終身受惠。而這次的機上閱讀帶給我的第一堂課即是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        閱讀好書是最好的長期投資，能豐富並讓你的人生更好。確保你會實際安排時間與精力去閱讀自己感興趣的書籍。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;的確，你不需要像我一樣在幾萬呎高空上閱讀才能得到一樣的感想。但多虧了長途飛行給的專注時間，讓我在這趟旅行的一開始就重新體會到這件重要的事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="從零開始的-NLP-之路"&gt;從零開始的 NLP 之路&lt;a class="anchor-link" href="#從零開始的-NLP-之路"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/La-place-Royale.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        到達布魯塞爾的當天飄著綿綿細雨
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;下了飛機，坐地鐵來到市區，EMNLP 會議也即將拉開序幕。讓我們回到 NLP 的話題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我一直以來都對 NLP 抱持著不少興趣，過去卻沒有認真去了解近年深度學習在 NLP 領域的快速發展以及創新。&lt;/p&gt;
&lt;p&gt;因此我明白，以自己當下幾乎是 0 的 NLP 知識水平，要在像 EMNLP 這種專業的會場內頭，迅速理解演講者們的論文發表這件事情的難度是很高的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-conference.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 其中一個會議廳
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基於這樣的背景，我將此次參加會議的目標設定為「掌握 NLP 基本概念以及關鍵字」。&lt;/p&gt;
&lt;p&gt;為了達到這樣的目標，我有一個非常 naive 的策略，其分為三個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;選擇有興趣的 Sessions 聆聽&lt;/li&gt;
&lt;li&gt;聽到不熟悉的關鍵字就把它們記下來&lt;/li&gt;
&lt;li&gt;Session 結束後 Google 這些關鍵字&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/food-in-belgium.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        來比利時，用功之餘也不能錯過淡菜及啤酒
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然你可以想像得到，一開始的幾場演講，作者的一句話或是一張投影片就能讓我打下無數關鍵字。&lt;/p&gt;
&lt;p&gt;不過會議每進行一天，我就記越少關鍵字。這並不稀奇，畢竟大部分論文運用的「基本」 NLP 概念是相通的，而我也逐漸熟悉這些概念。（謝了，Google！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你實際感受一下，以下節錄一些被我紀錄下來的關鍵字：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recurrent Neural Network（RNN）&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6"&gt;LSTM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datascience.stackexchange.com/a/25657"&gt;BiLSTM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32481747"&gt;GRU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sohu.com/a/240293276_610300"&gt;SRNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word Embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nlp.stanford.edu/projects/glove/"&gt;GloVe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Evaluation / Dataset&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/BLEU"&gt;BLEU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/"&gt;SQuAD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NLP Tasks&lt;ul&gt;
&lt;li&gt;&lt;a href="https://1fly2sky.wordpress.com/2016/04/02/%E5%91%BD%E5%90%8D%E5%AF%A6%E9%AB%94%E8%AD%98%E5%88%A5%E6%8A%80%E8%A1%93named-entity-recognition/"&gt;Named Entity Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Machine_translation"&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E5%95%8F%E7%AD%94%E7%B3%BB%E7%B5%B1"&gt;Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://machinelearningmastery.com/gentle-introduction-text-summarization/"&gt;Text Summarization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1711.06861"&gt;Style Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54"&gt;Reading Comprehension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/"&gt;Open / Closed Domain Conversation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://skymind.ai/wiki/attention-mechanism-memory-network"&gt;Attention Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bigdatafinance.tw/index.php/news/578-transformer-rnn-lstm"&gt;Transformer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你平常有在接觸 NLP 領域，可能都已經對這些詞彙朗朗上口；但假如你跟當初參加會議時的我一樣，對 NLP 有興趣但卻什麼都不知道的話也別擔心，之後我會在其他文章解釋這些 NLP 術語並附上最好的學習資源。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/nlp-word-cloud.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;EMNLP 當然不只談了上述東西，但以上詞彙應該沒有人會否認是現在 NLP 研究/應用領域裡頭常用的關鍵字。別忘了我們的目標是「掌握 NLP 基本概念以及關鍵字」。即使是 NLP 初學者如我，先了解這些詞彙的意義以及背後的理論，也能讓你對現在的 NLP 領域有個「還可以」的掌握。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/pan-xiaozhen-423533-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個「高頻關鍵字策略」很簡單，就跟我們從小學外語的方式如出一轍。在初學語言時，比較有效率的學習方法通常是先拿起「英文高頻 5000 單字」或是「常用日本會話 1000 句」來看，而不是去背一輩子可能看不到 5 次的「&lt;a href="https://www.ettoday.net/news/20121228/146060.htm"&gt;火山矽肺症&lt;/a&gt;」英文。&lt;/p&gt;
&lt;p&gt;下個小節你會看到，這個策略的效果還不賴。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="美術館驗收學習成果"&gt;美術館驗收學習成果&lt;a class="anchor-link" href="#美術館驗收學習成果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為期數天的 EMNLP 會議裡的某一天晚上，在&lt;a href="https://zh.wikipedia.org/wiki/%E6%AF%94%E5%88%A9%E6%97%B6%E7%9A%87%E5%AE%B6%E7%BE%8E%E6%9C%AF%E5%8D%9A%E7%89%A9%E9%A6%86"&gt;皇家美術館&lt;/a&gt;有一個與會者專屬的 Social Event。此活動讓所有人都可以欣賞到創作時期橫跨 15 世紀到 21 世紀的 20,000 件藝術作品。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/La-Mort-de-Marat.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        路易．大衛的《馬拉之死》
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了欣賞如法國新古典主義畫家&lt;a href="https://zh.wikipedia.org/wiki/%E9%9B%85%E5%85%8B-%E8%B7%AF%E6%98%93%C2%B7%E5%A4%A7%E5%8D%AB"&gt;路易．大衛&lt;/a&gt;最為人知的&lt;a href="https://gushi.tw/%E6%B3%95%E5%9C%8B%E5%A4%A7%E9%9D%A9%E5%91%BD%E7%9A%84%E7%9C%9F%E5%AF%A6%E6%9A%97%E6%AE%BA%EF%BC%9A%E3%80%8A%E9%A6%AC%E6%8B%89%E4%B9%8B%E6%AD%BB%E3%80%8B/"&gt;《馬拉之死》&lt;/a&gt;等經典藝術作品之外，很多來參加 Social Event 的人是來「 Social 」的：跟一起來的同事聊聊天吃點心、想辦法多認識幾個厲害學者要個名片、或是找幾個陌生人討論彼此的研究。&lt;/p&gt;
&lt;p&gt;利用上節説的簡單策略，我將目前流行的 NLP 術語理解了一遍，接著就這樣在皇家美術館裡頭拿著香檳與比利時巧克力，跟完全陌生的研究者、工程師們互相寒暄，大聊 NLP。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/art-museum.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        皇家美術館裡的 Social Event
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我都跟他們說：「我完全不懂 NLP，是劉姥姥到大觀園。」但卻不只一位跟我說：「我覺得你 NLP 概念很不錯啊！我講的內容你都能理解，甚至還能給我的研究一些建議！」&lt;/p&gt;
&lt;p&gt;但那只是因為我在前幾天學會了這門「 NLP 語言 」的基礎詞彙，並運用我不受任何限制的想像力，針對他們的研究給出一些自己的想法而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個夜晚，我學到了第二堂課：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在這個科技變化快速的時代，思考如何用最有效率的方式學習新知非常重要。未來，我們最大的潛力取決於能多快熟悉並掌握新事物。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別誤會，我並沒有說自己去了 EMNLP 就已經掌握了所有 NLP 專業知識，也沒有說學了一門知識的「基礎詞彙」就已經足夠。但對的方式能為你後面的學習奠定非常好的基礎及方向。&lt;/p&gt;
&lt;p&gt;這邊的重點在於你要找出最有效率的方式學習，並突破傳統「要掌握一門學門得花數年時間的正統教育」的思考框架。現在網際網路上有數不清的資源等待你的探索，幫助你快速起飛。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="開啟全新的學習之旅"&gt;開啟全新的學習之旅&lt;a class="anchor-link" href="#開啟全新的學習之旅"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我當初努力思考「從這趟 EMNLP 之旅，我究竟學到什麼？」這個問題時，發現會議裡頭的確有不少振奮人心的演說以及構思巧妙的論文，但真正讓我自己獲益最多的是以下 3 個體悟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;閱讀好書是最好的長期投資，能豐富並讓你的人生更好。確保你會實際安排時間與精力去閱讀自己感興趣的書籍。&lt;/li&gt;
&lt;li&gt;在這個科技變化快速的時代，思考如何用最有效率的方式學習新知非常重要。未來我們最大的潛力取決於能多快熟悉並掌握新事物。&lt;/li&gt;
&lt;li&gt;旅行其中一個好處是能讓你探索自我並改變人生。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Eglise-Notre-Dame-du-Sablon.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        薩布隆聖母教堂
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前 2 點我們已經在前面花了不少篇幅解釋，在這邊我們花一點點篇幅說明最後一項：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        旅行其中一個好處是能讓你探索自我並改變人生。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對我而言，這次的旅行是一個人生的轉捩點。它正式地打開了我「多年」對深度學習以及 NLP 興趣的開關，促使我開始大量學習相關知識。&lt;/p&gt;
&lt;p&gt;之後的部落格，除了&lt;a href="https://leemeng.tw/tag/zi-liao-ke-xue.html"&gt;資料科學&lt;/a&gt;以及&lt;a href="https://leemeng.tw/tag/zi-liao-gong-cheng.html"&gt;資料工程&lt;/a&gt;的文章以外，也將會包含自己學習深度學習以及 NLP 時使用到的線上資源和個人心得。如果你也對 NLP 與深度學習有興趣，或許之後可以從這裡學到點東西；而如果你能跟我分享好的 NLP 學習資源，我也會非常感激！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/bruno-van-der-kraan-750941-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管如何，我都希望你能從我的故事裡頭獲得些啟發，重新思考你自己的學習，並做一些好的改變。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="布魯塞爾美麗風景"&gt;布魯塞爾美麗風景&lt;a class="anchor-link" href="#布魯塞爾美麗風景"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;篇幅有限，這邊簡單跟你分享這次旅程中我所看到的一些美麗景色。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/IMG_1186.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 會場附近風光
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Grand-Place.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        布魯塞爾大廣場
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Cathedrale-des.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖彌額爾聖古都勒主教座堂
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Cathedrale-des-inner.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        主教座堂內部
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale-2.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖心聖殿
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale-inner.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖殿內部
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        從聖心聖殿眺望布魯塞爾
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這趟旅途雖然到此告一段落，但讓我們在下次的 NLP 文章再次碰面吧！：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="隨筆"></category><category term="自然語言處理"></category><category term="深度學習"></category></entry><entry><title>資料科學家 L 的奇幻旅程 Vol.2 如何用資料工程當個時間旅人</title><link href="https://leemeng.tw/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html" rel="alternate"></link><published>2018-11-09T21:00:00+09:00</published><updated>2018-11-09T21:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-11-09:/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html</id><summary type="html">&lt;p&gt;「資料工程」與「時間旅行」，兩個看似毫無相關的詞能擦出什麼火花？在這篇文章裡頭，我想跟你分享一個輕鬆話題：身為資料科學家的我，是如何利用資料工程在公司裡頭當個「時間旅人」的。當然，實際上每家公司的 DS 以及 DE 的工作內容都會有所不同，了解這個事實並調整期待，將幫助你找到最適合自己的工作環境。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;奇幻旅程的第一篇&lt;/a&gt;裡頭你已經看到，為何了解企業內部使用的 KPI 以及熟悉公司內部的「數據流動」能讓一個資料科學家在工作上更如魚得水。&lt;/p&gt;
&lt;p&gt;那是一篇稍微正經嚴肅，但我認為對資料科學家來說（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist，後簡稱 DS）很有幫助的一篇文章。不過今天，我想跟你分享一個輕鬆話題：身為 DS 的我，是如何利用資料工程（Data Engineering）在公司裡頭當個「時間旅人」的。&lt;/p&gt;
&lt;p&gt;「時間旅人？你在開玩笑嗎？」&lt;/p&gt;
&lt;p&gt;「資料工程跟時間旅行八竿子沒關係吧！」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/dog-705820_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這可能是現在困惑的你的最佳寫照
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對對對我知道。&lt;/p&gt;
&lt;p&gt;你或許正歪著頭，想著我是不是下了個釣魚標題騙你進來。我得承認自己是個浪漫主義者，常常會將工作上的任務跟看的小說、電影做聯想。但我想，聯想力或許就是人類跟 AI 最大的差距吧！我也不覺得這是件壞事：）&lt;/p&gt;
&lt;p&gt;拉回正題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="所以什麼是時間旅人"&gt;所以什麼是時間旅人&lt;a class="anchor-link" href="#所以什麼是時間旅人"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對我來說，一個理想的「時間旅人」要能掌握兩種超能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能夠預測未來，洞察先機&lt;/li&gt;
&lt;li&gt;能夠回到過去，修正錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而事實上後面我們會發現要實現這兩個能力，尤其是後者，除了「資料科學」以外，我們還需要「資料工程」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/wormhole-2514312_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        掌握資料工程讓我們彷彿可以穿越時空
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="預測未來，洞察先機"&gt;預測未來，洞察先機&lt;a class="anchor-link" href="#預測未來，洞察先機"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你也是一名 DS 或是分析人員的話，應該可以猜得到，在資料科學領域裡頭，所謂的「預測未來」是指「建立某些預測模型」。&lt;/p&gt;
&lt;p&gt;只不過，光是建立出一個可以做預測的模型並不足夠。&lt;/p&gt;
&lt;p&gt;不管是簡單的 &lt;a href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"&gt;Random Forest&lt;/a&gt; 還是複雜的 &lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;Neural Network&lt;/a&gt;，要讓你的預測模型真正發揮影響力，你需要讓它實際上線做預測，而不只是活在你的 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt; 裡頭。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在資料工程領域裡，讓預測模型實際部署上線，才代表你能真正地開始「預測未來」。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/crystal-kwok-487022-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        你需要資料工程的知識來將一個 DS 做的預測模型「弄上線」
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一些常見的預測模型案例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用者在安裝 App 7 天以後會不會繼續使用&lt;/li&gt;
&lt;li&gt;顯示給使用者的廣告的點擊率&lt;/li&gt;
&lt;li&gt;推薦給使用者的文章會不會被閱讀&lt;/li&gt;
&lt;li&gt;預測使用者性別（儘管她/他沒說）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等。&lt;/p&gt;
&lt;p&gt;在目前的公司，我主要使用 &lt;a href="https://aws.amazon.com/tw/sagemaker/"&gt;Amazon SageMaker&lt;/a&gt; 、 &lt;a href="https://aws.amazon.com/tw/ecs/features/?nc1=h_ls"&gt;Amazon ECS&lt;/a&gt; 並搭配 &lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;Airflow&lt;/a&gt; 來將這些預測模型部署到 Production 環境，以對真實世界做預測。&lt;/p&gt;
&lt;p&gt;眼尖的讀者會發現，撇除模型或演算法，上述提到的工具並不實際跟「分析」有關，而比較偏向「工程」。為了發揮這些工具的最大效用，你可能需要了解 &lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;ETL 的概念&lt;/a&gt;以及&lt;a href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html"&gt;如何使用 Docker&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;想要有效地預測真實世界，這些工具不可或缺。&lt;/p&gt;
&lt;p&gt;在下篇文章，我將說明如何應用上述工具以建立可靠的預測流程。而在本文，我想強調的是另一個你能透過資料工程培養的超能力：「回到過去」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="回到過去，修正錯誤"&gt;回到過去，修正錯誤&lt;a class="anchor-link" href="#回到過去，修正錯誤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;如果你現在正努力學習資料科學，期待未來能成為一個 DS，你可能會「想像」進了一間新公司以後，前人都已經幫你把所有專案 / 產品分析需要的關鍵績效指標（&lt;strong&gt;K&lt;/strong&gt;ey &lt;strong&gt;P&lt;/strong&gt;erformance &lt;strong&gt;I&lt;/strong&gt;ndicators，即 KPI）定義完成。&lt;/p&gt;
&lt;p&gt;除此之外，所有需要分析的數據也都事先被計算好並存放在&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html#%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2"&gt;資料倉儲或是資料湖&lt;/a&gt;裡頭供你大展身手。&lt;/p&gt;
&lt;p&gt;而你所需要做的，就是開始下 &lt;a href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;SQL 查詢&lt;/a&gt;並建立分析模型。&lt;/p&gt;
&lt;p&gt;如果你的公司規模如 Facebook、Google 或是 Netflix 那麽龐大，裡頭已經有非常專業的&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;資料平台團隊&lt;/a&gt;，則或許上述為真。身為一個小小的 DS，你無須擔心什麼 KPI 的定義或是數據品質。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/data-science/sean-pollock-203658-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        規模非常大的企業讓你看到自己的渺小，但好處是身為一個 DS，你要擔心的東西可能也比較少（數據品質、KPI 定義 etc）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很多時候，這種抱持著「KPI 永遠是對的！」的假設需要承擔不小風險。&lt;/p&gt;
&lt;p&gt;一般企業（尤其是新創）在事後發現，一直以來追蹤、監視的 KPI 計算需要做修正是常有的事情。&lt;/p&gt;
&lt;p&gt;最常見的一個例子就是發現當時用來計算 KPI 的 SQL 查詢需要修正，而其原因可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;之前產品釋出新功能，但使用者利用該功能的歷史紀錄沒有被反映到 KPI 裡頭&lt;/li&gt;
&lt;li&gt;少做了數據品質的檢查，導致表格裡頭有 NULL 的使用者 ID 等問題，無法識別用戶&lt;/li&gt;
&lt;li&gt;KPI 裡頭包含了不該被計算在裡頭的雜訊&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不管是哪項，我們都需要做修正。&lt;/p&gt;
&lt;p&gt;具體來說，是修正該 SQL 查詢的邏輯、更新 KPI 定義，並將改變反映到 Production 環境。&lt;/p&gt;
&lt;p&gt;這樣你才能確保在新的一天，該 KPI 能以最正確的方式被計算出來（假設我們一天算一次該 KPI）。&lt;/p&gt;
&lt;p&gt;畢竟如同我們在奇幻旅程的第一篇：&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;新人不得不問的 2 個問題&lt;/a&gt;裡頭看到的，錯誤的 KPI 數字會讓整個數據團隊或是公司策略走錯方向，影響可說是非常深遠，得及早修正。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/tim-gouw-68319-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在你修正該 SQL 查詢並部署到 Production 環境以後，唷呼！明天我們的 KPI 就會用最正確的邏輯被計算了！&lt;/p&gt;
&lt;p&gt;不過別開心得太早。&lt;/p&gt;
&lt;p&gt;過去的數個月，甚至數年間持續被顯示在儀表板（Dashboard）上的數字可不會全部「自動地」被以新的邏輯重新計算。&lt;/p&gt;
&lt;p&gt;但同時每個 PM 都拉著你，急著向你確認，到底用了最新的定義以後，該 KPI 過去的數字會變得如何、以及其對過去的分析的影響有多大。&lt;/p&gt;
&lt;p&gt;這時你需要用新的計算邏輯 / KPI 定義來「更新」過去全部的計算結果，才能讓你公平地比較過去、現在以及未來的數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/carlos-muza-84523-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        修正 KPI 定義以後，你會想要確保過去的數據也都隨之更新
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這時候資料分析能力幫不了你，你需要的是資料工程的知識（或是一個老實的資料工程師，&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer，DE）。&lt;/p&gt;
&lt;p&gt;好消息是，如果你已經有在使用如 &lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;Airflow&lt;/a&gt; 等工作流程管理工具來管理你的 ETL，要「回到過去」並利用最新的計算邏輯來修正過去所有「錯誤數字」 並不是一件太難的事情。&lt;/p&gt;
&lt;p&gt;事實上，「將過去執行過的 ETL 工作重新執行」這個任務在各個公司屢見不鮮，在資料工程領域裡頭甚至有其專業術語：Backfill。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/backfilling.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Backfill：行家才懂的資料工程關鍵字
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Backfill 本身直接翻譯成「回填」，在資料工程領域裡頭，代表著「用新的計算邏輯 / SQL 查詢」將過去執行過的 ETL 工作重新執行。&lt;/p&gt;
&lt;p&gt;更白話的比喻，你可以想像 Backfill 就是把以前的你或是前人挖的坑、犯的錯「填好填滿」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，「計算 KPI 」就是所謂的 ETL 工作。&lt;/p&gt;
&lt;p&gt;目前我常常使用 Airflow 以及 &lt;a href="https://aws.amazon.com/tw/emr/"&gt;Amazon EMR&lt;/a&gt; 來重新執行 ETL 工作，並讓實際的計算運行在 EMR 環境上以 scale。&lt;/p&gt;
&lt;p&gt;Backfill 常見到 Airbnb 甚至自己建立了一個 &lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0"&gt;Backfill Framework&lt;/a&gt;。而在&lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;裡頭，我則詳細探討了 Airflow 與資料工程的關係，以及你可以如何利用 Airflow 來「回到過去」，修正一切的錯誤。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/time-machine.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Airflow 回到過去，修正錯誤
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就算你現在不需自己做資料工程，了解相關概念也會有所幫助。&lt;/p&gt;
&lt;p&gt;在尋找數據相關工作或者想了解某個公司的數據環境時，可以詢問該公司的 DS / DE：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        所以你們平常是怎麼做 Backfill ？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是了解一個公司內部的數據處理流程很好的一個切入點。&lt;/p&gt;
&lt;p&gt;驚艷對方的同時，又能讓你實際了解非常多該公司數據平台的細節。&lt;/p&gt;
&lt;p&gt;如果你立志成為 DS，且不希望之後操心數據品質或是自己對資料工程沒興趣，那你反而更需要搞清楚，想去的公司的數據環境如何，能否讓你專注在數據分析；如果你是想成為 DE，你能透過這個問題，逐漸了解這家公司適不適合你大展身手。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這篇文章，我非常輕描淡寫地談了作為一個 DS，我如何利用資料工程當個「時間旅人」：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;預測未來，洞察先機&lt;/li&gt;
&lt;li&gt;回到過去，修正錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/journal/wormhole.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這只是我個人的例子。&lt;/p&gt;
&lt;p&gt;實際上，每家公司的 DS 以及 DE 的工作內容都會有所不同。了解這個事實並調整期待，將幫助你找到最適合自己的工作環境。&lt;/p&gt;
&lt;p&gt;如果你對資料工程多了點興趣，可以參考之前的文章：&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;就這樣，我們下個蟲洞見！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="日誌"></category><category term="資料科學"></category><category term="資料工程"></category></entry><entry><title>資料科學文摘 Vol.7 數據技能、深度學習以及 AI 的倫理道德</title><link href="https://leemeng.tw/data-science-digest-volume-7.html" rel="alternate"></link><published>2018-10-26T08:00:00+09:00</published><updated>2018-10-26T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-26:/data-science-digest-volume-7.html</id><summary type="html">&lt;p&gt;今天讓我跟你分享 4 篇跟數據以及人工智慧相關的文章。在第一篇文章，我們將看到如何用一個簡單、有效的方式來決定應該學習什麼「數據技能」；在第二篇文章，我們則會看到如何透過數據，了解網際網路是如何快速發展成為人們每天不可或缺的一部分。接著我們會聽聽在計算神經科學領域的先驅之一，泰瑞教授解釋何謂「深度學習」以及 AI 與人類智慧如何擦出火花；最後，我們將一窺 AI 的倫理道德議題以及著名的電車難題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今天讓我跟你分享 4 篇與數據以及人工智慧相關的文章。&lt;/p&gt;
&lt;p&gt;在第一篇文章，我們將看到如何用一個簡單、有效的方式來決定應該學習什麼「數據技能」；在第二篇文章，我們則會看到如何透過數據，了解網際網路是如何快速地發展成為人們每天不可或缺的一部分。&lt;/p&gt;
&lt;p&gt;接著我們會聽聽在計算神經科學領域的先驅之一，泰倫教授解釋何謂「深度學習」以及 AI 與人類智慧如何擦出火花；最後，我們將一窺 AI 的倫理道德議題以及著名的電車難題。&lt;/p&gt;
&lt;p&gt;本週閱讀清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;Which Data Skills Do You Actually Need? This 2&amp;times;2 Matrix Will Tell You.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#The-internet-history-has-just-begun"&gt;The internet's history has just begun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#A-pioneering-scientist-explains-"&gt;A pioneering scientist explains "deep learning"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;Establishing an AI code of ethics will be harder than people think&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;廢話不多說，讓我們開始閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;
&lt;a href="https://hbr.org/2018/10/which-data-skills-do-you-actually-need-this-2x2-matrix-will-tell-you" target="_blank"&gt;Which Data Skills Do You Actually Need? This 2&amp;times;2 Matrix Will Tell You.&lt;/a&gt;&lt;a class="anchor-link" href="#Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://hbr.org/2018/10/which-data-skills-do-you-actually-need-this-2x2-matrix-will-tell-you" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/oct18_18_607367679.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="https://leemeng.tw/demystify-the-hype-of-data-science-and-its-value.html"&gt;揭開資料科學的神秘面紗&lt;/a&gt;一文提到，在一個數據時代，提升「資料科學力」這件事情不管是對你自己，或者是對公司的資料科學團隊來說都非常重要。畢竟&lt;a href="http://reports.weforum.org/future-of-jobs-2016/employment-trends/"&gt;未來將需要更多跟數據處理相關的人才&lt;/a&gt;，數據導向的企業也越來越多。&lt;/p&gt;
&lt;p&gt;但是要學的東西太多，你可能不知從何下手，或者什麼都想學。&lt;/p&gt;
&lt;p&gt;這篇文章提供了一個簡單矩陣，將那些商業分析師、資料科學家以及機器學習工程師等數據相關職業的常見技能，依照&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;學習、精通該技能所需時間（Time, X 軸）&lt;/li&gt;
&lt;li&gt;學習後能為自己及企業帶來的效用（Utility, Y 軸）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;兩個要素，劃分出一個有 4 個象限的矩陣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/data-skill-matrix.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        將常見的數據技能分門別類，以利建立學習的優先順序
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從圖中你可以看到每個象限有不同的特色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;左上 Plan：這邊的技能如人工智慧、機器學習，雖然需要花更多時間來精通，但是未來很有用，因此你應該開始規劃長期的學習計畫&lt;/li&gt;
&lt;li&gt;左下 Ignore：這裡頭的數據技能要花不少時間學習，但在未來能產生的價值卻不高，你應該盡可能忽略它們&lt;/li&gt;
&lt;li&gt;右上 Learn：這邊的技能不需花太多成本精通，但能為你自己及企業帶來不少價值，應該馬上找時間學習&lt;/li&gt;
&lt;li&gt;右下 Browse：這邊的技能用處普普，但學習成本也不高，可以瀏覽、儲存相關文章，等有需要的時候拿出來用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;事實上，上面的技能擺放位置僅供參考，因為它只是某家公司的資料團隊自己判斷的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你要思考的是，那些你想學的「數據技能」，在你現有的實力下，分別需要花多少時間精通？而它們又能在未來為你帶來多少幫助？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在你心中或是企業策略裡頭，每個數據技能有了自己的位置以後，你就能非常清楚地知道該開始規劃什麼長期學習目標、該著手學習什麼，而哪些技能可以慢點再點。&lt;/p&gt;
&lt;p&gt;以我自己為例，就有一些長期學習「機器學習」的規劃，而在日常工作時就頻繁地學習「資料科學」以及「資料工程」。&lt;/p&gt;
&lt;p&gt;這個決定學習優先順序的概念，跟我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html"&gt;資料科學文摘 Vol.5 數據科學家面臨的挑戰、儀表板設計以及未來的被駭人生&lt;/a&gt;一文中出現過的&lt;a href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;艾森豪矩陣&lt;/a&gt;有異曲同工之妙。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-internet-history-has-just-begun"&gt;
&lt;a href="https://ourworldindata.org/internet-history-just-begun" target="_blank"&gt;The internet history has just begun&lt;/a&gt;&lt;a class="anchor-link" href="#The-internet-history-has-just-begun"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://ourworldindata.org/internet-history-just-begun" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/Share-of-internet-users-cover.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然多數的我們早已習慣網際網路（Internet）的存在，但事實上以人類幾百萬年的歷史來看，網際網路的出現也不過短短 20 年，是一個非常年輕的發明（儘管它已經展現巨大影響力）&lt;/p&gt;
&lt;p&gt;現在很多人已經無法脫離 Facebook、Google Maps、維基百科甚至是 Github。不過很難想像在我出生的時候（西元 1990 年）這些服務以及網際網路本身都還不存在。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/Share-of-internet-users.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        圖中粗線代表各大洲近 3 個月有使用任何裝置上網的人口比例，每一條細線則代表一個國家。頂端粗線為北美（78 %）、最底下的粗線則為撒哈拉以南非洲（20 %）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管從上圖我們已經可以了解 20 年來網際網路的蓬勃發展，你會發現在 2016 年，上網人口也只佔全球人口的 46 %。&lt;/p&gt;
&lt;p&gt;也就是說，世界上還有一半以上的人類沒有像你閱讀這篇文章般地使用網際網路。南亞以及撒哈拉以南也只有 20 ~ 30 % 的人在上網、東亞平均則為 53 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/curtain.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;隨著網際網路在這些人口成長迅速的地區快速普及，可以合理相信，網際網路在接下來數年還會持續大幅度地改變人們的生活模式。&lt;/p&gt;
&lt;p&gt;或許 Internet 的歷史現在才正式拉開序幕。&lt;/p&gt;
&lt;p&gt;對我來說，閱讀 Max Roser 這篇文章給我的最大的啟示是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        人類生活模式的轉變只會越來越快，我們需要加速運轉自己的大腦，以跟上未來的變化。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 deep-learning""="" id="A-pioneering-scientist-explains-"&gt;
&lt;a href="https://www.theverge.com/2018/10/16/17985168/deep-learning-revolution-terrence-sejnowski-artificial-intelligence-technology" target="_blank"&gt;A pioneering scientist explains "deep learning"&lt;/a&gt;&lt;a class="anchor-link" deep-learning""="" href="#A-pioneering-scientist-explains-"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://www.theverge.com/2018/10/16/17985168/deep-learning-revolution-terrence-sejnowski-artificial-intelligence-technology" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/jbareham_170215_1460_0001_v2_4.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://mitpress.mit.edu/books/deep-learning-revolution"&gt;The Deep Learning Revolution&lt;/a&gt; 的作者 &lt;a href="https://www.salk.edu/scientist/terrence-sejnowski/"&gt;Terrence Sejnowski（後簡稱泰瑞）&lt;/a&gt;教授專注在研究神經科學（Neuroscience）以及計算機科學。&lt;/p&gt;
&lt;p&gt;在這篇採訪裡頭，他簡單解釋了人工智慧、機器學習及近年備受注目的深度學習之間的關係。一言以蔽之，就如下圖所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/couins-of-ai.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        人工智慧包含了機器學習，而機器學習包含深度學習
                        （&lt;a href="https://towardsdatascience.com/cousins-of-artificial-intelligence-dda4edc27b55" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想平常有在閱讀本部落格的讀者應該都十分熟悉這個關係，不須贅述。不過了解深度學習為何變得如此熱門的人就不多了。&lt;/p&gt;
&lt;p&gt;一切要從 2012 年，全世界最大的 AI 學術會議 &lt;a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems"&gt;NIPS&lt;/a&gt; 說起。當年深度學習裡頭最關鍵的技術 &lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"&gt;Backpropagation&lt;/a&gt; 的發明者 &lt;a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton"&gt;Geoffrey Hinton&lt;/a&gt; 教授與他的團隊展示了如何利用深度學習，一口氣將擁有 10,000 個圖片分類以及多達 1,000 萬張照片的 &lt;a href="http://www.image-net.org/"&gt;ImageNet 分類挑戰&lt;/a&gt;的錯誤率降低近 20 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/imagenet.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這之前，儘管已經有非常多的研究，這個挑戰的錯誤率每年下降不到 1 %。我們可以說，深度學習模型的出現，瞬間縮減了 20 年的研究時間。在那之後，人人爭相學習，開啟「大深度學習」時代。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在人工智慧發展的背後推手主要即為深度學習，而深度學習的概念則來自於我們對人類大腦的理解。&lt;/p&gt;
&lt;p&gt;泰瑞教授表示我們正處於人工智慧以及人類智慧相互匯合的時代：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        AI 與人類智慧正在匯合。當我們越了解大腦運算的方式，就會越傾向將該知識反映到 AI 上面，讓 AI 變得更強大。但同時，更強大的 AI 也讓我們用全新的方式以及理論來了解人類大腦以及上千萬神經元的運作方式。因此你可以看到在「神經科學」以及「人工智慧」之間有一個不斷互相學習的循環。
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ Terrence&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個論點跟我們之前在&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;一文中聊到的想法十分類似：到最後，我們及我們的下一代將不在只是從其他人類學習知識，而是向那些我們創造出來的 AI 學習。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/learn-from-machine/andy-kelly-402111-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        未來教育模式的可能改變：從機器 / AI 中學習
                        （圖片來源：&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html" target="_blank"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;舉個簡單例子，等到語音辨識的技術更為成熟，以後你的小孩可能不再需要一位昂貴的英文老師教他 / 她怎麼唸英文單字，而是透過一個 24 小時不休息的 AI，聆聽由深度學習自動產生的擬人發音來學習英文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;
&lt;a href="https://www.technologyreview.com/s/612318/establishing-an-ai-code-of-ethics-will-be-harder-than-people-think/" target="_blank"&gt;Establishing an AI code of ethics will be harder than people think&lt;/a&gt;&lt;a class="anchor-link" href="#Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://www.technologyreview.com/s/612318/establishing-an-ai-code-of-ethics-will-be-harder-than-people-think/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/timeline-ai-now_1.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        人工智慧的進步一日千里，快到我們還無法為其建立一套完善的道德準則。更甚者，完美的準則一開始就不存在。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 的快速發展讓我們已經（快要）可以把一些複雜任務如臉部辨識、自動駕駛等工作交給機器處理，從此過著輕鬆快樂的生活。&lt;/p&gt;
&lt;p&gt;但你知道事情從來沒有那麼單純。&lt;/p&gt;
&lt;p&gt;除了合乎程式邏輯以外，AI 在執行這些複雜任務時，很多時候會牽涉到道德問題。那麼又應該要由誰來決定這些 AI 在執行任務時應該要遵守什麼規定呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/Artificial-intelligence-human-looking-robot-thinking-machine-world.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        「思考」中的 AI
                        （&lt;a href="https://engineercalcs.com/ethics-and-ai-the-future-dilemma-humans-will-face/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;美國麻省理工大學 MIT 開發了一個名為「&lt;a href="http://moralmachine.mit.edu/"&gt;道德機器（Moral Machine）&lt;/a&gt;」的網站，裡頭重現了著名的&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%89%E8%BD%A8%E7%94%B5%E8%BD%A6%E9%9A%BE%E9%A2%98"&gt;電車難題&lt;/a&gt;，目的就是為了告訴大家，每個人都有不同的道德標準，要為 AI 建立一套所有人都能滿意的道德準則非常困難。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/moral-machine.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        自動駕駛版本的電車問題：誰該活？誰死了也沒關係？AI 該遵守誰的道德準則？
                        （圖片來源：&lt;a href="http://moralmachine.mit.edu/" target="_blank"&gt;麻省理工大學「道德機器」網頁截圖&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你點進去回答完 13 道難題了嗎？&lt;/p&gt;
&lt;p&gt;如果還沒，我強烈建議你點進去&lt;a href="http://moralmachine.mit.edu/"&gt;該網站（站內可選中文）&lt;/a&gt;，並利用自己的道德準則決定自動駕駛車的運行方向，再實際看看有多少人以及動物因此受到影響，並了解其他人下的決定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/button-161555_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        哪邊的按鈕你點比較多次，左邊還是右邊？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你跟我一樣，花了不少時間掙扎猶豫，你就會了解「奠定 AI 所需要遵守的道德準則」這個課題有多麽困難。&lt;/p&gt;
&lt;p&gt;就算你好不容易決定了，你也知道該判斷並不完美，你可能之後會後悔，且也不是所有人都同意你的決定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/humanism.jpeg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%BA%BD%E7%BA%A6%E5%A4%A7%E5%AD%A6%E6%B3%95%E5%AD%A6%E9%99%A2"&gt;紐約大學法學院&lt;/a&gt;的 &lt;a href="https://en.wikipedia.org/wiki/Philip_Alston"&gt;Philip Alston&lt;/a&gt; 教授則認為我們應該以「維護人權」為最高判斷原則，建立不會傷害到人類的 AI。以上面的自動駕駛來說，一個以「人文主義」為原則的自動駕駛車會選擇避開人群，而往一整群貓咪撞下去。&lt;/p&gt;
&lt;p&gt;人文主義或許不完美，但或許是一個不錯的基準點。&lt;/p&gt;
&lt;p&gt;只是我擔心的是，在這數據主義以及資本主義橫行的年代，人文主義最後是否能站得住腳。&lt;/p&gt;
&lt;p&gt;如果自動駕駛還搭配了臉部辨識系統，利用大數據分析以及搜尋&lt;a href="https://www.legalaidnyc.org/nypd-gang-database/"&gt;犯罪記錄系統&lt;/a&gt;，自動車發現前方分別是一隻貓以及一個罪犯，它能否選擇撞人不撞貓呢？&lt;/p&gt;
&lt;p&gt;畢竟以「數據主義」的立場，「人」不再是至高無上的存在，一切由數據說的算。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;呼！以上就是本週文摘的內容啦！&lt;/p&gt;
&lt;p&gt;希望這些跟數據、AI 相關的文章以及我個人的想法有刺激到你的思考，讓你的生活變得豐富了一些，並實際思考做點什麼。&lt;/p&gt;
&lt;p&gt;歡迎留言跟我說說你自己的想法、分享這篇文章或是點擊下面的訂閱按鈕。&lt;/p&gt;
&lt;p&gt;最重要的，記得去&lt;a href="http://moralmachine.mit.edu/"&gt;道德機器網站&lt;/a&gt;實際做一下題目，感受一下 AI 時代的倫理難題。&lt;/p&gt;
&lt;p&gt;就這樣，我們下次見啦！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.6 人類壽命大進展、GAN、數據工廠以及產品分析</title><link href="https://leemeng.tw/data-science-digest-volume-6.html" rel="alternate"></link><published>2018-10-14T14:00:00+09:00</published><updated>2018-10-14T14:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-14:/data-science-digest-volume-6.html</id><summary type="html">&lt;p&gt;這週我們一樣保持閱讀的「營養均衡」，從全球平均壽命變化的資料視覺化、深度學習最夯的「對抗生成網路」話題、產品分析框架到理解何謂「數據工廠」，我希望能讓閱讀本文摘的你，廣泛地了解各領域跟「資料」相關的議題，並進一步找出自己的興趣，加以深度探索。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文摘來到第 6 篇，不知道這是你看的第幾篇呢？&lt;/p&gt;
&lt;p&gt;這週我們一樣保持閱讀的「營養均衡」，從全球平均壽命變化的資料視覺化、深度學習最夯的「對抗生成網路」話題、產品分析框架到理解何謂「數據工廠」，我希望能讓閱讀本文摘的你，廣泛地了解各領域跟「資料」相關的議題，並進一步找出自己的興趣，加以深度探索。&lt;/p&gt;
&lt;p&gt;本週閱讀清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;Twice as long &amp;ndash; life expectancy around the world&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;Interview with Deep Learning Researcher and The GANfather: Dr. Ian Goodfellow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data-Factories"&gt;Data Factories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;Engagement Drives Stickiness Drives Retention Drives Growth&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;
&lt;a href="https://ourworldindata.org/life-expectancy-globally" target="_blank"&gt;Twice as long &amp;ndash; life expectancy around the world&lt;/a&gt;&lt;a class="anchor-link" href="#Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://ourworldindata.org/life-expectancy-globally" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/life-expectancy.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在全球健康以及公衛還是存在很多不平等，但別忘了我們已經取得巨大進展。&lt;/p&gt;
&lt;p&gt;如同我們上週在&lt;a href="https://leemeng.tw/gapminder.html"&gt;如何用 30 秒了解台灣發展與全球趨勢：用 GapMinder 培養正確世界觀&lt;/a&gt;一文中聊到，好的資料視覺化可以幫助我們快速地了解世界。這週牛津大學的經濟學家 &lt;a href="https://www.maxroser.com/about/"&gt;Max Roser&lt;/a&gt; 用 3 張橫跨 2 世紀的世界地圖，來告訴我們全球平均壽命（Life Expectancy）的變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/3-world-maps-of-life-expectancy-e1538651530288.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以看到這 200 年來，生活在世界上的人們經歷了 3 個階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 1800 年以前所有人的平均壽命 &amp;lt; 40 歲，大部分兒童早夭&lt;/li&gt;
&lt;li&gt;在 1950 年，部分地區健康大幅改善，歐美及日本的平均壽命為 60 歲，為非洲整體平均的 2 倍，鴻溝顯而易見&lt;/li&gt;
&lt;li&gt;在 2015 年，幾乎全球所有地區都能活到 60 歲以上，鴻溝逐漸縮小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們都希望自己親人及朋友活得長久。就是因為這樣，你更應該感激這 200 年人類取得的進步。&lt;/p&gt;
&lt;p&gt;近 2 世紀人類在健康狀況改善的卓越成就，套句 Max Roser 的說法就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在人類歷史上，這是我們第一次改善了整個人群的健康狀況。在人類健康狀況停滯千年後，封印終於解除。
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ Max Roser&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，在 1950 年，台灣的平均壽命為 55.5 歲，經過了 65 年，來到了 80 歲。平均每 3 年，台灣人的平均壽命增加 1 歲，成長速度不可小覷。&lt;/p&gt;
&lt;p&gt;你也可以用 &lt;a href="https://ourworldindata.org/life-expectancy"&gt;Our World in Data&lt;/a&gt; 提供的圖表來看看全球變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;iframe src="https://ourworldindata.org/grapher/life-expectancy?year=2015" style="width: 100%; height: 600px; border: 0px none;"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;
&lt;a href="https://hackernoon.com/interview-with-deep-learning-researcher-and-the-ganfather-dr-ian-goodfellow-cd300863ecff" target="_blank"&gt;Interview with Deep Learning Researcher and The GANfather: Dr. Ian Goodfellow&lt;/a&gt;&lt;a class="anchor-link" href="#Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://hackernoon.com/interview-with-deep-learning-researcher-and-the-ganfather-dr-ian-goodfellow-cd300863ecff" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/v2-11b2d0d097085a51360d3756aff65435_1200x500.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;伊恩．古德費洛（Ian Goodfellow）是 &lt;a href="https://ai.google/research/people/105214"&gt;Google Brain 的研究科學家&lt;/a&gt;，最知名的成就是在 2014 年推出&lt;a href="https://buzzorange.com/techorange/2018/03/12/google-super-intern/"&gt;生成對抗網路（Generative Adversarial Network, 簡稱 GAN）&lt;/a&gt;。GAN 最基本的概念是讓兩個神經網路互相對抗，讓模型可以依靠較少的人類介入以及訓練資料，自己學會高度複雜的工作。自從那之後，GAN 領域的研究一日千里，現在 &lt;a href="https://arxiv.org/abs/1406.2661"&gt;arXiv 上該論文有超過 5,000 次引用&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/gan-example.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        GAN 有很多用途，像是自動產生高畫質圖片
                        （圖片來源：&lt;a href="https://youtu.be/AJVyzd0rqdc?t=575" target="_blank"&gt;NIPS 2016 Tutorial&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;GAN 有非常多「用途」，像是自動產生圖片、創作音樂、寫詩或是製造假新聞。但在這篇文摘裡頭，讓我們先專注於這篇訪問伊恩的內容。&lt;/p&gt;
&lt;p&gt;在這篇訪談裡頭，伊恩給想開始研究 ML 的人一些建議：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;徹底學好基礎。像是寫程式、除錯、並學習機率及線性代數。很多時候在研究 ML 的時候，幫助你最多的是扎實的基礎，而不是非常前衛的想法（這是他從 Google Brain 創立者&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;得到的建議）&lt;/li&gt;
&lt;li&gt;沒有什麼運算資源時，要選對研究主題。（沒有像是 Google 那樣等級的運算資源的話，就不要想去實現全世界最準的 &lt;a href="http://www.image-net.org/"&gt;ImageNet&lt;/a&gt; 分類器）&lt;/li&gt;
&lt;li&gt;一開始找個人家已經做過的題目來磨練你的 ML 能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最後一點需要額外解釋一下。&lt;/p&gt;
&lt;p&gt;如果你在練習 ML 的時候，選擇跟隨前人「已經成功」的東西來實作的話，這樣就算自己實作出來的模型表現不好，你也知道只是你的實作、基本功出了問題，而不是這個點子錯了。接著只要回去複習基本概念、加強實作功力即可。&lt;/p&gt;
&lt;p&gt;但如果你的 ML 的實作能力沒到一個水平，然後又馬上想要嘗試一個天馬行空的點子／演算法，最後實作出來失敗，你很難知道，到底是點子本身有瑕痴，還是因為你實作能力差而出問題。&lt;/p&gt;
&lt;p&gt;另外如果你現在就想開始了解 GAN 的話，可以試試 &lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN lab&lt;/a&gt;，在網頁上玩玩生成對抗網路。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/gan-lab.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        GAN lab 讓你可以利用網頁瀏覽器直接探索 GAN 並了解其運作原理
                        （&lt;a href="https://poloclub.github.io/ganlab/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data-Factories"&gt;
&lt;a href="https://stratechery.com/2018/data-factories/" target="_blank"&gt;Data Factories&lt;/a&gt;&lt;a class="anchor-link" href="#Data-Factories"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://stratechery.com/2018/data-factories/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/data-factory.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身處數據時代，我們應該更關心自己的資料被怎麼利用。&lt;/p&gt;
&lt;p&gt;這篇文章想說的是，其實 Facebook、Google 以及其他廣告業者都是所謂的「數據工廠」，而如果政府要立法規範這些工廠，最有效的方法就是請它們允許使用者看到工廠裡頭的情況。&lt;/p&gt;
&lt;p&gt;我認為「數據工廠」是對 Google 及 Facebook 這種利用數據來創造價值的公司的一個貼切比喻。因為他們除了使用者的行為數據，也從廣告代理商以及第三方數據收集業者取得大量資料。透過將這些原始資料「加工」並產生衍生價值，據此創造巨大收益。&lt;/p&gt;
&lt;p&gt;然而這些「數據工廠」跟一般傳統的「工廠」有一個非常大的差異：誰都無法窺探該「工廠」的內部情況。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/P1-BP885_NIKE3_GR_20140421170339.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;記者可以去 Nike 製造足球的工廠裡頭拍拍照，讓世人知道這些工廠內部的運作情況，但在這年代，你無法去 Facebook 裡頭拍拍照，了解他們是怎麼利用各式各樣的演算法，來「活用」所有跟你相關的資料（你按過讚的內容、瀏覽過的網頁，甚至是你為了雙重認證而輸入的電話號碼）。&lt;/p&gt;
&lt;p&gt;因此立法者以及那些關心自己數據可能被濫用的使用者要了解的是，要規範 Facebook 這種公司，不能只要求 Facebook 公布他們從使用者手上拿到的原始資料（Raw Data），而是應該公布那些他們利用演算法以及結合多種數據來源所產生出的 user profile，讓使用者自行判斷要不要繼續讓該公司使用自己的 profile。&lt;/p&gt;
&lt;p&gt;雖然多數人其實只在乎 Facebook 能不能秀給他們更多的動物影片以及朋友動態，不太在意自己的數據被怎麼拿來獲利。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;
&lt;a href="https://medium.com/swlh/engagement-drives-stickiness-drives-retention-drives-growth-3a6ac53a7a00" target="_blank"&gt;Engagement Drives Stickiness Drives Retention Drives Growth&lt;/a&gt;&lt;a class="anchor-link" href="#Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://medium.com/swlh/engagement-drives-stickiness-drives-retention-drives-growth-3a6ac53a7a00" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/product-analysis-framework.jpeg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在以提供 App 作為服務的公司裡頭，資料科學家大都會需要進行產品分析（Product Analysis）進而改善自家產品。&lt;/p&gt;
&lt;p&gt;這篇文章介紹了 App 產業以及我常在使用的一個分析框架，讓你可以感受一下，實際上 DS 在做產品分析的時候，要看些什麼東西。&lt;/p&gt;
&lt;p&gt;有做過產品分析的你，應該能很快地理解這個流程圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/engagement-framework.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖最重要的核心概念是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        當使用者發現你產品的價值以後，他們會主動回來。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當使用者發現你的產品的價值後，就會進一步參與使用（Engage），而好的參與程度（Engagement Level）會增加他們對此產品的黏著度（Stickiness），進一步讓他們願意回來繼續使用你的產品（Retentaion）。而有了越來越多的忠實用戶，就能進一步帶給你的產品成長（Growth），不斷持續地這個好的循環。&lt;/p&gt;
&lt;p&gt;在我們理解每個階段代表的意義以後，我們還需要一些指標（indicators）來實際幫助我們了解產品在每個階段的表現。&lt;/p&gt;
&lt;p&gt;像是 Engagement 底下的 TS/DAU 即分別代表「使用時間（&lt;strong&gt;T&lt;/strong&gt;ime &lt;strong&gt;S&lt;/strong&gt;pent）」以及「每天活躍使用者人數（&lt;strong&gt;D&lt;/strong&gt;aily &lt;strong&gt;A&lt;/strong&gt;ctive &lt;strong&gt;U&lt;/strong&gt;sers）」。這兩個都很常被拿來衡量使用者參與一個產品的程度。有了好的參與程度，一個使用者就更有可能在安裝 7 天後還回來繼續使用（Retention 階段的 D7）。&lt;/p&gt;
&lt;p&gt;這邊沒有篇幅一個個介紹圖中的指標，但要注意的是，在看指標的時候，要去想它是早期指標（Early Indicators）還是延遲指標（Lagging Indicators）。&lt;/p&gt;
&lt;p&gt;比方說你的最終目標是提升每月活躍使用者人數（&lt;strong&gt;M&lt;/strong&gt;onthly &lt;strong&gt;A&lt;/strong&gt;ctive &lt;strong&gt;U&lt;/strong&gt;sers，最右邊 Growth 階段的 MAU）這個延遲指標（延遲在於要過了 1 個月你才知道結果），那你除了看 MAU 以外，還需要去看 TS/DAU 等早期指標。因為 MAU 需要一個月的時間才能計算出來，有時候產品表現差，你從每天使用的人數下降就可以略知一二，可以馬上做調整而不需等到一個月後 MAU 數字難看才大傷腦筋。&lt;/p&gt;
&lt;p&gt;及早發現，及早治療。&lt;/p&gt;
&lt;p&gt;產品分析領域在網路上的資源不多，有機會再跟你分享我的心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;呼！這就是本週文摘的內容啦！希望你閱讀後有感覺自己腦中多了點東西，變得聰明了一點。&lt;/p&gt;
&lt;p&gt;社會人口、機器學習、產品分析以及數據隱私的議題，你會發現這些文章儘管領域大相徑庭，他們都與「數據」脫離不了關係。&lt;/p&gt;
&lt;p&gt;在這個時代，任何人的日常生活中都充斥著大量數據。我們需要重新思考、檢視並理解身邊的數據，甚至活用它們來創造更好的世界。&lt;/p&gt;
&lt;p&gt;這也是我寫這系列文章的原因，希望讓更多人（包含我自己）能更輕鬆地用數據理解這個世界。歡迎你點擊下面的訂閱按鈕，未來跟著我一起繼續探索這個世界：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>如何用 30 秒了解台灣發展與全球趨勢：用 GapMinder 培養正確世界觀</title><link href="https://leemeng.tw/gapminder.html" rel="alternate"></link><published>2018-10-08T01:50:00+09:00</published><updated>2018-10-08T01:50:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-08:/gapminder.html</id><summary type="html">&lt;p&gt;這篇文章提供你一個輕鬆探索台灣與世界的資料視覺化工具：GapMinder 中文版。除了工具本身以外，文中會透過大量動態的資訊圖表以及各國公開數據來帶你探索台灣以及世界。閱讀本文之後，你將了解全球的發展趨勢、對台灣的社會、經濟以及能源發展有個基礎認知，並重新建立一個宏觀、積極的世界觀。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;
再稍微花個 5 秒鐘咀嚼一下你所看到的。&lt;/p&gt;
&lt;p&gt;現在問你自己，你看到了什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個資訊爆炸的時代，大腦為了保護你的心智不被大量數據淹沒，可能已經很習慣性地忽視眼前數據其背後所隱含的意義。&lt;/p&gt;
&lt;p&gt;但讓我提醒你一下，就在剛剛的 30 秒內，全世界過去 200 年至今的經濟（所得收入）與社會（平均壽命）發展狀況活生生地重現在你眼前！&lt;/p&gt;
&lt;p&gt;這可不是小時候歷史老師會 / 能秀給你看的東西（至少我的老師沒有）我不知道你感受如何，但在我&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen"&gt;第一次見識到此圖&lt;/a&gt;的時候，內心可說是激動得不得了！&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen#t-249222" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/gapminder/ted-video-screenshot.jpg" style=""/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
    瑞典全球公衛教授 &lt;a href="https://zh.wikipedia.org/zh-tw/%E6%B1%89%E6%96%AF%C2%B7%E7%BD%97%E6%96%AF%E6%9E%97" target="_blank"&gt;漢斯・羅斯林&lt;/a&gt;
&lt;br/&gt;
    2006 年在 TED 利用上面的泡泡圖向觀眾們解說世界的經濟與社會發展
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;將專注拉回台灣。看著台灣的發展軌跡，你甚至還可以發現一些值得注意的現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1939 至 1945 年，人民所得以及平均壽命走倒車（二戰）&lt;/li&gt;
&lt;li&gt;1945 至 1953 年國民平均壽命的大幅提升，所得回歸正常&lt;/li&gt;
&lt;li&gt;1960 年代以後，經濟與社會的持續穩定發展&lt;/li&gt;
&lt;li&gt;2000 年後成長趨緩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了本身的發展軌跡以外，還可以發現到了 21 世紀，台灣在右上角，名列前茅。&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/taiwan-development.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/taiwan-development.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    泡泡圖除了可以讓我們觀察世界趨勢，也能同時了解台灣的發展軌跡以及與其他國家的相對位置
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剛剛在看圖的時候，你應該還有很多其他發現且迫不及待地想要了解更多。&lt;/p&gt;
&lt;p&gt;事實上，如果在看了剛剛的動畫以後，你突然渴望想要知道更多是很正常的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        重要的是不要停止問問題，好奇心有其存在的理由。
        &lt;br/&gt;
&lt;span style="float:right"&gt;─ 愛因斯坦&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;如果你現在想要更加地了解台灣或是其他不同的國家在各種社會 / 經濟 / 健康指標的發展（如所得收入、兒童死亡率、二氧化碳排放量等），我鼓勵你先上去改改 X 或 Y 軸、點選不同國家，查看結果以後再繼續往下讀。&lt;/p&gt;
&lt;p&gt;畢竟文章跑不掉，你的好奇心則可能在幾秒鐘後消逝：）&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;你回來了嗎？&lt;/p&gt;
&lt;p&gt;你現在應該已經暸解，透過值得信賴的數據來源（比方說&lt;a href="https://www.gapminder.org/data/documentation/gd004/"&gt;聯合國&lt;/a&gt;）以及良好的呈現方式（文章開頭的泡泡圖），能讓你在很短時間內「正確」地掌握全世界趨勢以及台灣的發展狀況。&lt;/p&gt;
&lt;p&gt;儘管媒體總是報憂不報喜，你會發現全世界大致上變得越來越好。&lt;/p&gt;
&lt;p&gt;你也會發現以「人均收入」以及「平均壽命」的角度來看，台灣的表現在全世界也是數一數二，這點值得我們欣慰及驕傲。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/factfulness-cover.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    《真確》是 2018 年由漢斯・羅斯林（Hans Rosling）所撰。（圖片來源：&lt;a href="https://meet.eslite.com/tw/tc/product/201807030007" target="_blank"&gt;迷誠品&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在《真確》這本書裡，羅斯林教授闡述如何利用數據以及正確心態來理解世界，是一本深具啟發性的著作。而「泡泡圖」則是他在傳達知識時，經常使用到的工具。&lt;/p&gt;
&lt;p&gt;首先你需要知道，文中的泡泡圖（Bubble Chart）的開發以及各個國家的數據整理，並非由我獨自完成，而是由漢斯・羅斯林教授與他所創辦的 &lt;a href="https://www.gapminder.org/"&gt;GapMinder 基金會&lt;/a&gt;從多個國際組織（如聯合國、國際衛生組織、世界銀行等）&lt;a href="https://github.com/Gapminder"&gt;蒐集、整理&lt;/a&gt;而來。（給他們點掌聲！）&lt;/p&gt;
&lt;p&gt;事實上，你可以直接使用&lt;a href="https://www.gapminder.org/tools/"&gt;官方的泡泡圖&lt;/a&gt;，或是像本文一樣，依照&lt;a href="https://bl.ocks.org/angieskazka/ed82b664173a9023fa8a"&gt;這邊的教學&lt;/a&gt;來將泡泡圖內嵌在你自己的網站裡頭。&lt;/p&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;「既然官方都已經有泡泡圖了，為何你要在這裡再弄一個出來呢？」&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/emily-morter-188019-unsplash.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;非常好的問題，但讓我先賣個關子。&lt;/p&gt;
&lt;p&gt;我會在&lt;a href="#為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;/a&gt;章節裡頭仔細說明。（提示：跟台灣有關係）&lt;/p&gt;
&lt;p&gt;在這邊想先讓你知道的是，文章接下來會說明泡泡圖裡頭有什麼台灣數據可供你探索，以及提供一些探索台灣以及世界的例子，讓你在了解世界的同時熟悉泡泡圖的使用方式。&lt;/p&gt;
&lt;p&gt;等你熟悉泡泡圖以後，可以利用它來更深入瞭解台灣與以及任何你有興趣的國家，並培養正確的世界觀。最重要的是，在有了正確思維以後，你能怎樣讓世界以及台灣變得更加美好。&lt;/p&gt;
&lt;p&gt;前言很長，不過接下來才是重頭戲。準備好了就跟上我們的探索之旅吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本文章節"&gt;本文章節&lt;a class="anchor-link" href="#本文章節"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#有什麼台灣數據可供探索？"&gt;有什麼台灣數據可供探索？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#用泡泡圖探索世界"&gt;用泡泡圖探索世界&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#媽媽不生寶寶了：生育率大幅下降"&gt;媽媽不生寶寶了：生育率大幅下降&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;怎麼創造乾淨未來：煤炭消耗與環境污染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#民主大躍進：我很自由，不過不想參與政治"&gt;民主大躍進：我很自由，不過不想參與政治&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#story-behind-data"&gt;看到數據背後的故事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#你能怎樣讓世界更好？"&gt;你能怎樣讓世界更好？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;a class="anchor-link" href="#為何需要本文的泡泡圖？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;你可能在想，何必要大費周章地弄出自己的泡泡圖。畢竟，只要使用 GapMinder 基金會（以下簡稱 GapMinder）&lt;a href="https://www.gapminder.org/tools/#"&gt;官方釋出的泡泡圖&lt;/a&gt;就可以透過數據來探索「全世界」與「台灣」了啊？&lt;/p&gt;
&lt;p&gt;這句話只對了前半段。&lt;/p&gt;
&lt;p&gt;第一個沒有那麼嚴重但是有點令人困擾的問題是，目前官方的泡泡圖只有英文，沒有繁體中文。&lt;/p&gt;
&lt;p&gt;雖然台灣人的英文能力普遍不差，但是要所有人在看到每個國家的英文名字後馬上反應出來，可不是一件簡單的事情。&lt;/p&gt;
&lt;p&gt;你還有多少把握可以認出東帝汶或柬埔寨的英文名字？（提示：下圖有其中一個）&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/chuttersnap-176806-unsplash.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;更不用說聯合國以及各個國際組織定義的各式各樣社會 / 經濟 / 公衛指標的英文了。（還記得結核病、旱災或是償債出口比怎麼唸嗎？）&lt;/p&gt;
&lt;p&gt;我們看泡泡圖的主要目的是為了瞭解世界，而不是學習翻譯各種英文專業術語。&lt;/p&gt;
&lt;p&gt;就算這樣講，英翻中或許問問 Google 還是勉強可以解決。但官方泡泡圖存在的第二個問題，則非常致命。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/official-page.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    GapMinder 釋出的&lt;a href="https://www.gapminder.org/tools/#" target="_blank"&gt;泡泡圖&lt;/a&gt;截圖。在右邊的清單搜尋「 Taiwan 」不會有結果
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在我撰寫此文的這個時間點（2018 年 10 月），在 &lt;a href="https://www.gapminder.org/tools/#"&gt;GapMinder 上的泡泡圖&lt;/a&gt;裡頭，你並無法找到「 Taiwan 」的存在。&lt;/p&gt;
&lt;p&gt;沒錯，你可以現在&lt;a href="https://www.gapminder.org/tools/#"&gt;去搜尋看看&lt;/a&gt;。然後你會發現有 2,300 多萬人口的台灣並不存在 GapMinder 的泡泡圖之中。&lt;/p&gt;
&lt;p&gt;依據 &lt;a href="https://getsatisfaction.com/gapminder/topics/what-happened-to-taiwan-it-used-to-be-included" target="_blank"&gt;GapMinder 的說法&lt;/a&gt;，泡泡圖預設只顯示&lt;a href="http://www.un.org/en/member-states/#gotoT" target="_blank"&gt;聯合國會員國&lt;/a&gt;。因此理所當然地，台灣不會被顯示在上面。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/keith-lee-803568-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
    儘管沒有在聯合國裡頭，在台灣努力生活的人們確確實實地存在著（&lt;a href="https://unsplash.com/photos/nYq3nW9Z9ok" target="_blank"&gt;圖&lt;/a&gt;為寧夏夜市）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;2018 年 7 月，GapMinder 表示&lt;a href="https://getsatisfaction.com/gapminder/topics/i-really-want-to-know-what-is-the-latest-situation-of-those-countries" target="_blank"&gt;他們正在想辦法讓非聯合國會員國（如台灣、香港）也能被加到泡泡圖裡頭&lt;/a&gt;，但自從那之後已經過了數個月。&lt;/p&gt;
&lt;p&gt;我真的不怪他們，畢竟他們是非營利機構，人手有限且已經為世界做出很多貢獻了。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/united-nations-headquarters.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    聯合國總部，紐約（圖片來源：&lt;a href="https://foreignpolicy.com/2017/03/13/white-house-seeks-to-cut-billions-in-funding-for-united-nations/" target="_blank"&gt;Foreign Policy&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;只是，我無法忍受在閱讀完《真確》並想要開始認真地探索這個世界的時候，發現裡頭竟然沒有熟悉的台灣。&lt;/p&gt;
&lt;p&gt;後來的故事你大概猜得到了。我開始研究 GapMinder &lt;a href="https://github.com/vizabi/vizabi"&gt;製作泡泡圖的程式碼&lt;/a&gt;以及&lt;a href="https://github.com/open-numbers/ddf--gapminder--systema_globalis"&gt;數據儲存格式&lt;/a&gt;。我寫些程式、閱讀聯合國以及各個國際組織的相關文獻以後，把台灣「駭」進泡泡圖的國家列表裡頭，並將裡頭所有國家以及（幾乎）所有指標翻譯成中文。你在文章開頭看到的泡泡圖就這樣誕生了。（感謝 Google 大神以及咖啡因！）&lt;/p&gt;
&lt;p&gt;現在，在了解本文泡泡圖的典故之後，讓我們看一下目前的泡泡圖裡頭有哪些台灣數據可供你探索。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="有什麼台灣數據可供探索？"&gt;有什麼台灣數據可供探索？&lt;a class="anchor-link" href="#有什麼台灣數據可供探索？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;GapMinder 將所有搜集來的資料整理在這個 &lt;a href="https://github.com/open-numbers/ddf--gapminder--systema_globalis"&gt;Github Repo&lt;/a&gt; 裡頭，也是本文泡泡圖的數據來源。&lt;/p&gt;
&lt;p&gt;理想上，每個指標（如二氧化碳排放量、國民平均壽命、人均收入）都會（或者說都要）包含每個國家及地區每年的資料才能方便我們做比較。但你可以想像，這不太可能實現。&lt;/p&gt;
&lt;p&gt;實際上，依照不同國家的數據開放狀況、國際組織蒐集數據的方法差異，都有可能造成指標裡頭沒有某些國家的資料。&lt;/p&gt;
&lt;p&gt;以台灣為例，透過分析 GapMinder 數據來源，我們可以知道，截至目前為止，泡泡圖裡頭總共有 500 多個指標，其中約有 40 % （ 200 個 ）指標含有台灣數據。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/gapminder-indicators-with-twn.svg"/&gt;
&lt;/center&gt;
&lt;center&gt;
    （跟本文的泡泡圖以及數據來源一樣，此圖的資訊也會定期更新）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;以大分類來看的話，「健康」及「工作」分類有較多的資料可供我們檢視台灣的狀況並同時與其他國家做比較；相較之下，「社會」及「人口」涵蓋的台灣指標較少，公共建設分類則只有 1 個（交通死亡人數）。&lt;/p&gt;
&lt;p&gt;健康分類中，屬男女的「癌症」相關數據最為完整：大腸癌、胃癌、肝癌、乳癌、攝護腺癌 .. 應有盡有。&lt;/p&gt;
&lt;p&gt;工作分類則有各個年齡層的失業 / 就業率及「勞動參與率」等指標，你可以自行稍後在泡泡圖上查看。&lt;/p&gt;
&lt;p&gt;不過實際上，你也不需記住哪些分類有多少台灣數據。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/menu-demo.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
    利用泡泡圖的選單，我們可以馬上知道每個分類底下有多少指標、有哪些指標有台灣數據、最早的年份為何
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果你剛剛有玩泡泡圖的話，可能會好奇在每個分類後面的數字代表什麼。圖中健康分類後面的 &lt;code&gt;（63/166）&lt;/code&gt;　代表在泡泡圖中，健康分類底下總共有 166 個指標，而其中的 63 個有台灣數據。這跟我們上一張長條圖吻合。&lt;/p&gt;
&lt;p&gt;現在看到上圖第三欄的「肺癌病例數」：指標名稱後面的 &lt;code&gt;（1990 ~&lt;/code&gt; 則代表在該指標中，台灣數據最早可以追溯到西元 1990 年。有了這些額外資訊，可以讓你更方便地探索台灣與世界的關係。&lt;/p&gt;
&lt;p&gt;值得一提的是，以上的結果僅代表 GapMinder 目前有的數據。他們持續努力地在添加新的數據，而我也預計在未來導入更多的台灣數據。但現在，先讓我們從已有的指標裡頭選幾個來探索看看吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用泡泡圖探索世界"&gt;用泡泡圖探索世界&lt;a class="anchor-link" href="#用泡泡圖探索世界"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在《真確》裡頭，漢斯・羅斯林教授已經向我們展示了很多很棒的泡泡圖範例。而在這個章節裡頭，我會列出一些自己利用泡泡圖探索世界以及了解台灣的例子。&lt;/p&gt;
&lt;p&gt;（小提醒：底下的圖幾乎都是動態的。如果你發現它們沒有動靜，請另外使用電腦或是手機上的瀏覽器開啟此頁連結以最佳化閱讀體驗，謝謝！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="媽媽不生寶寶了：生育率大幅下降"&gt;媽媽不生寶寶了：生育率大幅下降&lt;a class="anchor-link" href="#媽媽不生寶寶了：生育率大幅下降"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多我們以為是常態的事物，事實上在幾十年前完全不存在。&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/decline-of-female-fertility.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/decline-of-female-fertility.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;以婦女人均嬰兒數為例，在 1950 年前，跟亞洲大多數國家相同，台灣每個婦女平均有 6 個嬰兒。現代大多數的年輕人應該無法想像這件事情。&lt;/p&gt;
&lt;p&gt;但我們可以看到從 1960 年代開始，婦女人均嬰兒數以不可思議的速度溜滑梯下降，直到近年每位婦女平均只有一名嬰兒。&lt;/p&gt;
&lt;p&gt;解釋歷史從來不簡單，但我們可以想像在當時，醫療技術以及節育概念還不高，間接造成較高的兒童死亡率。兒童的死亡率高，也就代表平均一位婦女需要生產更多嬰兒來延續後代。要證實這點，我們可以把 X 軸的「人均所得」換成「兒童死亡率」：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/femaile-fertility-vs-child-death-rate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/femaile-fertility-vs-child-death-rate.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;不只台灣，我們可以發現全世界有一樣的趨勢：兒童死亡率下降，而同時媽媽們也不需再生那麼多寶寶。這現象很大部分是因為醫療進步、女性教育的普及以及家庭觀念的改變。&lt;/p&gt;
&lt;p&gt;另外從代表不同洲的顏色可以看到，在 2018 年，所有婦女人均嬰兒數 &amp;gt; 6 的國家都位在非洲。&lt;/p&gt;
&lt;p&gt;當然，婦女人均嬰兒數減少，同時也代表&lt;a href="https://www.sfaa.gov.tw/SFAA/Pages/ashx/File.ashx?FilePath=~/File/Attach/1613/File_2086.pdf"&gt;高齡化社會的來臨&lt;/a&gt;。讓我們將 X 軸換成「60 歲以上人口佔總人口比例」以後，看看日本的發展：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/japan-child-death-vs-elder.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/japan-child-death-vs-elder.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.stat.go.jp/data/topics/topi971.html"&gt;日本的高齡化人口比例增加&lt;/a&gt;，也代表青壯年的負擔加重。不只日本，在未來要怎樣建立一個良好的長照制度，在台灣也是一個日漸重要的議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;怎麼創造乾淨未來：煤炭消耗與環境污染&lt;a class="anchor-link" href="#怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;台灣能源供給高度仰賴進口，其進口量長期維持在 97 到 98 ％，而&lt;a href="https://secured-static.greenpeace.org/taiwan/PageFiles/770030/%E5%85%A8%E7%90%83%E6%9A%A8%E5%8F%B0%E7%81%A3%E7%87%83%E7%85%A4%E7%99%BC%E9%9B%BB%E4%B8%8D%E5%8F%AF%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%9C%9F%E7%9B%B8.pdf"&gt;煤炭又為台灣第二大主要進口能源&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;因為碳密度高，燃燒煤炭又會產生比其他化石燃料（石油、天然氣）來得更多的二氧化碳，造成更嚴重的氣候暖化以及環境破壞。讓我們看看從以前到現在，一個台灣人平均消耗的煤炭以及產生的二氧化碳的變化趨勢：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/coal-consumption.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/coal-consumption.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;我們可以看到從 1990 年起，台灣煤炭的人均消耗量（用來發電）快速增加，而同時人均二氧化碳的排放量也逐年增高。儘管近年趨向穩定，我們可以看到作為對照組的美國在 2010 年以後的人均煤炭消耗量已經低於我們。&lt;/p&gt;
&lt;p&gt;環境考量以及再生能源的成本下降，讓歐美各國的政府以及能源業者決定投向再生能源懷抱，但台灣似乎還想要&lt;a href="https://www.cmmedia.com.tw/home/articles/9316"&gt;建立燃煤電廠&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/coal-consumption-comparison.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;在 2014 年時，只有哈薩克跟澳大利亞的煤炭消耗量超越我們。而作為世界第一煤炭出口國，澳洲自己也因為大量開挖煤炭而導致大堡礁的生態浩劫。&lt;/p&gt;
&lt;p&gt;怎麼減少煤炭消耗並維持人民生活水準（如提高再生能源利用率），是台灣的重要議題之一。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="民主大躍進：我很自由，不過不想參與政治"&gt;民主大躍進：我很自由，不過不想參與政治&lt;a class="anchor-link" href="#民主大躍進：我很自由，不過不想參與政治"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對於現在的台灣人來說，「民主」是如吃飯喝水般的基本存在。&lt;/p&gt;
&lt;p&gt;但台灣的「民主」一直都存在嗎？要回答這個問題，我們可以看看台灣的&lt;a href="https://zh.wikipedia.org/wiki/%E6%B0%91%E4%B8%BB%E6%8C%87%E6%95%B0"&gt;民主指數（Democracy Index）&lt;/a&gt;發展：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/democracy-index-tw.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/democracy-index-tw.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;雖然上頭的數據只到 2011 年，但我想要你看的是，1990 年（也是我出生的那年）之後，比起所得提升速度，我們的民主指數的成長速度讓人驚訝，可以說是三級跳！&lt;/p&gt;
&lt;p&gt;基本上近年台灣的分數變動不大。而在最新的 &lt;a href="http://news.ltn.com.tw/news/politics/breakingnews/2327881"&gt;2017 年全球民主指數&lt;/a&gt;裡頭，台灣則獲得了 7.73 分，全球排名第 33 名。（第一名為挪威，美國 21，日本 23，中國則為 139 名）&lt;/p&gt;
&lt;p&gt;民主指數滿分為 10 分，由 5 個評量標準做平均：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;選舉過程及多元程度（獲 9.58 分）&lt;/li&gt;
&lt;li&gt;政府功能（獲 8.21 分）&lt;/li&gt;
&lt;li&gt;政治參與（獲 6.11 分）&lt;/li&gt;
&lt;li&gt;政治文化（僅 5.63 分）&lt;/li&gt;
&lt;li&gt;公民自由度（ 9.12 分）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到雖然我們的公民自由度很高，但政治參與以及政治文化不足。&lt;/p&gt;
&lt;p&gt;我個人認為跟長期無意義的藍綠對抗文化以及年輕一代普遍對政壇上的政治人物冷感有關。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        要讓民主成功，我們必須參與，而非只是冷眼旁觀。沒有投票的人沒有權利抱怨。
        &lt;br/&gt;
&lt;span style="float:right"&gt;─ 路易．路蒙，美國小說家&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;儘管我們的民主程度已經值得讚賞，在公民參與部分還有很多地方可以改善。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="kan dao shu ju bei hou de gu shi_1"&gt;&lt;span id="story-behind-data"&gt;看到數據背後的故事&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在上一章節，我們看了一些利用泡泡圖探索台灣以及世界的例子。&lt;/p&gt;
&lt;p&gt;相信你也有這種錯覺：搭配著大量數據，泡泡圖彷彿讓你站在上帝的視角綜觀全球。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/gods_point_view_2013_10_08-12.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;但我們不能就這樣停止，自我膨脹地以為彷彿透過泡泡圖裡頭的數據，就已經暸解世間萬物。&lt;/p&gt;
&lt;p&gt;正如《真確》裡頭漢斯・羅斯林教授跟我們說的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        我要你看到統計數據背後的個別故事，也要你看到個別故事背後的統計數據。不靠數據無法了解世界，但光靠數據也無法了解世界。
    &lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;舉例來說，在我查看台灣婦女在工業（Industry Sector）的勞動比例時，發現一個有趣的現象：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/female-industry-sector-tw-and-al-jaza-ir.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/female-industry-sector-tw-and-al-jaza-ir.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;工業一般給人的印象就是包含了很多需要體力的工作，因此看到右邊台灣婦女在工業的勞動比例逐年下降（與之相對，服務業勞動比例上升）完全符合我的期待。但是，看看那個&lt;a href="https://zh.wikipedia.org/wiki/%E9%98%BF%E5%B0%94%E5%8F%8A%E5%88%A9%E4%BA%9A#%E7%BB%8F%E6%B5%8E"&gt;阿爾及利亞&lt;/a&gt;！&lt;/p&gt;
&lt;p&gt;光看那條節節上升的曲線無法幫助我們實際了解阿爾及利亞，如同我們無法光靠數據了解世界。&lt;/p&gt;
&lt;p&gt;說來慚愧，在觀察到這現象前，儘管小時候從歷史老師的口中聽過它，我完全沒有研究過這個國家。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/algeria-oran.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    阿爾及利亞, &lt;a href="https://zh.wikipedia.org/wiki/%E7%93%A6%E8%B5%AB%E8%98%AD" target="_blank"&gt;瓦赫蘭&lt;/a&gt;（&lt;a href="https://www.ft.com/content/ee80ed52-29de-11e2-a5ca-00144feabdc0" target="_blank"&gt;圖片來源&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;透過一些閱讀，我現在了解阿爾及利亞（Algeria）是一個位於非洲北部的國家，1962 年從法國殖民統治下獲得獨立。因為&lt;a href="http://www.hkislam.com/index.php?action-viewnews-itemid-3616"&gt;婦女解放&lt;/a&gt;以及女權運動崛起地相對較其他伊斯蘭國家早，該國的女性在各個階級都很活躍。在勞動市場可以看到她們開大卡車、當加油站工人並穿寬大的工作服；&lt;a href="https://news.un.org/zh/story/2012/05/173592"&gt;女性議員在議會佔的比例&lt;/a&gt;在阿拉伯世界也是獨占鰲頭，最近甚至&lt;a href="https://www.demotivateur.fr/article/algerie-3-200-jeune-femmes-en-bikini-pour-lutter-contre-l-obscurantisme-religieux-10710"&gt;還舉辦比基尼示威&lt;/a&gt;，來呼籲保守的社會給予女性更多自由。&lt;/p&gt;
&lt;p&gt;在這邊不是要推薦你去阿爾及利亞觀光或是 Google 搜尋比基尼照片。&lt;/p&gt;
&lt;p&gt;我想強調的是，讓你的好奇心跨越冷冰冰的數字。在透過數據有個宏觀的概念以後，針對你有興趣的問題去實際查查資料，問問人並了解背後的故事。&lt;/p&gt;
&lt;p&gt;在你開始這麼做以後，會發現世界變得更遼闊，更多采多姿。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="你能怎樣讓世界更好？"&gt;你能怎樣讓世界更好？&lt;a class="anchor-link" href="#你能怎樣讓世界更好？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;看了那麼多的泡泡圖以及數據，實際上我們可以怎樣讓台灣以及世界變得更好呢？&lt;/p&gt;
&lt;p&gt;我相信每個人都有自己的想法，但這邊讓我給出一些拙見。&lt;/p&gt;
&lt;p&gt;如果你是老師或是從事教育業，開始思考要怎麼利用數據來教導學生或是下一代正確的世界觀吧！不要再教他們背誦歷史年表或是生硬數字，而是利用容易理解的資料視覺化工具（如本文的泡泡圖）將過去、現在的世界展示給他們看，刺激他們的好奇心，讓他們自主發問、蒐集資料並想像未來。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/children-ask-questions.jpeg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;如果你是從事經濟 / 社會 / 公衛 / 能源 / 政治 / 國際關係等專業領域的話，重新思考在這個世紀，我們應該要密切關注的人類發展指標吧！&lt;/p&gt;
&lt;p&gt;舉國民平均所得這個指標來說，我們在文章開頭看到近 200 年來全世界每個國家在國民平均所得皆有改善，但在 21 世紀只看這個就夠了嗎？&lt;/p&gt;
&lt;p&gt;21 世紀，我們面臨的新問題是貧富差距。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/the-indicator-we-need-in-the-future.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;從「平均所得」這單一數字來看一個國家的經濟發展非常危險，因為這會讓我們忽視一件事情：國家的總所得實際上是怎麼分配到所有人手上的。&lt;/p&gt;
&lt;p&gt;在 21 世紀，我們應該更關注如上圖的指標：「最富有的 10 % 人所擁有的收入份額」，來確保我們不只解決貧困，還會記得要對付社會不平等問題。&lt;/p&gt;
&lt;p&gt;就算你認為自己不屬於上面兩種人，別擔心！我幫你列了一個自由勾選的行動清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分享本文以讓更多人開始探索台灣與世界&lt;/li&gt;
&lt;li&gt;閱讀《真確》一書&lt;/li&gt;
&lt;li&gt;查看漢斯・羅斯林&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen#t-249222" target="_blank"&gt;在 TED 上的演講&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;查看 GapMinder 官網，尤其是 &lt;a href="https://www.gapminder.org/dollar-street/matrix"&gt;Dollar Street&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;找出泡泡圖的翻譯錯誤並通知我（如果有的話）&lt;/li&gt;
&lt;li&gt;加強數據科學力，學習利用數據說故事（尤其適合資料科學家）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以用任何方式探索世界，但如果你打算回來玩玩泡泡圖，隨時歡迎！我會持續更新數據來源並將我（和你）的新發現更新到文章裡頭。&lt;/p&gt;
&lt;p&gt;你可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將&lt;a href="https://leemeng.tw/gapminder.html"&gt;本頁網址&lt;/a&gt;加入書籤，方便隨時回來查看最新的泡泡圖&lt;/li&gt;
&lt;li&gt;用下面的按鈕訂閱部落格文章，在新文章出來的時候收到消息&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/gapminder/alessandro-erbetta-786007-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        最後，也是最重要的，對世界多點好奇並盡情探索吧！希望你享受我們這趟探索旅程，是時候展開你自己的冒險了：）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="致謝"&gt;致謝&lt;a class="anchor-link" href="#致謝"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;感謝&lt;a href="https://zh.wikipedia.org/wiki/%E6%B1%89%E6%96%AF%C2%B7%E7%BD%97%E6%96%AF%E6%9E%97"&gt;漢斯・羅斯林&lt;/a&gt;教授，我要謝謝他帶我用更宏觀、積極的態度來理解這個世界並帶給我無數啟發。這篇文章以及文內的泡泡圖是我向他的致敬。&lt;/p&gt;
&lt;p&gt;（漢斯・羅斯林教授已於 2017 年 2 月 7 日在瑞典烏普薩拉逝世）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="GapMinder"></category><category term="資料視覺化"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.5 數據科學家面臨的挑戰、儀表板設計以及未來的被駭人生</title><link href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html" rel="alternate"></link><published>2018-09-17T12:00:00+09:00</published><updated>2018-09-17T12:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-09-17:/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html</id><summary type="html">&lt;p&gt;真正的數據科學家面臨的 8 個挑戰是什麼？何時一個資料科學家可以說他 / 她真正地「完成」了工作？ 10 個儀表板設計的原則是什麼？何謂「被駭」人生？為了了解這些跟資料科學息息相關的問題以及可能的解答，這週我們一樣會透過閱讀幾篇文章，來分別了解幾位優秀的資料科學家、UI/UX 設計師甚至是歷史學家是怎麼思考這些問題的。如同以往的文摘，我會附上摘要並穿插自己的心得，供時間寶貴的你參考。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;真正的數據科學家面臨的 8 個挑戰是什麼？&lt;/li&gt;
&lt;li&gt;何時一個資料科學家可以說他 / 她真正地「完成」了工作？ &lt;/li&gt;
&lt;li&gt;10 個儀表板設計的原則是什麼？&lt;/li&gt;
&lt;li&gt;何謂「被駭」人生？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了了解這些跟資料科學息息相關的問題以及可能的解答，這週我們一樣會透過閱讀幾篇文章，來分別了解幾位優秀的資料科學家、UI/UX 設計師甚至是歷史學家是怎麼想的。如同以往的&lt;a href="https://leemeng.tw/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，針對每篇英文文章我會附上摘要並穿插自己的心得，供時間寶貴的你做參考。&lt;/p&gt;
&lt;p&gt;事不宜遲，讓我們直接開始吧：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;When Your Job Is Done as a Data Scientist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-Real-Challenges-Data-Scientists-Face"&gt;8 Real Challenges Data Scientists Face&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data-visualisation,-from-1987-to-today"&gt;Data visualisation, from 1987 to today&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-rules-for-better-dashboard-design"&gt;10 rules for better dashboard design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Hackable-humans-and-digital-dictators"&gt;Hackable humans and digital dictators&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本週想跟你分享 5 篇文章。如同以往的&lt;a href="https://leemeng.tw/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，你可以點擊任一連結，從有興趣的摘要看起。有時間的話，我則鼓勵你點擊下面各文章的標題 / 圖片來查看英文原文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;&lt;a href="https://towardsdatascience.com/when-your-job-is-done-as-a-data-scientist-c5d887bb0d0e"&gt;When Your Job Is Done as a Data Scientist&lt;/a&gt;&lt;a class="anchor-link" href="#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://towardsdatascience.com/when-your-job-is-done-as-a-data-scientist-c5d887bb0d0e" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_7cF6Us4qWFN6jX49OI4zgg.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在一個企業裡頭，資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist, &lt;strong&gt;DS&lt;/strong&gt;）常常會被各個部門（Product, Marketing, Sales Team etc）要求做各種不同的分析。如果你把每個分析視為一個專案（Project）的話，2 個你常常會需要問自己的問題是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什麼時候可以說這個專案完成了？&lt;/li&gt;
&lt;li&gt;要做到什麼程度可以說我這個工作做完了？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇文章裡頭，資料科學家 &lt;a href="https://towardsdatascience.com/@conordewey3"&gt;Conor Dewey&lt;/a&gt; 說明了一個簡單的判斷原則：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;如果利害關係人無法利用你的成果做出決策，則你的工作就不算完成。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果專案的利害關係人（Stakeholders）沒有辦法利用你的分析成果做出（好的）決策，則你的工作就還沒結束。反之，當你確定自己的工作結果能夠影響企業決策後，就不需要再去鑽研一些太複雜但沒有 actionable impact 的事情上面。&lt;/p&gt;
&lt;p&gt;如同我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;之前的文摘&lt;/a&gt;中看到的，比起建立複雜的深度學習模型，學會做一個好的簡報，並跟非技術專業的利害關係人溝通結果，進而&lt;strong&gt;影響企業決策&lt;/strong&gt;才是對一個 DS 來說更為重要的事情。&lt;/p&gt;
&lt;p&gt;為了產生最大的影響力，不管在做什麼分析或者專案的時候，都得要好好控管自己的時間以及專案的優先順序（Priority）。&lt;/p&gt;
&lt;p&gt;雖然該作者在文中並沒有著墨於如何管理時間，你可以利用美國總統&lt;a href="https://zh.wikipedia.org/wiki/%E5%BE%B7%E6%80%80%E7%89%B9%C2%B7%E8%89%BE%E6%A3%AE%E8%B1%AA%E5%A8%81%E5%B0%94"&gt;艾森豪&lt;/a&gt;的&lt;a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method"&gt;時間管理準則&lt;/a&gt;來決定專案的優先順序：&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://jamesclear.com/eisenhower-box" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/eisenhower-box.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現，這其實就是我們從小到大在說的「輕重緩急」。&lt;/p&gt;
&lt;p&gt;將專案依照重要性（Importance）以及緊急程度（Urgency）分為四個象限以後，你就能很清楚地知道該把自己大部分的工作時間花在那些最重要，且緊急的專案上面（上圖的左上角），藉此最大化自己的影響力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;重要的事情通常不太緊急；緊急的事情大多不太重要 - 艾森豪&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="8-Real-Challenges-Data-Scientists-Face"&gt;&lt;a href="https://www.forbes.com/sites/laurencebradford/2018/09/06/8-real-challenges-data-scientists-face/"&gt;8 Real Challenges Data Scientists Face&lt;/a&gt;&lt;a class="anchor-link" href="#8-Real-Challenges-Data-Scientists-Face"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.forbes.com/sites/laurencebradford/2018/09/06/8-real-challenges-data-scientists-face/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/8-challenges.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://www.forbes.com/"&gt;富比士&lt;/a&gt;的這篇文章說明數據科學家在實際工作時會面臨到的 8 個挑戰。以下是我針對這些挑戰，整理出來 5 點 DS 應該時時刻刻放在心上的準則：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;你得至少專精一個部門的領域專業。此部門可以是銷售、行銷、廣告或是產品部門，擇你所愛&lt;/li&gt;
&lt;li&gt;能向非技術人才、利害關係人簡單明瞭地說明洞見以及可執行的決策，並把技術細節留到 Q&amp;amp;A&lt;/li&gt;
&lt;li&gt;不要盲目地想從資料中找出什麼。先利用領域專業或者是直覺來弄出一個假設，然後利用數據驗證結果&lt;/li&gt;
&lt;li&gt;明白一個分析的「可信度」只跟你用來做出該分析的原數據「品質」一樣高&lt;/li&gt;
&lt;li&gt;不斷地磨練自己處理數據的技能。這通常體現在使用 Python、&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;R&lt;/a&gt; 以及 &lt;a href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;SQL&lt;/a&gt; 的能力&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;關於第 2 點，此篇文章則是這樣說明的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;A data scientist that cannot articulate what their model does and why it&amp;rsquo;s of value to business stakeholders is going to have a difficult path to success.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有固定在追蹤本部落格的你，想必已經非常了解清晰溝通的重要性。你也可閱讀之前的&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html"&gt;資料科學文摘 Vol.4&lt;/a&gt; 來了解更多相關內容。至於第 4 點，我們則在兩篇文章中有針對資料工程以及數據品質做些著墨：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;資料科學家 L 的奇幻旅程 Vol.1 新人不得不問的 2 個問題&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Garbage in, garbage out。&lt;/p&gt;
&lt;p&gt;了解企業內的資料處理流程，可以讓你合理地評估利用這些數據產生出來的分析，到底有多少價值以及可信度。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Data-visualisation,-from-1987-to-today"&gt;&lt;a href="https://medium.economist.com/data-visualisation-from-1987-to-today-65d0609c6017"&gt;Data visualisation, from 1987 to today&lt;/a&gt;&lt;a class="anchor-link" href="#Data-visualisation,-from-1987-to-today"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://medium.economist.com/data-visualisation-from-1987-to-today-65d0609c6017" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/leroy-stencil-set.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在經濟學人負責資料視覺化的 &lt;a href="https://medium.economist.com/@grahamdouglas_75252"&gt;Graham Douglas&lt;/a&gt; 分享他從 1987 年工作到現在，所使用的工具以及製圖歷程。遠在 2, 30年前，在「資料科學」這詞根本還不存在的年代，資料視覺化更像是一門藝術，而不是資料科學：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Before computers, creating charts was a lot more like art than data science.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對已經習慣使用 &lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt;、&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;ggplot2&lt;/a&gt; 以及 &lt;a href="https://www.tableau.com/"&gt;Tableau&lt;/a&gt; 等資料視覺化工具的 DS 來說，可能很難想像製作一張折線圖，還需要自己拿尺出來畫等間距格線的時代。&lt;/p&gt;
&lt;p&gt;雖然我們現在已經可以利用各種程式語言來輕鬆製圖，讀這篇文章能讓我們重新思考並感謝現代資料視覺化工具帶給我們的方便。我們也看到持續學習新技術以及工具的重要。&lt;/p&gt;
&lt;p&gt;對資料視覺化或是 R 語言中的 ggplot2 有興趣的話，可以參考&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="10-rules-for-better-dashboard-design"&gt;&lt;a href="https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c"&gt;10 rules for better dashboard design&lt;/a&gt;&lt;a class="anchor-link" href="#10-rules-for-better-dashboard-design"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_gOwMfjZn3odOcYdCatiHCw.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;UX/UI 設計師的 &lt;a href="https://uxplanet.org/@taras.bakusevych"&gt;Taras Bakusevych&lt;/a&gt; 提供了一些很不錯的儀表板（Dashboard）設計建議。&lt;/p&gt;
&lt;p&gt;3 點我覺得可以特別提出來：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;簡潔，想辦法把精華弄在一頁&lt;/li&gt;
&lt;li&gt;不要太依賴互動性，要讓使用者不需什麼操作就能得到重要資訊&lt;/li&gt;
&lt;li&gt;選擇對的視覺呈現方式來陳述你想表達的數據關係&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;針對第 1 點，文章是這樣說的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Don&amp;rsquo;t tell the full story, instead summarize, surface only key info.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;大部分儀表板的用意是要讓使用者在「幾秒鐘」之內掌握所有他需要知道的重要資訊。&lt;/p&gt;
&lt;p&gt;為了達到這個目的，你應該仔細思考，到底該在儀表板上的有限空間裡頭（一個視窗畫面內）顯示什麼圖表。&lt;/p&gt;
&lt;p&gt;不要因為大部分的儀表板可以無限捲動，你就一直往下加新的圖表。什麼圖表都放進去的話，很容易造成資訊過多（Information Overload）而導致使用者抓不到重點。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「選擇對的視覺呈現方式來陳述你想表達的數據關係」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這點，文中則給出一個數據關係跟圖表類型的對照表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/1_9VanG02d4If1TOIbpcTWbA.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對於一個老練的 DS，這些判斷基準應該都已經很自然地存在你腦海之中的吧！不過我覺得這很適合當做一個 reference 或者 cheatsheet 來使用，提醒自己。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Hackable-humans-and-digital-dictators"&gt;&lt;a href="https://www.aljazeera.com/indepth/features/hackable-humans-digital-dictators-qa-yuval-noah-harari-180824095306982.html"&gt;Hackable humans and digital dictators&lt;/a&gt;&lt;a class="anchor-link" href="#Hackable-humans-and-digital-dictators"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.aljazeera.com/indepth/features/hackable-humans-digital-dictators-qa-yuval-noah-harari-180824095306982.html" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/d0c2f05a21404458aee9066c6cd5219a_18.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇文章記錄了&lt;a href="https://www.books.com.tw/products/0010647371"&gt;人類大歷史&lt;/a&gt;的作者，以色列歷史學家 &lt;a href="http://www.ynharari.com/"&gt;Yuval Noah Harari&lt;/a&gt; 最近在接受新書訪談：&lt;a href="https://www.books.com.tw/products/0010796370?loc=P_037_001"&gt; 21 世紀的 21 堂課&lt;/a&gt;的內容。&lt;/p&gt;
&lt;p&gt;你會說，為何在資料科學文摘裡頭包含了這篇文章？&lt;/p&gt;
&lt;p&gt;在這個一切以數據為本，「數據主義」超越「人文主義」的時代，身為一個 DS，我覺得除了注重數據分析的手法以外，作為一個有血有肉的「人」，也需要去了解數據、機器學習以及 AI 會對未來的我們以及下一代造成什麼樣的影響。這篇訪談中 Harari 用易懂的方式，以歷史學家的角度說明這件事情，值得一讀。以下是我閱讀後整理的摘要。&lt;/p&gt;
&lt;p&gt;21 世紀人類面臨的 3 個挑戰：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核子戰爭&lt;/li&gt;
&lt;li&gt;氣候變遷&lt;/li&gt;
&lt;li&gt;科技破壞（Technological Disruption） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些挑戰最難的點在於，它們並不能只靠單一一個國家解決，而是要跨國合作。&lt;/p&gt;
&lt;p&gt;而前 2 個挑戰幾乎所有人都理解，因此或許不會發生，但最後一項挑戰（科技破壞）的影響卻不太明顯。&lt;/p&gt;
&lt;p&gt;未來的人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence, &lt;strong&gt;AI&lt;/strong&gt;）肯定會自動化掉更多人的「現有」工作。這些 AI 系統也將透過更多的 IoT 裝置來蒐集更多我們的資料（像是搜尋紀錄、身體資訊、情緒變化等），分析這些數據以後來幫我們自動做決策。&lt;/p&gt;
&lt;p&gt;這些系統甚至最後可能會告訴我們（現在已經有些系統號稱）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「透過大數據分析，我比你自己還懂你自己」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這就是所謂的「被駭人生」：這些利用機器學習或是人工智慧的系統能 hack 我們，透過大數據分析，在我們實際行動之前，就已經精準地預測，或者說是大幅度地直接影響我們內心、腦中的決策。你只要想像你現在在做大多數決策的時候，是比較常「聆聽自己內心的聲音」還是去「查看網站、服務、App 給你的個人推薦」就可以稍微了解這點了。&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re becoming Hackable human.&lt;/p&gt;
&lt;p&gt;注意的是我們可不是在討論科幻小說，這邊的 AI 不會有情緒感情，只是有著龐大數據、運算能力以及複雜演算法的系統。&lt;/p&gt;
&lt;p&gt;如果我們是這些 AI 系統的主人，AI 是為我們每個人自己的利益來服務的話很好。但看看那些大量蒐集你的數據的科技公司：一個比較可能出現的未來是，少數菁英掌握了 AI 力量，而 AI 會為了他們的利益而服務。在這樣的情況下，大多數的人類都會成為不重要的存在，等著被機器取代（如果我們什麼都不做的話）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;The most important fact anybody who is alive today needs to know about the 21 century is that we are becoming hackable animals ... If you can hack something, you can replace it.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這不是在危言聳聽，而是在討論現在的科技發展趨勢之下，可能產生的一個未來。重點是我們在了解現況以後，打算怎麼改變未來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在找出解決方案之前，你得先了解有什麼問題。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在還在閱讀 21 世紀的 21 堂課，希望之後能再跟你分享一些我的讀後心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;&lt;a name="ending"&gt;&lt;/a&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文摘裡頭，我們透過幾篇文章來了解以下幾個議題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;數據科學家的一些工作準則&lt;/li&gt;
&lt;li&gt;最大化你的工作影響力並為專案分優先順序&lt;/li&gt;
&lt;li&gt;幾個儀表板設計的原則&lt;/li&gt;
&lt;li&gt;數據主義時代下的「被駭」人生&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為本文篇幅有限，我只能跟你分享閱讀這些文章以後，自己覺得最精華的一小部分。&lt;/p&gt;
&lt;p&gt;閱讀這些文章讓我受益匪淺，因此我分享了自己的摘要，希望能幫助到沒有時間閱讀全部文章的你。儘管如此，我仍建議你從有興趣的議題開始閱讀原文或者相關文章以進一步學習。&lt;/p&gt;
&lt;p&gt;同時非常歡迎閱讀後跟我分享你的想法，或是提供一些你覺得有幫助的相關文獻，我會很感激。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Remember we are what we read. Read those books or articles that will make you a better person ：）&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>給資料科學家的 Docker 指南：3 種活用 Docker 的方式（上）</title><link href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html" rel="alternate"></link><published>2018-09-08T19:00:00+09:00</published><updated>2018-09-08T19:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-09-08:/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html</id><summary type="html">&lt;p&gt;本系列文章將分上下篇，本篇將直觀解釋 Docker 概念，並說明資料科學家能如何利用 Docker 來改善自己的開發效率；下篇則將分享作者在實際從事資料科學家時，為了解決一些數據問題而時常碰到的 3 種 Docker 使用方式。在本篇中，我們首先將透過一些簡單的比喻來直觀地理解 Docker，並讓讀者在閱讀本文後能馬上開始利用 Docker 來加速自己的開發效率，並為下篇的進階內容打好基礎。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今天我們來聊聊如何將 &lt;a href="https://zh.wikipedia.org/wiki/Docker_(%E8%BB%9F%E9%AB%94)" target="_blank"&gt;Docker&lt;/a&gt; 應用在資料科學領域裡頭吧！&lt;/p&gt;
&lt;p&gt;全文共分上下 2 篇。在這篇裡頭，我們將透過一些簡單的比喻來直觀地理解何謂 Docker，並讓你能在閱讀本文後馬上利用 Docker 來加速你的開發效率；在下篇的內容當中，我則會分享一個資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist：DS）為了解決一些數據問題而時常碰到的 3 種 Docker 使用方式。&lt;/p&gt;
&lt;p&gt;不管是哪一篇，我們都不會深入探討 Docker 本身是以什麼技術被實現的。反之，我們將會以 DS 的角度，專注在「應用」層面：如何把 Docker 實際應用在資料科學以及資料工程領域裡頭。&lt;/p&gt;
&lt;p&gt;這系列文章適合 2 種讀者：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對 Docker 完全沒有概念，但想讓自己的 Workflow 更有效率的資料科學家&lt;/li&gt;
&lt;li&gt;熟悉 Docker，但好奇其在資料科學領域如何被應用的工程師&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="雲端運算-&amp;amp;-Docker"&gt;雲端運算 &amp;amp; Docker&lt;a class="anchor-link" href="#雲端運算-&amp;amp;-Docker"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在解釋何謂 Docker 之前，讓我把你已經非常熟悉的雲端運算（Cloud Computing）老朋友叫出來。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/tw/"&gt;Amazon Web Service（AWS）&lt;/a&gt;、&lt;a href="https://cloud.google.com/"&gt;Google 雲端平台（GCP）&lt;/a&gt; 以及 &lt;a href="https://azure.microsoft.com/zh-tw/"&gt;Microsoft Azure&lt;/a&gt; 大概是大家最耳熟能詳的幾家雲端計算 / 服務平台了。隨著時代的演進，這些平台提供越來越多樣的機器學習 API，讓開發人員不需做複雜的開發，透過一個 HTTP 要求就能直接使用各種酷炫的服務，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/tw/lex/"&gt;Amazon Lex&lt;/a&gt; 讓你使用 Amazon Alexa 的深度學習技術建立聊天機器人&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloud.google.com/vision/"&gt;Google Cloud Vision API&lt;/a&gt; 讓你快速建立一個圖像辨識服務&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/zh-tw/services/cognitive-services/content-moderator/"&gt;Azure Content Moderate API&lt;/a&gt; 讓你自動審核網路上的圖片以及文字&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;儘管如此，很多時候只使用這些現成的 API 並不能滿足我們這些 DS 以及企業的野心。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/network-2402637_1280.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    比起使用現成 API，如何運用雲端運算來 scale 各種數據處理工作是一個 DS / DE 更常問的問題
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a name="three-tasks"&gt;&lt;/a&gt;除了直接用各家雲端平台提供的 API 以外，一個 DS 可能更常需要利用雲端上的計算資源來完成以下的工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;部署一些新的分析工具來嘗試提升自己及分析團隊的效率&lt;/li&gt;
&lt;li&gt;開發、訓練、部署並規模化（scale）自己的機器學習模型&lt;/li&gt;
&lt;li&gt;對大量數據做批次處理，將結果儲存後顯示在儀表板上&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;事實上，這就是本系列文章最想要跟你分享的 3 件 DS 可以活用 Docker 來最大化產出的案例。&lt;/p&gt;
&lt;p&gt;當我們透過這篇文章（上篇）熟悉了 Docker 的基本概念以及操作以後，就能在下篇裡頭深入地探討它們。因此在這篇先讓我們專注在學習 Docker 的基礎知識吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們現在不會細談，但如果你再看一次上面的 3 個工作的話，會發現裡頭可不只包含資料科學（Data Science）。除了建置儀表板以及設計 ML 演算法以外，這裡頭還包含了不少軟體工程、資料工程甚至 &lt;a href="https://zh.wikipedia.org/wiki/DevOps"&gt;DevOps&lt;/a&gt; 成分。當然資料工程師（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer）很樂意幫助你，但如果你想要快速地自己兜出一些方法呢？你該用什麼工具？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/work-2005640_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可能覺得一個 DS 要在各種 deadlines 內完成以上所有的事情是不可能的。不過後面我們會慢慢發現，活用 Docker 能讓這些工作變得簡單許多。&lt;/p&gt;
&lt;p&gt;接著就讓我們以 DS 的角度了解 Docker 到底是什麼技術。我相信閱讀接下來的文章，對你之後開發效率的提升是一個非常好的投資。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker：可愛的大鯨魚"&gt;Docker：可愛的大鯨魚&lt;a class="anchor-link" href="#Docker：可愛的大鯨魚"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先看看以下這張 Docker 示意圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/1_JAJ910fg52ODIRZjHXASBQ.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有什麼感覺嗎？注意到上圖包含了 3 個要素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;海洋&lt;/li&gt;
&lt;li&gt;鯨魚&lt;/li&gt;
&lt;li&gt;貨櫃&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在讓我們發揮點想像力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你把雲端運算的平台想像成一個充滿運算資源的&lt;strong&gt;大海&lt;/strong&gt;的話，Docker 就是如圖中在裡頭悠遊的大&lt;strong&gt;鯨魚&lt;/strong&gt;。這隻&lt;strong&gt;鯨魚&lt;/strong&gt;將上述所有 DS 想要做的數據處理工作、執行的 App，一個個封裝成彼此獨立的&lt;strong&gt;貨櫃&lt;/strong&gt;，並載著它們在這大海上運行。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5" target="_blank"&gt;Docker&lt;/a&gt; 提供的抽象化讓我們能輕鬆地運行任何想使用的資料科學工具、軟體而不需花費過多時間在建置底層環境。&lt;/p&gt;
&lt;p&gt;我知道你可能還是沒什麼感覺，讓我們看下去。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="鯨魚背上的貨櫃：Docker-容器"&gt;鯨魚背上的貨櫃：Docker 容器&lt;a class="anchor-link" href="#鯨魚背上的貨櫃：Docker-容器"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;實際上這一個個假想的貨櫃就代表著 Docker 術語裡頭的容器（Container）。&lt;/p&gt;
&lt;p&gt;「容器」顧名思義，是一個「容納」了某些東西的「器具」。&lt;/p&gt;
&lt;p&gt;一般而言，一個容器裡通常會包含了一個完整的 App。這邊的 App 不是手機上的 App，而是指廣義的應用程式（&lt;strong&gt;App&lt;/strong&gt;lication）。&lt;/p&gt;
&lt;p&gt;DS 常用的 App 可以是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個包含 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt; 函式庫的 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook 伺服器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個 ML 產品，如透過已訓練的模型來判斷圖片裡頭有沒有貓咪的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Flask App&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個 SQL 查詢以及資料視覺化的工具，如 &lt;a href="https://github.com/apache/incubator-superset"&gt;Superset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個簡單的 Python Script，針對輸入的大量數據做處理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要從頭建構這些 App 的環境不是不可能，但除了基本的 &lt;code&gt;pip install&lt;/code&gt; 以外你還需要花不少工夫；更令人困擾的是，很多時候你在 Mac、Windows 上安裝環境的步驟，到了雲端上的 Linux 機器上就完全行不通了。&lt;/p&gt;
&lt;p&gt;如果這時候有人先幫我們把一個在哪邊都能跑的 App 環境建好，我們不是就能馬上開始使用各種分析工具，進行各種有趣的分析，而不用煩惱底層如不同 OS 的差異了嗎？&lt;/p&gt;
&lt;p&gt;Docker 的容器就是這樣的一個概念，幫你事先將一個 App 所需要的所有環境，包含作業系統都「容納」在一起。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/docker-inside-container.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://stackoverflow.com/a/50489813/2447655" target="_blank"&gt;Docker&lt;/a&gt; 將一個 App 會使用到的程式語言函式庫（JAVA、Python、R）、資料庫、甚至作業系統（OS）都包在一個自給自足的容器（CONTAINER）裡頭。想使用某個 App 的 DS 不用從頭建置環境，只需利用 Docker 啟動該容器即可開始工作
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;容器裡頭不只包含 App 自己本身的程式碼，也涵蓋了所有能讓這個 App 順利執行的必要環境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;App 需要的各種 Python 函式庫，如特定版本的 TensorFlow、Pandas 及 Jupyter Notebook&lt;/li&gt;
&lt;li&gt;MySQL、MongoDB 等 App 會用到的資料庫&lt;/li&gt;
&lt;li&gt;App 會用到的各種 metadata、資料集&lt;/li&gt;
&lt;li&gt;各種 OS 限定的驅動程式（drivers）、依賴函式庫&lt;/li&gt;
&lt;li&gt;（把所有你想得到的東西填進來）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包羅萬象。&lt;/p&gt;
&lt;p&gt;因此只要我們能利用 Docker 把一個 App 需要執行的環境全部包在一個容器裡頭，我們就能在任何有 Docker 的地方啟動並運行該容器。不再需要每次重新建置環境，也不用考慮不同機器上的安裝問題。&lt;/p&gt;
&lt;p&gt;而這正是 Docker 最強大的地方：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker - Build, Ship, and Run Any App, Anywhere&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為連 OS 都被包起來了，實際上每個容器（container）的執行環境都是自給自足的（self-contained）。&lt;/p&gt;
&lt;p&gt;你可以把它想像成非常輕量的&lt;a href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8"&gt;虛擬機器&lt;/a&gt;，其執行結果不會因為啟動該容器的「計算環境」不同而受到影響，在任何地方（Anywhere）都能順利被執行，且執行的結果都是一樣的。&lt;/p&gt;
&lt;p&gt;以我們前面的比喻來說的話，每個貨櫃（容器 / App）都是我們想要 Docker 幫我們運送（執行）的東西，而不管 Docker 這隻鯨魚（或大船）現在在哪個海洋（計算環境）裡頭，它都能使命必達。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/container-on-the-sea.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://flipboard.com/topic/container" target="_blank"&gt;Docker&lt;/a&gt; 就像艘大船，幫我們在任何海洋（計算環境）上運送我們的貨櫃（容器）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有一點值得澄清的是，就算 Docker 幫我們抽象化建置一個 App 環境的工作，在執行一個容器的時候，我們還是需要實際的計算資源來跑這些容器。&lt;/p&gt;
&lt;p&gt;因此前面所謂的「計算環境」指的是一個擁有計算資源（CPU、GPU、記憶體 etc）且我們實際運行 Docker 的地方。這計算環境可以是任何一家雲端服務平台上的機器，如 AWS 的某台 &lt;a href="https://aws.amazon.com/tw/ec2/"&gt;EC2 機器&lt;/a&gt;、&lt;a href="https://cloud.google.com/kubernetes-engine/"&gt;GCP&lt;/a&gt; 上一個包含數千台機器的群集（Cluster），或是你現在用來看本文的筆電。只要 Docker 能在該計算環境下運行，它就能幫我們在該環境「之上」執行任何容器。&lt;/p&gt;
&lt;p&gt;簡單來說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker 幫我們抽象化在任何 OS 上建置環境的工作。只要給 Docker 一個容器，它就能在任何地方啟動該容器以供你使用。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你對 Docker 以及容器概念有個高層次的理解了，讓我們來看看這些 Docker 容器實際上是怎麼來的吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="貨櫃（Docker-容器）從哪來"&gt;貨櫃（Docker 容器）從哪來&lt;a class="anchor-link" href="#貨櫃（Docker-容器）從哪來"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解 Docker 這隻大鯨魚能幫我們運行任意的容器 / App 以後，你腦中浮現的第一個問題應該是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這些容器（貨櫃）最初是怎麼被產生的？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;非常好的一個問題。&lt;/p&gt;
&lt;p&gt;事實上，要產生一個新的 Docker 容器，Docker 需要一份「環境安裝步驟書」來讓它幫我們自動地建置容器內的環境，比方說使用什麼 OS，用什麼版本的 TensorFlow 等等。這份步驟書在 Docker 的世界裡被稱作 &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfile&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;舉個例子，以下是 Tensorflow 官方釋出的一個 &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile"&gt;Dockerfile&lt;/a&gt;（截錄重要部分）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; ubuntu:16.04&lt;/span&gt;

...

&lt;span class="k"&gt;RUN&lt;/span&gt; pip --no-cache-dir install &lt;span class="se"&gt;\&lt;/span&gt;
        ipykernel &lt;span class="se"&gt;\&lt;/span&gt;
        jupyter &lt;span class="se"&gt;\&lt;/span&gt;
        numpy &lt;span class="se"&gt;\&lt;/span&gt;
        pandas &lt;span class="se"&gt;\&lt;/span&gt;
        sklearn &lt;span class="se"&gt;\&lt;/span&gt;
        &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    python -m ipykernel.kernelspec

...

&lt;span class="c"&gt;# Install TensorFlow CPU version from central repo&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; pip --no-cache-dir install &lt;span class="se"&gt;\&lt;/span&gt;
    http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl

...

&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; ["/run_jupyter.sh", "--allow-root"]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;除了 &lt;code&gt;RUN&lt;/code&gt;、&lt;code&gt;CMD&lt;/code&gt; 等 Docker 專屬的關鍵字以後，你會發現這份 Dockfile 裡頭的指令其實跟你平常在本地開發時也會使用的指令如 &lt;code&gt;pip install&lt;/code&gt; 沒有相差太多。差別在於透過第一行的 &lt;code&gt;FROM ubuntu:16.04&lt;/code&gt; 指令，我們要求 Docker 在這個容器裡頭建置一個 Ubuntu OS 後，在其之上安裝這些函式庫。&lt;/p&gt;
&lt;h2 id="追求規模性：Docker-映像檔的誕生"&gt;追求規模性：Docker 映像檔的誕生&lt;a class="anchor-link" href="#追求規模性：Docker-映像檔的誕生"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;聽完以上的解釋，你可能會覺得在我們每次要啟動一個新的容器的時候，Docker 就得拿出 Dockerfile，一步步建置該容器的環境。&lt;/p&gt;
&lt;p&gt;這樣的實作也不是不行，但很沒有效率。為什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其中一個考量是可擴展性（Scalability）。&lt;/p&gt;
&lt;p&gt;有時你會想要用同一份 Dockerfile 在短時間內迅速地產生好幾個一模一樣的容器(s)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用多個相同的機器學習模型，同時對大量的新數據做批次預測&lt;/li&gt;
&lt;li&gt;使用多個相同的 Python Script 來處理大量數據&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這時候與其在每次要啟動新的容器時才拿出 Dockerfile 建置環境，Docker 可以事先用這個 Dockerfile 把建置環境所需的步驟先做好一遍，然後把該環境「拍張照」，存成一個 Docker 映像檔（image）後等待之後的使用。&lt;/p&gt;
&lt;p&gt;等你決定要開始使用容器的時候，因為我們已經有一個環境的快照（Snapshot），Docker 就能利用該映像檔，快速地啟動 1 個（或 100 個）相同的容器給你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/docker-three-basic-elements.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://medium.com/platformer-blog/practical-guide-on-writing-a-dockerfile-for-your-application-89376f88b3b5" target="_blank"&gt;Docker 三元素&lt;/a&gt;： Dockerfile、Docker 映像檔以及 Docker 容器
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到了這邊，我們已經了解 Docker 最基本也是最重要的概念：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker 利用 Dockerfile 預先建置好一個 Docker 映像檔。在使用者想要使用容器的時候，以該映像檔為基礎，運行一個對應的 Docker 容器&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;坐而言不如起而行。&lt;/p&gt;
&lt;p&gt;在掌握了這些概念以後，我相信你也迫不及待地想要開始使用 Docker 了，接下來就讓我們實際操作 Docker 來體會一下它的威力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker-映像檔：法式千層酥"&gt;Docker 映像檔：法式千層酥&lt;a class="anchor-link" href="#Docker-映像檔：法式千層酥"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管是 Windows 或是 Mac 用戶，你都可以很輕鬆地在&lt;a href="https://www.docker.com/get-started"&gt;官方網站&lt;/a&gt;下載 Docker 並安裝。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://www.docker.com/get-started" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/docker/website.png" style=""/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;下載完以後啟動 Docker，大鯨魚就會在你的筆電上開始閒晃，等待你的指示。一般而言，我們會在 terminal 使用各種 &lt;code&gt;docker&lt;/code&gt; 指令來跟大鯨魚溝通。&lt;/p&gt;
&lt;p&gt;當 Docker 就緒以後，依照我們前面的所學，你會需要一個 Dockerfile 或是 Docker 映像檔來產生一個 Docker 容器。就像 &lt;a href="https://github.com/"&gt;Github&lt;/a&gt; 是一個被大家拿來分享程式碼的地方，&lt;a href="https://hub.docker.com/"&gt;Dockerhub&lt;/a&gt; 則被用來分享 Dockerfile 以及 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;假設我們現在要開始一個新的 TensorFlow 專案，並且想透過 Jupyter Notebook 進行開發，最省力的方式就是從 Dockerhub 下載一個 &lt;a href="https://hub.docker.com/r/tensorflow/tensorflow/"&gt;TensorFlow 官方&lt;/a&gt;幫我們弄好的 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;讓我們打開一個 terminal 並輸入 &lt;code&gt;docker pull&lt;/code&gt; 指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第 1 個 &lt;code&gt;tensorflow&lt;/code&gt; 代表 Tensorflow 的官方 Dockerhub repository，就跟 Github repository 的概念相同；第 2 個則是容器名稱。&lt;/p&gt;
&lt;p&gt;你會看到當 Docker 在下載映像檔的時候，同時也在建置環境，而其環境會分成一層一層（Layer）的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker pull tensorflow/tensorflow
Using default tag: latest
latest: Pulling from tensorflow/tensorflow
3b37166ec614: Already exists
ba077e1ddb3a: Already exists
34c83d2bc656: Already exists
84b69b6e4743: Already exists
0f72e97e1f61: Already exists
6086c6484ab2: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
25817b9e5842: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
5252e5633f1c: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
8de57ae4ad7d: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
4b7717108c3b: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
b65e9e47e80a: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
006d31e013ea: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
700521cc53f3: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:f45d87bd473bf999241afe444748a2d3a9be24f8d736a808277b4f3e32159566
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; tensorflow/tensorflow:latest
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我們不會細談 Docker 實作細節，但你可以想像 Docker 映像檔是一個法式千層酥（Mille Feuille）。&lt;/p&gt;
&lt;p&gt;這時候的 Docker 是一名蛋糕師傅，利用 Dockerfile 作為食譜，逐行執行裡頭的指令以建立一層層的環境。每做出一層新的環境，就把它加在目前所有環境的上面，最後成為一個 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;這樣做有 2 個好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;當你對 Dockerfile 做變動的時候，Docker 可以只針對被改變的那一層環境做修改，而不用重建每一層，減少建置環境所需要的時間&lt;/li&gt;
&lt;li&gt;有利用到一樣環境的不同映像檔可以分享部分結果（如上面的 &lt;code&gt;Already exists&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/mille_feuille.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個 Docker 映像檔就像是蛋糕師傅利用 Dockerfile 食譜做出來的法式千層酥
    &lt;br/&gt;
    （誠摯地希望你不是晚上看本文，餓了）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照你的網路速度，下載映像檔所需的時間可能有所不同。&lt;/p&gt;
&lt;p&gt;在下載完成以後，輸入 &lt;code&gt;docker images&lt;/code&gt; 指令可以顯示所有目前本地端擁有的 Docker 映像檔：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker images tensorflow/tensorflow
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
tensorflow/tensorflow   latest              76fb62c3cb89        &lt;span class="m"&gt;2&lt;/span&gt; weeks ago         &lt;span class="m"&gt;1&lt;/span&gt;.23GB
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這邊因為我的環境裡已經有一大堆的映像檔，我在 &lt;code&gt;docker images&lt;/code&gt; 後面加入額外的篩選器來告訴 Docker 只顯示 &lt;code&gt;tensorflow&lt;/code&gt; repository 裡頭的 &lt;code&gt;tensorflow&lt;/code&gt; 容器。&lt;/p&gt;
&lt;p&gt;有了映像檔以後，最令人期待的時刻終於來臨了！&lt;/p&gt;
&lt;p&gt;我們現在要呼叫 Docker 幫我們從這個映像檔產生並執行（run）一個新的 Docker 容器：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run -it -p &lt;span class="m"&gt;1234&lt;/span&gt;:8888 tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;短短一行指令，包含了 3 個你不可不知的重要概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 &lt;code&gt;docker run&lt;/code&gt; 來告訴 Docker 我們要利用 &lt;code&gt;tensorflow/tensorflow&lt;/code&gt; 映像檔來運行一個容器。實際上 Docker 容器就是在 Docker 映像檔的環境之上再加 1 層可執行的環境供你使用（貫徹千層酥的理念） &lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;-it&lt;/code&gt; 參數來告訴 Docker 我們同時要建立一個互動式的 TTY 連線，讓容器內的結果直接顯示在我們的 terminal 裡頭，彷彿我們在本地環境下執行該 App 一樣。我們之後還可以直接在 terminal 使用 Ctrl + C 或 Command + C 來終止容器&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;-p 1234:8888&lt;/code&gt; 告訴 Docker 我們將會透過本地端的 &lt;code&gt;1234&lt;/code&gt; port 來連到容器裡頭的 &lt;code&gt;8888&lt;/code&gt; port&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以透過&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run --help
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;來查看所有 &lt;code&gt;docker run&lt;/code&gt; 可以使用的參數。&lt;/p&gt;
&lt;p&gt;另外，一個 DS 應該都知道，&lt;code&gt;8888&lt;/code&gt; 是 Jupyter Notebook 預設的 port。因此我們的企圖就跟司馬昭之心一樣，打算透過本地端的 &lt;code&gt;1234&lt;/code&gt; port 連到在容器裡頭跑的 Jupyter Notebook。&lt;/p&gt;
&lt;p&gt;現在打開你的瀏覽器並輸入 &lt;code&gt;localhost:1234&lt;/code&gt;，應該就能連到容器內部的 Jupyter Notebook 伺服器：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/tensorflow-notebook.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    容器內的 Juypter Notebook 畫面，所有環境包含 TensorFlow 都已經幫你設置好
    &lt;br/&gt;
    （輸入你在啟動容器的 terminal 裡看到的 token 就能通過認證）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對你沒看錯，你已經用 Docker 建置了一個完整的資料科學環境，裡頭有 TensorFlow 以及 Jupyter Notebook。&lt;/p&gt;
&lt;p&gt;而你只需要 2 個指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull tensorflow/tensorflow
docker run -it -p &lt;span class="m"&gt;1234&lt;/span&gt;:8888 tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;建置環境什麼的交給 Docker 吧，你已經能馬上開始實作機器學習模型了。&lt;/p&gt;
&lt;p&gt;有些 DS 可能會覺得他的 &lt;a href="https://anaconda.org/"&gt;Anaconda&lt;/a&gt; 或者是 pip 功能爐火純青，不需要用到 Docker 也能自己在本地建出這樣的環境。其實沒錯，如果你只是開發個人專案，說真的不學 Docker 也沒關係（喂！）&lt;/p&gt;
&lt;p&gt;但就如我們在下篇會看到的，當你在開發企業等級的數據處理工作、機器學習模型的時候，你可不能永遠躲在你的本地環境裡頭。當你習慣於在不透過 Docker 的情況下在本機建置環境，等到要在各種雲端平台上的機器重現你的結果的時候，你就會發現不妙了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="利用-Docker-分享你的成果"&gt;利用 Docker 分享你的成果&lt;a class="anchor-link" href="#利用-Docker-分享你的成果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了加強你使用 Docker 的動機，讓我再給個例子。&lt;/p&gt;
&lt;p&gt;有持續關注我文章的讀者會發現，我在&lt;a href="https://leemeng.tw/data-science-digest-volume-3.html"&gt;資料科學文摘 Vol.3 Pandas、Docker 以及數據時代的反思&lt;/a&gt;裡頭有提到，Docker 除了讓我們免除建置環境的痛苦以外，也能讓我們與他人簡單地分享開發結果。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Cat Recognizer&lt;/a&gt; 是我用 TensorFlow 以及 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 實作的一個非常 naive 的貓咪辨識 App。&lt;/p&gt;
&lt;p&gt;如同我們前面所說的，我事先將所有此 App 需要的環境用一個 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app/blob/master/Dockerfile"&gt;Dockerfile&lt;/a&gt; 定義、全部包在一個 Docker 映像檔後分享在 &lt;a href="https://hub.docker.com/r/leemeng/"&gt;Docker Hub&lt;/a&gt; 上面。&lt;/p&gt;
&lt;p&gt;任何想要使用此 App 的人，只需要利用 Docker 輸入兩行指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull leemeng/cat
docker run -it -p &lt;span class="m"&gt;2468&lt;/span&gt;:5000 leemeng/cat
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著他們就能在瀏覽器輸入 &lt;code&gt;localhost:2468&lt;/code&gt; 來看到我的 App：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/cat-demo.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Docker 讓你與其他人分享成果，不須額外做一大堆環境設定
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這個 ML App 在預測能力以及 UI 上都不完美，但這邊重點是你能利用 Docker 與他人快速地分享成果。如果你有想到其他利用 Docker 封裝好的 ML App 例子（或者是你接下來打算做一個自己的），非常歡迎留言讓我知道它們的存在：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="總結"&gt;總結&lt;a class="anchor-link" href="#總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;呼！看完本文以後，相信你現在應該對 Docker 有個非常清楚的認識了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker 是一個能幫我們在各種不同 OS 上建置開發環境的工具&lt;/li&gt;
&lt;li&gt;Docker 三元素包含 Dockerfile、Docker 映像檔（Image）以及 Docker 容器（Container）&lt;/li&gt;
&lt;li&gt;Docker 利用 Dockerfile 預先建置好一個 Docker 映像檔。在使用者想要使用容器的時候，以該映像檔為基礎，運行一個對應的 Docker 容器&lt;/li&gt;
&lt;li&gt;Docker Hub 上有各式各樣可以直接供使用的映像檔&lt;/li&gt;
&lt;li&gt;你只需要 &lt;code&gt;docker pull&lt;/code&gt; 及 &lt;code&gt;docker run&lt;/code&gt; 就能開始一個分析專案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;給自己鼓鼓掌！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/1_JAJ910fg52ODIRZjHXASBQ.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    現在這張 Docker 的示意圖在你眼裡應該變得平易近人許多
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;正因為我們是資料科學家，利用 Docker能幫我們抽象化很多不必要的環境建置工作，加速我們的開發效率。&lt;/p&gt;
&lt;p&gt;在本系列文章的下篇出爐之前，我鼓勵你先&lt;a href="https://www.docker.com/get-started"&gt;下載 Docker&lt;/a&gt;，並開始在 &lt;a href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt; 或者 Google 搜尋一些你感興趣的映像檔，甚至自己寫一個 Dockerfile 將你目前的專案打包起來跟別人分享。&lt;/p&gt;
&lt;p&gt;雖然我們這篇因為篇幅關係沒有細講，但只要有一個 Dockerfile，你就能使用 &lt;code&gt;docker build&lt;/code&gt; 來輕鬆建立一個自給自足的 Docker 映像檔。一個 Dockerfile 也不難寫，像是上面貓咪的 App 的 Dockerfile 也不過就如此幾行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; python:3.6.3&lt;/span&gt;
&lt;span class="k"&gt;MAINTAINER&lt;/span&gt;&lt;span class="s"&gt; Meng Lee "b98705001@gmail.com"&lt;/span&gt;
COPY ./requirements.txt /app/requirements.txt
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /app&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; pip install -r requirements.txt
COPY . /app
&lt;span class="k"&gt;ENTRYPOINT&lt;/span&gt;&lt;span class="s"&gt; [ "python3" ]&lt;/span&gt;
&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; ["app.py"]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在本篇裡頭我們都是在自己的機器上使用 Docker。在下篇，我們將利用本篇學到的 Docker 知識，將其運用在浩瀚無垠的雲端平台之上，去最大化我們的影響力。&lt;/p&gt;
&lt;p&gt;在那之前你可以先熟悉熟悉 Docker，下次遇到你的 DS 同事時，可以問問他/她：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;嘿！你的 Docker Image 呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="Docker"></category></entry><entry><title>資料科學文摘 Vol.4 數據科學 MMORPG 上線！你，選好自己的角色了嗎？</title><link href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html" rel="alternate"></link><published>2018-08-29T00:30:00+09:00</published><updated>2018-08-29T00:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-29:/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html</id><summary type="html">&lt;p&gt;這篇文摘透過多篇跟資料科學家相關的文章，闡述資料科學家這個職業近年可能產生，或者是已經正在發生的一些職涯趨勢。透過掌握大局觀，讓對資料科學領域感興趣的讀者能夠理性地思考自己未來如何進入這塊領域，並在符合自己興趣以及能力的情況下，發揮自己最大的價值。我們將探討在這個什麼職業都跟數據扯上關係的年代，你要如何在「全球數據科學 MMORPG」裡頭，找出自己的定位以及角色。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同以往，這篇文摘會介紹幾篇最近作者閱讀的文章以及其摘要。&lt;/p&gt;
&lt;p&gt;不過這次在條列式列出文章以前，我想先跟你分享身為一個資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist，DS），我在閱讀這些文章後得到的一些想法。&lt;/p&gt;
&lt;p&gt;與其說是想法，應該說是「針對資料科學家這個職業，自己感受到的一些發展趨勢以及對這個職業接下來數年的職涯預測」。對於那些只有 3 分鐘可以閱讀此文的你，這些想法可以歸納成以下幾點：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/li&gt;
&lt;li&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/li&gt;
&lt;li&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/li&gt;
&lt;li&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/diablo-3-characters.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    如同&lt;a href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E5%9E%8B%E5%A4%9A%E4%BA%BA%E5%9C%A8%E7%BA%BF%E8%A7%92%E8%89%B2%E6%89%AE%E6%BC%94%E6%B8%B8%E6%88%8F" target="_blacnk"&gt;大型多人線上角色扮演遊戲（MMORPG）一般&lt;/a&gt;，在後數據時代，萬能、什麼數據工作都會的「資料科學家」這個幻想已在式微。取而代之的是各個對相關領域專精的「數據」職業角色們：商業分析師、資料工程師、機器學習工程師、AI 研究者等（圖為&lt;a href="https://tw.diablo3.com/zh/" target="_blacnk"&gt;線上遊戲：暗黑破壞神 3 &lt;/a&gt;的角色一覽）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接下來我將會列出本週的閱讀清單，並在簡單說明各篇摘要的同時，一一描述它們是如何跟上述幾點概念互相呼應。最重要的，我們將探討在這個什麼職業都跟數據扯上關係的年代，你要如何在「全球數據科學 MMORPG」裡頭，找出自己的定位以及角色。&lt;/p&gt;
&lt;p&gt;這篇文章適合對資料科學領域有興趣，或是未來想從事數據相關工作的你。放心，以文章長度來說，保證比上一篇文章：「&lt;a href="https://leemengtaiwan.github.io/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;」要來得平易近人許多。&lt;/p&gt;
&lt;p&gt;讓我們開始本週的閱讀之旅吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;One Data Science Job Doesn&amp;rsquo;t Fit All&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#The-Death-of-the-Data-Scientist"&gt;The Death of the Data Scientist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-to-be-a-bad-data-scientist!"&gt;How to be a bad data scientist!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;Beyond Interactive: Notebook Innovation at Netflix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;What Data Scientists Really Do, According to 35 Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同以往的&lt;a href="https://leemengtaiwan.github.io/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，你可以從任意一篇開始看我寫的摘要。不過建議先把所有標題掃過一遍，感受一下我們接下來要談的話題。&lt;/p&gt;
&lt;p&gt;另外如果真的很趕時間，可以直接&lt;a href="#ending"&gt;跳到文章最後&lt;/a&gt;看我給你的建議。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;&lt;a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/"&gt;One Data Science Job Doesn&amp;rsquo;t Fit All&lt;/a&gt;&lt;a class="anchor-link" href="#One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/one-data-science-job.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在這篇文章中，Airbnb 解釋他們如何在經過多年發展資料科學以後，將資料科學家分為三個路線（Tracks）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分析路線（Analytics）&lt;/li&gt;
&lt;li&gt;演算法路線（Algorithms）&lt;/li&gt;
&lt;li&gt;推論路線（Inference） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;會這樣做的其中一個很大原因是因為「資料科學」包含的領域太廣，不像這樣細分的話，第一，DS 們不知道自己該注重在什麼方面的知識；第二，公司內部跟某個 DS 合作的團隊也不知道他的專精以及該怎麼期待他的能力。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/airbnb-data-roles.png" style=""/&gt;
&lt;p&gt;Airbnb 經過多年經驗，將資料科學家細分為三個路線，主要就是為了讓每個 DS 能專注在對的地方&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;其實想想很自然。就像是現在我們很習慣將工程師粗淺地分為前端（Frontend）和後端（Backend），未來的資料科學家也有很大機會依照個人的專精以及企業需求來細分路線。要不現在你想知道一家公司對 DS 的定義，還得親自去問裡頭的資料科學家到底在做什麼，且十家公司的 DS 可能會給你 9 種答案。&lt;/p&gt;
&lt;p&gt;理想上一個資料科學家是通才（Generalist），三個路線的專業都大致了解。儘管如此，學海無涯。一個建議是至少找出哪個路線你有興趣，去專精它，並尋找渴望你專業的企業。&lt;/p&gt;
&lt;p&gt;這呼應到我們最前面提到的第 4 項趨勢（也是最重要的一項）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將這些路線想像成角色扮演遊戲（RPG）中的角色就對了！順帶一提，作者自己想專注在演算法路線，輔修分析路線，你呢？&lt;/p&gt;
&lt;p&gt;另外這篇沒提到跟資料科學密切相關的資料工程（Data Engineering），個人臆測是因為 Airbnb 的資料平台本身建得夠齊全，有很專業的資料工程師在幫 DS 完成這些事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="The-Death-of-the-Data-Scientist"&gt;&lt;a href="https://www.datasciencecentral.com/profiles/blogs/the-death-of-the-data-scientist"&gt;The Death of the Data Scientist&lt;/a&gt;&lt;a class="anchor-link" href="#The-Death-of-the-Data-Scientist"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.datasciencecentral.com/profiles/blogs/the-death-of-the-data-scientist" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/Dinosaur.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;「資料科學家的滅亡」。&lt;/p&gt;
&lt;p&gt;非常聳動的標題，而且你可以從封面圖片看出作者想要表達 DS 會像恐龍一樣滅絕。&lt;/p&gt;
&lt;p&gt;不過基本上我是認同的。&lt;/p&gt;
&lt;p&gt;不是說 DS 不再重要，而是再過幾年，就像當年的「大數據」風潮，各企業或許不會再像現在一窩蜂地招聘大量的「資料科學家」，而是各行各業的每個人都能很自然地將資料科學應用在自己的工作裡頭。
如同我們在&lt;a href="https://leemengtaiwan.github.io/demystify-the-hype-of-data-science-and-its-value.html#%E5%85%85%E5%AF%A6%E4%BD%A0%E7%9A%84%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8%E5%8A%9B"&gt;揭開資料科學的神秘面紗&lt;/a&gt;一文提到的一樣，在數據驅動的時代之下，培養「資料科學力」將不再只是資料科學家的專利；就算你不是資料科學家，也應該加入這個行業。&lt;/p&gt;
&lt;p&gt;這呼應到我們最前面提到的第 3 個趨勢：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="How-to-be-a-bad-data-scientist!"&gt;&lt;a href="https://towardsdatascience.com/how-to-be-a-bad-data-scientist-434dfb5a209c"&gt;How to be a bad data scientist!&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-be-a-bad-data-scientist!"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://towardsdatascience.com/how-to-be-a-bad-data-scientist-434dfb5a209c" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_IDUj1IN8ZvQo2ZO0Fx68pA.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇說明了一般人在學習資料科學時會有的一些錯誤思維，我們應該隨時警惕自己並改善學習態度。&lt;/p&gt;
&lt;p&gt;我自己歸納一下新手 DS 常會遇到的迷思或困境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缺乏持續學習的動力：剛開始你可能因為資料科學很夯，薪水很高決定成為一個 DS。但資料科學領域的最大特色是變動很快。缺乏熱情或是單純跟隨潮流的人，如果沒有持續學習的動力可能會中途開始懷疑人生&lt;/li&gt;
&lt;li&gt;誤以為了解全世界：上了幾門線上課程或是參加過 Kaggle 競賽，利用乾淨的資料在 Jupyter Notebook 上建立一個 XGboost 模型就誤以為掌握了所有的資料科學。事實上，業界的 DS 需要做更多事情，如清理資料、建立可靠的資料管道以及與其他部門溝通協調等等。雖然本文沒辦法教你怎麼做良好溝通，想多了解資料工程的話可以參考&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;為了學而學，沒有思考如何應用所學：這點甚至稍微資深的 DS 都會遺忘。你最少要嘗試將平常閱讀的文章、學到的分析手法應用在解決工作上的問題。甚至更好的是，改善自己或者周遭人們的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇並不直接跟本篇主題相關，不過值得 DS 們參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;&lt;a href="https://medium.com/netflix-techblog/notebook-innovation-591ee3221233"&gt;Beyond Interactive: Notebook Innovation at Netflix&lt;/a&gt;&lt;a class="anchor-link" href="#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://medium.com/netflix-techblog/notebook-innovation-591ee3221233" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/neflix-notebook.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;平常有在關注 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt; 的 DS 們想必都注意到 Netflix 這篇文章了吧。&lt;/p&gt;
&lt;p&gt;Netflix 的資料平台（Data Platform）團隊發現，儘管企業內部有各式各樣使用該平台的使用者（如 DS、資料工程師以及分析人員等），並且表面上看來都在使用不同的程式語言，不同的工具，但事實上這些平常在處理數據的人的工作流程（Workflow）大多都可以分為這幾個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存取資料&lt;/li&gt;
&lt;li&gt;資料處理&lt;/li&gt;
&lt;li&gt;資料視覺化&lt;/li&gt;
&lt;li&gt;排程以及產品化（Productization）&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/netflix-data-roles.jpeg" style=""/&gt;
&lt;p&gt;Netflix：不同數據專業的人使用很不一樣的工具以及程式語言，但其實宏觀來看，處理數據的工作流程都很類似&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在明白這點以後，Netflix 的資料平台團隊展示了他們如何利用 Notebook 的「介面跟計算分離」這個特性，開發出能讓所有分析人員使用的統一介面。&lt;/p&gt;
&lt;p&gt;在 Netflix 裡頭，任何一個 DS / DE 都可以利用一個簡單的 Notebook 介面做到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存取 Netflix 裡頭所有的數據：內部有專門的團隊維護一個可以存取所有資料的 Python 函式庫&lt;/li&gt;
&lt;li&gt;參數化 Notebook：一個 Notebook 可以變成一個模板（Template），讓使用者可以每次利用不同參數重新執行類似的數據處理&lt;/li&gt;
&lt;li&gt;排程（Scheduling）。當使用者決定為目前 Notebook 規劃排程後，該平台會將當下使用者的 Notebook 存到 AWS S3 變成排程工作的參數設定，並在實際排程時建立輸出用的 Notebook，將所有 Logs 以及輸出都放在該輸出用的 Notebook 裡面，方便之後查看以及除錯。這最小化了一個 DS 建立 ETL 工作的時間以及人力成本。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇因為篇幅關係不會進一步解釋，但就算你平常沒在用 Notebook，應該也能感受到 Netflix 的數據平台團隊為了支援每天能在 100 PB 的數據量上跑的 15 萬個處理工作（Job）所做出的努力吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;抽象化（Abstraction）是對付複雜性（Complexity）最好的解藥。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個例子我們看到，Netflix 為了提高他們內部資料科學家的效率以及規模性（Scalability），做了一個這樣的數據平台，將所有基本的資料工程，甚至是對一個正常的 DS 來說需要花不少時間熟悉的數據處理流程都自動化 / 抽象化了。&lt;/p&gt;
&lt;p&gt;在全球數據量仍然爆炸性成長的今天，這樣的抽象化只會越來越普遍地出現在各個企業裡頭，而這對一個資料科學家來說當然是好事。再過一陣子，一個一般的 DS 或許也就不用再花所謂的 80 % 時間來做數據清理、建構資料管道等瑣事上，而是能有更多的時間在建構預測模型、進行複雜分析等更高層次的工作。&lt;/p&gt;
&lt;p&gt;現在我們已經有各種開源的自動化工具，幫我們快速地將機器學習產品化（如 Amazon 的 &lt;a href="https://aws.amazon.com/tw/sagemaker/"&gt;SageMaker&lt;/a&gt;）、自動化清理數據的工具（如 Google 的 &lt;a href="https://cloud.google.com/dataprep/"&gt;CLOUD DATAPREP&lt;/a&gt;）等等。一方面 DS 要慶幸這些事情可以被自動化，一方面則要努力學習新知，不能停滯不前。&lt;/p&gt;
&lt;p&gt;這呼應到我們前面提到的第 1 點趨勢：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我們並不都在有這些平台的企業工作，了解自己企業的現有狀況，盡可能將能夠自動化的「數據處理瑣事」抽象化，能讓一個 DS 提高自己的效率以及工作價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;&lt;a href="https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists"&gt;What Data Scientists Really Do, According to 35 Data Scientists&lt;/a&gt;&lt;a class="anchor-link" href="#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/aug18-15-137888421-burakpekakcan-1200x675.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果只有閱讀一篇原文的時間的話，我推薦你這篇哈佛商業評論的文章。&lt;/p&gt;
&lt;p&gt;這篇透過訪談多位資料科學家的工作經驗，讓我們能好好地思考「資料科學家」這個職業的未來走向。&lt;/p&gt;
&lt;p&gt;首先，根據這些資料科學家所說，（事實上我也這麼認為）一個 DS 並不像有些人想像的，整天在研究 AI 演算法。&lt;/p&gt;
&lt;p&gt;實際上，這些 DS 在做的是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料搜集、資料清理&lt;/li&gt;
&lt;li&gt;統計推論（Statistical Inference）&lt;/li&gt;
&lt;li&gt;建立儀表板（Dashboard）或是績效報告&lt;/li&gt;
&lt;li&gt;實作機器學習以及資料處理管道（Date Pipeline）&lt;/li&gt;
&lt;li&gt;跟決策者辯論，影響企業決策&lt;/li&gt;
&lt;li&gt;跟專案的利害關係人說明分析結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從這篇文章，我們也再次觀察到同樣的趨勢：現在的資料科學家的工作範圍以及被期待的技能樹過於廣泛，未來將會再進一步細分。其專業領域的細分的方式則可能依企業不同而異，像是前面提到 Airbnb 的 DS 的三個路線；或是此篇文章內提到的 Type A、Type B 的資料科學家；或是更廣泛地分為資料科學家、資料工程師以及機器學習工程師。&lt;/p&gt;
&lt;p&gt;我們同時也從這些專業的資料科學家的口中再度認識到溝通能力的重要。&lt;/p&gt;
&lt;p&gt;比起建立複雜的深度學習模型，學會做一個好的簡報，並跟非技術專業的利害關係人溝通結果，進而影響企業決策才是對一個 DS 來說更為重要的事情。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.books.com.tw/products/0010647371"&gt;人類大歷史&lt;/a&gt;的作者&lt;a href="http://www.ynharari.com/"&gt;哈拉瑞 Yuval Noah Harari&lt;/a&gt; 最近也在&lt;a href="https://www.wired.co.uk/article/yuval-noah-harari-extract-21-lessons-for-the-21st-century"&gt;訪談&lt;/a&gt;中提到未來 AI 時代裡頭，人類 4 個最重要的技能 4C：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;批判性思考（Critical Thinking）&lt;/li&gt;
&lt;li&gt;合作能力（Collaboration）&lt;/li&gt;
&lt;li&gt;創造能力（Creativity）&lt;/li&gt;
&lt;li&gt;溝通能力（Communication）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這呼應到我們最前面的第 2 點的發現：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;&lt;a name="ending"&gt;&lt;/a&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這篇文摘裡頭，我們透過閱讀不少跟資料科學家相關的文章，了解到了幾個 DS 的職涯趨勢：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/li&gt;
&lt;li&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/li&gt;
&lt;li&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/li&gt;
&lt;li&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些都是不錯的發現，但如果你只能記住其中一個的話，我希望是最後一個。&lt;/p&gt;
&lt;p&gt;如同我們在 Airbnb、Netflix 的例子以及多名專業的 DS 口中可以觀察到這個現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在不久的將來，非常有可能各個企業都依照分析領域的不同，再度細分一個 DS 的工作，並將其分為不同的路線，或是直接產生新的職業。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要我打個比方的話，就是像真實世界的 RPG 一樣。&lt;/p&gt;
&lt;p&gt;在急著成為一個資料科學家之前，仔細思考數據科學領域裡頭，究竟什麼地方吸引你？&lt;/p&gt;
&lt;p&gt;你是喜歡做統計分析、執行 AB 測試來提供產品改善的洞見嗎？&lt;/p&gt;
&lt;p&gt;還是你熱衷於研究機器學習演算法，想辦法利用龐大數據改善企業的數據產品（Data Product）呢？&lt;/p&gt;
&lt;p&gt;或者你對建構能夠處理大規模資料的數據平台的工作感興趣呢？&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/doors-1767562_1280.jpg" style=""/&gt;
&lt;p&gt;現在就開始思考你想要開的門、走的路線、想要成為的角色是什麼，專精它，並尋找渴望你專業的企業&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;不管你的答案是什麼，既然我們在玩 MMORPG 遊戲（好吧，可能只有我玩）的時候都會去認真地理解每個職業的優缺點、技能樹等等，為何不將各種數據職業視為一個個的 RPG 角色，了解自己的興趣以及跟這些職業的適合程度呢？&lt;/p&gt;
&lt;p&gt;玩遊戲很嗨，能把規劃數據相關的職涯當做遊戲來玩更嗨。&lt;/p&gt;
&lt;p&gt;最後，讓我把文章開頭所問的問題交給你思考並回答：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;數據科學 MMORPG 全球玩家齊聚上線。你，選好自己的角色了嗎？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載</title><link href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html" rel="alternate"></link><published>2018-08-21T23:30:00+09:00</published><updated>2018-08-21T23:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-21:/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html</id><summary type="html">&lt;p&gt;Airflow 是一個以 Python 開發的工作流管理系統，也是資料工程不可或缺的利器之一。近年不管是資料科學家、資料工程師還是任何需要處理數據的軟體工程師，Airflow 都是他們用來建構 ETL 以及處理批量資料的首選之一。這篇文章希望以一個簡易的漫畫連載通知 App 作為引子，讓讀者直觀地了解 Airflow 背後的運作原理、建立資料工程的知識基礎，並在閱讀本文後發揮自己的創意，實際應用 Airflow 來解決並自動化自己及企業的數據問題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;這是一篇當初我在入門資料工程以及 Airflow 時希望有人能為我寫好的文章。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt; 是一個從 Airbnb 誕生並開源，以 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 寫成的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F"&gt;工作流程管理系統（Workflow Management System）&lt;/a&gt;，也是&lt;a href="https://github.com/apache/incubator-airflow#who-uses-airflow"&gt;各大企業&lt;/a&gt;的資料工程環節中不可或缺的利器之一。&lt;/p&gt;
&lt;p&gt;近年不管是資料科學家、資料工程師還是任何需要處理數據的軟體工程師，Airflow 都是他們用來建構可靠的 ETL 以及定期處理批量資料的首選之一。（事實上在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt;，除了 DS/DE，會使用 Airflow 的軟體工程師也不在少數）&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/smartnews-dmp.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我們在
    &lt;a href="https://leemengtaiwan.github.io/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html#%E5%84%80%E8%A1%A8%E6%9D%BF%E4%B8%8A%E7%9A%84-KPI-%E6%98%AF%E6%80%8E%E9%BA%BC%E7%94%A2%E7%94%9F%E7%9A%84%EF%BC%9F" target="_blank"&gt;「資料科學家 L 的奇幻旅程(1)：新人不得不問的 2 個問題&lt;/a&gt;
    」一文提到 SmartNews 如何利用 Airflow 建立資料管道並管理各種 ETL
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;儘管它的方便以及強大，在完全熟悉 Airflow 之前，因為有些專業術語以及資料工程概念的存在，不少初學者（包含當時的我）在剛開始的時候容易四處撞壁。另外如果一開始就以 ETL 當作 Airflow 的入門的話，未免難度過高且缺少共鳴。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="追連載：一個-Airflow-的輕鬆使用案例"&gt;追連載：一個 Airflow 的輕鬆使用案例&lt;a class="anchor-link" href="#追連載：一個-Airflow-的輕鬆使用案例"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這篇文章希望以一個簡易的漫畫連載通知 App 作為引子，讓完全沒有資料工程經驗的讀者也能夠透過這個 App 的例子，輕鬆地理解工作流程的概念、自動化排程以及 Airflow 的使用方式。閱讀完本文，你將對 Airflow 以及自動排程工作有更深的理解，並學會如何建立多個能在 Airflow 上穩定運行的工作流程。更重要的，我相信你能利用這些學到的基礎，開始自動化自己生活中以及企業的數據處理 pipeline。&lt;/p&gt;
&lt;p&gt;如果你對資料工程有興趣，不太熟悉如 Airflow 這種工作流程管理系統，但有基本的 Python 程式基礎的話（或是純粹對用 Python 寫一個漫畫連載通知 App 有興趣），我相信這篇文章應該會很適合你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/app.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Slack 截圖：追漫畫應該要是件輕鬆的事情。&lt;br/&gt;我們將利用 Airflow 來實作一個像這樣會每天從 &lt;a href="https://slack.com/" target="_blank"&gt;Slack&lt;/a&gt; 推送最新漫畫連載的 App
    &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想重新複習 ETL 概念的讀者可以參考先前的文章：&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html#%E8%B3%87%E6%96%99%E7%AE%A1%E9%81%93"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="章節傳送門"&gt;章節傳送門&lt;a class="anchor-link" href="#章節傳送門"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#所以為何要這-App-？"&gt;了解需求：所以為何要這 App ？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#工作流概念-&amp;amp;-Airflow"&gt;工作流概念 &amp;amp; Airflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Python-&amp;amp;-Airflow-實作"&gt;Python 實作 &amp;amp; Airflow 操作&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#建置-Airflow-環境"&gt;建置 Airflow 環境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Airflow-基本概念"&gt;Airflow 基本概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#App-版本一：大鍋炒"&gt;App 版本一：大鍋炒&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#app-v3"&gt;App 版本三：填填樂&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為讓讀者完整了解開發這個 App 的背景脈絡、此 App 的執行邏輯以及使用 Airflow 來定期執行 App 的原因，在我們實際開始寫 Python 之前有兩小節的解說。&lt;/p&gt;
&lt;p&gt;如果你已經有 Airflow 及工作流程的基礎知識，且迫不及待想看 Python 程式碼，可以直接跳到 &lt;a href="#Python-&amp;amp;-Airflow-實作"&gt;Python 實作 &amp;amp; Airflow 操作&lt;/a&gt;章節之後再回來查看前面段落。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/toc-demo.jpg" style=""/&gt;
&lt;p&gt;
        這篇文章章節不少，你有時可能會需要回到前面章節回顧一些內容。活用左側放大鏡按鈕下面的章節傳送門能讓你更輕鬆地徜徉在本文的 Airflow 世界（此功能因為作者時間有限，目前只在寬螢幕實現）
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="所以為何要這-App-？"&gt;所以為何要這 App ？&lt;a class="anchor-link" href="#所以為何要這-App-？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;平常有在網路上追漫畫連載的讀者們應該都了解，市面上的漫畫網站通常都不是會員制的。更不用說「在新連載出的時候自動通知您！」這種推送功能（Push Notification）了。也因為這樣，導致我常常三不五時上去這些漫畫網站，看每個關注的漫畫到底出了最新一話了沒。可想而知，答案通常是否定的。（一週出一次每天檢查也沒用啊啊啊）&lt;/p&gt;
&lt;p&gt;如果你只看海賊王一個漫畫（索隆好帥！），這或許沒什麼負擔。但就像上面 Slack 截圖顯示的，我不只關注海賊王，還看很多其他漫畫。讓事情更糟的是，到最後你會發現：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不記得自己到底在追哪些漫畫&lt;/li&gt;
&lt;li&gt;每一部漫畫最後到底是看到第幾話&lt;/li&gt;
&lt;li&gt;上一話是什麼時候出的&lt;/li&gt;
&lt;li&gt;有幾話是新出而你還沒看的 &lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/tim-gouw-68319-unsplash.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;手動追最新連載經常讓我追到懷疑人生&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;追漫畫連載應該要是個輕鬆且享受的事情。在一個人人會寫 code 的時代，何不自己做個 App 幫我們自動檢查新連載呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="工作流概念-&amp;amp;-Airflow"&gt;工作流概念 &amp;amp; Airflow&lt;a class="anchor-link" href="#工作流概念-&amp;amp;-Airflow"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;概念上我們可以把此 App 需要做的工作按照「先後順序」由上往下列出來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;想像上述的工作清單由上往下流動，就形成了一個工作流程（Workflow）：前一個工作如寄 Slack 通知就是下一個工作：更新閱讀紀錄的上游工作（Upstream Task）。&lt;/p&gt;
&lt;p&gt;反過來說，更新閱讀紀錄則是寄 Slack 通知的下游工作（Downstream Task）。&lt;/p&gt;
&lt;p&gt;定義出工作之間的上下游關係的好處是什麼？&lt;/p&gt;
&lt;p&gt;可以讓我們確保工作之間的相依性（Dependencies）並讓如 Airflow 這種工作流程管理系統幫我們管理工作流程。一般而言，下游工作只能在上游「成功」完成之後被執行；如果上游工作失敗的話，下游工作應該被終止，通常也沒有繼續執行的意義（例：如果 App 在執行上游工作「取得使用者閱讀紀錄」時就失敗的話，不需要也不應該執行下游的「更新閱讀紀錄」工作）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/www-headsmartmedia-com-179929-unsplash.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;我們的 App 實際上就是一個完整的工作流程。&lt;br/&gt;
       App 從工作 A 執行到工作 B 就像是水從上游 A 流動到下游 B 一樣。&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;屏除剛剛介紹的工作流程概念，要實作這 App 的邏輯一點都不難。事實上我們只需要寫個 Python script，把每個工作各別用一個函式（Function）實作後再按照順序呼叫它們就好（你甚至可以只用一個函式實現所有邏輯！），為何需要 Airflow？&lt;/p&gt;
&lt;p&gt;在你往下滑前給個提示：我們這個 App 不是每一秒鐘都在執行。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對！顯而易見的，因為這個 App / 工作流程設計的方式不是即時工作（Realtime Job），而是批次工作，執行一次以後就結束它的生命了。&lt;/p&gt;
&lt;p&gt;我們可不希望它只在明天早上（比方說早上 9 點）去檢查新連載。我們希望它明天、下個月或是明年的今天早上都在運作。這也是為何我們需要一個像是 Airflow 的工作流程管理系統：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定期執行工作流程&lt;/li&gt;
&lt;li&gt;維護相依性，確保工作流程從上游到下游執行，不會在上游沒完成前執行到下游&lt;/li&gt;
&lt;li&gt;各個工作失敗時自動重試（&lt;a href="https://zh.wikipedia.org/wiki/%E6%91%A9%E8%8F%B2%E5%AE%9A%E7%90%86"&gt;墨菲定律&lt;/a&gt;，所有你認為邏輯上萬無一失的工作都會因為各種無法預期的情況給你失敗的驚喜）&lt;/li&gt;
&lt;li&gt;簡單易懂的 &lt;a href="https://airflow.apache.org/"&gt;Web UI&lt;/a&gt; 方便管理工作流程&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Airflow 非常適合用來管理相依性複雜，且具批次處理性質的工作流程。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/airflow.gif" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Airflow 的 &lt;a href="https://airflow.apache.org/" target="_blank"&gt;Web UI&lt;/a&gt; 讓我們能更輕鬆地管理及排程工作流程（後面我們會實際利用此 UI 管理並開發 App）&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上我們也可以透過 Linux 排程工具 &lt;a href="https://zh.wikipedia.org/wiki/Cron"&gt;Cron&lt;/a&gt; 來定期執行我們的 App。但 Cron 本身沒有工作流程的概念，沒辦法管理上下游工作的相依性、失敗時無法自動重跑、當然也沒有易懂的 Web UI。因此以 2, 3, 4 項的角度來看，Airflow 是一個比較好的選擇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，我們已經了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何要做這個 App&lt;/li&gt;
&lt;li&gt;此 App 的工作流程以及工作流程（Workflow）的基本概念&lt;/li&gt;
&lt;li&gt;為何要使用 Airflow 來幫我們管理 App 的工作流程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接著只差用 Python 將 App 的邏輯以 Airflow 工作流程的方式實現了，讓我們開始實作吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/show-me-the-code.jpg" style=""/&gt;
&lt;p&gt;[Warning] 接下來不只給你 Python 程式碼，而是給你大量的 Python 程式碼&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Python-&amp;amp;-Airflow-實作"&gt;Python &amp;amp; Airflow 實作&lt;a class="anchor-link" href="#Python-&amp;amp;-Airflow-實作"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;程式碼都會放在這個 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Github Repo&lt;/a&gt; 裡頭供你在閱讀完文章後參考。但如果你正在用電腦瀏覽的話且想趕快熟悉 Airflow 開發的話，可以 &lt;code&gt;git clone&lt;/code&gt; 下來以後跟著文章走。&lt;/p&gt;
&lt;p&gt;開啟一個新的 terminal，移動到你平常放新專案的資料夾，然後輸入：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/leemengtaiwan/airflow-tutorials.git
&lt;span class="nb"&gt;cd&lt;/span&gt; airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;之後沒特別明說的話，指令都會是在 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下執行。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建置-Airflow-環境"&gt;建置 Airflow 環境&lt;a class="anchor-link" href="#建置-Airflow-環境"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;雖然 production 環境需要很多調整，以建構測試環境來說，基本上參考官方的 &lt;a href="https://airflow.apache.org/start.html#quick-start"&gt;Quick Start&lt;/a&gt; 就可以很輕鬆地完成。因為 Airflow 是以 Python 實作的，我們可以很輕易地用 &lt;code&gt;pip install&lt;/code&gt; 來安裝所有需要的東西。用 &lt;a href="https://anaconda.org/"&gt;Anaconda&lt;/a&gt; 則是能讓你事後管理不同專案的環境時輕鬆不少：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda create -n airflow-tutorials &lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6 -y
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
pip install &lt;span class="s2"&gt;"apache-airflow[crypto, slack]"&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
airflow initdb
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以上的指令幫我們：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建立並啟動一個新的 Anaconda 環境&lt;/li&gt;
&lt;li&gt;在此環境下安裝 Airflow 以及&lt;a href="https://airflow.apache.org/installation.html#extra-packages"&gt;支援 Slack 功能的額外函式庫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;設定專用路徑以讓 Airflow 之後知道要在哪找檔案、存 log&lt;/li&gt;
&lt;li&gt;初始化 Airflow Metadata DB。此 DB 被用來記錄所有工作流程的執行狀況&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;理想上把 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 加入到 &lt;code&gt;~/.bash_profile&lt;/code&gt; 裡頭之後會比較輕鬆，不過現在不做也沒關係。&lt;/p&gt;
&lt;p&gt;【2018/08/27 加註】如果沒有設定 &lt;code&gt;export AIRFLOW_HOME="$(pwd)"&lt;/code&gt; 就執行 &lt;code&gt;airflow initdb&lt;/code&gt;的話，會讓 Airflow 使用作者當初測試時使用的路徑，而不是你 &lt;code&gt;git clone&lt;/code&gt; 下來的 repo 的路徑而造成問題，務必記得設定。&lt;/p&gt;
&lt;p&gt;在環境都搞定之後，我們可以啟動 Airflow 的網頁伺服器：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow webserver -p &lt;span class="m"&gt;8080&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著在瀏覽器輸入 &lt;code&gt;localhost:8080&lt;/code&gt; 就能看到 Airflow 簡潔的 Web UI 了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-impression-of-airflow-web-ui.jpg" style=""/&gt;
&lt;p&gt;Airflow Web UI 首頁：顯示所有已定義的工作流程（DAG）。&lt;br/&gt;
        圖中的 3 個 DAG 就對應到我們接下來逐漸改善 App 時產生的三個 App 版本&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Airflow-基本概念"&gt;Airflow 基本概念&lt;a class="anchor-link" href="#Airflow-基本概念"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;這邊值得注意的是 Airflow 利用 &lt;a href="https://airflow.apache.org/concepts.html#dags"&gt;DAG&lt;/a&gt; 一詞來代表一種特殊的工作流程（Workflow）。如工作流程一樣，DAG 定義了我們有什麼工作、工作之間的執行順序以及依賴關係。DAG 的最終目標是將所有工作依照上下游關係全部執行，而不是關注個別的工作實際上是怎麼被實作的（這點在後面的 &lt;a href="#Operator：將實作邏輯跟-DAG-排程分離"&gt;Operator&lt;/a&gt; 章節會有詳細解釋）。&lt;/p&gt;
&lt;p&gt;另外從它的全名&lt;a href="http://www.csie.ntnu.edu.tw/~u91029/DirectedAcyclicGraph.html"&gt;有向無環圖（&lt;strong&gt;D&lt;/strong&gt;irected &lt;strong&gt;A&lt;/strong&gt;cyclic &lt;strong&gt;G&lt;/strong&gt;raph）&lt;/a&gt;你可以看出它具備兩個特色：「有向」及「無環」。事實上我們的 App 邏輯就是一個理想的 DAG。首先，裡頭包含多個邏輯上的工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很明顯地， App 是從上而下地執行每個工作，即為「有向」；同時 App 不會在更新閱讀紀錄以後（下游工作），還跑回去漫畫網站看有沒有新的章節（上游工作）：上游會指向下游，但下游不會指回上游，此即「無環」。&lt;/p&gt;
&lt;p&gt;有了這個理解以後，我們的目標就很明顯了：將 App 的工作流程轉換成一個能在 Airflow 上執行的 DAG，然後排程它，就能讓它每天去找新連載！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本一：大鍋炒"&gt;App 版本一：大鍋炒&lt;a class="anchor-link" href="#App-版本一：大鍋炒"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Airflow 世界裡，一個 DAG 是由一個 Python script 所定義的。&lt;/p&gt;
&lt;p&gt;以下是我們 App 的第一個版本，也是最簡單的 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 的程式碼（&lt;code&gt;airflow-tutorials/dags&lt;/code&gt; 資料夾底下的 &lt;code&gt;comic_app_v1.py&lt;/code&gt;）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;

&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fn_superman&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Murphy's Law&lt;/span&gt;
    &lt;span class="n"&gt;accident_occur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;accident_occur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;天有不測風雲,人有旦夕禍福"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"工作遇到預期外狀況被中斷&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;new_comic_available&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_comic_available&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"寄 Slack 通知"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"什麼都不幹，工作順利結束"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你能專注在 Airflow 及 DAG 最核心的概念，讓我先用 &lt;code&gt;print()&lt;/code&gt; 假裝我們已經在一個函式 &lt;code&gt;fn_superman&lt;/code&gt; 裡頭實作所有工作的邏輯了。在修改完代表一個 DAG 的 Python script 後，要確保 Airflow 能正確地將其視為一個 DAG，最基本的檢查就是用 Python 直接執行該 script。&lt;/p&gt;
&lt;p&gt;你目前的 terminal 應該正被 Airflow 的網頁伺服器所使用。如果你還沒有把 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 加到 &lt;code&gt;~/.bash_profile&lt;/code&gt; 裡頭的話，開啟一個新的 terminal，重新進入 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾以後執行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這邊我們為新的 terminal 啟動 Anaconda 環境，並告訴 Airflow 在 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下找所有它要的東西。（之後要打開新的 terminal 也要做一樣的事情）&lt;/p&gt;
&lt;p&gt;接著我們就可以用 Python 測試 script 的正確性：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python dags/comic_app_v1.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;沒有特別設定的話， Airflow 會去 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 路徑底下的 &lt;code&gt;dags&lt;/code&gt; 子資料夾找 DAG，這也是為何我們在上面路徑有個 &lt;code&gt;dags&lt;/code&gt;。（你可以去 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Repo&lt;/a&gt; 確定檔案的路徑。）&lt;/p&gt;
&lt;p&gt;如果沒有任何錯誤跑出來，恭喜！Airflow 能將其視為一個正常的 DAG 並顯示在 Web UI 上。之後只要你有修改 DAG 裡頭的程式碼，都應該做這個檢查。&lt;/p&gt;
&lt;p&gt;這個 DAG 的程式碼雖不長，卻隱含了一些非常重要的概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="輕鬆排程"&gt;輕鬆排程&lt;a class="anchor-link" href="#輕鬆排程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;靠近 &lt;a href="#App-版本一：大鍋炒"&gt;Script&lt;/a&gt; 尾端的這行實際上就定義了我們的 DAG 並將它命名為 &lt;code&gt;comic_app_v1&lt;/code&gt;。而此 DAG 的排程（Scheduling）設定如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;'start_date': datetime(2100, 1, 1, 0, 0)&lt;/code&gt; 代表從西元 2100 年開始第一次執行此 DAG &lt;/li&gt;
&lt;li&gt;每次執行之間間隔多久。&lt;code&gt;'schedule_interval': '@daily'&lt;/code&gt; 代表每天執行一次&lt;/li&gt;
&lt;li&gt;&lt;code&gt;'retries': 2&lt;/code&gt; 則允許 Airflow 在 DAG 失敗時重試 2 次 &lt;/li&gt;
&lt;li&gt;DAG 失敗後等多久後開始重試（&lt;code&gt;'retry_delay': timedelta(minutes=1)&lt;/code&gt;　代表等一分鐘）&lt;/li&gt;
&lt;li&gt;更多更多 ...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;乍看之下沒什麼了不起的，就是些設定。&lt;/p&gt;
&lt;p&gt;但如果你有自己從頭實作過資料管道的經驗或者使用過 &lt;a href="https://zh.wikipedia.org/wiki/Cron"&gt;Cron&lt;/a&gt; 排程 ETL，就能體會 Airflow 這樣的「Configuration as Code」有多麽的強大：你只做一些設定（Config），Airflow 就幫你自動建立可靠、失敗時會自動重試的工作流程。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/utah-mechanical-contractors-1103725_1280.jpg" style=""/&gt;
&lt;p&gt;按幾個按鈕就能做出可靠的工作流程，將自動化、失敗重試、相依性管理全部交給 Airflow&lt;/p&gt;
&lt;/center&gt;&lt;p&gt;這些排程設定為了方便管理，一般都另外定義在 &lt;code&gt;default_args&lt;/code&gt; 變數並放在 script 的最上面。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Operator：將實作邏輯跟-DAG-排程分離"&gt;Operator：將實作邏輯跟 DAG 排程分離&lt;a class="anchor-link" href="#Operator：將實作邏輯跟-DAG-排程分離"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;最有趣的是我們使用 &lt;code&gt;with&lt;/code&gt; 關鍵字來定義一個只屬於 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 的領域。在這裡頭我們則定義了唯一一個工作 &lt;code&gt;superman_task&lt;/code&gt; 處理所有事情（你應該能猜到為何它被這樣命名）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這段程式碼用白話翻譯的話，就是說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 裡頭，利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個名為 &lt;code&gt;superman_task&lt;/code&gt; 的工作，而實際執行這個工作的時候，呼叫 &lt;code&gt;fn_superman&lt;/code&gt; 函式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一個非常重要且需要你搞懂的概念是，現在說的工作（Task），是指那些實際透過程式碼宣告，在 DAG 裡頭被定義出來的工作，如 &lt;code&gt;superman_task&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;前面我們提到，App 概念上本身就包含了多個工作（步驟）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些是「邏輯上」的工作，而在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭，為了方便說明，我們將它們全部包起來，定義成唯一一個 Airflow 工作： &lt;code&gt;superman_task&lt;/code&gt;。（在 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節裡，我們則會分別為這些「邏輯工作」建立他們自己的 Airflow 工作）。&lt;/p&gt;
&lt;p&gt;回到 Opeartor 的話題。在 Airflow 裡頭，DAG 只知道有哪些工作以及這些工作之間的執行順序。而實際上這些工作要怎麼被完成，其實作邏輯則是由各種 &lt;a href="https://airflow.apache.org/code.html#operators"&gt;Operator&lt;/a&gt; 負責。&lt;/p&gt;
&lt;p&gt;你可以想像 &lt;a href="https://airflow.apache.org/code.html#airflow.operators"&gt;Opeartors&lt;/a&gt; 就是幫我們完成特定種類工作的小幫手，像是一些常見的例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.PythonOperator"&gt;PythonOperator&lt;/a&gt; 執行一個 Python 函式&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.BashOperator"&gt;BashOperator&lt;/a&gt; 執行 Bash 指令&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.S3KeySensor"&gt;S3KeySensor&lt;/a&gt; 監測 S3 上的檔案存不存在&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.SlackAPIPostOperator"&gt;SlackAPIPostOperator&lt;/a&gt; 送訊息給 Slack&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要建立一個 DAG 裡的工作（Task）就是依照你想要它完成的特定目標，來選擇合適的 Operator。比方說上面的 &lt;code&gt;superman_task&lt;/code&gt; 就是透過 &lt;code&gt;PythonOperator&lt;/code&gt; 來執行特定的 Python 函式 &lt;code&gt;fn_superman&lt;/code&gt;，而該函式則把 App 裡頭所有的「邏輯工作」實作了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PythonOperator&lt;/code&gt; 可以說是 Airflow 裡最基本也最強大的 &lt;a href="https://airflow.apache.org/code.html#airflow.operators"&gt;Opeartors&lt;/a&gt; 之一。學會使用方法以後，你可以將任何你定義的 Python 函式變成一個 Airflow 工作。&lt;/p&gt;
&lt;p&gt;基本的使用方法非常簡單，你只要指定一個可呼叫的 Python 函式給 &lt;code&gt;python_callable&lt;/code&gt; 參數以及設定一個工作名稱（task_id）即可：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在後面的 &lt;a href="#Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;/a&gt;章節，我們則會看到如何使用其他 Operator 如 &lt;a href="https://airflow.apache.org/code.html#airflow.operators.SlackAPIPostOperator"&gt;SlackAPIPostOperator&lt;/a&gt; 來新增一個可以幫我們送 Slack 訊息的工作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="測試開發-Airflow-工作"&gt;測試開發 Airflow 工作&lt;a class="anchor-link" href="#測試開發-Airflow-工作"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該已經理解 DAG 本身關注的是有哪些工作以及他們的相依性，而不是各個工作的實作邏輯。（雖然在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭只有一個工作所以不存在相依性問題）&lt;/p&gt;
&lt;p&gt;我們用 &lt;code&gt;python dags/comic_app_v1.py&lt;/code&gt; 確保 DAG 本身沒有語法問題以後，接著就是要確保裡頭每個工作（Task）的執行結果如我們預期。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭，我們只有一個工作 &lt;code&gt;superman_task&lt;/code&gt; （其透過一個函式 &lt;code&gt;fn_superman&lt;/code&gt; 幫我們做所有邏輯上的工作）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fn_superman&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Murphy's Law&lt;/span&gt;
    &lt;span class="n"&gt;accident_occur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;accident_occur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;天有不測風雲,人有旦夕禍福"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"工作遇到預期外狀況被中斷&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;new_comic_available&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_comic_available&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"寄 Slack 通知"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"什麼都不幹，工作順利結束"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這樣的設計有什麼優點？&lt;/p&gt;
&lt;p&gt;一般來說 DAG 跟工作是一對多的關係（一個工作流程裡有多個小工作要做）：要讓一個 DAG 順利跑完，理所當然所有工作都要順利執行完畢。但 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 是個特例，它裡頭只有一個工作，一人吃全家飽。只要測試且確保 &lt;code&gt;superman_task&lt;/code&gt; 工作的執行結果如我們預期，就代表 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 能順利完成，簡單易懂！&lt;/p&gt;
&lt;p&gt;我們可以使用 Airflow 的 &lt;code&gt;test&lt;/code&gt; 指令來幫我們測試這個工作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-18
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這行指令是讓 Airflow 幫我們測試 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭的 &lt;code&gt;superman_task&lt;/code&gt; 工作，並假設這個工作是在 &lt;code&gt;2018-08-18&lt;/code&gt; 這個日期被執行。在我們的 App 例子中，&lt;code&gt;superman_task&lt;/code&gt; 工作的執行結果基本上不會受到執行日期的影響，可以隨便你改。&lt;/p&gt;
&lt;p&gt;但想像一個每天 24 點 0 分準備被啟動，從資料庫撈出數據並計算「當天」使用者數目的工作。其 SQL 查詢可能長這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{execute_date}'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因為此工作的結果會受到執行日期的影響，在測試的時候，你就得仔細選擇執行日期（execute_date）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;拉回 &lt;code&gt;superman_task&lt;/code&gt; 工作的測試。&lt;/p&gt;
&lt;p&gt;從上面 &lt;code&gt;fn_superman&lt;/code&gt; 函式的程式碼你可能已經注意到，我埋了個小彩蛋，每次執行都會有不同的執行結果。&lt;/p&gt;
&lt;p&gt;幸運的話你會得到下面這種：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-01
取得使用者的閱讀紀錄
去漫畫網站看有沒有新的章節
跟紀錄比較，有沒有新連載？
什麼都不幹，工作順利結束
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;喔耶！這執行結果如我們預期，可以讓 DAG 上線定期執行了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過別高興得太早。多執行幾次看看。如果墨菲定律發生，你會得到失敗的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-01
取得使用者的閱讀紀錄
去漫畫網站看有沒有新的章節
跟紀錄比較，有沒有新連載？

天有不測風雲,人有旦夕禍福
工作遇到預期外狀況被中斷
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設此執行結果不是我們預期的結果，該怎麼辦？&lt;/p&gt;
&lt;p&gt;如果你反應夠快，會說：&lt;/p&gt;
&lt;p&gt;「那又怎麼樣？墨菲定律不會每次發生，而且就算遇到而導致工作失敗的話， Airflow 不是會自己幫我們重試嗎？」&lt;/p&gt;
&lt;p&gt;的確，這是我們在前面&lt;a href="#輕鬆排程"&gt;輕鬆排程&lt;/a&gt;章節提到 Airflow 的強處。畢竟我們這 App 只是在檢查最新連載，不是做什麼很複雜的運算。基本上就算 DAG 裡頭這唯一一個工作 &lt;code&gt;superman_task&lt;/code&gt; 失敗了導致整個 DAG 要重跑，Airflow 也可以應付得來。&lt;/p&gt;
&lt;p&gt;但問題在於，企業在運行資料管道的時候，常常需要分成很多步驟，某些步驟可能需要龐大的計算資源跟時間（像是將每天使用者使用 App 的幾億筆紀錄做匯總存入資料庫），有些則很輕量（如存取一個外部 API 取得外匯比例）。&lt;/p&gt;
&lt;p&gt;現在假設你無視這些不同步驟的性質差異，將它們全部放在一個 &lt;code&gt;fn_superman&lt;/code&gt; 函式裡頭並只建立一個 Airflow 工作，當該 Airflow 工作裡頭任何一個輕量的步驟失敗，Airflow 得重跑整個工作，導致所有龐大計算的步驟也得跟著重新執行，重試的時間/計算成本會大到你哭出來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;雞蛋不要放在同個籃子裡。為邏輯上獨立的工作/步驟分別建立 Airflow 工作，可以讓 Airflow 只從失敗的工作開始重新做起。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此一個比較好的 Airflow DAG 設計模式是為我們 App 裡頭每個邏輯上獨立的工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都分別建立如同 &lt;code&gt;superman_task&lt;/code&gt; 的 Airflow 工作，並定義好它們之間的相依性（Dependencies）。而這將是我們下一節的重點。&lt;/p&gt;
&lt;p&gt;題外話：你可能會納悶為何我們只測試 &lt;code&gt;superman_task&lt;/code&gt; 工作而沒測試整個 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG。當然「一人吃全家飽」是個理由：只要確定 DAG 裡頭唯一一個工作正確運作，我們就能保證此 DAG 沒問題。&lt;/p&gt;
&lt;p&gt;事實上還有一個原因：&lt;code&gt;airflow test&lt;/code&gt; 指令實際上只能用來測試單一工作，而不能測試整個 DAG。關於 DAG 的測試我們在後面的 &lt;a href="#Airflow-排程器"&gt;Airflow 排程器&lt;/a&gt; 章節會詳細說明。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本二：模組化_1"&gt;&lt;a name="app-v2"&gt;&lt;/a&gt;App 版本二：模組化&lt;a class="anchor-link" href="#App-版本二：模組化"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以現在我們要做的改善（Refactoring）很簡單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將 App 邏輯從 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 中的函式 &lt;code&gt;fn_superman&lt;/code&gt; 中拿出來&lt;/li&gt;
&lt;li&gt;為 App 的每個步驟分別定義一個 Python 函式&lt;/li&gt;
&lt;li&gt;在 DAG 裡頭利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立多個 Airflow 工作並分別呼叫這些函式&lt;/li&gt;
&lt;li&gt;定義這些工作的執行順序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;版本二的 App 完整的程式碼如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.dummy_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.slack_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;

&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;anything_new&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_message&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"產生要寄給 Slack 的訊息內容並存成檔案"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;update_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'update_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;generate_message&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"YOUR_SLACK_TOKEN"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;do_nothing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;update_read_history&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;天啊這可比 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 的程式碼長了不少！&lt;/p&gt;
&lt;p&gt;不過在你開始懷疑自己適不適合寫 Airflow DAG 之前讓我提醒你一下。就跟我們剛剛上面提到的，實際上這個 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的架構從上到下也就分為三個區塊：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用 &lt;code&gt;def&lt;/code&gt; 定義負責實作的 Python 函式（們）&lt;/li&gt;
&lt;li&gt;在 DAG 利用各種 &lt;code&gt;Operator&lt;/code&gt; 定義 DAG 工作（大部分是 &lt;code&gt;PythonOperator&lt;/code&gt;，並使用 &lt;code&gt;python_callable&lt;/code&gt; 指定執行步驟 1 定義的函式）&lt;/li&gt;
&lt;li&gt;定義這些 DAG 工作的執行順序（Workflow）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;回頭再看一遍，有沒有清楚一點了？&lt;/p&gt;
&lt;p&gt;在細看 &lt;code&gt;comic_app_v2&lt;/code&gt; 的程式碼前，先讓我們用 Airflow Web UI 研究一下這個 DAG 在做什麼：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a ,="" href="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.gif" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Airflow Web UI 裡頭的 Graph View 幫我們視覺化 DAG 的工作流程&lt;br/&gt;
        （&lt;a ,="" href="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.gif" target="_blank"&gt;這個 GIF 展示如何從 Airflow UI 開啟此畫面&lt;/a&gt;）
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Airflow 工作寫成英文是為了方便使用 &lt;code&gt;airflow test&lt;/code&gt; 指令測試每個工作。&lt;/p&gt;
&lt;p&gt;儘管工作名稱都是英文，你應該不會覺得陌生。因為這就是我們 App 的邏輯：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄（get_read_history）&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節（check_comic_info）&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？（new_comic_available）&lt;ul&gt;
&lt;li&gt;沒有（no_do_nothing）&lt;/li&gt;
&lt;li&gt;有（yes_generate_notification）&lt;ul&gt;
&lt;li&gt;寄 Slack 通知（send_notification）&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄（update_read_history）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看來這應該不是巧合：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Airflow-排程器"&gt;Airflow 排程器&lt;a class="anchor-link" href="#Airflow-排程器"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同當初測試 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭的 &lt;code&gt;superman_task&lt;/code&gt; 工作一樣，在我們放心讓 Airflow 幫我們排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 以前，應該分別測試裡頭所有工作，確保它們的執行結果如我們預期：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 get_read_history &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
取得使用者的閱讀紀錄

airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 check_comic_info &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
跟紀錄比較，有沒有新連載？

airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 new_comic_available &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
去漫畫網站看有沒有新的章節

...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們已經做完所有工作的測試，想讓 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 開始被 Airflow 排程，除了已經被開啟的 Airflow 網頁伺服器以外，我們需要另外開啟 Airflow 排程器（Scheduler）。&lt;/p&gt;
&lt;p&gt;因為目前為止一直在運轉的 Airflow 網頁伺服器只負責：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顯示 DAG 資訊，如工作流程圖、各個 DAG 的運行狀況以及 Logs&lt;/li&gt;
&lt;li&gt;讓我們輕鬆地終止/開始 DAG 排程（在有排程器的前提）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而實際要執行 DAG、分配每個工作的運算資源則需要 Airflow 排程器。Airflow 的架構圖能幫助我們理解這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/airflow-architecture.png" style="width:70%"/&gt;
&lt;p&gt;
&lt;a href="https://medium.com/@dustinstansbury/understanding-apache-airflows-key-concepts-a96efed52b1a" target="_blank"&gt;Airflow 架構圖&lt;/a&gt;：Scheduler 是實際做排程、呼叫 Worker 執行工作的傢伙；我們熟悉的 Webserver 則提供一個 Web UI 讓我們可以輕鬆檢視工作執行時產生的 Logs、DAG 的程式碼以及工作的執行結果；所有資料都被存在 Metadata Database 裡頭。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事不宜遲，讓我們啟動 Airflow 排程器吧！&lt;/p&gt;
&lt;p&gt;現在再打開一個 terminal，進入 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾後設定環境：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著啟動排程器：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow scheduler
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到目前為止你應該有 3 個 terminals 各司其職：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用來輸入 &lt;code&gt;airflow&lt;/code&gt; 相關指令的 terminal&lt;/li&gt;
&lt;li&gt;Airflow Webserver&lt;/li&gt;
&lt;li&gt;Airflow Scheduler&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我保証不會再多了。&lt;/p&gt;
&lt;p&gt;有了排程器以後，打開 UI，在左邊將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 設成「On」後，點擊右邊「Trigger Dag」按鈕可以呼叫排程器馬上開始執行該 DAG。先讓我們按下去以後，再讓我解釋這樣做會發生什麼事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a ,="" href="https://leemeng.tw/images/airflow/trigger-dag-demo.gif" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/ready-to-trigger-dag.png" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;在左邊將 DAG 設成「On」後，可以利用右邊「Trigger Dag」按鈕呼叫排程器馬上開始執行該 DAG &lt;br/&gt;
        （&lt;a ,="" href="https://leemeng.tw/images/airflow/trigger-dag-demo.gif" target="_blank"&gt;這個 GIF 展示如何從 Airflow UI 觸發一個 DAG&lt;/a&gt;）
&lt;/p&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了避免預料之外的排程，Airflow 所有 DAG 的預設狀態都是暫停的（Paused），也就是上圖中如 &lt;code&gt;comic_app_v1&lt;/code&gt; 左邊的「Off」。只有在你將 DAG 的狀態設定成如圖中的 &lt;code&gt;comic_app_v2&lt;/code&gt; 的「On」，排程器才會開始為其做排程。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="手動觸發-DAG"&gt;手動觸發 DAG&lt;a class="anchor-link" href="#手動觸發-DAG"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖說將一個 DAG 取消暫停（Unpause）可以讓它成為 Airflow 的排程對象，實際上 Airflow 的排程又分兩種方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;手動觸發（Manual）&lt;ul&gt;
&lt;li&gt;常用在測試 DAG 或是有意外發生，需要手動重新執行 DAG 的時候&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;定期執行（Scheduled）&lt;ul&gt;
&lt;li&gt;也就是所謂的「正式上線」。&lt;/li&gt;
&lt;li&gt;依照 DAG 的 &lt;code&gt;start_date&lt;/code&gt; 及 &lt;code&gt;schedule_interval&lt;/code&gt; 設定決定何時執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在讓我們先專注在手動觸發。&lt;/p&gt;
&lt;p&gt;當然你也可以在不透過 Web UI 的情況下，直接利用 terminal 取消暫停一個 DAG 並觸發它：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;airflow unpause comic_app_v2
airflow trigger_dag comic_app_v2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;理論上我們剛剛手動觸發的 &lt;code&gt;comic_app_v2&lt;/code&gt; 應該已經跑完了。重新整理你應該會看到 Airflow UI 顯示 DAG 已被成功執行的畫面：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-dag.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從 Web UI 我們可以清楚地看到剛剛手動觸發的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 已經被 Airflow 排程器拿去執行，產生一個新的 DAG Run 並成功執行。DAG 跟 DAG Run 的差異在於前者只是個定義好的工作流程，後者則是該 DAG 在某個時間點實際被排程器拿去執行（Run）過後的結果，會有一個執行日期（execute_date）。&lt;/p&gt;
&lt;p&gt;接著點擊右邊 Links 中長得像太陽的 Graph View 按鈕後就可以看到這個 DAG Run 的執行狀況：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-tasks-in-dag.png" style=""/&gt;
&lt;p&gt;
        將游標放在右邊的「Success」狀態按鈕上可以顯示此 DAG Run 中被成功執行的工作（圖內的工作從左到右被執行）&lt;br/&gt;
        注意圖中 DAG Run 的 ID： manual_2018-08-19... 表示這是一個在 2018-08-19 被手動觸發的 DAG Run。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以清楚地看到這個 DAG Run 完美地模擬了我們 App 在檢查到新連載情報時送 Slack 訊息給我們的情境。我甚至收到一個 Slack 訊息：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-slack-message.png" style=""/&gt;
&lt;p&gt;
        comic_app_v2 DAG 如果發現有新連載就會寄一個罐頭 Slack 訊息，包含 DAG 執行日期。因為我是在 2018-08-19 當天手動觸發此 DAG，因此日期即為 2018-08-19。後面我們會看到如何客製化 Slack 訊息內容。
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="定義工作流程"&gt;定義工作流程&lt;a class="anchor-link" href="#定義工作流程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要在 DAG 裡頭定義出如上圖的工作流程也非常的直觀，讓我們參考這兩個工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;yes_generate_notification&lt;/li&gt;
&lt;li&gt;send_notification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它們在 &lt;code&gt;dags/comic_app_v2.py&lt;/code&gt; 裡頭被這樣定義（節錄最重要的部分）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以發現在 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡，我們分別定義好這兩個工作以後，在最下面用 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 語法告訴 Airflow 這兩個工作的相依性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yes_generate_notification&lt;/code&gt; 工作要在 &lt;code&gt;send_notification&lt;/code&gt; 之前執行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外眼尖的讀者會發現，Python 變數名稱 &lt;code&gt;generate_notification&lt;/code&gt; 跟實際上的工作名稱（task_id） &lt;code&gt;yes_generate_notification&lt;/code&gt; 並不一致。我們將實際的工作 &lt;code&gt;PythonOperator&lt;/code&gt; 命名為 &lt;code&gt;generate_notification&lt;/code&gt;，只是為了後面在定義工作流程的時候好提到它。參考下面的程式碼：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;task1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;task2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;task1&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;task2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這段程式碼跟上一段程式碼在定義工作流程上有一模一樣的效果，只是後者的 naming convention 在定義工作流程的時候比較易懂。&lt;/p&gt;
&lt;p&gt;雖然要多打幾個字，為了其他 DS/DE 以及未來的自己，一般推薦 Python 變數名稱取跟 &lt;code&gt;task_id&lt;/code&gt; 類似的名字。&lt;/p&gt;
&lt;p&gt;針對其他工作，我們也是用相同語法將它們串起來：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;

&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;

&lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;update_read_history&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然後我們就得到前面看過的工作流程圖了：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;/center&gt;&lt;p&gt;你也可以回到 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節，確認 &lt;code&gt;comic_app_v2&lt;/code&gt; 完整的程式碼後再利用左邊的傳送門回來，我等你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;a class="anchor-link" href="#Airflow-變數以及-Jinja-模板"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你應該已經了解如何使用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個新的工作，並利用 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 語法定義 Airflow 的工作流程（DAG）了。我們也實際觸發 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 讓 Airflow 排程器幫我們排程，最後收到一個 Slack 訊息。&lt;/p&gt;
&lt;p&gt;現在讓我們仔細研究一下負責寄 Slack 訊息的工作，也就是下圖的 &lt;code&gt;send_notificiation&lt;/code&gt;：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;p&gt;
        依照 Opeartor 種類不同，工作在 Web UI 上顯示的背景顏色也有所不同，方便區分。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;你會發現它的顏色跟其他工作不一樣，這是因為它並不是一個 &lt;code&gt;PythonOperator&lt;/code&gt;，而是一個 &lt;code&gt;SlackAPIPostOperator&lt;/code&gt;。由此 Operator 定義的工作並不會呼叫一個 Python 函式，而是直接呼叫 Slack API 來傳送訊息。下面是我們在當初落落長的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡頭定義的 &lt;code&gt;send_notificiation&lt;/code&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"YOUR_SLACK_TOKEN"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意 &lt;code&gt;text&lt;/code&gt; 參數的值。 &lt;code&gt;{{ ds }}&lt;/code&gt; 實際上是 &lt;a href="https://airflow.apache.org/tutorial.html#templating-with-jinja"&gt;Jinja&lt;/a&gt; 語法，它允許我們將 Python 變數渲染（Render）到字串裡頭，動態地產生文本。這就像是我們有個變數 &lt;code&gt;ds&lt;/code&gt;，然後利用 &lt;code&gt;format&lt;/code&gt; 語法一樣：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;text = "[{ds}] 海賊王有新番了!".format(ds=ds)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而這邊的重點是 Airflow 在執行一個 DAG 的時候會提供一些預設的&lt;a href="https://airflow.apache.org/code.html?highlight=macros#macros"&gt;環境變數&lt;/a&gt;供我們使用，像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ds&lt;/code&gt;：代表 DAG Run 的執行日期（execute_date），以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yesterday_ds&lt;/code&gt;：DAG Run 的執行日期的前一天，以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tomorrow_ds&lt;/code&gt;：DAG Run 的執行日期的後一天，以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而因為我們在 2018-08-19 的時候，利用下面這個指令手動觸發 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;trigger_dag&lt;/span&gt; &lt;span class="n"&gt;comic_app_v2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Airflow 會將實際執行該 DAG 的日期設定為執行日期（execute_date）。因此 &lt;code&gt;ds&lt;/code&gt; 即為 &lt;code&gt;2018-08-19&lt;/code&gt;，&lt;code&gt;SlackAPIPostOperator&lt;/code&gt; 裡頭的 &lt;code&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/code&gt; 就會被渲染成 &lt;code&gt;[2018-08-19] 海賊王有新番了!&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;最後我們就得到這個 Slack 訊息：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-slack-message.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;現在你也了解使用 Jinja 語法可以動態地調整每次 DAG 運行的邏輯以及執行結果。讓我們實際將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 丟上線試試看吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="執行日期：排程最重要的概念"&gt;執行日期：排程最重要的概念&lt;a class="anchor-link" href="#執行日期：排程最重要的概念"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過前面的幾個章節，我們已經對 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的測試及開發下了不少功夫：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 &lt;code&gt;airflow test&lt;/code&gt; 指令分別測試每個 Airflow 工作執行如預期&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python dags/comic_app_v2.py&lt;/code&gt; 確保 DAG 定義無誤&lt;/li&gt;
&lt;li&gt;使用 Web UI 點擊「 Trigger Dag 」按鈕或是透過 &lt;code&gt;airflow trigger&lt;/code&gt; 來手動觸發 DAG 確認結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些都是將一個 DAG 正式上線前必須完成的步驟。在這些測試都完成以後，是時候將我們的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 交給 Airflow 排程器，讓 Airflow 幫我們每天執行這個 DAG 了！&lt;/p&gt;
&lt;p&gt;在&lt;a href="#手動觸發-DAG"&gt;手動觸發 DAG&lt;/a&gt; 章節我們有看到，要讓 Airflow 排程器開始排程一個 DAG，首先要終止暫停（Unpause）該 DAG。而為何當時 Airflow 沒有在我們 &lt;code&gt;comic_app_v2&lt;/code&gt;一終止暫停 就開始自動排程，而要等到我們手動觸發呢？&lt;/p&gt;
&lt;p&gt;這是因為當時的 &lt;code&gt;comic_app_v2&lt;/code&gt; 的排程設定如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;'start_date': datetime(2100, 1, 1, 0, 0)&lt;/code&gt; 代表我們希望 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的第一個執行日期（execute_date）為西元 2100 年 1 月 1 號 0 點。&lt;/p&gt;
&lt;p&gt;你可能覺得為何要把話說得那麼複雜，就說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不就好了嗎？&lt;/p&gt;
&lt;p&gt;不這麼說的原因，就是因為上面的理解是錯的。事實上這是很多人在利用 Airflow 排程時最容易搞錯的&lt;a href="https://airflow.readthedocs.io/en/latest/scheduler.html?highlight=start_date"&gt;概念&lt;/a&gt;之一，值得花點篇幅徹底搞清楚。&lt;/p&gt;
&lt;p&gt;假如西元 2100 年我們架的 Airflow 排程器還在運作的話，它會在：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;start_date 2100 年 1 月 1 號 0 點 0 分 + 1 * schedule_interval
=   2100 年 1 月 1 號 0 點 0 分 + 1 * @daily
=   2100 年 1 月 1 號 0 點 0 分 + 1 * 24 小時
=   2100 年 1 月 2 號 0 點 0 分
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;也就是 2100 年 1 月 2 號 0 點 0 分的時候，將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 拿出來做第一次執行，而該 DAG Run 的執行日期為 2100 年 1 月 1 號 0 點 0 分。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/black-man-question.jpg" style=""/&gt;
&lt;p&gt;
        我知道你現在可能滿臉黑人問號，但讓我們好好想一想這到底是怎麼一回事。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;要理解為何我們一開始的猜想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是非常矛盾的，讓我們做個我最愛的假想實驗。還記得在&lt;a href="#測試開發-Airflow-工作"&gt;測試開發 Airflow 工作&lt;/a&gt;章節提到的 SQL 查詢嗎？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{execute_date}'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;現在假設我們給這個工作跟 &lt;code&gt;comic_app_v2&lt;/code&gt; 一模一樣的排程設定：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'start_date': datetime(2100, 1, 1, 0, 0)
'schedule_interval': '@daily'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;根據本章節一開始的敘述，這個 DAG 的第一個執行日期（execute_date）為 &lt;code&gt;2100-01-01&lt;/code&gt;。而按照我們在 &lt;a href="#Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;/a&gt;章節所說的，此 SQL 查詢裡頭的 Jinja 語法會被渲染成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'2100-01-01'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著假設我們一開始的猜想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是對的話，該 SQL 查詢會取回什麼資料？&lt;/p&gt;
&lt;p&gt;答案是什麼都沒有。&lt;/p&gt;
&lt;p&gt;因為如果這猜想是對的話，這個 SQL 查詢工作會馬上在西元 2100 年 1 月 &lt;strong&gt;1&lt;/strong&gt; 號的 0 點，想辦法去把西元 2100 年 1 月 &lt;strong&gt;1&lt;/strong&gt; 號整天的使用者資料全部撈出來。而因為此 SQL 查詢執行時， 1 月 1 號才剛開始，這個查詢不會取得任何資料。&lt;/p&gt;
&lt;p&gt;很明顯哪裡出了差錯了。&lt;/p&gt;
&lt;p&gt;而如果照我剛剛解釋的版本，就會顯得合理許多：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 2100 年 1 月 &lt;strong&gt;2&lt;/strong&gt; 號 0 點的時候，以下的 SQL 查詢會被執行&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'2100-01-01'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這代表我們在 1 月 1 號 23 點 59 分結束以後，也就是 1 月 2 號 0 點的時候，將 1 月 1 號所有的使用者資料做彙總。&lt;/p&gt;
&lt;p&gt;一般而言，Airflow 會在 &lt;code&gt;start_date&lt;/code&gt; 加上一個 &lt;code&gt;schedule_interval&lt;/code&gt; 之後開始&lt;a href="https://airflow.readthedocs.io/en/latest/scheduler.html?highlight=start_date"&gt;第一次執行某個 DAG&lt;/a&gt;，而該 DAG Run 的 &lt;code&gt;execute_date&lt;/code&gt; 為 &lt;code&gt;start_date&lt;/code&gt;。這樣的設計就是為了避免像是上面那個 SQL 查詢在當天才剛開始的時候就想要搜集該天所有資料的窘境。&lt;/p&gt;
&lt;p&gt;Airflow 擅長的是管理那些允許「事件發生時間」跟「實際數據處理時間」有落差的批次工作。因此 Airflow 都會在 &lt;code&gt;start_date&lt;/code&gt; 加上 &lt;code&gt;schedule_interval&lt;/code&gt; 長度的時間過完&lt;strong&gt;以後&lt;/strong&gt;，才開始處理發生在 &lt;code&gt;start_date&lt;/code&gt; 到 &lt;code&gt;start_date + schedule_interval&lt;/code&gt; 之間的資料。&lt;/p&gt;
&lt;p&gt;再換句話說，&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個 DAG Run 中的執行日期，只等於它「負責」的日期，不等於它實際被 Airflow 排程器執行的日期。一個被自動排程且執行日期為 dt 的 DAG Run，實際上是在 dt + schedule_period 後被 Airflow 執行。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們換了好幾種說法，希望你能百分之百地掌握這個 Airflow 排程的概念，因為這實在太重要了。&lt;/p&gt;
&lt;p&gt;有了這章節的排程概念以後，我們可以正式開始排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="正式排程"&gt;正式排程&lt;a class="anchor-link" href="#正式排程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過上一章節排程概念的洗禮，想必你還記得 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的開始排程日期（start_date）是遙遠的西元 2100 年 1 月 1 號：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;作者目前撰寫這段落的日期為西元 2018 年 8 月 20 號，所以大概還要再等 82 年，而且我啟動的 Airflow 排程器還活著，這個 DAG 才會被第一次執行。我們可等不了那麼久。&lt;/p&gt;
&lt;p&gt;在完全地理解上一章&lt;a href="#執行日期：排程最重要的概念"&gt;執行日期：排程最重要的概念&lt;/a&gt;所提到的概念以後，你可能會說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「那我們可以把 start_date 設為 2018 年 8 月 20 號，並維持 schedule_interval 為一天，這樣等到 8 月 21 號 0 點的時候，這個 DAG 就會被執行，然後我們就知道它 work 不 work 了！」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好傢伙（好姑娘？），我給你 100 分！&lt;/p&gt;
&lt;p&gt;這句話已經抓到 Airflow 排程的精髓中的精髓，只不過別誤會，我趕時間。何不讓我們當個時空旅人，將 start_date 設為 8 月 20 號以前的日期，比方說 8 月 17 號？&lt;/p&gt;
&lt;p&gt;畢竟我們在上一章提到：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個 DAG Run 中的執行日期，只等於它「負責」的日期，不等於它實際被 Airflow 排程器執行的日期。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將 start_date 設為今天（8 月 20 號）&lt;strong&gt;以前&lt;/strong&gt;的日期，並啟動 Airflow 排程器的話，就會讓 Airflow 排程器馬上開始排程執行日期為 start_date 的 DAG Run，並且一直執行到最新的 DAG Run 為止。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/time-machine.jpg" style=""/&gt;
&lt;p&gt;
    Airflow 排程器彷彿就像台時光機器，幫我們排程那些執行日期在過去的 DAG Run，重建過去。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;所以現在讓我修改 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的程式碼以排程「過去」的 DAG Run：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2018&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;保持好習慣，修改完程式碼以後用 Python 確認 DAG 沒語法錯誤：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python dags/comic_app_v2.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通常 Airflow 沒多久就會重新載入最新的程式碼。如果你懷疑程式碼沒有被更新，可以點擊 Airflow UI 首頁中 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 最右邊 Links 裡頭的「Refresh」按鈕。&lt;/p&gt;
&lt;p&gt;問題時間。&lt;/p&gt;
&lt;p&gt;將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的 start_date 設定成 2018 年 8 月 17 號以後，在作者撰文的 8 月 20 號晚間 10 點為止， Airflow 會排程幾次 DAG Runs？它們分別的執行日期為何？花個幾秒鐘思考，確定你知道答案。（schedule_interval 一樣為 &lt;code&gt;@daily&lt;/code&gt; ）&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/clock-1274699_1280.jpg" style=""/&gt;
&lt;p&gt;
        滴答滴答，你能在我們的時光機完成工作之前想出答案嗎？
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;答案揭曉，Airflow 排程器總共排程三個 DAG Runs，他們的執行日期分別為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2018-08-17&lt;/li&gt;
&lt;li&gt;2018-08-18&lt;/li&gt;
&lt;li&gt;2018-08-19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8 月 20 號的 DAG Run 則要等到 8 月 21 號 0 點才會被執行。&lt;/p&gt;
&lt;p&gt;喝杯水重新載入 UI，我們可以從 Airflow UI 裡頭確認 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 總共有 4 個成功的 DAG Runs：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-dags.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;除了第一個 DAG Run 是我們之前手動觸發以外（你可以從它的 Run Id 以及最右邊的 External Trigger 看出），其他三個都是 Airflow 排程器實際排程並執行的結果（一樣你可以從它們的 Run Id 看出端倪）。&lt;/p&gt;
&lt;p&gt;同時我的 Slack 作響。我們可以看到儘管執行日期相異，三個被排程的 DAG Runs 按照順序通知我有新番。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/three-slack-messages.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;嗯 .. 海賊王一週出一次，想必其中有幾個是 fake news。&lt;/p&gt;
&lt;p&gt;不管如何，我們在這章節成功讓 Airflow 排程器從好幾天前開始自動排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 並確認結果成功！&lt;/p&gt;
&lt;p&gt;如果我不將 Airflow 排程器關掉的話，之後每天的 0 點（UTC）它都會幫我執行 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG。沒有意外的話，或許 Airflow 排程器可以幫我們持續排程此 DAG 到西元 2100 年，希望到時海賊王已經完結，不用叫孫子燒給我了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本三：填填樂_1"&gt;&lt;a name="app-v3"&gt;&lt;/a&gt;App 版本三：填填樂&lt;a class="anchor-link" href="#App-版本三：填填樂"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;目前為止，本文為了讓你能專注在理解 Airflow 及工作流程的核心概念（而非個別工作的實作細節），以 &lt;code&gt;print()&lt;/code&gt; 代替我們 App 的實作邏輯。&lt;/p&gt;
&lt;p&gt;在此章節，我們則會一窺實作所有邏輯的 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG，也就是實現本文開頭展示的 App 的程式碼。&lt;/p&gt;
&lt;p&gt;但為何說「一窺」呢？&lt;/p&gt;
&lt;p&gt;因為 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 為了處理 JSON 檔案、利用 &lt;a href="http://selenium-python.readthedocs.io/" target="_blank"&gt;Selenium&lt;/a&gt; 存取網頁等事情，其程式碼變得比只用 &lt;code&gt;print()&lt;/code&gt; 的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 要長得多，且其程式碼很大一部份已經不直接跟 Airflow 相關了。&lt;/p&gt;
&lt;p&gt;我相信大部分的讀者是為了學習 Airflow 而來，而不是看我東 try 西 try 來實作這個 App。當然，如果你有興趣且想要練習如何建立一個自己的漫畫連載 App，你可以嘗試將實作邏輯填入到 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡頭的各個 Python 函式即可，或者直接執行我已經實作好所有邏輯的 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG，這個我們在後面的&lt;a href="#quick-start"&gt;如何建立你自己的連載通知 App（懶人法）&lt;/a&gt;章節會有詳細講解。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/BLOG-fill-in-the-blank@1X.jpg" style=""/&gt;
&lt;p&gt;
        填填樂：以 comic_app_v2 建立好的工作流程為基礎，實作每個工作的邏輯就像是填空題一般，將邏輯填入對應的 Python 函式就好。（comic_app_v3 也是從 comic_app_v2 為基礎開發的，工作流程一模一樣）
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在這章節，我想跟你分享一些在實作 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 時用到的 Airflow 知識及技巧。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="重複利用-Python-函式"&gt;重複利用 Python 函式&lt;a class="anchor-link" href="#重複利用-Python-函式"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;在 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節我們看到，大部分的 Airflow 工作都是由一個 &lt;code&gt;PythonOperator&lt;/code&gt; 所定義，而每個 &lt;code&gt;PythonOperator&lt;/code&gt; 分別呼叫不同的 Python 函式。但在 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 裡頭，我們只利用一個 Python 函式 &lt;code&gt;process_metadata&lt;/code&gt; 專門負責讀 / 寫使用者的閱讀紀錄：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;       

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;update_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'update_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你會發現上面兩個 Airflow 工作的 &lt;code&gt;python_callable&lt;/code&gt; 都呼叫 &lt;code&gt;process_metadata&lt;/code&gt;，因為它們做類似的事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get_read_history&lt;/code&gt; 負責讀取閱讀紀錄&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_read_history&lt;/code&gt; 負責更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而這兩個工作則利用不同的 &lt;code&gt;op_args&lt;/code&gt; 來使用 &lt;code&gt;process_metadata&lt;/code&gt; 函式的不同功能。這樣的好處是我們不需要為每個類似的 &lt;code&gt;PythonOperator&lt;/code&gt; 都分別建立一個新的 Python 函式，而是利用參數 &lt;code&gt;op_args&lt;/code&gt; 來改變同個 Python 函式的執行結果。&lt;/p&gt;
&lt;p&gt;當然，傳遞參數給 Python 函式這件事情本身就是很常見，這時候 &lt;code&gt;op_args&lt;/code&gt; 就會派上用場。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Xcom：工作之間的訊息交換"&gt;Xcom：工作之間的訊息交換&lt;a class="anchor-link" href="#Xcom：工作之間的訊息交換"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://airflow.apache.org/concepts.html?highlight=xcom#xcoms"&gt;Xcom（Cross Communication）&lt;/a&gt; 是 Airflow 工作之間交換訊息的方式。一個被 &lt;code&gt;PythonOperator&lt;/code&gt; 呼叫的 Python 函式所回傳（return）的值，都可以被其他 Airflow 工作透過 Xcom 存取：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"檢查有無新連載"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以看到最底下的 &lt;code&gt;check_comic_info&lt;/code&gt; 工作呼叫上方的 &lt;code&gt;check_comic_info&lt;/code&gt; 函式，而該函式回傳 &lt;code&gt;anything_new, all_comic_info&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;接著 &lt;code&gt;decide_what_to_do&lt;/code&gt; 函式則利用以下語法來取得該結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下游工作可以透過這樣的方式取得上游工作的執行結果，來決定接下來要做的任務。&lt;/p&gt;
&lt;p&gt;值得注意的是 XCom 的所有資料在 pickle 之後會被存到 Airflow 的 Metadata Database（通常是 MySQL）裡頭，因此不適合交換太大的數據（例：100 萬行的 Pandas DataFrame），而適合用在交換 Metadata。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;裡頭的 &lt;code&gt;**context&lt;/code&gt; 的語法是為了取得 Airflow 在執行工作時產生的&lt;a href="https://airflow.apache.org/code.html?highlight=macros#macros"&gt;環境變數&lt;/a&gt;，其中就包含 XCom。除了要在 Python 函式設置 &lt;code&gt;**context&lt;/code&gt; 以外，我們還必須將 &lt;code&gt;PythonOperator&lt;/code&gt; 的 &lt;code&gt;provide_context&lt;/code&gt; 參數設置為 &lt;code&gt;True&lt;/code&gt;，Airflow 才會把環境變數傳給該工作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="在工作流程內加入條件分支"&gt;在工作流程內加入條件分支&lt;a class="anchor-link" href="#在工作流程內加入條件分支"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;有時候我們會想要在工作流程裡頭加入分支，當某條件符合的時候執行這個分支，當不符合的時候執行別的分支。&lt;/p&gt;
&lt;p&gt;比方說我們的 App 就含有這樣的邏輯：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;p&gt;利用 BranchPythonOperator 實現 Airflow DAG 裡的條件分支
    &lt;/p&gt;
&lt;/center&gt;&lt;p&gt;圖中的 &lt;code&gt;check_comic_info&lt;/code&gt; 「上游」工作會去漫畫網頁檢查有沒有新的連載，依照結果的不同，我們希望不同分支被執行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有的話，執行上面分支的 &lt;code&gt;yes_generate_notification&lt;/code&gt; 「下游」工作&lt;/li&gt;
&lt;li&gt;沒有的話，則執行下面分支的 &lt;code&gt;no_do_nothing&lt;/code&gt; 「下游」工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要在 Airflow 裡頭實現這樣的邏輯，可以在上下游工作「之間」新增一個 &lt;code&gt;BranchPythonOperater&lt;/code&gt;（如圖中的 &lt;code&gt;new_comic_available&lt;/code&gt; 工作）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;砍掉原上游工作跟下游工作之間的 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將原上游工作 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 該 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 工作&lt;/li&gt;
&lt;li&gt;將該 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 工作 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 原下游工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;資料工程很大一部份的工作就是在建立資料管道/工作流程，接個水管合情合理對吧？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="nn"&gt;BranchPythonOperator&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;do_nothing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 一樣會呼叫一個 Python 函式（上例的 &lt;code&gt;decide_what_to_do&lt;/code&gt; 函式），由該函式決定到底最後哪個下游工作會被執行。基本上該函式會依照實際情況決定哪個下游工作被執行，並將該下游工作的 &lt;code&gt;task_id&lt;/code&gt; 回傳。&lt;/p&gt;
&lt;p&gt;而因為在這個例子中，我們希望依照上游工作 &lt;code&gt;check_comic_info&lt;/code&gt; 回傳的一個布林值 &lt;code&gt;anything_new&lt;/code&gt; 來決定要執行哪個下游工作，因此可以使用 &lt;code&gt;xcom_pull&lt;/code&gt; 取得該結果以後回傳要執行的下游工作 ID &lt;code&gt;task_id&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，這就是我想跟你分享在實作 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 時的幾個實用技巧，希望對你上手 Airflow 有所幫助。&lt;/p&gt;
&lt;p&gt;接下來我們將針對那些想要建立自己的連載通知 App 的你，提供一個快速起手指南。&lt;/p&gt;
&lt;p&gt;不過如果你現在沒有打算做這件事情的話，可以放心跳到最後面的&lt;a href="#結語"&gt;結語&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何建立你自己的連載通知-App（懶人法）_2"&gt;&lt;a name="quick-start"&gt;&lt;/a&gt;如何建立你自己的連載通知 App（懶人法）&lt;a class="anchor-link" href="#如何建立你自己的連載通知-App（懶人法）"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;此章節提供一個懶人指南，讓那些想要建立自己的 App 的你，在（幾乎）不需要改變 &lt;code&gt;comic_app_v3&lt;/code&gt; 程式碼的前提下完成這件事情。&lt;/p&gt;
&lt;p&gt;如同我們在&lt;a href="#建置-Airflow-環境"&gt;建置 Airflow 環境&lt;/a&gt;提到的，首先你當然得先把跟這篇文章相關的 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Github Repo&lt;/a&gt; 複製下來：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/leemengtaiwan/airflow-tutorials.git
&lt;span class="nb"&gt;cd&lt;/span&gt; airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你在之前就有複製 Repo 下來跟著走，你只需要再另外安裝 &lt;a href="https://selenium-python.readthedocs.io/"&gt;Selenium&lt;/a&gt;。Selenium 是一個自動化網頁測試的工具，在這個 App 裡頭被我們用來當網路爬蟲，去漫畫網站看連載資訊。&lt;/p&gt;
&lt;p&gt;接著啟動目前為止 Airflow 一直在使用的 Anaconda 環境，然後安裝 Selenium：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
conda install -c conda-forge selenium
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你之前沒有建置任何環境，可以利用 Repo 裡頭的 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials/blob/master/environment.yaml"&gt;environment.yaml&lt;/a&gt; 從頭安裝 Airflow 以及 Selenium：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda env create -n airflow-tutorials -f environment.yaml 
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在這個 App 裡頭，要讓 Selenium 正常運作，你還需要 &lt;a href="https://sites.google.com/a/chromium.org/chromedriver/"&gt;Chrome Driver&lt;/a&gt;。下載最新版本以後把它放在你的 &lt;code&gt;$PATH&lt;/code&gt; 讀得到的地方。Mac 使用者的話可以放到像是 &lt;code&gt;/usr/local/bin&lt;/code&gt; 資料夾下面。如果還是不懂可以查看&lt;a href="https://github.com/leemengtaiwan/gist-evernote#chrome-driver"&gt;這裡的 Chrome Driver 安裝教學&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;環境設定好以後，你會需要一個新的 &lt;a href="https://peppergeeks.slack.com/apps"&gt;Slack App&lt;/a&gt; 來送訊息到你的 Workspace。建立一個新的 Slack App，給予它寫訊息的權限以後，安裝到你自己的 Workspace。這時候你應該會得到一個開頭為 &lt;code&gt;xoxp-&lt;/code&gt; 的 Slack Token。將該 Token 複製下來，打開 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下的 &lt;code&gt;data/credentials/slack.json&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;將你的 Token 複製貼上如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"xoxp-....."&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;搞定網路爬蟲以及 Slack 認證以後，你需要改變 &lt;code&gt;comic_app_v3.py&lt;/code&gt; 裡頭的一行程式碼，以讓 Airflow 送訊息到你 Workspace 底下指定的頻道（channel）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_token&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_message_text&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將上述的 &lt;code&gt;channel='#comic-notification'&lt;/code&gt; 改成你自己的頻道，如 &lt;code&gt;channel='#my-new-channel'&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;接著你會需要一個正常運作的 Airflow 排程器。啟動方法參考 &lt;a href="#Airflow-排程器"&gt;Airflow 排程器&lt;/a&gt;章節。&lt;/p&gt;
&lt;p&gt;在 Airflow 排程器、Selenium 以及 Slack 都就緒以後，你可以直接手動觸發 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 來測試 App 的第一則訊息。如同我們在&lt;a href="#手動觸發-DAG"&gt;手動觸發 DAG&lt;/a&gt; 章節提到的，你可以透過 Web UI 或者 terminal 來終止暫停（Unpause）並手動觸發一個 DAG：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;unpause&lt;/span&gt; &lt;span class="n"&gt;comic_app_v3&lt;/span&gt;
&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;trigger_dag&lt;/span&gt; &lt;span class="n"&gt;comic_app_v3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;一切順利的話，幾秒鐘之後，你會在自己的 Slack Workspace 及 channel 底下收到這個測試訊息：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/real-slack-message.png" style=""/&gt;
&lt;p&gt;
    圖中的 channel 會隨著你實際的設定改變
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;目前 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 將使用者的閱讀紀錄儲存在 &lt;code&gt;data/comic.json&lt;/code&gt; 裡頭，底下則是為了產生上面這個 Slack 訊息的假閱讀紀錄：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1152"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"海賊王"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;900&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic-website.jpg" style=""/&gt;
&lt;p&gt;
        上頭 comic.json 裡頭，海賊王的 "1152" 就代表該漫畫主頁在動漫狂的連結中的數字（1152.html）
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;目前此 App 只能從&lt;a href="https://www.cartoonmad.com/"&gt;動漫狂&lt;/a&gt;（歡迎你丟 PR 改善！）找最新的漫畫連載。為了新增你自己的漫畫，你需要找出該漫畫主頁在動漫狂的連結，將連結中的數字如上述的例子一樣新增在 &lt;code&gt;data/comic.json&lt;/code&gt; 裡頭。假設你想開始關注「進擊的巨人」，然後最近看到 100 話的話，可以把 &lt;code&gt;data/comic.json&lt;/code&gt; 改成這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1221"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"進擊的巨人"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這樣一來， &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 就會用該數字去「進擊的巨人」的頁面，幫你查看有沒有最新的連載。當然你也可以像我一樣，在 &lt;code&gt;comic.json&lt;/code&gt; 裡追加多個漫畫：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1152"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"海賊王"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;911&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1221"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"進擊的巨人"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;107&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"4485"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"西遊"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;152&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1121"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"浪人劍客"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;327&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1122"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"王者天下"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;565&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;...&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改完 &lt;code&gt;comic.json&lt;/code&gt;，最後你會想要修改 &lt;code&gt;comic_app_v3.py&lt;/code&gt; 裡頭的排程設定：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將 &lt;code&gt;start_date&lt;/code&gt; 改成你想要他它開始的日期，接著 Airflow 排程器就會每天幫你執行 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 並查看最新連載。搞定收工！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先，由衷感謝你花了那麼多寶貴時間與力氣跟隨著我們的 Airflow 冒險。&lt;/p&gt;
&lt;p&gt;回顧一下，這一路上你已經學會不少資料工程相關的知識以及 Airflow 的開發技巧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解工作流程、上下游工作、相依性的概念以及其與 Airflow DAG 的關係&lt;/li&gt;
&lt;li&gt;模組化工作流程的重要性&lt;/li&gt;
&lt;li&gt;了解如何利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個 Airflow 工作並呼叫自定義 Python 函式&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;airflow test&lt;/code&gt; 指令以及 Web UI 測試 Airflow 工作以及 DAG&lt;/li&gt;
&lt;li&gt;了解如何利用 Python 定義一個工作流程以及決定工作間的相依性&lt;/li&gt;
&lt;li&gt;利用 Web UI 及 terminal 手動觸發 DAG 並確認執行結果&lt;/li&gt;
&lt;li&gt;了解 Airflow 排程概念（如執行日期）並實際讓工作流程上線（&lt;code&gt;comic_app_v2&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;了解一些 Airflow 開發時的技巧，如建立條件分支以及使用各種不同的 Operators 建立工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先給自己鼓個掌吧！&lt;/p&gt;
&lt;p&gt;如同我在文章開頭所述：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;這是一篇當初我在入門資料工程以及 Airflow 時希望有人能為我寫好的文章。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當時的我找不到這篇文章，而現在我自己寫了這篇文章。&lt;/p&gt;
&lt;p&gt;希望這篇文章能幫助到跟過去的我一樣，正在嘗試學習資料工程以及 Airflow 的你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然使用 Airflow 來實作本篇的漫畫連載 App 可能是一個殺雞用牛刀的例子，但我希望你能參考本文的 App 例子，開始思考如何用本文學到的知識，去實際解決、自動化你自身或是所在企業的數據問題。&lt;/p&gt;
&lt;p&gt;儘管這篇的 Airflow 故事即將進入尾聲，你的 Airflow 之旅才剛剛展開。&lt;/p&gt;
&lt;p&gt;Keep learning and happy Airflowing！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="Airflow"></category><category term="資料工程"></category><category term="Selenium"></category><category term="Slack"></category></entry><entry><title>資料科學文摘 Vol.3 Pandas、Docker 以及數據時代的反思</title><link href="https://leemeng.tw/data-science-digest-volume-3.html" rel="alternate"></link><published>2018-08-10T21:00:00+09:00</published><updated>2018-08-10T21:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-10:/data-science-digest-volume-3.html</id><summary type="html">&lt;p&gt;不同於上週的文摘，這週的選文比較技術以及實作導向。本週將導讀 3 篇使用 Python 以及 Pandas 的文章，並鼓勵讀者實際動手學習。我們也會看到如何使用 Docker 來讓資料科學變得更簡單，並提供一個有趣的貓咪圖片辨識 App 給有興趣的讀者參考。最後，讓我們分別看看哈佛商業評論以及美國前首席資料科學家 DJ Patil 談談如何讓資料科學在企業內普及，以及數據時代我們面臨的各種道德議題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不同於上週的&lt;a href="https://leemengtaiwan.github.io/data-science-digest-volume-2.html"&gt;文摘 Vol.2 產品理解以及 DS / DE 之路&lt;/a&gt;，這週的選文比較技術以及實作導向。本週將導讀 3 篇使用 Python 以及 Pandas 的文章，並鼓勵讀者實際動手學習。我們也會看到如何使用 Docker 來讓資料科學變得更簡單，並提供一個有趣的貓咪圖片辨識 App 給有興趣的讀者參考。最後，讓我們分別看看哈佛商業評論以及美國前首席資料科學家 DJ Patil 談談如何讓資料科學在企業內普及，以及數據時代我們面臨的各種道德議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Pandas、Python&lt;ul&gt;
&lt;li&gt;&lt;a href="#How-to-Master-Your-Skills-for-Pandas?"&gt;How to Master Your Skills for Pandas?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;How to rewrite your SQL queries in Pandas, and more&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Learn-Functional-Python-in-10-Minutes"&gt;Learn Functional Python in 10 Minutes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Docker    &lt;ul&gt;
&lt;li&gt;&lt;a href="#Docker-for-Data-Scientists"&gt;Docker for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Try-It-Yourself"&gt;Cat Recognizer: A flask app showcasing how to recognize cats using Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;數據時代的反思&lt;ul&gt;
&lt;li&gt;&lt;a href="#The-Democratization-of-Data-Science"&gt;The Democratization of Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data's-day-of-reckoning"&gt;Data's day of reckoning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-to-Master-Your-Skills-for-Pandas?"&gt;&lt;a href="https://engmrk.com/module5-introduction-to-pandas/"&gt;How to Master Your Skills for Pandas?&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-Master-Your-Skills-for-Pandas?"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://engmrk.com/module5-introduction-to-pandas/" target="_blank"&gt;
&lt;img src="images/digests/Module-5-Introduction-to-Pandas.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;Python 裡頭最著名的資料處理 library 非 &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; 莫屬了。&lt;a href="https://engmrk.com/module5-introduction-to-pandas/"&gt;這篇文章&lt;/a&gt;使用互動式的環境，列出挺完整的 Pandas 指令讓讀者可以邊參考 sample code 邊自己動手玩玩看。&lt;/p&gt;
&lt;p&gt;其中包含各種利用 Series 以及 Dataframe 兩種 Pandas 常見的資料格式來對數據進行各種操作，適合沒碰過 Pandas 的新手以及想要重新 refresh 語法的人。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;&lt;a href="https://codeburst.io/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e"&gt;How to rewrite your SQL queries in Pandas, and more&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://codeburst.io/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e" target="_blank"&gt;
&lt;img src="images/digests/kofu-pandas.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
提供常見的 SQL 查詢以及其對應的 Pandas 寫法。一個有效率的資料科學家通常需要 SQL 及 pandas 兼具。雖然這篇一開始的目標讀者是那些已經熟悉 SQL 並打算使用 Pandas 的讀者，我認為熟悉 Pandas 但還不了解 SQL 的同學們也能從這篇學到點東西。&lt;/p&gt;
&lt;p&gt;這篇適合至少懂 Python 或是 SQL 並想學習另外一個語言的讀者。如果你想要深入了解 SQL 或是其與 Python 之間的差異，你可以看看我之前寫的&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;為何資料科學家需要學習 SQL&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Learn-Functional-Python-in-10-Minutes"&gt;&lt;a href="https://hackernoon.com/learn-functional-python-in-10-minutes-to-2d1651dece6f"&gt;Learn Functional Python in 10 Minutes&lt;/a&gt;&lt;a class="anchor-link" href="#Learn-Functional-Python-in-10-Minutes"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://hackernoon.com/learn-functional-python-in-10-minutes-to-2d1651dece6f" target="_blank"&gt;
&lt;img src="images/digests/1_ZXixptvL4rzkx3EDuj38xw.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/"&gt;這篇 Hackernon 文章&lt;/a&gt;則簡單介紹 Functional Programming 在 Python 可以如何被實作，函式（function）是怎麼被視為 Python 的第一公民以及我們能如何活用函式如 Map、Filter 函式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你剛起步，想要有效率地學習 Python 的話，我建議可以從 &lt;a href="https://www.python-course.eu/list_comprehension.php"&gt;List comprehension&lt;/a&gt; 開始學起。&lt;/p&gt;
&lt;p&gt;一個簡單的例子是假設我們想從一個 List 中取得大於 50 的數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;70&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;larger_than_50&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;larger_than_50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[100, 70]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文章的後半段則透過 The Zen of Python （Python 的禪學）來說明為何使用 List comprehension 會比使用傳統 Functional Programming 中的 Map、Filter 函式來得簡單。&lt;/p&gt;
&lt;p&gt;Python 有一個著名的彩蛋，你可以利用 &lt;code&gt;import this&lt;/code&gt; 來顯示 The Zen of Python，它提供使用 Python 的人一個簡單的開發準則，具體如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;this&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;The Zen of Python, by Tim Peters

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker-for-Data-Scientists"&gt;&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/"&gt;Docker for Data Scientists&lt;/a&gt;&lt;a class="anchor-link" href="#Docker-for-Data-Scientists"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/" target="_blank"&gt;
&lt;img src="images/digests/docker-flickr.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
很簡單地說明常見的 &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; 術語以及使用 Docker 可以為資料科學家帶來的好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;節省建置開發 / 分析環境所需的時間&lt;/li&gt;
&lt;li&gt;增加可重現性（Reproducibility）&lt;/li&gt;
&lt;li&gt;抽象化作業系統（OS）的概念，再也沒有只能在 Mac 跑而不能在 Windows 跑的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇提供非常初級的指令來開始在本機環境使用 Docker，可以嘗試看看。&lt;/p&gt;
&lt;p&gt;在 Smartnews 我則是使用 &lt;a href="https://aws.amazon.com/tw/ecs/"&gt;Amazon Elastic Container Service&lt;/a&gt; 來快速部署一些資料科學家們常會用到的分析工具，如大家的好朋友 &lt;a href="https://jupyterhub.readthedocs.io/en/stable/"&gt;Jupyter Hub&lt;/a&gt;、Airbnb 開發的 BI 工具 &lt;a href="https://github.com/apache/incubator-superset"&gt;Superset&lt;/a&gt;。之後有機會會另外撰文分享經驗。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Try-It-Yourself"&gt;Try It Yourself&lt;a class="anchor-link" href="#Try-It-Yourself"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Docker 讓我們可以快速重現其他人的分析環境或者是有趣的 application。如果你想馬上感受 Docker 的威力，可以看看我之前利用 &lt;a href="https://www.tensorflow.org/"&gt;Tensorflow&lt;/a&gt; 以及 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 實作的一個貓咪圖片辨識的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Github repo&lt;/a&gt;（feat. &lt;a href="https://github.com/mnicnc404"&gt;CNC&lt;/a&gt;）：&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app" target="_blank"&gt;
&lt;img src="images/digests/cat-recog-cover.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app" target="_blank"&gt;Cat Recognizer&lt;/a&gt;
       ：利用 Tensorflow, Flask 實作 App 並使用 Docker 快速與他人分享成果
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;雖然 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Github repo&lt;/a&gt; 上也有教學指南，想要最快速地在你的電腦上使用這個 App 的話，下載 &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; 並開啟 Daemon 後，使用命令列輸入以下指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull leemeng/cat
docker run -it -p &lt;span class="m"&gt;2468&lt;/span&gt;:5000 leemeng/cat
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著在瀏覽器輸入 &lt;code&gt;localhost:2468&lt;/code&gt; 應該就能開始使用了。如果你想多了解點 Docker，可以參考我寫的&lt;a href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html"&gt;給資料科學家的 Docker 指南：3 種活用 Docker 的方式（上）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;不過現在讓我們繼續看剩下的 2 篇好文章：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-Democratization-of-Data-Science_1"&gt;&lt;a href="https://hbr.org/2018/07/the-democratization-of-data-science"&gt;The Democratization of Data Science&lt;/a&gt;&lt;a class="anchor-link" href="#The-Democratization-of-Data-Science"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://hbr.org/2018/07/the-democratization-of-data-science" target="_blank"&gt;
&lt;img src="images/digests/jul18-27-833771544-Patricia-Toth-McCormick-1200x675.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;&lt;a href="https://hbr.org/"&gt;哈佛商業評論（Harvard Business Review, HBR）&lt;/a&gt;在這篇文章裏頭敘述為何不只是針對資料科學家，提升所有人的「資料素養」對一個企業來說是一件非常重要的事情。&lt;/p&gt;
&lt;p&gt;最明顯的優點是可以讓數據團隊專注在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解決更高層次的企業問題&lt;/li&gt;
&lt;li&gt;建立分析工具以加速所有部門的數據分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而不是處理每個部門的「資料瑣事」。&lt;/p&gt;
&lt;p&gt;這個議題並非只跟企業的管理階層相關。對一個資料科學家來說，想辦法利用資料工程（Data Engineering）等方式來自動化如「建立簡單儀表板」的工作，並教導各個部門實際的使用方式，可以讓你一勞永逸，避免永遠在處理非常瑣碎的「資料瑣事」，專著在更大的目標。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;你不會因為自己不是會計師就不遵守專案預算；你也不會因為不是資料科學家就不提升資料素養。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data's-day-of-reckoning"&gt;&lt;a href="https://www.oreilly.com/ideas/datas-day-of-reckoning"&gt;Data's day of reckoning&lt;/a&gt;&lt;a class="anchor-link" href="#Data's-day-of-reckoning"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://www.oreilly.com/ideas/datas-day-of-reckoning" target="_blank"&gt;
&lt;img src="images/digests/shower-of-sparks-3115784_1280.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
生活在數據驅動時代的我們或許都能感受到世界變化的快速。&lt;/p&gt;
&lt;p&gt;美國前首席資料科學家 &lt;a href="https://www.oreilly.com/people/15b77-dj-patil"&gt;DJ Patil&lt;/a&gt; 認為不管是資料科學、機器學習還是人工智慧領域，「道德倫理」以及「安全隱私」議題都應該越來越被重視。&lt;/p&gt;
&lt;p&gt;電腦科學（Computer Science）時代最著名的安全議題非 SQL 注入&lt;a href="https://zh.wikipedia.org/zh-hant/SQL%E8%B3%87%E6%96%99%E9%9A%B1%E7%A2%BC%E6%94%BB%E6%93%8A"&gt;（SQL Injection）&lt;/a&gt;莫屬了。如同這個議題，在數據驅動時代，我們也會面臨類似道德以及數據保護的議題，像是人工智慧模型產生具有偏見的預測、以及最近的 &lt;a href="https://zh.wikipedia.org/wiki/%E6%AD%90%E7%9B%9F%E4%B8%80%E8%88%AC%E8%B3%87%E6%96%99%E4%BF%9D%E8%AD%B7%E8%A6%8F%E7%AF%84"&gt;GDPR&lt;/a&gt; 等等。&lt;/p&gt;
&lt;p&gt;在教育方面，DJ Patil 認為我們應該教育下一代在數據處理時，應該遵守的準則並將其被納入課綱；以數據驅動的公司則需要將這些想法都納入企業文化，在招聘資料科學家的時候，除了考慮他 / 她的分析能力以外，也要評估道德倫理的部分。&lt;/p&gt;
&lt;p&gt;身為一個資料科學家，除了技術層面的提升，也應該稍微了解這些議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;We can build a future we want to live in, or we can build a nightmare. The choice is up to us.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas、SQL、Docker、資料素養的培養以及數據時代的道德倫理問題等等，這週我們也看了不少資料科學相關的文章，希望你有從這篇文章裡頭學到點東西。&lt;/p&gt;
&lt;p&gt;雖然因為篇幅關係沒辦法把所有實際的 Python 指令列在這邊，我希望透過摘要的方式能讓沒時間的你也能學習、初步地了解資料科學並進一步發現自己有興趣的地方鑽研。&lt;/p&gt;
&lt;p&gt;有時間的話我推薦實際閱讀這些文章（當然也可以閱讀其他你自己收藏的文章，也歡迎分享），也可以試試看我寫的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Cat Recognizer&lt;/a&gt; 並留言跟我說說你的想法。&lt;/p&gt;
&lt;p&gt;之後一樣會定期更新，希望收到第一手消息的話可以點擊下面的訂閱。另外如果你有其他會對這篇文章有興趣的朋友，也請幫忙分享給他 / 她：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;That's it for this week, stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="Pandas"></category><category term="SQL"></category><category term="Docker"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.2 產品理解以及 DS / DE 之路</title><link href="https://leemeng.tw/data-science-digest-volume-2.html" rel="alternate"></link><published>2018-08-03T14:20:00+09:00</published><updated>2018-08-03T14:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-03:/data-science-digest-volume-2.html</id><summary type="html">&lt;p&gt;這週一樣會透過導讀一些優質文章，讓讀者了解 3 個問題：為何一個專業的資料科學家需要具備「產品理解」？ 何謂「顧客流失分析」？ 我們該如何使用 Python（XGBoost）來建立簡單的預測模型以改善產品？ 此外，我們也將簡單介紹在資料科學領域中逐漸崛起的「資料工程師」，其職責以及專業跟「資料科學家」有何不同。最後也會分享一些與資料科學家/資料工程師相關的文章。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週一樣會透過導讀一些優質文章，讓讀者了解 3 個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何一個專業的資料科學家需要具備「產品理解」？ &lt;/li&gt;
&lt;li&gt;何謂「顧客流失分析」？ &lt;/li&gt;
&lt;li&gt;我們該如何使用 Python（XGBoost）來建立簡單的預測模型以改善產品？ &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，我們也將簡單介紹在資料科學領域中逐漸崛起的「資料工程師」，其職責以及專精領域跟「資料科學家」有何不同。&lt;/p&gt;
&lt;p&gt;最後也會分享一些與資料科學家/資料工程師相關的文章。&lt;/p&gt;
&lt;p&gt;後文為了減少累贅，可能會穿插以下縮寫：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家 = &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist = DS&lt;/li&gt;
&lt;li&gt;資料工程師 = &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer  = DE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外有興趣了解此文摘緣由的讀者可以參考前篇：&lt;a href="https://leemengtaiwan.github.io/data-science-digest-volume-1.html"&gt;資料科學文摘 Vol.1 AutoML、Airflow 及 DAU&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;產品理解&lt;ul&gt;
&lt;li&gt;&lt;a href="#Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;Why Data Scientists Must Focus on Developing Product Sense&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Product-Scientist-@-Medium"&gt;Product Scientist @ Medium&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python、客戶流失預測&lt;ul&gt;
&lt;li&gt;&lt;a href="#Introduction-to-Churn-Prediction-in-Python"&gt;Introduction to Churn Prediction in Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DS / DE 相關&lt;ul&gt;
&lt;li&gt;&lt;a href="#Data-engineering:-A-quick-and-simple-definition"&gt;Data engineering: A quick and simple definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-To-Become-A-Data-Scientist-in-12-Months"&gt;How To Become A Data Scientist in 12 Months&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;Infographic &amp;ndash; 13 Common Mistakes Amateur Data Scientists Make and How to Avoid Them&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;就跟以往一樣，儘管下文會依照此順序列出文章與摘要，你仍然點擊上面的任意門，從最有興趣的文章開始閱讀：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;&lt;a href="https://www.kdnuggets.com/2018/04/data-scientists-product-sense.html"&gt;Why Data Scientists Must Focus on Developing Product Sense&lt;/a&gt;&lt;a class="anchor-link" href="#Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.kdnuggets.com/2018/04/data-scientists-product-sense.html" target="_blacnk"&gt;
&lt;img src="images/digests/customers-checking-products.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;作者闡述為何產品理解（Product Sense）對一個 DS 很重要，適合新手 DS 閱讀參考。&lt;/p&gt;
&lt;p&gt;通常在企業裡頭，一個資料科學家要發揮最大的影響力，就是透過手上的資料，產生可執行的洞見（Actionable Insight），進而影響產品（Product）的發展方向。不管我們做了多少分析、多少層的神經網路模型，或是產生多少特徵值（Features），如果最後這些產物沒有對產品的發展有任何影響，一切都白搭。&lt;/p&gt;
&lt;p&gt;我們可以透過深刻地了解自家產品（比方說使用自家的 App）、暸解競爭對手、與使用者直接溝通等方式，來培養「產品理解」。有了產品理解以後，甚至可以反過來幫助我們做特徵工程（Feature Engineering），知道在建立預測模型時什麼特徵會是重要的；還能培養從資料看不出來的敏銳直覺（intuition）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;理解產品的 DS 能同時從資料看出的趨勢以及業界直覺來改善產品並解決人們問題。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt;，資料科學團隊也是在產品部門之下，與此有異曲同工之妙：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Product-Scientist-@-Medium"&gt;&lt;a href="https://medium.com/@sall/product-scientist-ffd1ae846172"&gt;Product Scientist @ Medium&lt;/a&gt;&lt;a class="anchor-link" href="#Product-Scientist-@-Medium"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://medium.com/@sall/product-scientist-ffd1ae846172" target="_blacnk"&gt;
&lt;img src="images/digests/1_EWD67PTS_fxBjWoZJ30oCA.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
Medium 的人說明他們在找的 Product Scientist 應該要有什麼特質：簡單來說就是有「產品理解」的 DS，能將資料轉換成更好的產品的人材。&lt;/p&gt;
&lt;p&gt;一個好的 DS 需要強大的溝通能力來向其他人說明洞見、了解 A/B 測試的統計顯著性（statistical significance）、以及能合理地解釋 KPI 成長的背後因素。以及最重要的：你渴望改善某個產品。&lt;/p&gt;
&lt;p&gt;最後一點大概是所有分析領域的人都不可或缺的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;你要先對某個產品抱持著熱情，才會想方設法地找出洞見並改善它。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管是什麼領域的 DS，都要想辦法了解自家的產品，以提供可執行的洞見。反過來說，你應該選擇進入真的有興趣的公司 / 產業。老生常談：擇你所愛，愛你所擇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Introduction-to-Churn-Prediction-in-Python"&gt;&lt;a href="https://www.datascience.com/blog/churn-prediction-python"&gt;Introduction to Churn Prediction in Python&lt;/a&gt;&lt;a class="anchor-link" href="#Introduction-to-Churn-Prediction-in-Python"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.datascience.com/blog/churn-prediction-python" target="_blacnk"&gt;
&lt;img src="images/digests/churn-prediction-intro-2-407577-edited.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇適合沒用過 XGBoost 也不熟悉 App 產業的讀者。&lt;/p&gt;
&lt;p&gt;此文主要解釋了何謂客戶流失（Customer Churn）、如何利用 Python 來建立一個簡單的 XGBoost 模型，以及如何對一個簡單的資料集做預測。&lt;/p&gt;
&lt;p&gt;就跟預測使用一個產品 / 服務的使用者人數相同，能準確預測有多少使用者會在什麼時候放棄使用某產品（Churn）這件事情，對了解一個產品（如手機 App）的發展趨勢是很重要的事情。如果我們把「預測使用者會不會放棄使用產品」這個問題視為一個二元分類問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 = 客戶流失，停止使用某產品&lt;/li&gt;
&lt;li&gt;0 = 客戶持續使用某產品&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;並使用如 XGBoost 等 tree-based 的模型的話，可以直接從模型中得到各個特徵的重要程度（Feature Importance），由此獲得改善產品功能的靈感 / 線索。這同時告訴我們一個重要的事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;除了準確度，選擇解釋性高的預測模型可以讓 DS 更容易解釋模型給決策者並影響企業決策。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然，如何定義何謂「客戶流失」就需要資料科學家掌握領域知識。另外值得注意的是，隨著產品功能的進化，客戶流失的定義也有可能跟著改變。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data-engineering:-A-quick-and-simple-definition"&gt;&lt;a href="https://www.oreilly.com/ideas/data-engineering-a-quick-and-simple-definition"&gt;Data engineering: A quick and simple definition&lt;/a&gt;&lt;a class="anchor-link" href="#Data-engineering:-A-quick-and-simple-definition"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.oreilly.com/ideas/data-engineering-a-quick-and-simple-definition" target="_blacnk"&gt;
&lt;img src="images/digests/data-metal-tubes-crop-22ff1fb1bba80c8258fc47980bd7694b.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;適合想成為資料工程師（DE）並對大數據處理有興趣的讀者。&lt;/p&gt;
&lt;p&gt;不同於我們之前以 DS 的角度討論&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;為何資料科學家需要了解資料工程&lt;/a&gt;，這篇直接以 DE 角度探討 DE 對企業的重要：處理大數據的能力。&lt;/p&gt;
&lt;p&gt;以各別負責的領域來區分的話，DS 通常負責從資料找出可執行的洞見，DE 則是負責資料管道的開發以及保證數據品質。 儘管一個 DS 也需要具備基本的 ETL 素養以及資料清理能力，這些分析專家能提供最大的價值是在找出洞見，而不是清理資料。&lt;/p&gt;
&lt;p&gt;因此稍具規模的公司都會尋找具備大數據處理能力（&lt;a href="https://zh.wikipedia.org/wiki/Apache_Spark"&gt;Spark&lt;/a&gt;、&lt;a href="https://flink.apache.org/"&gt;Flink&lt;/a&gt;、&lt;a href="https://kafka.apache.org/"&gt;Kafka&lt;/a&gt; 等）的 DE 來處理數據，以讓 DS 能更專注在商業分析。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資料科學領域越趨成熟的情況下， 我們需要更多 DE 與 DS 分工合作，以從海量數據中創造更大價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-To-Become-A-Data-Scientist-in-12-Months"&gt;&lt;a href="https://medium.com/@FreddieO/how-to-become-a-data-scientist-in-12-months-7e0deb51fac5"&gt;How To Become A Data Scientist in 12 Months&lt;/a&gt;&lt;a class="anchor-link" href="#How-To-Become-A-Data-Scientist-in-12-Months"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://medium.com/@FreddieO/how-to-become-a-data-scientist-in-12-months-7e0deb51fac5" target="_blacnk"&gt;
&lt;img src="images/digests/1_Tcx7pHt5Jctu7tMrdztrcQ.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;&lt;p&gt;這篇適合想開始學習資料科學的讀者作為參考。&lt;/p&gt;
&lt;p&gt;一個誤打誤撞，闖入資料科學世界的工程師述說他是如何從自學程式語言到成為一個資料科學家。列了一些他個人給新人的建議、不少線上課程以及值得追蹤的資料科學家們。&lt;/p&gt;
&lt;p&gt;雖然每個人際遇不同，看完這篇可以確定的是，想要成為一個資料科學家絕對不是學完幾堂線上課程就可以了。關鍵在於持續學習新知。（這道理當然可以套用到各行各業上）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;&lt;a href="https://www.analyticsvidhya.com/blog/2018/07/infographic-common-mistakes-amateur-data-scientists-make-how-avoid-them/"&gt;Infographic &amp;ndash; 13 Common Mistakes Amateur Data Scientists Make and How to Avoid Them&lt;/a&gt;&lt;a class="anchor-link" href="#Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.analyticsvidhya.com/blog/2018/07/infographic-common-mistakes-amateur-data-scientists-make-how-avoid-them/" target="_blacnk"&gt;
&lt;img src="images/digests/13-common-mistake.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;一個簡單的資料圖表說明新手 DS 常犯的 13 個錯誤。&lt;/p&gt;
&lt;p&gt;每個項目值得一一查看，不過裡頭有幾點我認為值得特別強調：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學在於應用。總是要想著該怎麼實際應用學到的知識，而不是死記硬背。&lt;/li&gt;
&lt;li&gt;專注在能「解決什麼問題」，而不是該學什麼「工具」。&lt;/li&gt;
&lt;li&gt;業界想要解決的問題不是你在線上課程學到的那麼單純。要解決一個真正的企業問題，你還需要培養資料工程、領域知識（Domain Knowledge）以及良好的溝通能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週我們學到在分析任何數據之前，為何理解產品對一個資料科學家來說非常重要；我們也看到一個簡單利用 Python 嘗試預測顧客流失的案例；最後我們看到資料工程師的崛起以及閱讀了 2 篇跟資料科學相關的文章。&lt;/p&gt;
&lt;p&gt;程式能力以及分析能力固然重要，但對產品的理解、良好的溝通能力都是成為一個專業的 DS 不可不缺的能力。&lt;/p&gt;
&lt;p&gt;閱讀完之後如果有任何想法，或者有其他想推薦給其他讀者們閱讀的文章，都歡迎在底下留言跟其他讀者們分享。&lt;/p&gt;
&lt;p&gt;目前預計每週會發佈新文摘，不過當有別的系列文章要寫的話可能會順延一週。如果希望在新文摘出爐的時候馬上收到通知的話，可以點擊下面的訂閱：）&lt;/p&gt;
&lt;p&gt;Stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category><category term="資料工程"></category><category term="Python"></category></entry><entry><title>資料科學文摘 Vol.1 AutoML、Airflow 及 DAU</title><link href="https://leemeng.tw/data-science-digest-volume-1.html" rel="alternate"></link><published>2018-07-29T18:00:00+09:00</published><updated>2018-07-29T18:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-07-29:/data-science-digest-volume-1.html</id><summary type="html">&lt;p&gt;這週介紹幾篇機器學習、資料工程及 App 分析的優質文章以及重點摘要，關鍵字包含：AutoML、Airflow 以及 DAU / MAU。希望讓更多人能更快地掌握資料科學領域的知識，找出自己有興趣的領域專研，並激盪出更多的討論。透過閱讀大量的相關文章並從它們學習及模仿，我們可以更快地，且有效率地成為一個稱職的資料科學家。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;作為「資料科學文摘」系列文的第一篇，在開始介紹一些優質的文章之前，請讓我稍微說明一下為何會有這系列文章的誕生。先說結論：我希望透過分享一些優質文章的重點摘要，讓更多人能更快地掌握資料科學領域的知識，找出自己有興趣的領域專研，並激盪出更多的討論。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在開始閱讀之前"&gt;在開始閱讀之前&lt;a class="anchor-link" href="#在開始閱讀之前"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;或許所有職業皆如此，但個人認為資料科學家是前幾不「佛系」的一個職業，你需要擁有非常多知識來讓工作更為順利：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特定程式語言如 Python、SQL 及 R 的使用方法&lt;/li&gt;
&lt;li&gt;統計分析方法&lt;/li&gt;
&lt;li&gt;建構資料管道（Data Pipeline）&lt;/li&gt;
&lt;li&gt;訓練並部署機器學習模型&lt;/li&gt;
&lt;li&gt;業界趨勢&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/digests/budda-data-scientist.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然，你也可以選擇當個佛系資料科學家（如果你知道有哪間企業在應徵，站內信 500 P）。&lt;/p&gt;
&lt;p&gt;不過身為一個（非佛系）資料科學家，我常需要閱讀大量的相關文章、新知，並且嘗試模仿文章內出現的演算法、分析手法，加以實踐並應用在自己的工作上。&lt;/p&gt;
&lt;p&gt;愛爾蘭詩人&lt;a href="https://zh.wikipedia.org/wiki/%E5%A5%A5%E6%96%AF%E5%8D%A1%C2%B7%E7%8E%8B%E5%B0%94%E5%BE%B7"&gt;奧斯卡．王爾德&lt;/a&gt; 曾說過一句&lt;a href="https://en.wikiquote.org/wiki/Talk:Oscar_Wilde"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;You are what you read. - Oscar Wilde&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以資料科學為例，你讀越多相關文章，你就越接近一個資料科學家。不管要精通什麼能力，最快的方式都是透過「模仿」專家怎麼做的。透過閱讀大量的相關文章並從它們學習及模仿，我們可以更快地，且有效率地成為一個稱職的資料科學家。&lt;/p&gt;
&lt;p&gt;以往我在閱讀完不錯的文章以後，都會在 &lt;a href="https://evernote.com/intl/zh-tw/"&gt;Evernote&lt;/a&gt; 裡頭寫重點摘要以供自己之後做參考、連結不同領域的知識。在回顧的時候節省了自己大量的時間。有鑑於現在越來越多人對資料科學有興趣，透過分享自己的文摘，希望能讓沒有什麼時間的人也能快速地了解新知，並進一步閱讀自己有興趣的文章。&lt;/p&gt;
&lt;p&gt;前言說得夠多了，讓我們來看看這週的文摘吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週分享：機器學習、資料工程及-App-分析"&gt;本週分享：機器學習、資料工程及 App 分析&lt;a class="anchor-link" href="#本週分享：機器學習、資料工程及-App-分析"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週想分享 5 篇文章的文摘，大致上可分為三個主題。這週因為想一次分享 Rachel Thomas 在 &lt;a href="http://www.fast.ai/"&gt;fast.ai&lt;/a&gt; 談 AutoML 的三篇系列文章，機器學習的文章比例會佔得比較重。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;機器學習&lt;ul&gt;
&lt;li&gt;&lt;a href="#What-do-machine-learning-practitioners-actually-do"&gt;What do machine learning practitioners actually do&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;An Opinionated Introduction to AutoML and Neural Architecture Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Google's-AutoML:-Cutting-Through-the-Hype"&gt;Google's AutoML: Cutting Through the Hype&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;資料工程&lt;ul&gt;
&lt;li&gt;&lt;a href="#Airflow:-a-workflow-management-platform"&gt;Airflow: a workflow management platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;App 業界分析&lt;ul&gt;
&lt;li&gt;&lt;a href="#DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;DAU/MAU is an important metric to measure engagement, but here&amp;rsquo;s where it fails&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了 AutoML 的系列文以外，閱讀順序不限：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="What-do-machine-learning-practitioners-actually-do"&gt;&lt;a href="http://www.fast.ai/2018/07/12/auto-ml-1/"&gt;What do machine learning practitioners actually do&lt;/a&gt;&lt;a class="anchor-link" href="#What-do-machine-learning-practitioners-actually-do"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/12/auto-ml-1/" target="_blacnk"&gt;
&lt;img src="images/digests/automl_1.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇介紹機器學習工程師平常在做些什麼，在理解這點以後，我們才知道中間有什麼地方可以自動化，以讓機器學習專案更有效率。&lt;/p&gt;
&lt;p&gt;一個完整的機器學習專案通常會包含這些步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解企業脈絡&lt;/li&gt;
&lt;li&gt;清理＆準備資料&lt;/li&gt;
&lt;li&gt;訓練模型&lt;/li&gt;
&lt;li&gt;實際部署&lt;/li&gt;
&lt;li&gt;事後監控模型表現&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;針對每個步驟，文內都有進一步的項目細分以及解釋，推薦閱讀。儘管一個機器學習工程師不需要自己做所有步驟，了解它們會讓專案更為順利。&lt;/p&gt;
&lt;p&gt;就算是專業的研究者，訓練一個深度學習的模型也不是一件非常簡單的事情。而這是 AutoML 以及其子領域，神經結構搜索（neural architecture search）嘗試要解決的。 Google 甚至號稱「只要我們有現在的一百倍計算能力，就可以取代所有機器學習人才」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;&lt;a href="http://www.fast.ai/2018/07/16/auto-ml2/"&gt;An Opinionated Introduction to AutoML and Neural Architecture Search&lt;/a&gt;&lt;a class="anchor-link" href="#An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/16/auto-ml2/" target="_blacnk"&gt;
&lt;img src="images/digests/automl-headlines.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
神經結構搜索或者 AutoML 領域可以幫助我們在「訓練模型」這個步驟的時候，訓練並選擇出最好的超參數（Hyperparameters）。&lt;/p&gt;
&lt;p&gt;但如同上篇文所述，這通常只是機器學習專案的其中一小部分，資料科學家或機器學習相關人才並不會因此被全部取代且失業。&lt;/p&gt;
&lt;p&gt;現在 AutoML 是非常計算密集（Computation-intensive）的：拿大量的 GPU 計算能力換取研究員的時間。但沒有大量計算能力的人，等 Google 等大公司把最佳化的架構推出來再使用或許是一個比較實際的方案。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.groundai.com/project/darts-differentiable-architecture-search/"&gt;DARTS&lt;/a&gt; 也是 CMU 與 DeepMind 在嘗試解決「神經結構搜索」這個問題時提出的一個架構，不過他們的假設是所有可行的模型之間是「連續的」，因此可以用常見的「梯度學習」的方式找出最佳模型。這個概念使得他們所需要的計算資源大量減少，值得關注。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Google's-AutoML:-Cutting-Through-the-Hype"&gt;&lt;a href="http://www.fast.ai/2018/07/23/auto-ml-3/"&gt;Google's AutoML: Cutting Through the Hype&lt;/a&gt;&lt;a class="anchor-link" href="#Google's-AutoML:-Cutting-Through-the-Hype"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/23/auto-ml-3/" target="_blacnk"&gt;
&lt;img src="images/digests/sundar_pichai2.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
作者認為 Google 在推廣 AutoML 的主張：「我們需要更多計算能力來做神經架構搜尋」值得懷疑，因為就算我們能自動化搜尋出最好的神經模型架構，如何用這些模型解決真正的企業問題、如何實際部署並持續改善機器學習應用等課題，都需要人動腦筋來解決，而這部分還無法自動化。&lt;/p&gt;
&lt;p&gt;另外畢竟不是所有做機器學習的人都需要、且有（計算）能力使用神經架構搜尋來訓練自己的模型。但我們可以透過轉換學習（Transfer Learning）來使用已訓練過的模型（pre-trained model）來解決類似問題。與其想著自己也要做最夯的神經架構搜尋，不如多多善用如 Dropout、Batch Normalization 以及 ReLU Linear Unit 來強化模型的預測能力。&lt;/p&gt;
&lt;p&gt;不過 &lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Google Colab Notebook&lt;/a&gt; 是不錯的免費計算資源，可以善加利用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Airflow:-a-workflow-management-platform"&gt;&lt;a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8"&gt;Airflow: a workflow management platform&lt;/a&gt;&lt;a class="anchor-link" href="#Airflow:-a-workflow-management-platform"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8" target="_blacnk"&gt;
&lt;img src="images/digests/airflow-example-python-operator.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
資料科學家在進行各式各樣的分析前，首先需要做的事情通常是蒐集、整理並匯總各式各樣的資料來源以供分析。舉幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建立數據倉儲（Data Warehousing）&lt;/li&gt;
&lt;li&gt;做 A/B 測試的效果分析&lt;/li&gt;
&lt;li&gt;Sessionization：了解使用者在一個 session 裡頭的探訪的網頁、點擊的廣告等活動&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了做這些分析，資料團隊需要建立可靠的資料管道及 ETL，來確保有資料可供分析以及保證資料的品質。&lt;/p&gt;
&lt;p&gt;Airflow 是一個由 Airbnb 開發，以 Python 實作的工作流管理系統（Workflow Management System, WMS）。 Airflow 被設計來幫助資料科學家們專注在建構資料管道的邏輯，而不是擔心如果資料管道中間出了什麼差錯時該怎麼維護、重新啟動工作流。（Airflow 有會自己重試失敗工作、當失敗時通知工程師等方便功能）。&lt;/p&gt;
&lt;p&gt;Airflow 現在已經進入 &lt;a href="https://incubator.apache.org/"&gt;Apache 孵化器&lt;/a&gt;，前景可期。其作者 &lt;a href="https://medium.com/@maximebeauchemin"&gt;Maxime Beauchemin&lt;/a&gt; 在這篇用淺顯易懂的方式解說 Airflow，值得一看。手癢的朋友可以參考 &lt;a href="http://pythonhosted.org/airflow/start.html"&gt;Quickstart&lt;/a&gt; 以及 &lt;a href="http://pythonhosted.org/airflow/tutorial.html"&gt;Tutorial&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;SmartNews 也有在使用 Airflow，我也寫了一篇給新手看的 Airflow 的指南：「&lt;a href="https://leemengtaiwan.github.io/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;」，你可以參考看看：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;&lt;a href="https://andrewchen.co/dau-mau-is-an-important-metric-but-heres-where-it-fails/"&gt;DAU/MAU is an important metric to measure engagement, but here&amp;rsquo;s where it fails&lt;/a&gt;&lt;a class="anchor-link" href="#DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://andrewchen.co/dau-mau-is-an-important-metric-but-heres-where-it-fails/" target="_blacnk"&gt;
&lt;img src="images/digests/daumau-header.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;&lt;p&gt;多年前由 Facebook 開始使用，DAU / MAU 是一個 App 產業常用的指標，用來衡量使用者利用自家 App 的程度。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DAU：每天活躍人數（Daily Active Users）&lt;/li&gt;
&lt;li&gt;MAU：每月活躍人數（Monthly Active Users）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DAU / MAU 則是這兩者的比例。可以想像當此比例越高，代表在每月活躍的使用者人數（MAU）中，每天活躍的人數（DAU）越高，可以說明使用者的黏著度越高。&lt;/p&gt;
&lt;p&gt;但這篇重點在於說明不同服務、產品因為本身性質的不同，並不都適合用這個指標。像是 Airbnb 這種公司，有些使用者每年可能只使用一次（活躍次數一年才一次），但一次的消費金額很驚人。以 DAU 的角度來看這種顧客的話價值不高，但使用者的生涯價值（Life Time Value）卻很高。&lt;/p&gt;
&lt;p&gt;雖然業界很常使用，不盲目使用 DAU / MAU 這個指標，而是依照自己的產品種類，選擇最能代表使用者價值的指標，並將其最大化才是上策。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;呼！以上就是這週的文摘內容了！儘管我們在這篇文摘裡頭只包含了 5 篇文章， 3 篇還是系列文，你應該也能感受到不同領域的知識在腦海中互相激盪吧！&lt;/p&gt;
&lt;p&gt;在整理這幾篇文章的重點時我學到不少，希望你也一樣。之後會定期更新，可以隨時回來看看有沒有新文章。如果懶得每天打卡，但希望在新文摘出來的時候馬上收到通知的話，可以點擊下面的訂閱。如果你在閱讀完後有其他感想，也歡迎跟我分享：）&lt;/p&gt;
&lt;p&gt;Stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category><category term="資料工程"></category><category term="機器學習"></category></entry><entry><title>資料科學家 L 的奇幻旅程 Vol.1 新人不得不問的 2 個問題</title><link href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html" rel="alternate"></link><published>2018-07-07T20:30:00+09:00</published><updated>2018-07-07T20:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-07-07:/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html</id><summary type="html">&lt;p&gt;為了讓有志成為資料科學家，或是單純想要了解的讀者們能理解資料科學是如何實際被企業應用，以及讓自己多一點反思的機會，趁著最近開始在 SmartNews 的新工作，我打算開始紀錄自己平常的工作內容以及一些經驗分享。作為系列文的第一篇文章，我們將探討一個資料科學家在進入新公司熟悉環境的時候，除了問該裝什麼工具以外，可以問的兩個重要問題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為一個資料科學家，我平常會寫些相關領域的文章，像是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/demystify-the-hype-of-data-science-and-its-value.html"&gt;揭開資料科學的神秘面紗&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;為何資料科學家需要學習 SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/data-visualization-from-matplotlib-to-ggplot2.html"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它們都獲得不錯的迴響，我也得到不少很棒的回饋。&lt;/p&gt;
&lt;p&gt;不過如果只是介紹特定跟資料科學（Data Science，以下簡稱 DS）相關的工具或概念的話，我們可能會陷入「見樹不見林」的窘境：知道很多 DS 的知識，但卻不曉得這些知識是如何實際被運用在解決人們或是企業的問題。實際上我相信大多數企業的資料科學家在做的事情，並不像很多線上課程那麼單純；有時候你需要結合多種領域的知識，如資料工程、分析手法以及領域知識（Domain Knowledge）來解決一個商業問題。&lt;/p&gt;
&lt;p&gt;為了讓有志成為資料科學家，或是單純想要了解的讀者們能理解 DS 是如何實際被（企業）應用，以及讓自己多一點反思的機會，趁著最近開始在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 的新工作，我打算開始（不定期地）紀錄自己平常的工作內容以及一些經驗分享（當然，在不洩漏隱私資訊的前提下）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/green-chameleon-21532-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我相信透過寫作，能讓更多人了解資料科學並幫助自己釐清重要概念
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這系列文章將以類似說故事（奇幻旅程，喔耶！）的手法，闡述我在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 遇到的一些挑戰，以及作為一名資料科學家（Data Scientist），我如何利用手邊各式各樣的工具以及手法來解決這些問題。透過問題導向（Problem-oriented）的方式，我希望能讓更多人理解 DS 是如何實際被應用在企業之中，進而思考自己該如何預先準備，減少進入這個領域的障礙。（歡迎分享你的想法！）&lt;/p&gt;
&lt;p&gt;在後面幾篇文章，我們將有機會深入探討一些分析手法、如何建置預測模型，以及建置可靠的資料流（Dataflow）。但在那之前可別忘了：「巧婦難為無米之炊」。我們才剛剛開始資料科學家的工作，就連筆電裡頭也是什麼軟體都還沒被安裝呢！&lt;/p&gt;
&lt;p&gt;因此在大展身手之前，在這篇文章我們將討論作為一個資料科學家，如何在開始第一個分析專案的同時，「有效率」地熟悉新環境。後面你將會發現，這個初始步驟看似瑣碎，卻能讓之後的工作進行地更為順利。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="熟悉環境-=-安裝軟體？"&gt;熟悉環境 = 安裝軟體？&lt;a class="anchor-link" href="#熟悉環境-=-安裝軟體？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們想像一下剛從 IT 管理部門手上拿到新筆電的情境。&lt;/p&gt;
&lt;p&gt;通常拿到公司配的新電腦以後，一個資料科學家會思考的幾個問題是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「我要在新電腦上面裝什麼軟體？」&lt;/li&gt;
&lt;li&gt;「公司的資料科學家們用什麼軟體？」&lt;/li&gt;
&lt;li&gt;「我要怎麼存取公司的資料？」&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/markus-spiske-37176-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    面對一片空白的環境，我們的腦袋可不能也是一片空白
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些問體的確很重要也很實際（practical），也是我當初能馬上想到的問題。但後面我們會看到，該安裝什麼軟體、該怎麼存取資料庫都是「熟悉環境」裏頭最簡單的部分。為什麼？&lt;/p&gt;
&lt;p&gt;因為通常 manager 會準備好一個清單告訴你該裝什麼，只要照著做就好了。這個清單當然會依照公司內部使用的技術而有所差異，但在大 Google 搜尋時代之下，要在自己的筆電安裝任何東西（應該）都不是太困難的事情。&lt;/p&gt;
&lt;p&gt;就算公司沒有給你清單，沒問題！事實上，我也不過就安裝了以下軟體：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; &amp;amp; &lt;a href="https://www.anaconda.com/download/#macos"&gt;Anaconda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.r-project.org/"&gt;R 語言&lt;/a&gt; &amp;amp; &lt;a href="https://www.rstudio.com/"&gt;RStudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.iterm2.com/"&gt;iTerm2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/pycharm/"&gt;PyCharm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sourcetreeapp.com/"&gt;SourceTree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然隨著專案的增加，你可能還會需要其他工具，但基本上沒有想像中的那麼多。有了開發/分析工具以後， IT 管理部門也會跟你說明該如何透過加密的方式，存取一些重要的資料庫以及伺服器。等到這些都搞定以後，理論上我們已經可以準備寫落落長的 SQL 查詢來結合多個資料庫的表格，並使用各種酷炫的 Python packages 進行分析了！&lt;/p&gt;
&lt;p&gt;不過在進行分析的同時，有一些問題值得我們花幾天慢慢地思考。這篇我想特別強調 2 個：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司內有什麼&lt;a href="https://zh.wikipedia.org/wiki/%E9%97%9C%E9%8D%B5%E7%B8%BE%E6%95%88%E6%8C%87%E6%A8%99"&gt;關鍵績效指標（KPI）&lt;/a&gt;？&lt;/li&gt;
&lt;li&gt;這些 KPI 是怎麼被產生並顯示在儀表板（Dashboard）上的？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可能覺得這些事情看起來並不直接跟資料分析相關，但接下來你會看到，為何在進入公司早期就理解它們，對一個資料科學家來說很重要。首先讓我們看看第一個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="公司內有什麼關鍵績效指標？"&gt;公司內有什麼關鍵績效指標？&lt;a class="anchor-link" href="#公司內有什麼關鍵績效指標？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為什麼了解公司內有什麼關鍵績效指標（Key Performance Indicator, 後簡稱 KPI）很重要？&lt;/p&gt;
&lt;p&gt;因為這些 KPI 代表著一企業或團隊衡量成功的方式，同時也決定了資料科學家們將要努力的方向。沒有這些 KPI，我們將不能評估我們是不是走在對的路上，也不知道前進的速度。講得浮誇點，一個資料科學家能提供的最大價值就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;分析數據、從中找出洞見讓企業做出更好的決策，以在最短的時間內最大化 KPI&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以這樣的角度來看，KPI 的概念就跟機器學習中的&lt;a href="http://terms.naer.edu.tw/detail/1316865/"&gt;目標函數（Objective Function）&lt;/a&gt;的概念相同，差別只在於我們是用電腦去最佳化目標函數；用人腦去最佳化企業的 KPI。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/journal/carlos-muza-84523-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    資料科學家的工作說穿了，就是如何利用資料以及 DS 的力量，來最大化儀表板上的 KPI
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;因為 SmartNews 是一個新聞 APP，讓我們舉些&lt;a href="https://www.adweek.com/digital/top-12-key-performance-indicators-for-maximizing-mobile-app-revenue/"&gt;手機 APP 產業中常被使用的 KPI&lt;/a&gt; 為例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安裝次數（#Installs）&lt;/li&gt;
&lt;li&gt;每人平均使用時間（Session Time）&lt;/li&gt;
&lt;li&gt;瀏覽頁面數（#Page Views）&lt;/li&gt;
&lt;li&gt;每天活躍人數（#Daily Active Users）&lt;/li&gt;
&lt;li&gt;每月活躍人數（#Monthly Active Users）&lt;/li&gt;
&lt;li&gt;重度使用者人數（#Heavy Users）&lt;/li&gt;
&lt;li&gt;每日廣告營收（Ad Revenue Per Day）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;儘管相同產業可能用類似的 KPI，每家公司給的實際定義（Definition）可能有所出入。不同公司之間的定義有差異是正常的，但該定義合不合理就是另外一回事了。&lt;/p&gt;
&lt;p&gt;就跟我們訓練一個機器學習模型的時候會注意目標函數的定義是否合理一樣，在了解有什麼 KPI 以後，我們也應該積極地去詢問相關人員，了解這些 KPI 的定義是否合理。像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;怎樣的行為可以算是完成安裝？是使用者第一次打開 APP 的瞬間算安裝，還是完成新手教學的時候呢？&lt;/li&gt;
&lt;li&gt;何謂活躍？使用者要做什麼操作才算活躍？打開 APP，更改設定就關掉也算活躍嗎？&lt;/li&gt;
&lt;li&gt;何謂重度使用者？過去一個月使用超過 7 天的人算嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/william-stitt-224297-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    把握 onboarding 的機會，詢問所有你能質疑的問題
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果 KPI 的定義不合理，糟一點的結果就是你的努力方向對了， KPI 卻沒有上升；更糟的結果則是你往錯的方向最佳化：錯誤的 KPI 提升了，你則沾沾自喜。儘管定義合適的 KPI 需要大量的領域知識，在剛開工的時候，你仍應該對現有的 KPI 做出適當的質疑，嘗試理解它們的合理性。&lt;/p&gt;
&lt;p&gt;現在假設 KPI 的定義沒有明顯問題，不管什麼公司都會希望能將這些 KPI 即時地顯示在儀表板上以方便監控自己的營運狀況。但如果一個 APP 的&lt;a href="http://about.smartnews.com/ja/2017/10/10/25million/"&gt;下載次數超過 2500 萬&lt;/a&gt;，每天產生上億筆使用者存取紀錄的話，幾個衍生出來的問題就是：KPI 該怎麼從這些原始資料產生出來的？如何保證中間沒有出錯？我們能信賴這些計算出來的值嗎？&lt;/p&gt;
&lt;p&gt;讓我們在下小節討論這個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="儀表板上的-KPI-是怎麼產生的？"&gt;儀表板上的 KPI 是怎麼產生的？&lt;a class="anchor-link" href="#儀表板上的-KPI-是怎麼產生的？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實作方式會依照公司有所不同，但讓我們以 SmartNews 為例。&lt;/p&gt;
&lt;p&gt;我們的儀表板是使用 &lt;a href="https://chartio.com/"&gt;CHARTIO&lt;/a&gt;，但基本上 CHARTIO 這種儀表板服務也只是一個 Web UI，它並不會自動幫我們把使用者的存取紀錄轉成 KPI。為了理解每天人們使用 APP 的情況，我們必須自己將所有網路伺服器（Web Servers）上的使用者存取紀錄（Log Data）做一系列的處理以後，轉變成儀表板上的 KPI。&lt;/p&gt;
&lt;p&gt;而一個使用者的使用行為大致上會經過以下幾個步驟轉變成 KPI：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用者打開 SmartNews App，手機客戶端向網路伺服器做出請求（Request）&lt;/li&gt;
&lt;li&gt;網路伺服器回傳結果，並將該請求紀錄存在自己的硬碟上&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fluentd.org/"&gt;fluentd&lt;/a&gt; 搜集所有伺服器上的請求資料，將它們存到 &lt;a href="https://aws.amazon.com/tw/s3/"&gt;Amazon S3&lt;/a&gt; 上&lt;/li&gt;
&lt;li&gt;工作流管理系統 &lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt; 進行 Batch 處理，定期將被存到 S3 上的使用者存取紀錄轉成 &lt;a href="https://en.wikipedia.org/wiki/Apache_Hive"&gt;Apache Hive&lt;/a&gt; SQL 表格（Tables）&lt;/li&gt;
&lt;li&gt;CHARTIO 透過分散式 SQL 查詢引擎 &lt;a href="https://prestodb.io/"&gt;Presto&lt;/a&gt; 對該表格作查詢，顯示 KPI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從左到右來表示這個流程的話會如下圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/smartnews-dmp.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.slideshare.net/smartnews/20160127-building-a-sustainable-data-platform-on-aws" target="_blank"&gt;SmartNews 的資料平台&lt;/a&gt;：將大量原始日誌資料轉成儀表板上有用的 KPI（當然不只用在顯示 KPI）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;乍看之下，你可能會想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「這看起來跟資料科學完全沒相關啊！」&lt;/li&gt;
&lt;li&gt;「我只要能存取關聯式資料庫（Relational Database）裡頭的表格不就好了？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;沒錯，嚴格來說這是一個資料工程（Data Engineering）的問題。但正如我們在&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;一文裡頭提到的，身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;
&lt;p&gt;事實上，了解儀表板上的 KPI 是怎麼產生的，有以下幾個優點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解工程師的痛點。能事先以他們的角度思考建立新表格所需的成本的話，他們會更願意幫你建立&lt;/li&gt;
&lt;li&gt;通常新的分析會需要新的 ETL，而你可以利用跟產生 KPI 一樣的 ETL 來產生自己的資料管道（Data Pipeline）&lt;/li&gt;
&lt;li&gt;確保資料品質。一旦使用的資料有瑕痴，做出來的分析也不會有意義。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/studio-314-270213-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個資料科學家會去了解企業內的資料是怎麼流動的，確保資料的品質並建立自己需要的資料流
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最後一點尤其重要。在 SmartNews 的例子裡頭，資料科學家實際上想要分析的是「APP 使用者的存取行為」，而跟使用者行為最直接相關的其實是那些被存在網路伺服器上的 log。只是因為該資料量太大，我們必須建立資料管道做前處理，從大量原始資料中萃取、匯總出我們「可能」有興趣的資料存入關聯式資料庫供之後分析。&lt;/p&gt;
&lt;p&gt;以這種角度來看的話，資料彷彿是從網路伺服器（上游）經過一連串的河道（資料管道）流向資料庫（下游）。這也就暗示著兩個可能的風險：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料在經過河道的時候被污染，資料品質下降&lt;/li&gt;
&lt;li&gt;資料在經過河道的時候被限縮，有些有價值的資料沒辦法抵達下游&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個資料科學家如果只專注在下游的資料，就可能冒著以上的風險而不自知。這就是為什麼我們需要了解企業內的資料是如何流動的。&lt;/p&gt;
&lt;p&gt;資料的流動當然不限於 KPI 的產生，但我認為用這個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「儀表板上的 KPI 是怎麼產生的？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;來理解一個企業的資料流是一個很好的起始點。畢竟 KPI 是公司最重視的資訊，用來建構其的資料管道也會是最完善且重要的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文章裏頭，我們討論了一個資料科學家在進入新公司熟悉環境的時候，除了問該裝什麼工具以外，可以問的兩個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司內有什麼 KPI？&lt;/li&gt;
&lt;li&gt;儀表板上的 KPI 是怎麼產生的？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表面上看來是兩個再簡單不過的問題，實際上第一個問題跟業界的專業知識（Domain Knowledge）息息相關；第二個問題則牽涉到大量的資料工程專業。而透過深刻地思考這兩個問題並詢問相關人員，一個資料科學家可以更全面的理解企業並掌握大局觀，做出最有影響力的分析。&lt;/p&gt;
&lt;p&gt;當然，除了這兩個問題以外，你還需要問很多其他重要的問題如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司的資料文化如何？&lt;/li&gt;
&lt;li&gt;我在 Data Science 團隊裡頭的定位為何？&lt;/li&gt;
&lt;li&gt;many more ..&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但作為「資料科學家 L 的奇幻旅程」系列文的第一篇文章，為了避免累贅，我把這些問題留給你們（可以留言跟我說你覺得還有什麼問題重要！）&lt;/p&gt;
&lt;p&gt;最後的 Bonus 問題：為何是資料科學家「L」？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="日誌"></category></entry><entry><title>從彼此學習 - 淺談機器學習以及人類學習</title><link href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html" rel="alternate"></link><published>2018-06-16T17:20:00+09:00</published><updated>2018-06-16T17:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-06-16:/some-thought-on-learning-from-machine-learning.html</id><summary type="html">&lt;p&gt;說到近年最熱門的機器學習或者人工智慧，因為知識背景以及觀點的不同，幾乎每個人都有不一樣的見解。雖然我們有千百種定義、無數的專業術語，這篇文章希望用直觀的方式以及具體的例子，讓讀者能夠在跳入一大堆 ML 的教學文章以及線上課程之前，能以一個更高層次且人性化的角度理解機器學習，並進而思考要如何開啟自己的機器學習旅程。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;說到近年最熱門的機器學習（Machine Learning）或者人工智慧（Artificial Intelligence），因為知識背景以及觀點的不同，幾乎每個人都有不一樣的見解。雖然我們有千百種定義、無數的專業術語，這篇文章希望用直觀的方式以及具體的例子，讓讀者能夠在跳入一大堆 ML 的教學文章以及線上課程之前，能以一個更高層次且人性化的角度理解機器學習，並進而思考要如何開啟自己的機器學習旅程。&lt;/p&gt;
&lt;p&gt;不僅如此，你將發現機器學習並不是冷冰冰的科學，隨處可見人類的巧思；就算不是資料科學家，你也能從『機器學習』獲得啟發，將一些概念用在改善『自己的學習』。&lt;/p&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#何謂機器學習"&gt;何謂機器學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#機器學習實例：智慧咖啡機"&gt;機器學習實例：智慧咖啡機&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何讓機器學得更好"&gt;如何讓機器學得更好&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何改善我們的學習"&gt;如何改善我們的學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂機器學習"&gt;何謂機器學習&lt;a class="anchor-link" href="#何謂機器學習"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;多虧了媒體的大量宣傳，我們現在都知道&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;被應用在各個領域。一些常見的例子包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自然語言處理，如 Google 翻譯、iPhone 的 Siri 語音辨識&lt;/li&gt;
&lt;li&gt;推薦系統，如 Amazon 的&lt;a href="https://technews.tw/2016/07/17/amazon-page-system/"&gt;『買了這個商品的人同時也購買了 ...』功能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;垃圾郵件自動判定，如同我們在&lt;a href="https://leemengtaiwan.github.io/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html"&gt;《直觀理解貝氏定理及其應用》&lt;/a&gt;一文中談到的&lt;/li&gt;
&lt;li&gt;電腦視覺，如 &lt;a href="https://www.techbang.com/posts/58630-facebook-calls-users-to-upload-nude-photos-in-order-not-to-make-you-the-yan-zhao-door-lead"&gt;Facebook 的人臉辨識&lt;/a&gt;、Youtube 的影片推薦，影像分類&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;〈這張照片是貓還是狗？〉&lt;/a&gt;等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例子不勝枚舉。有那麼多應用機器學習的例子，不禁讓人思考，究竟什麼是『機器學習』？&lt;/p&gt;
&lt;p&gt;依照目前機器學習的應用，一個大致上的定義是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;讓機器學習如何將輸入的資料 X 透過一系列的運算，轉換成指定的輸出 y。並提供一個衡量成功的方式，讓機器知道怎麼修正學習方向。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這個定義，讓我們再看一下上面提到的幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自然語言處理：將得到的英文字串〈輸入〉，轉成中文文字〈輸出〉&lt;/li&gt;
&lt;li&gt;推薦系統：將使用者過去的購買記錄〈輸入〉，轉成使用者可能想要購買的商品列表〈輸出〉&lt;/li&gt;
&lt;li&gt;垃圾郵件判斷：將郵件內文〈輸入〉，轉成該郵件為垃圾信的機率〈輸出〉&lt;/li&gt;
&lt;li&gt;電腦視覺：將一個　400 x 400 像素的圖片，轉成多個標籤的機率〈輸出〉&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;a href="https://developers.google.com/machine-learning/practica/image-classification/" target="_blank"&gt;
&lt;img src="images/learn-from-machine/cat-image-classification.PNG" style="" title="Google Machine Learning Practica"/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://developers.google.com/machine-learning/practica/image-classification/" target="_blank"&gt;Google Machine Learning Practica&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;
&lt;br/&gt;
    Google 教你做影像分類，利用機器學習，將充滿著像素的圖片轉換成一個個標籤
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;嗯嗯，我想這定義還算合理。&lt;/p&gt;
&lt;p&gt;眼尖的讀者會發現，這邊的例子說明了上述定義的一半：將輸入 X 轉換成輸出 y。為了進一步解釋後半段『衡量成功的方式』，下面讓我們以一個虛構的咖啡機舉例。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器學習實例：智慧咖啡機"&gt;機器學習實例：智慧咖啡機&lt;a class="anchor-link" href="#機器學習實例：智慧咖啡機"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設你是個咖啡愛好者，家裡有好幾台高檔的咖啡機，但每次泡出來的咖啡都不合你胃口。&lt;/p&gt;
&lt;p&gt;經過無數的失敗，忍無可忍，你最後決定向月巴克公司買台『智慧』咖啡機。該咖啡機宣稱可以了解你的個人需求，泡出世界上最符合你胃口的咖啡。&lt;/p&gt;
&lt;p&gt;拆開咖啡機包裝，你興奮地把咖啡豆、砂糖以及牛奶加到該咖啡機裡頭。幾分鐘過後，號稱世界上最好喝的咖啡完成了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/nolan-issac-38299-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;外觀看起來不錯，你滿懷期待地啜了一口。&lt;/p&gt;
&lt;p&gt;『太甜了吧！砂糖太多了，什麼鳥機器！』&lt;/p&gt;
&lt;p&gt;你怒吼著，幾乎馬上萌生退貨的想法。這時候咖啡機感應到你的抱怨，用很委屈的聲調說：&lt;/p&gt;
&lt;p&gt;『目前調配咖啡的方式為原廠設定。經過統計分析，要得到一個正常台灣人的最佳評分，平均一杯咖啡裡頭的咖啡豆顆數、砂糖匙數以及牛奶的小杯數的比例應該要是 10 比 2 比 3。』&lt;/p&gt;
&lt;p&gt;你只覺得莫名其妙，心想這什麼神奇的比例。而且咖啡機剛剛是在拐彎抹角地說我不正常嗎？&lt;/p&gt;
&lt;p&gt;這時候咖啡機又說話了：&lt;/p&gt;
&lt;p&gt;『為了做出最符合您口味的咖啡，滿分 100 的情況下，請按鈕輸入你認為此杯咖啡值幾分。另外請告訴我是哪邊出了問題，如糖份比例太高還是牛奶太多，以讓我能記住您的喜好。』&lt;/p&gt;
&lt;p&gt;你翻了個白眼，喝杯咖啡還要教機器怎麼調配？哪裡智慧了？&lt;/p&gt;
&lt;p&gt;但為了喝到最符合自己喜好的咖啡，你決定給咖啡機一個機會，好好地調教它。針對眼前這杯咖啡，你把自己的回饋〈評分、調配比例的建議：砂糖太多〉老老實實地輸入進去。&lt;/p&gt;
&lt;p&gt;於是乎就這樣，不知不覺中你已經與月巴克咖啡機一起踏上了調配世界上最好喝咖啡的學習之旅。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/david-charles-schuett-362484-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了實際了解咖啡機怎麼學習，你翻開咖啡機使用手冊，看到以下內容：&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;《月巴克智慧咖啡機說明指南》&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本假設；使用者評分 = 使用者滿意程度&lt;/li&gt;
&lt;li&gt;預測使用者給咖啡的評分 &lt;code&gt;y'&lt;/code&gt; = &lt;code&gt;w1&lt;/code&gt; * 咖啡豆顆數 + &lt;code&gt;w2&lt;/code&gt; * 砂糖匙數 + &lt;code&gt;w3&lt;/code&gt; * 牛奶小杯數 + 基本分 &lt;code&gt;b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;目標：找出一組調配比重 &lt;code&gt;w1, w2, w3, b&lt;/code&gt;，使得咖啡機預測的評分 &lt;code&gt;y'&lt;/code&gt; 越接近實際的使用者評分 &lt;code&gt;y&lt;/code&gt; 越好&lt;/li&gt;
&lt;li&gt;咖啡製作：使用上述比重調配咖啡，使得預測評分 &lt;code&gt;y'&lt;/code&gt; 接近 100&lt;/li&gt;
&lt;li&gt;各原料調配比重〈原廠設定〉： &lt;code&gt;w1 = 10, w2 = 2, w3 = 3, b = 60&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;你恍然大悟，原來月巴克公司為了讓咖啡機最大化你給咖啡的評分，在咖啡機裡頭建構了一個簡單的&lt;a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8"&gt;線性回歸〈Linear Regression〉&lt;/a&gt;模型。&lt;/p&gt;
&lt;p&gt;在這模型裡頭，使用者針對一杯咖啡的評分 &lt;code&gt;y&lt;/code&gt; 會受到多個原料的量的影響。每個原料量的影響程度則透過個別的 &lt;code&gt;w&lt;/code&gt; 來描述。理想上，如果咖啡機可以找出一組比重〈weights〉 &lt;code&gt;w&lt;/code&gt; ，使得咖啡機『預測』出來的評分 &lt;code&gt;y'&lt;/code&gt; 跟『實際』使用者給的評分 &lt;code&gt;y&lt;/code&gt; 非常相近的話，咖啡機就可以利用該模型來合理地選擇咖啡豆、砂糖以及牛奶的量，調配出一杯預期能獲得你最高評分的咖啡。&lt;/p&gt;
&lt;p&gt;那咖啡機要如何實際『學習』呢？ 或者換句話說，咖啡機要怎麼樣知道它現在用的參數〈&lt;code&gt;w1&lt;/code&gt;、&lt;code&gt;b&lt;/code&gt;等〉夠不夠好呢？如果不夠好的話，要怎麼修正呢？&lt;/p&gt;
&lt;p&gt;在一開始完全沒有任何使用者回饋的時候，咖啡機可以很合理地使用原廠設定來計算使用者評分 &lt;code&gt;y'&lt;/code&gt;。等到你輸入了一些評分 &lt;code&gt;y&lt;/code&gt; 以後，將所有從你得到的評分 &lt;code&gt;y&lt;/code&gt; 跟咖啡機自己預測的 &lt;code&gt;y'&lt;/code&gt; 做比較，看咖啡機做的預測評分跟你的給分差了多少，據此修正原料的比重 &lt;code&gt;w&lt;/code&gt; 以及 &lt;code&gt;b&lt;/code&gt;。&lt;code&gt;y'&lt;/code&gt;跟&lt;code&gt;y&lt;/code&gt;的差異讓我們暫時稱作 &lt;code&gt;diff_y&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;修正以後，一般來說我們會得到新的比重　&lt;code&gt;w'&lt;/code&gt; 以及 &lt;code&gt;b'&lt;/code&gt;。當咖啡機使用 &lt;code&gt;w'&lt;/code&gt; 以及 &lt;code&gt;b'&lt;/code&gt;產生新的預測評分 &lt;code&gt;y''&lt;/code&gt;，其跟你的實際給分 &lt;code&gt;y&lt;/code&gt; 也會有一個差距，我們則將其稱作為 &lt;code&gt;diff_y'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;當使用新的參數〈&lt;code&gt;w1&lt;/code&gt;、&lt;code&gt;b&lt;/code&gt;等〉產生的 &lt;code&gt;diff_y'&lt;/code&gt; 比原來的 &lt;code&gt;diff_y&lt;/code&gt; 來小的時候，我們就能很開心地表示：『這咖啡機幹得真不錯！學到了點東西，能更準確地找出我的喜好！』。&lt;/p&gt;
&lt;p&gt;而在每次獲得你回饋的時候重複上述步驟，咖啡機不斷地修正它用來預估你給咖啡分數的參數，讓預測出來的值 &lt;code&gt;y'&lt;/code&gt; 跟你過去所有評分 &lt;code&gt;y&lt;/code&gt; 之間的差異都更小。雖然我們這邊不會細講，但在線性回歸裡頭，一個常被用來計算預測值 &lt;code&gt;y'&lt;/code&gt; 跟實際值 &lt;code&gt;y&lt;/code&gt; 差異的方式是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"&gt;最小平方法〈Least Squares〉&lt;/a&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;diff_y = 針對每次使用者的評分 y，機器利用當下的參數產生相對應的 y' 以後，用兩者計算 (y' - y) 的平方並加總它們
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以看到，當 &lt;code&gt;diff_y&lt;/code&gt; 越小，代表咖啡機越能準確地依據目前的原料量，來預測你會給咖啡的評分。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/daryan-shamkhali-89504-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;咖啡機學得很快。經過幾個怒吼以及失望的夜晚，透過你給的回饋，它現在做出的咖啡已經能很穩定地讓你給出 90 分以上的評價。&lt;/p&gt;
&lt;p&gt;透過詢問咖啡機，你現在知道，為了獲得你的高評價，咖啡機學到了以下的模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你給咖啡的評分 = 咖啡豆顆數 * 13 + 砂糖匙數 * 1.2 + 牛奶小杯數 * 1.5 + 基本分 40 分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這跟一開始為了滿足所有人的原廠設定相比，還差真不少：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般使用者評分 = 咖啡豆顆數 * 10 + 砂糖匙數 * 2 + 牛奶小杯數 * 3 + 基本分 60 分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照你過去的回〈ㄊㄧㄠˊ〉饋〈ㄐㄧㄠˋ〉，咖啡機發現跟一般人相比，咖啡豆量對你來說，是一杯咖啡好不好喝的重要指標〈13 vs 10〉，砂糖跟牛奶量則反而顯得沒那麼重要。而從基本分來看，咖啡機甚至學到你對咖啡的要求程度比一般人要來得嚴格〈40 vs 60〉，實實在在地說明機器了解你是個專業的咖啡愛好者。&lt;/p&gt;
&lt;p&gt;現在再讓我們看一次前面定義的機器學習：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;讓機器學習如何將輸入的資料 X 透過一系列的運算，轉換成指定的輸出 y。並提供一個衡量成功的方式，讓機器知道怎麼修正學習方向。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過上面的咖啡機例子，我們能清楚地歸納出以下幾點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;咖啡機是在進行機器學習，學習如何用一連串運算，將原物料的量〈咖啡豆顆數等〉&lt;code&gt;X&lt;/code&gt; 轉換成使用者評分 &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;機器學習裡所謂的一系列運算，在咖啡機的例子裡是進行線性回歸，即 &lt;code&gt;y = w * x + b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;咖啡機衡量成功的方式是計算『預測評分 &lt;code&gt;y'&lt;/code&gt; 跟實際評分 &lt;code&gt;y&lt;/code&gt; 之間的差異大小』，此差異越小，代表學得越好&lt;/li&gt;
&lt;li&gt;衡量成功的方法很重要，因為咖啡機可以知道『努力/學習的方向』&lt;/li&gt;
&lt;li&gt;咖啡機透過反覆地修正參數，進而最小化上述差異，成功地『學習』&lt;/li&gt;
&lt;li&gt;機器學習是學習一組最符合目標的『參數』〈如基本分的 &lt;code&gt;40&lt;/code&gt;、咖啡豆顆數的 &lt;code&gt;13&lt;/code&gt;〉&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們可以總結說，咖啡機在你給的回饋以及監督之下，想辦法從三種原料〈咖啡豆、砂糖、牛奶〉中，『學習』出一個最棒的調配比例，以做出一杯能得到你最高評價的咖啡。在機器學習領域裡頭，這實際上被稱作&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式學習〈Supervised Learning〉&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;太棒了，你跟月巴克咖啡機從此過著幸福美滿的日子‧&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何讓機器學得更好"&gt;如何讓機器學得更好&lt;a class="anchor-link" href="#如何讓機器學得更好"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你閱讀完上面例子，開始思考以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;『除了原物料的量以外，或許還可以搜集其他類型的資料，像是咖啡機主人的性別、年齡甚至泡咖啡的時間，然後把它們加到模型裡頭以提高預測評分的準度？』&lt;/li&gt;
&lt;li&gt;『除了簡單的線性回歸，我們應該也可以用其他更複雜的模型或演算法來預測使用者的評分？』&lt;/li&gt;
&lt;li&gt;『與其預測使用者評分，能不能建立新的模型，直接預測使用者喜好？』&lt;/li&gt;
&lt;li&gt;『如果咖啡機得到更多我的回饋資料，是不是會更準？』&lt;/li&gt;
&lt;li&gt;『我的喜好會隨很多因素如時間做改變，要怎麼讓咖啡機模擬這情況？』&lt;/li&gt;
&lt;li&gt;『這咖啡機學到最後，是不是只能產生適合我口味的咖啡，而不能產生大家都喜歡的咖啡？』&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我得說聲恭喜，你已經擁有機器學習的思維且準備好進入機器學習的殿堂了。&lt;/p&gt;
&lt;p&gt;但在你摩拳擦掌，準備進入殿堂時，有些人可能會跟你說，近年因為機器學習在各領域發展神速，且機器能使用的訓練資料〈Training Data〉也越來越多，&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7"&gt;強人工智慧〈Strong AI〉&lt;/a&gt;很快就會出現。不久的未來，我們甚至也不用自己設計演算法以及模型，A.I.會自動幫我們全部做好。也就是：機器會自己讓機器學得更好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/strong-ai.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    當強人工智慧出現以後，或許人類就不再被需要了。因為機器會自己讓機器學得更好。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;真的嗎？沒有人能真正的預測未來，所以我們無從知曉。&lt;/p&gt;
&lt;p&gt;但至少在接下來幾年，要讓機器學習或者人工智慧再繼續進步，『人類的思考』是不可或缺的重要因素。主要體現在兩個地方：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;機器並沒有意識判斷『為什麼』以及何謂『對的方向』&lt;/li&gt;
&lt;li&gt;機器的世界觀是人類教的&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="機器並沒有意識判斷『為什麼』以及何謂『正確』"&gt;機器並沒有意識判斷『為什麼』以及何謂『正確』&lt;a class="anchor-link" href="#機器並沒有意識判斷『為什麼』以及何謂『正確』"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;電腦因為有著強大的記憶以及運算能力，在很多任務上面都已經可以超越人類的表現。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/image-classification-history.PNG" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://chtseng.wordpress.com/2017/11/20/ilsvrc-%E6%AD%B7%E5%B1%86%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B/" target="_blank"&gt;ILSVRC 歷屆的深度學習模型&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;近年電腦視覺〈Computer Vision〉領域發展快速，機器學習在影像分類〈Image Classification〉的表現已經超越人眼。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;但能達到這樣的成果的前提，都是因為有人類在設計模型、監督機器學習。&lt;/p&gt;
&lt;p&gt;目前機器學習或是 A.I. 的應用其背後的模型，當你去看裡頭一行行的程式碼的時候，裡頭並不會定義『為什麼』要做這些任務。實際上，在機器學習的過程中，機器並沒有意識到為什麼要做這些任務；而如果沒有人類的介入的話，機器也不會自己定義什麼樣的結果叫做『成功』或『正確』，而也就不知道該往什麼方向學習。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;該讓機器學習什麼&lt;/li&gt;
&lt;li&gt;怎麼定義『正確/成功』，讓機器遵從並往該方向改善&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩件事情只有依靠人類來做決定。而其決定將大大地影響機器學習的成果以及品質。機器不會跟你說：&lt;/p&gt;
&lt;p&gt;『我覺得把影片裡面的貓咪識別出來，比識別出交通號誌燈來得重要。』&lt;/p&gt;
&lt;p&gt;『喔... 我覺得我們學的方向怪怪的，讓我們往這個方向學習如何？』&lt;/p&gt;
&lt;p&gt;一個定義出錯的目標函式〈Objective Function〉將永遠無法讓機器學出我們想要的結果。&lt;/p&gt;
&lt;p&gt;針對這點，我們應該：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;找出值得解決的問題，下定我們的目標並明確定義何謂『正確』，以讓機器往該方向學習。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="機器的世界觀是人類教的"&gt;機器的世界觀是人類教的&lt;a class="anchor-link" href="#機器的世界觀是人類教的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;第二點應該也不難理解。一個機器的世界觀基本上取決於兩點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人類指定使用的模型〈Model〉&lt;/li&gt;
&lt;li&gt;餵給它的資料〈Data〉&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前面咖啡機的線性回歸，我們透過一個簡單的線性模型，教會咖啡機看世界。在咖啡機所認知的世界裡頭，使用者的評分就只會受到三種原物料量的影響：咖啡豆、砂糖及牛奶。這是一個非常簡單的世界，方便我們理解機器學習，但在真實世界上基本上不會成功運作，你需要考慮更多因素。&lt;/p&gt;
&lt;p&gt;如同我們前面有提到，你可能會思考以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;『我的喜好會隨很多因素如時間做改變，要怎麼讓咖啡機模擬這情況？』&lt;/li&gt;
&lt;li&gt;『除了原物料的量以外，或許還可以搜集其他類型的資料，然後把它們加到模型裡頭以提高預測評分的準度？』&lt;/li&gt;
&lt;li&gt;『除了簡單的線性回歸，我們應該也可以用其他更複雜的模型或演算法來預測使用者的評分？』&lt;/li&gt;
&lt;li&gt;『這咖啡機學到最後，是不是只能產生適合我口味的咖啡，而不能產生大家都喜歡的咖啡？』&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/ricardo-resende-692381-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我們怎麼看世界，將直接影響機器怎麼看世界。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上你已經在思考如何擴充機器的世界觀了。你可以使用各式各樣的模型、更多的資料以讓機器能用更全面的方式來理解這個世界。而這個新的世界觀只能由你來定義。&lt;/p&gt;
&lt;p&gt;〈現在的〉機器不會突然跟你說：&lt;/p&gt;
&lt;p&gt;『嗯... 我覺得我們應該考慮泡咖啡時有沒有下雨，因為這可能會嚴重地影響使用者心情，進而影響評分。』&lt;/p&gt;
&lt;p&gt;『我只依照你的評分做最佳化，可能會有&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適&lt;/a&gt;問題喔！』&lt;/p&gt;
&lt;p&gt;這些問題都是我們必須自己發現並解決，不能只期待機器自動解決〈至少這幾年〉。在機器學習領域裡頭，最怕的不是模型完全不行，而是上述的&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適〈Overfitting〉&lt;/a&gt;問題：機器所看到的資料本身太過侷限，導致其雖然只看到真實世界的一小部分，就誤以為那是全世界。換句話說，機器裡存在著強烈的偏見〈bias〉。前陣子常聽到的案例是&lt;a href="https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police"&gt;白人設計出來的臉部辨識模型對黑人有偏見&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;以我們咖啡機的例子來說，如果你家裡只有你一人，咖啡機只需要服務你一人即好；但如果你們是一個家庭，家裡的人都希望咖啡機能為它們弄出好喝的咖啡，則每個人都需要給予咖啡機回饋，以讓咖啡機了解每個人喜好。如果仍然只有你一個人給予咖啡機回饋，其他人不給分，則咖啡機會以為得到的評分來自所有人，誤以為只要最佳化這些評分，就能滿足所有人，其實不然。&lt;/p&gt;
&lt;p&gt;為了讓機器看得更遠更全面，我們應該：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;想辦法在機器學習的模型內融入更多我們的直觀想法〈intuition〉，並讓機器看到更全面的資料，以拓展機器的『世界觀』。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何改善我們的學習_1"&gt;如何改善我們的學習&lt;a class="anchor-link" href="#如何改善我們的學習"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;閱讀到此，相信你對機器學習已經有個高層次的理解了。&lt;/p&gt;
&lt;p&gt;在對機器學習有個基本的了解以後，我們在前面章節提到為了讓機器學得更好，一個可行的方向是將我們的直觀想法、世界觀轉換成機器可以運算的模型或是目標函式，以讓機器能從聰明的我們身上學習。但換個角度思考，在我們教機器『學習』的時候，應該也能從機器『學習』到什麼才對。&lt;/p&gt;
&lt;p&gt;事實上，很多我們應用在機器學習領域的想法，緊密地跟我們的個人生活息息相關。&lt;/p&gt;
&lt;p&gt;舉個例子，在機器學習中，過適〈Overfitting〉是我們最想要避免的問題。我們不會希望機器只學到事物的表象，或者受到 outliers 的影響，而是希望機器學到更重要的模式〈Pattern〉、趨勢〈Trend〉。所以研究者們透過各種方式來讓機器不要過適：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入更多資料&lt;/li&gt;
&lt;li&gt;用更簡單的模型&lt;/li&gt;
&lt;li&gt;減輕 outliers 的比重&lt;/li&gt;
&lt;li&gt;正規化〈Normalization〉&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而當機器成功地學到了事物的本質，就能精準地預測未來並且概括所有情況〈Generalize〉：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;預測股票漲幅&lt;/li&gt;
&lt;li&gt;預測誰最後會當上總統&lt;/li&gt;
&lt;li&gt;預測詐騙交易&lt;/li&gt;
&lt;li&gt;預測一張照片裡頭有什麼物件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;畢竟，一個只看過貓跟狗照片的機器，不管未來看到什麼，就算是汽車或是人類，也只會將視它們為一定程度的貓或者是狗。&lt;/p&gt;
&lt;p&gt;知名心理學家&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%9A%E4%BC%AF%E6%8B%89%E7%BD%95%C2%B7%E9%A9%AC%E6%96%AF%E6%B4%9B"&gt;馬斯洛&lt;/a&gt;曾&lt;a href="https://www.brainyquote.com/authors/abraham_maslow"&gt;說過&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;如果你只有一個槌子，你可能就會把每個問題都視為釘子。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/tr-veler-671730-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    不管學習的是機器還是人類，學會概括〈Generalize〉並避免過適〈Overfitting〉是最重要的課題。手中只有槌子的人，什麼問題都看起來像釘子。
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同樣道理可以應用在人類的學習上。&lt;/p&gt;
&lt;p&gt;當我們只注重在參加各式各樣的線上深度學習〈Deep Learning〉課程，而不去了解機器學習背後的原理就是一種過適；當我們掙扎著要用 Python 還是 R 畫漂亮的圖，而不去理解為何要這樣畫，才能讓觀眾更容易理解時也是一種過適。更不用說一個只了解&lt;a href="https://zh.wikipedia.org/zh-hant/决策树"&gt;決策樹〈Decision Tree〉&lt;/a&gt;的同學，看到什麼問題都會想要用決策樹來解的案例了。&lt;/p&gt;
&lt;p&gt;學習表象比較簡單沒錯，但不能帶你走很遠。了解趨勢或者模式則讓你看到未來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卓越的歷史學家忽視單一歷史事件，透過了解世界整體的歷史脈絡來預測未來&lt;/li&gt;
&lt;li&gt;愛因斯坦觀察到世界的運作原理而推出有名的質能轉換公式 &lt;code&gt;E = mc&amp;sup2;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;好的學習方式是理解事物背後的運作的趨勢、模式。為何我們要機器學習？為什麼深度學習會崛起？注重在詢問更多的『為什麼』以理解事物本質。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從一些已經被應用在機器學習的概念獲得啟發，我們可以重新思考並改善我們人類自己的學習。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這篇文章前半段以一個虛構的智慧咖啡機為例，深入探討機器學習的一些基本但十分的重要概念以及運作方式。&lt;/p&gt;
&lt;p&gt;在掌握機器學習的基本概念以後，我們討論了如何以『人』為本，融入我們人類的智慧以讓機器更聰明地學習、了解這個世界。接著，我們用了一點篇幅，討論了看似不相關的『人類學習』以及『機器學習』之間一個共同且最重要的核心目標：『學習如何去概括〈Generalize〉事物並避免過適〈Overfitting〉』。&lt;/p&gt;
&lt;p&gt;現在機器學習〈尤其是深度學習〉跟其他學術領域如統計、電腦科學相比，是一個相對新的領域，大家都還在摸索階段。但正如當年新興的程式設計已經普遍被重視，甚至加入國高中教育一般，我想再過幾年，等機器學習更為成熟後，人們也會開始呼籲將『機器學習』領域的知識納入課綱，成為我們下一代的基本素養之一。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/andy-kelly-402111-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    未來教育模式的改變：
    &lt;br/&gt;
    或許『機器學習』會如同『程式設計』素養一般，成為下一代必備的基本知識素養之一
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;或許那就是本篇所提到的『從機器學習中學習』。&lt;/p&gt;
&lt;p&gt;但在那時代到達之前，讓我們開心〈機器〉學習吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="機器學習"></category><category term="machine learning"></category></entry><entry><title>從經驗中學習 - 直觀理解貝氏定理及其應用</title><link href="https://leemeng.tw/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html" rel="alternate"></link><published>2018-05-25T15:30:00+09:00</published><updated>2018-05-25T15:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-05-25:/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html</id><summary type="html">&lt;p&gt;貝氏定理（Bayes' theorem）是機率論中，一個概念簡單卻非常強大的定理。有了機率論的存在，人們才能理性且合理地評估未知事物發生的可能性（例：今天的下雨機率有多少？我中樂透的可能性有多高？），並透過貝氏定理搭配經驗法則來不斷地改善目前的認知，協助我們做更好的決策。這篇將利用生活上我們（或人工智慧）常需要考慮的事情當作引子，如今天的下雨機率是多少？來直觀地了解貝氏定理是怎麼被應用在各式各樣的地方。我們甚至可以效仿貝氏定理的精神，讓自己能更理性地評估未知並從經驗中學習。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;貝氏定理（Bayes' theorem）&lt;/a&gt;是機率論中，一個概念簡單卻非常強大的定理。有了機率論的存在，人們才能理性且合理地評估未知事物發生的可能性（例：今天的下雨機率有多少？我中樂透的可能性有多高？），並透過貝氏定理搭配經驗法則來不斷地改善目前的認知，協助我們做更好的決策。&lt;/p&gt;
&lt;p&gt;英國數學家&lt;a href="https://zh.wikipedia.org/wiki/%E5%93%88%E7%BD%97%E5%BE%B7%C2%B7%E6%9D%B0%E5%BC%97%E9%87%8C%E6%96%AF"&gt;哈羅德&amp;middot;傑弗里斯&lt;/a&gt;甚至&lt;a href="https://en.wikipedia.org/wiki/Bayes%27_theorem#cite_note-1"&gt;說過&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;貝氏定理之於機率論，就像是畢氏定理之於幾何學。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為其簡單且強大的特性，被廣泛應用在醫療診斷以及機器學習等領域。網路並不缺貝氏定理的教學文章，但多數以&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;機率公式&lt;/a&gt;出發，不夠直觀（至少以我個人來說），就算理解了也不易內化成自己的知識。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/Bayes_Theorem_MMB_01.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://commons.wikimedia.org/w/index.php?curid=14658489" target="_blank"&gt;貝氏定理公式&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;喔喔喔感覺到數學的力量了嗎？
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此這篇將利用生活上我們（或&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"&gt;人工智慧&lt;/a&gt;）常需要考慮的事情當作引子，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;今天的下雨機率是多少？&lt;/li&gt;
&lt;li&gt;這封 email 是垃圾郵件的可能性有多高？&lt;/li&gt;
&lt;li&gt;醫生說我得癌症了，這可靠度有多高？（好吧，或許這沒那麼常發生）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;來直觀地了解貝氏定理是怎麼被應用在各式各樣的地方。我們甚至可以效仿貝氏定理的精神，讓自己能更理性地評估未知並從經驗中學習。&lt;/p&gt;
&lt;p&gt;廢話不多說，讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="今天會下雨嗎？"&gt;今天會下雨嗎？&lt;a class="anchor-link" href="#今天會下雨嗎？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實際說明貝氏定理的公式把你嚇跑之前，讓我們先做個簡單的假想實驗來說明貝氏定理的精神。&lt;/p&gt;
&lt;p&gt;假設大雄一早準備出門跟靜香見面，正在考慮要不要帶傘出門。&lt;/p&gt;
&lt;p&gt;起床的時候他想：&lt;/p&gt;
&lt;p&gt;「這地區不太會下雨，不需要帶傘吧！」&lt;/p&gt;
&lt;p&gt;往窗外一看，大雄眉頭一皺，發現烏雲密佈。&lt;/p&gt;
&lt;p&gt;「痾有烏雲，感覺下雨機率上升了，但好懶得帶傘 .. 先吃完早餐再說吧。」&lt;/p&gt;
&lt;p&gt;走到廚房，發現餐桌上一大堆螞蟻在開趴。&lt;/p&gt;
&lt;p&gt;「依據老媽的智慧，螞蟻往屋內跑代表&lt;a href="http://news.ltn.com.tw/news/local/paper/715319"&gt;下雨機率又提升了&lt;/a&gt;。真的不得不帶傘了嗎 .. 不不不！我不要帶好麻煩！」&lt;/p&gt;
&lt;p&gt;想著想著，這時候靜香打電話過來了：&lt;/p&gt;
&lt;p&gt;「胖虎說他也要去喔！」「蛤你說什麼！？」&lt;/p&gt;
&lt;p&gt;胖虎是有名的雨男，每次跟他出遊都會下雨。依照這個經驗以及前面看到的幾個現象，最後大雄放棄掙扎，帶著雨傘出門了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/andy-grizzell-543812-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在上面的例子中，大雄觀察到三個現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;烏雲密佈&lt;/li&gt;
&lt;li&gt;螞蟻開趴&lt;/li&gt;
&lt;li&gt;胖虎出沒&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依據他過往的經驗，這些現象都會使得降雨的機率提升，讓他逐漸改變剛起床的時候「今天不太會下雨」的想法，最後決定帶傘出門。&lt;/p&gt;
&lt;p&gt;這個決策的轉變過程，其實就是貝氏定理的精神：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;針對眼前發生的現象以及獲得的新資訊，搭配過往經驗，來修正一開始的想法。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，大雄已經在腦海中進行了多次貝氏定理的運算而不自知（我家大雄哪有那麼聰明）。現在讓我們用比較數學的方式來重現大雄腦海中的運算。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="讓我們帶點數字進去"&gt;讓我們帶點數字進去&lt;a class="anchor-link" href="#讓我們帶點數字進去"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解貝氏定理的目的以後，讓我們以&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%91%E7%94%9F%E6%AF%94"&gt;發生比（odds）&lt;/a&gt;的方式來闡述定理。發生比很簡單，就只是列出兩個（或以上）的事件分別（可能）發生的次數。&lt;/p&gt;
&lt;p&gt;使用發生比的好處是可以很容易地比較不同事件發生的相對次數。後面會看到，我們也能把發生比轉成機率。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設依據過往氣象紀錄，大雄住的地區一年 365 天中有 270 天放晴，下雨的天數為 365 - 270 = 95 天。則下雨的發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天數：晴天數 = 95：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以把發生比想像成是一種相對關係，上面這個發生比代表，在大雄所住的地區，每觀測到 95 個雨天的日子，我們同時會觀測到 270 個晴天。晴天約是雨天的三倍之多（270 / 95）。&lt;/p&gt;
&lt;p&gt;轉換成機率來看的話，就是把雨天的天數，去除以所有天數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;95 / (95 + 270) = 0.26 = 26%
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一年也就只有 26% 的降雨機會，這也是為何大雄一開始在還沒觀察到新現象（烏雲、螞蟻及胖虎）的時候，合理認為今天「應該」不會下雨的原因。&lt;/p&gt;
&lt;p&gt;我們再繼續假設，依據大雄的過往經驗，他發現：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時，早上烏雲密佈的頻率是晴天時出現烏雲的 9 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這個 9 倍是怎麼來的呢？&lt;/p&gt;
&lt;p&gt;這其實是所謂的&lt;a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing"&gt;概度比（likelihood ratio）&lt;/a&gt;。分別計算雨天及晴天發生的情況下，出現「烏雲密佈」現象的機率以後，再將兩者相除：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天時烏雲密佈的機率 = P(烏雲|雨天）
-------------------------------
晴天時烏雲密佈的機率 = P(烏雲|晴天）
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這兩個機率又被稱為&lt;a href="https://zh.wikipedia.org/wiki/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"&gt;條件機率（conditional probability）&lt;/a&gt;。一般 &lt;code&gt;P(A|B)&lt;/code&gt; 代表在事件 B 發生的情況下，事件 A 發生的機率。&lt;/p&gt;
&lt;p&gt;假設平均來看，在 10 個雨天裡頭，早上烏雲密佈的天數為 9 天（也就是說平均有 1 天的雨天是早上沒有烏雲密佈的），則我們可以說，「給定雨天的條件下，烏雲密佈」的機率是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|雨天） = 9 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;另外在 10 個晴天裡頭，早上烏雲密佈的天數平均為 1 天（也就是說早上雖然烏雲密佈，但最後並沒有下雨的天數），則「給定晴天的條件下，烏雲密佈」的機率是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|晴天） = 1 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;則烏雲密佈的概度比即為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|雨天）    9 / 10
-----------  = --------- = 9
P(烏雲|晴天）    1 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;雖然「概度比」一詞很饒舌，但它就是一個比例，也就是「幾分之幾」的概念。 9 就是「一分之九」＝ 9 倍，而因為分母是「晴天」，你可以解讀這個 9 為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「在烏雲密佈發生的情況下，每觀測到 1 個晴天，就會同時觀測到 9 個雨天」。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也可以像是大雄觀察到的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「雨天時，早上烏雲密佈的頻率是晴天時出現烏雲的 9 倍」。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/cloudy-field-2.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    經驗告訴我們，早上烏雲密佈的情況下，該天是雨天的機率就隨著上升
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="貝氏定理初顯鋒芒"&gt;貝氏定理初顯鋒芒&lt;a class="anchor-link" href="#貝氏定理初顯鋒芒"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以有了這個倍數可以做什麼？直覺及經驗告訴我們，在觀測到烏雲密佈的前提下，下雨機率理論上會有所提升。&lt;/p&gt;
&lt;p&gt;換句話說，在烏雲密佈，且觀測到的晴天數不變的情況下，觀測到的雨天數應該要有所上升，這樣下雨的天數在所有天數裡頭的比例才會上升。&lt;/p&gt;
&lt;p&gt;而其上升的倍數就是前面的概度比（ 9 倍）。因此在烏雲密佈發生的情況下，新的下雨發生比（odds）可以寫成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =   95   *   9   ： 270
　　　　　　　　 =       855      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;新的下雨發生比是我們利用觀測到的現象重新計算的，因此一般稱為「事後發生比」（posterior odds）；而一開始的發生比則被稱為「事前發生比」（prior odds）。&lt;/p&gt;
&lt;p&gt;事後發生比告訴我們，在烏雲密佈的情況下，每觀測 855 個雨天，就會同時觀測到 270 個晴天。跟事前發生比相反，現在雨天數反而超過晴天的三倍（855 /　270）。&lt;/p&gt;
&lt;p&gt;要計算新的下雨機率，我們一樣把雨天數去除以所有天數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;855 / (855 + 270) = 0.76 = 76%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;跟一開始的 26% 相比，在觀測到烏雲密佈這個現象以後，下雨的機率足足上升了 50 個百分點，現在我們有更充分的理由請大雄帶把傘了。&lt;/p&gt;
&lt;p&gt;實際上，透過上面的計算，我們已經套用貝氏定理的公式了（&lt;a href="https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/"&gt;發生比版本&lt;/a&gt;）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;事後發生比 = 概度比 * 事前發生比&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同大雄的例子，一般應用貝氏定理的情境如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;對一件未知事物有初步的猜測（事前發生比）&lt;/li&gt;
&lt;li&gt;觀測到跟該事物相關的現象&lt;/li&gt;
&lt;li&gt;利用先前跟該現象有關的經驗計算出概度比&lt;/li&gt;
&lt;li&gt;利用概度比修正該猜測，得到修正後結果（事後發生比）&lt;/li&gt;
&lt;li&gt;重新評估、做決策&lt;/li&gt;
&lt;li&gt;又觀察到新現象，重複步驟 3 到 5 &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;透過貝氏定理，我們可以很快速地利用過去的經驗改善自己的想法，並產生更好的決策。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="大雄不死心：單純貝式"&gt;大雄不死心：單純貝式&lt;a class="anchor-link" href="#大雄不死心：單純貝式"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然觀察到了烏雲密佈，且利用過往經驗修正下雨的機率到了 76%，懶惰的大雄一開始還是不想帶傘出去。但為何最後還是帶傘出門了呢？那是因為除了烏雲密佈以外，他還觀察到了其他兩個影響下雨機率的現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;螞蟻開趴&lt;/li&gt;
&lt;li&gt;胖虎出沒&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;貝氏定理本身雖然強大，但其中一個使它被廣泛利用的是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"&gt;單純貝式（Naive Bayes）&lt;/a&gt;的概念：假設不同現象之間出現的機率為&lt;a href="https://zh.wikipedia.org/wiki/%E7%8B%AC%E7%AB%8B_(%E6%A6%82%E7%8E%87%E8%AE%BA"&gt;獨立&lt;/a&gt;)。&lt;/p&gt;
&lt;p&gt;設成獨立有什麼好處？事情變得很簡單，我們不用考慮現象 A 跟現象 B 之間的關聯性，能針對每個現象，分別去計算概度比，修正從「前面」的現象得到的結果，持續改善我們的認知。也就是上一節提到的貝氏定理的應用步驟 6。&lt;/p&gt;
&lt;p&gt;如法炮製，讓我們假設大雄針對其他兩個現象的經驗是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時，螞蟻出現在室內的天數是晴天的 2 倍&lt;/li&gt;
&lt;li&gt;雨天時，胖虎出遊的次數是晴天的 3 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們再次套用貝氏定理，但這次不是套用在一開始什麼都不知道的事前發生比：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天數：晴天數 = 95：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而是在觀察到烏雲密佈後的事後發生比：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;烏雲密佈下的雨天數：晴天數 = 855：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先，讓我們套用跟螞蟻相關的經驗：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時螞蟻出現在室內的天數是晴天的 2 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;概度比已經算好，所以依照貝氏定理的公式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;事後發生比 = 概度比 * 事前發生比&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新的（螞蟻）事後發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =   855  *   2   ： 270
　　　　　　　　 =      1710      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下雨的機率則提升為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1710 / (1710 + 270) = 0.86 = 86%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;比起只有烏雲密佈，在螞蟻也出現的情況下，降雨機率又提升了接近 10%。大雄是一個降雨機率不大於 90% 就不帶傘的傢伙，讓我們看看胖虎出沒能不能使他改變心意。&lt;/p&gt;
&lt;p&gt;同樣，再次套用定理到上一個（螞蟻的）發生比，則新的（胖虎）事後發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =  1710  *   3   ： 270
　　　　　　　　 =      5130      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在轉換成機率之前，我們發現新的雨天數是晴天數的 10 倍以上，因此可以想像新的機率至少是 90% 以上。而實際計算下雨的機率：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;5130 / (5130 + 270) = 0.95 = 95%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在觀察到烏雲密佈、螞蟻以及胖虎出沒以後，大雄預估降雨機率上升至 95%，這下不得不帶傘出門了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/eddy-klaus-33079-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
重複套用貝氏定理以修正想法的過程就像是在創作：把眼前所有所見（顏料）一個一個納入考量，做出最後的判斷（作品）
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="動動腦時間"&gt;動動腦時間&lt;a class="anchor-link" href="#動動腦時間"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到了這邊，我相信你現在應該已經可以在腦中直觀地運用貝氏定理：針對眼前發生的現象，運用過去相關的經驗（計算概度比），來理性地評估某事件可能發生的機率。&lt;/p&gt;
&lt;p&gt;事實上在你繼續讀下去之前，我建議先停一停，思考幾個可以實際在生活中運用（或者已經在用）此定理的現象，以幫助你內化（internalize）這些概念。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/bayes/neonbrand-618322-unsplash.jpg" style=""/&gt;
&lt;/center&gt;&lt;p&gt;如果你一時想不到點子，這邊提供幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;email 內文裡頭出現「週年慶」時，該郵件為垃圾信的機率&lt;/li&gt;
&lt;li&gt;新聞內文出現「柯文哲」時，文章主題為政治的機率&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;醫生說你得胰腺癌&lt;/a&gt;時，你真的得病的機率&lt;/li&gt;
&lt;li&gt;玩&lt;a href="https://zh.wikipedia.org/wiki/%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F"&gt;英雄聯盟&lt;/a&gt;時，&lt;a href="https://baike.baidu.com/item/kDa/20623453"&gt;KDA&lt;/a&gt; 超過 4 的對手排位是鑽石以上的機率&lt;/li&gt;
&lt;li&gt;在東京藥妝店血拼，旁邊講中文的人是台灣人的機率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你有其他有趣的例子，歡迎留言跟大家分享。（現在留言不用登入了！）&lt;/p&gt;
&lt;p&gt;如同上述，貝氏定理有非常多應用。不過這邊想深入探討第一個 email 的案例：給定一封電子郵件的內文，你要怎麼判斷該信是不是垃圾信件？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="從人腦到電腦：讓機器幫我們做判斷"&gt;從人腦到電腦：讓機器幫我們做判斷&lt;a class="anchor-link" href="#從人腦到電腦：讓機器幫我們做判斷"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/spam.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個典型的垃圾郵件內文
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你說沒有什麼事情難得了我們人腦。依照過往經驗：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;垃圾信件裡頭出現「週年慶」一詞的機會是一般信件的 20 倍&lt;/li&gt;
&lt;li&gt;垃圾信件裡頭出現「折扣」一詞的機會是一般信件的 10 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在假設所有信件裡頭一半是垃圾信件（發生比 1：1）的前提下，依照單純貝氏的公式，這封信是垃圾信件的可能性上升 200 倍（20 * 10），我們可以放心把這封信丟入垃圾信分類。&lt;/p&gt;
&lt;p&gt;但是沒有人會想要在腦中對每封信做這個運算。人類是懶惰的，能自動化的東西就請電腦幫我們解決就好了。&lt;/p&gt;
&lt;p&gt;另外你也不可能記得每一個詞的倍數，實際上也沒有必要。只要讓電腦幫我們記住每個詞分別在垃圾郵件以及一般信件出現的次數，就能計算所有詞彙的概度比（odds）。&lt;/p&gt;
&lt;p&gt;等到一封新的信件來以後，找出裡頭的字對應的倍數做相乘以後，電腦就能自動分類郵件了。事實上這就是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;中&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"&gt;單純貝氏分類器（Naive Bayes Classifier）&lt;/a&gt;在做的事情。&lt;/p&gt;
&lt;p&gt;讓機器取代人腦自動判斷，有幾個顯而易見的好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;判斷速度倍增&lt;/li&gt;
&lt;li&gt;記憶能力超強&lt;/li&gt;
&lt;li&gt;（可以把分類郵件空出的時間拿去看貓咪影片）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;唷呼！垃圾郵件自動變不見！小鎮村又變得更美好了。&lt;/p&gt;
&lt;p&gt;當然你想自己實作單純貝氏分類器的話，Python 可以使用 &lt;a href="http://scikit-learn.org/stable/modules/naive_bayes.html"&gt;scikit-learn&lt;/a&gt; 來實作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="小心！你的經驗可靠嗎？"&gt;小心！你的經驗可靠嗎？&lt;a class="anchor-link" href="#小心！你的經驗可靠嗎？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們花了很長的篇幅講了幾個貝氏定理/單純貝氏的應用，也看到它既簡單又強大的特性。但在你摩拳擦掌並實際應用此定理的時候，有幾點需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同現象/事件真的獨立嗎？&lt;/li&gt;
&lt;li&gt;一開始的猜測以及經驗可靠嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多現象不一定是完全獨立而是相關的。不過一個常見的解決方法是想辦法增加更多的現象/事件/特徵值（features）來讓做出來的貝氏分類器比較可靠。貝氏定理當然不完美，但正如統計學家&lt;a href="https://www.google.co.jp/search?q=George+E.+P.+Box&amp;amp;rlz=1C5CHFA_enJP695JP700&amp;amp;oq=George+E.+P.+Box&amp;amp;aqs=chrome..69i57j69i60&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8"&gt;喬治&amp;middot;E&amp;middot;P&amp;middot;博克斯&lt;/a&gt;&lt;a href="https://en.wikipedia.org/wiki/All_models_are_wrong"&gt;所說&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;所有模型（models）都是錯的；但有些是有用的。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管「獨立」這個假設在某些情況下不合常理，但在如垃圾郵件分類等問題上，貝氏分類器有不錯的表現。而且重點是它實作簡單，可以拿來當作 baseline。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而一開始的猜測跟經驗可不可靠這個問題，英國數學家&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%A1%E5%B0%94%C2%B7%E7%9A%AE%E5%B0%94%E9%80%8A"&gt;卡爾&amp;middot;皮爾森&lt;/a&gt;，針對貝氏定理則給出一個我很愛的&lt;a href="https://en.wikipedia.org/wiki/Talk%3ABayesian"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個信奉貝氏定理的人常常做這樣的事情：模糊地期待著馬的出現，瞥見驢子的蹤影，強烈地相信他是見到了一匹駝子。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;「先入為主」大概是應用貝氏定理最忌諱的點了。下次再套用定理時，記得先思考自己一開始的假設以及經驗是否值得信任或者有什麼盲點。需不需要搜集更多資料來修正一開始的想法。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/tim-mossholder-603227-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我真的是驢子不是駝子啊！（豆知識：駝是馬跟驢生下的動物）
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="總結"&gt;總結&lt;a class="anchor-link" href="#總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這篇開頭首先用「大雄評估下雨」的例子來直觀地理解貝氏定理背後的精神，接著透過簡單的數學概念、發生比（odds）以及概度比（likelihood ratio）來推出基本的貝氏定理公式。&lt;/p&gt;
&lt;p&gt;接著進一步延伸至單純貝氏（naive bayes）的概念，讓機器透過過去累積的資訊，為我們自動分類垃圾郵件。&lt;/p&gt;
&lt;p&gt;最後我們提到一些應用貝氏定理需要注意的事情。&lt;/p&gt;
&lt;p&gt;即使基本的貝氏定理不難，延伸的領域非常的廣。這篇沒辦法包含所有範圍，但希望透過這篇基礎介紹，能讓讀者能利用貝氏定理的概念，更理性地評估未知並從經驗中學習（或者是建立自己的貝氏分類器）。&lt;/p&gt;
&lt;p&gt;另外如果你有其他有趣的例子可以應用在貝氏定理，歡迎留言跟大家分享。（現在留言不用登入了！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="貝氏定理"></category><category term="機率"></category><category term="機器學習"></category></entry><entry><title>揭開資料科學的神秘面紗</title><link href="https://leemeng.tw/demystify-the-hype-of-data-science-and-its-value.html" rel="alternate"></link><published>2018-05-11T21:10:00+09:00</published><updated>2018-05-11T21:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-05-11:/demystify-the-hype-of-data-science-and-its-value.html</id><summary type="html">&lt;p&gt;市面上有大量資料科學相關課程、書籍供我們自由學習，但你有想過為何我們需要學習資料科學嗎？為什麼資料科學現在那麼夯？我們應該拿資料科學來做什麼？抽離技術實作或者分析手法的討論，這篇文章試著用簡單的經濟學解釋其背後原因。希望閱讀完本文的讀者能了解為何資料科學在資訊時代扮演重要角色，以及我們要怎麼有效率地把握「資料科學力」以創造更大的價值。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;幾乎每天我們都能看到跟資料科學（Data Science）相關的新聞與文章，像是最近 &lt;a href="https://www.bnext.com.tw/article/49070/google-ai-phone-call-assistant-duplex-ethical-social-implications"&gt;Google 利用遞迴神經網路建立可以跟真人對話而不被發現的語音助理&lt;/a&gt;、 &lt;a href="https://www.inside.com.tw/2018/04/24/data-scientist-interview"&gt;成為 Apple 等公司的資料科學家前必讀的面試題目&lt;/a&gt;等等。&lt;/p&gt;
&lt;p&gt;市面上有大量資料科學相關課程、書籍供我們自由學習，事實上，多到一個人不可能看完。你有想過為何我們需要學習資料科學嗎？為什麼資料科學現在那麼夯？我們應該拿資料科學來做什麼？&lt;/p&gt;
&lt;p&gt;抽離技術實作或者分析手法的討論，這篇文章試著用簡單的經濟學原理回答這幾個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望閱讀完本文的讀者能了解為何資料科學在資訊時代扮演重要角色，以及我們要怎麼有效率地把握「資料科學力」以創造更大的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文大致上會分成以下段落：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#聽說你想當資料科學家？"&gt;聽說你想當資料科學家？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料科學到底在夯什麼？"&gt;資料科學到底在夯什麼？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#啊所以那個資料科學勒？"&gt;啊所以那個資料科學勒？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#充實你的資料科學力"&gt;充實你的資料科學力&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="聽說你想當資料科學家？"&gt;聽說你想當資料科學家？&lt;a class="anchor-link" href="#聽說你想當資料科學家？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料科學大概是近年最夯的流行語之一了。不管在哪邊，你都可以聽到媒體相關的報導：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://taronews.tw/2018/05/07/34472/"&gt;食農教育科研成果農業大數據結合資料科學&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.inside.com.tw/2018/04/24/data-scientist-interview"&gt;想成為資料科學家？來挑戰 Google、FB、Apple 等六間公司人工智慧最新面試題&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.digitimes.com.tw/iot/article.asp?cat=130&amp;amp;cat1=&amp;amp;cat2=&amp;amp;id=0000529979_36M8SBKK8S3C4K8O2RHKM&amp;amp;social_share=y"&gt;台灣產業AI化 最大問題人才不足&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ithome.com.tw/news/121342"&gt;成為搶手資料科學家應具備什麼技能？先學Python準沒錯&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... 族繁不及備載。&lt;/p&gt;
&lt;p&gt;而因為企業對擁有資料科學能力的人才需求大，想成為資料科學家（Data Scientist）的同學們也不少，相關的教學文章、線上課程如雨後春筍般湧現。這邊我沒辦法把它們一一列出，但你可以前往一些知名的線上課程平台如 &lt;a href="https://www.coursera.org/"&gt;Coursera&lt;/a&gt;、&lt;a href="https://www.udemy.com/"&gt;Udemy&lt;/a&gt;、&lt;a href="https://www.datacamp.com/"&gt;DataCamp&lt;/a&gt; 並搜尋「資料科學」（或者 Data Science）就知道我的意思了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/datacamp-courses.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/" target="_blank"&gt;DataCamp&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;基本上全部都是資料科學相關課程，寫程式寫到飽
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們把這些新聞報導或者教學課程，依照主題/領域做個粗略分類的話，還可以得到一些關鍵字：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大數據（Big Data）&lt;/li&gt;
&lt;li&gt;人工智慧（Artificial Intelligence）&lt;/li&gt;
&lt;li&gt;資料視覺化（Data Visualization）&lt;/li&gt;
&lt;li&gt;機器學習（Machine Learning）&lt;/li&gt;
&lt;li&gt;深度學習（Deep Learning）&lt;/li&gt;
&lt;li&gt;統計分析（Statistical Analytics）&lt;/li&gt;
&lt;li&gt;雲端運算 （Cloud Computing）&lt;/li&gt;
&lt;li&gt;Python、R、SQL&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/sean-pollock-203658-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/PhYq704ffdA?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料科學&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;涵蓋大量領域，各領域的專業知識就像一棟棟大樓將你包圍吞噬
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想學習資料科學的同學這時候就頭疼了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「全部都要學嗎？從哪邊開始 .. 」&lt;/li&gt;
&lt;li&gt;「選 &lt;a href="https://zh.wikipedia.org/wiki/Python"&gt;Python&lt;/a&gt; 或是 &lt;a href="https://zh.wikipedia.org/wiki/R%E8%AF%AD%E8%A8%80"&gt;R 語言&lt;/a&gt;？還是先學 &lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;SQL&lt;/a&gt;？」&lt;/li&gt;
&lt;li&gt;「資料視覺化要學 Python 的 &lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt; 還是 R 的 &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt; ？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在有些網站很用心，為了解決你的煩惱，還將相關的課程集結起來成一個&lt;a href="https://www.coursera.org/specializations/data-science-python"&gt;專業課程（Specialization）&lt;/a&gt;讓你一步一步跟著學。&lt;/p&gt;
&lt;p&gt;勤學如你，上了幾門課以後學會如何利用 &lt;a href="https://www.coursera.org/learn/python-machine-learning"&gt;Python 做簡單的機器學習模型&lt;/a&gt;、&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1"&gt;使用 R 做資料視覺化&lt;/a&gt;，甚至也懂得&lt;a href="https://www.datacamp.com/courses/intro-to-sql-for-data-science"&gt;使用 SQL 存取資料庫&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;恭喜！你是個資料科學家了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;痾.. 這麼簡單？好像哪裡怪怪的？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會不會開始思考：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;所以到底啥是資料科學？資料科學到底在夯什麼？為什麼我要學資料科學？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上會這樣想的不止你一人。在仔細思考並給上述問題一個合理的解釋之前，就算學了再多門課，充其量只是在不斷擴充自己的「資料科學工具盒」，但卻不知道「為何要買這些工具」、「要拿這些工具做什麼」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/barn-images-12223-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料科學工具箱&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;琳瑯滿目，酷！但你要用這些工具創造或是改善什麼？
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為你學的是方便實踐資料科學的程式語言、工具、方法論（Methodology），而不是「為什麼資料科學重要」。我會用剩下的篇幅試著對此問題給出一套解釋。解釋方法有很多種，所以非常歡迎在底下留言分享你的看法。&lt;/p&gt;
&lt;p&gt;不過現在，且聽我娓娓道來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料科學到底在夯什麼？"&gt;資料科學到底在夯什麼？&lt;a class="anchor-link" href="#資料科學到底在夯什麼？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了耳熟能詳的「技術發展快速」、「資料量龐大」的理由以外，資料科學之所以那麼夯，背後還有一個可想而知的巨大推手：「商業利益」。&lt;/p&gt;
&lt;p&gt;要進一步解釋這個概念，我們可以從 Google 首席經濟學家 &lt;a href="https://zh.wikipedia.org/wiki/%E5%93%88%E5%B0%94%C2%B7%E8%8C%83%E9%87%8C%E5%AE%89"&gt;哈爾&amp;middot;范里安&lt;/a&gt; 在 2009 年接受麥肯錫的訪問，探討&lt;a href="https://www.mckinsey.com/industries/high-tech/our-insights/hal-varian-on-how-the-web-challenges-managers"&gt;網際網路對企業的挑戰&lt;/a&gt;中看出一些端倪。（真知灼見，建議作課外閱讀）&lt;/p&gt;
&lt;p&gt;近年網際網路快速發展。要在網路上發表內容，對任何人或者任何企業來說都是輕而易舉的事情。這邊說的內容（Content）可以是任意資訊，比如説：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一則 Facebook 粉絲團貼文&lt;/li&gt;
&lt;li&gt;一則銷售青島啤酒的網頁&lt;/li&gt;
&lt;li&gt;一個教你學習資料科學的線上課程網頁&lt;/li&gt;
&lt;li&gt;一篇部落格文章（像你正在看的這篇）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為傳播媒介以及科技的進步，要在網路上發布這些資訊並讓他人注意到的成本趨近於零，而其導致的結果就是&lt;a href="https://www.ithome.com.tw/article/87190"&gt;全球的資訊量急速成長&lt;/a&gt;。被稱為人工智慧之父之一的經濟學家 &lt;a href="http://wiki.mbalib.com/zh-tw/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99"&gt;赫伯特&amp;middot;西蒙&lt;/a&gt; 針對這種現象就曾說過一句&lt;a href="https://en.wikiquote.org/wiki/Herbert_A._Simon"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在一個資訊豐富的世界裡頭，資訊量的富裕導致人們注意力的貧窮。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以個人的角度來看，在時間以及精力有限的情況下，我們每天能接受資訊的時間以及注意力都是有限的。如何分配這些寶貴的注意力以接收對的資訊，變成現代人的課題。&lt;/p&gt;
&lt;p&gt;痛點即商機。很多企業透過解決這個&lt;a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E8%A8%8A%E8%B6%85%E8%BC%89"&gt;資料超載（Information Overload）&lt;/a&gt;的問題來提供使用者價值：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;漫畫網站把所有知名漫畫整理在一起供你閱讀&lt;ul&gt;
&lt;li&gt;價值：統整、數位化、自動更新散落各地的漫畫資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Google 提供搜尋功能給你&lt;ul&gt;
&lt;li&gt;價值：讓你快速找到存在地球上的任何相關資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Youtube 讓你免費看到飽&lt;ul&gt;
&lt;li&gt;價值：讓你隨時看全世界最新的貓咪影片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;只要喊「+1」Facebook 粉絲團就免費把「珍貴」的內容給你&lt;ul&gt;
&lt;li&gt;價值：給你數位內容如新產品資訊、整理過後的旅遊資訊等&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;天下沒有白吃的午餐，企業願意這麼做必定有得到什麼。你的確取得了免費的數位內容（文章、影片、漫畫），但又付出了什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/velizar-ivanov-540528-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/lz_VB9yEc_c?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資訊時代最珍貴的資源&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;人們（與喵）的關注
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，不管是閱讀文章、觀看影片、瀏覽漫畫，你都是在拿了你最寶貴的「注意力」跟企業交換這些價值。而在成功獲得你目光的同時，這些企業則透過秀廣告給你來獲利（例 1 - 3，暫不考慮 AdBlock）。&lt;/p&gt;
&lt;p&gt;註：在這邊，「注意力」跟「時間」有些微秒差異。不過你只要回想昨天晚上跟朋友或是家人吃飯的時候，各自滑手機的景象就可以了：你把「時間」花在跟身旁的人吃飯，卻把「注意力」（或者說是關注）放在手機裡頭的數位資訊。（如果你沒用手機，我很抱歉。）&lt;/p&gt;
&lt;p&gt;例 4 很有趣，你是拿「你自己以及你朋友圈的人的注意力」來做價值交換（你的留言讓 Facebook 的演算法自動推播該貼文到你朋友的動態牆上，粉絲團賺到他們的關注），但基本上是同樣的道理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/rawpixel-552390-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/PUyuhpHr9Z4?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資訊時代最常見的價值交換&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;給我你的關注，我就給你免費資訊（外加廣告）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以經濟學的角度來重述前面的觀點，現在的資訊時代最不缺的資源就是「資料」；稀有、價值高且需要小心分配的稀有財是「人們的注意力」。在這個資訊爆炸的時代，企業透過加工處理大量的原始資料，產生新產品、服務及價值來換取該稀有財：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;誰能善用資料科學的力量、從現有數據創造新價值、服務或產品，並以此吸引人們珍貴的關注，就能獲得商機。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是為何資料科學那麼夯的其中一個原因：從資料中創造新價值，進而產生商業利益。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="啊所以那個資料科學勒？"&gt;啊所以那個資料科學勒？&lt;a class="anchor-link" href="#啊所以那個資料科學勒？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;聽到上面的例子，有些人的想法可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「哇這些企業好狡猾把我的注意力都偷走了！」&lt;/li&gt;
&lt;li&gt;「這樣回覆 +1 好有罪惡感喔嗚嗚」&lt;/li&gt;
&lt;li&gt;「好險我用 AdBlock 嘻嘻」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但這邊重點是要說明，這種依靠廣告的商業模式已經行之多年。Facebook、Google 等企業為了抓住我們的目光，持續不斷地在精進，以求能有效率地儲存、處理以及分析由我們產生的大量數據。&lt;/p&gt;
&lt;p&gt;而他們用來處理、分析、視覺化以及理解數據的這些程式語言、工具、方法論的總集合就構成所謂的資料科學。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;搜集、理解、分析、處理、視覺化資料數據並從中萃取有用的價值就是資料科學。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們以一個簡單的 Google 搜尋做更進一步的解釋。&lt;/p&gt;
&lt;p&gt;想像你在 Google 上搜尋「 data science courses 」後可能跑出以下結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/google.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Google 日常：搜尋結果之上有幾個相關廣告
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒什麼特別的，Google 日常不是嗎？&lt;/p&gt;
&lt;p&gt;現在試著做以下步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;開一個新的分頁/視窗&lt;/li&gt;
&lt;li&gt;隨便搜尋一個你有興趣的商品/產品，記下出現的幾個廣告還有它們的順序。&lt;/li&gt;
&lt;li&gt;隨便點幾個連結或者什麼都不做&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重複步驟 2 跟 3 幾次以後，你應該可以觀察到顯示的廣告消失或者順序改變了：而這是因為背後有 Google 的廣告競價系統在運作。下面是這系統的超級簡化示意圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/google-bidding-system.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Google 廣告競價：運用使用者的行為資料，即時地推算出該使用者點擊各廣告的機率。搭配業主的出價，選出適當的廣告顯示。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要完成此系統需要強大的資料科學技術支持。只有一個人搜尋的時候事情還好辦，但你得知道，在本文撰寫當下，Google &lt;a href="http://www.internetlivestats.com/one-second/#google-band"&gt;平均 1 秒鐘處理 67, 000 筆&lt;/a&gt;搜尋。試著想像一下，為了實現這個系統，Google 可能需要完成以下幾件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用深度學習進行自然語言處理，判斷使用者輸入的語言以及想要表達什麼&lt;/li&gt;
&lt;li&gt;即時處理所有使用者查詢的串流數據&lt;/li&gt;
&lt;li&gt;利用使用者過往的瀏覽紀錄來預測點擊某廣告的機率&lt;/li&gt;
&lt;li&gt;在公司內部監控目前台灣使用者的搜尋趨勢（類似 &lt;a href="https://trends.google.com.tw/trends/"&gt;Google Trend&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器學習、統計分析、大數據 ... 這些工作運用到的技術，不就是那些我們在&lt;a href="#聽說你想當資料科學家？"&gt;聽說你想當資料科學家&lt;/a&gt;章節裡頭看到的關鍵字嗎？&lt;/p&gt;
&lt;p&gt;我們這篇只以 Google 的廣告系統為例，但實際上現在幾乎可以說是全世界都在想辦法利用資料科學的力量來處理資料並創造新的價值、服務、公司。看看現在的新創，有哪些沒有用到資料科學？&lt;/p&gt;
&lt;p&gt;所以你現在知道為何資料科學那麼重要了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;全世界都在想辦法活用資料科學以從龐大數據中為使用者創造更多價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="充實你的資料科學力"&gt;充實你的資料科學力&lt;a class="anchor-link" href="#充實你的資料科學力"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;綜觀資料科學一詞萌芽到最近的過程，全世界的資料量&lt;a href="https://www.ithome.com.tw/article/87190"&gt;持續成長&lt;/a&gt;，而人們也不斷地在想辦法追趕這些資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用最有效率的方式儲存這些資料&lt;/li&gt;
&lt;li&gt;用最快的速度處理及分析這些資料&lt;/li&gt;
&lt;li&gt;對這些資料做實驗，重複再重複測試不同的假說及演算法&lt;/li&gt;
&lt;li&gt;快速地從資料萃取出新的洞見（Insight）&lt;/li&gt;
&lt;li&gt;以這些洞見創造新的價值、產品、服務&lt;/li&gt;
&lt;li&gt;加速以上步驟所需要的循環時間&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前面 Google 的例子，這些都是資料科學。&lt;/p&gt;
&lt;p&gt;你會發現，所謂的資料科學（Data Science）就是對資料（Data）做科學、有系統地（Scientific）的處理罷了。資料科學一詞或許誕生沒多久，但對資料做科學這概念老早就存在了。只是近年因為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;數據量的快速成長（如&lt;a href="http://technews.tw/2017/06/07/seagate-one-fifth-of-global-data-will-be-real-time-and-most-of-them-belongs-to-internet-of-things/"&gt;物聯網裝置的火紅&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;運算能力的進步&lt;/li&gt;
&lt;li&gt;人工智慧的突破&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等原因，讓我們更急迫地想辦法用以往做不到的方式來理解這個世界的龐大數據。 &lt;a href="https://www.youtube.com/watch?v=F1wlCerC40E"&gt;Youtube 現在能夠分析出你喜歡看貓咪影片&lt;/a&gt;，&lt;a href="https://www.bnext.com.tw/article/49070/google-ai-phone-call-assistant-duplex-ethical-social-implications"&gt;Google 可以建立跟真人對話而不被發現的語音助理&lt;/a&gt;。這些都是他們利用資料科學，從現有的大量數據創造額外價值的例子。如同&lt;a href="https://www.safaribooksonline.com/library/view/what-is-data/9781449336080/ch01.html"&gt;這篇&lt;/a&gt;所說的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;未來是屬於那些能從大量資料數據創造價值的企業以及人才的。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個好消息是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一企業擁有的資料量&lt;/li&gt;
&lt;li&gt;一企業裡能夠處理、分析此資料量的資料科學人才數量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩者在多數企業都是不成比例的（後者短缺），因此擁有資料科學能力的人才薪水可以說是水漲船高。而這當然也變成為何近年那麼多人想成為資料科學家的動機（儘管有些人可能不知道背後原因）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/stefan-stefancik-257625-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/UCZF1sXcejo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;了解資料科學相關知識的人才&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;是大多數的企業積極尋找的對象
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解這點以後，你可以先想想自己的興趣在哪裡、想用資料科學創造什麼價值。這邊想強調的是，先思考你能透過資料科學，創造什麼新的「價值」，而不是什麼「商業利益」。&lt;/p&gt;
&lt;p&gt;如同我們前面看到的，資料科學是現行廣告經濟的背後推手，但為何我們願意看 Google、Facebook 丟給我們的廣告？那是因為他們「先」從資料創造了價值（方便的搜尋功能、社群網路功能）從而取得我們的關注。&lt;/p&gt;
&lt;p&gt;實際上，在取得關注以後，你的商業模式不是一定要秀廣告給使用者看。訂閱制（Subscription）或會員制是一個替代方案： NetFlix 和 Amazon 都是這樣。甚至，你可以&lt;a href="https://www.bnext.com.tw/article/49041/google-fb-business-model"&gt;不像 Google 一樣思考&lt;/a&gt;，使用新的商業模型。&lt;/p&gt;
&lt;p&gt;但「商業模式」不是這篇想討論的議題。重點是「價值」：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資訊爆炸的時代，各行各業的每個人都需要學習善用資料科學，從資料數據創造新的使用者價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，與其想著要成為一個資料科學家，不如先好好想想，在自己目前所在的業界、公司、職位能怎麼利用手邊的資料數據搭配資料科學來創造新的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你耐心地看到這邊，代表我得到你最珍貴的關注了，賺賺賺！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;稍微複習一下，我們在這篇文章開頭假想了一個有志學習資料科學的同學。在他/她學習資料科學的過程產生了幾個疑問：「為何資料科學那麼夯？」「為何我們需要資料科學？」&lt;/p&gt;
&lt;p&gt;而本篇則以非常簡單的經濟學供給概念，加上 Google 以及 Facebook 的運作方式來說明現在的企業是怎麽利用資料科學來創造新的使用者價值來交換人們的關注。&lt;/p&gt;
&lt;p&gt;我們接著說著為何今後各行各業都需要「資料科學力」來處理日益增加的資料數據並為人們建立新的價值。事實上很多職稱不是「資料科學家」的人現在都已經在做著資料科學：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;搜集、理解、分析、處理、視覺化資料數據並從中萃取有用的價值&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當年網際網路開始蓬勃發展，軟體工程師是最夯最潮的行業。儘管現在工程師的重要性並沒有下降，隨著人們的程式能力穩定上升，軟體工程師回歸平凡，甚至還有人戲稱為「碼農」、「程式猿」。&lt;/p&gt;
&lt;p&gt;歷史總是不斷重演。&lt;/p&gt;
&lt;p&gt;或許再過幾年，等人們的資料科學力上升到一定階段，資料科學變成呼吸喝水般的知識以後，資料科學家們也會被人戲稱為「資料農」。&lt;/p&gt;
&lt;p&gt;或許當你幾年後遇到我，我可能這樣回你：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;嘿！我就只是個資料農！你也是嗎？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category></entry><entry><title>為何資料科學家需要學習 SQL</title><link href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html" rel="alternate"></link><published>2018-04-30T23:50:00+09:00</published><updated>2018-04-30T23:50:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-30:/why-you-need-to-learn-sql-as-a-data-scientist.html</id><summary type="html">&lt;p&gt;這篇將簡單討論資料科學家必備的能力之一：結構化查詢語言（SQL）在概念上跟命令式程式語言如 Python 有什麼不同之處，以及在什麼樣的情況下我們會想要利用 SQL 做資料分析。這篇注重在為何你會想要使用 SQL 做資料分析，而非 SQL 本身功能的教學。如果要學習 SQL 本身，可以參考本文最後面的推薦閱讀。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇簡單討論&lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;結構化查詢語言（SQL）&lt;/a&gt;在概念上跟命令式程式語言如 Python 有什麼不同之處，以及在什麼樣的情況下我們會想要利用 SQL 做資料分析。&lt;/p&gt;
&lt;p&gt;這篇注重在為何你會想要使用 SQL 做資料分析，而非 SQL 本身功能的教學。如果要學習 SQL 本身，可以參考最後面的&lt;a href="#推薦閱讀"&gt;推薦閱讀&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用-SQL-與數據對話"&gt;使用 SQL 與數據對話&lt;a class="anchor-link" href="#使用-SQL-與數據對話"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;身為資料科學家或者是分析人員，我們都知道 SQL 基本上是必備的分析工具。&lt;/p&gt;
&lt;p&gt;簡單來說，&lt;a href="https://zh.wikipedia.org/wiki/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;SQL 是一種程式語言&lt;/a&gt;，我們可以透過它對被儲存在&lt;a href="https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93"&gt;關聯式資料庫&lt;/a&gt;裡頭的資料進行查詢或操作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;SQL 是資料科學家與資料庫（Database）溝通的語言&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在沒接觸過 SQL 之前，你可能會想&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「做為一個程式語言，為何 SQL &lt;a href="https://insights.stackoverflow.com/survey/2018/"&gt;有那麼多人在使用？&lt;/a&gt;」&lt;/li&gt;
&lt;li&gt;「我們有 Python、R，不學 SQL 應該也沒關係吧？」&lt;/li&gt;
&lt;li&gt;「又要學一個程式語言好麻煩。」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了釐清這些疑問，讓我們做一個假想實驗。比方說我們現在想要知道某個特定顧客過去的所有購買記錄。&lt;/p&gt;
&lt;p&gt;如果你熟悉 SQL 的話，可以對資料庫下一個簡單的查詢（Query）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;totalprice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt; 
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt; 
       &lt;span class="k"&gt;INNER&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt; 
       &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; 
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt; 
 &lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面這個查詢翻為白話就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從顧客清單 &lt;code&gt;customer&lt;/code&gt; 還有購賣紀錄 &lt;code&gt;orders&lt;/code&gt; 裡頭&lt;ul&gt;
&lt;li&gt;FROM customer AS c INNER JOIN orders AS o ON c.custkey = o.custkey&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;找出名為 Customer#000000001 的顧客的所有購買紀錄&lt;ul&gt;
&lt;li&gt;WHERE c.name = 'Customer#000000001'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;並把那些紀錄依照購買日期排序&lt;ul&gt;
&lt;li&gt;ORDER BY o.orderdate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最後只回傳顧客名稱、總購買金額、購買日期幾個項目&lt;ul&gt;
&lt;li&gt;SELECT c.name AS customer, o.totalprice, o.orderdate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這個查詢對第一次寫 SQL 的人可能會覺得很複雜，但注意，我們並沒有告訴資料庫「如何」取得這些資料，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;怎麼合併顧客跟購買紀錄？&lt;/li&gt;
&lt;li&gt;怎麼過濾特定顧客？&lt;/li&gt;
&lt;li&gt;怎麼排序？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們只告訴它該給我們「什麼資料」。而得到的結果是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;customer            | totalprice | orderdate
--------------------+------------+------------
 Customer#000000001 |  152411.41 | 1993-06-05
 Customer#000000001 |  165928.33 | 1995-10-29
 Customer#000000001 |  270087.44 | 1997-03-04
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如同我們預期，只有該顧客的購買紀錄被回傳，且依照購買日期 &lt;code&gt;orderdate&lt;/code&gt; 從早排到晚。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，資料庫可能需要做以下運算來取得資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將顧客表格 &lt;code&gt;customer&lt;/code&gt; 以及購買紀錄的表格 &lt;code&gt;orders&lt;/code&gt; 分別命名為 &lt;code&gt;c&lt;/code&gt; 及 &lt;code&gt;o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;依照共通的鍵值 &lt;code&gt;custkey&lt;/code&gt; 合併（&lt;code&gt;JOIN&lt;/code&gt;）兩表格&lt;/li&gt;
&lt;li&gt;找出特定顧客 &lt;code&gt;Customer#000000001&lt;/code&gt; 的購買記錄&lt;/li&gt;
&lt;li&gt;將該紀錄依照購買日期 &lt;code&gt;orderdate&lt;/code&gt; 排序&lt;/li&gt;
&lt;li&gt;選出要顯示的欄位 &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些運算最後都得依照「某個」順序執行，但是我們不需要考慮這些事情，完全依靠資料庫的&lt;a href="http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf"&gt;查詢最佳化器（Query Optimizer）&lt;/a&gt;來幫我們決定。&lt;/p&gt;
&lt;p&gt;寫 SQL 敘述時，你可以理解成我們是指定「要的資料」，而查詢最佳化器會依照此需求，找出一個最佳路徑來取得必要的資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/sql/yoal-desurmont-619654-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/pcLLI0MTDNg?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;&lt;/a&gt;
    SQL 查詢
    &lt;font color="purple"&gt;: &lt;/font&gt;專注在你的目標，查詢最佳化器會負責找到達成目標的最佳路徑
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;換句話說，當我們在寫 SQL 的時候，是在進行&lt;a href="https://zh.wikipedia.org/wiki/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;宣告式程式設計（Declarative Programming）&lt;/a&gt;：我們只告訴資料庫，我們想要什麼資料（What），而不是怎麼取得（How）它們。&lt;/p&gt;
&lt;p&gt;這跟一般常見的&lt;a href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;命令式程式語言（Imperative Programming）&lt;/a&gt;如 Python、Java 有所不同。在寫 SQL 時，我們告訴資料庫它該達成的目標 - 取得什麼資料（What）；在寫 Python 時，我們得告訴程式該怎麼達成該目標（How）。&lt;/p&gt;
&lt;p&gt;為了進一步闡述這個概念，接著讓我們試著使用 Python 來取得跟上面的 SQL 查詢一樣的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用-Python-達到-SQL-查詢效果"&gt;用 Python 達到 SQL 查詢效果&lt;a class="anchor-link" href="#用-Python-達到-SQL-查詢效果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先先假設所有顧客資料是透過一個 &lt;code&gt;list&lt;/code&gt; 儲存，裡頭包含多個 &lt;code&gt;dict&lt;/code&gt;。每個 &lt;code&gt;dict&lt;/code&gt; 則代表一個顧客的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Customer#000000001"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custkey"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Customer#000000002"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custkey"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"2"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而購買記錄則是一個 &lt;code&gt;dict&lt;/code&gt;，&lt;code&gt;dict&lt;/code&gt; 的鍵值為所有顧客的 &lt;code&gt;custkey&lt;/code&gt;；鍵值對應的值則是包含該顧客所有購買紀錄的 &lt;code&gt;list&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;"1"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;152411.41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1993-06-05"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;270087.44&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1997-03-04"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;165928.33&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1995-10-29"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
         &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以 &lt;code&gt;orders["1"]&lt;/code&gt; 就代表 &lt;code&gt;custkey = 1&lt;/code&gt; 的顧客的購買紀錄。&lt;/p&gt;
&lt;p&gt;了解背後的資料結構以後，我們可以寫一段 Python 程式碼來取得資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"customer           | totalprice| orderdate "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"------------------ | ----------| --------- "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 從所有顧客找符合條件的人&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# 跳過我們沒興趣的顧客&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'name'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;continue&lt;/span&gt;
    &lt;span class="c1"&gt;# 利用 custkey 取德該顧客的購買紀錄&lt;/span&gt;
    &lt;span class="n"&gt;c_orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'custkey'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 依照 orderdate 排序購買紀錄&lt;/span&gt;
    &lt;span class="n"&gt;c_orders_sorted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_orders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'orderdate'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將所有排序後的記錄回傳&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;c_orders_sorted&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'name'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'totalprice'&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'orderdate'&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" | "&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 已經找到該顧客，提早結束迴圈以減少處理時間&lt;/span&gt;
    &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;customer           | totalprice| orderdate 
------------------ | ----------| --------- 
Customer#000000001 | 152411.41 | 1993-06-05
Customer#000000001 | 165928.33 | 1995-10-29
Customer#000000001 | 270087.44 | 1997-03-04
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以我們使用 Python 達到跟上面的 SQL 查詢一樣的結果了。但兩者在執行上有什麼差異？&lt;/p&gt;
&lt;p&gt;使用命令式程式語言來處理資料時，我們需要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解資料結構以操作資料（顧客是存在 &lt;code&gt;list&lt;/code&gt; 還是 &lt;code&gt;dict&lt;/code&gt; ？）&lt;/li&gt;
&lt;li&gt;明確地定義執行步驟（先排序購買記錄 &lt;code&gt;orders&lt;/code&gt; 還是先把顧客 &lt;code&gt;customers&lt;/code&gt; 跟購買紀錄合併？）&lt;/li&gt;
&lt;li&gt;最佳化（如最後的 &lt;code&gt;break&lt;/code&gt; ）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再看一次先前的 SQL 查詢（+註解）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;-- 給我以下幾個欄位：顧客名稱、總購買金額、購買日期&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;totalprice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;
&lt;span class="c1"&gt;-- 將有相同 custkey 的顧客跟購買紀錄合併&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;
       &lt;span class="k"&gt;INNER&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;
       &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt;
&lt;span class="c1"&gt;-- 只需要此顧客的購買紀錄&lt;/span&gt;
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt;
&lt;span class="c1"&gt;-- 依照購買日期排序&lt;/span&gt;
 &lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這裡頭我們不需要了解資料被以什麼形式儲存，也不需要定義要以什麼順序執行查詢，更不用做最佳化。這些事情全部交給背後的資料庫處理，使得資料科學家可以專注在更高層次的問題：「我們需要什麼資料？」&lt;/p&gt;
&lt;p&gt;而這正是 SQL 最強大的地方：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;SQL 讓資料科學家可以專注在需要「什麼」資料而非要「怎麼」取得。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們這篇只舉了一個十分簡單的例子，但一般來說 SQL 非常適合以下的使用情境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將多個資料來源（例：表格）合併起來並依照一些條件篩選結果&lt;/li&gt;
&lt;li&gt;依照取得的資料做一些簡易的 aggregation （如：加總、平均、最大值）&lt;/li&gt;
&lt;li&gt;簡單的資料轉換（例：把 datetime 欄位取出年份）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果需要十分複雜的資料轉換或者計算時，一般我還是推薦使用 Python 或 R。但是下次當你有機會使用 SQL 取得想要的資料時，不妨試著專注在「想要什麼資料」而不是「怎麼取得資料」。說不定一個 SQL 查詢就能幫你省下一些花在搜集資料的時間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="推薦閱讀"&gt;推薦閱讀&lt;a class="anchor-link" href="#推薦閱讀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/intro-to-sql-for-data-science"&gt;DataCamp - Intro to SQL for Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/joining-data-in-postgresql"&gt;DataCamp - Joining Data in PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/learning/advanced-sql-for-data-scientists"&gt;LinkedIn Learning - Advanced SQL for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="SQL"></category><category term="data-science"></category></entry><entry><title>資料科學家為何需要了解資料工程</title><link href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html" rel="alternate"></link><published>2018-04-23T22:55:00+09:00</published><updated>2018-04-23T22:55:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-23:/why-you-need-to-learn-data-engineering-as-a-data-scientist.html</id><summary type="html">&lt;p&gt;透過描述資料科學家的一天日常，本文將簡單介紹資料工程（Data Engineering）的概念、其如何跟資料科學相關。以及最重要的，作為一個資料科學家應該如何學習並善用這些知識來創造最大價值。身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過描述資料科學家的一天日常，本文將簡單介紹資料工程（Data Engineering）的概念、其如何跟資料科學相關。以及最重要的，作為一個資料科學家（Data Scientist）應該如何學習並善用這些知識來創造最大價值。&lt;/p&gt;
&lt;p&gt;身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料科學家的一天"&gt;資料科學家的一天&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料準備"&gt;資料準備&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#第一挑戰：資料量大增"&gt;第一挑戰：資料量大增&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#第二挑戰：非結構化資料"&gt;第二挑戰：非結構化資料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料為本"&gt;資料為本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料管道"&gt;資料管道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料倉儲"&gt;資料倉儲&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料湖"&gt;資料湖&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何實際應用資料工程？"&gt;如何實際應用資料工程？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料科學家的一天"&gt;資料科學家的一天&lt;a class="anchor-link" href="#資料科學家的一天"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;一說到資料科學，在你腦海中浮現的幾個關鍵字可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料分析&lt;/li&gt;
&lt;li&gt;資料視覺化&lt;/li&gt;
&lt;li&gt;A.I. / 機器學習&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等為人津津樂道的面向。&lt;/p&gt;
&lt;p&gt;的確，這些都在資料科學的範疇裡頭，但實際上佔用多數資料科學家大部分時間，卻常被忽略的部分是資料準備：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/data-scientist-work-pie-chart.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#5d0184f76f63" target="_blank"&gt;Forbes&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;依據調查，多數資料科學家花 80 % 的時候在準備資料
    &lt;br/&gt;
&lt;/center&gt;&lt;h3 id="資料準備"&gt;資料準備&lt;a class="anchor-link" href="#資料準備"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;說到資料準備，你可能會聯想到我們在前一篇&lt;a href="data-visualization-from-matplotlib-to-ggplot2.html#載入資料-+-簡單資料處理"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;裡頭，使用 R 語言做的簡單資料清理：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 將 CSV 檔案載入成資料框架（dataframe）&lt;/span&gt;
ramen_all &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"datasets//ramen-ratings.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 將「星星數」轉成定量資料&lt;/span&gt;
ramen_all&lt;span class="o"&gt;$&lt;/span&gt;Stars &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="o"&gt;$&lt;/span&gt;Stars&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="c1"&gt;# Subset 資料&lt;/span&gt;
ramen &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ramen_all &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  filter&lt;span class="p"&gt;(&lt;/span&gt;Country &lt;span class="o"&gt;%in%&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="p"&gt;,&lt;/span&gt; Country&lt;span class="p"&gt;,&lt;/span&gt; sort &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; drop&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  filter&lt;span class="p"&gt;(&lt;/span&gt;Style &lt;span class="o"&gt;%in%&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="p"&gt;,&lt;/span&gt; Style&lt;span class="p"&gt;,&lt;/span&gt; sort &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; drop&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在做分析之前，我們做了以下的步驟來準備資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;讀進&lt;code&gt;ramen-ratings.csv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;轉變某些欄位的資料型態&lt;/li&gt;
&lt;li&gt;依照一些條件取出想要分析的資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然資料量不大，你仍然可以試著想像我們實際上建立了一個 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將資料從來源（硬碟）擷取出來（&lt;strong&gt;E&lt;/strong&gt;xtract）&lt;/li&gt;
&lt;li&gt;做了一些轉換（&lt;strong&gt;T&lt;/strong&gt;ransform）&lt;/li&gt;
&lt;li&gt;載入（&lt;strong&gt;L&lt;/strong&gt;oad）目的地（記憶體）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;假設我們把一般的資料分析專案分為以下兩階段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;資料準備：將資料轉換成適合分析的格式&lt;/li&gt;
&lt;li&gt;資料分析：探索資料、建構預測模型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上面的 ETL 就屬於第一個步驟。又因為此資料集大概只包含 5,000 筆資料，步驟 1 所花的時間跟步驟 2 的所需時間相比，可以說微乎其微，它不會是你做資料科學的一個 bottleneck。&lt;/p&gt;
&lt;p&gt;但如果你要處理的資料量是這個的 1,000 倍大呢？你還能馬上進入分析階段嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第一挑戰：資料量大增"&gt;第一挑戰：資料量大增&lt;a class="anchor-link" href="#第一挑戰：資料量大增"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;實際上一個資料科學家每天需要分析的資料量可能要乘上幾個級數。現在假設你從銷售部門拿到一個包含數百萬筆銷售紀錄，大小為 60G 的 CSV 檔案，我想你應該不會想要直接打開它，即使它在某些人眼裡還不夠資格稱為大數據 (&amp;acute;；&amp;omega;；｀)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你殫精竭慮，最後決定去問公司內一位資深的&lt;a href="https://medium.freecodecamp.org/the-rise-of-the-data-engineer-91be18f1e603"&gt;資料工程師（Data Engineer）&lt;/a&gt;該怎麼解決這問題。&lt;/p&gt;
&lt;p&gt;該仁兄施了點你不曉得的魔法，過了幾分鐘從 Slack 丟來個神秘的 URL。連到上面，你發現熟悉的 &lt;a href="http://jupyter.org/"&gt;Jupyter Nook&lt;/a&gt; 介面，而且 CSV 還幫你載好了 &amp;Sigma;(ﾟдﾟ;&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/jupyter-notebook.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.ithome.com.tw/news/121497" target="_blank"&gt;Bonus&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;Jupyter Lab 是 Jupyter Notebook 的改善版，大推
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;你開心地在資料工程師幫你搞定的機器上做出分析，最後在大家面前做口頭報告。大家針對報告的反應不錯，但坐在底下的廣告部門的人這時候提問了：&lt;/p&gt;
&lt;p&gt;「可以把這些銷售紀錄跟廣告點擊的串流日誌（log）合在一起分析嗎？這樣我們會有更多有趣的結果！」&lt;/p&gt;
&lt;p&gt;你的頭又痛了起來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第二挑戰：非結構化資料"&gt;第二挑戰：非結構化資料&lt;a class="anchor-link" href="#第二挑戰：非結構化資料"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;除了資料量級的差異，一個資料科學家在企業裡頭會遇到的另外一個挑戰是非結構化資料（Unstructured Data）的快速增加。你如何將各種不同格式（JSON、存取日誌、CSV 等）的資料以有效率的方式跟平常熟悉的關聯式資料庫如 &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; 裡頭的資料結合以供分析？&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/increasing-dark-data.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.slideshare.net/AmazonWebServices/how-to-build-a-data-lake-with-aws-glue-data-catalog-abd213r" target="_blank"&gt;AWS Reinvent&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;非結構化資料快速增加，但因為不存在關聯式資料庫裡，無法直接被拿來分析
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果我們能寫一個簡單的 &lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;SQL&lt;/a&gt; 查詢，把銷售資料（sales）跟廣告點擊（clicks）資料依照共有的鍵值 &lt;code&gt;sale_id&lt;/code&gt; 合起來該有多好：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT *
FROM sales AS s
INNER JOIN clicks AS c
ON s.sale_id = c.sale_id&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你想著想著就到下班時間了。&lt;/p&gt;
&lt;p&gt;「算了，還是先回家睡個覺，明天再厚著臉皮問資料工程師吧！反正之前他也幫我在&lt;a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2"&gt;資料倉儲（Data Warehouse）&lt;/a&gt;加了新的表格。」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料為本_1"&gt;資料為本&lt;a class="anchor-link" href="#資料為本"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從上面這個資料科學家的一天，我們得到什麼啟示？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料（的基礎設施）為資料科學之基礎 - 巧婦難為無米之炊&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;老實說這個例子裡頭的資料科學家已經非常幸運：公司裡有資料工程師能幫他把大量、複雜格式的資料做 ETL 並以資料倉儲中的一個新表格（Table）的方式呈現轉換過後的資料以供他使用。硬要說稍微不方便的地方，頂多就是該資料科學家得等資料工程師搞定好資料就是了。&lt;/p&gt;
&lt;p&gt;然而因為資料工程師是一個很新的職位，多數的企業現在並沒有這樣的人存在。大多數的資料科學家只能自己下海，想辦法生出可以用的資料。實際上，&lt;a href="https://hackernoon.com/@mrogati?source=post_header_lockup"&gt;Monica Rogati&lt;/a&gt; 在 &lt;a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007"&gt;The AI Hierarchy of Needs&lt;/a&gt; 提到，一些常見的資料科學專案像是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建置 AI &lt;/li&gt;
&lt;li&gt;建置簡單的機器學習模型&lt;/li&gt;
&lt;li&gt;資料分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都得建立在「有完善且可靠的資料」這個基礎之下：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/ai-need.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007" target="_blank"&gt;資料科學的金字塔層級要求&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;你需要建立好資料科學的基礎設施才有本錢往「上」發展
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以金字塔最下三層為例，要讓資料科學的專案順利進行，你最少要（由下而上）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;持續搜集（COLLECT）原始資料&lt;/li&gt;
&lt;li&gt;將該資料轉移（MOVE / STORE）到適合分析的地方如資料倉儲、&lt;a href="https://itw01.com/G4DCESL.html"&gt;資料湖&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;轉換（TRANSFORM）被轉移的資料，進行前處理以方便分析&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我認爲資料工程的重頭戲在上面的 2, 3 點：將資料以「轉換好」的形式「送」到可供分析的地方。（當然也可以先送再轉換，或者不轉換，詳見下面章節的&lt;a href="#資料湖"&gt;資料湖&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;身為資料科學家，如果你夠幸運，公司內部有專業的資料工程師幫你把上面這件事情做好，恭喜！你可以多專注在分析以及建置預測模型上面；
但假設公司裡頭只有資料科學家，而企業又想要處理大數據的話，抱歉，你得擔起這個攤子，想辦法把資料的基本設施搞定：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;每個成功的資料科學家背後都有個偉大的資料工程師。或者該資料科學家就是那個資料工程師。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為資料科學家，如果我們也能了解資料工程相關的知識的話，不就能更快地、更有效率地進行資料分析了嗎？&lt;/p&gt;
&lt;p&gt;這個想法即是所謂的&lt;a href="http://www.effectiveengineer.com/blog/master-adjacent-disciplines"&gt;從鄰近專業（Adjacent Disciplines）學習&lt;/a&gt;：透過學習跟本業息息相關的資料工程，資料科學家可以加速資料科學的專案進行，並為個人以及團隊創造更大價值。想閱讀更多，可以看看&lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7"&gt;在 Airbnb 工作的資料科學家怎麼說&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;接著讓我們稍微聊聊到底什麼是資料工程以及一些相關例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料管道"&gt;資料管道&lt;a class="anchor-link" href="#資料管道"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;依照前面的論述，資料工程最主要的目的就是建構資料科學的基本設施（Infrastructure）。而這些基礎設施裡頭一個很重要的部分是&lt;a href="https://www.alooma.com/answers/what-is-the-difference-between-a-data-pipeline-and-an-etl-pipeline"&gt;資料管道（Data Pipeline）&lt;/a&gt;的建置：將資料從來源 &lt;strong&gt;S&lt;/strong&gt;ource 導向目的地 
&lt;strong&gt;T&lt;/strong&gt;arget 以供之後的利用。有必要的話，對資料進行一些轉換。&lt;/p&gt;
&lt;p&gt;一些簡單的例子像是我們之前部落格提到的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html"&gt;將 NoSQL（MongoDB） 資料導向資料倉儲（Redshift）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="use-kinesis-streams-and-firehose-to-build-a-data-lake.html"&gt;將串流資料（Kinesis）導向資料湖（AWS S3）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從上面的例子也可以看到，實際上資料管道是一個涵蓋範圍很廣的詞彙，包含&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;即時的串流資料處理&lt;/li&gt;
&lt;li&gt;Batch 處理（如：每 12 小時作一次）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ETL 做的事情跟資料管道類似，但偏重在 Batch 處理，這篇文章將 ETL 視為資料管道裡頭的一個子集。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/etl-flow.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://robinhood.engineering/why-robinhood-uses-airflow-aed13a9a90c8" target="_blank"&gt;ETL&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;從資料來源擷取、轉換資料並將其導入目的地
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料的來源或目的地可以是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分散式檔案儲存系統（如 &lt;a href="https://zh.wikipedia.org/wiki/Apache_Hadoop"&gt;HDFS&lt;/a&gt;、&lt;a href="https://aws.amazon.com/tw/s3/"&gt;AWS S3&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;一般的資料庫 / 資料倉儲（如 &lt;a href="https://aws.amazon.com/tw/redshift/getting-started/"&gt;AWS Redshift&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ETL 最重要的是轉換步驟，一些常見的轉換包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;改變欄位名稱&lt;/li&gt;
&lt;li&gt;去除空值（Missing Value）&lt;/li&gt;
&lt;li&gt;套用商業邏輯，事先做資料整合（Aggregate）&lt;/li&gt;
&lt;li&gt;轉變資料格式（例：從 JSON 到適合資料倉儲的格式如 &lt;a href="https://parquet.apache.org/"&gt;Parquet&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/man-on-data-pipeline.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/xNdPWGJ6UCQ?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料工程師&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;建構資料管道以讓大量的資料可供分析
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這些轉換都是為了讓之後使用資料的資料科學家們能更輕鬆地分析資料。為了建置可靠的資料管道 / ETL 流程，我們常會需要使用一些管理工具像是 &lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt;、 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 以確保資料的處理如同我們預期。&lt;/p&gt;
&lt;h3 id="一些關鍵技術"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Hadoop 生態環境&lt;/li&gt;
&lt;li&gt;分散式系統上的 ETL 設計&lt;/li&gt;
&lt;li&gt;SQL-on-Hadoop 的專案了解（如 Apache Hive, Spark SQL, Fackbook Presto）&lt;/li&gt;
&lt;li&gt;資料流程管理（如 Airflow、AWS Glue）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;那經過資料管道處理後的資料要怎麼存取/分析？依照存取方式的不同，資料管道的架構方式也會有所不同。&lt;/p&gt;
&lt;p&gt;而存取資料的方式大概可以分為兩種：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7"&gt;資料倉儲（Data Warehousing）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://itw01.com/G4DCESL.html"&gt;資料湖（Data Lake）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料倉儲_1"&gt;資料倉儲&lt;a class="anchor-link" href="#資料倉儲"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料倉儲的概念就跟實際的倉儲相同：你在這邊將原料（原始資料）轉化成可以消化的產品（資料庫裡頭的經過整理的一筆筆紀錄）並存起來方便之後分析。&lt;/p&gt;
&lt;p&gt;這邊最重要的概念是：為了方便商業智慧的萃取，在將資料放入資料倉儲前，資料科學家 / 資料工程師需要花很多的心力決定資料庫綱目（Database Schema）要長什麼樣子。
也就是說資料庫的綱要（Schema）在建立資料管道的時候就已經被決定了：這種模式稱之為 Schema-on-Write。這是為了確保資料在被放進資料倉儲的時候就已經是可以分析的形式，方便資料科學家分析。&lt;/p&gt;
&lt;p&gt;你可以想像資料工程師在建構資料管道 / ETL 的時候，得對原始資料做大量的轉換以讓資料在被&lt;strong&gt;寫&lt;/strong&gt;入資料倉儲時就已經符合一開始定義的 Schema。而資料倉儲最常被拿來使用的一個資料模型（Data Model）是所謂的 &lt;a href="https://en.wikipedia.org/wiki/Dimensional_modeling"&gt;Dimensional Modeling&lt;/a&gt;（Stars / Snowflaks Schema）。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/star-schema.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="http://publib.boulder.ibm.com/tividd/td/TEDW/SC32-1497-00/en_US/HTML/srfmst158.htm" target="_blank"&gt;資料倉儲最被廣泛使用的 Data Model&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;Stars Schema
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;資料工程師將企業最重要的事件（如：使用者下了訂單、發了一個 Facebook 動態）放到最中間的 Fact Table，並且為了可以使用所有想像得到的維度來分析這些事件，會把事件本身的維度（Dimensions）再分別存在外圍的多個 Dimension Tables。常見的維度有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;時間（此事件什麼時候產生、年月份、星期幾等）&lt;/li&gt;
&lt;li&gt;商品的製造商的資料、其他細節&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為看起來就像是一個星星，因此被命名為 Stars Schema。Snowflakes 則是其變形。&lt;/p&gt;
&lt;h3 id="一些關鍵技術_1"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;在資料倉儲的部分，關鍵的技術與概念有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解正規化（Normalization）的好處&lt;/li&gt;
&lt;li&gt;分散式 SQL 查詢引擎的原理（如 &lt;a href="https://prestodb.io/"&gt;Presto&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;分析專用的資料模型的設計原理（如 Stars / Snowflakes schema）&lt;/li&gt;
&lt;li&gt;了解分散式系統背後各種 JOIN 的原理（Sort-Merge JOINs、Broadcast Hash JOINs、Paritioned Hash JOINs 等）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料湖_1"&gt;資料湖&lt;a class="anchor-link" href="#資料湖"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;「每天新增的資料量太多，要把所有想分析的資料都做詳細的 Schema 轉換再存入資料倉儲太花人力成本。總之先把這些資料原封不動地存到分散式檔案儲存系統上，之後利用如 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 等服務將資料的 schema 爬出來並分析。」這就是以資料湖為核心的資料管道架構想法。一般這種存取資料的方式我們稱之為 Schema-on-Read，因為 Schema 是在實際載入原始資料的時候才被使用。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/tw/athena/"&gt;AWS Athena&lt;/a&gt; 就是一個 AWS 依照這樣的想法打造的服務。&lt;/p&gt;
&lt;p&gt;舉個簡單的例子，假設我們現在想把&lt;a href="#資料科學家的一天"&gt;資料科學家的一天&lt;/a&gt;提到的銷售資料以及廣告資料合併起來做分析，在 AWS 上我們可以實作一個這樣的資料管道：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/data-lake-example.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    利用 AWS Athena 及 AWS Glue 實作以資料湖為基礎的分析架構
    &lt;font color="purple"&gt;: &lt;/font&gt;即時合併並分析不同格式的資料
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;我們將存在關聯式資料庫的銷售資料透過 ETL 存到資料湖（AWS S3）裡頭以後，利用 AWS Glue 將資料的中繼資料（Meta Data）存在資料目錄（Data Catalogue）底頭。常見的中繼資料有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表格定義（有哪些欄位，如：&lt;code&gt;sale_id&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;各個欄位的資料型態&lt;/li&gt;
&lt;li&gt;各個欄位實際在原始資料（如 CSV ）裡頭的排列順序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接著我們就可以利用提到的 SQL 查詢把銷售資料跟廣告資料合併：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT *
FROM sales AS s
INNER JOIN clicks AS c
ON s.sale_id = c.sale_id&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;收到以上的 SQL 查詢，Athena 會分別把銷售資料以及廣告資料依照對應的資料目錄解析資料後合併再回傳結果給我們。&lt;/p&gt;
&lt;p&gt;我認為今後這種以資料湖為基礎的分析架構會越來越熱門，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非結構化資料量越來越大，花費人力在事前為資料倉儲建立完整的 schema 越來越不實際&lt;/li&gt;
&lt;li&gt;分散式 SQL 查詢服務像是 Athena 抽象化複雜的資料格式，允許資料科學家下 SQL 查詢做 ad-hoc 分析&lt;/li&gt;
&lt;li&gt;透過 Parquet / ORC 等資料格式來自動減少資料湖沒有做正規化而導致的效能損失&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="一些關鍵技術_2"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;雖然再過幾年，等到資料工程的人才增加，資料科學家或許可以完全不用介意背後的資料基礎設施的建置，但近幾年這部分可能還是要靠資料科學家自己實作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料湖的概念&lt;/li&gt;
&lt;li&gt;AWS Glue + AWS Athena 的運用（Bonus: Serverless 分析架構，不需管理機器）&lt;/li&gt;
&lt;li&gt;Hive MetaData Store&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在資料湖的例子我主要都用 AWS 的服務來舉例，但你可以自由使用其他雲端服務或者 Hadoop。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何實際應用資料工程？_1"&gt;如何實際應用資料工程？&lt;a class="anchor-link" href="#如何實際應用資料工程？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;首先你得先了解目前環境的資料基礎設施。而為了釐清這點，你可以問自己或者相關人員以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學的金字塔，我們建到哪一層了？&lt;/li&gt;
&lt;li&gt;我們過去有哪些專案是在取得、準備資料階段就陷入瓶頸？&lt;/li&gt;
&lt;li&gt;我們有專業的資料工程師或相關人員在做資料倉儲或者是資料湖的準備嗎？&lt;/li&gt;
&lt;li&gt;我們的資料是儲存在什麼分散式檔案儲存系統上面？ HDFS 還是 S3？&lt;/li&gt;
&lt;li&gt;我們是怎麼管理/監管 ETL 工作的？ 要考慮用 Airflow 嗎？&lt;/li&gt;
&lt;li&gt;要建構一個新的資料管道的話，要自己架 Hadoop 群集還是使用雲端服務？&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在你思考過以上幾個問題以後，你就會發現為何過往有些資料科學的專案進展緩慢了。這時候與其一直在等待資料的到來，你可以把你想到的幾個問題拿去跟相關的工程師討論。相信我，從你開口跟他們討論如何解決資料基礎設施的瓶頸這點開始，他們將不再視你為「那個只想要拿到資料」的敵人，而是同伴。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/hadoop-framework.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://medium.com/@ssola/becoming-a-data-engineer-5e0f14048d42" target="_blank"&gt;Hadoop 的分散式基礎設施&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;要學的東西太多，不如就用雲端服務吧
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;假如很不幸，你們公司沒有專業的工程師，而你得自己想辦法兜出一個可以處理這些大量資料的方法，我會建議先從現存的全受管（Full-Managed）雲端服務找能解決痛點的方案。&lt;/p&gt;
&lt;p&gt;使用現成的雲端服務來建置資料基礎有幾個好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pay-as-you-go，通常是用多少花多少&lt;/li&gt;
&lt;li&gt;Proof-of-concept，你可以直接開始嘗試建立最重要的商業邏輯而非架機器&lt;/li&gt;
&lt;li&gt;Serverless 架構，不需管理機器（如 AWS Glue + Athena）&lt;/li&gt;
&lt;li&gt;導入成本降低（相較於自己架 Hadoop Cluster）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我嘗試在這篇文章說明資料工程對資料科學家的重要，以及你可以如何開始學習資料工程。&lt;/p&gt;
&lt;p&gt;在這個大數據時代，資料科學家的價值在於找出「大量」資料背後的潛在價值，不要反而讓「資料量太多」這邊成了你最大的限制。
從雲端服務開始，多學一點資料工程，讓你的資料科學專案前進地更快吧！&lt;/p&gt;
&lt;p&gt;如果你有任何想法想要提出或分享，都歡迎在底下留言或者透過社群網站聯絡我 B-)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="資料工程"></category><category term="data-science"></category><category term="data engineering"></category></entry><entry><title>淺談資料視覺化以及 ggplot2 實踐</title><link href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html" rel="alternate"></link><published>2018-04-14T15:10:00+09:00</published><updated>2018-04-14T15:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-14:/data-visualization-from-matplotlib-to-ggplot2.html</id><summary type="html">&lt;p&gt;這篇主要描述自己以往在利用 Python 做資料視覺化時常犯的思維瑕疵，而該思維如何在接觸 R 的 ggplot2 以後得到改善。本文會試著說明資料視覺化的本質為何，以及在設計視覺化時，概念上應該包含什麼要素以及步驟。最後展示如何透過 ggplot2 活用前述的概念，來實際做資料視覺化。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇主要描述自己以往在利用 Python 做資料視覺化 (data visualization) 時常犯的思維瑕疵，而該思維如何在接觸 R 的 &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt; 以後得到改善。&lt;/p&gt;
&lt;p&gt;本文會試著說明資料視覺化的本質為何，以及在設計視覺化時，概念上應該包含什麼要素以及步驟。最後展示如何透過 ggplot2 活用前述的概念，來實際做資料視覺化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文章內容大致上會分為以下幾個小節：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料視覺化應該是-.."&gt;資料視覺化應該是 ..&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ggplot2-實踐"&gt;ggplot2 實踐&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#References"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;a class="anchor-link" href="#資料視覺化是資料與圖的直接映射？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為一個 Python 起家的資料科學家，在做資料視覺化的時候，我很自然地使用 Python ecosystem 裡像是 &lt;a href="https://matplotlib.org/"&gt;matplotlib&lt;/a&gt; 以及 &lt;a href="https://seaborn.pydata.org/"&gt;seaborn&lt;/a&gt; 等繪圖 packages。針對手中的資料，我會想辦法找到一個「對應」的圖然後把資料塞進去。簡單無腦 &lt;em&gt;(:3 」&amp;ang;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;舉例來說，當我們手上有三個變數 x, y, z 且其各自的資料型態為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x: &lt;a href="https://zh.wikibooks.org/zh-hant/%E7%B5%B1%E8%A8%88%E5%AD%B8/%E7%B5%B1%E8%A8%88%E8%B3%87%E6%96%99"&gt;定量變數 (quantitative)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;y: 定量變數&lt;/li&gt;
&lt;li&gt;z: &lt;a href="https://zh.wikibooks.org/zh-hant/%E7%B5%B1%E8%A8%88%E5%AD%B8/%E7%B5%B1%E8%A8%88%E8%B3%87%E6%96%99"&gt;定性變數（categorical）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;則我們想要進行資料視覺化的時候有幾種選擇：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想分析 x, y -&amp;gt; 都是定量資料 -&amp;gt; 散佈圖 (scatter plot)&lt;/li&gt;
&lt;li&gt;想分析 x, z -&amp;gt; 一定量一定性 -&amp;gt; 長條圖 (bar chart)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這，「資料視覺化」的定義是一種映射關係 (mapping)：也就是如何將資料直接對應到某個「特定」圖表形式（折線圖、散佈圖 etc.）。基本上這種映射關係在做簡單的分析的時候沒有什麼問題，但是當想要同時分析/呈現的變數超過兩個 （例： x &amp;amp; y &amp;amp; z ）的時候就不容易找到適合的圖。一個折衷的方法是我們把變數兩兩畫圖做比較，但這樣會侷限我們能分析的資料維度數目，錯過一些有趣的洞見。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料視覺化應該是-.."&gt;資料視覺化應該是 ..&lt;a class="anchor-link" href="#資料視覺化應該是-.."&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="先確認觀眾及目的"&gt;先確認觀眾及目的&lt;a class="anchor-link" href="#先確認觀眾及目的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在完成一些 &lt;a href="#References"&gt;ggplot2 的 tutorials&lt;/a&gt; 後，可以發現資料視覺化一般依用途可以分為兩種：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;探索、了解資料特性&lt;/li&gt;
&lt;li&gt;說故事：將探索過後得到的洞見 (insight) 傳達給其他人&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/data-vis-purpose.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;搞清楚資料視覺化的目的以及觀眾是重要的第一步
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照目的以及觀眾的不同，資料視覺化的方式會有所不同。一個常見的例子是當我們第一次接觸某個資料集。這時候資料視覺化的觀眾是自己，目的是在最短的時間了解資料特性。則這時我們在做圖的時候的要求就可以很寬鬆，像是不加上標題，或是只要能做出自己能理解的視覺化即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="正式定義"&gt;正式定義&lt;a class="anchor-link" href="#正式定義"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在確認觀眾及目的以後，我們終於可以開始進行資料視覺化了！資料視覺化的定義因人而異，而這邊我想給出一個非常直觀的定義：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料視覺化是將資料中的變數映射到視覺變數上，進而有效且有意義地呈現資料的樣貌&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一些常見且肉眼容易識別的視覺變數 / 刻度（visual variables / scales）包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;位置（x / y axis）&lt;/li&gt;
&lt;li&gt;顏色（color）&lt;/li&gt;
&lt;li&gt;大小（size）&lt;/li&gt;
&lt;li&gt;透明程度（alpha）&lt;/li&gt;
&lt;li&gt;填滿（fill）&lt;/li&gt;
&lt;li&gt;形狀（shape）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用更口語的方式來解釋：在做資料視覺化的時候，我們希望能將&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;肉眼難以分析的資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;對應到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;肉眼容易解讀的視覺元素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這個映射關係，我們可以將原本的變數的數值變化也映射到視覺變數的變化。而因為我們人類容易區別視覺變數的變化（位置差異、大小長度變化 etc），我們能更容易地理解原始資料的樣貌、變化以及模式。&lt;/p&gt;
&lt;p&gt;舉例來說，我們可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把不同捷運路線（文湖線、板南線）對應到不同顏色&lt;/li&gt;
&lt;li&gt;把各國的 GDP 對應到點的大小&lt;/li&gt;
&lt;li&gt;把某個資料的年份對應到 Ｘ 軸，越右邊代表越接近現代&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="一個簡單例子"&gt;一個簡單例子&lt;a class="anchor-link" href="#一個簡單例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，我們可能平常每天都在做資料視覺化而不自知。比方說我們有一個數列 &lt;code&gt;y&lt;/code&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.055&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.132&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.522&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.229&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.013&lt;/span&gt; &lt;span class="o"&gt;..&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;光是看這個數字，肉眼無法看出什麼模式，但我們可以簡單畫個圖：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/simple-visual-encoding.png" style="width:70%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們利用視覺變數「Y軸位置」來呈現數值的變化，可以馬上看出數列裡頭的值都落在 -3 到 3 之間，而這是因為我們肉眼很容易辨別「位置」這個視覺變數的變化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="圖像的分層文法"&gt;圖像的分層文法&lt;a class="anchor-link" href="#圖像的分層文法"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 &lt;a href="http://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf"&gt;A Layered Grammar of Graphics&lt;/a&gt; 裡頭，&lt;a href="http://hadley.nz/"&gt;Hadley Wickham&lt;/a&gt; 闡述所謂的圖像（包含由資料視覺化產生的圖像）實際上如同我們平常使用的語言，是有文法的。而其文法可以拆成 7 個部分（層）。前述的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始資料 = 資料層（Data）&lt;/li&gt;
&lt;li&gt;視覺變數層（Visual variables = Aesthetics）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;則恰好是這個架構裡頭最底下的兩層。視覺變數是我為了方便理解建立的名詞，在原文以及 ggplot2 裡頭被稱作 &lt;strong&gt;Aesthetics&lt;/strong&gt;。（中文翻作「美學」，當初看好久也無法理解啊 (╯&amp;deg;Д&amp;deg;)╯ ┻━┻）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/layered-grammar-of-graphics.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;圖像的分層文法
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;看到這你一定會「哇靠那我每次畫個圖都要實作七層？」。實際上不需要，上面幾層像是主題（Theme）比較像是裝飾品，給我們更大的自由與彈性來訂製（customize）視覺化結果。在下一節我們會看到，ggplot2 會自動幫我們設定合適的主題或座標。（如果沒特別指定的話）&lt;/p&gt;
&lt;p&gt;但一般而言，一個圖像最基本的組成是底下三層。也就是除了前述的兩層（資料、視覺變數）以外還需要加上&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;幾何圖形層（Geometries）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為何還要這層？假如我們有了資料，決定了視覺變數（第二層，例：把資料中的變數 A 對應到 X 軸；變數 B 對應到 Y 軸）後，實際上就可以畫一個充滿點（point）的散佈圖了不是嗎？&lt;/p&gt;
&lt;p&gt;這樣的思維如同&lt;a href="#資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;/a&gt;部分所提到的，有所瑕疵。如果變數 A 是分類型變數（Categorical）的話，單純以&lt;strong&gt;點&lt;/strong&gt;為圖形的散佈圖就會變得十分難以理解（下圖左）；這時候以&lt;strong&gt;長條&lt;/strong&gt;為圖形（下圖右）的方式會比較清楚：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/make-geom-layer-independent.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    獨立幾何圖形層
    &lt;font color="purple"&gt;: &lt;/font&gt;
&lt;br/&gt;讓資料視覺化不再侷限於「我要畫什麼圖」，而是「我想要怎麼畫」
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將「幾何圖形」這個選擇獨立出來一層讓我們在資料視覺化的時候有更大的彈性。有了這些基本概念以後，我們可以開始嘗試使用 ggplot2 來實際做一些資料視覺化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="ggplot2-實踐_1"&gt;ggplot2 實踐&lt;a class="anchor-link" href="#ggplot2-實踐"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這個章節裡頭我們將使用 Kaggle 的 &lt;a href="https://www.kaggle.com/residentmario/ramen-ratings/data"&gt;Ramen Ratings&lt;/a&gt; 來做資料視覺化。這資料集紀錄了各國泡麵所得到的星星數。首先我們要先載入這次的主角：R 語言裡頭最著名的視覺化 package ggplot2。&lt;a href="http://yaojenkuo.io/r_programming/ch14#(1"&gt;dplyr&lt;/a&gt; 則是 R 語言用來處理資料的 package。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="載入-packages"&gt;載入 packages&lt;a class="anchor-link" href="#載入-packages"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ggplot2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dplyr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是它們都是同屬於 &lt;a href="https://medium.com/datainpoint/tidyverse-r-%E8%AA%9E%E8%A8%80%E5%AD%B8%E7%BF%92%E4%B9%8B%E6%97%85%E7%9A%84%E6%96%B0%E8%B5%B7%E9%BB%9E-3b01ca6a348c"&gt;TidyVerse&lt;/a&gt; 的一員。TidyVerse 是 R 裡頭常被用來做資料科學的 packages 的集合，以 Python 來說大概就像是 Pandas + Matplotlib + Numpy 的感覺吧。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="載入資料-+-簡單資料處理"&gt;載入資料 + 簡單資料處理&lt;a class="anchor-link" href="#載入資料-+-簡單資料處理"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;如下註解所示，這邊將資料集讀入，做一些簡單的資料型態轉變後選擇一部分的資料集（subset）來做之後的視覺化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 將 CSV 檔案載入成資料框架（dataframe）&lt;/span&gt;
&lt;span class="n"&gt;ramen_all&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"datasets//ramen-ratings.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將「星星數」轉成定量資料&lt;/span&gt;
&lt;span class="n"&gt;ramen_all&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Stars&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen_all&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Stars&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 

&lt;span class="c1"&gt;# Subset 資料，選擇拉麵數量前幾多的國家方便 demo&lt;/span&gt;
&lt;span class="n"&gt;ramen&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;ramen_all&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Country&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;% count(ramen_all, Country, sort = TRUE)[1:6, 1, drop=TRUE]) %&amp;gt;%
  &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Style&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;% count(ramen_all, Style, sort = TRUE)[1:4, 1 , drop=TRUE])
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了我們使用 dplyr 的 &lt;code&gt;filter&lt;/code&gt; 依照條件 subset 資料集以外，值得一提的是 pipe 運算子 &lt;code&gt;%&amp;gt;%&lt;/code&gt;。它是前面提到的 TidyVerse 裡頭的 packages 共享的介面（interface），將前一個函示的輸出當作下一個函式的輸入，讓我們可以把運算全部串（chain）在一起。在 Linux 裡頭就是如同 &lt;code&gt;|&lt;/code&gt; 的存在。&lt;/p&gt;
&lt;p&gt;而實際我們的資料長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea "&gt;
&lt;table class="table table-striped table-responsive"&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt;Review..&lt;/th&gt;&lt;th scope="col"&gt;Brand&lt;/th&gt;&lt;th scope="col"&gt;Variety&lt;/th&gt;&lt;th scope="col"&gt;Style&lt;/th&gt;&lt;th scope="col"&gt;Country&lt;/th&gt;&lt;th scope="col"&gt;Stars&lt;/th&gt;&lt;th scope="col"&gt;Top.Ten&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;2580                                                       &lt;/td&gt;&lt;td&gt;New Touch                                                  &lt;/td&gt;&lt;td&gt;T's Restaurant Tantanmen                                   &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;Japan                                                      &lt;/td&gt;&lt;td&gt;37                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2579                                                       &lt;/td&gt;&lt;td&gt;Just Way                                                   &lt;/td&gt;&lt;td&gt;Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles&lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;Taiwan                                                     &lt;/td&gt;&lt;td&gt; 7                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2578                                                       &lt;/td&gt;&lt;td&gt;Nissin                                                     &lt;/td&gt;&lt;td&gt;Cup Noodles Chicken Vegetable                              &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;USA                                                        &lt;/td&gt;&lt;td&gt;16                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2577                                                       &lt;/td&gt;&lt;td&gt;Wei Lih                                                    &lt;/td&gt;&lt;td&gt;GGE Ramen Snack Tomato Flavor                              &lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;Taiwan                                                     &lt;/td&gt;&lt;td&gt;19                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2575                                                       &lt;/td&gt;&lt;td&gt;Samyang Foods                                              &lt;/td&gt;&lt;td&gt;Kimchi song Song Ramen                                     &lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;South Korea                                                &lt;/td&gt;&lt;td&gt;47                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2574                                                       &lt;/td&gt;&lt;td&gt;Acecook                                                    &lt;/td&gt;&lt;td&gt;Spice Deli Tantan Men With Cilantro                        &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;Japan                                                      &lt;/td&gt;&lt;td&gt;39                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="簡單資料視覺化"&gt;簡單資料視覺化&lt;a class="anchor-link" href="#簡單資料視覺化"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了資料，讓我們再確定一下資料視覺化的目的及觀眾：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：探索資料&lt;/li&gt;
&lt;li&gt;觀眾：我們自己&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這樣的條件讓我們知道視覺化的條件是快速做出結果，不需調整如標題、主題的設定。&lt;/p&gt;
&lt;p&gt;現在讓我們問一些簡單的問題。像是&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;泡麵的包裝（碗裝、袋裝等）各佔多少比例？&lt;/li&gt;
&lt;li&gt;不同國家各有多少泡麵在資料集裡頭？&lt;/li&gt;
&lt;li&gt;不同包裝的泡麵所得到的星星總數，在不同國家有什麼差異嗎？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中一種能解決第一個問題的資料視覺化是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAYAAACPNyggAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;ramen&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; Style&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;裡頭，我們實際上已經建構了圖表最基礎的三層元素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料層： &lt;code&gt;ramen&lt;/code&gt; 告訴 ggplot2 使用此資料框架&lt;/li&gt;
&lt;li&gt;視覺變數層： &lt;code&gt;aes(x = Style)&lt;/code&gt; 告訴 ggplot2 我們將使用「 X 軸位置」這個視覺變數來反映泡麵包裝 &lt;code&gt;Style&lt;/code&gt; 這個變數的變化&lt;ul&gt;
&lt;li&gt;因為包裝的值有四種可能，你可以想像 ggplot2 已經準備好要幫你在 X 軸上的四個位置畫圖&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aes&lt;/code&gt; 是我們前面提到 &lt;strong&gt;aesthetics&lt;/strong&gt; 的縮寫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;幾何圖形層： &lt;code&gt;geom_bar()&lt;/code&gt; 告訴 ggplot 去計算對應到 &lt;code&gt;x&lt;/code&gt; 視覺變數的變數裡頭，所有值的出現次數後將結果以&lt;strong&gt;長條&lt;/strong&gt;來呈現&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們通常透過 &lt;code&gt;+&lt;/code&gt; 來疊加不同層的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="基本層數缺一不可"&gt;基本層數缺一不可&lt;a class="anchor-link" href="#基本層數缺一不可"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的例子很簡單，但假如我們沒有指定幾何圖形層的話，圖會長什麼樣子呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAYAAACPNyggAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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="/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就像我們剛剛所說的，雖然 ggplot2 已經知道要用什麼資料框架、要用什麼視覺變數，不知道要用什麼圖形表示的話就會是空白一張圖。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="另個簡單例子"&gt;另個簡單例子&lt;a class="anchor-link" href="#另個簡單例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們依樣畫葫蘆，來解決第二個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同國家各有多少泡麵在資料集裡頭？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Country&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;coord_flip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAYAAABq5QSEAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
這邊有兩個值得注意的地方：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;除了基本的三層以外，我們透過 &lt;code&gt;+ coord_flip()&lt;/code&gt; 額外對座標層（Coordinates）做操作，請 ggplot2 把 x, y 軸互換。&lt;/li&gt;
&lt;li&gt;透過 &lt;code&gt;aes(..., fill = Style)&lt;/code&gt; 裡頭的 &lt;code&gt;fill = Style&lt;/code&gt; ，我們告訴 ggplot2 將長條圖裡頭的填滿空間（fill）這個視覺變數，依照泡麵包裝（Style）做變化&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第二點是在做資料視覺化的時候，想辦法增加&lt;a href="https://en.wikipedia.org/wiki/Edward_Tufte"&gt;資料墨水量（Data Ink Ratio）&lt;/a&gt;的例子。透過增加顯示在同張圖上的變數數目，進而提高該圖能傳達的訊息量。&lt;/p&gt;
&lt;p&gt;舉例而言，我們可以很明顯地看到，在這資料集裡頭，台灣的杯裝泡麵（Cup）沒有被記錄到多少；而日本被記錄到的泡麵量最多，且袋裝（Pack）數目最多。這些是在我們沒有用「填滿」這個視覺變數時無法察覺的。而在 ggplot2 裡，要實現這種視覺化非常容易。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="複雜例子"&gt;複雜例子&lt;a class="anchor-link" href="#複雜例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;讓我們解決最後一個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同包裝的泡麵所得到的星星總數，在不同國家有什麼差異嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;資料視覺化一個有趣的地方就是：同個問題不同的人會有不同的做法。而針對這問題其中一種做法是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將包裝 &lt;code&gt;Style&lt;/code&gt; 對應到 X 軸、星星數 &lt;code&gt;Stars&lt;/code&gt; 對應到 Y 軸，然後使用長條 &lt;code&gt;geom_bar&lt;/code&gt; 顯示數值&lt;/li&gt;
&lt;li&gt;依照每個國家重複步驟一&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而 ggplot2 的實作為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Stars&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"identity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;facet_wrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Country&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAYAAABfdxm0AAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
實際上在上面的程式碼裡頭，我們多操作了額外兩層：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;統計層（Statistics）：專門負責匯總資料&lt;/li&gt;
&lt;li&gt;小平面層（Facets）：依照選定的變數分別畫圖，如上述的步驟二&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先 ggplot2 的 &lt;code&gt;geom_bar&lt;/code&gt; 預設只需要 &lt;code&gt;x&lt;/code&gt; 視覺變數，因為匯總資料的統計層會把 x 依照不同的值分別計數（也就是各個包裝的數量），然後讓 &lt;code&gt;geom_bar&lt;/code&gt; 顯示。但我們並不希望 &lt;code&gt;geom_bar&lt;/code&gt; 使用這個數值，因此使用 &lt;code&gt;geom_bar&lt;/code&gt; 裡頭的 &lt;code&gt;stat = "identity"&lt;/code&gt; 是告訴統計層不要分別計數，而是使用我們給定的星星數 &lt;code&gt;y&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;而 &lt;code&gt;facet_wrap( ~ Country)&lt;/code&gt; 則是告訴小平面層依照 &lt;code&gt;Country&lt;/code&gt; 這個變數重複畫&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;ramen&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; Style&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; Stars&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"identity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意所有的圖的 x, y 軸都是一致的，方便我們做比較。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料視覺化需要統計知識以及設計美感，涵蓋範圍非常廣大。這篇雖然打了落落長，但真的只有碰到皮毛（淚）。資料視覺化感覺都可以打個系列文了。但最後再次重申資料視覺化的定義：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料視覺化是將資料中的變數映射到視覺變數上，進而有效且有意義地呈現資料的樣貌&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;總之先確認你的觀眾與目的，選好你想要觀察的變數，選擇適當的視覺變數做可視化吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1"&gt;DataCamp - Data Visualization with ggplot2 (Part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://r-statistics.co/ggplot2-Tutorial-With-R.html"&gt;r-statistics.co - ggplot2 tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.safaribooksonline.com/library/view/data-visualization-in/9781491963661/"&gt;Safari - Data Visualization in R With ggplot2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="R"></category><category term="visualization"></category><category term="ggplot2"></category><category term="資料視覺化"></category></entry><entry><title>利用 Kinesis 處理串流資料並建立資料湖</title><link href="https://leemeng.tw/use-kinesis-streams-and-firehose-to-build-a-data-lake.html" rel="alternate"></link><published>2018-04-04T21:30:00+09:00</published><updated>2018-04-04T21:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-04:/use-kinesis-streams-and-firehose-to-build-a-data-lake.html</id><summary type="html">&lt;p&gt;所謂的資料湖指的是一企業裡頭所有形式的資料的集合。這些資料包含原始資料，以及經過轉換的衍生資料。資料湖的核心概念是將所有可用的資料全部整合在一個邏輯上相近的地方以供企業自由結合並做各式各樣的運用。資料湖可以用很多方式建立，這裏我們主要介紹如何利用 Amazon Kinesis 將串流資料載入資料湖。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所謂的&lt;a href="https://en.wikipedia.org/wiki/Data_lake"&gt;資料湖 (data lake) &lt;/a&gt; 指的是一企業裡頭所有形式的資料的集合。這些資料包含原始資料 (raw data)，以及經過轉換的衍生資料 (derived data)。&lt;/p&gt;
&lt;p&gt;資料湖的核心概念是將所有可用的資料全部整合在一個邏輯上相近的地方以供企業自由結合並做各式各樣的運用。資料湖可以用很多方式建立，這裏我們主要介紹如何利用 &lt;a href="https://aws.amazon.com/tw/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 將串流資料 (streaming data) 載入資料湖。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="概觀"&gt;概觀&lt;a class="anchor-link" href="#概觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料湖概念上可以說是企業的所有資料的最終目的地。現在假設我們打算以 &lt;a href="https://aws.amazon.com/tw/s3/"&gt;Amazon S3&lt;/a&gt; 中作為我們的資料湖，問題就變成：要如何將串流資料穩定地傳到 S3。這部分我們將透過 &lt;a href="https://aws.amazon.com/tw/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 來達成。 Kinesis 本質上是跟 &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; 類似的 &lt;a href="https://en.wikipedia.org/wiki/Message_broker"&gt;message broker&lt;/a&gt;，將訊息依照 message producers 產生的順序傳遞給 message consumers。實際上資料的流動會如下圖所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/simple-streaming-data-flow.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    Simple Dataflow
    &lt;font color="purple"&gt;: 將 streaming data 透過 Kinesis 保存在 S3&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上圖有幾點值得說明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作為一個簡易的 demo，這邊我們的串流資料產生者 (streaming data producer) 是一個簡易 python script&lt;/li&gt;
&lt;li&gt;Streams 指的是 &lt;a href="https://aws.amazon.com/tw/kinesis/data-streams/"&gt;Amazon Kinesis Data Streams&lt;/a&gt;。在 Kinesis 架構裡頭，一個 data stream 通常代表一個主題 (topic)，
跟這個主題相關的 producers 會把資料傳入該 stream 以讓該主題的 consumers 之後能接受訊息。&lt;/li&gt;
&lt;li&gt;Firehose 指的是 &lt;a href="https://aws.amazon.com/tw/kinesis/data-firehose/"&gt;Amazon Kinesis Data Firehose&lt;/a&gt;，是專門把接受到的串流資料寫入 AWS 上的資料存放區（如 S3、Redshift、ElasticSearch）以供後續分析的服務。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建構流程"&gt;建構流程&lt;a class="anchor-link" href="#建構流程"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要完成上述的資料傳輸 pipeline，我們會 follow 以下步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#建立一個-Kinesis-data-stream"&gt;建立一個 Kinesis data stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#建立一個-Firehose-delivery-stream"&gt;建立一個 Firehose delivery stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#用-Python-傳串流資料"&gt;用 Python 傳串流資料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#確認-S3-上的資料"&gt;確認 S3 上的資料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在每個步驟裡頭會稍微澄清一些概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立一個-Kinesis-data-stream"&gt;建立一個 Kinesis data stream&lt;a class="anchor-link" href="#建立一個-Kinesis-data-stream"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在假設有一個名為 naive-app 的應用程式，我們想要把使用者在上面做的操作紀錄下來。這時候我們可以建立一個新的 Kinesis Data Stream 來接受 app 的 streaming data。這邊指的 streaming data 是使用者存取應用程式時產生的 access log。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/create-kinesis-stream.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Scalability"&gt;Scalability&lt;a class="anchor-link" href="#Scalability"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊最重要的是 &lt;code&gt;Number of shards&lt;/code&gt; 的設定。Kinesis 將接收到的資料以 log 的方式儲存在硬碟上，而為了提高 scalability，Kinesis 利用 Partitioning 的概念將 log 切割成多個部分並分配到不同的 shards 上，再將這些 shards 分別存在不同機器上面以提高 read/write capacity。因此我們可以理解一個 Kinesis Stream (Topic) 的資料吞吐量 (throughput) 直接受到 shard 的數目影響： shard 數目越多，同時能處理 read/write 的機器越多，資料吞吐量越高。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="How-to-scale"&gt;How to scale&lt;a class="anchor-link" href="#How-to-scale"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;理想上是一開始就掌握該 Stream/Topic 需要的資料吞吐量，進而決定最佳的 &lt;code&gt;Number of shards&lt;/code&gt; ，但有時候事與願違。事後想要改變 shard 數目時需要透過 &lt;a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/"&gt;AWS Streams API&lt;/a&gt; 做 Resharding。Resharding 實際上就是在改變 shard 數目：增加 shard 會讓已存在的 shard 再度被切割；減少 shard 則會合併已存在的 shard。&lt;/p&gt;
&lt;p&gt;在這邊我們就只直接使用一個 shard for demo。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Availability"&gt;Availability&lt;a class="anchor-link" href="#Availability"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外值得一提的是 Kinesis 為了避免資料損失，會在三個不同的 availability zones 進行資料的 replication。因為這個額外的 overhead 可能使得在同樣設定下， &lt;a href="https://www.opsclarity.com/evaluating-message-brokers-kafka-vs-kinesis-vs-sqs/"&gt;Kinesis 比 Kafka 慢&lt;/a&gt; 的情況。因為是 log-based message broker，資料會被暫時存在硬碟上，預設保留 24 小時，而最多可以付費提升到維持 7 天以用來 replay data。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立一個-Firehose-delivery-stream_1"&gt;建立一個 Firehose delivery stream&lt;a class="anchor-link" href="#建立一個-Firehose-delivery-stream"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了接受 naive-app 串流資料的 Kinesis stream 以後，我們要建立一個 Firehose delivery stream 來接收 Kinesis stream 的資料。&lt;/p&gt;
&lt;p&gt;Firehouse delivery stream 簡單來說是一個將串流資料存到 AWS 資料存放區的服務（如 S3、Redshift、ElasticSearch）。因此除了 &lt;a href="https://aws.amazon.com/tw/about-aws/whats-new/2017/08/amazon-kinesis-firehose-can-now-read-data-directly-from-amazon-kinesis-streams/"&gt;Kinesis stream 的串流資料&lt;/a&gt;以外，當然也可以接其他的串流資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CloudWatch 的 log &lt;/li&gt;
&lt;li&gt;AWS IoT&lt;/li&gt;
&lt;li&gt;使用者自定義的串流資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇裡頭我們的串流資料是 Kinesis stream，因此 Source 選擇 &lt;code&gt;Kinesis stream&lt;/code&gt; 並填入我們剛剛建立的 stream 名稱： &lt;code&gt;naive-app-access-log&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/create-delivery-stream.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是 Firehose delivery stream 會 auto-scale，並不像 Kinesis stream 要手動調整 shard 數目。不過當然傳越多花越多。&lt;/p&gt;
&lt;p&gt;如上張圖所示，實際上 Firehose 還允許我們在 delivery stream 接受到串流資料以後把原始資料傳到指定的 &lt;a href="https://aws.amazon.com/tw/lambda/"&gt;Lambda function&lt;/a&gt; 做進一步的轉換。
但因為我們想要資料湖儲存原始的串流資料，這邊我們省略這步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Configuration"&gt;Configuration&lt;a class="anchor-link" href="#Configuration"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上 Firehose 不會一接收到資料就進行資料轉移。我們可以設定 Buffer size 以及 Buffer interval 讓 Firehose 在達到其中一個條件的時候把接收到的訊息統整起來一次做資料的轉移 (batch processing)。這邊為了能讓 Firehose 盡快把收到的資料轉移到 S3，設定 Buffer interval 為 &lt;code&gt;60&lt;/code&gt; 秒。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/firehose-configure-settings.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="選擇-delivery-stream-目的地"&gt;選擇 delivery stream 目的地&lt;a class="anchor-link" href="#選擇-delivery-stream-目的地"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在設定好 Firehose delivery stream 的串流資料來源（e.g., Kinesis stream）以及基本設定以後，我們要決定串流資料的目的地。這邊基本上很直覺， Destination 選擇 &lt;code&gt;Amazon S3&lt;/code&gt; 以及想要放資料的 bucket 即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/firehose-select-destination.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較需要注意的是我們可以指定此 Firehose delivery stream 在放資料進入 bucket 時要為檔案加什麼前綴。&lt;/p&gt;
&lt;p&gt;假設未來其他的串流資料我們也想要統一放在 &lt;code&gt;me-data-lake&lt;/code&gt; 這個 bucket 裡頭。為了方便管理，我們可以為每個 delivery stream 設定一個識別用的 Prefix。以 naive-app 來說，我們指定 Prefix 為 &lt;code&gt;naive-app-access-log/&lt;/code&gt; 。加上 Firehose 預設的 &lt;code&gt;YYYY/MM/DD/HH/&lt;/code&gt; ，該 stream 的每個檔案的路徑就會變成如下圖的 &lt;code&gt;naive-app-access-log/YYYY/MM/DD/HH/file_name&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/s3-bucket-path.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    加入 Prefix 後實際將串流資料存入 S3 時的檔案路徑
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用-Python-傳串流資料_1"&gt;用 Python 傳串流資料&lt;a class="anchor-link" href="#用-Python-傳串流資料"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;確保 Kinesis stream -&amp;gt; Firehose delivery stream -&amp;gt; S3 的資料流設定以後，我們可以寫一個簡單的 Python script 實際傳資料進 Kinesis stream 做測試。但首先先讓我們使用 &lt;a href="https://boto3.readthedocs.io/en/latest/"&gt;AWS SDK for Python&lt;/a&gt; 實作一個寄訊息給 Kinesis stream 的 function &lt;code&gt;write_to_stream&lt;/code&gt; ：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;boto3&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write_to_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Write streaming event to specified Kinesis Stream within specified region.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    event_id: str&lt;/span&gt;
&lt;span class="sd"&gt;        The unique identifer for the event which will be needed in partitioning.&lt;/span&gt;
&lt;span class="sd"&gt;    event: dict&lt;/span&gt;
&lt;span class="sd"&gt;        The actual payload including all the details of the event.&lt;/span&gt;
&lt;span class="sd"&gt;    region_name: str&lt;/span&gt;
&lt;span class="sd"&gt;        AWS region identifier, e.g., "ap-northeast-1".&lt;/span&gt;
&lt;span class="sd"&gt;    stream_name: str&lt;/span&gt;
&lt;span class="sd"&gt;        Kinesis Stream name to write.&lt;/span&gt;

&lt;span class="sd"&gt;    Returns&lt;/span&gt;
&lt;span class="sd"&gt;    -------&lt;/span&gt;
&lt;span class="sd"&gt;    res: Response returned by `put_record` func defined in boto3.client('kinesis')&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boto3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'kinesis'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put_record&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;StreamName&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;stream_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;Data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;PartitionKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;write_to_stream&lt;/code&gt; 基本上是把一個 Python dict &lt;code&gt;event&lt;/code&gt; 利用 &lt;code&gt;json.dumps&lt;/code&gt; 轉成字串後傳到指定的 region 的 Kinesis stream 裡的函式。（完整的 &lt;a href="https://gist.github.com/leemengtaiwan/b5edca45e12664164e6634d6fe24d913"&gt;Gist&lt;/a&gt; ）&lt;/p&gt;
&lt;p&gt;這邊值得注意的是 &lt;code&gt;Data=json.dumps(event) + '\n'&lt;/code&gt; 裡頭的 &lt;code&gt;'\n'&lt;/code&gt; 。如果之後想要利用 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 或者 &lt;a href="https://aws.amazon.com/tw/athena/"&gt;Athena&lt;/a&gt; 來進一步分析此串流資料的話，推薦在代表一個 event 的字串後面加上換行符號以維持「一行一事件」的資料形式，方便 schema 的自動產生。&lt;/p&gt;
&lt;p&gt;範例日誌檔案內容會像是這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{"event_id": "56262", "timestamp": 1522740951, "event_type": "write_post"}
{"event_id": "35672", "timestamp": 1522740956 ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外值得一提的是因為 Kinesis 背後是使用 &lt;a href="https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html"&gt;Hash partitioning&lt;/a&gt; 來分配資料到 shard，基本上 &lt;code&gt;PartitionKey=event_id&lt;/code&gt; 裡頭的 &lt;code&gt;event_id&lt;/code&gt; 只要每個訊息都是獨一無二的，就能保證資料能「平均地」分配到各個 shard 上。&lt;/p&gt;
&lt;p&gt;有了此函式以後，我們可以實際傳一些訊息進 Kinesis stream：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;"event_id"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
        &lt;span class="s2"&gt;"event_type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'read_post'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'write_post'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'make_comments'&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
        &lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;calendar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timegm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utcnow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timetuple&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="c1"&gt;# send to Kinesis Stream&lt;/span&gt;
    &lt;span class="n"&gt;event_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'event_id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;write_to_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;REGION_NAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;KINESIS_STREAM_NAME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們的 naive-app 可以讓使用者讀文章、寫文章以及寫評論，則上面的程式碼是模擬使用者使用 naive-app 時產生的事件，並將該事件的內容傳到 Kinesis stream &lt;code&gt;naive-app-access-log&lt;/code&gt;。60 秒內幾筆產生的事件如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{'event_id': '56262', 'event_type': 'write_post', 'timestamp': 1522740951}
{'event_id': '35672', 'event_type': 'make_comments', 'timestamp': 1522740956}
{'event_id': '71613', 'event_type': 'read_post', 'timestamp': 1522740962}
{'event_id': '48160', 'event_type': 'make_comments', 'timestamp': 1522740967}
{'event_id': '96093', 'event_type': 'write_post', 'timestamp': 1522740972}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="確認-S3-上的資料"&gt;確認 S3 上的資料&lt;a class="anchor-link" href="#確認-S3-上的資料"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意因為上面的 5 個事件在 $5 * 5 = 25$ 秒內就產生了。且因為我們前面設定 Firehose delivery stream 的 Buffer interval 為 60 秒，Firehose 會把以上的事件的訊息全部串接起來，放到一個檔案裡頭，而不是分成五個檔案：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/kinesis/s3-bucket-path.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;而實際檔案的內容如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{"event_id": "56262", "timestamp": 1522740951, "event_type": "write_post"}
{"event_id": "35672", "timestamp": 1522740956 ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到這邊為止成功把（偽）串流資料透過 Kinesis 存到 S3 了！為了方便之後的應用，輸出的檔案的內容格式或許還可以再改進，但資料湖的其中一個想法是 &lt;a href="https://www.youtube.com/watch?v=JHGkaShoyNs"&gt;Command Query Responsibility Segregation (CQRS)&lt;/a&gt;，也就是在存放資料的時候就只專心丟資料，不去在意之後資料會被以什麼方式、schema 使用，可以保證之後實際應用資料時有最大的彈性。&lt;/p&gt;
&lt;p&gt;另外在確保資料好好地儲存在資料湖以後，我們通常會實際針對串流資料再進行一些處理 / 分析像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/tw/blogs/big-data/building-a-near-real-time-discovery-platform-with-aws/"&gt;放到 Elasticsearch 並用 Kibana 做 Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;觸發 Lambda function 做進一步處理&lt;/li&gt;
&lt;li&gt;使用 Athena 做 ad-hoc 分析&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/kinesis/kinesis-firehose-intro.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;但這邊時間有限，之後有機會再來記錄資料湖之後的分析筆記。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=814aUb5n_Fk"&gt;Youtube: Introduction to Amazon Kinesis Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sumologic.com/blog/devops/kinesis-streams-vs-firehose/"&gt;sumologic - Kinesis Stream vs Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://acloud.guru/forums/aws-certified-big-data-specialty/discussion/-KhI3MgPEo-FY5rfgl3J/what_is_difference_between_kin"&gt;A Cloud Guru - difference betwwen Kinesis Streams and Kinesis Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.arundhaj.com/blog/getting-started-kinesis-python.html"&gt;Getting started with AWS Kinesis using Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.opsclarity.com/evaluating-message-brokers-kafka-vs-kinesis-vs-sqs/"&gt;opsclarity - Evaluating Message Brokers: Kafka vs. Kinesis vs. SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料工程"></category><category term="python"></category><category term="aws"></category><category term="kinesis"></category></entry><entry><title>AWS Data Migration Service - 從 MongoDB 遷移到 Redshift</title><link href="https://leemeng.tw/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html" rel="alternate"></link><published>2018-03-27T18:30:00+09:00</published><updated>2018-03-27T18:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-27:/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html</id><summary type="html">&lt;p&gt;同樣一份資料因應不同的使用案例，可能需要使用不同的存取方式。而針對這些不同的存取方式，我們通常需要選擇最適合的資料庫來最佳化使用者體驗。這篇文章將簡單介紹如何使用 AWS Database Migration Service來快速地達到我們的目標：將 MongoDB 資料遷移到 Redshift 上。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同樣一份資料因應不同的使用案例，可能需要使用不同的存取方式。而針對這些不同的存取方式，我們通常需要選擇最適合的資料庫來最佳化使用者體驗。&lt;/p&gt;
&lt;p&gt;這篇文章將簡單介紹如何使用 &lt;a href="https://aws.amazon.com/tw/dms/"&gt;AWS Database Migration Service&lt;/a&gt; (以下簡稱 AWS DMS )來快速地達到我們的目標：將 MongoDB 資料遷移到 Redshift 上。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用案例"&gt;使用案例&lt;a class="anchor-link" href="#使用案例"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;舉例來說，一個電子商務網站的後端可以使用一個具有高度彈性的 NoSQL 資料庫如 &lt;a href="https://www.mongodb.com/"&gt;MongoDB&lt;/a&gt; 來應對變化快速的使用者需求；而公司內部的資料科學家可以利用資料倉儲如 &lt;a href="https://aws.amazon.com/tw/redshift/"&gt;Redshift&lt;/a&gt; 來找出 business insight 。但這時候一個問題產生了：資料科學家用的資料倉儲 (例：Redshift) 的資料哪裡來？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;常見的方式是對 MongoDB 裡頭的資料定期做 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 以後將轉換過後的資料載入 Redshift 供分析需求。理論上在做 ETL 時要依照資料倉儲的 Data Model 重新設計 Tables (例： &lt;a href="https://en.wikipedia.org/wiki/Star_schema"&gt;Star Schema&lt;/a&gt;)，但為了能在最短的時間將 MongoDB 上的資料轉到 Redshift 進行一些 Query，這篇文章將簡單介紹 AWS DMS 的運作方式，以及如何運用它來實際進行資料遷移所需要的步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/intro.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://aws.amazon.com/tw/dms/" target="_blank"&gt;AWS DMS&lt;/a&gt;
&lt;font color="purple"&gt;: 遷移（並轉換） AWS 上的資料庫&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AWS-DMS-基本介紹"&gt;AWS DMS 基本介紹&lt;a class="anchor-link" href="#AWS-DMS-基本介紹"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;DMS 基本上運作方式就是幫我們啟動一台 EC2 機器 (稱之為 replication instance) ，然後在上面跑 replication task(s) 。 一個 instance 上可以有多個 tasks 進行資料遷移。 instance 則分別透過 &lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.Sources.html"&gt;Source Endpoint&lt;/a&gt; / &lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.Targets.html"&gt;Target Endpoint&lt;/a&gt; 連結來源 / 目標資料庫。在後面我們會看到， endpoints 實際上就只是告訴 AWS DMS 的 replication instance 如何連結到實際的資料庫的設定罷了。在我們的例子裡頭，來源 / 目標資料庫分別對應到 MongoDB / Redshift 。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/flow.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/Welcome.html" target="_blank"&gt;DMS 基本運作方式&lt;/a&gt;
&lt;font color="purple"&gt;: 資料遷移是由在 Replication Instance 上執行的 Replication Task 透過 endpoints 連結來源/目標資料庫完成的&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="基本遷移步驟"&gt;基本遷移步驟&lt;a class="anchor-link" href="#基本遷移步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在假設來源 / 目標資料庫已經在運作的情況下，如同 AWS DMS 的 Get started, 一般會進行以下步驟來遷移資料：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#建立-replication-instance"&gt;建立 replication instance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#確保-replication-instance-能連結到來源-/-目標資料庫"&gt;確保 replication instance 能連結到來源 / 目標資料庫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#定義-replication-task"&gt;定義 replication task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Debugging"&gt;Debugging：確保一切運作正常&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下針對每個步驟，我會紀錄一些需要注意的地方。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立-replication-instance"&gt;建立 replication instance&lt;a class="anchor-link" href="#建立-replication-instance"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;點擊 AWS DMS 介面的 Get started 選項會請我們建立新的 instance:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/create-replicate-instance.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    建立 Replication Instance
    &lt;font color="purple"&gt;: 注意 VPC /設定&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟基本上沒什麼問題， replication task 會佔用大量的 CPU 以及記憶體資源，理想上是依據需求選擇 Instance class ，不過第一次測試功能的話用預設的 t2.medium 即可。這邊值得注意的是 VPC 以及下面進階選項的 VPC Security Group(s) 設定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果來源 / 目標資料庫都可供公開存取的話，基本上不需要 VPC 。但一般來說我們都會有安全考量，也就是要求所有在 AWS 上的資源都要套用安全設定，則最簡單的架構是將來源資料庫、目標資料庫以及 Replication Instance 都放入同一個 VPC ，並利用 &lt;a href="https://docs.aws.amazon.com/zh_cn/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html"&gt;security group&lt;/a&gt; 設定來允許該 Instance 存取兩個資料庫。概念上此 VPC 的架構會如下 ( &lt;code&gt;sg&lt;/code&gt; 為 Security Group 之縮寫 )：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/naive-vpc-structure.png" style="width:60%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;來源 / 目標資料庫所在的 Security Group 要允許 Replication Instance 所在的 Security Group 存取&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以上圖為例， Security Group &lt;code&gt;sg_mongodb&lt;/code&gt; 以及 &lt;code&gt;sg_redshift&lt;/code&gt; 的 Inbound Rule 要允許 &lt;code&gt;sg_replicate&lt;/code&gt; 存取。而允許存取的 Port 則依照資料庫實際使用的 Port 設定即可 (例： MongoDB 慣用 27017； Redshift 則是 5439)。最後別忘了在建立 replication instance 的進階設定的 VPC Security Group(s) 選擇 &lt;code&gt;sg_replicate&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你可能已經注意到上圖的 S3 bucket 。就 replication tasks 的 log 來看， AWS DMS 在遷移資料的時候實際上會再細分為兩步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replication Task 將來源資料庫的資料載出、轉換並暫存到 S3&lt;/li&gt;
&lt;li&gt;Task 將存在 S3 的資料載入目標資料庫&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然 &lt;a href="https://aws.amazon.com/tw/cloudwatch/"&gt;ClodWatch&lt;/a&gt; 需要額外收費，但為了方便除錯，建議使用。在文章後面的 &lt;a href="#Debugging"&gt;Debugging&lt;/a&gt; 我們會實際看一些例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="確保-replication-instance-能連結到來源-/-目標資料庫"&gt;確保 replication instance 能連結到來源 / 目標資料庫&lt;a class="anchor-link" href="#確保-replication-instance-能連結到來源-/-目標資料庫"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;上一步驟設定好以後， AWS DMS 會馬上幫我們建立一個新的 replication instance。在等待的同時我們可以開始設定資料庫的 endpoints。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/check-replication-instance-can-connect-to-both-endpoints.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    設定來源 / 目標 enpoints
    &lt;font color="purple"&gt;: 在此步驟確保 Replication Instance 可以連到兩個資料庫可以減少除錯時間&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟基本上依照資料庫的不同，需要的輸入的項目可能不一樣。不過值得一提的是，在&lt;a href="#建立-replication-instance"&gt;建立 replication instance&lt;/a&gt; 的時候我們已經讓來源 / 目標資料庫以及 replication instance 都待在同個 VPC 裡頭。假設我們的 MongoDB 是運行在該 VPC 裡頭的某個 EC2 instance 之上，要允許在同個 VPC 的 replication instance 存取該 EC2 instance，我們要在 Server name 選項輸入運行 MongoDB 的 EC2 的 Private IP (上圖第一個紅框)。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="MongoDB-as-Source-Database"&gt;MongoDB as Source Database&lt;a class="anchor-link" href="#MongoDB-as-Source-Database"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當 MongoDB 為來源資料庫時有一些值得注意的事情可以參考&lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Source.MongoDB.html"&gt;官方文件&lt;/a&gt;。以下會說明一些值得特別注意的地方。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Metadata-mode"&gt;Metadata mode&lt;a class="anchor-link" href="#Metadata-mode"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Metadata mode 預設為 &lt;code&gt;document&lt;/code&gt;（上圖第二個紅框），也就是把 MongoDB 裡頭的 json-formated 文件放到 Redshift 裡頭對應 Table 的一個 &lt;code&gt;_doc&lt;/code&gt; 欄位。假設 MongoDB 裡有一個 &lt;code&gt;users&lt;/code&gt; collection ，裡頭存了以下文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"user"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"leemeng"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"favorite"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"chocolate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="nt"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"For fun!"&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;"unnecessary_field"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Don't include me!"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將會被以下的格式載入 Redshift：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;_doc                      |
---------------------------
{"user": "leemeng", "fav ..&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而這通常不是我們要的。將 metadate mode 設定為 &lt;code&gt;table&lt;/code&gt; 模式能讓 AWS DMS 把文件裡頭的欄位扁平化後放入對應的欄位(column)：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;user    | favorite  | a.b     | unnecessary_field
-------------------------------------------------
leemeng | chocolate | For fun!| Don't include me!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意到這邊有一個我們不需要遷移到 Redshift 的 &lt;code&gt;unnecessary_field&lt;/code&gt; 。在後面的 &lt;a href="#Transformation Rules"&gt;Transformation Rules&lt;/a&gt; 我們會了解怎麼辦該欄位去除。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Numbers-of-documents-to-scan"&gt;Numbers of documents to scan&lt;a class="anchor-link" href="#Numbers-of-documents-to-scan"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;而 Numbers of documents to scan 選項則讓我們決定要讓 AWS DMS 拿多少文件來決定要建立哪些欄位。如果要遷移的 MongoDB collection 的文件 schema 很常被更動（常有新鍵值）的話，建議可以讓 AWS DMS 掃描多一點文件來建立足夠的欄位。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Redshift-as-Target-Database_1"&gt;Redshift as Target Database&lt;a class="anchor-link" href="#Redshift-as-Target-Database"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果按照 AWS DMS 的 Get started 一步一步走的話基本上沒有問題。要注意的是 Redshift 要有允許 DMS 存取的 AMI Rule，否則會出錯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="定義-replication-task_1"&gt;定義 replication task&lt;a class="anchor-link" href="#定義-replication-task"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在確定 replication instance 可以連線到兩個資料庫後，可以開始建立我們的 replication task：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/create-replication-task.png" width="90%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們可以看到有三種資料遷移方式 (圖中的 Migration type)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;遷移目前 MongoDB 的資料&lt;/li&gt;
&lt;li&gt;同上，但在遷移後之後繼續同步 MongoDB &amp;amp; Redshift (前提是 MongoDB 要以 Replica Set 模式執行)&lt;/li&gt;
&lt;li&gt;只把 Task 啟動後 MongoDB 的資料變動遷移到 Redshift&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這邊選擇自己的想要的遷移方式即可。接著我們要告訴 AWS DMS 想要進行遷移的 MongoDB Collections 以及在想要做的簡單轉換。兩者分別透過 &lt;a href="#Selection-Rules"&gt;Selection Rules&lt;/a&gt; 還有 &lt;a href="#Transformation-Rules"&gt;Transformation Rules&lt;/a&gt; 定義。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Selection-Rules"&gt;Selection Rules&lt;a class="anchor-link" href="#Selection-Rules"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Selection Rules 的用途是告訴 AWS DMS 該遷移以及不要遷移的 (MongoDB) collections 。我們可以定義一個 general rule 讓一個 task 處理某個 db 的所有 collections ；也能讓一個 task 只負責一個 collection 的遷移。後者的設定比較花時間但是彈性比較高，可以依照不同 collection 特性決定遷移的方式。&lt;/p&gt;
&lt;p&gt;下圖是定義一個 rule 告訴 AWS DMS 遷移所有在 MongoDB 的 Collections。另外如果想要排除哪個 collection 的話就新增一個 rule 並在 Action 選擇 &lt;code&gt;Exclude&lt;/code&gt;。基本上想要加幾個 Selection Rules 都可以。而 Exclude Rules 的效果是在所有 Include Rules 後套用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/selection-rules.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.netpromoter.com/know/" target="_blank"&gt;Selection Rules&lt;/a&gt;
&lt;font color="purple"&gt;: 選擇要遷移到目標資料庫的 Tables / Collections&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Transformation-Rules"&gt;Transformation Rules&lt;a class="anchor-link" href="#Transformation-Rules"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;這邊所謂的轉換並不是對欄位的實際值 (value) 進行轉換，而是針對 Table / Column 層級做&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;排除（不遷移該 Table / Column）&lt;/li&gt;
&lt;li&gt;幫 Table / Column 更名、大小寫轉換或是名稱加上 prefix / postfix&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這種操作。下圖是將 &lt;code&gt;users&lt;/code&gt; collection 裡頭不需要遷移的鍵值 &lt;code&gt;uncessary_field&lt;/code&gt; 從 Redshift 排除的 rules:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/transformation-rules.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;透過這個 Transformation rule，我們上面 &lt;code&gt;users&lt;/code&gt; collection 的範例文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"user"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"leemeng"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"favorite"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"chocolate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"For fun!"&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;"unnecessary_field"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Don't include me!"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;就會被轉成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;user    | favorite  | a.b     
------------------------------
leemeng | chocolate | For fun!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意 &lt;code&gt;uncessary_field&lt;/code&gt; 不會被存到 Redshift 裡頭。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Debugging_1"&gt;Debugging&lt;a class="anchor-link" href="#Debugging"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當建立並執行一個新的 replication task 後，我們可以從 Load State 看到每個 Table 載入的狀況。 Load State 有幾種可能的值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before Loading&lt;/li&gt;
&lt;li&gt;Full Load&lt;/li&gt;
&lt;li&gt;Table completed&lt;/li&gt;
&lt;li&gt;Table error&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當出現 &lt;code&gt;Table error&lt;/code&gt; 時，我們可以先看 log 瞭解情況：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;2018-03-28T01:23:30 [TARGET_LOAD ]E: RetCode: SQL_ERROR SqlState: XX000 NativeError: 30 Message: [Amazon][Amazon Redshift] (30) Error occurred while trying to execute a query: [SQLState XX000] ERROR: Load into table 'users' failed. Check 'stl_load_errors' system table for details. [1022502] (ar_odbc_stmt.c:4406)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;依照不同的錯誤、不同的目標資料庫，實際的 log 內容會有所不同。以我們目標資料庫 = Redshift 的情況下，上面的 log 告訴我們 replication task 在載入 &lt;code&gt;users&lt;/code&gt; Table 時出錯，詳情可以參考 Redshift 的 &lt;code&gt;stl_load_error&lt;/code&gt; Table (&lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_STL_LOAD_ERRORS.html"&gt;官方文件&lt;/a&gt;)：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;pg_catalog&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stl_load_errors&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;starttime&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/load-error-example.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    查看 Redshift 裡頭 stl_load_error Table 來除錯
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就這個錯誤例子來看， err_reason 的內容告訴我們有個 &lt;code&gt;memo&lt;/code&gt; 欄位 ( colname ) 的值太長導致沒辦法載入 Redshift。這時候可以把正在運行的 replication task 暫停，用前面提到的 &lt;a href="#Transformation-Rules"&gt;Transformation Rules&lt;/a&gt; 來去除該欄位。而基本上其他錯誤也能用類似的方式解決。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到這邊為止大致上應該可以順利把 MongoDB 的資料載入 Redshift 了。之後想到什麼再補充。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="aws"></category><category term="資料庫"></category><category term="資料工程"></category></entry><entry><title>Designing Data-Intensive Applications (1) - 序言</title><link href="https://leemeng.tw/designing-data-intensive-applications-1-preface.html" rel="alternate"></link><published>2018-03-24T15:33:00+09:00</published><updated>2018-03-24T15:33:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-24:/designing-data-intensive-applications-1-preface.html</id><summary type="html">&lt;p&gt;最近在拜讀 Martin Kleppmann 的 Designing Data-Intensive Applications， 覺得受益匪淺，且我也相信透過 Feynman Technique 將學到的東西用最淺顯易懂的方式表達能幫助自己內化這些知識，遂嘗試把閱讀後的心得記錄在此。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最近在拜讀 &lt;a href="http://martin.kleppmann.com/"&gt;Martin Kleppmann&lt;/a&gt; 的 &lt;a href="https://dataintensive.net/"&gt;Designing Data-Intensive Applications&lt;/a&gt;，
覺得受益匪淺，且我也相信透過 
&lt;a href="http://blog.xxc.idv.tw/km/%E8%B2%BB%E6%9B%BC%E7%9A%84%E5%AD%B8%E7%BF%92%E6%8A%80%E5%B7%A7-the-feynman-technique.html"&gt;Feynman Technique&lt;/a&gt; 
將學到的東西用最淺顯易懂的方式表達能幫助自己內化這些知識，遂嘗試把閱讀後的心得記錄在此。&lt;/p&gt;
&lt;p&gt;另外在提到書內內容時都會盡量使用英文原文，不另做名詞的翻譯，以方便對照書內內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂-data-intensive-applications"&gt;何謂 data-intensive applications&lt;a class="anchor-link" href="#何謂-data-intensive-applications"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所謂的 data-intensive applications 如同名稱所示，專注在如何有效率地處理、儲存&lt;a href="#何謂資料密集"&gt;密集資料&lt;/a&gt;。通常一個這樣的系統的後端要用多種方式處理資料，而不是只用一個資料庫就結束了。（雖然對 end users 來說可能看起來像這樣）&lt;/p&gt;
&lt;p&gt;舉個簡單例子，一個電子商務網頁的後端除了做為 &lt;a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E4%B8%8A%E4%BA%A4%E6%98%93%E8%99%95%E7%90%86"&gt;OLTP&lt;/a&gt; 的 NoSQL 資料庫 (e.g., MongoDB) 以外，可能還有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個專門存放網頁快取的資料庫 (e.g. Redis) &lt;/li&gt;
&lt;li&gt;給資料科學家分析用的資料倉儲 (e.g., Redshift) &lt;/li&gt;
&lt;li&gt;處理 streaming events 的 messaging queue (e.g., Kafka)&lt;/li&gt;
&lt;li&gt;定期將 NoSQL 資料庫的資料做 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 存到 資料倉儲的批次處理 (e.g., Hive jobs)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;光是要把以上所列的資料庫 / 分散式系統 / 資料流 以有系統的方式組合起來就需要大量經驗，更遑論還要達到以下三個要求了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠性 (reliable): 像是 zero-down time, 很短的回應時間 etc&lt;/li&gt;
&lt;li&gt;規模性 (scalable): 即使之後資料量增加，系統也能很好地運作&lt;/li&gt;
&lt;li&gt;維護性 (maintainable): 容易改善、新增功能的系統設計&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/ddia/jigsaw-puzzle.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="http://www.jigsaw-puzzle-club.co.uk/" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: 如何了解各個 data system 的優缺點並予以組合&lt;/font&gt;&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我們不可能熟悉所有資料庫以及分散式系統的細節，了解他們背後設計的核心理念、演算法以及大致上的運作方式能讓我們了解每個 data system 的特性以及優缺點，依照不同的使用案例選擇最適合的 data system 並予以組合。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂資料密集"&gt;何謂資料密集&lt;a class="anchor-link" href="#何謂資料密集"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;書中所指的「密集」資料有以下所列的特徵（一個以上）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大量資料&lt;/li&gt;
&lt;li&gt;資料的（格式、 schema etc）變動速度很快&lt;/li&gt;
&lt;li&gt;資料有複雜結構&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;針對「資料有複雜結構」以及「資料變動很快」這點，最為人所知的 solution 就是 NoSQL 等允許彈性 schema 的資料庫的崛起；
而針對「資料量很大」這點，則端看使用案例有各式各樣的資料庫、分散式系統。舉幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能有效儲存大量資料的 Google BigTable&lt;/li&gt;
&lt;li&gt;以欄 (column) 為單位儲存以壓縮大量資料的資料倉儲 Redshift&lt;/li&gt;
&lt;li&gt;Amazon 的 Single-leader Replication - DynamoDB&lt;/li&gt;
&lt;li&gt;專門處理 realtime streaming data 的 Kafka, RabbitMQ etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前述，以上提到的系統依照它們想要解決的問題的特性，背後都會有一些假設以及 trade-off 。了解這些背後的原理可以讓我們了解哪些工具在什麼時候最 powerful 。&lt;/p&gt;
&lt;p&gt;這本書主要分成三部分來闡述，抓到大方向會比較容易閱讀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;針對單一機器上的資料，有哪些常用的資料儲存/處理方法&lt;/li&gt;
&lt;li&gt;類似前一部份，闡述針對分散式系統的資料儲存/處理方法&lt;/li&gt;
&lt;li&gt;資料密集型應用：如何將多個 data systems 組合起來&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一句話總結"&gt;一句話總結&lt;a class="anchor-link" href="#一句話總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資料密集的時代，我們的最終目標在於如何將各式各樣的 data systems 以有系統的方式「組合」起來，以建立一個可靠、具規模性以及維護性的系統。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料工程"></category></entry><entry><title>Google Data Studio 基礎</title><link href="https://leemeng.tw/google-data-studio-basics.html" rel="alternate"></link><published>2018-03-13T16:34:00+09:00</published><updated>2018-03-13T16:34:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-13:/google-data-studio-basics.html</id><summary type="html">&lt;p&gt;Google Data Studio 是 Google 推出的一個儀表板服務，讓我們可以利用多種連結器將儲存在如 Google Analytics、 Google 試算表及 Google BigQuery 等特定資料來源的資料做出漂亮的 visualization ，用資料講故事而不用自己設計 UI。這篇把學到的一些技巧以及使用心得記錄下來。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/data-studio/"&gt;Google Data Studio&lt;/a&gt; 是 Google 推出的一個 Dashboard / Reporting 的服務，讓我們可以利用多種&lt;a href="https://support.google.com/datastudio/answer/7530149?hl=en&amp;amp;ref_topic=6370347"&gt;連結器&lt;/a&gt;將儲存在如 Google Analytics、 Google 試算表及 Google BigQuery 等特定資料來源的資料做出漂亮的 visualization ，用資料講故事而不用自己設計 UI。公司內部雖然有自己的 dashboards 不過想說多試一些方案沒有壞處，而且現在 Data Studio 還是 Beta 版本，雖然介面是中文，說明文件還只有英文，想說把學到的一些技巧以及使用心得記錄下來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="將-Google-試算表的資料可視化"&gt;將 Google 試算表的資料可視化&lt;a class="anchor-link" href="#將-Google-試算表的資料可視化"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了快速展示 Data Studio 的功能，我們將使用&lt;a href="https://data.gov.tw/"&gt;政府資料開放平臺&lt;/a&gt;上由交通部觀光局提供的&lt;a href="https://data.gov.tw/dataset/45444"&gt;105年來台旅客性別統計&lt;/a&gt;資料。將 CSV 檔案下載下來，稍微簡化格式後上傳到 Google 試算表以當作報表的資料來源。下圖是簡化後的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/table-preview.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://data.gov.tw/dataset/45444" target="_blank"&gt;資料來源&lt;/a&gt;
&lt;font color="purple"&gt;: 2016年來台旅客性別統計&lt;/font&gt;&lt;br/&gt;
    每一列代表某地區 / 國家的訪台人數以及男女比
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="條件欄位應用"&gt;條件欄位應用&lt;a class="anchor-link" href="#條件欄位應用"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://support.google.com/datastudio/answer/7359285"&gt;條件欄位&lt;/a&gt;讓我們可以針對試算表裡頭每一列做 IF ELSE 判斷，依照判斷結果給予不同的值。現在假設我們想知道有多少國家的男性遊客過半數，可以使用簡易的評量表來計算：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/male-over-half.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;訪台男性遊客過半國家佔全部國家的比例&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現高達八成的國家（有些是區域）的訪台男性遊客較女性為多。我們可以調查其他國家的訪客性別比，看是不是只有台灣有此現象。要產生分母的「國家數」很直覺，我們只要新增一個欄位並計算有幾個國家即可：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/num_countries_as_metric.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;新增一個名為「國家數」的欄位&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但要計算分子的「男性遊客過半國家數」就稍微 tricky 了。我們想做的是，針對每一國家（每一列），只有在該國訪台男性遊客百分比過半（超過 50%)的時候才會被納入結果。而 Data Studio 的&lt;a href="https://support.google.com/datastudio/answer/7359285"&gt;條件欄位&lt;/a&gt;就是專門針對這種情況設計的。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/conditional-calculated-field.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;使用 CASE 語法對每一列做 IF-ELSE 判斷&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;&lt;p&gt;上面的公式用白話來說就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;針對每一列的國家，看它的「男性百分比」欄位的值有沒有大於50。有的話值為1，否則為0。在針對每列做完條件判斷以後再把所有 1 加起來，就等於符合條件的國家數。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="篩選器（filter）應用"&gt;篩選器（filter）應用&lt;a class="anchor-link" href="#篩選器（filter）應用"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;根據上個分析，我們知道女性遊客過半的國家只佔 20%。假設我們想確切知道是哪些國家的女性遊客過半，可以從女性百分比最高的國家開始列出男女比：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/multibar-female-over-half.png" style="width:100%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;訪台女性遊客過半國家&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現女性遊客過半的都是亞洲國家，或許我們可以簡單解釋成這些國家與台灣的距離短，適合女性遊客拜訪。而為了讓圖表易讀，上面這張組合圖額外建立一個篩選器來過濾掉男性遊客比女性多的國家：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/female-more-than-half.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;新增一個篩選器以過濾男性遊客比例較高的國家&lt;br/&gt;&lt;/font&gt;
    註：一般的長條圖可以直接透過設定限制長條圖數目
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="維度-VS-指標"&gt;維度 VS 指標&lt;a class="anchor-link" href="#維度-VS-指標"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在 Data Studio 裡頭，了解&lt;a href="https://support.google.com/datastudio/answer/6402048?ref_topic=7441655&amp;amp;utm_source=product&amp;amp;utm_medium=cta&amp;amp;utm_campaign=wwr&amp;amp;utm_content=dims_mets"&gt;維度跟指標的差異&lt;/a&gt;很重要。&lt;/p&gt;
&lt;p&gt;以我們現在的資料集為例，每一列就是一筆紀錄（record），每一行則是一個欄位。每個欄位則是維度或指標。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指標（Metric，底下藍色）&lt;ul&gt;
&lt;li&gt;數值型欄位，有經過「匯總」，負責 quantify 資料&lt;/li&gt;
&lt;li&gt;如「國家數」、「總人數」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;維度（Dimension，底下綠色）&lt;ul&gt;
&lt;li&gt;分類型欄位，負責 qualify 資料&lt;/li&gt;
&lt;li&gt;如「國家」、「居住地」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/metric-versus-dimension.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;fx 則代表是額外利用公式建立的欄位&lt;/font&gt;&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;像我們前面定義的「男性遊客過半國家數」欄位因為有經過 &lt;code&gt;SUM&lt;/code&gt; 公式匯總成為一個數值，因此為一個指標（藍）。而如果我們透過 &lt;code&gt;CASE&lt;/code&gt; 語法新定義一個「男性過半」欄位如下：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/define-a-dimension-with-case-syntax.png" style="width:70%"/&gt;
&lt;/center&gt;&lt;p&gt;此欄位沒有經過匯總因此被視為維度，在上一張圖被標為綠色。因此一句話總結維度跟指標的功能就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;維度負責「描述」資料； 指標則負責「衡量」資料。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料透視表-(Pivot-Table)"&gt;資料透視表 (Pivot Table)&lt;a class="anchor-link" href="#資料透視表-(Pivot-Table)"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料透視表很適合拿來看在不同條件下某個指標的表現。下圖是一個依照&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;居住地&lt;/li&gt;
&lt;li&gt;國家&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;兩個維度計算「男性人數」指標的資料透視表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/pivot-table.png" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照&lt;a href="https://support.google.com/datastudio/answer/7516660?hl=en"&gt;官方文件&lt;/a&gt;有幾點值得注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料透視表最多處理 50,000 筆資料，為了避免 scan 資料太花時間，可以額外建立一些篩選器 subset 資料&lt;/li&gt;
&lt;li&gt;列維度跟欄維度最多可以分別設定 2 個維度（上例列欄各設定 1 個維度）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="限制"&gt;限制&lt;a class="anchor-link" href="#限制"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;可能因為還處在 beta 版本，在這篇文章寫的時候（2018/03）試用了一陣子發現 Data Studio 也有一些使用案例沒有辦法做到，像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;篩選器（filter）只能設定像是「欄位 C 大於 X」這種條件，而不能做「當欄位 C1 &amp;gt; 欄位 C2」這種欄位間的比較。&lt;/li&gt;
&lt;li&gt;同上，條件欄位也只能設定像是「欄位 C 大於某固定值 X」的條件&lt;/li&gt;
&lt;li&gt;資料透視表包含的資料稍多 (&amp;gt; 2000筆)就開始變慢 ..&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實戰演練"&gt;實戰演練&lt;a class="anchor-link" href="#實戰演練"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這篇文章用的報表連結在&lt;a href="https://datastudio.google.com/open/19a--FnAQ9asll18anhv7negoXGO0fpyH"&gt;此&lt;/a&gt;，可以自己試試不同 visualization。有任何 feedback 也歡迎聯絡。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/google-data-studio-preview.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="資料視覺化"></category></entry><entry><title>Pelican 實戰手冊(主題篇)</title><link href="https://leemeng.tw/build-a-pelican-powered-blog-like-a-pro.html" rel="alternate"></link><published>2018-03-05T15:00:00+09:00</published><updated>2018-03-05T15:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-05:/build-a-pelican-powered-blog-like-a-pro.html</id><summary type="html">&lt;p&gt;Pelican 是一個用 Python 寫的靜態網頁生成器, 可以幫我們把 reStructedText, Markdown file 甚至 Jupyer notebook 轉成靜態的 HTML 檔案。 有些人可能已經注意到這個部落格是用 Pelican 所寫成並且 host 在 Github 上的。這篇主要紀錄如何使用 Jinja2 自訂主題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有些人可能已經注意到這個部落格是用 &lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt; 所寫成並且 host 在 &lt;a href="https://github.com/leemengtaiwan/leemengtaiwan.github.io"&gt;Github&lt;/a&gt; 上。這篇主要紀錄如何使用 &lt;a href="http://jinja.pocoo.org/docs/2.10/"&gt;Jinja2&lt;/a&gt; 自訂主題。&lt;/p&gt;
&lt;p&gt;Pelican 是一個用 Python 寫的靜態網頁生成器, 可以幫我們把 reStructedText, Markdown file 甚至 &lt;a href="http://jupyter.org/"&gt;Jupyer notebook&lt;/a&gt; 轉成靜態的 HTML 檔案。 靜態網頁的好處就是我們不需要一個 web server 或者是資料庫來管理內容, 可以把 HTML 檔案 host 在想要的地方，比方說 &lt;a href="https://pages.github.com/"&gt;Github Pages&lt;/a&gt;。用 Pelican 官網一句來介紹的話就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Pelican is a static site generator, written in Python, that requires no database or server-side logic. - Pelican Blog&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Google 一下你會發現除了 Pelican 以外還有很多其他像是 Jekyll, Hexo 等&lt;a href="https://www.staticgen.com/"&gt;靜態網頁生成器&lt;/a&gt;。 之所以會選擇 Pelican 是因為以下幾點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pelican 是用 Python 寫的，讓 Python 開發者（我）很容易客製化&lt;/li&gt;
&lt;li&gt;可以把 &lt;a href="https://github.com/danielfrg/pelican-ipynb"&gt;jupyter notebook 轉成 HTML&lt;/a&gt;，這對每天寫一堆 notebooks 的資料科學家很友善&lt;/li&gt;
&lt;li&gt;主題是用強大的 &lt;a href="http://jinja.pocoo.org/docs/2.10/"&gt;Jinja2&lt;/a&gt; 模組引擎建立，可以用前人寫好的&lt;a href="http://www.pelicanthemes.com/"&gt;主題&lt;/a&gt;或是自己寫 templates，自由度很高，也是本篇重點。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你的需求類似而且想要自己架一個部落格，可以現在就跳入 &lt;a href="https://github.com/getpelican/pelican/blob/master/docs/quickstart.rst"&gt;Pelican Quickstart&lt;/a&gt;，有問題再回來看這篇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;img src="images/jinja2.jpeg"/&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Jinja2 是 Python 知名的模組引擎 (templating engine)，可以有系統地產生 HTML，很常出現在 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 或是 &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; Apps 裡頭。以下介紹在建立 Pelican blog 時常用到的功能。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="再利用-HTML-區塊"&gt;再利用 HTML 區塊&lt;a class="anchor-link" href="#再利用-HTML-區塊"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比方說我們可以建立一個汎用的 template base.html 來定義整個部落格共用的資訊，像是 header 裡頭要 import 的 css / favicon 等等：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% block head %}
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"stylesheet"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text/css"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"css/vendor.css"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"icon"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"images/favicon.ico"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"image/x-icon"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
{% endblock head %}
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    {% block content %}
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;部落格內容&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    {% endblock content %}
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意到上面的 &lt;code&gt;{% block head %}&lt;/code&gt; jinja2 語法。會在多個 HTML 檔案重複使用的部分我們可以用 &lt;code&gt;{% block BLOCKNAME %}&lt;/code&gt; 以及 &lt;code&gt;{% endblock BLOCKNAME %}&lt;/code&gt; 包起來，然後在獨立顯示一篇文章的 article.html 裡頭我們可以定義：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;extends&lt;/span&gt; &lt;span class="s2"&gt;"base.html"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;文章標題&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endblock&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;文章內容&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endblock&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的 code 基本上是告訴 jinja2 article.html 要繼承 base.html 的所有內容，而在 &lt;code&gt;head&lt;/code&gt; block 除了用&lt;code&gt;{{ super() }}&lt;/code&gt; 繼承 base.html 的內容以外，在下面再追加新的內容。而 &lt;code&gt;content&lt;/code&gt; block 則是完全取代。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此最後 article.html 會被渲染成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"stylesheet"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text/css"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"css/vendor.css"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"icon"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"images/favicon.ico"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"image/x-icon"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;文章標題&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;文章內容&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="為當前文章取得前/後一篇文章連結"&gt;為當前文章取得前/後一篇文章連結&lt;a class="anchor-link" href="#為當前文章取得前/後一篇文章連結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;img src="images/pagination_prev_and_next.png" style="width:70%"/&gt;&lt;/center&gt;
&lt;center&gt;&lt;font color="purple"&gt; Pagination 範例: 顯示前後文章連結 &lt;br/&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照主題不同，有些主題可能文章頁面裡頭並沒有提供前一篇/後一篇文章的連結。要像上圖為每一篇文章取得前後文章的連結，可以在 article.html 裡存取 &lt;a href="https://github.com/getpelican/pelican/blob/master/docs/themes.rst#common-variables"&gt;articles Variable&lt;/a&gt; 並使用 jinja2 &lt;a href="http://jinja.pocoo.org/docs/2.10/templates/#assignments"&gt;namespace&lt;/a&gt; 來取得前後文章(&lt;code&gt;namespace&lt;/code&gt; 要在 jinja 2.10+ 以後才能使用)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# get prev- and next-article for pagination #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;namespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 要使用 break 要安裝 extension, 最佳化效率可省略 #}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%-&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endif&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 假設文章標題不會重複, unique #}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;true&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;previtem&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nextitem&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endif&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endfor&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的 code 會 iterate 所有文章，當遇到當前文章的時候利用 &lt;code&gt;loop.previtem&lt;/code&gt; 以及 &lt;code&gt;loop.nextitem&lt;/code&gt; 把前後文章記下來。 &lt;a href="https://stackoverflow.com/questions/9486393/jinja2-change-the-value-of-a-variable-inside-a-loop"&gt;jinja2 預設是無法在 loop 裡頭改變變數的值&lt;/a&gt;，但使用 &lt;code&gt;namespace&lt;/code&gt; 即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著就能利用剛剛取得的前後 article 物件來渲染前後連結：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{# 方便起見的 assignment %}
{% set prev_article = ns.prev %}
{% set next_article = ns.next %}

{% if prev_article %}
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"prev_article.url"&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"prev"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Previous Post&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        {{ prev_article.title }}
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% endif %}
{% if next_article %}
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"next_article.url"&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"next"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Next Post&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        {{ next_article.title }}
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% endif %}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="傳參數給子-template"&gt;傳參數給子 template&lt;a class="anchor-link" href="#傳參數給子-template"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;有時候多個 templates 會使用類似的 HTML，像是當首頁 index.html 以及部落格 blog.html 都用相同格式渲染最新幾篇文章時，我們可以定義一個 article_entries.html 如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 簡化版 #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"col-block"&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"{{ SITEURL }}/{{ article.url }}"&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endfor&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意這時候如果直接在 index.html 使用&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="s1"&gt;'article_entries.html'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;是會出現&lt;a href="https://stackoverflow.com/questions/9404990/how-to-pass-selected-named-arguments-to-jinja2s-include-context"&gt;錯誤&lt;/a&gt;的。理由是被 include 的 article_entries.html 看不到定義在 index.html 的 &lt;code&gt;articles&lt;/code&gt; 變數。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;解決方法是在 index.html 裡透過 &lt;code&gt;{% with %}&lt;/code&gt; 語法定義一個 scope：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 選擇前五篇文章來渲染 #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;articles_to_show&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;articles_page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;object_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 定義 scope #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;articles_to_show&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="s1"&gt;'article_entries.html'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endwith&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;使用 &lt;code&gt;with&lt;/code&gt; 的好處是可以把子 template article_entries.html 當作 function 來使用，我們可以依照母 template 的需要，傳進想要渲染的文章即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reference"&gt;Reference&lt;a class="anchor-link" href="#Reference"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jinja.pocoo.org/docs/2.9/templates/#extensions"&gt;Jinja2 Extension&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="日誌"></category></entry><entry><title>BeautifulSoup 筆記</title><link href="https://leemeng.tw/beautifulsoup-cheat-sheet.html" rel="alternate"></link><published>2018-03-02T15:34:00+09:00</published><updated>2018-03-02T15:34:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-02:/beautifulsoup-cheat-sheet.html</id><summary type="html">&lt;p&gt;Beautifulsoup 是一個可以幫助我們 parse HTML 的函式庫，不管是在寫爬蟲還是做 HTML 檔案的處理都很方便。這篇主要紀錄使用 beautifulsoup 時常用的指令。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Beautifulsoup 是一個可以幫助我們 parse HTML 的 lib, 這篇主要紀錄使用 beautifulsoup 時常用的指令。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="安裝"&gt;安裝&lt;a class="anchor-link" href="#安裝"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install beautifulsoup4
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="下載一個網頁並爬出特定內容"&gt;下載一個網頁並爬出特定內容&lt;a class="anchor-link" href="#下載一個網頁並爬出特定內容"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這邊假設我們想要把維基百科上的&lt;a href="https://zh.wikipedia.org/wiki/ISO_3166-1#cite_note-taiwan-4"&gt;「國家區域代碼」&lt;/a&gt;的表格爬下來，並轉成一個 Pandas 的 Dataframe：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/beautifulsoup/wiki.png" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;取得某個頁面的 HTML 字串&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://zh.wikipedia.org/zh-tw/ISO_3166-1"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'html.parser'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;利用 class 從該 HTML 裡取得特定表格&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'wikitable sortable'&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生欄位名稱&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;th&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;th&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'th'&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;columns&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['英文短名稱', '二位代碼', '三位代碼', '數字代碼', 'ISO 3166-2', '中文名稱', '獨立主權']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生每個國家的對應資料&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;trs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;trs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;td&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\xa0&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;td&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'td'&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[['Afghanistan', 'AF', 'AFG', '004', 'ISO 3166-2:AF', '阿富汗', '是'],
 ['&amp;Aring;land Islands', 'AX', 'ALA', '248', 'ISO 3166-2:AX', '奧蘭', '否'],
 ['Albania', 'AL', 'ALB', '008', 'ISO 3166-2:AL', '阿爾巴尼亞', '是'],
 ['Algeria', 'DZ', 'DZA', '012', 'ISO 3166-2:DZ', '阿爾及利亞', '是'],
 ['American Samoa', 'AS', 'ASM', '016', 'ISO 3166-2:AS', '美屬薩摩亞', '否']]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生 Dataframe&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;英文短名稱&lt;/th&gt;
&lt;th&gt;二位代碼&lt;/th&gt;
&lt;th&gt;三位代碼&lt;/th&gt;
&lt;th&gt;數字代碼&lt;/th&gt;
&lt;th&gt;ISO 3166-2&lt;/th&gt;
&lt;th&gt;中文名稱&lt;/th&gt;
&lt;th&gt;獨立主權&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;Afghanistan&lt;/td&gt;
&lt;td&gt;AF&lt;/td&gt;
&lt;td&gt;AFG&lt;/td&gt;
&lt;td&gt;004&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AF&lt;/td&gt;
&lt;td&gt;阿富汗&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;&amp;Aring;land Islands&lt;/td&gt;
&lt;td&gt;AX&lt;/td&gt;
&lt;td&gt;ALA&lt;/td&gt;
&lt;td&gt;248&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AX&lt;/td&gt;
&lt;td&gt;奧蘭&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;Albania&lt;/td&gt;
&lt;td&gt;AL&lt;/td&gt;
&lt;td&gt;ALB&lt;/td&gt;
&lt;td&gt;008&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AL&lt;/td&gt;
&lt;td&gt;阿爾巴尼亞&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;Algeria&lt;/td&gt;
&lt;td&gt;DZ&lt;/td&gt;
&lt;td&gt;DZA&lt;/td&gt;
&lt;td&gt;012&lt;/td&gt;
&lt;td&gt;ISO 3166-2:DZ&lt;/td&gt;
&lt;td&gt;阿爾及利亞&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;American Samoa&lt;/td&gt;
&lt;td&gt;AS&lt;/td&gt;
&lt;td&gt;ASM&lt;/td&gt;
&lt;td&gt;016&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AS&lt;/td&gt;
&lt;td&gt;美屬薩摩亞&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="找出特定-HTML-物件"&gt;找出特定 HTML 物件&lt;a class="anchor-link" href="#找出特定-HTML-物件"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們有一個字串代表一個表格：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"""&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;"""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;渲染成 HTML:&lt;/p&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際 HTML 架構：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
   &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;table&lt;/span&gt; &lt;span class="na"&gt;border&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"1"&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"dataframe"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;thead&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt; &lt;span class="na"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text-align: right;"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;x&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;y&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;thead&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tbody&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;0&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-2.863752&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-1.066424&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;1&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-0.779238&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;0.862169&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tbody&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
   &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;table&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;利用 &lt;code&gt;BeautifulSoup&lt;/code&gt; 物件 parse HTML:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'html.parser'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;找到第一個符合條件的 &lt;code&gt;table&lt;/code&gt; 標籤&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'dataframe'&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設定新屬性-/-class"&gt;設定新屬性 / class&lt;a class="anchor-link" href="#設定新屬性-/-class"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為這時候我們取出來的 &lt;code&gt;table&lt;/code&gt; 物件是 reference 到 soup 裡頭對應的物件, 只要直接改變對應的 attr 就會直接反映結果到 &lt;code&gt;soup&lt;/code&gt; 物件:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'table-striped'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'table-responsive'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe table table-striped table-responsive"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Iterate-標籤裡頭的子標籤"&gt;Iterate 標籤裡頭的子標籤&lt;a class="anchor-link" href="#Iterate-標籤裡頭的子標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;children&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{c.name}&lt;/span&gt;&lt;span class="s1"&gt; in &lt;/span&gt;&lt;span class="si"&gt;{table.name}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;thead in table
tbody in table
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="移除標籤"&gt;移除標籤&lt;a class="anchor-link" href="#移除標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊假設我們要移除表格裡頭第一行的值 ( 第2個 &lt;code&gt;tr&lt;/code&gt; 標籤 ), 可以對要移除的標籤物件使用 &lt;code&gt;extract()&lt;/code&gt; func.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;tr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立新標籤"&gt;建立新標籤&lt;a class="anchor-link" href="#建立新標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們想要建立一個新的 &lt;code&gt;blockquote&lt;/code&gt; 標籤，並加入一些文字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'I love BeautifulSoup!'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;blockquote&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'blockquote'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;blockquote&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;blockquote&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;blockquote&amp;gt;I love BeautifulSoup!&amp;lt;/blockquote&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="beautifulsoup"></category><category term="html"></category></entry><entry><title>Seaborn 筆記</title><link href="https://leemeng.tw/seaborn-cheat-sheet.html" rel="alternate"></link><published>2018-03-02T00:10:00+09:00</published><updated>2018-03-02T00:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-02:/seaborn-cheat-sheet.html</id><summary type="html">&lt;p&gt;這篇記錄我在使用 seaborn 做資料分析還有 visualization 時常用的 code. 一般慣例會把 seaborn 更名成 sns for reference.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇記錄我在使用 &lt;a href="https://seaborn.pydata.org/"&gt;seaborn&lt;/a&gt; 做資料分析還有 visualization 時常用的 code.
一般慣例會把 seaborn 更名成 &lt;code&gt;sns&lt;/code&gt; for reference.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="基本設定"&gt;基本設定&lt;a class="anchor-link" href="#基本設定"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊值得注意的是要調整的參數要一次全部設定, 用好幾次 &lt;code&gt;set()&lt;/code&gt; 的話只有最後一次的 &lt;code&gt;set()&lt;/code&gt; 的結果會被保留&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;font&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'IPAPMincho'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Histogram"&gt;Histogram&lt;a class="anchor-link" href="#Histogram"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([-0.53267554,  0.03851161, -0.16072742, -0.70889663,  0.23085979,
       -1.61295347, -0.46508874,  0.60112507,  0.42017249, -0.73656917])&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;seaborn 是建立在 matplotlib 之上, 因此 matplotlib 也可以直接拿來跟 seaborn 產生的圖互動&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Defualt style with kde'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kde&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'dark'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Dark style without kde'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kde&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Scatter-plot"&gt;Scatter plot&lt;a class="anchor-link" href="#Scatter-plot"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;0.016786&lt;/td&gt;
&lt;td&gt;-0.016519&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;0.948504&lt;/td&gt;
&lt;td&gt;0.298314&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;2.029428&lt;/td&gt;
&lt;td&gt;1.211997&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要使用 seaborn 初始設定就再呼叫一次 &lt;code&gt;set()&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般用lmplot畫, 然後設定 &lt;code&gt;fit_reg=False&lt;/code&gt; 就可以讓 regression line 消失. 有時候有沒有那條線影響圖很大&lt;/li&gt;
&lt;li&gt;一樣先 &lt;code&gt;x&lt;/code&gt;, 再 &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fit_reg&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lmplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;fit_reg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fit_reg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;scatter_kws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"marker"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"D"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"s"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Show regression line'&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;fit_reg&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="s1"&gt;'Without regression line'&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWAAAAFuCAYAAAC/a8I8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmUZFd94PnvW2LJrUpZUlapFqnKSOKqBKVCSEIsKsBq1DY03mh7PMdj3NbBbnfPeHDD0Db2gZ45Z+ym7ekejMf2me42NO7u4djGQJs2SCwSoBJCe1EqUaUrkFRVqkVVKdWSayxvmT9evMgXkRGREZkRb4n4fc4BVUa+fHFfLL933+/+7n2G7/sIIYSIn5l0A4QQYlRJABZCiIRIABZCiIRIABZCiIRIABZCiIRIABZCiITYSTdAZINS6s3AJ4ArCU7cLwEf0Vr/QCn1TuBPtdavT7CJiVNKfZXgNTnah319FnhGa/1vlVLfB96ptb600f2KdJEALNaklCoAfw/8Q631U7XHfhm4Vyn1Y4k2LkW01u8Z0H7fMIj9iuRJABbdGAeuACYjj/1/wBxg1X6eVEr9FXAjUAR+XWt9UCm1Gfgz4A2AD9wL/B7wb4F5rfXHlVLbgTPAXVrrb9WC+09prX8x2gilVBn4O2A/8D8Bi8CnCHrlFvAnWuvP1Lb9KPABYB54EPhZrfWeWs9yC3AdwUnl48AfAu+o7eMQ8EGt9ZxS6p8D/wyoACXgN7TWRzs8fhz4ea31E0qpfwp8EHCBc8Bvaq2fqz3/HLAPuAZ4GvgVrfVCuxdfKeUDM8B7gZ8DPOAGYAn4J1rrY7XX+VO1/eaA+4F/qbV22u1XJE9ywGJNWuuLwG8D9ymlXlBK/RfgHuCbWutKbbNdwCdrvbV/D/wftcf/BHiVIDDcRhA8PwJ8EXh3bZufBF4G7q79/NPAF1o0JQ/8d621Ar4P/C3wUa31rQQB9CNKqTcrpX4C+FXgduBWYKppP+Na69dprX8H+CjgALdqrfcTnAj+jVLKAv4Y+Emt9e3AfwDubPd4dOdKqbtqr9eP1/b5OeC/KaWM2ia31o55L7AH+IUWx9rOO4D/tZbuebTWfoBPAk/WXotbgKuAD/ewX5EACcCiK1rr/xvYRtCrOwv8DnCo1vMCeF5r/Wjt398Httb+/W6C/LCvtS4D/2/tsYeAXUqpbQTB6PeBu5VSeYIg89U2TTlY++9rCXqxn6nlSL8DjBEEn/cAn9daX9Ja+wQ98KiHIv9+L/AztWP5PvCzwE1aaxf4PPCwUupPgUvAp9s93rT/nwT+Wms9W3vtPgvsJAi2APdprcta6ypwhKBH3q0ntdanav9+KvK37wV+o3YMTwJvIjjpiRSTFIRYk1LqbcBbtdb/F8Fl+98rpX4PeIag1/oKUI38iQ+EvT2z9jORn3Naa08p9fcEwfIO4P3A7xL0Bh/ucEkePm4Bl6P50Vowvwz8QeT5IUgDtNpHuJ/f0lrfW9vHJEEKBa31LyulXg+8i6Cn+X7gf2j3eNM+KzQyCFIDAMuRx6OvVTfa/a0F/ILW+ljtOK6g8XUXKSQ9YNGNWeBjSqnopfZ2YDNBD66TrwG/qZQyaoN5/xT4Ru13XyS4VD9SS2U8QFBp0Sr90EwDy7V8MUqpawhOCLcCXwH+caR3/gHaB6OwfXmllAn8R+ATSqmrlFIvAa9qrf8Y+Bhwe7vHm/Z5H/A/KqVmam27hyAN86Mujmu9vgZ8KPI6fxn4zQE+n+gDCcBiTVrr5wguzf91LQd8FPgb4B6ttV7jzz9IkI44UvufJuihAnwT2MFKQP4aQZrjv3fRpgpB6uDXlFJPA18HPq61/q7W+gGCQPo9pdQTBCeKpTa7+j+B4wSDb0cJepT/m9b6FYK0yP1KqSeBf0MwsNjy8aa2fYMgJ/uAUuoHwD8B3qu19tY6rg34IDBB8Bo/XfvvHw3w+UQfGLIcpRg2SqnbCFImf1L7+cPAHc1VFUIkTXLAYhg9B/xOrRTMB04SpD6ESBXpAQshREIkByyEEAmRACyEEAlJfQ54dna+6xzJ9PQ4Fy+2G+zONjm2bBrWYxvW44LBHNvMzFTLWu+h6gHbtrX2Rhklx5ZNw3psw3pcEO+xDVUAFkKILJEALIQQCZEALIQQCZEALIQQCZEALIQQCZEALIQQCZEALIQQCUn9RAwh4lCqOBw7fpH55SpTYzn27pmmmJevhxgs+YSJkXfw8BkeOnKWirOyXO99j53kzn3bObB/R4ItE8NOArAYaQcPn+GBQ6dXPV5xvPrjEoTFoEgOWIysUsXhoSNnO27z0JGzlCvNt5QToj8kAIuRdez4xYa0QysVx+PoiQsxtUiMGgnAYmTNL1fX3ghYWOpuOyF6JQFYjKypsdzaGwGT491tJ0SvJACLkbV3zzR5u/NXIG+b3LR7S0wtEqNGArAYWcW8zZ37tnfc5s592ynkh3ftW5EsKUMTIy0sMWuuA87bptQBi4GTACxG3oH9O3jT3m0cPXGBhaUqk+M5btq9RXq+YuAkAAsBFPIWt9wwk3QzxIiRHLAQQiREesAiNWRBHDFq5NMtUkEWxBGjSAKwSNw3Hj0hC+KIkSQ5YJGoUsXhm4+f7LiNLIgjhpUEYJGoY8cvUql2Dq6yII4YVhKARaJkQRwxyiQAi0TJgjhilEkAFonau2eafK7zjDNZEEcMKwnAIlHFvM27br+24zayII4YVlKGJhJ39x27mZ8vyYI4KdVqgozoj1gDsFIqB3wG2AMUgN/XWn85zjaIdJIFcdKp3QSZd7/1x3jDayQttFFx94B/GXhVa/1+pdSVwCFAArAAZEGctOl0x+ivPvwi8/MluTrZoLhzwJ8HPh752Yn5+YUQXZA7Rscj1h6w1noBQCk1Bfwt8LG1/mZ6ehzb7v4ydGZmat3tSzs5tmzK4rE98sxZfCDX4ZZNPnD64jJ3vL7zXUWyKK73LPZBOKXUNcCXgD/XWn9ure0vXlzqet8zM1PMzs5voHXpJceWTVk9ttMvz1GN5H2b5WyTquNx+uU5ZrdNxtiywRvEe9YuoMc9CLcN+Drwm1rr++N8biFE92SCTDzizgH/HjANfFwp9e3a/8ZiboMQYg1yx+h4xJ0D/i3gt+J8TiFE78I7RreqggjJBJmNk4kYQoiWOt0xWuqA+0MCsBCirXYTZHbtvCKTg4tpIwFYCNGRTJAZHFmMRwghEiIBWAghEiIBWAghEiI5YJG45bLDoedmG5Y7LObT8dFstRRjWtomsk8+SaKluALPwcNnePTZ8yxG7g1332MnU7EOcLulGNPQtmZyosgmeYfEKnEFnnC5w+YFXyqOV58AkFSg67QUY9Jta5alE4VoJDlg0SAMPJWmhVjCwHPw8Jm+PE+alztMc9uaxfV+icGQACzq4gw8x45fXBU0mlUcj6MnLmz4uXrVr7aVKg6PPHOWBw+f4dBzs5Qq/V3+OksnCtGapCBEXS+BZ6OF+fORnG8nC0vdbddP/WhbmBbwob6sY7/TAnG+X2IwJACLujiDYpqXO9xo26L542h+u9/54zSfxER3JAUh6uIMimle7rDXtpUqQRndg4fP8OjRl3nw6c55136lBdJ8EhPdkQAs6uIMiuFyh50ktdxhL207ePgMn/ybw3z54eN869BpvvjgC5w6v9ix19mv3HaaT2JJiJ4IB5FzHwRJQYi6uNeADS/DH332fMPtb/K2mXgJVaelGMO2tSpVcz0f3/eZX6oAML2p0HL//UgLyJq9K7JaiicBWDToJvCE+lH8f2D/Dt5z4DoefPJkw3KHaQga7ZZiLOStthUIlmnU/72wXGXzVOsA3K+0QC/v17DKUs12MwnAYpVOgSfUzx5HsWCndpS+3VKM7SoQinmbOaOK7wc94YtzJUzDwDINigULwzD6nhbo5v0aVt2W4r1p77ZUvh4SgEVLndaAzXKPo1/aVSCYpsHkWI5LC2W8WirCNIJesbEY/O6n37an78FgVNfszXopngzCiZ5ktfi/3wM0XVUg+GBgrL2dWLesl+JJD1j0JIs9jkEM0OzdM819j51c9Vr4vs/CchXLDNIO05sKOI6PaRoU8xamaaT6knjQ+r1oUNZL8SQAi55krccxqHRJuwqEUtnF930ApsbzTI3nGyo8wudO0wkqLnGeCKPSXIonKQjRkyz1OAadLjmwfwd33bKzoRbX9XwMw2BqPN/xNUjLCSoug1o0KM315N2QHrDoSa89jiTXqY0jXdJcgXD+4jJPv/Aqptk595uGE1RcBl2pkOVSPAnAoie9FP8nXRwfV7okWoFQqjg8d+pSZi+JByGJE2FWSvEkAIuerXeWGMRbqpZEuiSJ2WlpvxtGEifCrEjPuyQyZT2zxKLiqARIaoAmeoLym55rEHcVSfsU3CyNG8RNArBYt15niUXFUQmQ5FoJ4Qnq9MVlTr88N5BL4jRcZXQja5UKcd4kVgLwiInjcjVNpWpJDtAU8hZ3vH47s9sm+77vtFxldCNLiwbFfZNYCcAjJK7L1bRdcmZtgKabk2RarjK6lYVKhSRuEisBeETEebmaxkvOrAzQdHuSTNNVRrfSfCJM6opCJmKMgLjXb8h6cXxSepmskLarjG6FJ8ID+3dwyw0zqfkMJHWTWAnAIyCJD1erWWIQ9HzvumVnKi4506TXk6TcDaO/krqikBTECEjqw5WmS86018r2mtPN0sBWFiR1RZGeT6AYmCQvV9OQe81Crex6TpJZGNjKiqTGLSQAj4A0DorFJSu1sus9SabpKiPLkrqikBzwCBjVQbF+Dz4O8q67G8nppnVgK2vq4xa5xtdvkOMW0gMeEaN4udrPWtlBpzEkp5sOcd8kVgLwCBm1y9V+DT7GlcYYxZNkGsV5k9hEArBS6g7gD7XW70zi+UdZGgbF4tKPwce4C/RH7SQ56mLPASulfhv4C6AY93OL0dKPWtkkaqglpzs6khiEex54XwLPK0ZMPwYfszjlV2RH7CkIrfUXlFJ7ut1+enoc2+6+BzAzM7WeZmWCHFvv3vcuxdRUkW8+fpJKdaXaIZ+zeNft13L3Hbs7/v3OqzeRszunIMLt2h3DsL5vw3pcEN+xpX4Q7uLFpa63nZmZYnZ2foCtSY4c2/pns73hNVvYu2tzy7zqS6cvdtznzukiBqxZQ71zeqzlMQzr+zasxwWDObZ2AT31AVgI2HgZWKvBxweeOsX9T56iUvWwTINiwVq1z2EoD0v7NOxRJu+CSL1BlIF9+u+P8oSexfdXbhpkLBpMjuVW7TPL5WFZmIY9yhIJwFrr48Cbk3hukS2DKAN74MlTq4IvgO/7zC9VWu4zjeVha/VsszINe5RJD1ikWr/v/FCqONz/1KlVwTdqYbnKxJi9ap9pqqFeq2ebpVsWjTIJwCLV+l0Gduz4RcrVzms/+L5PqewmVlrWj57t5FguU7csGlUSgEWq9XspzfnlKpZprLmd6/mJ3E1iPT1bz/MpVRxcz8cyDR48fIa3vO7qrp5P6peTlfoAPLdUwTINbNPEsgws08Aw1v4CieHQ76U0p8ZyFPM2c0a1Yxoin1t7n/2uLlhPz3ZhqcrCcuOxzC1WefqFV7p6zrTdsmjUpD4AL5Ual/wzAMs0sCyTnG1iWwa2ZWJbsrLmMOp3GVgY0CfHcvUBt2aGYfCuW3d13Ge/qwt6ydmGFpaqLY/B931OnV8kZ5sUC+2/4sO6BnSvmk+kBzaNxfbcqQ/AzXzA8Xwcz23I5RkGYNvMLVbqPWXbMqXHPAT6WQbWHNCbe4+GYXCbmuHH37ir7T4GUV0QDjaG+ecwnVAsWPXPb8XxuDRfBoK0w0KH/LhtmfgEwbjd5z/t9cvt9PPKo9WJ9P5Dp7njxq2xVIhkLgC34/tQcVyWyqsXyTZNA9tc6SnbloFtm5gSmDOjn2Vg0YA+XrQpVVw8zyefM/kHb9zFXbe2D76Dqi6YX662TCeEtclhqmB6U4G8bXJpodw2hWIYK4H7+p2bOHluIXP1y+20CphfffQEe7ZNcc22qZ4CctsTadWNrUxvaAJwJ57nU/H8VXlE0zTIWUFuORcJztJjTqd+loGtN6D3uywudPLcfNt0Qvj45HiO6akCd+7bzt9998W2+5ocy9U/w9duneLn33F9quqX16tVwAxPWi+dW2Bq/FUmx3NdpYLSUqY3EgG4Hc/zKXsuNF3JhemLnB2kMIJcs+SYh816Anq0LK5TuqCX6oJSxeHEy/MYhtG2V7uwXOWKqXw9eJ44N893j7y8Kn0S7S1DELTTVL+8Xq0CZnMOfGG5ynjR7ioVNKgTaa9GOgC343o+bnOOGbAiA345y8S2DSxTAnM/ZGW9grAsbq10QS/VBceOX8Tx/PrAoO/7+H4w3mFQG98A9lw9Ve+N/fw7r+PEuXnmF6stTwAwXINszQHT91fnwH3fp1RxGS8Gn5tOPdi0LDOavk94SvmA4/o4rgusBGbToDG3XPu32UWtqQh849ET3Pvwi5lYr2Dvnmn+5ls/6pgusC2jp8AXBoPJ8RylihOMY0Q7wgaMFyyu3bqyolYxb/P2m3dkepGgXjQHzFLZbXm14Hkrj3Xqwfa7vny9JABvkOcHb/Ta+eUgOEt+udHBw2c4eOQs1abXL83rFbSvHg64vs/hH71Cqeqy8+pN7JwuduzNR3vVVccLKhhqvWDDCFILVcfj5PnGJRKzvEhQr5oDpuu1fheaOz7terD9ri9vxff9tu0MSQAekHb5ZbtWwxwGZMs0MM3RnGCSloGQXhw7fpGxgo3r+i1L2GzLYH6xyhcffIGxok3OPosBHQPi3j3TfPWRE/VLaqO2LyIfB8MwOP7yPOWK2/BapHGRoEFoDpitZjMahkGx6bjb9WD7VV/u+T6u6+O4Xi116eNG/g0w1qEWWwJwzFZqmFf/rl67bAUz/8IgPazpjDCvl+tw37a0rVcQTRdES9hM08BxPRZrv3ebLoU79eaLeZvdV0/x0vmFts87OZbDcf2Wr8UwDLKtpTlgFgsWxmLjoOXkWK7hu7JWD7btFUTO4kDkhOm4Hq7r43rRIBv8vEYHd00SgFMkHPxr7jUbgGuaXJ4r1WcBDsMMwH4OhMQ1iBe9FDZNoz7g43k+5y+u5IVb9dA69eav3TbF1PirLXvV0cqGUV67oTlghoOWrao/oLsebHgF8YPjrzK3WGWsYHHHzTu5dGmJVy4t43r+mimnjZAAnAE+QXBeOUs3zgAMe8tWLaUR/jvtE036NRAS56Lj7XKHpYpTD5zhRIhmaw0KTY7nmBiz25a2gazd0JxyOXlunuMvz+NEuqKdcuBhXtZxvdqguofjeuy8apIdVwXbVByPUqXzinn9IgE443wfqq5HUDHX+KEJZwCGveZ6cDbTkdYIg1mnHsZal5FxLzreLncYTTlEJ0I062ZQaKzY+ms5TGVlG9GccilX3IYcuLpmGtsyWC47DTlZx/MbqiTSQALwEAtnAAYag3O4qFE4AGjbZtCTjrG2OQxmBzsMxHW6jExqEK9V7jAcRG11KRw16EGhNBpEesj3/XoPtup67Ll6Uz3QzrVZZCmNJACPqHBRo/ooQqUxrRGU0JnkbXOgMwEP7N/B1FRxVR1wN6VUSc5mar4UzudNvvnEKRx3pYcVThao1m76OTWRW9+gUIbLyvqRHnI9D8fxqdbSBY7jDTw3GxcJwGIVv1bbjOOxHCy+hWlAzrbI2SvLgParp3z3Hbvb3ja+k6RnMzVfClcqK2mPcKYcsDKoZsBjx861DDxhL9EH/sEbd4ERXFpnuaxsrfSQ7/u8dd92vFplgecHKQLP8/H8IPCG/x5WEoBFVzwfytXO07M3UpmxnlKqtMxmCoWB9auPnKjPlDOMldTEWMFumZdu1UsMe71ZLS8rVRwOPn2mfvIJp1bj+7VlMuFbh06zZ/sm8rnsnVz6RQKwWLe1pmeHA3/RXLNpGn2rzohjNlOvbt+7lQcPn8HzqS9x2VzLHc1LD2IQsdec63pztGFFQbQuNvz3kRdeZancuZKg6vr86PRlbtozugOLEoBF33mRFEYrhgGWsRKU82N5FparmIZR61F3l95I48BVuLBOWB+cs82W06yPnrjA3t3TfR9E7DXn2mn7O2/eXh/oCnqwwfRox/XwLIvzF5fbtqPb9FDzHW9GjQRgETvfB8dfGQBcWK6uWtnKgHqAtkwDI+xBG7X/mcHl/dtu3g6kZ+Cql7x0vwcRe+1Nh9v7tbQAtSC7VPb4+uMvcXmxwm03bgWgXHV4/tQci2WHiYLNbfu2d2zLRIfpt1HjbUruRsVoH71IrXDyyVqLmQCoa6/g+l2b+dHpyyyVHKbGc9x4zTRjRZtK1cU0DQwDTGPw6230kpee73JwsNuZgM296eiMOt+H7xw+w+v2bMGyTZZLVb516PSq3nnUk/o8N193JU8//ypP6vNUIxUe3zt2jv2vubIeoJtdt2sTB58+0/A3zXKWwfU7N695bMNMArDIhGgPLG+H90jzmSjYXLdrE4WczQ27rqhvX3E9Kour60Gb0x9mJC9tW+HjvQ8ihnnUC/MlKlW34xoeYV766PELXe07OogYVgr4PvUV0zzf5/s/fIXlilPrxQYBt5lbcfn+869w054tHO2i9111fb726AlOnF9c/buqyyNHzwG0DMKFnM2tamt9m1ZuVVtHegAOJACLDHji2fP1HtjScpXF2n3/Jgo242M5Dj59hlvV1ra9sajm9Ec79YXQ2/SYw1+ZhsFjx87x+LPn673JUtllsVRivJjjisk8jutFFzbjtpu2UXZcdm2dwDRY1QuNtixnmWy7YpzZS8tB4G3T3lfmSnid4ymwknNdbHHvxGa+76NPXe44IBf2klsF0vD9aO495yyj6/dr2EkAFqn2xLPn672opeUqi6WVy/Hw3+NjuY69sfWo9yLb3CJopX3nVvXyxoo2vu+zWKpimsFgoc9K4Nl3/VX1QHjLDTMde4lvfO0MpmWsmYrpNefazfblirvmZIe1Khluu3ErN193ZT09NF60uX7n5pHv+YYkAIvUKlcdntTngaA31qrXtlh2KBZsTNPo2BsbdPuajY/lgkAM3PbaGTZN5lsGnn71EnvNuXazPQYU7LVfy7UqGfI5a6RLzTqRACxS6/lTc/UAUa64rXujvk+56jJWsGOvK422rxXDMMhZBpsm8x3b1E0vsbkKIcx7h3rNuXazvdq1uWX+t9moVzJshLxyfbDWl0OsT7TH22kVKz/yuzjrSrvJo0J3berUS4zmwEOt8t699qbX2n7fdVv47FeflUqGAZIosUHdfjlE76J5yk7LZxqR38XZG4uj1jXMgfu+Tzly9w0/b7XMe/eac11re6lkGCwJwBsQHSCKqrp+3weFRlE0T1nIW8wvG6vTEIZBoRYA4u6NdZV3zVnrblOYY65XfkSOfX7ZYKJgt8x7t+tNt7tS69T7bttLzlncptrXAcfN81eX5jX+u3mblce8yN/5vs9CxeXS5WV838fzgskp4X99r3Hf4SSWsEIl/K8f+Xm8aHP9nitbtlsC8Dp1GoAJxT0olJRBpWCieUrDCAJOtAoCgl5o2DuOozcWfuF838cyTfZffxWPPXu+XjsWmfoAPuy//ioWS1Xma7ca8vzGL+fKl3X1l/34mXleuVSiVG2RwvB85pcqVByXrz/+EtuvHK8HBG9VIIKT5+Y5NbvQUE1hGnD1lRNcvSX6t62CFWzZVOTyYgXH8TAtg80TBX546hL6pUsNwWj1c68OcKuD4urnbHUMrYJruG3a/eJP7G35uATgdVprAAY2vthI9MtedTyqjtf+zN7iS+2F/236AEe/5OWqy+nziyxXHAq2xdVXjWObZsOXoNWXKtzfi2fnOXluvmF9VtOAnTOT7Lxqos2XKnws2F+hYLNUC1CtvnCmARfmyni1HmB4+xnLNFiuuJSqLlPjOZ587jwPPX0Wx/MwDYN8zgSMNQNCq+OMBqPmdvXii99+fl3vfbeWyi4PP/Pyuv/+8uIl9MlLPf/d8bPz635OscLwe/1ExeyzXz7id/qiRANCsZhjcanS5oy69tm03TatnnNuscLcYqWxTtIPe0ArjxbzNvmc2eHLHg2iTZc76X5rxIhamdYdLre5Ms07fMxs2qb19ivbtnocfJbLLp7vY5smk2M5LMtou9/ofqL767RNfV0RVh6bmMhTWq6u+hvTNGoTcGr7rv1smsbq9mNg1PY7NZ7jrjv2tBzESH0P+AvfeSHpJmzIwnIV2i8aJdbQ6gvT/AVzXI+K0zjbDIP6zxPF4Bby3QQEM/j2tPzSrvlFbhEAJsbzlErVhr9v2I/Z+GUNpkUHv/vRqcsceeHVldxvy6+wwZtu3MpNr9lS+/vG/b94Zo4n9PmGP26e3GcAd968HXXtdFevN8CWLRNcuLB2idp6hYPbhmFgGQY+wXTvOAa3+31sYx0Ga1MfgOMSTi1t/eFj1RcIAxaXq8F3w2j4eAf/rj22dXqsvtZAd2f/1tuMjeUol532X+Tofkyj/mUMv9zhF8c0DFzf45FnzuH6ftN32qh/OW3T4K5bd5HPWS17PCdfnuepH77SJuit/P+bX7eN115zRccey5YtE1y+tBQJfI1f9k7KVaerUql73rO3p/xwv/Lanb7Maz1HMWdx/Ozcqrx31EQxx3W7NnPdjtYDfWdfXSLXxWQK3w9uJpoGozS4nfoA/IH37m0KOK2CT/Dv6elx5i4vr7oU6vQ30W161e6DEnrzTdv69kHp51n56IsXKHZRQpWzTfbunm75uwtz5Xr1QSe2ZbJlU7HjNmMFm+V1Dp4NIhffj9LCMLjy0iVwvFXBtZvnuG7XJjZP5gFWVUFgBIOSm2sz7NrJ2rKQoza4HfurrpQygT8H9gNl4Ne01j9qt327M3srW6bHsWNMnGZ1sZF+TCBIyxe7n5MhoD+9r2hwtS0Dx/Ubgmv0OTzPp1x16vW94YDabTdubagCKRZsylUX3/MxzKD0zjSNNSs/srYsZByD22mSxGnvZ4Gi1votSqk3A/8O+JkE2tEXWVxspB/BMy1f7H6eCDbS+wp7vEePX+DFl+co5OyGySNhAHccj8PPvwLQsr53wXAhcyLBAAAcU0lEQVT49vdP158jepKP7q+bk3zYpis3FVu2KZSmyRT9PqGmXRIB+E7gPgCt9SNKqdsSaENfZW2xkX4Ez7Ss99rPE8F6e19hj7fieLxyuQS+z4IR5HU31VIIoe8dfRnbMlkuOa1zu77P/GKFrz12gp9622uA9Z3km1McvgcX5kuM54MlPMPXpVUQT3JqfVqurOKSxFFsAi5HfnaVUrbWuuUpbdOmInYXgwihLVsmNti89ChVHJ49foGF5SqTryxy454tXd0ssRtvf+MuvvPUqY6/v3rbpo77+Idv/THyeZtvP3WKihPceaKYtyjkbd66bztv27+z6/Zs5H3rx7EA8NIlbGvtsQDDMuvt/e7h07UqA6i6tQV5a+MJi2UH0zIaBrdKFR/Pd1mqOG3XGgZ4/sw8E5MFCpH3u6tjaGpTeDybJvNM+nnKFYfdV0/xhtfOcOOeLQ37D//24SNnqUbufv29Y+davp+D+K7dNlnge8fONTx/s1zO4vbXb1/V9n7q57F1OlkkEYDngKnIz2a74AswN1fqeseDLo2JU3MPxrYM7v3ui33LLe+95goWFytt89d7r7lizddypVQI8MGpepSBW2+Y6ervQxt939Z7LM09varr4qzRAwbwXY8LFxYpVx0efOpU/W+cqrdqqvTCcpW8bdUv/X3fp1z2GhYQasVxPB5/5mzPV1bNbWqWsy3OzC7wE7dfw+JCmUXK9d+1y387rsP9j7/EYuQecYP8ru1/zZUdr6xuU1euans/9fvYlgs201OtB6KTCMDfBX4K+JtaDvhIAm1ItbjKcDaSv4620TCMhqqKx/UslmXGOggZHsuxkxc4UZultefqTajdV7TcvlUVgmVCueJ07FlF0xnNKYvm/Krv+3guzC1WKORNCjmbQs6m6qxxjzfDoJC31pXnXG8aJU3VB1kd3F6PJALwl4C7lVIPE5SK3pNAG1Ir7i/CevLXafqyRkVvHmkY8NLsIo8cPcftN27ljpu21UsOHz16jseeDU4epknDOg6eB8tlJ0gbNNR3B96xfwfbr5wIyhotg5y9cv8428qxUJtS7XrhGgU+pYpDuQpQYaKYY99rtvDEs+1fv8mxHLZlcuXmIhNFG8+vTTFvNU266W/XO4iVtuqDLA5ur0fsAVhr7QH/LO7nzYq0fRFaSbKNBmBZBrZl1m9Zb5oG33vmZZ6ozZzK2Sth0wcee/Y8k2M5DuzfQani8ORzs21vvLlpMs9y2SGfMxsu41vd5n7zeOMAm2EYTI3nubRQxveDtvoEt58zartaLDn88PRlxgo25apHdCkAwwjyxZPjOfK2yRtvmKGQ7xxw6reUrx3s9i1jWJYRuTlnbRCu6e1qzkumsfoga4Pb6zEcQ4lDJI1fhGb9bqNhBAHOssxgDYHazMHwd+EU3TDYNitVnPqKae08dOQsb9q7jWNd3A14rGBz923XkLNNFpaqTI7nuGn3llXBcO+eae577GTD/saLNpcXy2A0zSCuTQSyTIP5xSrjRZtxy8TzfBzXw7ZMpiZy9RPDnfu2rxl8g9fHWOmlG/D611zJN544FWnTSu4ZgpNBzjK48ZrGCTajVn2QFvJqpkwWvgi9ttEgWLnMCnuttQVVwoC6/apJZjcwgaaboFpxPI6euMD88hr515pyxeVNe7d13KaYt7lz33YeOHS6/lip4gSzLC0Dx/EwzJWFaUK+7+M4HssVJzih+MGdkUsVlysm87znzbsbetq9aNUmWJnpaRnwzjfsZMfMROQW9z633TjDd4+cZW6pglubFFLIWQ0ntTRN2BgWEoBTJi0THDqJttEI86RNPbG8bfLmm65mrGCta5p3L7oNqgtLVaa6XO9gcry77cJA+dCRs1Qcb2W9XT/oyduWSfOKg67ns1R2sEyDTeN5DMOoz4TrR46zuU2h5jSKaRiYtTK1R35wjqWyw/xS5K7TRpALnxgLwsTb9+9g6/QYngebJvKUFsv1IL7y3w03f6RIAE6ZtExwiDIMsE0T2zbJWQa2VeDHb9nJt75/pu3fvP3mHbH10nsJqnt3r04bNMvbJjft7j73eGD/Dt60dxtHT1zgBy9e4JkXLuC4XrASXgue72MZYWqAeoALhemSblIQ3bSpUxoF4ODhMzxw6DTFgs2U69cHEn0/WPTdsgz+UVOvfGo8T2kiv2pfQD0gu56/+t+1/7nrWFt5GEkATqGkynCiA1zB/1b+3eztb9iJYRhr9rLi0CoX2ywMqoW81fISParb/GtUIW9xyw0z7N09zUvnF7i8UGm5nVcrXTBqL2mrnHaYLrnlhpme2tCuTZ2UKg4PHTlb/3lyPOjxlsourudjmcF6tmulY6JM08DEYK35U57n43oejhtZr9sLgrXreg2L/A8rCcAp1VyGs+2qCbZtLrbt+fYyfdSqXRqHA1vhz7Zl9JQu6KWXNUjt8p5R0aDa7SX6Rtpy/1OnMBZXv5a+H13AO5g52MrCUndplY1qlT83DIOxyNWL4/p9OSE0M00D07ToNMs5DNCOG/zXdT0c1xuaVIcE4BSLluF0mp3TbmnD29RW3vL6q2upA5OcHQyC9TMn200vKw69BtVBnjzC5/rqIye4FOkJG4bBeMGiXJtmOzmWa3u3525z0BvVS/48CZZpYpmsWvo0rB5xXB/H83DdbPaaJQBnmEGQpnj02DkMI+jZQpCz9YEnnptl00Q+1nRAknoNqtGTR6nicPR4UCUxNZZj757pDa27EbblK4+e5LGjLwe3zMoHi9ufv7jMRDHXNsj2moPeiH4PSsbFNA3ypkW+RbMcNwjITth7doJecxoDswTgjLBqZUGWZZCr5WUd1+Xw86+2zNGG+jGgkyXr6ZEfPHxmVc/5vsdObjgdUchb/Mb7buYf3XFtw0nh4lyZg5G8a7P15KDXq5f8eVYE6TQo0PgaRgOz6/m1G9YGaY6kKjgkAKeIaQQfHisyy8u2gvrZbVdOYHmNX5JnXni16/rXNKQJ0iisAGhWcbz64xu9gmh1UsjZZioGMHvNn2dZu8Ac8nwf1/W5YqpAaamM6/pU3SA4D6xNA9uzaKte1mUZ2HbQm83VBsV6kfb8Xdo1VwC0MqgriLQMYIZtgcEMSmaJaRiYtsF4McemyDTzMN/sek2DgX0IzBKAByRaWWBbZu321+2n065HVvN3adHLDLpBXEGkZQAT0nVCSJsw39zM9/16hUbV9eq55l7isgTgDYimDGzLwDZNLMvoe6VBO8OYvwuVKg7Hjl/s26BYK3IF0ShNJ4QsCBd+ytkmY5HHXc/DcYL0heN69cHxViQAdyFcyyCaLrBto+2KWnEZ1vzdoAbFmskVhBgEyzSx8u1zzVESgGsaFoyxDGwzCLDhzLC0Grb8XRyDYqFhvoIQ2TBSATicalsPrJGUQZqD7FqGJX8X16BYNL1xzdZJfnjqctu8fBavILoRR4pHrG3oXvHVC3abtVKu5FMGgzQM+bs4BsVapTcqVRefYB3gUFavILoRV4onTlk9oaS/hW1E1zAIe7NXbxknn8r5LtmTxAd60INi7dIbxYKN7/tcv3MT126dyuwVRDfiTPHEJcsnlNQHYMsMRhmjJV3tqgysDKcR0iSpD/QgB8XWSm8YhsHJcwv8/DuuH8rAC8nWPQ9K1k8oa0YspdTtcTSknZkrxrhissDkWI5i3sa2zFhKvEZV+IFuTgWEH+iDh9uvAbxRe/dMk7c7fyTXOyjWS3pjkEoVh0PPzfLg4TMcem6WUmX1bZu62WY90vIa9Eu3J5RyxY2pRb3rpgf8R0qpq4D/DPwXrfXLA26TSEjSPaRBltWloea3myuLQV59pOE16KekJ9L0w5oBWGv940qp3cD7ga8rpU4CnwX+TmudjXdKdCUNH+hBldUlXfPbzaUyMNDL6aRfg34bhhNKVzlgrfUJpdR/BhyCW8p/EPgDpdRHtdZfGmQDRXzS8oFeb1ldp4HDJGt+u7myePDpM6w1frzRq49hq3sehhPKmgFYKfUB4FeA7cBfAndqrU8ppXYAhwAJwEMiTR/oXsvq1rp0T3LW4FpXFp7n88p8GdfzGStYFPP2QG5VNGwzJ4fhhNJND/gdwP+utf529EGt9Rml1P88kFaJRGT1A93tSHhSswY7XVksLFVZWK7iuEF7KlWXOaPK5FjrBds3evUxTDMnh+GE0k0O+Fc6/O4L/W2OSFIWP9C9DhwmMWuw3ZXFwlKV+aXglkXRwp7wbsSw+mqjH1cfwzJzErJ/Qkl9HbCIV9Y+0OsZOIx71mCrKwvP8xtuWx+umBW9VfvCcpXx4ko6op9XH8MwczKU5ROKBGCxSpo+0GvNyEvLwGEnra4sShUHPxJtJ8eCBcDDni8EPeFSxWW8dofitF19pElWTygSgEVLafhAd1MTm6aBw06aryzc2qrdhmGsyvcuLFfrwdnz/NRefYiNkwAsUqnbgbUsDRxGryx+8OIFnnnhAsWC1TCzc3I8x8SYTans4no+b37dNt77lj3S8x1SEoBF6nRVN3v4DIWcRanqZmpJyfDKYu/uaV46v9DyxGEYBmNFm7xtSvAdchKAReqsNbAWlm598cEXGKvlR7O2pGQWK05E/0kAFqmzVt1sOFDlRu5+mMUlJbNWcSL6TwKwSJ12A2vtSrdCWVxSMk0VJyJ+soCuSJ12y1JGS7cMw6BYWB2ksrScYijMCx/Yv4NbbpiR4DtCJACL1Anzo82iKYfJsVzbdaHTvPqVEFGSghCp1Co/Gt4Jpd06CaGka36F6JYE4CGX1ZsVwur8aD5v8s0nTuG47ddtTEvN77Bp/hwd2DSWdJOGQja+iWJdsnyzwlDzjLxKxRv50q24T6qtPkf3HzrNHTduzcznKK0SCcBKqZ8DfkFr/UtJPP8oyPrNCttJe+nWoHuKcZ9U236Oqm6mP0dpEXsAVkp9CvgJ4PtxPF+WL8HXK+l7uw1amJo4/Pwr/PClS/jAa3ddwc3XX5louwbdU4z7pDrsn6M0SCISPQz8N+A3Bv1Ew3AJvh5puLfboD127FzDe/v8mTnuf+pUYu/toHuKSQTDUfgcJW1gAbh2K6MPNT18j9b6r5VS7+x2P9PT49h29x+omZkpAL7x6AkO1j6wuUhNqQ8cPHKWqakid9+xu+v9pkF4bGt64ULDMbdjWFb3+xywXtqRtvd2uezw6LPn277mOdvk0WfP854D11EsrO8r98gzZ/Gh4/vqA6cvLnPH61eX8K3LGp+j8Hdp+hz1S1zHM7AArLX+NPDpje7n4sWlrredmZlidnaeUsXh3odfpNrh7H3vwy+yd9fmzFw6hcfWFcfteOwh33W73+cA9XJsaXxvDz03y2Kb6dM526TqeFQdjwefPLnunuLpl+e6ek9PvzzH7LbJdT3HKh0+R+FxQXo+R/3S03eth322MpQTMXq5dBpG7WaSRWW1XCuN720ci8Inse7xMH+O0mIoA3AW7pIwSO1mkkVltVwrje9tHMExiWA4zJ+jtEikHKB2h+VvD2r/WblLwiClvVxrvdL43saxKHxSy1eGn5MHnz7D/GIV1/OxTIOxzUUOxPQ5GuZKpuE4iiZZukvCIA3jSltpfG/jCo6JnlT9YJCv9s/YDHsl01AGYFnsekUa7u3WT2l9b9sGx5zV155iXCfVsNf51HOz/PDUZYoFq35zUADHHfyEnmGdTBQ1lAEYhvcSXKTjvW11WdwqOL791muZn1vu63MP+qQa9jpLFZfzF5fxfR9jsfUiSIOaiNHVbameXrktVVZTE0b01thpNDs733UDW5WPlCvuUFyCD6I0Ji3We2xJvbetLovbBf+svW/RXudSqcrlhUrD76fG80yO5xrK0H76bXv6fkI49NwsX374eNvfh7el2jSRr/fM+3UCHlAZWsu1U7N1uliHYbsEFyuSeG+H+bK4udcZXX85tLBcZWKsMWwMouKk29tSeZE2ZvE9GMoyNDE6ShWHQ8/N8uDhMxx6bpZSxRnoc3UzHbhccTf0HHEdT7PmGuvmWz4B+L5Pqdx4fIOoOGlX7eL7jbelanUn7I2+B3Ea+h6wGF5xj5APem2EpEf8m3udxbzNnFGlOU0Z7RkPquKkXbVLqew23paqRcopS+tTSA9YZFKYCmj+goaXoQcPn+n7cw5yEkgSx9OsuddpmsHAW7Noz3hQFSfd3paqVQ8YsjPJSgKwyJw4UgGtDGoSSFLH06zVbLvJ8RxT4/n6/ffCm6HmcxZ33bJzoD3zA/t3cNctOxvaFN6WKhwMbCcrk6wkBSEyJ6llEgc1CSQtyz62q7GeHM8xXrQpVVxeu2szb1QzAymva6W5tK+Qt/jG4y/htBggDGVpkpUEYJE5Sa0HMahJIGla36JdjXUxb/GuW3fVf18s2MRVXNdc7VKuuKmbiLNeEoBF5iS5HsQgJoGkbX2LtE9hT8NEnH6RACwyJ+n1IPodoJI+nlbSXj+f9pNEtyQAi8xJw3oQ0QBVqjgcPX5h3at1peF4sijtJ4luSAAWmZSWy9B+1e6m5XhEvCQAi8xK+jK0m2nJ73uX6np/SR+PiJ8EYJFpSV2Gdlu7+54D1/W032G4rBbdk4kYQqxDt7W7h384G1OLRBZJABZiHbqt3Z1brKy9kRhZEoCFWIdua3c3TeQH3BKRZRKAhViHbu9SvF/yuaIDCcBCrEO3t2wvFtI1zp3kesNitXR9OoTIkKzV7ia93rBYTQKwEBuQldrdYb6VUpZJABZig9Jeu9ttzfIg7m4sOpMcsBBDrpf1hkW8JAALMeTStN6waCQBWIghl7b1hsUKCcBCDLlua5azchufYSIBWIgh123NsgzAxU+qIIQYAVmrWR4VEoCFGBFZqVkeJRKAhRghaa9ZHjWSAxZCiIRIABZCiIRIABZCiIRIABZCiIRIABZCiIRIABZCiITEWoamlNoM/FdgE5AHPqy1/l6cbRBCiLSIuwf8YeB+rfU7gF8F/izm5xdCiNSIeyLGJ4Fy5LlLMT+/EEKkhuH7/kB2rJT6APChpofv0Vo/rpS6GrgX+Bda6+902o/juL5ty1RJIUSmGS0fHFQAbkcptQ/4K+AjWut719p+dna+6wbOzEwxOzu/keallhxbNg3rsQ3rccFgjm1mZqplAI57EO4m4PPAL2qtD8f53EIIkTZx54A/ARSBTymlAC5rrX8m5jYIIUQqxBqAJdgKIcQKmYghhBAJkQAshBAJkQAshBAJkTtiCJExpYrDseMXmV+uMjWWY++eaYp5+SpnkbxrQmTIwcNnVt1Y877HTsqNNTNKArAQGXHw8BkeOHR61eMVx6s/LkE4WyQHLEQGlCoODx0523Gbh46cpVxxY2qR6AcJwEJkwLHjFxvSDq1UHI+jJy7E1CLRDxKAhciA+eVqV9stLHW3nUgHCcBCZMDUWK6r7SbHu9tOpIMEYCEyYO+eafJ2569r3ja5afeWmFok+kECsBAZUMzb3Llve8dt7ty3nUJe1s7OEilDEyIjwhKz5jrgvG1KHXBGSQAWIkMO7N/Bm/Zu4+iJCywsVZkcz3HT7i3S880oCcBCZEwhb3HLDTNJN0P0geSAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIRKAhRAiIXacT6aUmgA+B2wBFoH3a61n42yDEEKkRdw94F8HntRaHwD+CvhYzM8vhBCpYfi+H+sTKqUsrbWrlPpXgKO1/tedtncc17dtK6bWCSHEQBitHhxYCkIp9QHgQ00P36O1flwp9QCwD7h7rf1cvLjU9XPOzEwxOzvfUzuzQo4tm4b12Ib1uGAwxzYzM9Xy8YEFYK31p4FPt/ndXUqpG4GvANcNqg1CCJFmseaAlVK/q5R6f+3HRcCN8/mFECJNYq2CAD4D/GUtPWEB98T8/EIIkRqxBmCt9TngJ+N8TiGESCuZiCGEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmRACyEEAmJe0F2IVKjVHE4dvwi88tVpsZy7N0zTTEvXwkRH/m0iZF08PAZHjpylorj1R+777GT3LlvOwf270iwZWKUSAAWI+fg4TM8cOj0qscrjld/XIKwiIPkgMVIKVUcHjpytuM2Dx05S7ki94sVgycBWIyUY8cvNqQdWqk4HkdPXIipRWKUSQAWI2V+udrVdgtL3W0nxEZIABYjZWos19V2k+PdbSfERkgAFiNl755p8nbnj33eNrlp95aYWiRGmQRgMVKKeZs7923vuM2d+7ZTyFsxtUiMMilDEyMnLDFrrgPO26bUAYtYSQAWI+nA/h28ae82jp64wMJSlcnxHDft3iI9XxErCcBiZBXyFrfcMJN0M8QIkxywEEIkRAKwEEIkRAKwEEIkRAKwEEIkRAKwEEIkRAKwEEIkRAKwEEIkxPB9P+k2CCHESJIesBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJGSo1gNWSk0AnwO2AIvA+7XWs8m2qj+UUpuB/wpsAvLAh7XW30u2Vf2jlPo54Be01r+UdFs2SillAn8O7AfKwK9prX+UbKv6Syl1B/CHWut3Jt2WflFK5YDPAHuAAvD7WusvD/I5h60H/OvAk1rrA8BfAR9LuD399GHgfq31O4BfBf4s2eb0j1LqU8AnGJ7P488CRa31W4CPAv8u4fb0lVLqt4G/AIpJt6XPfhl4tRY/3g386aCfcFg+8ABorf8Y+IPaj9cC5xJsTr99Evj3tX/bQCnBtvTbw8A/T7oRfXQncB+A1voR4LZkm9N3zwPvS7oRA/B54OORn51BP2FmUxBKqQ8AH2p6+B6t9eNKqQeAfcDd8bds49Y4tqsJUhH/Iv6WbUyH4/prpdQ7E2jSoGwCLkd+dpVSttZ64F/oOGitv6CU2pN0O/pNa70AoJSaAv6WGK6gMxuAtdafBj7d5nd3KaVuBL4CXBdrw/qg3bEppfYRpFY+orX+TuwN26BO79mQmQOmIj+bwxJ8h51S6hrgS8Cfa60/N+jnG6oUhFLqd5VS76/9uAi4Sbann5RSNxFcIv2S1vrepNsjOvou8B4ApdSbgSPJNkd0Qym1Dfg68Dta68/E8ZyZ7QG38RngL2uXuhZwT8Lt6adPEAx6fEopBXBZa/0zyTZJtPEl4G6l1MOAwXB9DofZ7wHTwMeVUmEu+N1a6+VBPaEsRymEEAkZqhSEEEJkiQRgIYRIiARgIYRIiARgIYRIiARgIYRIiARgIYRIiARgIYRIyLBNxBCiK0qpDwL/GHgn8DbgPwG3hOsBCBEH6QGLUfX/AB7BKmx/AfyqBF8RN5kJJ0aWUurHgGcIFl75l0m3R4we6QGLUbYbmAfeqJQykm6MGD0SgMVIUkpNAv8R+ClgmeFaEF5khARgMar+CPiK1vpx4H8B/lUtJSFEbCQHLIQQCZEesBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJEQCsBBCJOT/B1zokTPjwTrDAAAAAElFTkSuQmCC
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想要將兩個 &lt;code&gt;lmplot&lt;/code&gt; 並排 render 可以參考這個 &lt;a href="https://stackoverflow.com/a/33091668/3859572"&gt;stackoverflow 答案&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Correlation-matrix-/-Heatmap"&gt;Correlation matrix / Heatmap&lt;a class="anchor-link" href="#Correlation-matrix-/-Heatmap"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;'x1'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'x2'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'x3'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;1.269566&lt;/td&gt;
&lt;td&gt;0.349083&lt;/td&gt;
&lt;td&gt;-0.000743&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-1.634587&lt;/td&gt;
&lt;td&gt;0.072568&lt;/td&gt;
&lt;td&gt;0.042596&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;-0.581238&lt;/td&gt;
&lt;td&gt;-0.337935&lt;/td&gt;
&lt;td&gt;-0.412084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;-0.080881&lt;/td&gt;
&lt;td&gt;-1.376481&lt;/td&gt;
&lt;td&gt;1.361046&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;-0.609886&lt;/td&gt;
&lt;td&gt;-1.061285&lt;/td&gt;
&lt;td&gt;0.265788&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊利用 pandas 本身的 &lt;code&gt;corr()&lt;/code&gt; 計算 correlation matrix 然後使用 seaborn 做 vis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;corr&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;td&gt;-0.034731&lt;/td&gt;
&lt;td&gt;0.032407&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;td&gt;-0.034731&lt;/td&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;td&gt;-0.192169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;td&gt;0.032407&lt;/td&gt;
&lt;td&gt;-0.192169&lt;/td&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;heatmap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Blues'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annot_kws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"size"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="n"&gt;xticklabels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;yticklabels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWYAAAECCAYAAADNQ31aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8TPf++PHXDBkJ0SCLJXatNYkEiS1avdoUvWg0WnVLUTsJJREllqAIEdS+lJ9U26hW2uqX63ali5Y0oSSWxtog+4JITJb5/aEdRrZRk8zi/ezj/DGf8znnvD+n8c5n3meJQqPRaBBCCGEylMYOQAghhC5JzEIIYWIkMQshhImRxCyEECZGErMQQpgYScxCCGFiJDELIcQ/MG/ePObMmVNun5MnTzJ06FA6duyIj48Pn332mV77lsQshBAPQaPRsGbNGnbv3l1uv8zMTMaMGUOHDh3Yu3cvw4cPZ86cOfz4448VHqO6oYIVQghL9+effzJ79mz++OMPGjVqVG7fPXv2YGtry5w5c1AqlbRq1YqEhAS2b9+Ot7d3udvKjFkIIfQUFxdHkyZN2LdvH40bNy63b0xMDJ6eniiV99Ksl5cXsbGxFBcXl7utzJiFEEJPAwcOZODAgXr1TU5Opn379jptTk5O5OXlkZ2dTb169crctsoTs43HlKo+5GMn/n/hxg7B4uXeKTR2CI8F18a2j7yPh8k5eXHrHvl4f8vPz0elUum0/f1ZrVaXu62UMoQQohJYW1uXSMB/f7axsSl3WyllCCEsm8I4888GDRqQlpam05aamkrNmjWpXbt2udvKjFkIYdmU1fRfDKhz587ExMRw/5uVf/31Vzp16qRzQbDUkA0aiRBCmBqFQv/lEajVatLS0rTlCj8/PzIzM5k/fz7nz5/n/fff58svv2TMmDEV7ksSsxDCsimU+i+PIC4uDm9vb+Li4gBwcHBg27ZtJCQk8NJLL7Fr1y7CwsLo3r17xSFX9V8wkbsyKp/clVH55K6MqmGQuzK6BundN+/XFY98PEOQi39CCMtmpIt/j0ISsxDCsj1i7dgYJDELISybge+2qAqSmIUQlk1KGUIIYWKklCGEECZGZsxCCGFiJDELIYSJqSYX/4QQwrRIjVkIIUyMlDKEEMLEyIxZCCFMjMyYhRDCxMiMWQghTIw8ki2EECZGShlCCGFipJQhhBAmRmbMQghhYiQxCyGEiZGLf0IIYWKkxiyEECZGShlCCGFiZMYshBCmRSGJ2TKtnTOUatWUTFr4obFDMVlFRUVEbl3HVwe+IO92Lp279mTy9NnUrWdf5jbnzsSzec1yzp87g72jE6+9MY7n+g3Qrr988Txb14aTcOoEVioV3s/0YfTEadSyrQ1Aft5tBvv0QKPR6Ow3aO47/OuFf1fOQI2kqKiIqB0b+O7gPvJv38bdswdjAoKpU8b5TTybwI714VxMPEM9Byf8Xh9Db5975+TPSxfYuSmCs/G/Y2VlRddefXh9rL/23ObdzuWj7Rs4+tN33Lp5k+atnuI/Y/xp5+pRJeM1JHNMzOZXfKlicye+yBg/b2OHYfI+2L6Rrw/sIzBkMSvW7SA9NYXFc6aX2T87K5OQ6RNp1bota7dHMdDvNVYvW8BvR38GIO/2bWZPG0/tJ+xYs/UDFixbw6kTsUQsmafdx6ULiQDs+Pj/+ODzb7SLd+/nK3ewRvBx5Ga+/9+X+AcvZOGqrWSkpxAeGlRq35zsLBYHT6HlU21ZsekD+vsOZWP4Qo7HHAEgL+82C2dOxLb2Eyxbv5PgRas4fTKO9StCtfvYuHIRx2OOMGVmKMs37qLlU+1YFDyZa39erpLxGpJCqdB7MRWSmMvQ3Nme/24JYOwQb65czzR2OCatoKCAz/Z8yMjx/nTy7M6TbdrxdmgYCSePk3DyeKnbHPwymlq1bJkwNZgmzVowyG8Y/3qhP59+tBOA1ORrdHDzYGrwPJo0a0E7l470G+jH8d+Oavdx+WIijk4NaNCoMfXsHbSLqkaNKhl3VSkoKGD/3iiGjZ5Mxy7daNm6HW+FLOXMqROciT9Rov83+6OpaWvLqMmBODdtQX/foTz9XH+++Ph9ANJTrtPWxZ0J0+fi3LQFbTq48fyLvpyKu3tub97I4cihrxk5cQYuHp40atKMUZMDqWfvyE/fHazSsRuCQqHQe6lIUVERK1euxNvbGw8PDwICAkhPTy+z/5EjR/Dz88Pd3Z3nnnuOrVu3lviGVxpJzGXo5taCi1fT8RyyhEtXM4wdjkm78McZ8m7n4ubRRdtWv6Ez9Rs24tSJ2FK3OXUiFhf3ziiV934EXT08STh5nOLiYpq1fJLZi1ZgbVMTgKQrl/j24Jd08uyu7X/pwnmaNGtRSaMyHZfOnyXvdi4d3O+dX6cGjXBq0IjTv8eV6H/65HHau3ronNsOHTtzNv4ExcXFNGneihnzwrC2sQHg2p+XOfT1ftw6dwPAykrF7CXv0s7VXbu9QqEAhYJbt25W1jArjSET89q1a4mOjiYsLIxdu3aRnJyMv79/qX0vX77MhAkT6N27N/v27SMwMJD169fz4YcVl0SlxlyGqAMxRB2IMXYYZiE9LQUAe0cnnXZ7ByfSU5PL3KbVU20f6O/Infx8bt7Iwa5OXW375JGvcCHxLE4NGjF36Wpt++ULidy5k0+w/5tcuXSBhs5NeO2NcXh2t6zSU0ZaKgD1HBx12uvaO5Lx17nX7Z9CiyfblOh7Jz+fWzdzeMLu3rkNHPcal86fw7F+Q4IXrgTA2sYGD68eOtv/cvgbkq/+icd9vxjNhaFqzGq1msjISEJCQujZsycAERER9OnTh9jYWDp16qTT/4cffsDa2popU6YA0KRJEw4cOMAPP/zAf/7zn3KPVeaMOSUlRe9FPN7u5OejVCqpXt1Kp93Kygq1Wl3mNqoaqgf63/384DZvvR3KivU7sHdwZFbAGPLz84C7Fwdv5GTzyvA3WRS+gfau7syfOYXjv/1qqKGZBHU557dAfadk/zv5WKkeOLd/fS544NxOCpzHwlXbqGvvyPwZ47nz17m937nTJ9kQHkq3Xn1w9+xRYr3JUzzEUo4zZ86Qm5uLl5eXtq1x48Y4OzsTE1NyElevXj2ys7P58ssvKS4u5ty5c8TExODi4lJhyGXOmPv27Ut+fn65G2s0GhQKBadPn67wQMJyREVuY/f727SfX3n9TYqLiykqLKRa9Xs/UgUFBVhb25S6jxo1alCgLtBpKyi4mzQe3ObJNu0ACFm8kuGDfThy+Due9enPe7v36fR/sk07Ll9IJHr3Ltw7d33EUZoOVY0ad89vUSHVqume3xqlnF9VjRoUFjxwbv9KyA/2b9n67rkNWrCc8UP7c/Sn7+nVp592fdzRn1m5MJin2rng//ZCg42pKhlqxpycfPfbX/369XXanZyctOvu5+Pjg5+fH4GBgcycOZOioiL69evHpEmTKjxWmYn5888/Z/To0djZ2REcHPywYxAW7MWXhvD0v3y0n2/eyCFy6zoyM9JxrN9A256Rnko3796l7sPBqQGZGWk6bRnpadjY1KSWrS0p169yIfEc3Xs9q11fz8GR2k/YkZF+96t9aUm/eauniD165FGGZ3Lsne4mgqyMdByc7p3frIw06jk8U7K/YwOyMnQvSGVlpGFtU5OatWxJTb7GpfPn8OrZW7u+rr0jtk/YkZl+7//J9wf3sXHlIjp3f5q35iwpMQs3F/fX2h9FXl4eSqUSKyvdby4qlYo7d0p+c7lx4wbXrl1jzJgx9O/fn3PnzrFkyRLWrVtHQEBA+TGXtaJp06Zs3bqVS5cukZmZiZeXV5mLeLzUfsKORo2bapcWT7bBpmYtTh6/93Uu5fpVUq5fw6Vj51L30cHNg1MnYnWuUP8ee4z2ru4olUrOJpxiccgMsjLvXXhNvpZETnYWTZu3JDsrA7++3vx06Gud/f5xJp6mLVoZeMTG1bxla2xq1iLhvgupqcnXSE2+Rnu3TiX6t3VxJ+Gk7rk9dTyGti4dUSqVJJ45RfiCmWTfd25Trl/lRnYWjf+6mPrTd/9j/YpQnu07kBnzwsw2KYPhLv5ZW1tTXFxMYWGhTrtarcbGpuQkITw8HKVSSWBgIO3bt+ell15i5syZbNmyhaysrHKPVe6vkhYtWhAQEMAnn3xS7k7E402lUvFv31fYtj6CmF9+IvHsaZbOD8bVvQvtXNyAu1+7MzPSKfjrK/YL//YlJzuLtSsWceXSBT7/5EO+/2o/fv8ZCYBXz6dp2NCZ5aFvc/H8HyScPM47IYG0c+lIl27e1KlrTzuXjmxbF8Hx334l6col3tuwioRTJxg6/E1jnYpKYaVS8cJAPyI3rybu6M9cOHeaVYvfpn3HzrRu70pBQQFZmffObZ9+g7iRncWWVUtIunyR/dFR/Pjtfxn06ggAOnfrRf2GzqxZGsLlC39wJv4EK0Nn0rq9Gx5ePcnOzGDjykW4de7KqyMncCMni6zMdLIy07mde8uYp+KfMVCNuWHDhgCkpel+00tNTS1R3gA4ceJEiXpyx44dKSgo4Pr16+Ueq8K7Mt544w2GDRtW5vqUlJRSgxKPlzfGTqGosJAVi2ZTWFhIl649mDR9tnb96ZPHCQ4YQ9i723Dr5EndevYsCt/ApjXLmDL6VZzqN2RGyGJtbdja2oZ3Vm1i87srmDl5FCgU9Hj6X4zzD9R+NQ2ev5T/t3kt4YvmcONGDk+2bseSVZtp1vJJo5yDyvTa6EkUFRby7tIQiooKtU/+AZyNP8GCGeNZsHIzLu5dqFPPnpBl69i+bgVB44fhWL8hU4IX4upx99ttDWsb5i5fz//bsJJ5b41FoVDg1fNZ3pj4FkqlkmM/HyI/7zYnYn5h7JAXdOLo028QEwPnlYjPlBmqxty2bVtq1arF0aNHGTRoEABJSUlcvXoVT0/PEv0bNGjA2bNnddr++OMPlEolTZs2LT9mjR53Ow8ePJiIiAiaN2+u0/7555+zZMkSfv1V/6vgNh5T9O4r/pn4/4UbOwSLl3unsOJO4pG5NrZ95H04jtqtd9+0Ha+Wuz48PJzo6GiWLl2Kvb09oaGh1KhRg/fffx+1Wk1OTg52dnaoVCoOHTrE+PHjCQgIYMCAASQmJjJv3jx8fHyYO3duucfRqypuZ2eHr68ve/bsASArKwt/f3/efvttfH199RyyEEJUPUM+kj1t2jQGDBhAUFAQI0aMoFGjRqxZswaAuLg4vL29iYu7+9DPM888w7p16/j6668ZOHAgS5Ys4dVXX2XWrFkVx6zPjBkgMjKSiIgIunTpwunTp3F0dGTRokW4urrqs7mWzJgrn8yYK5/MmKuGIWbM9cfs0btvyrYhj3w8Q9D7yb8hQ4YQFxfHgQMHqF69OiEhIQ+dlIUQoqpZ7NvlDh8+zIsvvkhsbCybNm1iwoQJBAUFMXXqVDIy5D0SQgjTZch3ZVQVvRLzuHHj6NSpE/v27aN3795MmTKFqKgoEhMT6d+/f2XHKIQQ/5g5Jma9ShmrV6+mb9++Om0uLi5ER0ezatWqSglMCCEMwnTyrd70SswPJuW/qVQqeVxbCGHSDPVIdlWS134KISyaKZUo9CWJWQhh2cwvL0tiFkJYNpkxCyGEiZHELIQQJkYSsxBCmBh93oFhaiQxCyEsmsyYhRDCxEhiFkIIE2OGeVkSsxDCssmMWQghTIxSLv4JIYRpMcMJsyRmIYRlkxmzEEKYGJkxCyGEiZGLf0IIYWLMMC9LYhZCWDZ5Ub4QQpgYmTELIYSJMccas/nN8YUQ4iEoFPovFSkqKmLlypV4e3vj4eFBQEAA6enpZfZPTk4mICAADw8PunfvzoIFC8jLy6vwOJKYhRAWTaFQ6L1UZO3atURHRxMWFsauXbtITk7G39+/1L5qtZpRo0aRnZ3NRx99xKpVq/j+++9ZsWJFhceRUoYQwqIZqpKhVquJjIwkJCSEnj17AhAREUGfPn2IjY2lU6dOOv337dtHWloaUVFR2NnZATBlyhSioqIqPJbMmIUQFk2pVOi9lOfMmTPk5ubi5eWlbWvcuDHOzs7ExMSU6P/jjz/So0cPbVIG8PPz45NPPqkw5iqfMcf/L7yqD/nY6eATaOwQLF7WsXXGDkHoyVAX/5KTkwGoX7++TruTk5N23f0uXbpEt27dWL16NV988QUKhQIfHx+mTZtGjRo1yj2WlDKEEBbNUKWMvLw8lEolVlZWOu0qlYo7d+6U6H/r1i0++eQTnn76adasWUNKSgqLFi0iMzOTsLCwco8liVkIYdEMNWO2tramuLiYwsJCqle/lzrVajU2NjYl+levXh07OzuWL19OtWrVcHV1pbCwkKlTpzJr1izq1q1b5rGkxiyEsGiGul2uYcOGAKSlpem0p6amlihvwN2SR6tWrahWrZq27cknnwTg6tWr5R5LErMQwqIZ6uJf27ZtqVWrFkePHtW2JSUlcfXqVTw9PUv079KlC6dPn6agoEDbdu7cOapVq4azs3P5MT/kGIUQwqwY6j5mlUrFsGHDWL58OYcPHyY+Pp7p06fj5eWFu7s7arWatLQ01Go1AEOHDuXOnTvMmjWL8+fP8/PPP7NixQoGDRpUbhkDJDELISycIR8wmTZtGgMGDCAoKIgRI0bQqFEj1qxZA0BcXBze3t7ExcUB4ODgwAcffEB2djaDBw9mxowZ+Pj4EBoaWnHMGo1G82jDfjgX0vKr8nCPJbldrvLJ7XJVw9oAtyc8s+onvfseeqvnox/QAOSuDCGERTPHlxhJYhZCWDQzzMuSmIUQlk3+GKsQQpgYpRlOmSUxCyEsmhnmZUnMQgjLJhf/hBDCxJhhiVkSsxDCssnFPyGEMDEKJDELIYRJMcMJsyRmIYRlk4t/QghhYswwL0tiFkJYNnnARAghTIzclSGEECbGDCfMkpiFEJZNShlCCGFizC8tS2IWQlg4uV1OCCFMjBle+5PELISwbHJXhhBCmBgpZQghhIkxwwnz45GYi4qKiNy6jq8OfEHe7Vw6d+3J5OmzqVvPvsxtzp2JZ/Oa5Zw/dwZ7Rydee2Mcz/UboF1/+eJ5tq4NJ+HUCaxUKryf6cPoidOoZVsbgPy82wz26YFGo9HZb9Dcd/jXC/+unIGaubVzhlKtmpJJCz80dihmo6ioiHXvruaLz6LJzc2lp3cvZofMw97BocJt/7xyBb/BA/niy/9Sv0EDbXt6WhrLw5Zw9JcjKJRKfF7ox9S3ZlCzZs3KHEqlMccZs9LYAVSFD7Zv5OsD+wgMWcyKdTtIT01h8ZzpZfbPzsokZPpEWrVuy9rtUQz0e43Vyxbw29GfAci7fZvZ08ZT+wk71mz9gAXL1nDqRCwRS+Zp93HpQiIAOz7+Pz74/Bvt4t37+codrJmaO/FFxvh5GzsMs7Nx/Vr2fR7N4qVh7IjcRUpKMtOn+Ve43aVLF5kwbjT5eXk67QUFBYwfO5qL58+z6t31bNi0lTMJ8Uzzn1RZQ6h0iodYTIXFz5gLCgr4bM+HTJwWTCfP7gC8HRrGyCH9STh5nPau7iW2OfhlNLVq2TJhajBKpZImzVpw/txpPv1oJ529epCafI0Obh5MDZ6Htc3dWUS/gX68/94G7T4uX0zE0akBDRo1rpqBmqnmzvZsmv8f2j/ZkCvXM40djlkpUKv5cFckwW+H0L1HTwDCwiPo79OH43GxuHt0KnW7D97fyfq1a2jarHmJdT8cPkTiH+f4Yv9Bmv21fvnK1bzwXG9ijh2li6dXZQ2n0lQzw1qGxc+YL/xxhrzbubh5dNG21W/oTP2GjTh1IrbUbU6diMXFvTNK5b3T4+rhScLJ4xQXF9Os5ZPMXrRCm5STrlzi24NfahM/wKUL52nSrEUljcpydHNrwcWr6XgOWcKlqxnGDsesnDlzhtzcXLp43UuWzs6NaeTsTOxvMWVu98Phw8wLXcyMoOAS665cvoSDg6M2KQPUb9CAOnXrEnPsqEHjryoKhULvpSJFRUWsXLkSb29vPDw8CAgIID09Xa84xo8fz/Dhw/Xqa/GJOT0tBQB7RyeddnsHJ9JTk8vcxt7hwf6O3MnP5+aNHJ32ySNfYeywQeTkZDMuIEjbfvlCInl5twn2f5PXBjzL9AkjOHbkR0MMyaJEHYhhYuiHpGTcNHYoZicl5e7Pr5NTfZ12J0cnkpNL/9kG2LT1Pfr261/qOkcnJ3Jysrl9+7a2LTf3FjdycsjMNM9vNAqF/ktF1q5dS3R0NGFhYezatYvk5GT8/SsuHUVFRfH999/rHXOZibm4uJiNGzfy/PPP07VrVwIDA7l+/bpOn4yMDFxcXPQ+mDHcyc9HqVRSvbqVTruVlRVqtbrMbVQ1VA/0v/v5wW3eejuUFet3YO/gyKyAMeTn363ZXb54nhs52bwy/E0WhW+gvas782dO4fhvvxpqaOIxl5+fh1KpxMrqgZ9tlQq1+s4/2qe399PY2tqyaMFcbty4wc2bN1kcOh+FQkFhQYEhwq5ySoVC76U8arWayMhIpk+fTs+ePenQoQMRERHExsYSG1v6t2+Ay5cvs2rVKjw8PPSPuawV27ZtY8eOHfj6+jJy5EiOHTuGr68v8fHx2j4ajYbCwkK9D1YVoiK34ft8N+2Sknyd4uJiih6Is6CgAGtrm1L3UaNGDQrUBQ/0v5uQH9zmyTbtcOnYiZDFK0m+lsSRw98B8N7ufazdHkVnrx482aYdYyZPp7NXD6J37zLUUMVjZtuWTXTr4qFdrl+7RnFxcYl/gwVqNTY2pf9sV8SuTh3WrNvIqVOneLqHF88924v6DRrSpk1bbGvbGmIYVc5QM+a/S0de95WOGjdujLOzMzExpZeOioqKCA4OZsyYMbRq1UrvmMu8+Pfpp5+yePFifHx8ABg+fDiTJk1i1KhRfPDBBzz11FN/Ddq0CusvvjSEp//lo/1880YOkVvXkZmRjmP9e7cEZaSn0s27d6n7cHBqQGZGmk5bRnoaNjY1qWVrS8r1q1xIPEf3Xs9q19dzcKT2E3ZkpKcCJRM4QPNWTxF79MijDE88xoa8MhSfF/ppP+fk5LDu3dWkp6XRoGFDbXtqWiq9HyhvPIyO7h7s23+QjIwMatWqhbW1NU/36MpLL/s9UvzGYqgc9Xd5qH79B0pHTmWXjjZv3gzAm2++ydy5c/U+Vpkz5tTUVNq1a6f9bGtry5YtW2jZsiWjR4/m2rVreh+kKtV+wo5GjZtqlxZPtsGmZi1OHr/3Gy3l+lVSrl/DpWPnUvfRwc2DUydide5B/j32GO1d3VEqlZxNOMXikBlkZd67WJV8LYmc7CyaNm9JdlYGfn29+enQ1zr7/eNMPE1b6P9bU4j72dWpQ9NmzbRLm7ZtqVWrFjEx9y7KXb2axLWrV+ncxfMfHePy5Uu88fpr5GRnY29vj7W1Nb/FHOPmzRt069bDUEOpUtUUCr2X8uTllV46UqlU3LlTsnQUHx/Pjh07CAsL07mRQB9l9m7WrBk//PCDTpu1tTUbN26kZs2ajBo1qtwLDKZCpVLxb99X2LY+gphffiLx7GmWzg/G1b0L7VzcgLtljcyMdAr+qqG98G9fcrKzWLtiEVcuXeDzTz7k+6/24/efkQB49Xyahg2dWR76NhfP/0HCyeO8ExJIO5eOdOnmTZ269rRz6ci2dREc/+1Xkq5c4r0Nq0g4dYKhw9801qkQFkalUvHK0GFErFjOTz8c5nRCPMGB0+ni6YVbx7u3gRao1aSnpVFQxvWUBzk7NyY1NYVlSxZx5fJljv76C7NmzsB3sB9NmzWrzOFUGqVC/6U81tbWpZaO1KWUju7cuUNQUBDTpk2j2T84b2Um5nHjxvHOO+8wY8YMzp8/r22vW7cu7733HgUFBbzxxhsPfUBjeGPsFJ59vj8rFs0mOGAM9Rs0ZM7icO360yeP859BfTh98jgAdevZsyh8A+f/OMOU0a+y79MoZoQsxr1zV+BumeKdVZuwqVmTmZNHMX+mPy2fasOi8PXa34zB85fSuWtPwhfNYdLIIcT/HseSVZtp1vLJqj8BwmJNCZhG/38PYPasIMaMGkHDRo0IX7VGu/748Tj69Pbm+PE4vfZXvXp11m7YTFpaGq+8/BIhs4MZNMiX2XPnV9YQKp2hEnPDv8pFaWm6Zc7U1NQS5Y0TJ05w/vx5wsPD8fDwwMPDg88++4yYmBg8PDwqrDgoNA8+M3yfQ4cOsXv3biZMmICbm5vOuszMTBYsWMA333yjc0GwIhfS8vXuK/6ZDj6Bxg7B4mUdW2fsEB4L1gZ4BG7GvrN69105oE2Z69RqNd26dWP+/PkMGjQIgKSkJPr06cPu3btxd7/3sFp+fj4pKSk620dERHDt2jXCw8NxdnamevWyB1fusJ955hmeeeYZBg8eTEREBM2bN9euq1evHn369OHXX+X2LyGE6TLUg38qlYphw4axfPly6tati729PaGhoXh5eeHu7o5arSYnJwc7Ozusra1LlDBsbW1LbS81Zn0CsrOzw9fXlz179gCQlZWFv78/s2fPZvDgwf9giEIIUTUM+YDJtGnTGDBgAEFBQYwYMYJGjRqxZs3d0lFcXBze3t7ExelXNio35vJKGfeLjIwkIiKCLl26cPr0aRwdHVm0aBGurq4PdUApZVQ+KWVUPillVA1DlDJm7z+nd98l/Vs/+gENQO97OIYMGcKzzz7Ljz/+SE5ODuPHj3/opCyEEFXNkDPmqqJXYj58+DAvvvgisbGxbNq0iQkTJhAUFMTUqVPJyJAXzwghTJehHsmuSnol5nHjxtGpUyf27dtH7969mTJlClFRUSQmJtK/f+kvQxFCCFNgjjNmvSo4q1evpm/fvjptLi4uREdHs2rVqkoJTAghDMEMX8esX2J+MCn/TaVSERxc8p2uQghhKszxRfkW/xdMhBCPNzPMy5KYhRCWTWFSf81PP5KYhRAWTWbMQghhYiQxCyGEiTG1P+ahD0nMQgiLVs0M/+S0JGYhhEUzpSf69CWJWQhh0aTGLIQQJsYMJ8ySmIUQlk0p9zELIYRpkRmzEEKYmOpmWGSWxCyEsGgyYxZCCBMjt8sJIYSJMcO8LIlZCGHZzPDBP0nMQghbrBH5AAAT4klEQVTLJqUMIYQwMZKYhRDCxJhfWjbP8osQQujNkH8lu6ioiJUrV+Lt7Y2HhwcBAQGkp6eX2X///v0MGjQId3d3nn/+ebZs2UJRUVGFx5HELISwaAqFQu+lImvXriU6OpqwsDB27dpFcnIy/v7+pfY9dOgQgYGBDBkyhC+++IIZM2awdetWNm3aVOFxJDELISya8iGW8qjVaiIjI5k+fTo9e/akQ4cOREREEBsbS2xsbIn+UVFR+Pj48Prrr9O0aVP69u3LyJEj2bt3b4UxS41ZCGHRDHXx78yZM+Tm5uLl5aVta9y4Mc7OzsTExNCpUyed/hMnTqRmzZq6sSiV3Lhxo8JjVXlizr1TWNWHfOxkHVtn7BAsXl3PKcYO4bGQF/foP8uG+tNSycnJANSvX1+n3cnJSbvufm5ubjqfb926xUcffUSvXr0qPJbMmIUQFs1Q9dq8vDyUSiVWVlY67SqVijt37lS47aRJk7hz5w4zZsyo8FiSmIUQFs1QM2Zra2uKi4spLCykevV7qVOtVmNjY1PmdpmZmUyaNInExES2b9+Os7NzhceSi39CCIumeIilPA0bNgQgLS1Npz01NbVEeeNvSUlJvPbaayQlJbFr164S5Y2ySGIWQli0agqF3kt52rZtS61atTh69Ki2LSkpiatXr+Lp6Vmif0ZGBiNGjKC4uJiPPvqItm3b6h2zlDKEEBbNUE9kq1Qqhg0bxvLly6lbty729vaEhobi5eWFu7s7arWanJwc7OzsUKlUhIaGkpWVxc6dO7G2ttbOtBUKBQ4ODuUeSxKzEMKiKQz4UPa0adMoLCwkKCiIwsJCevXqxbx58wCIi4tjxIgRREZG0rFjR7766iuKi4sZMmSIzj6qVatGQkJC+TFrNBqNwaLWw8mkW1V5uMfSUw1sjR2CxZPb5aqGIW6X2x+fqnff/h2cHvl4hiAzZiGERZO/ki2EECbGDN/6KYlZCGHZ5H3MQghhYpTml5clMQshLJsh78qoKpKYhRAWzQwrGZKYhRCWTWbMQghhYqTGLIQQJkbuyhBCCBNjfmlZErMQwsLJjFkIIUyM+aVlScxCCEtnhplZErMQwqJJKUMIIUyM+aVlScxCCEtnhplZErMQwqLJk39CCGFizLDELIlZCGHZzDAvS2IWQlg2hRlOmSUxCyEsmhnmZUnMQgjLZoZ52fITc1FREVE7NvDdwX3k376Nu2cPxgQEU6eefan9E88msGN9OBcTz1DPwQm/18fQ2+ff2vV/XrrAzk0RnI3/HSsrK7r26sPrY/2pZVsbgLzbuXy0fQNHf/qOWzdv0rzVU/xnjD/tXD2qZLymoqioiHXvruaLz6LJzc2lp3cvZofMw97BocJt/7xyBb/BA/niy/9Sv0EDbXt6WhrLw5Zw9JcjKJRKfF7ox9S3ZlCzZs3KHIpFWTtnKNWqKZm08ENjh1J1zDAzK40dQGX7OHIz3//vS/yDF7Jw1VYy0lMIDw0qtW9OdhaLg6fQ8qm2rNj0Af19h7IxfCHHY44AkJd3m4UzJ2Jb+wmWrd9J8KJVnD4Zx/oVodp9bFy5iOMxR5gyM5TlG3fR8ql2LAqezLU/L1fJeE3FxvVr2fd5NIuXhrEjchcpKclMn+Zf4XaXLl1kwrjR5Ofl6bQXFBQwfuxoLp4/z6p317Nh01bOJMQzzX9SZQ3B4syd+CJj/LyNHUaVUzzEf6bCohNzQUEB+/dGMWz0ZDp26UbL1u14K2QpZ06d4Ez8iRL9v9kfTU1bW0ZNDsS5aQv6+w7l6ef688XH7wOQnnKdti7uTJg+F+emLWjTwY3nX/TlVNxRAG7eyOHIoa8ZOXEGLh6eNGrSjFGTA6ln78hP3x2s0rEbU4FazYe7IvGfOp3uPXrSrn0HwsIjOB4Xy/G42DK3++D9nQx75WVq136ixLofDh8i8Y9zhK9+F49OnWnXvgPLV67m6K+/EHPsaGUOx+w1d7bnv1sCGDvEmyvXM40dTpVTKPRfTMVDJ2aNRkNWVlZlxGJwl86fJe92Lh3cu2jbnBo0wqlBI07/Hlei/+mTx2nv6oFSee+0dOjYmbPxJyguLqZJ81bMmBeGtY0NANf+vMyhr/fj1rkbAFZWKmYveZd2ru7a7RV//R+/detmZQ3T5Jw5c4bc3Fy6eHlp25ydG9PI2ZnY32LK3O6Hw4eZF7qYGUHBJdZduXwJBwdHmjVrrm2r36ABderWlcRcgW5uLbh4NR3PIUu4dDXD2OFUOUMm5qKiIlauXIm3tzceHh4EBASQnp5eZv+TJ08ydOhQOnbsiI+PD5999pleMZebmL/77juWLFnCoUOHAFi9ejWdOnWiR48eeHt78/HHH+t1EGPJSEsFoJ6Do057XXtHMtJSSumfQj0HpxJ97+Tnc+tmjk574LjXCBg5mJs52YyaNAMAaxsbPLx6YFOzlrbfL4e/Ifnqn3h4djfImMxBSkoyAE5O9XXanRydSE5OLnO7TVvfo2+//qWuc3RyIicnm9u3b2vbcnNvcSMnh8zMx28W+DCiDsQwMfRDUjIen8nB/QxZyli7di3R0dGEhYWxa9cukpOT8fcvvUSXmZnJmDFj6NChA3v37mX48OHMmTOHH3/8scLjlHnxb+/evcydO5fWrVuze/duBg0axP/93/8xadIkWrduze+//87SpUupXr06gwcPrvBAxqDOz0epVFK9upVOu5WVFQXqOyX738nHSqXS7fvX5wK1Wqd9UuA88vPz2bX1XebPGM/KLR9Rw9pGp8+50yfZEB5Kt159cPfsYYghmYX8/DyUSiVWVg+cd5UKdSnnXR/e3k9ja2vLogVzeTtkPgqFgiWLFqBQKCgsKDBE2MJCGapEoVariYyMJCQkhJ49ewIQERFBnz59iI2NpVOnTjr99+zZg62tLXPmzEGpVNKqVSsSEhLYvn073t7l1/rLnDFv376dBQsWEB0dzbJly9izZw8hISGMHTuWZ555Bn9/f2bPns2WLVsMMOTKoapRg+LiYoqKCnXaCwoKSiTRv/s/+I/874T8YP+WrdvR3s2DoAXLSb1+laM/fa+zPu7ozywMmkSrNh3wf3uhAUZjurZt2US3Lh7a5fq1axQXF1NY+MB5V6uxsSl53vVhV6cOa9Zt5NSpUzzdw4vnnu1F/QYNadOmLba1bQ0xDGGhFA+xlOfvEp3XfSW6xo0b4+zsTExMyRJdTEwMnp6eOqVRLy8vYmNjKS4uLvdYZSbmK1eu0KPH3Vmej48PSqWSdu3a6fTp2rVruV9Njc3+r6/SWRm6NaCsjLQSJQsAe8cGpfa1tqlJzVq2pCZfK5GA69o7YvuEHZnpadq27w/uY1nINNw6d2X2O2uoUcPaQCMyTUNeGcrHn36mXbp1vzubSE9L0+mXmpZaorzxMDq6e7Bv/0G+OfQTh378hWnTA0lKSqJxk6aPFL+wcAbKzH/nuvr1HyjROZVeoktOTi61b15eHtnZ2eUeq8zE3LhxY44dOwZAtWrV2L17Nw0bNtTp89VXX9GsWbNyD2BMzVu2xqZmLRJO3LsTIDX5GqnJ12jv1qlE/7Yu7iScjEWj0WjbTh2Poa1LR5RKJYlnThG+YCbZmfcuoKRcv8qN7CwaN2sBwE/f/Y/1K0J5tu9AZswLK1EasUR2derQtFkz7dKmbVtq1apFTMy9i3JXryZx7epVOnfx/EfHuHz5Em+8/ho52dnY29tjbW3NbzHHuHnzBt26PT5lIvHwlAqF3kt58vJKL9GpVCru3ClZosvPz0f1wL//vz+rHyiNloi5rBWjR49m7ty52lKFi4sLdnZ2wN0p/YQJE1i5cmWZhW9TYKVS8cJAPyI3rybu6M9cOHeaVYvfpn3HzrRu70pBQQFZmekU/FW+6NNvEDeys9iyaglJly+yPzqKH7/9L4NeHQFA5269qN/QmTVLQ7h84Q/OxJ9gZehMWrd3w8OrJ9mZGWxcuQi3zl15deQEbuRkkZWZTlZmOrdzbxnzVFQplUrFK0OHEbFiOT/9cJjTCfEEB06ni6cXbh3v3rFSoFaTnpZWonZfFmfnxqSmprBsySKuXL7M0V9/YdbMGfgO9qOpCU8OhPEZqpRhbW1daolOXUaJztraukQC/vtzRSW9Mi/++fn5Ubt2bbKysigsLKR69Xtdb968SXFxMdu2baNVq1YVDMe4Xhs9iaLCQt5dGkJRUaH2yT+As/EnWDBjPAtWbsbFvQt16tkTsmwd29etIGj8MBzrN2RK8EJcPe7WlGpY2zB3+Xr+34aVzHtrLAqFAq+ez/LGxLdQKpUc+/kQ+Xm3ORHzC2OHvKATR59+g5gYOK/Kx28sUwKmUVhYyOxZQRQWFtLjryf//nb8eBxjRo1g245IPL26Vri/6tWrs3bDZpa9s4hXXn6JJ+yeYNAgXyZMNt2JgTARBrr493fFIC0tTad6kJqaWqJkAdCgQQPSHiznpaZSs2ZNateuXe6xFJr7v7eXYfDgwURERNC8eXOd9s8//5wlS5bw66+/VrQLrZNJj8/M0VieaiAXwypbXc8pxg7hsZAXt+6R9/FHSl7Fnf7yVP2yZ7JqtZpu3boxf/58Bg0aBEBSUhJ9+vRh9+7duLu76/TftGkTe/fu5eDBg9o33M2aNYu0tDTee++9cuPQ6wETOzs7fH192bNnDwBZWVkEBATw9ttv4+vrq88uhBDCKAz1gIlKpWLYsGEsX76cw4cPEx8fz/Tp0/Hy8sLd3R21Wk1aWpq2XOHn50dmZibz58/n/PnzvP/++3z55ZeMGTOmwpj1eonRjh07iIyM5J133uHgwYOcPn0aR0dHdu/ejaurqz67EEIIozDkk9bTpt0t0QUF3S3R9erVi3nz7pbo4uLiGDFiBJGRkXTt2hUHBwe2bdvG4sWLeemll2jUqBFhYWF0717xw2Z6lTLg7hXJ2bNnc+DAAapXr86KFSvo16/fQw9MShmVT0oZlU9KGVXDEKWMC2n5evdt6Wgat7bqVco4fPgwL774IrGxsWzatIkJEyYQFBTE1KlTych4/J69F0KYD4t9idG4cePo1KkT+/bto3fv3kyZMoWoqCgSExPp37/0dxsIIYQpMNTtclVJrxrz6tWr6du3r06bi4sL0dHRrFq1qlICE0IIgzCljKsnvRLzg0n5byqViuDgkq9oFEIIU2FKL8DXl8X/aSkhxOPNlGrH+pLELISwaEpJzEIIYWrMLzNLYhZCWDQpZQghhIkxw7wsiVkIYdlkxiyEECZGYYaZWRKzEMKimV9alsQshLBwZjhhlsQshLBs8uSfEEKYGvPLy5KYhRCWzQzzsiRmIYRlU5phkVkSsxDCoplhXtbvRflCCCGqjsyYhRAWzRxnzJKYhRAWTW6XE0IIEyMzZiGEMDGSmIUQwsRIKUMIIUyMzJiFEMLEmGFelsQshLBwZpiZJTELISyaOT6SrdBoNBpjByGEEOIeeSRbCCFMjCRmIYQwMZKYhRDCxEhiFkIIEyOJWQghTIwkZiGEMDGSmB/ClStXcHd3Jzk52dihWJz9+/czaNAg3N3def7559myZQtFRUXGDsvifPLJJ/Tr1w9XV1f69+/Pp59+auyQRCnkARM9Xbx4kbFjx5KXl2fsUCzOoUOHCAwMZPbs2Tz99NMkJCQwd+5cCgoKmDx5srHDsxgHDx5kwYIFLFy4EE9PT3755Rfmzp1LnTp16NOnj7HDE/eRGbMedu7cycsvv8wTTzxh7FAsUlRUFD4+Prz++us0bdqUvn37MnLkSPbu3Wvs0CxKZmYm/v7+DB48mCZNmjBkyBBat27NkSNHjB2aeIAkZuDAgQO0adOGQ4cOAaDRaBg1ahS+vr6o1WoOHz7M4sWLCQ4ONnKk5qu8czxhwgSmTJmi01+pVHLjxg1jhGrWyjvPL7/8MuPHjwegsLCQAwcOcP78eXr27GnMkEVpNEKj0Wg006dP1/Tu3Vtz69Ytzc6dOzUdO3bUJCYm6vT55ZdfNK1bt9Zcv37dSFGaN33OsUaj0dy8eVPTq1cvzVtvvWWEKM1fRef5999/17Rr107TunVrzZw5czTFxcVGjFaURhLzX7KzszXe3t6aqVOnatzc3DRRUVEl+khifjT6nOPbt29rhg8frvHy8tIkJSUZIUrzV9F5zszM1CQkJGg++eQTjYeHhyYiIsJIkYqySGK+z7fffqtp3bq1ZvTo0aWul8T86Mo7xxkZGZpXX31V07lzZ82JEyeMEJ3lqOhn+W+bN2/WuLm5aQoLC6soMqEPqTHfJz4+nmrVqpGQkEBmZqaxw7FIZZ3jpKQkXnvtNZKSkti1axdubm5GjNL8lXaejx49yunTp3X6tWnThvz8fHJycowRpiiDJOa/nDp1io0bNxIeHo6joyPz5s0zdkgWp6xznJGRwYgRIyguLuajjz6ibdu2Ro7UvJV1nrdu3crq1at1+v7+++/Y29tTt25dY4QqyiD3MQNqtZrg4GD+9a9/0b9/fxo3bsyrr77KZ599xksvvWTs8CxCeef422+/JSsri507d2JtbU1aWhoACoUCBwcHI0duXso7zyNHjuTNN99k27ZtPP/88xw9epRt27Yxa9YsFGb4MnmLZuxaiilYtmyZxtPTU5OamqptW7JkiaZLly469WSpMf9z5Z3jtm3balq3bl1iadeunREjNk8V/SwfPHhQM2DAAI2rq6vGx8dH8/HHHxsxWlEW+QsmQghhYqTGLIQQJkYSsxBCmBhJzEIIYWIkMQshhImRxCyEECZGErMQQpgYScxCCGFiJDELIYSJkcQshBAm5v8D9W5tMuCgHDsAAAAASUVORK5CYII=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://seaborn.pydata.org/api.html"&gt;API References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="seaborn"></category><category term="資料視覺化"></category></entry><entry><title>SQLite 筆記</title><link href="https://leemeng.tw/sqlite-note.html" rel="alternate"></link><published>2018-02-23T22:00:00+09:00</published><updated>2018-02-23T22:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-02-23:/sqlite-note.html</id><summary type="html">&lt;p&gt;這篇主要紀錄使用 SQLite shell 下 SQL Query 的指令。基本上在 shell 裡頭都是用 dot-command, 使用 .help 可以顯示所有可用的指令。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Table-of-Contents"&gt;Table of Contents&lt;a class="anchor-link" href="#Table-of-Contents"&gt;&amp;para;&lt;/a&gt;&lt;/h1&gt;&lt;div class="toc" style="margin-top: 1em;"&gt;&lt;ul class="toc-item" id="toc-level0"&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="Prettier-output-1" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#Prettier-output"&gt;Prettier output&lt;/a&gt;&lt;/span&gt;&lt;ul class="toc-item"&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="調整每一個-column-寬度-1.1" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#調整每一個-column-寬度"&gt;調整每一個 column 寬度&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="在-sqlite3-shell-裡清空畫面-2" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#在-sqlite3-shell-裡清空畫面"&gt;在 sqlite3 shell 裡清空畫面&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="使用-SQL-script-建立-tables-3" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#使用-SQL-script-建立-tables"&gt;使用 SQL script 建立 tables&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示目前的-tables-4" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示目前的-tables"&gt;顯示目前的 tables&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示-table-schema-5" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示-table-schema"&gt;顯示 table schema&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示-indexes-6" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示-indexes"&gt;顯示 indexes&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇主要紀錄使用 SQLite shell 下 SQL Query 的指令。基本上在 shell 裡頭都是用 dot-command, 使用 &lt;code&gt;.help&lt;/code&gt; 可以顯示所有可用的指令.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Prettier-output"&gt;Prettier output&lt;a class="anchor-link" href="#Prettier-output"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在 command-line program 裡頭使用的 response format&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.mode column
.headers on

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example output&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Code        Name        Price       Manufacturer
----------  ----------  ----------  ------------
7           CD drive    90          2           
9           Toner cart  66          3           

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="調整每一個-column-寬度"&gt;調整每一個 column 寬度&lt;a class="anchor-link" href="#調整每一個-column-寬度"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;.width 5 18 15

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;缺點是不同的 tables, 不同的 columns 需要的寬度不同, 要自己調整
要重置設定:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.width 0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在-sqlite3-shell-裡清空畫面_1"&gt;在 sqlite3 shell 裡清空畫面&lt;a class="anchor-link" href="#在-sqlite3-shell-裡清空畫面"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;要看 OS 決定實際的 shell command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.shell clear

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了 &lt;code&gt;clear&lt;/code&gt; 以外, 其他 shell command都能使用, e.g.,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.shell cd&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用-SQL-script-建立-tables"&gt;使用 SQL script 建立 tables&lt;a class="anchor-link" href="#使用-SQL-script-建立-tables"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;比方我們有一個 &lt;code&gt;create_tables.sql&lt;/code&gt; 內容是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE Departments (
  Code INTEGER PRIMARY KEY,
  Name varchar(255) NOT NULL ,
  Budget decimal NOT NULL 
);

INSERT INTO Departments(Code,Name,Budget) VALUES(14,'IT',65000);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我們可以用 &lt;code&gt;.read&lt;/code&gt; dot-command 在 shell 跑該 script 建立 &lt;code&gt;Department&lt;/code&gt; table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.read create_tables.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示目前的-tables"&gt;顯示目前的 tables&lt;a class="anchor-link" href="#顯示目前的-tables"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.tables&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示-table-schema"&gt;顯示 table schema&lt;a class="anchor-link" href="#顯示-table-schema"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.schema &amp;lt;TABLE_NAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示-indexes"&gt;顯示 indexes&lt;a class="anchor-link" href="#顯示-indexes"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.indexes

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 Table T 的 Column C 建立 index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE INDEX &amp;lt;INDEX_NAME&amp;gt; ON T(C);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;砍掉 index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DROP INDEX &amp;lt;INDEX_NAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="SQL"></category><category term="SQLite"></category><category term="資料庫"></category></entry><entry><title>Find Word Semantic by Using Word2vec in TensorFlow</title><link href="https://leemeng.tw/find-word-semantic-by-using-word2vec-in-tensorflow.html" rel="alternate"></link><published>2017-09-30T18:30:00+09:00</published><updated>2017-09-30T18:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-30:/find-word-semantic-by-using-word2vec-in-tensorflow.html</id><summary type="html">&lt;p&gt;Naive Word2vec implementation using Tensorflow&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal of this assignment is to train a Word2Vec skip-gram model over &lt;a href="http://mattmahoney.net/dc/textdata"&gt;Text8&lt;/a&gt; data using Tensorflow.&lt;/p&gt;
&lt;p&gt;Word2vec is a kind of vector space model (VSM) in natural language processing (NLP) where the core assumption/intuition is that words that appear in similar 'context' share similar meaning and they should be near in the vector space. So what word2vec trying to do is to find a vector representation (embedding) for each word in our training corpus where words with similar meanings are near in the vector space.&lt;/p&gt;
&lt;center&gt;&lt;img src="images/word2vec_linear_relationship.png" style="width:80%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 1&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: words' representation in 2D vector space&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Unlike supervised learning, we don't have labels that tell us 'kitten' = 'cat'. So how do we train a model that will learn the relationship between these two words?&lt;/p&gt;
&lt;p&gt;Recap the assumption mentioned before, words with similar meaning tend to appear in similar context. Because 'kitten' and 'cat' appear in similar context, if we can train a model to predict the context of the target word 'cat' and 'kitten' respectively, model should learn a similar representation for both 'kitten' and 'cat' because they produce similar context.&lt;/p&gt;
&lt;center&gt;&lt;img src="images/cat_vs_kitten.png" style="width:60%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 2&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Training data generated from target word and context&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As shown above, for each words like 'cat' in raw text, we will treat them as &lt;strong&gt;target word&lt;/strong&gt; and the words surrounding it as &lt;strong&gt;context&lt;/strong&gt; and construct the training instances (x, y) where x is target word and y is one of the word in context. And the definition of 'context' is decided by the parameter 'window size'.&lt;/p&gt;
&lt;p&gt;First, let's load the text data and build the training data in order to train our model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Libraries"&gt;Libraries&lt;a class="anchor-link" href="#Libraries"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# These are all the modules we'll be using later. Make sure you can import them&lt;/span&gt;
&lt;span class="c1"&gt;# before proceeding further.&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;collections&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;zipfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="c1"&gt;# from matplotlib import pylab # use pyplot instead&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves.urllib.request&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.manifold&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;TSNE&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tqdm&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ggplot'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Raw-text-data"&gt;Raw text data&lt;a class="anchor-link" href="#Raw-text-data"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Download-/-load-data"&gt;Download / load data&lt;a class="anchor-link" href="#Download-/-load-data"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Download the data from the source website if necessary. will store the zip file in the 'datasets' subdirectory.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'http://mattmahoney.net/dc/'&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;maybe_download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;expected_bytes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Download a file into 'datasets' sub-directory&lt;/span&gt;
&lt;span class="sd"&gt;    if not present, and make sure it's the right size.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;rel_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'datasets/&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# if file in not found, download it&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rel_path&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rel_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;statinfo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rel_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;expected_bytes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Found and verified &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;. size: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rel_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Failed to verify '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                        &lt;span class="s1"&gt;'. Can you get to it with a browser?'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;rel_path&lt;/span&gt;


&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'text8.zip'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;31344016&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Found and verified datasets/text8.zip. size: 31344016
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Turn-data-into-words"&gt;Turn data into words&lt;a class="anchor-link" href="#Turn-data-into-words"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Read the data into a string.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;read_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Extract the first file enclosed in a zip file as a list of words"""&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;zipfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ZipFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;namelist&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;


&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;read_data&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Data size &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Data size 17005207
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Look-into-text-corpus"&gt;Look into text corpus&lt;a class="anchor-link" href="#Look-into-text-corpus"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The 'data size' above mean how many words we have in the data. That is, there are about 17 millions words!&lt;br/&gt;
Let's show some parts of the text data to make some sense of it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Some phrases which include word 'cat' with window size = '2'.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'cat'&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'cats'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cats&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;cats&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;the cartoon cat garfield would
amount of cats that roam
politicians autodidacts cat lovers firearm
and activists cat lovers epistemologists
force australia cat six two
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Some phrases which include word 'kitten' with window size = '2'.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;kitten&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'kitten'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kitten&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;kitten&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;put the kitten nermal in
s sex kitten in the
of tom kitten one nine
as a kitten rudolph grey
called a kitten which is
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Create-training-data_1"&gt;Create training data&lt;a class="anchor-link" href="#Create-training-data"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In order to let TensorFlow make use of the text corpus, we have to transform the text corpus into sequence of numbers. The way to achieve this to build a dictionary which map every word to a unique number and use that dictionary to transform the corpus into number-based data.&lt;/p&gt;
&lt;center&gt;&lt;img src="images/turn_corpus_into_numbers.png" style="width:60%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 3&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Build dictionary and turn text into numbers&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Notice that some rare words may appear very few times in the entire text corpus. We may want to exclude these terms to keep our dictionary in a reasonable size. In order to do this, we will build the dictionary and view these terms as UNK tokens. UNK means unknown word that doesn't exist in the vocabulary set and the default number of a UNK in dictionary is 0 as shown above.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Decide-dictionary-size"&gt;Decide dictionary size&lt;a class="anchor-link" href="#Decide-dictionary-size"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Depend on the size of the vocabulary, we will construct a dictionary for top &lt;strong&gt;vocabulary_size - 1&lt;/strong&gt; common words. For example, if the &lt;code&gt;vocabulary_size = 50000&lt;/code&gt;, we will first count the frequencies of every word appeared in the text corpus and put the most common 49,999 terms into our vocabulary and make the rest of words as UNK token. ( thus the 50,000 th term in the vocabulary).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-dictionary-and-transform-text-corpus-into-sequence-of-numbers"&gt;Build dictionary and transform text corpus into sequence of numbers&lt;a class="anchor-link" href="#Build-dictionary-and-transform-text-corpus-into-sequence-of-numbers"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Build training data for word2vec from a string including&lt;/span&gt;
&lt;span class="sd"&gt;    sequences of words divided by spaces.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    Parameters:&lt;/span&gt;
&lt;span class="sd"&gt;    -----------&lt;/span&gt;
&lt;span class="sd"&gt;    words: a string with every word devided by spaces&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;    --------&lt;/span&gt;
&lt;span class="sd"&gt;    dictionary: a dict with word as key and a unique number(index)&lt;/span&gt;
&lt;span class="sd"&gt;        as their value. dictionary[word] = idx&lt;/span&gt;
&lt;span class="sd"&gt;    reverse_dictionary: a dict with index as key and the corresponding &lt;/span&gt;
&lt;span class="sd"&gt;        word as value. reverse_dictionary[idx] = word&lt;/span&gt;
&lt;span class="sd"&gt;    counts: a list contain tuples (word, frequency) sorted descendingly &lt;/span&gt;
&lt;span class="sd"&gt;        by frequency while use ('UNK', unk_count) as first tuple.&lt;/span&gt;
&lt;span class="sd"&gt;    data: a list contain indices of the original words in the parameters&lt;/span&gt;
&lt;span class="sd"&gt;        'words'.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="c1"&gt;# count term frequencies and choose the most frequent &lt;/span&gt;
    &lt;span class="c1"&gt;# terms of vocabulary_size&lt;/span&gt;
    &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s1"&gt;'UNK'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;collections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Counter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;most_common&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="c1"&gt;# index term by their frequency. while UKN is indexed as 0,&lt;/span&gt;
    &lt;span class="c1"&gt;# the term with most frequencies is indexed as 1, the term with 2th frequencies&lt;/span&gt;
    &lt;span class="c1"&gt;# is indexed as 2, ...&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# turn the text corpus into a sequence of number where each number is the &lt;/span&gt;
    &lt;span class="c1"&gt;# index of the original term in 'dictionary' dict and mark those UNK's number&lt;/span&gt;
    &lt;span class="c1"&gt;# as 0 which indicate that they're unknown words&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;unk_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="c1"&gt;# dictionary['UNK']&lt;/span&gt;
            &lt;span class="n"&gt;unk_count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unk_count&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;index&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
    &lt;span class="c1"&gt;# update UNK's count in corpus&lt;/span&gt;
    &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;unk_count&lt;/span&gt;
    
    &lt;span class="c1"&gt;# create reverse dict to enable lookup the original word by their index&lt;/span&gt;
    &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;build_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Most common words (+UNK) in text corpus:&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Most common words (+UNK) in text corpus:
[['UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="See-transformed-text-corpus"&gt;See transformed text corpus&lt;a class="anchor-link" href="#See-transformed-text-corpus"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'"&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s1"&gt;was transformed into&lt;/span&gt;&lt;span class="se"&gt;\n\n&lt;/span&gt;&lt;span class="s1"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;"'&lt;/span&gt;\
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sample_idx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sample_idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
              &lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;sample_idx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sample_idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;  &lt;span class="c1"&gt;# Hint to reduce memory.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;"american individualist anarchism benjamin tucker in one eight two five"

was transformed into

"64 10276 5234 3248 9615 5 4 13 10 16"
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Function-to-generate-a-training-batch-for-the-skip-gram-model._1"&gt;Function to generate a training batch for the skip-gram model.&lt;a class="anchor-link" href="#Function-to-generate-a-training-batch-for-the-skip-gram-model."&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;As usual, we will use mini-batch GD to update our model's parameters.&lt;br/&gt;
Other than batch_size, we also have to decide the range of context surrounding target word (skip_window) and how many training instances are we going to create from a single (target, context) pair.&lt;/p&gt;
&lt;center&gt;&lt;img src="images/mini_batch_by_different_num_skips.png" style="width:70%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 4&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Build mini-batches by different num_skips&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# global variable to randomize mini-batch&lt;/span&gt;
&lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Generate a mini-batch containing (target_word, context) pairs&lt;/span&gt;
&lt;span class="sd"&gt;    of `batch_size`. &lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    Parameters:&lt;/span&gt;
&lt;span class="sd"&gt;    -----------&lt;/span&gt;
&lt;span class="sd"&gt;    batch_size: mini_batch's size, typically 16 &amp;lt;= batch_size &amp;lt;= 512&lt;/span&gt;
&lt;span class="sd"&gt;    num_skips: how many times to reuse an input/target word to &lt;/span&gt;
&lt;span class="sd"&gt;        generate a label. &lt;/span&gt;
&lt;span class="sd"&gt;    skip_window: how many words to consider left and right.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;    --------&lt;/span&gt;
&lt;span class="sd"&gt;    batch: a list of target words&lt;/span&gt;
&lt;span class="sd"&gt;    labels: a list of context words corresponding to target words&lt;/span&gt;
&lt;span class="sd"&gt;        in batch&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="k"&gt;global&lt;/span&gt; &lt;span class="n"&gt;data_index&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt;
    &lt;span class="n"&gt;batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# initialize first (target, context) sequence&lt;/span&gt;
    &lt;span class="c1"&gt;# = [ skip_window target skip_window ]&lt;/span&gt;
    &lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;buffer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;collections&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;deque&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# for every target word, &lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt;  &lt;span class="c1"&gt;# target label at the center of the buffer&lt;/span&gt;
        &lt;span class="n"&gt;targets_to_avoid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        
        &lt;span class="c1"&gt;# generate #num_skips of training instances&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="c1"&gt;# randomly choose a context word that hasn't been chosen yet&lt;/span&gt;
            &lt;span class="c1"&gt;# exclude target word by default&lt;/span&gt;
            &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;targets_to_avoid&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;target&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;targets_to_avoid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            
        &lt;span class="c1"&gt;# shift to next (target, context) sequence&lt;/span&gt;
        &lt;span class="n"&gt;buffer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data_index&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="c1"&gt;# randomize the start location of every mini-batch&lt;/span&gt;
        &lt;span class="c1"&gt;# by adding one offset&lt;/span&gt;
        &lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;


&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'data: "&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;"'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;di&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;di&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]:&lt;/span&gt;
    &lt;span class="n"&gt;data_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;generate_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;(target, context) with num_skips = &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; and skip_window = &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;:'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                           &lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt; \
                   &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;))])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;data: "anarchism originated as a term of abuse first"

(target, context) with num_skips = 2 and skip_window = 1:
('originated', 'anarchism')
('originated', 'as')
('as', 'originated')
('as', 'a')
('a', 'term')
('a', 'as')
('term', 'of')
('term', 'a')

(target, context) with num_skips = 4 and skip_window = 2:
('as', 'term')
('as', 'anarchism')
('as', 'a')
('as', 'originated')
('a', 'as')
('a', 'originated')
('a', 'term')
('a', 'of')
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Word2Vec-skip-gram-model."&gt;Word2Vec skip-gram model.&lt;a class="anchor-link" href="#Word2Vec-skip-gram-model."&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;img src="images/word2vec_model.png" style="width:70%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 5&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Word2vec model&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Computation-graph"&gt;Computation graph&lt;a class="anchor-link" href="#Computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;embedding_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;  &lt;span class="c1"&gt;# Dimension of the embedding vector.&lt;/span&gt;
&lt;span class="n"&gt;skip_window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="c1"&gt;# How many words to consider left and right.&lt;/span&gt;
&lt;span class="n"&gt;num_skips&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;  &lt;span class="c1"&gt;# How many times to reuse an input to generate a label.&lt;/span&gt;
&lt;span class="c1"&gt;# We pick a random validation set to sample nearest neighbors. here we limit the&lt;/span&gt;
&lt;span class="c1"&gt;# validation samples to the words that have a low numeric ID, which by&lt;/span&gt;
&lt;span class="c1"&gt;# construction are also the most frequent.&lt;/span&gt;
&lt;span class="n"&gt;valid_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;  &lt;span class="c1"&gt;# Random set of words to evaluate similarity on.&lt;/span&gt;
&lt;span class="n"&gt;valid_window&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;  &lt;span class="c1"&gt;# Only pick dev samples in the head of the distribution.&lt;/span&gt;
&lt;span class="n"&gt;valid_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_window&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;valid_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;num_sampled&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;  &lt;span class="c1"&gt;# Number of negative examples to sample.&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;device&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'/cpu:0'&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data.&lt;/span&gt;
    &lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_examples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="n"&gt;embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random_uniform&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;softmax_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;embedding_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;embedding_size&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="n"&gt;softmax_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Model.&lt;/span&gt;
    &lt;span class="c1"&gt;# Look up embeddings for inputs.&lt;/span&gt;
    &lt;span class="n"&gt;embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_lookup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# Compute the softmax loss, using a sample of the negative labels each time.&lt;/span&gt;
    &lt;span class="c1"&gt;# this is how we speed up training phase &lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sampled_softmax_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;softmax_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;biases&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;softmax_biases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;num_sampled&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_sampled&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;num_classes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;vocabulary_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="c1"&gt;# Note: The optimizer will optimize the softmax_weights AND the embeddings.&lt;/span&gt;
    &lt;span class="c1"&gt;# This is because the embeddings are defined as a variable quantity and the&lt;/span&gt;
    &lt;span class="c1"&gt;# optimizer's `minimize` method will by default modify all variable quantities&lt;/span&gt;
    &lt;span class="c1"&gt;# that contribute to the tensor it is passed.&lt;/span&gt;
    &lt;span class="c1"&gt;# See docs on `tf.train.Optimizer.minimize()` for more details.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AdagradOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Compute the similarity between minibatch examples and all embeddings.&lt;/span&gt;
    &lt;span class="c1"&gt;# We use the cosine distance:&lt;/span&gt;
    &lt;span class="n"&gt;norm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_dims&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;normalized_embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embeddings&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;
    &lt;span class="n"&gt;valid_embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding_lookup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normalized_embeddings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                              &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;similarity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_embeddings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;normalized_embeddings&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Train-the-model"&gt;Train the model&lt;a class="anchor-link" href="#Train-the-model"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100001&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Initialized'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;average_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;generate_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_skips&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                  &lt;span class="n"&gt;skip_window&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;average_loss&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;average_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;average_loss&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt;
            &lt;span class="c1"&gt;# The average loss is an estimate of the loss over the last 2000 batches.&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Average loss at step &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;average_loss&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;average_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="c1"&gt;# note that this is expensive (~20% slowdown if computed every 500 steps)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sim&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;similarity&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;valid_word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;valid_examples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
                &lt;span class="n"&gt;top_k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;  &lt;span class="c1"&gt;# number of nearest neighbors&lt;/span&gt;
                &lt;span class="n"&gt;nearest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argsort&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;top_k&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Nearest to &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;:'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;valid_word&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top_k&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                    &lt;span class="n"&gt;close_word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;nearest&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
                    &lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;,'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;close_word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;final_embeddings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalized_embeddings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="2b0af47c-2643-4c50-ad71-70c956d675d8"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#2b0af47c-2643-4c50-ad71-70c956d675d8');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "479bac87e8864793a2657306231c3b2a", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Average loss at step 0: 7.942154
Nearest to up: refit, airmen, unexplored, scharnhorst, histones, envelopes, wanna, wick,
Nearest to many: herbivorous, kazimierz, surgeries, juliette, merovingian, christadelphians, experimentation, strauss,
Nearest to people: chicken, zulu, glaucus, temporarily, groundbreaking, mapuche, varnish, vinod,
Nearest to some: platelets, mauritania, anzus, soaemias, plankton, orcs, cegep, danzig,
Nearest to was: blotter, continuously, gulls, lineages, turbines, cardano, honky, gcb,
Nearest to and: haller, potion, rickshaw, fares, soldier, mariam, sponsor, irs,
Nearest to in: wrench, atwood, boys, fermat, uhf, midrash, hallucinogens, deflate,
Nearest to be: infertility, olaf, faramir, dxf, latino, clem, aia, cation,
Nearest to all: stripe, abbreviation, nationalised, maoi, hermann, three, lara, jay,
Nearest to than: antiderivatives, deduce, brainiac, wry, propel, requested, selangor, transposed,
Nearest to system: rmi, devine, elite, deism, transgressions, bows, primer, undoubtedly,
Nearest to were: ange, oh, widest, fidel, kristallnacht, predicates, coprocessor, surnames,
Nearest to see: astounding, equilateral, concubines, syllables, lackluster, transoxiana, kasparov, smooth,
Nearest to that: figurative, cluster, wendell, horch, cards, prinz, ellesmere, maximilian,
Nearest to s: endosperm, saberhagen, pipelined, recantation, calcium, infrastructural, manchuria, spears,
Nearest to will: suppressive, rotations, predefined, dessau, confederation, hovered, radiohead, apicomplexa,
Average loss at step 2000: 4.364343
Average loss at step 4000: 3.857699
Average loss at step 6000: 3.785119
Average loss at step 8000: 3.686496
Average loss at step 10000: 3.616513
Nearest to up: scharnhorst, refit, arabs, concubines, zeeland, airmen, calibers, diem,
Nearest to many: some, kazimierz, herbivorous, timber, poorly, revitalize, psychoanalyst, studies,
Nearest to people: ach, la, semester, several, glaucus, gediminas, mechanism, yupik,
Nearest to some: many, overbearing, firmer, oracles, dissonant, limes, soaemias, cpu,
Nearest to was: is, has, had, were, by, been, be, are,
Nearest to and: or, s, but, scriptores, who, of, in, alans,
Nearest to in: on, at, of, from, with, between, by, during,
Nearest to be: have, was, is, do, receiving, latino, subclass, chisel,
Nearest to all: marketed, maoi, abbreviation, stripe, protectors, nationalised, lara, chadic,
Nearest to than: haer, deduce, caucus, omniglot, casings, propel, selangor, softer,
Nearest to system: rmi, devine, elite, primer, hcl, try, deism, bows,
Nearest to were: are, was, tiu, have, adware, ragged, popularizer, macrobiotic,
Nearest to see: william, concubines, astounding, transoxiana, but, bullough, pigeon, artistic,
Nearest to that: which, ellesmere, she, it, pectoral, also, who, breaches,
Nearest to s: and, vu, his, the, was, carlist, tanoana, chulainn,
Nearest to will: may, would, jews, barbarism, predefined, could, confederation, receiving,
Average loss at step 12000: 3.606183
Average loss at step 14000: 3.572916
Average loss at step 16000: 3.410224
Average loss at step 18000: 3.453891
Average loss at step 20000: 3.539739
Nearest to up: unvoiced, scharnhorst, zeeland, him, refit, arabs, cesium, wick,
Nearest to many: some, these, several, other, kazimierz, studies, all, psychoanalyst,
Nearest to people: languages, gediminas, countries, glaucus, eplf, several, those, temporarily,
Nearest to some: many, these, their, olav, overbearing, his, its, most,
Nearest to was: is, has, were, had, became, be, chisel, been,
Nearest to and: or, but, at, which, from, in, however, for,
Nearest to in: at, on, during, from, for, by, with, and,
Nearest to be: have, been, was, were, campaigner, by, receiving, combination,
Nearest to all: these, marketed, maoi, marshals, many, lara, escalation, agate,
Nearest to than: or, deduce, much, trough, haer, brainiac, tug, spalding,
Nearest to system: hcl, rmi, elite, devine, oleg, bows, henotheism, primer,
Nearest to were: are, was, had, tiu, have, be, by, is,
Nearest to see: atzma, diaconate, transoxiana, syllables, showcasing, lackluster, bullough, rabbinical,
Nearest to that: which, but, breaches, because, it, ietf, this, ellesmere,
Nearest to s: pu, purr, tanoana, forum, traveller, predicated, plasmodium, integrator,
Nearest to will: would, may, can, could, should, to, cannot, geographic,
Average loss at step 22000: 3.502537
Average loss at step 24000: 3.485267
Average loss at step 26000: 3.483680
Average loss at step 28000: 3.478223
Average loss at step 30000: 3.503296
Nearest to up: him, begin, scharnhorst, them, unvoiced, refit, zeeland, calibers,
Nearest to many: some, several, these, their, its, all, various, the,
Nearest to people: countries, those, languages, dhea, temporarily, ach, vlsi, eplf,
Nearest to some: many, these, several, the, their, olav, limes, this,
Nearest to was: is, were, had, has, became, been, when, by,
Nearest to and: or, who, in, but, from, of, rehearsal, tsunamis,
Nearest to in: during, at, from, of, on, since, between, and,
Nearest to be: have, is, been, are, were, mustelids, aldiss, impurity,
Nearest to all: these, lara, some, many, inhabiting, several, maoi, marketed,
Nearest to than: much, or, no, deduce, trough, spalding, tug, haer,
Nearest to system: hcl, group, devine, francisco, oleg, rmi, raccoons, master,
Nearest to were: are, was, have, had, is, tiu, dowager, been,
Nearest to see: diaconate, include, atzma, showcasing, slider, transoxiana, rent, syllables,
Nearest to that: which, this, however, but, what, where, kilometre, if,
Nearest to s: his, forum, isbn, her, ancestral, insulated, sucking, and,
Nearest to will: can, would, could, may, should, must, cannot, to,
Average loss at step 32000: 3.500015
Average loss at step 34000: 3.495233
Average loss at step 36000: 3.458392
Average loss at step 38000: 3.301554
Average loss at step 40000: 3.431673
Nearest to up: out, him, them, unvoiced, back, arabs, down, begin,
Nearest to many: some, several, these, various, those, their, certain, such,
Nearest to people: languages, countries, those, quintessential, baum, serif, dhea, areas,
Nearest to some: many, these, any, several, olav, their, those, most,
Nearest to was: is, had, were, became, has, severing, being, been,
Nearest to and: or, but, while, cynical, subsystem, where, mus, in,
Nearest to in: from, of, during, on, for, and, bubbled, at,
Nearest to be: been, have, were, are, is, continue, was, shotguns,
Nearest to all: lara, these, both, two, many, travellers, lobster, citizen,
Nearest to than: or, much, no, spalding, deduce, even, brainiac, significance,
Nearest to system: systems, code, crusading, group, bows, smuts, hcl, completions,
Nearest to were: are, have, was, tiu, had, be, been, being,
Nearest to see: include, pigeon, syllables, algardi, diaconate, theroux, slider, lada,
Nearest to that: which, however, what, this, because, where, it, oro,
Nearest to s: his, forum, levine, fl, fender, isbn, tyr, empowerment,
Nearest to will: would, can, could, may, should, must, might, cannot,
Average loss at step 42000: 3.433565
Average loss at step 44000: 3.451384
Average loss at step 46000: 3.450792
Average loss at step 48000: 3.354962
Average loss at step 50000: 3.388338
Nearest to up: out, them, down, him, disproven, off, back, unvoiced,
Nearest to many: some, several, these, various, those, most, such, other,
Nearest to people: countries, languages, roots, vlsi, men, gediminas, those, scholars,
Nearest to some: many, these, several, olav, most, their, any, the,
Nearest to was: is, has, were, became, had, been, being, be,
Nearest to and: but, or, in, while, of, from, whose, eurasia,
Nearest to in: from, during, of, since, on, and, by, within,
Nearest to be: have, been, were, was, is, become, being, are,
Nearest to all: both, these, many, lara, writs, every, citizen, diffuses,
Nearest to than: or, much, even, bam, deduce, while, spalding, significance,
Nearest to system: systems, crusading, bows, code, hcl, renderings, smuts, group,
Nearest to were: are, was, have, tiu, be, had, those, been,
Nearest to see: include, pigeon, diaconate, algardi, theroux, bloomington, showcasing, pwnage,
Nearest to that: which, however, what, often, uv, this, where, honoring,
Nearest to s: whose, isbn, romanian, his, cleaner, adheres, fender, predicated,
Nearest to will: would, could, can, may, must, should, shall, might,
Average loss at step 52000: 3.437301
Average loss at step 54000: 3.427909
Average loss at step 56000: 3.438053
Average loss at step 58000: 3.394049
Average loss at step 60000: 3.394188
Nearest to up: out, them, down, him, off, back, disproven, replace,
Nearest to many: some, several, these, various, all, most, such, other,
Nearest to people: those, countries, men, scholars, roots, gediminas, others, vlsi,
Nearest to some: many, several, these, olav, most, any, each, this,
Nearest to was: is, had, became, has, were, been, be, although,
Nearest to and: or, but, including, than, owning, shutting, with, sagan,
Nearest to in: during, within, including, of, at, since, throughout, anew,
Nearest to be: been, have, are, is, was, were, refer, become,
Nearest to all: many, these, both, rediscovery, some, timers, menial, various,
Nearest to than: or, much, but, spalding, and, deduce, no, far,
Nearest to system: systems, code, crusading, group, hcl, software, depth, smuts,
Nearest to were: are, was, had, have, tiu, those, haired, be,
Nearest to see: include, diaconate, but, can, bloomington, pwnage, according, algardi,
Nearest to that: which, however, this, what, where, it, often, ellesmere,
Nearest to s: whose, infrastructural, isbn, tanoana, arbenz, flybys, vladimir, geographic,
Nearest to will: would, can, could, may, must, should, might, cannot,
Average loss at step 62000: 3.243753
Average loss at step 64000: 3.259946
Average loss at step 66000: 3.404854
Average loss at step 68000: 3.393782
Average loss at step 70000: 3.359670
Nearest to up: out, them, down, off, back, him, disproven, arabs,
Nearest to many: some, several, these, various, all, most, olav, numerous,
Nearest to people: men, those, countries, scholars, children, peoples, languages, historians,
Nearest to some: many, several, these, olav, various, all, those, any,
Nearest to was: is, were, has, had, became, severing, been, when,
Nearest to and: or, while, but, which, like, stockade, than, unclassified,
Nearest to in: within, during, on, throughout, through, from, for, at,
Nearest to be: been, were, is, have, being, become, are, fully,
Nearest to all: many, some, both, every, any, montag, various, these,
Nearest to than: or, no, spalding, much, while, but, and, resign,
Nearest to system: systems, crusading, bred, depth, group, hcl, smuts, code,
Nearest to were: are, was, have, tiu, had, be, those, been,
Nearest to see: include, diaconate, orators, list, algardi, according, but, fatality,
Nearest to that: which, however, what, this, but, where, because, also,
Nearest to s: pu, infrastructural, isbn, whose, chulainn, codifying, sequestered, purr,
Nearest to will: would, could, may, can, should, must, might, shall,
Average loss at step 72000: 3.372420
Average loss at step 74000: 3.350309
Average loss at step 76000: 3.322349
Average loss at step 78000: 3.355263
Average loss at step 80000: 3.377625
Nearest to up: out, off, down, them, him, disproven, back, arabs,
Nearest to many: several, some, various, these, most, numerous, those, both,
Nearest to people: men, children, countries, those, words, members, peoples, scholars,
Nearest to some: many, several, various, these, olav, most, both, any,
Nearest to was: is, were, has, had, became, been, being, when,
Nearest to and: or, but, including, than, while, globalsecurity, rehearsal, lances,
Nearest to in: during, within, on, until, at, since, after, through,
Nearest to be: been, have, become, refer, being, were, is, proceed,
Nearest to all: both, every, various, any, many, some, these, aguilera,
Nearest to than: or, much, but, while, and, spalding, resign, even,
Nearest to system: systems, crusading, smuts, software, code, familias, nonpartisan, game,
Nearest to were: are, was, had, have, those, tiu, being, be,
Nearest to see: include, according, diaconate, but, orators, includes, list, eth,
Nearest to that: which, however, where, ellesmere, markham, what, this, thus,
Nearest to s: pu, isbn, whose, chulainn, mondeo, infrastructural, electorates, adheres,
Nearest to will: would, could, can, may, should, must, might, cannot,
Average loss at step 82000: 3.407648
Average loss at step 84000: 3.411925
Average loss at step 86000: 3.389199
Average loss at step 88000: 3.359499
Average loss at step 90000: 3.365950
Nearest to up: out, off, down, them, back, him, disproven, arabs,
Nearest to many: some, several, various, these, all, numerous, most, those,
Nearest to people: children, men, women, persons, religions, god, screenwriters, countries,
Nearest to some: many, several, these, all, any, various, those, most,
Nearest to was: is, became, had, were, has, been, being, be,
Nearest to and: or, but, while, emory, consistory, including, however, who,
Nearest to in: within, during, around, of, throughout, under, between, near,
Nearest to be: have, been, become, is, produce, was, refer, simulate,
Nearest to all: many, both, some, every, various, several, each, any,
Nearest to than: or, much, spalding, no, even, resign, showered, considerably,
Nearest to system: systems, crusading, process, program, group, mee, unit, brockovich,
Nearest to were: are, was, had, have, while, tiu, those, been,
Nearest to see: list, diaconate, include, includes, references, refer, external, kliper,
Nearest to that: which, however, what, but, markham, autos, where, ellesmere,
Nearest to s: whose, isbn, infrastructural, his, pu, tyr, vladimir, mondeo,
Nearest to will: would, could, can, may, must, should, might, cannot,
Average loss at step 92000: 3.398944
Average loss at step 94000: 3.258866
Average loss at step 96000: 3.356221
Average loss at step 98000: 3.242518
Average loss at step 100000: 3.359612
Nearest to up: out, off, down, him, back, them, arabs, begin,
Nearest to many: several, some, these, various, numerous, those, all, few,
Nearest to people: persons, men, children, someone, women, countries, players, scholars,
Nearest to some: many, several, these, any, various, olav, all, certain,
Nearest to was: is, became, had, were, has, although, when, been,
Nearest to and: or, but, like, while, including, when, than, who,
Nearest to in: within, during, throughout, of, at, from, on, with,
Nearest to be: been, have, is, refer, become, are, were, produce,
Nearest to all: many, various, any, every, these, some, both, several,
Nearest to than: or, spalding, much, and, even, showered, while, omniglot,
Nearest to system: systems, crusading, process, program, software, familias, hcl, stewardship,
Nearest to were: are, was, have, tiu, these, those, had, be,
Nearest to see: diaconate, includes, references, list, include, links, refer, external,
Nearest to that: which, however, what, this, lodges, ellesmere, who, dicke,
Nearest to s: whose, isbn, his, tyr, ancestral, infrastructural, pu, starring,
Nearest to will: would, could, must, can, should, may, might, cannot,

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Transform-embedding-into-2D-using-t-SNE_1"&gt;Transform embedding into 2D using t-SNE&lt;a class="anchor-link" href="#Transform-embedding-into-2D-using-t-SNE"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;final_embeddings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(50000, 128)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
num_points = 400

tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')
two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Visualize-result"&gt;Visualize result&lt;a class="anchor-link" href="#Visualize-result"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'More labels than embeddings'&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# in inches&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embeddings&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;annotate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;xy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;xytext&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
            &lt;span class="n"&gt;textcoords&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'offset points'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;ha&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'right'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;va&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'bottom'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;reverse_dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_points&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;two_d_embeddings&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA28AAANqCAYAAAAaAnNPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Todo"&gt;Todo&lt;a class="anchor-link" href="#Todo"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;CBOW&lt;/p&gt;
&lt;p&gt;An alternative to skip-gram is another Word2Vec model called &lt;a href="http://arxiv.org/abs/1301.3781"&gt;CBOW&lt;/a&gt; (Continuous Bag of Words). In the CBOW model, instead of predicting a context word from a word vector, you predict a word from the sum of all the word vectors in its context. Implement and evaluate a CBOW model trained on the text8 dataset.&lt;/p&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Original &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/5_word2vec.ipynb"&gt;jupyter notebook&lt;/a&gt; from the Udacity MOOC course: &lt;a href="https://www.udacity.com/course/deep-learning--ud730"&gt;Deep learning by Google&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/tutorials/word2vec"&gt;TensorFlow word2vec tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/"&gt;http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="TensorFlow"></category><category term="Word2Vec"></category><category term="NLP"></category><category term="VSM"></category></entry><entry><title>Simple Convolutional Neural Network using TensorFlow</title><link href="https://leemeng.tw/simple-convolutional-neural-network-using-tensorflow.html" rel="alternate"></link><published>2017-09-26T18:30:00+09:00</published><updated>2017-09-26T18:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-26:/simple-convolutional-neural-network-using-tensorflow.html</id><summary type="html">&lt;p&gt;The goal here is to practice building convolutional neural networks to classify notMNIST characters using TensorFlow. As image size become bigger and bigger, it become unpractical to train fully-connected NN because there will be just too many parameters and thus the model will overfit very soon. And CNN solve this problem by weight sharing. We will start by building a CNN with two convolutional layers connected by a fully connected layer and then try also pooling layer and other thing to improve the model performance.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to practice building convolutional neural networks to classify &lt;a href="http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html"&gt;notMNIST&lt;/a&gt; characters using TensorFlow.
As image size become bigger and bigger, it become unpractical to train fully-connected NN because there will be just too many parameters and thus the model will overfit very soon. And CNN solve this problem by weight sharing.&lt;/p&gt;
&lt;p&gt;We will start by building a CNN with two convolutional layers connected by a fully connected layer and then try also pooling layer and other thing to improve the model performance.&lt;/p&gt;
&lt;p&gt;Original &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/4_convolutions.ipynb"&gt;jupyter notebook&lt;/a&gt; originated from the Udacity MOOC course: &lt;a href="https://www.udacity.com/course/deep-learning--ud730"&gt;Deep learning by Google&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Import-libraries"&gt;Import libraries&lt;a class="anchor-link" href="#Import-libraries"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# These are all the modules we'll be using later. Make sure you can import them&lt;/span&gt;
&lt;span class="c1"&gt;# before proceeding further.&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cPickle&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tqdm&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;

&lt;span class="c1"&gt;# beautify graph&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ggplot'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Load-notMNIST-dataset"&gt;Load notMNIST dataset&lt;a class="anchor-link" href="#Load-notMNIST-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'datasets/notMNIST.pickle'&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;  &lt;span class="c1"&gt;# hint to help gc free up memory&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training set (200000, 28, 28) (200000,)
Validation set (10000, 28, 28) (10000,)
Test set (10000, 28, 28) (10000,)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reformat-data"&gt;Reformat data&lt;a class="anchor-link" href="#Reformat-data"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reformat into a TensorFlow-friendly shape:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;convolutions need the image data formatted as a cube of shape (width, height, #channels)&lt;/li&gt;
&lt;li&gt;labels as float 1-hot encodings.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;
&lt;span class="n"&gt;num_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;num_channels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;  &lt;span class="c1"&gt;# grayscale&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;


&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training set (200000, 28, 28, 1) (200000, 10)
Validation set (10000, 28, 28, 1) (10000, 10)
Test set (10000, 28, 28, 1) (10000, 10)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.0&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
          &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Helper-for-training-visualization"&gt;Helper for training visualization&lt;a class="anchor-link" href="#Helper-for-training-visualization"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's define a function that make better visualization of our training progress.&lt;br/&gt;
The function will draw mini-batch loss and training/validation accuracy dynamically.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# dynamic showing loss and accuracy when training&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; notebook

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'X'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                &lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Y'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'b'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;sleep_sec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_size_inches&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;forward&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;canvas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;draw&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sleep_sec&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="NN-with-2-convolutional-layers"&gt;NN with 2 convolutional layers&lt;a class="anchor-link" href="#NN-with-2-convolutional-layers"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Computation-graph"&gt;Computation graph&lt;a class="anchor-link" href="#Computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Although this assignment already provide good Tensorflow code to build convoluational networks, I found that I can't imagine what NN I was going to build by reading the code. So I tried to draw what we're going to build and explain some parameters used in code by comments.&lt;/p&gt;
&lt;p&gt;The convolutional network we're going to build:&lt;/p&gt;
&lt;center&gt;&lt;img src="images/2convolational_layers_with_1_fully_connected_nn.png" style="width:80%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 1&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: CNN with 1 fully connected layer&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Something worth mentioning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We set both convoluational layers' output depth = 16.&lt;/li&gt;
&lt;li&gt;We use filters/patches of shape (5 * 5) to find features in local area of a image.&lt;/li&gt;
&lt;li&gt;The new width and height of the convoluational layer will be half of that in the previous layer because we use stride = 2 and SAME padding to 'slide' our patches. Thus 28 -&amp;gt; 14 -&amp;gt; 7.&lt;/li&gt;
&lt;li&gt;Notice that ReLU layers applied after convoluational layers are omitted for simplicity.&lt;/li&gt;
&lt;li&gt;The activations in C2 fully connected to the FC layer. For each neuron on the FC layer, there are $7 * 7 * 16 = 784$ weights ($785$ for bias ), so there are $785 * 64 = 50240$ parameters in the FC layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more details about CNN, I recommend &lt;a href="http://cs231n.github.io/convolutional-networks/"&gt;CS231n&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;patch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;num_hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data.&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="c1"&gt;# When defining weights for a convoluational layer, use the notation&lt;/span&gt;
    &lt;span class="c1"&gt;# [filter_size, filter_size, input_depth, output_depth]&lt;/span&gt;
    &lt;span class="n"&gt;layer1_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer1_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# in this CNN, two convoluational layers happen to have the same depth.&lt;/span&gt;
    &lt;span class="c1"&gt;# if we want, we can adjust them to be different like depth1, depth2&lt;/span&gt;
    &lt;span class="n"&gt;layer2_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer2_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# because we use stride = 2 and SAME padding, our new shape of first feature map C1&lt;/span&gt;
    &lt;span class="c1"&gt;# will be (image_size // 2, image_size //2). and because we use 2 convolutional layers,&lt;/span&gt;
    &lt;span class="c1"&gt;# the shape of second feature map C2 will be (image_size // 2 // 2, image_size // 2 // 2)&lt;/span&gt;
    &lt;span class="c1"&gt;# = (image_size // 4, image_size // 4). and because we have depth == 16,&lt;/span&gt;
    &lt;span class="c1"&gt;# the total neurons on C2 will be image_size // 4 * image_size // 4 * depth&lt;/span&gt;
    &lt;span class="n"&gt;layer3_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer3_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer4_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer4_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Model.&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# this is where we set stride = 2 for both width and height and also SAME padding&lt;/span&gt;
        &lt;span class="c1"&gt;# the third parameters in tf.nn.conv2d is to set stride for every dimension&lt;/span&gt;
        &lt;span class="c1"&gt;# specified in the first parameter data's shape&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer1_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer1_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer2_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer2_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_shape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        
        &lt;span class="c1"&gt;# turn the C2 3D cube back to 2D matrix by shape (#data_points, #neurons)&lt;/span&gt;
        &lt;span class="n"&gt;reshape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer3_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer3_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer4_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer4_biases&lt;/span&gt;

    &lt;span class="c1"&gt;# Training computation.&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Predictions for the training, validation, and test data.&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Train-the-model-and-visualize-the-result"&gt;Train the model and visualize the result&lt;a class="anchor-link" href="#Train-the-model-and-visualize-the-result"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The best thing of the visualization is that it's rendered in a real-time manner.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1001&lt;/span&gt;
&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# initialize weights&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# plot for mini-batch loss and accuracy&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# get new mini-batch for training&lt;/span&gt;
        &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        
        &lt;span class="c1"&gt;# draw loss and accuracy while training&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     
            &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Loss'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Acc'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Valid Acc'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
           
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;.'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                      &lt;span class="s1"&gt;'batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                              &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test accuracy: &lt;/span&gt;&lt;span class="si"&gt;%.1f%%&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                                             &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div id="08e57ca3-2a82-4851-a275-e14f842c5c99"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_javascript "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#08e57ca3-2a82-4851-a275-e14f842c5c99');
/* Put everything inside the global mpl namespace */
window.mpl = {};

mpl.get_websocket_type = function() {
    if (typeof(WebSocket) !== 'undefined') {
        return WebSocket;
    } else if (typeof(MozWebSocket) !== 'undefined') {
        return MozWebSocket;
    } else {
        alert('Your browser does not have WebSocket support.' +
              'Please try Chrome, Safari or Firefox ≥ 6. ' +
              'Firefox 4 and 5 are also supported but you ' +
              'have to enable WebSockets in about:config.');
    };
}

mpl.figure = function(figure_id, websocket, ondownload, parent_element) {
    this.id = figure_id;

    this.ws = websocket;

    this.supports_binary = (this.ws.binaryType != undefined);

    if (!this.supports_binary) {
        var warnings = document.getElementById("mpl-warnings");
        if (warnings) {
            warnings.style.display = 'block';
            warnings.textContent = (
                "This browser does not support binary websocket messages. " +
                    "Performance may be slow.");
        }
    }

    this.imageObj = new Image();

    this.context = undefined;
    this.message = undefined;
    this.canvas = undefined;
    this.rubberband_canvas = undefined;
    this.rubberband_context = undefined;
    this.format_dropdown = undefined;

    this.image_mode = 'full';

    this.root = $('&lt;div/&gt;');
    this._root_extra_style(this.root)
    this.root.attr('style', 'display: inline-block');

    $(parent_element).append(this.root);

    this._init_header(this);
    this._init_canvas(this);
    this._init_toolbar(this);

    var fig = this;

    this.waiting = false;

    this.ws.onopen =  function () {
            fig.send_message("supports_binary", {value: fig.supports_binary});
            fig.send_message("send_image_mode", {});
            fig.send_message("refresh", {});
        }

    this.imageObj.onload = function() {
            if (fig.image_mode == 'full') {
                // Full images could contain transparency (where diff images
                // almost always do), so we need to clear the canvas so that
                // there is no ghosting.
                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);
            }
            fig.context.drawImage(fig.imageObj, 0, 0);
        };

    this.imageObj.onunload = function() {
        this.ws.close();
    }

    this.ws.onmessage = this._make_on_message_function(this);

    this.ondownload = ondownload;
}

mpl.figure.prototype._init_header = function() {
    var titlebar = $(
        '&lt;div class="ui-dialog-titlebar ui-widget-header ui-corner-all ' +
        'ui-helper-clearfix"/&gt;');
    var titletext = $(
        '&lt;div class="ui-dialog-title" style="width: 100%; ' +
        'text-align: center; padding: 3px;"/&gt;');
    titlebar.append(titletext)
    this.root.append(titlebar);
    this.header = titletext[0];
}



mpl.figure.prototype._canvas_extra_style = function(canvas_div) {

}


mpl.figure.prototype._root_extra_style = function(canvas_div) {

}

mpl.figure.prototype._init_canvas = function() {
    var fig = this;

    var canvas_div = $('&lt;div/&gt;');

    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');

    function canvas_keyboard_event(event) {
        return fig.key_event(event, event['data']);
    }

    canvas_div.keydown('key_press', canvas_keyboard_event);
    canvas_div.keyup('key_release', canvas_keyboard_event);
    this.canvas_div = canvas_div
    this._canvas_extra_style(canvas_div)
    this.root.append(canvas_div);

    var canvas = $('&lt;canvas/&gt;');
    canvas.addClass('mpl-canvas');
    canvas.attr('style', "left: 0; top: 0; z-index: 0; outline: 0")

    this.canvas = canvas[0];
    this.context = canvas[0].getContext("2d");

    var rubberband = $('&lt;canvas/&gt;');
    rubberband.attr('style', "position: absolute; left: 0; top: 0; z-index: 1;")

    var pass_mouse_events = true;

    canvas_div.resizable({
        start: function(event, ui) {
            pass_mouse_events = false;
        },
        resize: function(event, ui) {
            fig.request_resize(ui.size.width, ui.size.height);
        },
        stop: function(event, ui) {
            pass_mouse_events = true;
            fig.request_resize(ui.size.width, ui.size.height);
        },
    });

    function mouse_event_fn(event) {
        if (pass_mouse_events)
            return fig.mouse_event(event, event['data']);
    }

    rubberband.mousedown('button_press', mouse_event_fn);
    rubberband.mouseup('button_release', mouse_event_fn);
    // Throttle sequential mouse events to 1 every 20ms.
    rubberband.mousemove('motion_notify', mouse_event_fn);

    rubberband.mouseenter('figure_enter', mouse_event_fn);
    rubberband.mouseleave('figure_leave', mouse_event_fn);

    canvas_div.on("wheel", function (event) {
        event = event.originalEvent;
        event['data'] = 'scroll'
        if (event.deltaY &lt; 0) {
            event.step = 1;
        } else {
            event.step = -1;
        }
        mouse_event_fn(event);
    });

    canvas_div.append(canvas);
    canvas_div.append(rubberband);

    this.rubberband = rubberband;
    this.rubberband_canvas = rubberband[0];
    this.rubberband_context = rubberband[0].getContext("2d");
    this.rubberband_context.strokeStyle = "#000000";

    this._resize_canvas = function(width, height) {
        // Keep the size of the canvas, canvas container, and rubber band
        // canvas in synch.
        canvas_div.css('width', width)
        canvas_div.css('height', height)

        canvas.attr('width', width);
        canvas.attr('height', height);

        rubberband.attr('width', width);
        rubberband.attr('height', height);
    }

    // Set the figure to an initial 600x600px, this will subsequently be updated
    // upon first draw.
    this._resize_canvas(600, 600);

    // Disable right mouse context menu.
    $(this.rubberband_canvas).bind("contextmenu",function(e){
        return false;
    });

    function set_focus () {
        canvas.focus();
        canvas_div.focus();
    }

    window.setTimeout(set_focus, 100);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            // put a spacer in here.
            continue;
        }
        var button = $('&lt;button/&gt;');
        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +
                        'ui-button-icon-only');
        button.attr('role', 'button');
        button.attr('aria-disabled', 'false');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);

        var icon_img = $('&lt;span/&gt;');
        icon_img.addClass('ui-button-icon-primary ui-icon');
        icon_img.addClass(image);
        icon_img.addClass('ui-corner-all');

        var tooltip_span = $('&lt;span/&gt;');
        tooltip_span.addClass('ui-button-text');
        tooltip_span.html(tooltip);

        button.append(icon_img);
        button.append(tooltip_span);

        nav_element.append(button);
    }

    var fmt_picker_span = $('&lt;span/&gt;');

    var fmt_picker = $('&lt;select/&gt;');
    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');
    fmt_picker_span.append(fmt_picker);
    nav_element.append(fmt_picker_span);
    this.format_dropdown = fmt_picker[0];

    for (var ind in mpl.extensions) {
        var fmt = mpl.extensions[ind];
        var option = $(
            '&lt;option/&gt;', {selected: fmt === mpl.default_extension}).html(fmt);
        fmt_picker.append(option)
    }

    // Add hover states to the ui-buttons
    $( ".ui-button" ).hover(
        function() { $(this).addClass("ui-state-hover");},
        function() { $(this).removeClass("ui-state-hover");}
    );

    var status_bar = $('&lt;span class="mpl-message"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];
}

mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {
    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,
    // which will in turn request a refresh of the image.
    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});
}

mpl.figure.prototype.send_message = function(type, properties) {
    properties['type'] = type;
    properties['figure_id'] = this.id;
    this.ws.send(JSON.stringify(properties));
}

mpl.figure.prototype.send_draw_message = function() {
    if (!this.waiting) {
        this.waiting = true;
        this.ws.send(JSON.stringify({type: "draw", figure_id: this.id}));
    }
}


mpl.figure.prototype.handle_save = function(fig, msg) {
    var format_dropdown = fig.format_dropdown;
    var format = format_dropdown.options[format_dropdown.selectedIndex].value;
    fig.ondownload(fig, format);
}


mpl.figure.prototype.handle_resize = function(fig, msg) {
    var size = msg['size'];
    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {
        fig._resize_canvas(size[0], size[1]);
        fig.send_message("refresh", {});
    };
}

mpl.figure.prototype.handle_rubberband = function(fig, msg) {
    var x0 = msg['x0'];
    var y0 = fig.canvas.height - msg['y0'];
    var x1 = msg['x1'];
    var y1 = fig.canvas.height - msg['y1'];
    x0 = Math.floor(x0) + 0.5;
    y0 = Math.floor(y0) + 0.5;
    x1 = Math.floor(x1) + 0.5;
    y1 = Math.floor(y1) + 0.5;
    var min_x = Math.min(x0, x1);
    var min_y = Math.min(y0, y1);
    var width = Math.abs(x1 - x0);
    var height = Math.abs(y1 - y0);

    fig.rubberband_context.clearRect(
        0, 0, fig.canvas.width, fig.canvas.height);

    fig.rubberband_context.strokeRect(min_x, min_y, width, height);
}

mpl.figure.prototype.handle_figure_label = function(fig, msg) {
    // Updates the figure title.
    fig.header.textContent = msg['label'];
}

mpl.figure.prototype.handle_cursor = function(fig, msg) {
    var cursor = msg['cursor'];
    switch(cursor)
    {
    case 0:
        cursor = 'pointer';
        break;
    case 1:
        cursor = 'default';
        break;
    case 2:
        cursor = 'crosshair';
        break;
    case 3:
        cursor = 'move';
        break;
    }
    fig.rubberband_canvas.style.cursor = cursor;
}

mpl.figure.prototype.handle_message = function(fig, msg) {
    fig.message.textContent = msg['message'];
}

mpl.figure.prototype.handle_draw = function(fig, msg) {
    // Request the server to send over a new figure.
    fig.send_draw_message();
}

mpl.figure.prototype.handle_image_mode = function(fig, msg) {
    fig.image_mode = msg['mode'];
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Called whenever the canvas gets updated.
    this.send_message("ack", {});
}

// A function to construct a web socket function for onmessage handling.
// Called in the figure constructor.
mpl.figure.prototype._make_on_message_function = function(fig) {
    return function socket_on_message(evt) {
        if (evt.data instanceof Blob) {
            /* FIXME: We get "Resource interpreted as Image but
             * transferred with MIME type text/plain:" errors on
             * Chrome.  But how to set the MIME type?  It doesn't seem
             * to be part of the websocket stream */
            evt.data.type = "image/png";

            /* Free the memory for the previous frames */
            if (fig.imageObj.src) {
                (window.URL || window.webkitURL).revokeObjectURL(
                    fig.imageObj.src);
            }

            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(
                evt.data);
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }
        else if (typeof evt.data === 'string' &amp;&amp; evt.data.slice(0, 21) == "data:image/png;base64") {
            fig.imageObj.src = evt.data;
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }

        var msg = JSON.parse(evt.data);
        var msg_type = msg['type'];

        // Call the  "handle_{type}" callback, which takes
        // the figure and JSON message as its only arguments.
        try {
            var callback = fig["handle_" + msg_type];
        } catch (e) {
            console.log("No handler for the '" + msg_type + "' message type: ", msg);
            return;
        }

        if (callback) {
            try {
                // console.log("Handling '" + msg_type + "' message: ", msg);
                callback(fig, msg);
            } catch (e) {
                console.log("Exception inside the 'handler_" + msg_type + "' callback:", e, e.stack, msg);
            }
        }
    };
}

// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas
mpl.findpos = function(e) {
    //this section is from http://www.quirksmode.org/js/events_properties.html
    var targ;
    if (!e)
        e = window.event;
    if (e.target)
        targ = e.target;
    else if (e.srcElement)
        targ = e.srcElement;
    if (targ.nodeType == 3) // defeat Safari bug
        targ = targ.parentNode;

    // jQuery normalizes the pageX and pageY
    // pageX,Y are the mouse positions relative to the document
    // offset() returns the position of the element relative to the document
    var x = e.pageX - $(targ).offset().left;
    var y = e.pageY - $(targ).offset().top;

    return {"x": x, "y": y};
};

/*
 * return a copy of an object with only non-object keys
 * we need this to avoid circular references
 * http://stackoverflow.com/a/24161582/3208463
 */
function simpleKeys (original) {
  return Object.keys(original).reduce(function (obj, key) {
    if (typeof original[key] !== 'object')
        obj[key] = original[key]
    return obj;
  }, {});
}

mpl.figure.prototype.mouse_event = function(event, name) {
    var canvas_pos = mpl.findpos(event)

    if (name === 'button_press')
    {
        this.canvas.focus();
        this.canvas_div.focus();
    }

    var x = canvas_pos.x;
    var y = canvas_pos.y;

    this.send_message(name, {x: x, y: y, button: event.button,
                             step: event.step,
                             guiEvent: simpleKeys(event)});

    /* This prevents the web browser from automatically changing to
     * the text insertion cursor when the button is pressed.  We want
     * to control all of the cursor setting manually through the
     * 'cursor' event from matplotlib */
    event.preventDefault();
    return false;
}

mpl.figure.prototype._key_event_extra = function(event, name) {
    // Handle any extra behaviour associated with a key event
}

mpl.figure.prototype.key_event = function(event, name) {

    // Prevent repeat events
    if (name == 'key_press')
    {
        if (event.which === this._key)
            return;
        else
            this._key = event.which;
    }
    if (name == 'key_release')
        this._key = null;

    var value = '';
    if (event.ctrlKey &amp;&amp; event.which != 17)
        value += "ctrl+";
    if (event.altKey &amp;&amp; event.which != 18)
        value += "alt+";
    if (event.shiftKey &amp;&amp; event.which != 16)
        value += "shift+";

    value += 'k';
    value += event.which.toString();

    this._key_event_extra(event, name);

    this.send_message(name, {key: value,
                             guiEvent: simpleKeys(event)});
    return false;
}

mpl.figure.prototype.toolbar_button_onclick = function(name) {
    if (name == 'download') {
        this.handle_save(this, null);
    } else {
        this.send_message("toolbar_button", {name: name});
    }
};

mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {
    this.message.textContent = tooltip;
};
mpl.toolbar_items = [["Home", "Reset original view", "fa fa-home icon-home", "home"], ["Back", "Back to  previous view", "fa fa-arrow-left icon-arrow-left", "back"], ["Forward", "Forward to next view", "fa fa-arrow-right icon-arrow-right", "forward"], ["", "", "", ""], ["Pan", "Pan axes with left mouse, zoom with right", "fa fa-arrows icon-move", "pan"], ["Zoom", "Zoom to rectangle", "fa fa-square-o icon-check-empty", "zoom"], ["", "", "", ""], ["Download", "Download plot", "fa fa-floppy-o icon-save", "download"]];

mpl.extensions = ["eps", "jpeg", "pdf", "png", "ps", "raw", "svg", "tif"];

mpl.default_extension = "png";var comm_websocket_adapter = function(comm) {
    // Create a "websocket"-like object which calls the given IPython comm
    // object with the appropriate methods. Currently this is a non binary
    // socket, so there is still some room for performance tuning.
    var ws = {};

    ws.close = function() {
        comm.close()
    };
    ws.send = function(m) {
        //console.log('sending', m);
        comm.send(m);
    };
    // Register the callback with on_msg.
    comm.on_msg(function(msg) {
        //console.log('receiving', msg['content']['data'], msg);
        // Pass the mpl event to the overriden (by mpl) onmessage function.
        ws.onmessage(msg['content']['data'])
    });
    return ws;
}

mpl.mpl_figure_comm = function(comm, msg) {
    // This is the function which gets called when the mpl process
    // starts-up an IPython Comm through the "matplotlib" channel.

    var id = msg.content.data.id;
    // Get hold of the div created by the display call when the Comm
    // socket was opened in Python.
    var element = $("#" + id);
    var ws_proxy = comm_websocket_adapter(comm)

    function ondownload(figure, format) {
        window.open(figure.imageObj.src);
    }

    var fig = new mpl.figure(id, ws_proxy,
                           ondownload,
                           element.get(0));

    // Call onopen now - mpl needs it, as it is assuming we've passed it a real
    // web socket which is closed, not our websocket-&gt;open comm proxy.
    ws_proxy.onopen();

    fig.parent_element = element.get(0);
    fig.cell_info = mpl.find_output_cell("&lt;div id='" + id + "'&gt;&lt;/div&gt;");
    if (!fig.cell_info) {
        console.error("Failed to find cell for figure", id, fig);
        return;
    }

    var output_index = fig.cell_info[2]
    var cell = fig.cell_info[0];

};

mpl.figure.prototype.handle_close = function(fig, msg) {
    fig.root.unbind('remove')

    // Update the output cell to use the data from the current canvas.
    fig.push_to_output();
    var dataURL = fig.canvas.toDataURL();
    // Re-enable the keyboard manager in IPython - without this line, in FF,
    // the notebook keyboard shortcuts fail.
    IPython.keyboard_manager.enable()
    $(fig.parent_element).html('&lt;img src="' + dataURL + '"&gt;');
    fig.close_ws(fig, msg);
}

mpl.figure.prototype.close_ws = function(fig, msg){
    fig.send_message('closing', msg);
    // fig.ws.close()
}

mpl.figure.prototype.push_to_output = function(remove_interactive) {
    // Turn the data on the canvas into data in the output cell.
    var dataURL = this.canvas.toDataURL();
    this.cell_info[1]['text/html'] = '&lt;img src="' + dataURL + '"&gt;';
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Tell IPython that the notebook contents must change.
    IPython.notebook.set_dirty(true);
    this.send_message("ack", {});
    var fig = this;
    // Wait a second, then push the new image to the DOM so
    // that it is saved nicely (might be nice to debounce this).
    setTimeout(function () { fig.push_to_output() }, 1000);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items){
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) { continue; };

        var button = $('&lt;button class="btn btn-default" href="#" title="' + name + '"&gt;&lt;i class="fa ' + image + ' fa-lg"&gt;&lt;/i&gt;&lt;/button&gt;');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);
        nav_element.append(button);
    }

    // Add the status bar.
    var status_bar = $('&lt;span class="mpl-message" style="text-align:right; float: right;"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];

    // Add the close button to the window.
    var buttongrp = $('&lt;div class="btn-group inline pull-right"&gt;&lt;/div&gt;');
    var button = $('&lt;button class="btn btn-mini btn-primary" href="#" title="Stop Interaction"&gt;&lt;i class="fa fa-power-off icon-remove icon-large"&gt;&lt;/i&gt;&lt;/button&gt;');
    button.click(function (evt) { fig.handle_close(fig, {}); } );
    button.mouseover('Stop Interaction', toolbar_mouse_event);
    buttongrp.append(button);
    var titlebar = this.root.find($('.ui-dialog-titlebar'));
    titlebar.prepend(buttongrp);
}

mpl.figure.prototype._root_extra_style = function(el){
    var fig = this
    el.on("remove", function(){
	fig.close_ws(fig, {});
    });
}

mpl.figure.prototype._canvas_extra_style = function(el){
    // this is important to make the div 'focusable
    el.attr('tabindex', 0)
    // reach out to IPython and tell the keyboard manager to turn it's self
    // off when our div gets focus

    // location in version 3
    if (IPython.notebook.keyboard_manager) {
        IPython.notebook.keyboard_manager.register_events(el);
    }
    else {
        // location in version 2
        IPython.keyboard_manager.register_events(el);
    }

}

mpl.figure.prototype._key_event_extra = function(event, name) {
    var manager = IPython.notebook.keyboard_manager;
    if (!manager)
        manager = IPython.keyboard_manager;

    // Check for shift+enter
    if (event.shiftKey &amp;&amp; event.which == 13) {
        this.canvas_div.blur();
        event.shiftKey = false;
        // Send a "J" for go to next cell
        event.which = 74;
        event.keyCode = 74;
        manager.command_mode();
        manager.handle_keydown(event);
    }
}

mpl.figure.prototype.handle_save = function(fig, msg) {
    fig.ondownload(fig, null);
}


mpl.find_output_cell = function(html_output) {
    // Return the cell and output element which can be found *uniquely* in the notebook.
    // Note - this is a bit hacky, but it is done because the "notebook_saving.Notebook"
    // IPython event is triggered only after the cells have been serialised, which for
    // our purposes (turning an active figure into a static one), is too late.
    var cells = IPython.notebook.get_cells();
    var ncells = cells.length;
    for (var i=0; i&lt;ncells; i++) {
        var cell = cells[i];
        if (cell.cell_type === 'code'){
            for (var j=0; j&lt;cell.output_area.outputs.length; j++) {
                var data = cell.output_area.outputs[j];
                if (data.data) {
                    // IPython &gt;= 3 moved mimebundle to data attribute of output
                    data = data.data;
                }
                if (data['text/html'] == html_output) {
                    return [cell, data, j];
                }
            }
        }
    }
}

// Register the function which deals with the matplotlib target/channel.
// The kernel may be null if the page has been refreshed.
if (IPython.notebook.kernel != null) {
    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);
}

&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea "&gt;
&lt;img src="data:image/png;base64,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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="9ded9b60-29ee-4ea6-8746-45b2b0655293"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#9ded9b60-29ee-4ea6-8746-45b2b0655293');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "255b2330df764c069bf0fa8b72e282b3", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 4.085.batch acc: 0.0%, Valid acc: 10.0%.

Minibatch loss at step 100: 0.861.batch acc: 62.5%, Valid acc: 74.5%.
Minibatch loss at step 200: 0.425.batch acc: 87.5%, Valid acc: 79.1%.
Minibatch loss at step 300: 0.934.batch acc: 62.5%, Valid acc: 79.8%.
Minibatch loss at step 400: 0.861.batch acc: 68.8%, Valid acc: 79.6%.
Minibatch loss at step 500: 0.204.batch acc: 87.5%, Valid acc: 80.6%.
Minibatch loss at step 600: 0.741.batch acc: 75.0%, Valid acc: 82.0%.
Minibatch loss at step 700: 0.591.batch acc: 87.5%, Valid acc: 82.5%.
Minibatch loss at step 800: 1.171.batch acc: 68.8%, Valid acc: 81.8%.
Minibatch loss at step 900: 0.171.batch acc: 100.0%, Valid acc: 83.2%.
Minibatch loss at step 1000: 0.487.batch acc: 93.8%, Valid acc: 82.6%.

Test accuracy: 89.4%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As shown above, mini-batch loss dropped rapidly at first 200 iterations, training and validation accuracy also improve quickly (both achieved about 80%). After 200 iterations, validation performance become stable but still improved about 5%. The test accuracy is about 89%.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Problem-1---Use-pooling-layers-to-reduce-dimensionality_1"&gt;Problem 1 - Use pooling layers to reduce dimensionality&lt;a class="anchor-link" href="#Problem-1---Use-pooling-layers-to-reduce-dimensionality"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (&lt;code&gt;nn.max_pool()&lt;/code&gt;) of stride 2 and kernel size 2.&lt;/p&gt;
&lt;p&gt;The reason why we're going to use pooling layer is that we can reduce spatial size thus parameters to reduce the chance of overfitting. And the advantage of pooling layer is that it require no new parameters. Let's see how much performance we can gain by using max pooling.&lt;/p&gt;
&lt;center&gt;&lt;img src="images/pool.jpeg" style="width:50%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 2&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Max Pooling&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-model-with-pooling-layers"&gt;Build model with pooling layers&lt;a class="anchor-link" href="#Build-model-with-pooling-layers"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Actually, what we will do is just to add pooling layers right after ReLU layers and let the convoluational layer use stride 1. In intuition, we let the convoluational layers look more 'closely' into the images, but also try to limit the number of activation and extract the important parts by pooling layers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;patch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;num_hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data.&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="n"&gt;layer1_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer1_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer2_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer2_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer3_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer3_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer4_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer4_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Model.&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer1_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer1_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer2_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer2_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_shape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;reshape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer3_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer3_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer4_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer4_biases&lt;/span&gt;

    &lt;span class="c1"&gt;# Training computation.&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Predictions for the training, validation, and test data.&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Train-the-model"&gt;Train the model&lt;a class="anchor-link" href="#Train-the-model"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1001&lt;/span&gt;
&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# initialize weights&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# plot for mini-batch loss and accuracy&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# get new mini-batch for training&lt;/span&gt;
        &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        
        &lt;span class="c1"&gt;# draw loss and accuracy while training&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     
            &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Loss'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Acc'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Valid Acc'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
           
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;.'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                      &lt;span class="s1"&gt;'batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                              &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test accuracy: &lt;/span&gt;&lt;span class="si"&gt;%.1f%%&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                                             &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div id="455e2759-dcb3-42a7-a9e5-6527b61922c7"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_javascript "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#455e2759-dcb3-42a7-a9e5-6527b61922c7');
/* Put everything inside the global mpl namespace */
window.mpl = {};

mpl.get_websocket_type = function() {
    if (typeof(WebSocket) !== 'undefined') {
        return WebSocket;
    } else if (typeof(MozWebSocket) !== 'undefined') {
        return MozWebSocket;
    } else {
        alert('Your browser does not have WebSocket support.' +
              'Please try Chrome, Safari or Firefox ≥ 6. ' +
              'Firefox 4 and 5 are also supported but you ' +
              'have to enable WebSockets in about:config.');
    };
}

mpl.figure = function(figure_id, websocket, ondownload, parent_element) {
    this.id = figure_id;

    this.ws = websocket;

    this.supports_binary = (this.ws.binaryType != undefined);

    if (!this.supports_binary) {
        var warnings = document.getElementById("mpl-warnings");
        if (warnings) {
            warnings.style.display = 'block';
            warnings.textContent = (
                "This browser does not support binary websocket messages. " +
                    "Performance may be slow.");
        }
    }

    this.imageObj = new Image();

    this.context = undefined;
    this.message = undefined;
    this.canvas = undefined;
    this.rubberband_canvas = undefined;
    this.rubberband_context = undefined;
    this.format_dropdown = undefined;

    this.image_mode = 'full';

    this.root = $('&lt;div/&gt;');
    this._root_extra_style(this.root)
    this.root.attr('style', 'display: inline-block');

    $(parent_element).append(this.root);

    this._init_header(this);
    this._init_canvas(this);
    this._init_toolbar(this);

    var fig = this;

    this.waiting = false;

    this.ws.onopen =  function () {
            fig.send_message("supports_binary", {value: fig.supports_binary});
            fig.send_message("send_image_mode", {});
            fig.send_message("refresh", {});
        }

    this.imageObj.onload = function() {
            if (fig.image_mode == 'full') {
                // Full images could contain transparency (where diff images
                // almost always do), so we need to clear the canvas so that
                // there is no ghosting.
                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);
            }
            fig.context.drawImage(fig.imageObj, 0, 0);
        };

    this.imageObj.onunload = function() {
        this.ws.close();
    }

    this.ws.onmessage = this._make_on_message_function(this);

    this.ondownload = ondownload;
}

mpl.figure.prototype._init_header = function() {
    var titlebar = $(
        '&lt;div class="ui-dialog-titlebar ui-widget-header ui-corner-all ' +
        'ui-helper-clearfix"/&gt;');
    var titletext = $(
        '&lt;div class="ui-dialog-title" style="width: 100%; ' +
        'text-align: center; padding: 3px;"/&gt;');
    titlebar.append(titletext)
    this.root.append(titlebar);
    this.header = titletext[0];
}



mpl.figure.prototype._canvas_extra_style = function(canvas_div) {

}


mpl.figure.prototype._root_extra_style = function(canvas_div) {

}

mpl.figure.prototype._init_canvas = function() {
    var fig = this;

    var canvas_div = $('&lt;div/&gt;');

    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');

    function canvas_keyboard_event(event) {
        return fig.key_event(event, event['data']);
    }

    canvas_div.keydown('key_press', canvas_keyboard_event);
    canvas_div.keyup('key_release', canvas_keyboard_event);
    this.canvas_div = canvas_div
    this._canvas_extra_style(canvas_div)
    this.root.append(canvas_div);

    var canvas = $('&lt;canvas/&gt;');
    canvas.addClass('mpl-canvas');
    canvas.attr('style', "left: 0; top: 0; z-index: 0; outline: 0")

    this.canvas = canvas[0];
    this.context = canvas[0].getContext("2d");

    var rubberband = $('&lt;canvas/&gt;');
    rubberband.attr('style', "position: absolute; left: 0; top: 0; z-index: 1;")

    var pass_mouse_events = true;

    canvas_div.resizable({
        start: function(event, ui) {
            pass_mouse_events = false;
        },
        resize: function(event, ui) {
            fig.request_resize(ui.size.width, ui.size.height);
        },
        stop: function(event, ui) {
            pass_mouse_events = true;
            fig.request_resize(ui.size.width, ui.size.height);
        },
    });

    function mouse_event_fn(event) {
        if (pass_mouse_events)
            return fig.mouse_event(event, event['data']);
    }

    rubberband.mousedown('button_press', mouse_event_fn);
    rubberband.mouseup('button_release', mouse_event_fn);
    // Throttle sequential mouse events to 1 every 20ms.
    rubberband.mousemove('motion_notify', mouse_event_fn);

    rubberband.mouseenter('figure_enter', mouse_event_fn);
    rubberband.mouseleave('figure_leave', mouse_event_fn);

    canvas_div.on("wheel", function (event) {
        event = event.originalEvent;
        event['data'] = 'scroll'
        if (event.deltaY &lt; 0) {
            event.step = 1;
        } else {
            event.step = -1;
        }
        mouse_event_fn(event);
    });

    canvas_div.append(canvas);
    canvas_div.append(rubberband);

    this.rubberband = rubberband;
    this.rubberband_canvas = rubberband[0];
    this.rubberband_context = rubberband[0].getContext("2d");
    this.rubberband_context.strokeStyle = "#000000";

    this._resize_canvas = function(width, height) {
        // Keep the size of the canvas, canvas container, and rubber band
        // canvas in synch.
        canvas_div.css('width', width)
        canvas_div.css('height', height)

        canvas.attr('width', width);
        canvas.attr('height', height);

        rubberband.attr('width', width);
        rubberband.attr('height', height);
    }

    // Set the figure to an initial 600x600px, this will subsequently be updated
    // upon first draw.
    this._resize_canvas(600, 600);

    // Disable right mouse context menu.
    $(this.rubberband_canvas).bind("contextmenu",function(e){
        return false;
    });

    function set_focus () {
        canvas.focus();
        canvas_div.focus();
    }

    window.setTimeout(set_focus, 100);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            // put a spacer in here.
            continue;
        }
        var button = $('&lt;button/&gt;');
        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +
                        'ui-button-icon-only');
        button.attr('role', 'button');
        button.attr('aria-disabled', 'false');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);

        var icon_img = $('&lt;span/&gt;');
        icon_img.addClass('ui-button-icon-primary ui-icon');
        icon_img.addClass(image);
        icon_img.addClass('ui-corner-all');

        var tooltip_span = $('&lt;span/&gt;');
        tooltip_span.addClass('ui-button-text');
        tooltip_span.html(tooltip);

        button.append(icon_img);
        button.append(tooltip_span);

        nav_element.append(button);
    }

    var fmt_picker_span = $('&lt;span/&gt;');

    var fmt_picker = $('&lt;select/&gt;');
    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');
    fmt_picker_span.append(fmt_picker);
    nav_element.append(fmt_picker_span);
    this.format_dropdown = fmt_picker[0];

    for (var ind in mpl.extensions) {
        var fmt = mpl.extensions[ind];
        var option = $(
            '&lt;option/&gt;', {selected: fmt === mpl.default_extension}).html(fmt);
        fmt_picker.append(option)
    }

    // Add hover states to the ui-buttons
    $( ".ui-button" ).hover(
        function() { $(this).addClass("ui-state-hover");},
        function() { $(this).removeClass("ui-state-hover");}
    );

    var status_bar = $('&lt;span class="mpl-message"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];
}

mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {
    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,
    // which will in turn request a refresh of the image.
    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});
}

mpl.figure.prototype.send_message = function(type, properties) {
    properties['type'] = type;
    properties['figure_id'] = this.id;
    this.ws.send(JSON.stringify(properties));
}

mpl.figure.prototype.send_draw_message = function() {
    if (!this.waiting) {
        this.waiting = true;
        this.ws.send(JSON.stringify({type: "draw", figure_id: this.id}));
    }
}


mpl.figure.prototype.handle_save = function(fig, msg) {
    var format_dropdown = fig.format_dropdown;
    var format = format_dropdown.options[format_dropdown.selectedIndex].value;
    fig.ondownload(fig, format);
}


mpl.figure.prototype.handle_resize = function(fig, msg) {
    var size = msg['size'];
    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {
        fig._resize_canvas(size[0], size[1]);
        fig.send_message("refresh", {});
    };
}

mpl.figure.prototype.handle_rubberband = function(fig, msg) {
    var x0 = msg['x0'];
    var y0 = fig.canvas.height - msg['y0'];
    var x1 = msg['x1'];
    var y1 = fig.canvas.height - msg['y1'];
    x0 = Math.floor(x0) + 0.5;
    y0 = Math.floor(y0) + 0.5;
    x1 = Math.floor(x1) + 0.5;
    y1 = Math.floor(y1) + 0.5;
    var min_x = Math.min(x0, x1);
    var min_y = Math.min(y0, y1);
    var width = Math.abs(x1 - x0);
    var height = Math.abs(y1 - y0);

    fig.rubberband_context.clearRect(
        0, 0, fig.canvas.width, fig.canvas.height);

    fig.rubberband_context.strokeRect(min_x, min_y, width, height);
}

mpl.figure.prototype.handle_figure_label = function(fig, msg) {
    // Updates the figure title.
    fig.header.textContent = msg['label'];
}

mpl.figure.prototype.handle_cursor = function(fig, msg) {
    var cursor = msg['cursor'];
    switch(cursor)
    {
    case 0:
        cursor = 'pointer';
        break;
    case 1:
        cursor = 'default';
        break;
    case 2:
        cursor = 'crosshair';
        break;
    case 3:
        cursor = 'move';
        break;
    }
    fig.rubberband_canvas.style.cursor = cursor;
}

mpl.figure.prototype.handle_message = function(fig, msg) {
    fig.message.textContent = msg['message'];
}

mpl.figure.prototype.handle_draw = function(fig, msg) {
    // Request the server to send over a new figure.
    fig.send_draw_message();
}

mpl.figure.prototype.handle_image_mode = function(fig, msg) {
    fig.image_mode = msg['mode'];
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Called whenever the canvas gets updated.
    this.send_message("ack", {});
}

// A function to construct a web socket function for onmessage handling.
// Called in the figure constructor.
mpl.figure.prototype._make_on_message_function = function(fig) {
    return function socket_on_message(evt) {
        if (evt.data instanceof Blob) {
            /* FIXME: We get "Resource interpreted as Image but
             * transferred with MIME type text/plain:" errors on
             * Chrome.  But how to set the MIME type?  It doesn't seem
             * to be part of the websocket stream */
            evt.data.type = "image/png";

            /* Free the memory for the previous frames */
            if (fig.imageObj.src) {
                (window.URL || window.webkitURL).revokeObjectURL(
                    fig.imageObj.src);
            }

            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(
                evt.data);
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }
        else if (typeof evt.data === 'string' &amp;&amp; evt.data.slice(0, 21) == "data:image/png;base64") {
            fig.imageObj.src = evt.data;
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }

        var msg = JSON.parse(evt.data);
        var msg_type = msg['type'];

        // Call the  "handle_{type}" callback, which takes
        // the figure and JSON message as its only arguments.
        try {
            var callback = fig["handle_" + msg_type];
        } catch (e) {
            console.log("No handler for the '" + msg_type + "' message type: ", msg);
            return;
        }

        if (callback) {
            try {
                // console.log("Handling '" + msg_type + "' message: ", msg);
                callback(fig, msg);
            } catch (e) {
                console.log("Exception inside the 'handler_" + msg_type + "' callback:", e, e.stack, msg);
            }
        }
    };
}

// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas
mpl.findpos = function(e) {
    //this section is from http://www.quirksmode.org/js/events_properties.html
    var targ;
    if (!e)
        e = window.event;
    if (e.target)
        targ = e.target;
    else if (e.srcElement)
        targ = e.srcElement;
    if (targ.nodeType == 3) // defeat Safari bug
        targ = targ.parentNode;

    // jQuery normalizes the pageX and pageY
    // pageX,Y are the mouse positions relative to the document
    // offset() returns the position of the element relative to the document
    var x = e.pageX - $(targ).offset().left;
    var y = e.pageY - $(targ).offset().top;

    return {"x": x, "y": y};
};

/*
 * return a copy of an object with only non-object keys
 * we need this to avoid circular references
 * http://stackoverflow.com/a/24161582/3208463
 */
function simpleKeys (original) {
  return Object.keys(original).reduce(function (obj, key) {
    if (typeof original[key] !== 'object')
        obj[key] = original[key]
    return obj;
  }, {});
}

mpl.figure.prototype.mouse_event = function(event, name) {
    var canvas_pos = mpl.findpos(event)

    if (name === 'button_press')
    {
        this.canvas.focus();
        this.canvas_div.focus();
    }

    var x = canvas_pos.x;
    var y = canvas_pos.y;

    this.send_message(name, {x: x, y: y, button: event.button,
                             step: event.step,
                             guiEvent: simpleKeys(event)});

    /* This prevents the web browser from automatically changing to
     * the text insertion cursor when the button is pressed.  We want
     * to control all of the cursor setting manually through the
     * 'cursor' event from matplotlib */
    event.preventDefault();
    return false;
}

mpl.figure.prototype._key_event_extra = function(event, name) {
    // Handle any extra behaviour associated with a key event
}

mpl.figure.prototype.key_event = function(event, name) {

    // Prevent repeat events
    if (name == 'key_press')
    {
        if (event.which === this._key)
            return;
        else
            this._key = event.which;
    }
    if (name == 'key_release')
        this._key = null;

    var value = '';
    if (event.ctrlKey &amp;&amp; event.which != 17)
        value += "ctrl+";
    if (event.altKey &amp;&amp; event.which != 18)
        value += "alt+";
    if (event.shiftKey &amp;&amp; event.which != 16)
        value += "shift+";

    value += 'k';
    value += event.which.toString();

    this._key_event_extra(event, name);

    this.send_message(name, {key: value,
                             guiEvent: simpleKeys(event)});
    return false;
}

mpl.figure.prototype.toolbar_button_onclick = function(name) {
    if (name == 'download') {
        this.handle_save(this, null);
    } else {
        this.send_message("toolbar_button", {name: name});
    }
};

mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {
    this.message.textContent = tooltip;
};
mpl.toolbar_items = [["Home", "Reset original view", "fa fa-home icon-home", "home"], ["Back", "Back to  previous view", "fa fa-arrow-left icon-arrow-left", "back"], ["Forward", "Forward to next view", "fa fa-arrow-right icon-arrow-right", "forward"], ["", "", "", ""], ["Pan", "Pan axes with left mouse, zoom with right", "fa fa-arrows icon-move", "pan"], ["Zoom", "Zoom to rectangle", "fa fa-square-o icon-check-empty", "zoom"], ["", "", "", ""], ["Download", "Download plot", "fa fa-floppy-o icon-save", "download"]];

mpl.extensions = ["eps", "jpeg", "pdf", "png", "ps", "raw", "svg", "tif"];

mpl.default_extension = "png";var comm_websocket_adapter = function(comm) {
    // Create a "websocket"-like object which calls the given IPython comm
    // object with the appropriate methods. Currently this is a non binary
    // socket, so there is still some room for performance tuning.
    var ws = {};

    ws.close = function() {
        comm.close()
    };
    ws.send = function(m) {
        //console.log('sending', m);
        comm.send(m);
    };
    // Register the callback with on_msg.
    comm.on_msg(function(msg) {
        //console.log('receiving', msg['content']['data'], msg);
        // Pass the mpl event to the overriden (by mpl) onmessage function.
        ws.onmessage(msg['content']['data'])
    });
    return ws;
}

mpl.mpl_figure_comm = function(comm, msg) {
    // This is the function which gets called when the mpl process
    // starts-up an IPython Comm through the "matplotlib" channel.

    var id = msg.content.data.id;
    // Get hold of the div created by the display call when the Comm
    // socket was opened in Python.
    var element = $("#" + id);
    var ws_proxy = comm_websocket_adapter(comm)

    function ondownload(figure, format) {
        window.open(figure.imageObj.src);
    }

    var fig = new mpl.figure(id, ws_proxy,
                           ondownload,
                           element.get(0));

    // Call onopen now - mpl needs it, as it is assuming we've passed it a real
    // web socket which is closed, not our websocket-&gt;open comm proxy.
    ws_proxy.onopen();

    fig.parent_element = element.get(0);
    fig.cell_info = mpl.find_output_cell("&lt;div id='" + id + "'&gt;&lt;/div&gt;");
    if (!fig.cell_info) {
        console.error("Failed to find cell for figure", id, fig);
        return;
    }

    var output_index = fig.cell_info[2]
    var cell = fig.cell_info[0];

};

mpl.figure.prototype.handle_close = function(fig, msg) {
    fig.root.unbind('remove')

    // Update the output cell to use the data from the current canvas.
    fig.push_to_output();
    var dataURL = fig.canvas.toDataURL();
    // Re-enable the keyboard manager in IPython - without this line, in FF,
    // the notebook keyboard shortcuts fail.
    IPython.keyboard_manager.enable()
    $(fig.parent_element).html('&lt;img src="' + dataURL + '"&gt;');
    fig.close_ws(fig, msg);
}

mpl.figure.prototype.close_ws = function(fig, msg){
    fig.send_message('closing', msg);
    // fig.ws.close()
}

mpl.figure.prototype.push_to_output = function(remove_interactive) {
    // Turn the data on the canvas into data in the output cell.
    var dataURL = this.canvas.toDataURL();
    this.cell_info[1]['text/html'] = '&lt;img src="' + dataURL + '"&gt;';
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Tell IPython that the notebook contents must change.
    IPython.notebook.set_dirty(true);
    this.send_message("ack", {});
    var fig = this;
    // Wait a second, then push the new image to the DOM so
    // that it is saved nicely (might be nice to debounce this).
    setTimeout(function () { fig.push_to_output() }, 1000);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items){
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) { continue; };

        var button = $('&lt;button class="btn btn-default" href="#" title="' + name + '"&gt;&lt;i class="fa ' + image + ' fa-lg"&gt;&lt;/i&gt;&lt;/button&gt;');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);
        nav_element.append(button);
    }

    // Add the status bar.
    var status_bar = $('&lt;span class="mpl-message" style="text-align:right; float: right;"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];

    // Add the close button to the window.
    var buttongrp = $('&lt;div class="btn-group inline pull-right"&gt;&lt;/div&gt;');
    var button = $('&lt;button class="btn btn-mini btn-primary" href="#" title="Stop Interaction"&gt;&lt;i class="fa fa-power-off icon-remove icon-large"&gt;&lt;/i&gt;&lt;/button&gt;');
    button.click(function (evt) { fig.handle_close(fig, {}); } );
    button.mouseover('Stop Interaction', toolbar_mouse_event);
    buttongrp.append(button);
    var titlebar = this.root.find($('.ui-dialog-titlebar'));
    titlebar.prepend(buttongrp);
}

mpl.figure.prototype._root_extra_style = function(el){
    var fig = this
    el.on("remove", function(){
	fig.close_ws(fig, {});
    });
}

mpl.figure.prototype._canvas_extra_style = function(el){
    // this is important to make the div 'focusable
    el.attr('tabindex', 0)
    // reach out to IPython and tell the keyboard manager to turn it's self
    // off when our div gets focus

    // location in version 3
    if (IPython.notebook.keyboard_manager) {
        IPython.notebook.keyboard_manager.register_events(el);
    }
    else {
        // location in version 2
        IPython.keyboard_manager.register_events(el);
    }

}

mpl.figure.prototype._key_event_extra = function(event, name) {
    var manager = IPython.notebook.keyboard_manager;
    if (!manager)
        manager = IPython.keyboard_manager;

    // Check for shift+enter
    if (event.shiftKey &amp;&amp; event.which == 13) {
        this.canvas_div.blur();
        event.shiftKey = false;
        // Send a "J" for go to next cell
        event.which = 74;
        event.keyCode = 74;
        manager.command_mode();
        manager.handle_keydown(event);
    }
}

mpl.figure.prototype.handle_save = function(fig, msg) {
    fig.ondownload(fig, null);
}


mpl.find_output_cell = function(html_output) {
    // Return the cell and output element which can be found *uniquely* in the notebook.
    // Note - this is a bit hacky, but it is done because the "notebook_saving.Notebook"
    // IPython event is triggered only after the cells have been serialised, which for
    // our purposes (turning an active figure into a static one), is too late.
    var cells = IPython.notebook.get_cells();
    var ncells = cells.length;
    for (var i=0; i&lt;ncells; i++) {
        var cell = cells[i];
        if (cell.cell_type === 'code'){
            for (var j=0; j&lt;cell.output_area.outputs.length; j++) {
                var data = cell.output_area.outputs[j];
                if (data.data) {
                    // IPython &gt;= 3 moved mimebundle to data attribute of output
                    data = data.data;
                }
                if (data['text/html'] == html_output) {
                    return [cell, data, j];
                }
            }
        }
    }
}

// Register the function which deals with the matplotlib target/channel.
// The kernel may be null if the page has been refreshed.
if (IPython.notebook.kernel != null) {
    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);
}

&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea "&gt;
&lt;img src="data:image/png;base64,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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="758e05d0-930b-4871-82cc-36240b2b4519"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#758e05d0-930b-4871-82cc-36240b2b4519');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "ae81313ad6ad4b428ce63444b7f0ae73", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 2.485.batch acc: 18.8%, Valid acc: 13.0%.
Minibatch loss at step 100: 0.886.batch acc: 75.0%, Valid acc: 73.2%.
Minibatch loss at step 200: 0.417.batch acc: 87.5%, Valid acc: 79.7%.
Minibatch loss at step 300: 0.759.batch acc: 81.2%, Valid acc: 80.9%.
Minibatch loss at step 400: 0.835.batch acc: 75.0%, Valid acc: 80.5%.
Minibatch loss at step 500: 0.366.batch acc: 87.5%, Valid acc: 82.0%.
Minibatch loss at step 600: 0.630.batch acc: 75.0%, Valid acc: 83.3%.
Minibatch loss at step 700: 0.605.batch acc: 81.2%, Valid acc: 83.2%.
Minibatch loss at step 800: 1.031.batch acc: 68.8%, Valid acc: 83.5%.
Minibatch loss at step 900: 0.240.batch acc: 93.8%, Valid acc: 84.6%.
Minibatch loss at step 1000: 0.500.batch acc: 87.5%, Valid acc: 83.9%.

Test accuracy: 90.7%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;There is some performance gain in my current iteration between model w/o pooling layer ( about 1.3% ). And it seems that after several iterations, the validation set performance is slightly better with the pooling layers. But it took about 1 minute and 30 seconds to train CNN with pooling layers, and only 30 seconds to train the one without pooling layers. I think it depends on whether you're willing to gain a little more performance by using more time to train the model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Problem-2_1"&gt;Problem 2&lt;a class="anchor-link" href="#Problem-2"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Try to get the best performance you can using a convolutional net. Look for example at the classic &lt;a href="http://yann.lecun.com/exdb/lenet/"&gt;LeNet5&lt;/a&gt; architecture, adding Dropout, and/or adding learning rate decay.&lt;/p&gt;
&lt;p&gt;I will just try to add a convoluational layer here and train a little longer to see how the performance changed.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Computation-graph_1"&gt;Computation graph&lt;a class="anchor-link" href="#Computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;patch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;
&lt;span class="n"&gt;num_hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data.&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="n"&gt;layer1_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer1_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer2_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer2_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;layer3_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;patch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer3_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# CONV -&amp;gt; FC&lt;/span&gt;
    &lt;span class="n"&gt;layer4_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
            &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer4_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# FC -&amp;gt; output&lt;/span&gt;
    &lt;span class="n"&gt;layer5_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;layer5_biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Model.&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# [CONV -&amp;gt; RELU -&amp;gt; POOL] * 3&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer1_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer1_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer2_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer2_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conv2d&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer3_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conv&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer3_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max_pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;padding&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'SAME'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_shape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;reshape&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
        &lt;span class="n"&gt;hidden&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer4_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer4_biases&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hidden&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer5_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;layer5_biases&lt;/span&gt;

    &lt;span class="c1"&gt;# Training computation.&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.05&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Predictions for the training, validation, and test data.&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Train-the-model_1"&gt;Train the model&lt;a class="anchor-link" href="#Train-the-model"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10001&lt;/span&gt;
&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# initialize weights&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# plot for mini-batch loss and accuracy&lt;/span&gt;
    &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sharex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# get new mini-batch for training&lt;/span&gt;
        &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        
        &lt;span class="c1"&gt;# draw loss and accuracy while training&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     
            &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Loss'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Mini-batch Acc'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;plt_dynamic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_acc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'#Iterations'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Valid Acc'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'r'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
           
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_interval&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;.'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                      &lt;span class="s1"&gt;'batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                              &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test accuracy: &lt;/span&gt;&lt;span class="si"&gt;%.1f%%&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
                                             &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div id="2c30901b-f20f-48a5-98ac-bbb1623af43d"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_javascript "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#2c30901b-f20f-48a5-98ac-bbb1623af43d');
/* Put everything inside the global mpl namespace */
window.mpl = {};

mpl.get_websocket_type = function() {
    if (typeof(WebSocket) !== 'undefined') {
        return WebSocket;
    } else if (typeof(MozWebSocket) !== 'undefined') {
        return MozWebSocket;
    } else {
        alert('Your browser does not have WebSocket support.' +
              'Please try Chrome, Safari or Firefox ≥ 6. ' +
              'Firefox 4 and 5 are also supported but you ' +
              'have to enable WebSockets in about:config.');
    };
}

mpl.figure = function(figure_id, websocket, ondownload, parent_element) {
    this.id = figure_id;

    this.ws = websocket;

    this.supports_binary = (this.ws.binaryType != undefined);

    if (!this.supports_binary) {
        var warnings = document.getElementById("mpl-warnings");
        if (warnings) {
            warnings.style.display = 'block';
            warnings.textContent = (
                "This browser does not support binary websocket messages. " +
                    "Performance may be slow.");
        }
    }

    this.imageObj = new Image();

    this.context = undefined;
    this.message = undefined;
    this.canvas = undefined;
    this.rubberband_canvas = undefined;
    this.rubberband_context = undefined;
    this.format_dropdown = undefined;

    this.image_mode = 'full';

    this.root = $('&lt;div/&gt;');
    this._root_extra_style(this.root)
    this.root.attr('style', 'display: inline-block');

    $(parent_element).append(this.root);

    this._init_header(this);
    this._init_canvas(this);
    this._init_toolbar(this);

    var fig = this;

    this.waiting = false;

    this.ws.onopen =  function () {
            fig.send_message("supports_binary", {value: fig.supports_binary});
            fig.send_message("send_image_mode", {});
            fig.send_message("refresh", {});
        }

    this.imageObj.onload = function() {
            if (fig.image_mode == 'full') {
                // Full images could contain transparency (where diff images
                // almost always do), so we need to clear the canvas so that
                // there is no ghosting.
                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);
            }
            fig.context.drawImage(fig.imageObj, 0, 0);
        };

    this.imageObj.onunload = function() {
        this.ws.close();
    }

    this.ws.onmessage = this._make_on_message_function(this);

    this.ondownload = ondownload;
}

mpl.figure.prototype._init_header = function() {
    var titlebar = $(
        '&lt;div class="ui-dialog-titlebar ui-widget-header ui-corner-all ' +
        'ui-helper-clearfix"/&gt;');
    var titletext = $(
        '&lt;div class="ui-dialog-title" style="width: 100%; ' +
        'text-align: center; padding: 3px;"/&gt;');
    titlebar.append(titletext)
    this.root.append(titlebar);
    this.header = titletext[0];
}



mpl.figure.prototype._canvas_extra_style = function(canvas_div) {

}


mpl.figure.prototype._root_extra_style = function(canvas_div) {

}

mpl.figure.prototype._init_canvas = function() {
    var fig = this;

    var canvas_div = $('&lt;div/&gt;');

    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');

    function canvas_keyboard_event(event) {
        return fig.key_event(event, event['data']);
    }

    canvas_div.keydown('key_press', canvas_keyboard_event);
    canvas_div.keyup('key_release', canvas_keyboard_event);
    this.canvas_div = canvas_div
    this._canvas_extra_style(canvas_div)
    this.root.append(canvas_div);

    var canvas = $('&lt;canvas/&gt;');
    canvas.addClass('mpl-canvas');
    canvas.attr('style', "left: 0; top: 0; z-index: 0; outline: 0")

    this.canvas = canvas[0];
    this.context = canvas[0].getContext("2d");

    var rubberband = $('&lt;canvas/&gt;');
    rubberband.attr('style', "position: absolute; left: 0; top: 0; z-index: 1;")

    var pass_mouse_events = true;

    canvas_div.resizable({
        start: function(event, ui) {
            pass_mouse_events = false;
        },
        resize: function(event, ui) {
            fig.request_resize(ui.size.width, ui.size.height);
        },
        stop: function(event, ui) {
            pass_mouse_events = true;
            fig.request_resize(ui.size.width, ui.size.height);
        },
    });

    function mouse_event_fn(event) {
        if (pass_mouse_events)
            return fig.mouse_event(event, event['data']);
    }

    rubberband.mousedown('button_press', mouse_event_fn);
    rubberband.mouseup('button_release', mouse_event_fn);
    // Throttle sequential mouse events to 1 every 20ms.
    rubberband.mousemove('motion_notify', mouse_event_fn);

    rubberband.mouseenter('figure_enter', mouse_event_fn);
    rubberband.mouseleave('figure_leave', mouse_event_fn);

    canvas_div.on("wheel", function (event) {
        event = event.originalEvent;
        event['data'] = 'scroll'
        if (event.deltaY &lt; 0) {
            event.step = 1;
        } else {
            event.step = -1;
        }
        mouse_event_fn(event);
    });

    canvas_div.append(canvas);
    canvas_div.append(rubberband);

    this.rubberband = rubberband;
    this.rubberband_canvas = rubberband[0];
    this.rubberband_context = rubberband[0].getContext("2d");
    this.rubberband_context.strokeStyle = "#000000";

    this._resize_canvas = function(width, height) {
        // Keep the size of the canvas, canvas container, and rubber band
        // canvas in synch.
        canvas_div.css('width', width)
        canvas_div.css('height', height)

        canvas.attr('width', width);
        canvas.attr('height', height);

        rubberband.attr('width', width);
        rubberband.attr('height', height);
    }

    // Set the figure to an initial 600x600px, this will subsequently be updated
    // upon first draw.
    this._resize_canvas(600, 600);

    // Disable right mouse context menu.
    $(this.rubberband_canvas).bind("contextmenu",function(e){
        return false;
    });

    function set_focus () {
        canvas.focus();
        canvas_div.focus();
    }

    window.setTimeout(set_focus, 100);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items) {
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) {
            // put a spacer in here.
            continue;
        }
        var button = $('&lt;button/&gt;');
        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +
                        'ui-button-icon-only');
        button.attr('role', 'button');
        button.attr('aria-disabled', 'false');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);

        var icon_img = $('&lt;span/&gt;');
        icon_img.addClass('ui-button-icon-primary ui-icon');
        icon_img.addClass(image);
        icon_img.addClass('ui-corner-all');

        var tooltip_span = $('&lt;span/&gt;');
        tooltip_span.addClass('ui-button-text');
        tooltip_span.html(tooltip);

        button.append(icon_img);
        button.append(tooltip_span);

        nav_element.append(button);
    }

    var fmt_picker_span = $('&lt;span/&gt;');

    var fmt_picker = $('&lt;select/&gt;');
    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');
    fmt_picker_span.append(fmt_picker);
    nav_element.append(fmt_picker_span);
    this.format_dropdown = fmt_picker[0];

    for (var ind in mpl.extensions) {
        var fmt = mpl.extensions[ind];
        var option = $(
            '&lt;option/&gt;', {selected: fmt === mpl.default_extension}).html(fmt);
        fmt_picker.append(option)
    }

    // Add hover states to the ui-buttons
    $( ".ui-button" ).hover(
        function() { $(this).addClass("ui-state-hover");},
        function() { $(this).removeClass("ui-state-hover");}
    );

    var status_bar = $('&lt;span class="mpl-message"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];
}

mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {
    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,
    // which will in turn request a refresh of the image.
    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});
}

mpl.figure.prototype.send_message = function(type, properties) {
    properties['type'] = type;
    properties['figure_id'] = this.id;
    this.ws.send(JSON.stringify(properties));
}

mpl.figure.prototype.send_draw_message = function() {
    if (!this.waiting) {
        this.waiting = true;
        this.ws.send(JSON.stringify({type: "draw", figure_id: this.id}));
    }
}


mpl.figure.prototype.handle_save = function(fig, msg) {
    var format_dropdown = fig.format_dropdown;
    var format = format_dropdown.options[format_dropdown.selectedIndex].value;
    fig.ondownload(fig, format);
}


mpl.figure.prototype.handle_resize = function(fig, msg) {
    var size = msg['size'];
    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {
        fig._resize_canvas(size[0], size[1]);
        fig.send_message("refresh", {});
    };
}

mpl.figure.prototype.handle_rubberband = function(fig, msg) {
    var x0 = msg['x0'];
    var y0 = fig.canvas.height - msg['y0'];
    var x1 = msg['x1'];
    var y1 = fig.canvas.height - msg['y1'];
    x0 = Math.floor(x0) + 0.5;
    y0 = Math.floor(y0) + 0.5;
    x1 = Math.floor(x1) + 0.5;
    y1 = Math.floor(y1) + 0.5;
    var min_x = Math.min(x0, x1);
    var min_y = Math.min(y0, y1);
    var width = Math.abs(x1 - x0);
    var height = Math.abs(y1 - y0);

    fig.rubberband_context.clearRect(
        0, 0, fig.canvas.width, fig.canvas.height);

    fig.rubberband_context.strokeRect(min_x, min_y, width, height);
}

mpl.figure.prototype.handle_figure_label = function(fig, msg) {
    // Updates the figure title.
    fig.header.textContent = msg['label'];
}

mpl.figure.prototype.handle_cursor = function(fig, msg) {
    var cursor = msg['cursor'];
    switch(cursor)
    {
    case 0:
        cursor = 'pointer';
        break;
    case 1:
        cursor = 'default';
        break;
    case 2:
        cursor = 'crosshair';
        break;
    case 3:
        cursor = 'move';
        break;
    }
    fig.rubberband_canvas.style.cursor = cursor;
}

mpl.figure.prototype.handle_message = function(fig, msg) {
    fig.message.textContent = msg['message'];
}

mpl.figure.prototype.handle_draw = function(fig, msg) {
    // Request the server to send over a new figure.
    fig.send_draw_message();
}

mpl.figure.prototype.handle_image_mode = function(fig, msg) {
    fig.image_mode = msg['mode'];
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Called whenever the canvas gets updated.
    this.send_message("ack", {});
}

// A function to construct a web socket function for onmessage handling.
// Called in the figure constructor.
mpl.figure.prototype._make_on_message_function = function(fig) {
    return function socket_on_message(evt) {
        if (evt.data instanceof Blob) {
            /* FIXME: We get "Resource interpreted as Image but
             * transferred with MIME type text/plain:" errors on
             * Chrome.  But how to set the MIME type?  It doesn't seem
             * to be part of the websocket stream */
            evt.data.type = "image/png";

            /* Free the memory for the previous frames */
            if (fig.imageObj.src) {
                (window.URL || window.webkitURL).revokeObjectURL(
                    fig.imageObj.src);
            }

            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(
                evt.data);
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }
        else if (typeof evt.data === 'string' &amp;&amp; evt.data.slice(0, 21) == "data:image/png;base64") {
            fig.imageObj.src = evt.data;
            fig.updated_canvas_event();
            fig.waiting = false;
            return;
        }

        var msg = JSON.parse(evt.data);
        var msg_type = msg['type'];

        // Call the  "handle_{type}" callback, which takes
        // the figure and JSON message as its only arguments.
        try {
            var callback = fig["handle_" + msg_type];
        } catch (e) {
            console.log("No handler for the '" + msg_type + "' message type: ", msg);
            return;
        }

        if (callback) {
            try {
                // console.log("Handling '" + msg_type + "' message: ", msg);
                callback(fig, msg);
            } catch (e) {
                console.log("Exception inside the 'handler_" + msg_type + "' callback:", e, e.stack, msg);
            }
        }
    };
}

// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas
mpl.findpos = function(e) {
    //this section is from http://www.quirksmode.org/js/events_properties.html
    var targ;
    if (!e)
        e = window.event;
    if (e.target)
        targ = e.target;
    else if (e.srcElement)
        targ = e.srcElement;
    if (targ.nodeType == 3) // defeat Safari bug
        targ = targ.parentNode;

    // jQuery normalizes the pageX and pageY
    // pageX,Y are the mouse positions relative to the document
    // offset() returns the position of the element relative to the document
    var x = e.pageX - $(targ).offset().left;
    var y = e.pageY - $(targ).offset().top;

    return {"x": x, "y": y};
};

/*
 * return a copy of an object with only non-object keys
 * we need this to avoid circular references
 * http://stackoverflow.com/a/24161582/3208463
 */
function simpleKeys (original) {
  return Object.keys(original).reduce(function (obj, key) {
    if (typeof original[key] !== 'object')
        obj[key] = original[key]
    return obj;
  }, {});
}

mpl.figure.prototype.mouse_event = function(event, name) {
    var canvas_pos = mpl.findpos(event)

    if (name === 'button_press')
    {
        this.canvas.focus();
        this.canvas_div.focus();
    }

    var x = canvas_pos.x;
    var y = canvas_pos.y;

    this.send_message(name, {x: x, y: y, button: event.button,
                             step: event.step,
                             guiEvent: simpleKeys(event)});

    /* This prevents the web browser from automatically changing to
     * the text insertion cursor when the button is pressed.  We want
     * to control all of the cursor setting manually through the
     * 'cursor' event from matplotlib */
    event.preventDefault();
    return false;
}

mpl.figure.prototype._key_event_extra = function(event, name) {
    // Handle any extra behaviour associated with a key event
}

mpl.figure.prototype.key_event = function(event, name) {

    // Prevent repeat events
    if (name == 'key_press')
    {
        if (event.which === this._key)
            return;
        else
            this._key = event.which;
    }
    if (name == 'key_release')
        this._key = null;

    var value = '';
    if (event.ctrlKey &amp;&amp; event.which != 17)
        value += "ctrl+";
    if (event.altKey &amp;&amp; event.which != 18)
        value += "alt+";
    if (event.shiftKey &amp;&amp; event.which != 16)
        value += "shift+";

    value += 'k';
    value += event.which.toString();

    this._key_event_extra(event, name);

    this.send_message(name, {key: value,
                             guiEvent: simpleKeys(event)});
    return false;
}

mpl.figure.prototype.toolbar_button_onclick = function(name) {
    if (name == 'download') {
        this.handle_save(this, null);
    } else {
        this.send_message("toolbar_button", {name: name});
    }
};

mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {
    this.message.textContent = tooltip;
};
mpl.toolbar_items = [["Home", "Reset original view", "fa fa-home icon-home", "home"], ["Back", "Back to  previous view", "fa fa-arrow-left icon-arrow-left", "back"], ["Forward", "Forward to next view", "fa fa-arrow-right icon-arrow-right", "forward"], ["", "", "", ""], ["Pan", "Pan axes with left mouse, zoom with right", "fa fa-arrows icon-move", "pan"], ["Zoom", "Zoom to rectangle", "fa fa-square-o icon-check-empty", "zoom"], ["", "", "", ""], ["Download", "Download plot", "fa fa-floppy-o icon-save", "download"]];

mpl.extensions = ["eps", "jpeg", "pdf", "png", "ps", "raw", "svg", "tif"];

mpl.default_extension = "png";var comm_websocket_adapter = function(comm) {
    // Create a "websocket"-like object which calls the given IPython comm
    // object with the appropriate methods. Currently this is a non binary
    // socket, so there is still some room for performance tuning.
    var ws = {};

    ws.close = function() {
        comm.close()
    };
    ws.send = function(m) {
        //console.log('sending', m);
        comm.send(m);
    };
    // Register the callback with on_msg.
    comm.on_msg(function(msg) {
        //console.log('receiving', msg['content']['data'], msg);
        // Pass the mpl event to the overriden (by mpl) onmessage function.
        ws.onmessage(msg['content']['data'])
    });
    return ws;
}

mpl.mpl_figure_comm = function(comm, msg) {
    // This is the function which gets called when the mpl process
    // starts-up an IPython Comm through the "matplotlib" channel.

    var id = msg.content.data.id;
    // Get hold of the div created by the display call when the Comm
    // socket was opened in Python.
    var element = $("#" + id);
    var ws_proxy = comm_websocket_adapter(comm)

    function ondownload(figure, format) {
        window.open(figure.imageObj.src);
    }

    var fig = new mpl.figure(id, ws_proxy,
                           ondownload,
                           element.get(0));

    // Call onopen now - mpl needs it, as it is assuming we've passed it a real
    // web socket which is closed, not our websocket-&gt;open comm proxy.
    ws_proxy.onopen();

    fig.parent_element = element.get(0);
    fig.cell_info = mpl.find_output_cell("&lt;div id='" + id + "'&gt;&lt;/div&gt;");
    if (!fig.cell_info) {
        console.error("Failed to find cell for figure", id, fig);
        return;
    }

    var output_index = fig.cell_info[2]
    var cell = fig.cell_info[0];

};

mpl.figure.prototype.handle_close = function(fig, msg) {
    fig.root.unbind('remove')

    // Update the output cell to use the data from the current canvas.
    fig.push_to_output();
    var dataURL = fig.canvas.toDataURL();
    // Re-enable the keyboard manager in IPython - without this line, in FF,
    // the notebook keyboard shortcuts fail.
    IPython.keyboard_manager.enable()
    $(fig.parent_element).html('&lt;img src="' + dataURL + '"&gt;');
    fig.close_ws(fig, msg);
}

mpl.figure.prototype.close_ws = function(fig, msg){
    fig.send_message('closing', msg);
    // fig.ws.close()
}

mpl.figure.prototype.push_to_output = function(remove_interactive) {
    // Turn the data on the canvas into data in the output cell.
    var dataURL = this.canvas.toDataURL();
    this.cell_info[1]['text/html'] = '&lt;img src="' + dataURL + '"&gt;';
}

mpl.figure.prototype.updated_canvas_event = function() {
    // Tell IPython that the notebook contents must change.
    IPython.notebook.set_dirty(true);
    this.send_message("ack", {});
    var fig = this;
    // Wait a second, then push the new image to the DOM so
    // that it is saved nicely (might be nice to debounce this).
    setTimeout(function () { fig.push_to_output() }, 1000);
}

mpl.figure.prototype._init_toolbar = function() {
    var fig = this;

    var nav_element = $('&lt;div/&gt;')
    nav_element.attr('style', 'width: 100%');
    this.root.append(nav_element);

    // Define a callback function for later on.
    function toolbar_event(event) {
        return fig.toolbar_button_onclick(event['data']);
    }
    function toolbar_mouse_event(event) {
        return fig.toolbar_button_onmouseover(event['data']);
    }

    for(var toolbar_ind in mpl.toolbar_items){
        var name = mpl.toolbar_items[toolbar_ind][0];
        var tooltip = mpl.toolbar_items[toolbar_ind][1];
        var image = mpl.toolbar_items[toolbar_ind][2];
        var method_name = mpl.toolbar_items[toolbar_ind][3];

        if (!name) { continue; };

        var button = $('&lt;button class="btn btn-default" href="#" title="' + name + '"&gt;&lt;i class="fa ' + image + ' fa-lg"&gt;&lt;/i&gt;&lt;/button&gt;');
        button.click(method_name, toolbar_event);
        button.mouseover(tooltip, toolbar_mouse_event);
        nav_element.append(button);
    }

    // Add the status bar.
    var status_bar = $('&lt;span class="mpl-message" style="text-align:right; float: right;"/&gt;');
    nav_element.append(status_bar);
    this.message = status_bar[0];

    // Add the close button to the window.
    var buttongrp = $('&lt;div class="btn-group inline pull-right"&gt;&lt;/div&gt;');
    var button = $('&lt;button class="btn btn-mini btn-primary" href="#" title="Stop Interaction"&gt;&lt;i class="fa fa-power-off icon-remove icon-large"&gt;&lt;/i&gt;&lt;/button&gt;');
    button.click(function (evt) { fig.handle_close(fig, {}); } );
    button.mouseover('Stop Interaction', toolbar_mouse_event);
    buttongrp.append(button);
    var titlebar = this.root.find($('.ui-dialog-titlebar'));
    titlebar.prepend(buttongrp);
}

mpl.figure.prototype._root_extra_style = function(el){
    var fig = this
    el.on("remove", function(){
	fig.close_ws(fig, {});
    });
}

mpl.figure.prototype._canvas_extra_style = function(el){
    // this is important to make the div 'focusable
    el.attr('tabindex', 0)
    // reach out to IPython and tell the keyboard manager to turn it's self
    // off when our div gets focus

    // location in version 3
    if (IPython.notebook.keyboard_manager) {
        IPython.notebook.keyboard_manager.register_events(el);
    }
    else {
        // location in version 2
        IPython.keyboard_manager.register_events(el);
    }

}

mpl.figure.prototype._key_event_extra = function(event, name) {
    var manager = IPython.notebook.keyboard_manager;
    if (!manager)
        manager = IPython.keyboard_manager;

    // Check for shift+enter
    if (event.shiftKey &amp;&amp; event.which == 13) {
        this.canvas_div.blur();
        event.shiftKey = false;
        // Send a "J" for go to next cell
        event.which = 74;
        event.keyCode = 74;
        manager.command_mode();
        manager.handle_keydown(event);
    }
}

mpl.figure.prototype.handle_save = function(fig, msg) {
    fig.ondownload(fig, null);
}


mpl.find_output_cell = function(html_output) {
    // Return the cell and output element which can be found *uniquely* in the notebook.
    // Note - this is a bit hacky, but it is done because the "notebook_saving.Notebook"
    // IPython event is triggered only after the cells have been serialised, which for
    // our purposes (turning an active figure into a static one), is too late.
    var cells = IPython.notebook.get_cells();
    var ncells = cells.length;
    for (var i=0; i&lt;ncells; i++) {
        var cell = cells[i];
        if (cell.cell_type === 'code'){
            for (var j=0; j&lt;cell.output_area.outputs.length; j++) {
                var data = cell.output_area.outputs[j];
                if (data.data) {
                    // IPython &gt;= 3 moved mimebundle to data attribute of output
                    data = data.data;
                }
                if (data['text/html'] == html_output) {
                    return [cell, data, j];
                }
            }
        }
    }
}

// Register the function which deals with the matplotlib target/channel.
// The kernel may be null if the page has been refreshed.
if (IPython.notebook.kernel != null) {
    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);
}

&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea "&gt;
&lt;img src="data:image/png;base64,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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="33e2d01c-6a4a-4aed-bee2-7fc2088c181a"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#33e2d01c-6a4a-4aed-bee2-7fc2088c181a');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "b240065c4ffa4ca29432614b189f2e04", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 3.563.batch acc: 6.2%, Valid acc: 10.0%.
Minibatch loss at step 1000: 0.502.batch acc: 87.5%, Valid acc: 84.9%.
Minibatch loss at step 2000: 0.414.batch acc: 87.5%, Valid acc: 86.4%.
Minibatch loss at step 3000: 0.164.batch acc: 93.8%, Valid acc: 87.0%.
Minibatch loss at step 4000: 0.545.batch acc: 75.0%, Valid acc: 88.1%.
Minibatch loss at step 5000: 0.898.batch acc: 75.0%, Valid acc: 88.4%.
Minibatch loss at step 6000: 0.493.batch acc: 81.2%, Valid acc: 86.4%.
Minibatch loss at step 7000: 0.613.batch acc: 81.2%, Valid acc: 89.3%.
Minibatch loss at step 8000: 0.089.batch acc: 100.0%, Valid acc: 89.2%.
Minibatch loss at step 9000: 0.280.batch acc: 93.8%, Valid acc: 89.6%.
Minibatch loss at step 10000: 0.437.batch acc: 87.5%, Valid acc: 89.4%.

Test accuracy: 94.6%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;By adding a new convoluational layer and train 10x steps, our model's performance can even boost to almost 95%! (though it take about 5 minutes to train on my pc) and I think there are still many things we can tune to make the model better, but I will stop here to move on to sequence model!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="Tensorflow"></category><category term="Deep Learning"></category><category term="Convolutional Neural Network"></category><category term="CNN"></category><category term="Deep Learning by Google"></category><category term="Machine Learning Engineer by kaggle"></category><category term="Udacity"></category></entry><entry><title>Regularization for Multi-layer Neural Networks in Tensorflow</title><link href="https://leemeng.tw/regularization-for-multi-layer-neural-networks-in-tensorflow.html" rel="alternate"></link><published>2017-09-25T16:00:00+09:00</published><updated>2017-09-25T16:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-25:/regularization-for-multi-layer-neural-networks-in-tensorflow.html</id><summary type="html">&lt;p&gt;The goal of this assignment is to explore regularization techniques.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal of this assignment is to explore regularization techniques.
The original notebook can be found &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/3_regularization.ipynb"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Import-libraries"&gt;Import libraries&lt;a class="anchor-link" href="#Import-libraries"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# These are all the modules we'll be using later. Make sure you can import them&lt;/span&gt;
&lt;span class="c1"&gt;# before proceeding further.&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tqdm&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cPickle&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Load-NotMNIST-dataset"&gt;Load NotMNIST dataset&lt;a class="anchor-link" href="#Load-NotMNIST-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;First reload the data we generated in &lt;code&gt;1_notmnist.ipynb&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'datasets/notMNIST.pickle'&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;X_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;Y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;Y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;Y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;  &lt;span class="c1"&gt;# hint to help gc free up memory&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training set (200000, 28, 28) (200000,)
Validation set (10000, 28, 28) (10000,)
Test set (10000, 28, 28) (10000,)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reformat-dataset"&gt;Reformat dataset&lt;a class="anchor-link" href="#Reformat-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reformat into a shape that's more adapted to the models we're going to train:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data as a flat matrix,&lt;/li&gt;
&lt;li&gt;labels as float 1-hot encodings.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I did in previous notebook, this reformat operation will be different from the operation suggested by the original &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/3_regularization.ipynb"&gt;notebook&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;
&lt;span class="n"&gt;num_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    
    &lt;span class="c1"&gt;# Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;


&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_valid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_valid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training set (784, 200000) (10, 200000)
Validation set (784, 10000) (10, 10000)
Test set (784, 10000) (784, 10000)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Using-Accuracy-as-Default-Metric"&gt;Using Accuracy as Default Metric&lt;a class="anchor-link" href="#Using-Accuracy-as-Default-Metric"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Because as we explored before, there exist no unbalanced problem in the dataset,&lt;br/&gt;
so accuracy alone will be sufficient for evaluating performance of our model on the classification task.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="3-layer-NN-as-base-model_1"&gt;3-layer NN as base model&lt;a class="anchor-link" href="#3-layer-NN-as-base-model"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;In order to test the effect with/without regularization, we will use a little more complex neural network with 2 hidden layers as our base model. And we will be using ReLU as our activation function.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Hyper-parameters"&gt;Hyper parameters&lt;a class="anchor-link" href="#Hyper-parameters"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# hyper parameters&lt;/span&gt;
&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-2&lt;/span&gt;
&lt;span class="n"&gt;lamba&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1e-3&lt;/span&gt;
&lt;span class="n"&gt;keep_prob&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;
&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;501&lt;/span&gt;
&lt;span class="n"&gt;n0&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="c1"&gt;# input size&lt;/span&gt;
&lt;span class="n"&gt;n1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt; &lt;span class="c1"&gt;# first hidden layer&lt;/span&gt;
&lt;span class="n"&gt;n2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt; &lt;span class="c1"&gt;# second hidden layer&lt;/span&gt;
&lt;span class="n"&gt;n3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt; &lt;span class="c1"&gt;# third hidden layer&lt;/span&gt;
&lt;span class="n"&gt;n4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_labels&lt;/span&gt; &lt;span class="c1"&gt;# output size&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-model"&gt;Build model&lt;a class="anchor-link" href="#Build-model"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# build a model which let us able to choose different optimzation mechnism&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lamba&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_decay&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    Train 3-layer NN with following settings:&lt;/span&gt;
&lt;span class="sd"&gt;    Regularization lambda: {}&lt;/span&gt;
&lt;span class="sd"&gt;    Learning rate: {}&lt;/span&gt;
&lt;span class="sd"&gt;    learning_decay: {}&lt;/span&gt;
&lt;span class="sd"&gt;    keep_prob: {}&lt;/span&gt;
&lt;span class="sd"&gt;    Batch_size: {}&lt;/span&gt;
&lt;span class="sd"&gt;    Number of steps: {}&lt;/span&gt;
&lt;span class="sd"&gt;    n1, n2, n3: {}, {}, {}"""&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lamba&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;learning_decay&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# construct computation graph&lt;/span&gt;
    &lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="c1"&gt;# placeholder for mini-batch when training &lt;/span&gt;
        &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;global_step&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# use all valid/test set&lt;/span&gt;
        &lt;span class="n"&gt;tf_X_valid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_valid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;tf_X_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# initialize weights, biases&lt;/span&gt;
        &lt;span class="c1"&gt;# notice that we have two hidden &lt;/span&gt;
        &lt;span class="c1"&gt;# layers so we now have W1, b1, W2, b2, W3, b3&lt;/span&gt;
        &lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n0&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="n"&gt;W3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="n"&gt;W4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;stddev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;2.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="n"&gt;b1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="n"&gt;b2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="n"&gt;b3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
        &lt;span class="n"&gt;b4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;n4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;


        &lt;span class="c1"&gt;# training computation&lt;/span&gt;
        &lt;span class="n"&gt;Z1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;
        &lt;span class="n"&gt;A1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Z2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;
        &lt;span class="n"&gt;A2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Z3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b3&lt;/span&gt;
        &lt;span class="n"&gt;A3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Z4&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b4&lt;/span&gt;

        &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z4&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;lamba&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;lamba&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; \
            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;l2_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;l2_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;l2_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;l2_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

        &lt;span class="c1"&gt;# optimizer&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;learning_decay&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exponential_decay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.80&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;staircase&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;global_step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;global_step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;
                         &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

        &lt;span class="c1"&gt;# valid / test prediction&lt;/span&gt;
        &lt;span class="n"&gt;Y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Z4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Y_vaild_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_X_valid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Y_test_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_X_test&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# define training&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="c1"&gt;# initialized parameters&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Initialized"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

            &lt;span class="c1"&gt;# generate randomized mini-batches from training data&lt;/span&gt;
            &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;batch_X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X_train&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
            &lt;span class="n"&gt;batch_Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Y_train&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

            &lt;span class="c1"&gt;# train model&lt;/span&gt;
            &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_Y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sess&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y_pred&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_Y&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;. batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_Y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_Y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                              &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y_vaild_pred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;Y_valid&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Y_test_pred&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;Y_test&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Train-model-without-regularization"&gt;Train model without regularization&lt;a class="anchor-link" href="#Train-model-without-regularization"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1601&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
    Train 3-layer NN with following settings:
    Regularization lambda: 0
    Learning rate: 0.5
    learning_decay: False
    keep_prob: 1
    Batch_size: 128
    Number of steps: 1601
    n1, n2, n3: 1024, 512, 256
Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="3bc654aa-7f94-4546-b795-3d5900f9fd7f"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#3bc654aa-7f94-4546-b795-3d5900f9fd7f');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "95a1e075513f4d02a8579c4fcd5b8509", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 2.374. batch acc: 14.1%, Valid acc: 28.4%.
Minibatch loss at step 200: 0.600. batch acc: 82.0%, Valid acc: 84.9%.
Minibatch loss at step 400: 0.429. batch acc: 89.8%, Valid acc: 85.8%.
Minibatch loss at step 600: 0.372. batch acc: 87.5%, Valid acc: 85.7%.
Minibatch loss at step 800: 0.454. batch acc: 89.1%, Valid acc: 87.7%.
Minibatch loss at step 1000: 0.374. batch acc: 87.5%, Valid acc: 88.1%.
Minibatch loss at step 1200: 0.251. batch acc: 91.4%, Valid acc: 88.8%.
Minibatch loss at step 1400: 0.397. batch acc: 89.8%, Valid acc: 89.0%.
Minibatch loss at step 1600: 0.470. batch acc: 82.0%, Valid acc: 88.9%.

Test acc: 94.2%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="L2-regularization_1"&gt;L2 regularization&lt;a class="anchor-link" href="#L2-regularization"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Introduce and tune L2 regularization for the models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor &lt;code&gt;t&lt;/code&gt; using &lt;code&gt;nn.l2_loss(t)&lt;/code&gt;. The right amount of regularization should improve your validation / test accuracy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# for lamda in [1 / 10 ** i for i in list(np.arange(1, 4))]:&lt;/span&gt;
&lt;span class="c1"&gt;#     model(lamba=lamda)&lt;/span&gt;
    
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lamba&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
    Train 3-layer NN with following settings:
    Regularization lambda: 0.1
    Optimizer: sgd
    Learning rate: 0.01
    Batch_size: 128
    Number of steps: 501
    n1, n2: 512, 256
Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="c6329555-33b9-497e-80d7-1a5933b2d209"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#c6329555-33b9-497e-80d7-1a5933b2d209');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "6b6986da296646b9aac2266326edcf21", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 22969.777. batch acc: 9.4%, Valid acc: 19.3%.
Minibatch loss at step 200: 13876.185. batch acc: 74.2%, Valid acc: 75.2%.
Minibatch loss at step 400: 9266.566. batch acc: 78.1%, Valid acc: 74.3%.

Test acc: 81.4%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Case-of-overfitting"&gt;Case of overfitting&lt;a class="anchor-link" href="#Case-of-overfitting"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
    Train 3-layer NN with following settings:
    Regularization lambda: 0
    Learning rate: 0.01
    learning_decay: False
    keep_prob: 1
    Batch_size: 128
    Number of steps: 10
    n1, n2, n3: 1024, 512, 256
Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="5b4b3cf8-93b4-4cd9-b93c-6eb8b9e5aed7"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#5b4b3cf8-93b4-4cd9-b93c-6eb8b9e5aed7');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "312b63e26f364cec95540b452b4ec95c", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 2.442. batch acc: 8.6%, Valid acc: 11.4%.

Test acc: 20.7%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Dropout"&gt;Dropout&lt;a class="anchor-link" href="#Dropout"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides &lt;code&gt;nn.dropout()&lt;/code&gt; for that, but you have to make sure it's only inserted during training.&lt;/p&gt;
&lt;p&gt;What happens to our extreme overfitting case?&lt;/p&gt;
&lt;p&gt;&lt;img src="images/dropout1_kiank.mp4"/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
    Train 3-layer NN with following settings:
    Regularization lambda: 0
    Learning rate: 0.01
    learning_decay: False
    keep_prob: 0.5
    Batch_size: 128
    Number of steps: 10
    n1, n2, n3: 1024, 512, 256
Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="373f77a8-f05c-4f06-85a3-b4b62094388e"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#373f77a8-f05c-4f06-85a3-b4b62094388e');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "f5a5be47b2a14f488d9d302df5d5988d", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 2.784. batch acc: 7.0%, Valid acc: 10.0%.

Test acc: 17.3%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Boost-performance-by-using-Multi-layer-NN"&gt;Boost performance by using Multi-layer NN&lt;a class="anchor-link" href="#Boost-performance-by-using-Multi-layer-NN"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is &lt;a href="http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595"&gt;97.1%&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One avenue you can explore is to add multiple layers.&lt;/p&gt;
&lt;p&gt;Another one is to use learning rate decay:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;global_step = tf.Variable(0)  # count the number of steps taken.
learning_rate = tf.train.exponential_decay(0.5, global_step, ...)
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)

&lt;/code&gt;&lt;/pre&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_decay&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1501&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lamba&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;keep_prob&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;
    Train 3-layer NN with following settings:
    Regularization lambda: 0
    Learning rate: 0.01
    learning_decay: True
    keep_prob: 1
    Batch_size: 128
    Number of steps: 1501
    n1, n2, n3: 1024, 512, 256
Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="ad1dccd5-9fd0-47ed-98d0-9f7a78e54460"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#ad1dccd5-9fd0-47ed-98d0-9f7a78e54460');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "ee2b75cf5f6542f99a17c5ad02bc49fd", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 2.395. batch acc: 12.5%, Valid acc: 37.0%.

Minibatch loss at step 200: 0.589. batch acc: 82.0%, Valid acc: 84.7%.
Minibatch loss at step 400: 0.409. batch acc: 89.1%, Valid acc: 86.2%.
Minibatch loss at step 600: 0.396. batch acc: 88.3%, Valid acc: 86.5%.
Minibatch loss at step 800: 0.435. batch acc: 88.3%, Valid acc: 87.6%.
Minibatch loss at step 1000: 0.407. batch acc: 85.2%, Valid acc: 88.5%.
Minibatch loss at step 1200: 0.262. batch acc: 91.4%, Valid acc: 88.9%.
Minibatch loss at step 1400: 0.411. batch acc: 87.5%, Valid acc: 88.8%.

Test acc: 94.3%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Tensorflow"></category><category term="Python"></category><category term="Deep Learning"></category><category term="Regularization"></category><category term="Deep Learning by Google"></category><category term="Machine Learning Engineer by kaggle"></category><category term="Udacity"></category></entry><entry><title>Using TensorFlow to Train a Shallow NN with Stochastic Gradient Descent</title><link href="https://leemeng.tw/using-tensorflow-to-train-a-shallow-nn-with-stochastic-gradient-descent.html" rel="alternate"></link><published>2017-09-21T23:50:00+09:00</published><updated>2017-09-21T23:50:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-21:/using-tensorflow-to-train-a-shallow-nn-with-stochastic-gradient-descent.html</id><summary type="html">&lt;p&gt;The goal here is to progressively train deeper and more accurate models using TensorFlow. We will first load the notMNIST dataset which we have done data cleaning. For the classification problem, we will first train two logistic regression models use simple gradient descent, stochastic gradient descent (SGD) respectively for optimization to see the difference between these optimizers.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The goal here is to progressively train deeper and more accurate models using TensorFlow. We will first load the notMNIST dataset which we have done data cleaning. For the classification problem, we will first train two logistic regression models use simple gradient descent, stochastic gradient descent (SGD) respectively for optimization to see the difference between these optimizers.&lt;/p&gt;
&lt;p&gt;Finally, train a Neural Network with one-hidden layer using ReLU activation units to see whether we can boost our model's performance further.&lt;/p&gt;
&lt;p&gt;Previously in &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb"&gt;1_notmnist.ipynb&lt;/a&gt;, we created a pickle with formatted datasets for training, development and testing on the &lt;a href="http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html"&gt;notMNIST dataset&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post is modified from the &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/2_fullyconnected.ipynb"&gt;jupyter notebook&lt;/a&gt; originated from the Udacity MOOC course: &lt;a href="https://www.udacity.com/course/deep-learning--ud730"&gt;Deep learning by Google&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Import-libraries"&gt;Import libraries&lt;a class="anchor-link" href="#Import-libraries"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# These are all the modules we'll be using later. Make sure you can import them&lt;/span&gt;
&lt;span class="c1"&gt;# before proceeding further.&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cPickle&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Load-notMNIST-dataset"&gt;Load notMNIST dataset&lt;a class="anchor-link" href="#Load-notMNIST-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This time we will use the dataset which has been normalized and randomized before to omit the data preprocessing step.&lt;/p&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Release memory after loading big-size dataset using &lt;code&gt;del&lt;/code&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'datasets/notMNIST.pickle'&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Dataset size: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt; MB'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'train_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'valid_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_dataset'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'test_labels'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;save&lt;/span&gt;  &lt;span class="c1"&gt;# hint to help gc free up memory&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Dataset size: 658.8 MB
Training set (200000, 28, 28) (200000,)
Validation set (10000, 28, 28) (10000,)
Test set (10000, 28, 28) (10000,)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reformat-data-for-easier-training"&gt;Reformat data for easier training&lt;a class="anchor-link" href="#Reformat-data-for-easier-training"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Reformat both pixels(features) and labels that's more adapted to the models we're going to train:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;features(pixels) as a flat matrix with shape = (#total pixels, #instances)&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src="images/flattened_features.png" style="width:70%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 1&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Flattened features &lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;&lt;ul&gt;
&lt;li&gt;labels as float 1-hot encodings with shape = (#type of labels, #instances)&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src="images/flattened_ground_true.png" style="width:70%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 2&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: Flattened labels &lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Notice that we use different shape of matrix with the original TensorFlow example &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/2_fullyconnected.ipynb"&gt;nookbook&lt;/a&gt; because I think it's easier to understand how matrix multiplication work by imagining each training/test instance as a column vector. But in response to this change, we have to modify several code in order to make it works!&lt;ul&gt;
&lt;li&gt;Transpose logits and labels when calling &lt;code&gt;tf.nn.softmax_cross_entropy_with_logits&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;dim = 0&lt;/code&gt; when using &lt;code&gt;tf.nn.softmax&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;code&gt;axis = 0&lt;/code&gt; when using &lt;code&gt;np.argmax&lt;/code&gt; to compute accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One-hot encode labels by compare the label with the 0-9 array and transform True/False array as float array use &lt;code&gt;astype(np.float32)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;
&lt;span class="n"&gt;num_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    
    &lt;span class="c1"&gt;# Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="c1"&gt;# key point1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;


&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;reformat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training set (784, 200000) (10, 200000)
Validation set (784, 10000) (10, 10000)
Test set (784, 10000) (10, 10000)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Logistic-regression-with-gradient-descent"&gt;Logistic regression with gradient descent&lt;a class="anchor-link" href="#Logistic-regression-with-gradient-descent"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;For logistic regression, we use the formula $WX + b = Y'$ to do the computation. W is of shape (10, 784), X is of shape (784, m) and Y' is of shape (10, m) where $m$ is the number of training instances/images. After compute the probabilities of 10 classes stored in Y', we will use built-in &lt;code&gt;tf.nn.softmax_cross_entropy_with_logits&lt;/code&gt; to compute cross-entropy between Y' and Y(train_labels) as cost.&lt;/p&gt;
&lt;p&gt;We will first instruct Tensorflow how to do all the computation and make it run the optimization several times.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-the-Tensorflow-computation-graph"&gt;Build the Tensorflow computation graph&lt;a class="anchor-link" href="#Build-the-Tensorflow-computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We're first going to train a multinomial logistic regression using simple gradient descent.&lt;/p&gt;
&lt;p&gt;TensorFlow works like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with graph.as_default():
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Then you can run the operations on this graph as many times as you want by calling &lt;code&gt;session.run()&lt;/code&gt;, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;with tf.Session(graph=graph) as session:
    ...&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's load all the data into TensorFlow and build the computation graph corresponding to our training:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# With gradient descent training, even this much data is prohibitive.&lt;/span&gt;
&lt;span class="c1"&gt;# Subset the training data for faster turnaround.&lt;/span&gt;
&lt;span class="n"&gt;train_subset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# when we want to create multiple graphs in the same script,&lt;/span&gt;
&lt;span class="c1"&gt;# use this to encapsulate each graph and run session right after graph definition&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data.&lt;/span&gt;
    &lt;span class="c1"&gt;# Load the training, validation and test data into constants that are&lt;/span&gt;
    &lt;span class="c1"&gt;# attached to the graph.&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;train_subset&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;train_subset&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="c1"&gt;# These are the parameters that we are going to be training. The weight&lt;/span&gt;
    &lt;span class="c1"&gt;# matrix will be initialized using random values following a (truncated)&lt;/span&gt;
    &lt;span class="c1"&gt;# normal distribution. The biases get initialized to zero.&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Training computation.&lt;/span&gt;
    &lt;span class="c1"&gt;# We multiply the inputs with the weight matrix, and add biases. We compute&lt;/span&gt;
    &lt;span class="c1"&gt;# the softmax and cross-entropy (it's one operation in TensorFlow, because&lt;/span&gt;
    &lt;span class="c1"&gt;# it's very common, and it can be optimized). We take the average of this&lt;/span&gt;
    &lt;span class="c1"&gt;# cross-entropy across all training examples: that's our loss.&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="c1"&gt;# We are going to find the minimum of this loss using gradient descent.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Predictions for the training, validation, and test data.&lt;/span&gt;
    &lt;span class="c1"&gt;# These are not part of training, but merely here so that we can report&lt;/span&gt;
    &lt;span class="c1"&gt;# accuracy figures as we train.&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As we saw before, &lt;code&gt;logits = tf.matmul(weights, tf_train_dataset) + biases&lt;/code&gt; is equivalent to the logistic regression formula $Y' = WX + b$&lt;/li&gt;
&lt;li&gt;Transpose y_hat and y to fit in &lt;code&gt;softmax_cross_entropy_with_logits&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Gradient-descent-by-iterating-computation-graph"&gt;Gradient descent by iterating computation graph&lt;a class="anchor-link" href="#Gradient-descent-by-iterating-computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now we can tell TensorFlow to run this computation and iterate.&lt;br/&gt;
Here we will use &lt;code&gt;tqdm&lt;/code&gt; library to help us easily visualize the progress and the time used in the iterations.&lt;/p&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;np.argmax(predictions, axis=0)&lt;/code&gt; to transfrom one-hot encoded labels back to singe number for every data points.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;.eval()&lt;/code&gt; to get the predictions for test/validation set&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tqdm&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;
&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;801&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""For every (logit/Z, y) pair, get the (predicted label, label) and count the &lt;/span&gt;
&lt;span class="sd"&gt;    occurence where predicted label == label and divide by the total number of &lt;/span&gt;
&lt;span class="sd"&gt;    data points.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
            &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Calculate the correct predictions&lt;/span&gt;
&lt;span class="c1"&gt;#     correct_prediction = tf.equal(tf.argmax(predictions), tf.argmax(labels))&lt;/span&gt;

&lt;span class="c1"&gt;#     # Calculate accuracy on the test set&lt;/span&gt;
&lt;span class="c1"&gt;#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;accruacy&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# This is a one-time operation which ensures the parameters get initialized as&lt;/span&gt;
    &lt;span class="c1"&gt;# we described in the graph: random weights for the matrix, zeros for the&lt;/span&gt;
    &lt;span class="c1"&gt;# biases.&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Initialized'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Run the computations. We tell .run() that we want to run the optimizer,&lt;/span&gt;
        &lt;span class="c1"&gt;# and get the loss value and the training predictions returned as numpy&lt;/span&gt;
        &lt;span class="c1"&gt;# arrays.&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Cost at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;. Training acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Validation acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;train_subset&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;"&amp;gt;"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            
    &lt;span class="c1"&gt;# Calling .eval() on valid_prediction is basically like calling run(), but&lt;/span&gt;
    &lt;span class="c1"&gt;# just to get that one numpy array. Note that it recomputes all its graph&lt;/span&gt;
    &lt;span class="c1"&gt;# dependencies.&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="0860d758-7822-46d8-b36b-bc7f6fe55457"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#0860d758-7822-46d8-b36b-bc7f6fe55457');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "a776469c0f394bab94bc900cf03f469d", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Cost at step 0: 20.057. Training acc: 6.4%, Validation acc: 10.0%.
Cost at step 100: 2.326. Training acc: 70.9%, Validation acc: 70.7%.
Cost at step 200: 1.868. Training acc: 73.9%, Validation acc: 73.4%.
Cost at step 300: 1.611. Training acc: 75.4%, Validation acc: 74.5%.
Cost at step 400: 1.436. Training acc: 76.4%, Validation acc: 74.8%.
Cost at step 500: 1.306. Training acc: 77.1%, Validation acc: 75.1%.
Cost at step 600: 1.207. Training acc: 77.8%, Validation acc: 75.5%.
Cost at step 700: 1.127. Training acc: 78.5%, Validation acc: 75.6%.
Cost at step 800: 1.062. Training acc: 79.2%, Validation acc: 75.9%.

Test acc: 82.8%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Logistic-regression-with-SGD_1"&gt;Logistic regression with SGD&lt;a class="anchor-link" href="#Logistic-regression-with-SGD"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Or more precisely, mini-batch approach.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;From the result above, we can see it cost about 20 seconds (on my computer) to iterate 10,000 training instances by simple gradient descent. Let's now switch to stochastic gradient descent training instead, which is much faster.&lt;/p&gt;
&lt;p&gt;The graph will be similar, except that instead of holding all the training data into a constant node, we create a &lt;code&gt;Placeholder&lt;/code&gt; node which will be fed actual data at every call of &lt;code&gt;session.run()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The difference between SGD and gradient descent is that the former don't use whole training set to compute gradient descent, instead just use a 'mini-batch' of it and assume the corresponding gradient descent is the way to optimize. So we will keep using &lt;code&gt;GradientDescentOptimizer&lt;/code&gt; but with a different &lt;code&gt;loss&lt;/code&gt; computed from a smaller sub-training set.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src="images/sgd_vs_gradient_descent.png" style="width:70%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 3&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: SGD vs Gradient Descent&lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-computation-graph"&gt;Build computation graph&lt;a class="anchor-link" href="#Build-computation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="c1"&gt;# Input data. For the training data, we use a placeholder that will be fed&lt;/span&gt;
    &lt;span class="c1"&gt;# at run time with a training minibatch.&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Variables.&lt;/span&gt;
    &lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;biases&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

    &lt;span class="c1"&gt;# Training computation.&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

    &lt;span class="c1"&gt;# Optimizer.&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Predictions for the training, validation, and test data.&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;biases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Iterate-using-SGD"&gt;Iterate using SGD&lt;a class="anchor-link" href="#Iterate-using-SGD"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3001&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Initialized"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# Pick an offset within the training data, which has been randomized.&lt;/span&gt;
        &lt;span class="c1"&gt;# Note: we could use better randomization across epochs.&lt;/span&gt;
        &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Generate a minibatch.&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="c1"&gt;# Prepare a dictionary telling the session where to feed the minibatch.&lt;/span&gt;
        &lt;span class="c1"&gt;# The key of the dictionary is the placeholder node of the graph to be fed,&lt;/span&gt;
        &lt;span class="c1"&gt;# and the value is the numpy array to feed to it.&lt;/span&gt;
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;. batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="0b4a2adb-6517-4e80-bf52-c15e62d50b0a"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#0b4a2adb-6517-4e80-bf52-c15e62d50b0a');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "2d2a36e34f9843b5a38a9fe105281093", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 20.939. batch acc: 6.2%, Valid acc: 9.7%.
Minibatch loss at step 500: 2.546. batch acc: 70.3%, Valid acc: 75.1%.
Minibatch loss at step 1000: 1.520. batch acc: 74.2%, Valid acc: 76.3%.
Minibatch loss at step 1500: 1.441. batch acc: 76.6%, Valid acc: 77.8%.
Minibatch loss at step 2000: 1.135. batch acc: 79.7%, Valid acc: 77.1%.
Minibatch loss at step 2500: 1.225. batch acc: 72.7%, Valid acc: 78.8%.
Minibatch loss at step 3000: 0.932. batch acc: 76.6%, Valid acc: 79.4%.

Test acc: 86.9%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;It took only about 3 seconds in my computer to finish the optimization using SGD (which took gradient descent about 20 seconds) and got a even slightly better result. The key of SGD is take &lt;strong&gt;randomized&lt;/strong&gt; samples / mini-batches and feed that into the model every iteration (thus the &lt;code&gt;feed_dict&lt;/code&gt; term).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="2-layer-NN-with-ReLU-units_1"&gt;2-layer NN with ReLU units&lt;a class="anchor-link" href="#2-layer-NN-with-ReLU-units"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Instead all just linear combination of features, we want to introduce non-linearlity in our logistic regression. By turning the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units &lt;a href="https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu"&gt;nn.relu()&lt;/a&gt; and 1024 hidden nodes, we should be able to improve validation / test accuracy.&lt;/p&gt;
&lt;p&gt;A 2-layer NN (1-hidden layer NN) look like this:&lt;/p&gt;
&lt;center&gt;&lt;img src="images/2layer_nn.png" style="width:30%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 4&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: 1 hidden-layer NN &lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;&lt;p&gt;A ReLU activation unit look like this:&lt;/p&gt;
&lt;center&gt;&lt;img src="images/relu.png" style="width:30%"/&gt;&lt;caption&gt;&lt;center&gt; &lt;u&gt;&lt;font color="purple"&gt; Figure 5&lt;/font&gt;&lt;/u&gt;&lt;font color="purple"&gt;: ReLU &lt;br/&gt; &lt;font color="black"&gt; &lt;/font&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/caption&gt;&lt;/center&gt;&lt;/caption&gt;&lt;/center&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Build-compuation-graph"&gt;Build compuation graph&lt;a class="anchor-link" href="#Build-compuation-graph"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In this part, use the notation $X$ in replace of  &lt;code&gt;dataset&lt;/code&gt;. The weights and biases of the hidden layer are denoted as $W1$ and $b1$, and the weights and biases of the output layer are denoted as $W2$ and $b2$.&lt;/p&gt;
&lt;p&gt;Thus the pre-activation output(logits) of output layer is computed as $ logits = W2 * ReLU(W1 * X + b1) + b2 $&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;num_hidden_unit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;

&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Graph&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# placeholder for mini-batch when training &lt;/span&gt;
    &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;tf_train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;placeholder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# use all valid/test set&lt;/span&gt;
    &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# initialize weights, biases&lt;/span&gt;
    &lt;span class="c1"&gt;# notice that we have a new hidden layer so we now have W1, b1, W2, b2&lt;/span&gt;
    &lt;span class="n"&gt;W1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_hidden_unit&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;b1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_hidden_unit&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;W2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncated_normal&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_hidden_unit&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;b2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Variable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;num_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;


    &lt;span class="c1"&gt;# training computation&lt;/span&gt;
    &lt;span class="n"&gt;logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;    
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax_cross_entropy_with_logits&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# optimizer&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientDescentOptimizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# valid / test prediction - y_hat&lt;/span&gt;
    &lt;span class="n"&gt;train_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;valid_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_prediction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;relu&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf_test_dataset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Run-the-iterations"&gt;Run the iterations&lt;a class="anchor-link" href="#Run-the-iterations"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3001&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Session&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# initialized parameters&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;global_variables_initializer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Initialized"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# take steps to optimize&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tnrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_steps&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        
        &lt;span class="c1"&gt;# generate randomized mini-batches&lt;/span&gt;
        &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;batch_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        &lt;span class="n"&gt;batch_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;:(&lt;/span&gt;&lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
        
        &lt;span class="n"&gt;feed_dict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;tf_train_labels&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;
        &lt;span class="p"&gt;}&lt;/span&gt;
        
        &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_prediction&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;feed_dict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;500&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Minibatch loss at step &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{:.3f}&lt;/span&gt;&lt;span class="s1"&gt;. batch acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%, Valid acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%.'&lt;/span&gt;\
                  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_labels&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                          &lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
            
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test acc: &lt;/span&gt;&lt;span class="si"&gt;{:.1f}&lt;/span&gt;&lt;span class="s1"&gt;%'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_prediction&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eval&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Initialized
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div id="a45191ff-0e87-4356-9e61-94bd28e8b795"&gt;&lt;/div&gt;
&lt;div class="output_subarea output_widget_view "&gt;
&lt;script type="text/javascript"&gt;
var element = $('#a45191ff-0e87-4356-9e61-94bd28e8b795');
&lt;/script&gt;
&lt;script type="application/vnd.jupyter.widget-view+json"&gt;
{"model_id": "f379ee5b4ed04eb18e5ee8d6b1e69a17", "version_major": 2, "version_minor": 0}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Minibatch loss at step 0: 409.203. batch acc: 4.7%, Valid acc: 30.5%.
Minibatch loss at step 500: 12.319. batch acc: 75.8%, Valid acc: 80.7%.
Minibatch loss at step 1000: 12.638. batch acc: 74.2%, Valid acc: 80.8%.
Minibatch loss at step 1500: 7.635. batch acc: 77.3%, Valid acc: 81.2%.
Minibatch loss at step 2000: 7.322. batch acc: 80.5%, Valid acc: 81.4%.
Minibatch loss at step 2500: 10.451. batch acc: 76.6%, Valid acc: 80.1%.
Minibatch loss at step 3000: 3.914. batch acc: 83.6%, Valid acc: 82.7%.

Test acc: 88.7%
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Summary_1"&gt;Summary&lt;a class="anchor-link" href="#Summary"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Because we use a more complex model(1 hidden-layer NN), it take a little longer to train, but we're able to gain more performance from logistic regression even with the same hyper-parameter settings (learning rate = 0.5, batch_size=128). Better performance may be gained by tuning hyper parameters of the 2 layer NN. Also notice that by using mini-batch / SGD, we can save lots of time training models and even get a better result.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="TensorFlow"></category><category term="Deep Learning"></category><category term="Neural Networks"></category><category term="Optimization"></category><category term="NotMNIST"></category><category term="Machine Learning"></category><category term="Image Recognition"></category><category term="SGD"></category><category term="Gradient Descent"></category><category term="Deep Learning by Google"></category><category term="Machine Learning Engineer by kaggle"></category><category term="Udacity"></category></entry><entry><title>Simple Image Recognition using NotMNIST dataset</title><link href="https://leemeng.tw/simple-image-recognition-using-notmnist-dataset.html" rel="alternate"></link><published>2017-09-19T20:30:00+09:00</published><updated>2017-09-19T20:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-19:/simple-image-recognition-using-notmnist-dataset.html</id><summary type="html">&lt;p&gt;Today we're going to do some simple image recogintion using NotMNIST dataset. But before creating model for prediction, it's more important to explore, clean and normalize our dataset in order to make the learning go smoother when we actually build predictive models.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Today we're going to do some simple image recogintion using NotMNIST dataset. But before creating model for prediction, it's more important to explore, clean and normalize our dataset in order to make the learning go smoother when we actually build predictive models.&lt;/p&gt;
&lt;p&gt;I motified the &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb"&gt;notebook&lt;/a&gt; from Udacity's online Deep learning course and the objective of this assignment is to learn about &lt;strong&gt;simple data curation practices&lt;/strong&gt;, and familiarize you with some of the data we'll be reusing later.&lt;/p&gt;
&lt;p&gt;This notebook uses the &lt;a href="http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html"&gt;notMNIST&lt;/a&gt; dataset to be used with python experiments. This dataset is designed to look like the classic &lt;a href="http://yann.lecun.com/exdb/mnist/"&gt;MNIST&lt;/a&gt; dataset, while looking a little more like real data: it's a harder task, and the data is a lot less 'clean' than MNIST.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/notmnist.png" width="70%"/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This notebook is mainly foucsing on data preprocessing rather than building models.&lt;/p&gt;
&lt;h2 id="Workflow"&gt;Workflow&lt;a class="anchor-link" href="#Workflow"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Download / load raw notMNIST dataset&lt;/li&gt;
&lt;li&gt;Drop unreadable images and save the remaining images&lt;/li&gt;
&lt;li&gt;Combine all images and divide it into testing/validation/test set&lt;/li&gt;
&lt;li&gt;Shuffle / Randomize the dataset&lt;/li&gt;
&lt;li&gt;Remove duplicate images appear both in train/test or train/validation set&lt;/li&gt;
&lt;li&gt;Build simple model for image recognition using different size of training data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="After-finishing-this-notebook,-we-learn"&gt;After finishing this notebook, we learn&lt;a class="anchor-link" href="#After-finishing-this-notebook,-we-learn"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Use matplotlib to read images, transform them to ndarray and render.&lt;/li&gt;
&lt;li&gt;Identify whether there exist unbalanced problem for the labels of classification .&lt;/li&gt;
&lt;li&gt;Understand why it's important to have both valid and test set.&lt;/li&gt;
&lt;li&gt;Identify the importance of randomizing data for better efficieny when training sequentially.&lt;/li&gt;
&lt;li&gt;Identify duplicate images between training/test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Import-libraries"&gt;Import libraries&lt;a class="anchor-link" href="#Import-libraries"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# These are all the modules we'll be using later. Make sure you can import them&lt;/span&gt;
&lt;span class="c1"&gt;# before proceeding further.&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tarfile&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;display&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scipy&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ndimage&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves.urllib.request&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;six.moves&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;cPickle&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;

&lt;span class="c1"&gt;# Config the matplotlib backend as plotting inline in IPython&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Dataset"&gt;Dataset&lt;a class="anchor-link" href="#Dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Download compressed dataset if the dataset is not available yet&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;First, we'll download the dataset to our local machine. The data consists of characters rendered in a variety of fonts on a 28x28 image. &lt;strong&gt;The labels are limited to 'A' through 'J' (10 classes). The training set has about 500k and the testset 19000 labeled examples.&lt;/strong&gt; Given these sizes, it should be possible to train models quickly on any machine.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'https://commondatastorage.googleapis.com/books1000/'&lt;/span&gt;
&lt;span class="n"&gt;last_percent_reported&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
&lt;span class="n"&gt;data_root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'./datasets'&lt;/span&gt; &lt;span class="c1"&gt;# Change me to store data elsewhere&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;download_progress_hook&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;totalSize&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;"""A hook to report the progress of a download. This is mostly intended for users with&lt;/span&gt;
&lt;span class="sd"&gt;  slow internet connections. Reports every 5% change in download progress.&lt;/span&gt;
&lt;span class="sd"&gt;  """&lt;/span&gt;
  &lt;span class="k"&gt;global&lt;/span&gt; &lt;span class="n"&gt;last_percent_reported&lt;/span&gt;
  &lt;span class="n"&gt;percent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;blockSize&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;totalSize&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;last_percent_reported&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;percent&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;percent&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;%s%%&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;percent&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"."&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
      
    &lt;span class="n"&gt;last_percent_reported&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;percent&lt;/span&gt;
        
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;maybe_download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;expected_bytes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;"""Download a file if not present, and make sure it's the right size."""&lt;/span&gt;
  &lt;span class="n"&gt;dest_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dest_filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Attempting to download:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlretrieve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reporthook&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;download_progress_hook&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;Download Complete!'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;statinfo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dest_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;expected_bytes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Found and verified'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="s1"&gt;'Failed to verify '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;dest_filename&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'. Can you get to it with a browser?'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dest_filename&lt;/span&gt;

&lt;span class="n"&gt;train_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'notMNIST_large.tar.gz'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;247336696&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_download&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'notMNIST_small.tar.gz'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8458043&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Found and verified ./datasets/notMNIST_large.tar.gz
Found and verified ./datasets/notMNIST_small.tar.gz
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Extract-the-dataset-into-folders-by-characters"&gt;Extract the dataset into folders by characters&lt;a class="anchor-link" href="#Extract-the-dataset-into-folders-by-characters"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Extract the dataset from the compressed .tar.gz file.
This should give you a set of directories, labeled A through J.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;133&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;maybe_extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;root&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;splitext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="c1"&gt;# remove .tar.gz&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# You may override by setting force=True.&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; already present - Skipping extraction of &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;.'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Extracting data for &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;. This may take a while. Please wait.'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tarfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extractall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_root&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;data_folders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_folders&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;num_classes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="s1"&gt;'Expected &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; folders, one per class. Found &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; instead.'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_classes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_folders&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_folders&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data_folders&lt;/span&gt;
  
&lt;span class="n"&gt;train_folders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_folders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;./datasets/notMNIST_large already present - Skipping extraction of ./datasets/notMNIST_large.tar.gz.
['./datasets/notMNIST_large/A', './datasets/notMNIST_large/B', './datasets/notMNIST_large/C', './datasets/notMNIST_large/D', './datasets/notMNIST_large/E', './datasets/notMNIST_large/F', './datasets/notMNIST_large/G', './datasets/notMNIST_large/H', './datasets/notMNIST_large/I', './datasets/notMNIST_large/J']
./datasets/notMNIST_small already present - Skipping extraction of ./datasets/notMNIST_small.tar.gz.
['./datasets/notMNIST_small/A', './datasets/notMNIST_small/B', './datasets/notMNIST_small/C', './datasets/notMNIST_small/D', './datasets/notMNIST_small/E', './datasets/notMNIST_small/F', './datasets/notMNIST_small/G', './datasets/notMNIST_small/H', './datasets/notMNIST_small/I', './datasets/notMNIST_small/J']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-1---Sample-some-images-in-dataset-and-render-them"&gt;Problem 1 - Sample some images in dataset and render them&lt;a class="anchor-link" href="#Problem-1---Sample-some-images-in-dataset-and-render-them"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's take a peek at some of the data to make sure it looks sensible. Each exemplar should be an image of a character A through J rendered in a different font. Display a sample of the images that we just downloaded. Hint: you can use the package IPython.display.&lt;/p&gt;
&lt;h3 id="For-each-character-folder-in-dataset,-randomly-choose-one-picture-in-it-and-render-them-horizontally"&gt;For each character folder in dataset, randomly choose one picture in it and render them horizontally&lt;a class="anchor-link" href="#For-each-character-folder-in-dataset,-randomly-choose-one-picture-in-it-and-render-them-horizontally"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use &lt;code&gt;os.listdir()&lt;/code&gt; to get list of file in a folder&lt;/li&gt;
&lt;li&gt;use &lt;code&gt;mpl.image.imread&lt;/code&gt; to read in image as ndarray, and use &lt;code&gt;plt.imshow&lt;/code&gt; to render ndarray as images&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;ls ./datasets/notMNIST_small/
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&lt;span class="ansi-blue-fg"&gt;A&lt;/span&gt;        B.pickle &lt;span class="ansi-blue-fg"&gt;D&lt;/span&gt;        E.pickle &lt;span class="ansi-blue-fg"&gt;G&lt;/span&gt;        H.pickle &lt;span class="ansi-blue-fg"&gt;J&lt;/span&gt;
A.pickle &lt;span class="ansi-blue-fg"&gt;C&lt;/span&gt;        D.pickle &lt;span class="ansi-blue-fg"&gt;F&lt;/span&gt;        G.pickle &lt;span class="ansi-blue-fg"&gt;I&lt;/span&gt;        J.pickle
&lt;span class="ansi-blue-fg"&gt;B&lt;/span&gt;        C.pickle &lt;span class="ansi-blue-fg"&gt;E&lt;/span&gt;        F.pickle &lt;span class="ansi-blue-fg"&gt;H&lt;/span&gt;        I.pickle
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;characters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'abcdefghij'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# sub folders to choose images from &lt;/span&gt;
&lt;span class="n"&gt;image_per_folder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;# number of images to show for each folder&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BASE_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'./datasets/notMNIST_small/'&lt;/span&gt;

&lt;span class="n"&gt;list_of_images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_per_folder&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;characters&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;char_folder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BASE_PATH&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'/'&lt;/span&gt;
        &lt;span class="n"&gt;images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char_folder&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;image_file_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="n"&gt;list_of_images&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char_folder&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;image_file_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;showImagesHorizontally&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_files&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.image&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;
    
    &lt;span class="n"&gt;number_of_files&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_files&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;num_char&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;characters&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;number_of_files&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;num_char&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_char&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_char&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_files&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;num_char&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'off'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;showImagesHorizontally&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list_of_images&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAABnCAYAAACJvUq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJzsfVdzJNlx9WnvvfcAGsAAGLezXEohSsHg0/cLpCe96Pfo
vyj0wgcpqAhKCnLJWDM7Fhj4hulGe+/t9zDK3NuFgneN2ToRHZgBuqtvVd26N0/myUzVZDKBAgUK
FChQoECBAgUKFCi4H6gfegAKFChQoECBAgUKFChQ8EuCQsIUKFCgQIECBQoUKFCg4B6hkDAFChQo
UKBAgQIFChQouEcoJEyBAgUKFChQoECBAgUK7hEKCVOgQIECBQoUKFCgQIGCe4RCwhQoUKBAgQIF
ChQoUKDgHqGQMAUKFChQoECBAgUKFCi4RygkTIECBQoUKFCgQIECBQruEQoJU6BAgQIFChQoUKBA
gYJ7hELCFChQoECBAgUKFChQoOAeob2Lg6pUqskNPjv1U/pvAJhMzj/8ZDKZOg69dDodtFotgsEg
FhcXsbi4iIWFBSSTSYTDYbjdbrjdbvz+97/Hv//7v+Mvf/kLms0mGo0GxuPx1DguGoPcORHG47Hq
jLeed4wzv1Cr1UKr1eLFixf4p3/6J/zjP/4j7HY7TCYT9Hr9qXHIXVvxfCaTCb9uAvE4w+EQg8EA
g8GA/91ut9FqtdBoNFCpVFAul5HL5ZBOp5FOp5HNZnFycoJarYZ+v4/BYIDxeCw7tslkcqvX9BKf
PXVf1Wo1NBoNNBoNtFotdDodPB4P3G43gsEgIpEIIpEI/H4//H4/XC4XzGYzzGYz9Ho930e1Wg21
Wo3JZILxeIzRaDT1ot+1Wi20Wi3U63VUKhVUKhWUSiUUi0UUi0WUy2WUSiU0Gg20Wi10Oh3+7Hg8
5hddS+l1vc41pY9e97rSOERI7/lN56XccyxeE+n1HgwG6Pf76PV6/Op0OlPXv16vo1ar8TymV7Va
RbPZRLPZpHt2rWv61VdfTdRqNUwmE0wmEzQazZnndFVIn/2rQG4t0Wg0ss+CXq+HwWCA2WyGyWSC
xWKBxWKB1WqF3W6HzWaD0+mEy+WCxWLBf/7nf+IPf/gD3r9/j0KhgEKhMLW233Su3uT5vwmMRiOM
RiP8fj+ePXuG58+fY35+HnNzcwiHw3yP9Xo99Ho9dDodjffW7vNoNMJwOMRwOESpVEKhUMDe3h6+
/fZb3vc+fvx4L9dU+jzS+ifOIavVynMjFAohFArB5/Pxnu10OuF0OmG323lNNRgMvOer1WqoVKqp
86Y9pdfrod1uo91uo9FooNFo8DPbarVQrVZRrVZ5fS2Xy6jVavx3uTX1Nvcp3HA9BabXUJVKBbVa
jY2NDfzP//wP/vSnP2F7exs7OzuoVCp8rWj/uQiijUWfcblcWFhYwMLCAn73u9/hd7/7HVZXV3kc
9H61+vw4gNx6NBqN0Ol00G63MZlMEAwGr3xNh8Oh7DW9yvN1GVv1riG3dl9lDT/rvVqt9taffem6
/erVK3zzzTf4+uuv8fLlS7x8+RImk+nMz30BkD2ROyFh18F5RIse2utMLqPRCIvFArvdzou3x+Ph
BXs0GuHg4AD5fB5WqxUWiwUbGxsoFosYDAYYjUY8PnESXTQx5B6Ou5pMarUaOp0OKpUK/X4fjUYD
KpUK4/EYw+GQF1Xa1Oj/Z43ntsYpvWdqtRparZY3LDLI7HY7XC4XgsEgotEoFhcXUa1Wkc1mkc1m
kclkcHx8jHQ6jXa7jU6ng8FgcCtjvM45EUSDQafTwel0wuFwwOPxwOfzwefzweVywe12w+FwwGaz
wWaz8T0gA16OZEmJMN0vrVbLxplWq4VGo4HNZoPFYkE4HObNiY7daDSYIEj/X6vVUK1WmRxfZsO9
TxB573a76Ha7bDzRM3lZSDdJ0QCQPhdkFJDxBwAGg2HKeCMnQq/XQ7/f5/HRtW+32ygWi8jn8ygW
i3y9rzpuEX//938PrVbLhigZ5qJBc13clNQSRKNEvLZ0fcnJQISMSJler4fRaITBYGByptVqmZxZ
rVbUajXZ77qtsd8nfD4fEokEFhcXsbKygrW1Nfj9fl4n6PqIc/C29w5x3lutVgBAv99HPB7HyckJ
ms3mrX7fWWMgiPfRaDTCbrfDbrfD4/GwI8vr9TLpcrvdU4SLiL3RaOS5RddPvIb0ovk4Go1gNBph
MpnYCdDtdtnZ0u/3T62ptI6Sg1bud7QO9Pv9O7+OCq6OSqXC/5Y67M+DuHeIa9pN1+CbQHTW0v54
lhNA7rNy5M3n893pmBX8jJkhYcDPRrvcxLnuZmswGOByuRCJRPD8+XO8ePECNpuNDc9CoYDDw0N0
u132mm1vb6NYLKLf75+KgNE45f590bjvymAgcqNSqdDr9VCv1/lajkajKY/0ZDKZ8lSfhdteVCiy
Iz7wtFCI0QfRS5nL5ZDNZrGzs4PXr1+j1+uhXC6zEUzjvC9IiTidi0ajgdFohM/nQywWw8LCApaX
l5FMJuFyueByuWAwGPh8ybMqviiq0m63eW6KXksyLIi02u32KS+wzWaD1WqdiqB1Oh10u13UajWU
y2UUi0WOLqbTaRwdHXFEkq7/rECMoLZaLdRqNTaOLkvA5cgXMB2poU3UYDDAaDTyGiAacNJ7TtdX
On/Fn7lcDplMBrlcjqOUw+Hw2tfjN7/5DXQ6HYLBIILBIIxG4ynnzm08CzeJhMn9Xk6RIJIzkbCJ
xvF4PIbFYmEHA0X0H9LYuS1QBOzVq1dYWlrC8vIyE08xEk4Ogbs4XzEKYbVaYTabAQDxeBzZbBbt
dvvWv1P6/Wft9yaTCR6PB5FIhKMp4XAYfr8fPp8PFouFI13isyxeNzlHI32fRqOZepale5H0Je5N
5AQkBUe9Xkcmk0Emk0E2m0U+n0c+n0epVOIIuoLZA5EwOcfRWZASMHIeib97CNA8HQwG6Ha76Pf7
lyZi4tyn/wMKCbtPzBwJIwOIPKY6nY4XWOC0VE40hkSPPj0YXq8Xc3NzSCQScLvdAIBGo8GRgWw2
i1wuh3a7zZ8hw4mkc2IYX4rziJdoJIkeudsGka1Go4H9/X18//33sNlsUxuVRqPhiKDdbueojShX
JHLT7XbZq0e4judZzgATjVudTseSEZ1OB4vFMvU9ZrMZTqeTQ9R6vR77+/tIpVLI5/NT9+euId57
tVrNnnuHwwGXywWv14toNIp4PI5oNIpYLIZwOAwATCTomopyNYpGEQGjKN9ZJIw8tjabjUmYy+WC
w+GAw+HgaC55hykS5/V6EQwGEQgEEAqFEA6HEQ6HEYvFOOJYLpdZdvfQUTHaHNrtNrLZLI6Pjzl6
1+12r3w80SCTi86QF53kcVarlQm00Wi8cIOWgo7ldrvZS34TktvtdpmUTiYTngtGo3Equn1ViEam
VJ56VUiJl1w07Kw1VFxjSTZmMplYpqjX66+shnhoiGsZEX2DwYBoNIonT55gdXUVkUgEXq+XI5vS
z0pxm1FLUXZGjjzaR++SPIjnRnuBXq/nvSkUCiEWiyEWiyEejyORSLD00Ol0sqMEAO8BnU6H5YVi
xJrmNzAdNRb3ItHWoBfJQMWI82Qy4e8Qo2NerxeBQIAJWD6fx/b2Nvr9Plqt1p1dRwXXx7fffsv/
ljqI5CA68Og5drvdHMGmqP59E7HxeIx+v49+v8+y4nK5zJFcce7LQeqMICwvL9/L+B/Ten5VSM/t
rLk1MySMFkiSBlitVvbu06QHcEqyJeYatVotNJtN9Ho9Nq6i0ShWVlaQSCRQr9fx8eNHztuoVCr8
mcFgwA8hRSUoEiY1Ei5zLiJUKhV7TS7SQF8HZJjlcjm8efMG2WyWZT4kU1SpVAgEAryxLS4usnSD
0O120Ww2kc/nkUqlkEqleIO+rjdWGrrX6XRsPIpk0GazsayPrp/ZbObPms1mJBIJ/PDDD1Cr1RgM
Bkxq7powSKOdJAvz+XyYn5/H4uIi5ubmWIJoNpuh0+kwGo1wcnKCk5MT9pIWCgWeX51OZ0r2IjoR
pNp5MrSJuNJ8ovwRIl8+nw+hUIilnZFIBEajES6Xi2Wf0WiUHRG1Wg0fPnzA+/fvsbOzg3K5PBPS
RCJhzWYTh4eHePfuHV/Her1+5ePJRcWIHIiRMKfTCb/fj0AggOXlZSwtLbEhdplnl76HvPlms5mJ
7U02nHfv3sFgMKBYLKJUKnFELBAIsNEodZRc5pkdjUYspzxLlnqZcUs9ytJnntYiitiLx5aT3gKf
VQxkmNP6L37fLG/gYqQHAHQ6HVwuFzweD+bm5pBMJpFIJGC1Wqfed9E9u07ehzgm6XcQ4aX9s1Qq
IZ1Oo9FoXPn4VxkD8PkcdDodjEYj3G43kskkFhcXEY/HEY/HEQ6HYbfb4XA4WG5I84CMT9oDRLk1
7ekUOe/3+7yeiHlmZFeYzWZ2bNF8Ixks7Us0bp1Ox8cwGAzssAkEAlNrqsFgQKFQQC6Xm+l5+kvF
v/3bvwG4fD4XPc96vZ7nSjKZxNraGqcEUMDgPjEej9HtdlGv15FKpbCxsYHd3V1+FsiZe1E0TPwJ
AP/yL/9y10Of+t5f8jMyEySMJrhWq+Xoh9vthsfj4SRti8UCAGwoEBGj3Ixer8eyn06nw5GDeDyO
J0+eIB6P44cffsDm5ibngJVKJR7DRZPgPEnief+n8yIP+12QMCKmVJDh/fv3pzzPk8kECwsLePr0
Ker1OsxmM2KxGB9jMpmwdO34+Bhv377F69evWb5xHRImGrtkhImRHJ/Px8bkeDxmQ5JeRDIcDgci
kQgTZTrP8Xh8555GOVmVwWDgCOvLly/x61//Gk+fPuV5SrLJYrGIw8NDvHnzBltbWzg8PGQJ4Gg0
utHCIxpuFJkzGo2IxWJYXFzE0tIShsMhF2ixWCwcUVSpfs4XHAwGcLlcGI1GaLfbGA6HqFarN7xq
NwdFd5vNJo6Pj/H+/Xvs7e0hlUpNPbc3Bc1PIrZ+vx9zc3OYn5+HXq9HMBiE0+mckm/R+OSORaC5
S0T6ppvMhw8foNfrUSqVuNiKSqWCzWaDyWRiGZtU/nzRc0tR2nq9zkarKJu87LilEQbRYUC5Xmaz
mZ06UmWD+F00bikJm3XidR70ej2cTicikQji8Tjm5+cRi8VOFUwgnHfvbsNoEUkiRZLq9TqKxSIy
mcypHLzbgDTSMJlM+B6HQiE8e/YMf/M3f4NkMolYLIZAIHBqPovRqEajwU4JikBRQaJKpcKFMzqd
DtsLNC9J2m2xWOBwOOD1euH1elny6PP5eHyiI1MkcDQmr9cLAHwdu90uCoUCfvrpp1u/hgpuB7//
/e+v9H7RJqE8xUajAavVCp/Px0qe+wYVKanX6zg8PMRPP/2EH3/8kfcJcv491nXzMeKq13omSJjT
6ZxKvvV4PNBoNLxBtdttdLtd9thRTgh50kwmE9xuN+Lx+ClZgd/v54pTlEfT6/XYeyUmM4qJ/xRd
Ej27ohZYlPmRN528vuRVFyUNouFxH5AaN+JGLzeWyWSCTqeDSqXC+SwHBwenImHXyRkRvY/k+TQa
jex5dLlcLI+j4imBQGBqnLR5BoNBPHv2DIPBgKOad53LRAuw3+/nCFMymUQymcTc3Byi0Sj0ej2K
xSJ2d3eRy+VwfHyMo6MjHB0d4fj4GNlsFrVabWpeice/jswT+Pl+DIdD9Ho9lEolqNVqtNttVCoV
pFIplvZEo1E2amlOUgXHZDKJer2OTqeDdDp9exfvFiCVi1w3KitCvAdkiAKY8p6TnOmsMV30u5tE
LaQ4OTmBRqNBo9HgqGqxWEQul8P8/Dzm5+fhdDovHKM4tslkgkKhgI8fP2Jzc/NU0RtxXl7WSSUX
YaRoA+V4ORwOrmbndDq5MAR9nr7XYDCww0YaCXuMkBaKAOQ98RdJEW8y/+n60nrR6/WQTqdxfHyM
ra0tbGxsIJ/P37pzS3zWKJpgsVh47i4sLHC1Yq/Xyw4MUgVQXmi1WmUDk17lcnmqMAZJuyk/hiJh
9MyLRIpkvRTRIvmry+WCz+djuRnJvkmdQ3JIgjSiK71XihH8ZeAu9qLbguj0nrWxyUE6XhGXVZ19
CZgZEjY/P49EIoFAIMChfYpWtdvtU5It2uiJWFEJ8Gg0CrfbzaQIAC/itLgCP5folZaeFhdusagF
SWv0ej3LFMQSuJQjRHlXtFjTgk2Sn/tcjCk3To6EyT2knU4H1WoV+XyeCzeMRiNZr/VlIRoWIiEj
AkAeJNL+r62t4dWrV3wPAUyR4EAggGfPnmEy+VzgYmtrC71e7xau1vnnQN/9/PlzPHv2jBPqSSoz
Ho9RLBbx6dMnbG5uYnNzEzs7O6cMAjL2xesvlS6dNw45EIkYj8col8totVrI5XJIpVJwOp1YXFzE
q1evMBwOEYlE2Pig++D1epFMJtFqtZDJZE4ZGA8J6TW6i82Frt9oNOI1gAqAiMbUQ24KmUwGKpUK
uVwOWq0WmUwG+Xye5U5+v/8UCTsPZOAWCgW8efMGf/zjH9mApYiz+N6rQHzOaa7RWujxeKZyfdRq
NeeCSgnJeSTssRm1dE3EcunSv19lfl3VoSclBRT5rtfr2N3dxdu3b/Hx40fs7e2hUCjc6poqrm9E
wqga7ldffYVf/epXePLkyVQOJsnkKWJfr9dxdHSEw8NDlspnMhnOrRXbn0irxJEjRZR3i84Ccg6K
0lly0gYCAcz9n3x0fn6ei+KIaySdl1xVWwVfDqSOplkkCXJEbFbnovgM3mS/mUXIpSSdhQeztkTZ
isfjQTwex9zcHAwGA0vj6vU6yuUyJ8GSETsajaYqJDmdToTDYfaqeTweJlWk0S4Wi1x8w2w2M0mj
hVrMLRMXc6nxp9PpOIJDvVyIfIk9b+x2O0d8hsMhCoUC8vn8jSqkXQfipkCyQJPJxBIL8X1UWbFS
qXDVPiJyUjJ3m9Dr9fy94/GYyTLlA5AUSaVSwel0IpFIoNPpYHNzE3a7/U4eWvo+Kr7hcDiwurqK
ly9f4tmzZ2xEkiwmn89ja2sLb9++xadPn7Czs4NUKgVA/oGUkx9dF6IRQBW8qCKiXq9nrzb1FptM
JggEApybZ7VaOWJMJbIfqtLTQ0Cc06IRJxcFu+zGe9tzkorkkKFHxVNGoxGSyeSVi5XQfGk2m0in
09jY2OBcRTE/9rrPO63v5GihQjFut5slZI1Ggx1rRLbEHFWRhFEBkse6QYuyoXK5jHw+D5/Pxzmd
F80r2qfElghXuRY0b0i63m63Wbb37t07vHv3jqsCN5vNW9unxPMip6Xf70cymcTS0hJevHjBfdIo
hYDmdaPRQLVaZYn8/v4+F2ZKpVLI5XJcHv625oUoO8vlcvB4PFxAqVar8d4j9ngUz5OeKwVfJmY1
CkaY1XHJQVyPHuu6fh6kkXFxbxNxryRMZOVU1ttgMHA5WpfLhcPDQxwcHKBUKqFSqaBerzNBEg0j
KuxAxiNFwAwGAzqdDo6Pj3F8fMwacZIs1Ot19kgSISEyJZYIpoksEjNKWqfPiC8iZkQMDQYDR9rq
9Tr29/fx6dMndLtd/PM///ODXHOKOjkcDtkiIZScTWXS6fN0Peja30UkolarYTwec1U5tVrNidpG
o5HfR8UTyEsZDAZlG/zdFOShcbvdWFlZ4WpmKysriMfjsNlsXHhjc3MTW1tbHAGjBtOi50wqDb2K
1Eu8Thf9Trw3o9EI/X4f+XweHz58YPlOq9XC4uIiV0mk6oDk2DAajdeqQHgXkJPU3saCfdYxpJG3
WYFI3MU8nkajgW63O/VsXkbKQcaiKPGW2wyvcg2k+TuUs0sEgBQGnU6Hq9JSH0CKLFNhHjESRg4v
nU53biPcWYM4PqpeNhgMuFG7SqXiSqoXOT1IPlipVLgk+mWNfSn5EslguVzGyckJMpkMOypvi0RI
5w5VdE0mk/jVr36FV69eIRaLwefzsbxfpfrc67LZbKJSqWB7extbW1s4OjpCOp3GyckJN06mIlxy
33UTTCafK0SS7dHv91EsFrG/v88l8+f+r+JyLBbjCJpIxGZ9bipQ8NCgZ4uKQonR+sf+/Ij7NJ3b
g5MwqUFKxQRsNhu8Xi9XQvrxxx/x7bffTkkMCHRjtFotgsEgbDYbl9yOxWIsW6GKaq9fv8bJyQk3
TBWlBmazGXq9nvPQRL03RbAot6bdbqPZbHLFJVp0xZLWlN9AfSMAoFwuo1QqoVarYX9/Hz/++OO9
NME8CzqdDlarFQ6HAyaT6VShgX6/z2V3pQ/FTSSJF2E8HrPefzweQ6PRYDgcQqfTIRKJwO128/cS
waUKdndFwlSqzwVVXC4Xnj59it/97ndIJBKIRqNwuVzsFMhkMnj9+jX++te/cg6Y2GPnPCJ2V6B7
RREdqsr46dMn7gkGfPZMh0Ihzquk4h00/2cFZ+Vb3BVmiXyJEOeQGFmhfNnLQoycirLsszySl90U
pe8jwkTHV6lUqNVqyGazAMD5kicnJ1Cr1ZyzSBCl30TCyBE365u01NHS6/U4AkjOOooUUiuL80BN
y4vFIjY3N/Hhw4cL77koPSRjgBQORMCIGF6nCfpF3y2SEuAzCYtEIlhZWcGvf/1r/Pa3v2Vpn7gX
kePy5OQEb9++xZ///Gfs7++zY1a6Dogyw5uCjkskrF6vI5/PQ6VSwWQyYWlpCYeHh3j58iU0Gg18
Ph+fg0LCFCi4PET5vzTyPqt78FVAJIxUK+LeJuLB5IhikQu1Ws03pNfrcXI4sUcqv01eUYfDgfn5
eczNzSEWi8HtdkOtVnPxg5OTE2xsbGB9fR3lchmNRgOdTmcqf4vkgyQdJAOUyuCSZ0vMEaGS9SRP
83g8UKlUsFgsvEnS5pHNZjnykMlksLW1hXQ6fef5S1KIm4F47nTdRVDjXpJ+iscQDbfbhFTm2G63
kc/nYbFYsLS0xJWtpDlUVHHS5XLdeg6TWq1GKBRCJBLB6uoq1tbWkEgkOGGcktnT6TTevHmDzc1N
HB0doVKpnGrwLY0O3MfmLOYCit/b7/eRyWTw4cMHNsDVajVHbylZftZI2H3jNu7RXUSLpf8/i5Re
97svE2m96ufl/k4/m80mTk5OoNVqEQ6HEQgE0Ov1uCouzUlab2kTo7kMzPZmfdY9I1m4NLdI7jP0
HDebTRQKBRweHmJnZwfr6+uypEl0nBFEMkxKB3IqdjqdqXX9NtenyWTCharMZjOWlpbw8uVLPH/+
HNFodIqAUantXq+HVCrFyoL19XUcHR2hXC6zA+msMd722krkjq5Nr9dDoVBgJQ05C+PxOGKx2J04
Ax8K0sj7VT6jQMFlUKvVkEqluFKpyWRCMBiE2+2eIixya9os4CyHJXGYarXKBdr6/f6ZZf8fNCeM
JIEqlYqbBFNC/Hg8ZtIgVqWjF5WUFZO20+k0Pn78yOXADw4OWFpHhry0f420hw3lw5A8RNoQ2GAw
IBwOIxKJoNfrwWAwwOVyodPpAADy+Tx++OEHvH79GsVikcvmk6b8riv5EeQmrig7ozwrESIJEytQ
0iZ9Hx5o8vZqNBouykIFUkTSSL3DqFHibUKtViMSieCbb77BixcvsLKyglgsxgnjFNl8/fo1V5Y7
OTlhAkalwqUE7D5wkcwun8+j0+lwnphWq2VZDUWITSbTzMgR7xuzakRcVbp6W993m98plXpSKe/h
cMiFRSaTzy0xXC4XO4qol6DD4eCWJOJxHhsoR456YIoqA/opSkqJhOVyORwcHEyRsMvk7olkXZT2
iz3hrmN0y0Ga56rT6WC32+HxePDkyRP87d/+LVZXV+F2u6dan1C+arVaxfb2Nv7617/i9evXKBQK
KBQK3D5Der/v8rmQzq/xeMwtcOj6US8mt9v96EiY1LEp9/erEDAFCs6DdC5Vq1W2+8kZs7KyAo1G
M+VwA2Z7fklllFRl/PDwED/++CN++OEHtNvt2SNhBHHz0Gq1cDgcCIfD6PV60Ov1XDmPymzHYjGE
w2EmVL1ejxOJNzc38ebNG2xsbHAvqcsmGEsTLsUyy0QGzWYz7HY7a1jJ4NZqtRgOh2g0GshkMlhf
X8ef//xnzmkjgvYQECeIXCRM3MSIhImRSPEYdxnJoePSxqZWq1Gv17nrOxkq9DCKctbrlv6XMxio
yMrc3ByeP3+O58+fIxKJwOPxsAFYKBSwu7uLn376Cbu7u0in06hWq6c27Yc06OUWr8lkwrLPwWDA
TaXH4zH3OCEjmBoU/1Ixi5Ki+x7PXRq2ouNtMBgglUqxFNzlciESiUz1GiPnUaPReJRFY0j1odPp
4Ha74fP5uJn3WWsGOb+GwyHK5TIODg6wu7uLg4MDpNPpUxH3694v8Z7c5j0nCR9VGKS82oWFBc4z
pnETIT86OsKnT5+4WIi00fldjPOssUtBVZabzSY7JXu9HkKhENbW1lg2/1idAwoU3BdUKhUXgur1
erBYLByU8Xg8Uy2K5FRFs/J8SdddlUqFdruNYrGIg4MDfPz4Ed9//z0ajcaZx7g3EiZ69oCfcxqo
H5jFYuHmldS8l3JVqHcYRW+oWtLx8TEXdBiNRhz6owRj6XdKcdZCS5s8ReEo/ygQCLDH1ul0wu/3
IxQKwe12T/UwKZfLqFarHMV5qAkjbgjS5qmihp3eOxgM0Ol02NMnPdZ9jVnMVaGX1PASz+u6Rpl0
M7darVzkZW1tDclkEqFQCDabDSqVCtVqFdlsFltbW9je3sb+/j4KhQI6nc7M5gOc5d1ut9s4ODjg
fJ3BYACDwYBsNjvlIVeg4DZwlmRSpVJhNBqhUChga2sLVqsVoVCIez5qtVru80TR8FnZgM+DNEJl
NBp5/3jy5AmWlpYQj8fhdDqnnGHidaFns9Vq4ejoCB8+fMDGxgYKhcJUBOuiSJiIi6R8t7V2kQHl
8XiwurqKr7/+GouLi3A4HFPrNRUMqVar2NzcxA8//ICNjQ2cnJywA04qrb7oXG4D50l8qXgI5TdW
KpWpPOrHQsLEOXOf11KBAhGDwQD5fJ5rNESjUe7tazKZpqriPobnimT2h4eHXG1WrBMgxYNFwoiE
Uelds9ntL/CnAAAgAElEQVSMWCyGUCiEb775hr3xVMHQbDYz+To8PMT79+/xl7/8BcfHx3yDqPoW
LYZSSYd0IaWftMhLq24ZjUaEw2Gsra1haWkJS0tLXMlKo9FwA2iz2cwae6rGWKlUTjXmfajFSNpk
2mg0nipRD2CKhIkFUe4ScnkTIgkjKakcKRCbQF8X4gZvtVqRSCTw4sUL9tiGQiE+fqVSwd7eHtbX
17G1tYX9/X00m03O8xB70swSpOFyAGi1WkilUiyjHA6HcDgcyOVyU1FQBbONWSP954HGKpIOAFw8
ptFowGKxIJlMolKp8FpFic2UhyN1Hs3ixiwtTGEymRAKhTgatLy8zH3S5CL5lItEecYiCWs0Gnwd
r2rwyxGau5g/pBAhEvYP//AP8Pl8sNvtU/efKrhWKhVsbm7if//3f3F8fIxKpYJer3cqSveQ0WDx
OlORk8lkgkqlwhJ+UsfMqlNODnLju+q4Z/0cFcwORNt7MplwBedWqwWv14ulpSUuwEOF7sT5OIvr
vQiRhBUKBc69PQv3SsKkXiwiKScnJ1ztiXpvUMl4ipSNx2OUSiUmYVtbW1xWVzzmeTdKbsMWpZBG
oxEmkwlOpxMulws+nw+hUAiBQIBzlIbD4VQlRDoGGeh7e3v8PlEucp8QN1ox947OT6zmJOYK9Ho9
liNSJOy+jRxphOss7/dkMuHy2mIRket8H3ncqX/N8+fPEY/H4XA4WGpKC8XOzg4+ffqEk5MT3njv
SyJzU4jjo0I4g8EA6XQaBoMBVqsVmUwG9Xr93ki4gl8eaM0RSQBFPahwDBVH0mq13IOP2itI16ZZ
e+5EA5ycidTf8Pnz55ibm+Oct/PG3mg0cHh4iP39fezu7nJfLLGZ9nWjGXdFwCaTCacVuFwurigb
CoVgsVhY5kz3jaoPbm9v4+DgACcnJ0zApON76Psst36SpEqsnCynNJllSHPDVCoVRx8ukwdO+zVF
tcVjyTXjVaBABMl6x+Mx6vU6Go0G2u02LBbLVMGgWXG4nafqAMDtY9rtNu9r5znnHywSRkb0eDxG
KpXCaDTC/v4+fD4fvF4vE4XJZIJGo4F6vY5SqcSJuoVCAY1GY+rkLsrJoYVf+nMy+ZwPRFpU6gXi
9/v5GPV6HYeHhxgMBhwVoypXGo0GuVwOnz59YmNB7nzvcxMRz5HK6YsvnU7HHkkiMyIJk8sJu69x
U+EUsXiK1FtM8slut3vtnDuSnhIBCQaDWFxcxPPnzznRWmyQSlJEkgSJBVseI2iTpTLVOp2OjYpZ
jOgp+DJA847+Lf4+l8vhp59+Qi6X4983Gg3uKdbtdk9Vbp0lSFUP5NzzeDyYn5/Hy5cvEYlEYLVa
zz3OZPI5f3Nraws//PADtra2UC6Xp6qvXndPuetrptFo+HxJTeB0Oqccf2SgVyoV7Ozs4MOHDzg6
OprKA56laJLUAKRcPdozydtN7RSkOdezCClJEgkYkbDLnIM0WknzUyFgCuQgPksicSEyRjadnCJn
VojYeaC1QeyReR4elITR4DKZDEqlEvb29hCJRBCJRGA0GqHRaDhfIJ/Po1qtMlMWN3LxmOdJ/+QI
GEVabDYbQqEQFhYWsLKygpWVFbjdbu6xRJtFtVqFwWBAMBiE0+lEs9lkD+7Ozg729/dRr9fvRfIh
B2lUhiJhYmNp0VMnThia/HJ9G+7yHMTxkoyFctcoIiqtIEbkiPqa3eS7LRYLvF4vIpEI5ubmsLi4
yFFY+g5qPbC3t4dUKsWGAo1pljfb80DGXrVafeihKPjCQWsTOVcIFIkfjUYs7drb2zuVF3rZIkuz
ANpjjEYjHA4HgsEgEokEVlZWuCriWaBzLRQK2N7exuvXr5HJZFCr1aYi7/Q9swRy+nm9XiSTSczP
zyMQCMBqtbJBQka6SqVCuVzG7u4uPn36hHQ6jWazyT3lHkqCeBakDgPag5rNJrejAT73t5vlvFqa
OxqNhotb2e12OJ1Ovn/UNP2qkTDq7UrVTImUUiuGWYxcK7h/SG11SkGhNlWUIjFLz78c5AghnQu9
LsKDV0cEftaFUxnebrfL0Y/xeMz5VhTeO+/GXPaGkZeHmjXHYjEsLy9jeXkZKpUK6XQa29vb3POL
GqJSg+BwOAyDwYBcLscELZfLodFonOoF9pCTiApyUASMiA3lOdGEoSpU55Gwu4DUoKCSxj6fDzab
jT2KUq9ov99Ho9HgRtzXBckQl5eXkUwm4fF4mPSpVJ/LaOdyORweHiKdTqNWq8l6ah8j5DxSj/Vc
FMw2yLlisVgQDAYRCoVY6UBS31wux7KUbrfLMvTH0JwZkHeA+Xw+LC4u4unTp4hEItx0WlqZVvQI
k9Px06dP2Nvb43VHLNE+q9eD9hq/34+lpSUkEgkuN01jH4/HnOtbLBa5nUy1Wp0yWmbdAAM+n0sm
k8GbN29Qq9W4n9379+9RLpcfengM6ToPAHa7HclkEgAwNzeHFy9ecLE0ioRd9vrT3CfD02Qywe/3
w+fzYWFhATabjd8rrXSsQAFBjKo+5vlxlWdnJkiYuCj3ej2USqWpm0BeUpIvXtfDJOdBdLvdSCaT
WFlZwdraGtbW1rC5ucn9xqgpr8vlQjQa5Z5lkUgEnU4H29vb+PDhA3Z2dji5fJZ07OR5piR3KpMs
GgyU83RWJOwuI2BSw0Wn08Fms8Hj8XAPOJGE0f0XSdhNojharRY+nw9PnjzBwsLCqf41vV4PuVwO
29vbXI1T9NQSHvo+XxdkAH4J56JgdkESYzL8nj9/DqPRyGW/NzY20O12WXIn1yz+sYCeJbVaDb/f
zw3fw+EwzGYzO8Ck+4RarWYStrW1NUXCaP+bteiQFETCAoEAFhcXkUgk4HA4+O80fioCVSwWcXR0
hMPDwykZ9GOQHQGf96OTkxO8ffsWx8fHnNO+s7ODSqXy0MObgvR62u12LCwswOv1cn9QIvpS5cll
j00OE1LfmM3mqUbrj+GeKrhfzOpadh1cZ37PBAmjTYWkcXcB8eJQDhAtQktLSwgGgxiNRjg4OMDe
3h6XIK/X6+h2uzCbzYjH41heXobFYkG5XEY2m8Xm5ibev3+Po6MjNBoNHv+sLDYqlYo7klMumFhN
UJT1iWHg+5JSiB66yeRzNRyv14tEIjHVloBAGnySf5RKJdRqtWt9t9FohNVqhd/vx/z8PKLRKOx2
+xRR73Q6yOfznBhPhoK4UT12iJ57Bb9MSIm4dC5c1RiTfk6r1cJsNnOxhufPn8NkMnF58mq1ioOD
A9RqNc5TlTveYwAVQrJYLIhGo1heXj7l4JHLdaA+jScnJ/j06RO2t7eRz+fRbrcfjWfY6/XC7XZz
WxeXywWj0Ti1xoxGIzSbzamWLhTpkxLTWTfQJpPPxUWOj49RLpdZaVIsFm8kk79tyM0dvV4Pp9MJ
i8XCEtib7gXSNAiqyqzX6x/F/FVwfzjr2f4SImFXwUyQMBFyYfObRpak+nKr1Yr5+XnMzc1hYWEB
8/PzUKlU2N3d5bLd2WwWzWYTBoMBgUAAy8vL+Prrr/H06VNUKhW8f/8eu7u7eP/+PT5+/IharYZu
tzv1PbOwgajVam5ATMVORIxGI3S7XbRarakm1Hc5drl7TDCbzQiFQlhaWoLf7z+VO9Fut5HP53F8
fIxcLscb+HVgt9vhcDjg9/s5yklNiyniRt7aVCqFQqGAbrfLn5+l+3xTfCnnoeBqOEv+IVUNXGVD
lBYwmEwmTEo8Hg8TE7PZjMFggGKxiN3dXc4DFuVKsy6/A07vVdRw1O/3Y25uDslkErFYbEqSJf0s
FXmo1Wo4OjrC+vo69vb2OJoyS+qK8xCLxeB0OuHz+eBwODjyJ5VcUo5tuVzmPDA5YjrrIEcdRXRJ
ykdOzVkGpSpQgTFx378NEkaOSvGZVqDgMjjPRvzSMFMkTNx05S6+WFDjqscUj+1wODA3N4dXr14h
FAohHA7j5OQEu7u7+I//+A8u0W40Grl32eLiIl6+fInV1VX86U9/wvr6Ot69e4fNzU3s7u5OJafO
kkFLC6zVap1KkCWIpXZJhngfUTA5o0+tVsNisZxLwlqtFpOwfD6PSqVybjfy80BllH0+HyKRCPx+
P/R6PYCfq3cSCTs4OECxWJzaWGflHitQcBOIa5dcNOy6a664Xuv1ethsNi6Ak0wmYTab0e/3YbFY
4Ha7T0mPHwuk+apUDTEej2Nubg7z8/OIRCKyOWD0k9aaarWKdDqNT58+cQEgwmNYb6LRKBwOB7xe
L+x2O1eYFY3zwWDAjY7L5TI3Ohb36VktaiEHKibw2EDVC6U2wV3gsT3TCh4GZzkEH8PaB5x2Qlxm
3s8UCZN6++S8oFc1BghUgIF6Qa2uriIWi6FareK7777DwcEB9vf3uQQwAJhMJkQiEbx48QLJZBIO
hwOj0QjtdhuVSoWLNMh976xMGrVazRWQziJh3W4XzWaTk+KB0yTpKpA79/N+p9Vq4XK54HK5sLq6
imQyiWg0OtVLhwqI5HI5bGxs4MOHD8hmszeSr87NzcHpdMLr9cJsNk+VwifZY6VSQaVSQbVaZc08
jX2W7rMCBdeFWAVNJAo3cSZJP+90OjE/P4+lpSX4fD5otVrOBSYZtFQK/ViiP+LGq1ar4XQ6kUwm
8dVXXyEej8NsNp/5GfpcvV7HwcEBtra2cHx8jEajwaqExxANJEQiEdhsNu6xKM4DMRLWbDZRKBSm
ehLKkffHhsd0r+5zjI8lx0/Bw+OXFAUDZoyEAbe38UqlLFqtFqFQCM+fP8fi4iLm5+cRCoVwfHyM
77//nvt7ibIIo9GISCSC58+fY35+Hna7HePxGO12G+VymXua0PdJv/+m53AbIDmi1WqF2Ww+RcKG
w+EUCaPkb/KSAVdvAnrZIg/0N7VaDa/Xi4WFBS6QEYvFWEtOxUOGwyFXDbsNEkaVuzweDxNU2vx7
vR4ajQbnq1SrVa6QeZlzU6DgMUA0kqXzWYxGXDTXz3vmVSoVXC4X5v6v/YPX64VGo+EcYCJg952P
elugNY+kV06nEwsLC/j6668Ri8VgMpkuPAaRsPX19alS7QC4SvBjQDQahdlsht1un9prxDk2GAzQ
aDS416fYfPqx4qI0ilnHXY31sd9XBfeHs6Txj+k5erSFOW4b4o0kMmG1WhGLxfDs2TOEQiHo9XqU
y2Wk02ns7OwglUpxhUaSxOj1erhcLsRiMfj9fpjNZiYDJEEQe0XNCkQCSJEwu90uS8JIBlOv11nb
Lh7nqud1mc+Qbp7K5judTjx58gRra2tYXV1FJBLhakqTyYQjUtRTZm9vD0dHR2g2mzcyTqLRKKxW
K5xOJwwGw1TZ/m63y/2zqBHnY+pTpEDBWRANRp1OB4vFAqfTyURIbL8AnI7ayB1H/Detn1SgQq/X
c+9FsUAFrbdiHzCqgCv33bME6fVRqVQwm82wWq0Ih8NIJBJIJpOw2+0wGAxnKgGo6mGxWMT+/j42
NzeRzWZ5LZYaJbN6PQiBQIALHokFoESMRiO0Wi3OB1PWVQUKftmQrnPSf8/6uifiqkTs0ZIwOSNB
yqDH4zEXpQgEAkgkElhdXcVkMsHm5ia2t7exsbGBcrnMlYFE8qbValnKRwRGjBSdtzk+1KSRTgCK
hNE5iE1SAWAwGKDZbHKTVGlp+uvIks6THmo0Gi6XHwgEEIlEEI/HsbKywhJRr9cL4OceZtVqFZ8+
fcLGxgaXAm40Ghy1vK63LRgMwmQywWazTRkMk8mESRgVXCE8FmNIgYLzIOZgBoNBLC4uMgkTjX/g
NAkT10jR0UX/pmavFosFLpeL5XmLi4uIxWKw2+1Mwuj4YoPLWX+2xPOnsVOri2g0isXFRUQiEbhc
Ls5zkyOyVPin3W4jm80ilUphd3cXpVKJr430M4RZvUYej4er8UoLrNCLHH+1Wo33nMcuV5uV/f+6
eMzXXsGXhfPm4qzP0+tI+B8lCTsv9C8m9k4mPzf/pUpVKysrSKfTODw8xB/+8AeOdoiJwWRUULRG
LGrR7/f579KKP7O48Io5YWfJEVutFpMwMbJHr9usliiSwmg0ihcvXuDZs2dYXl7GkydPYLfb+bqS
XKlSqWBjYwP//d//jVQqxSTsptrhYDDIUk05EibKEEWCLr5PgYLHCJrLZrMZgUAAyWQSg8GA85Ck
DdLFz4jrH0W1xf+bTCaYTCZ4PB6Ew2GEw2F4PB64XC5YrVbZfFMxKvQYnis6XyKsWq0WXq8Xy8vL
WFpaQiQSgdvtls2JAsB7VKfTQaVSQTabxf7+PnZ3dzEYDGSjQ+L9mFXvsMfjgU6n46qINGZxPg2H
w1MkDHg8OYDn4bGOW4GCh8RFhSxmnXzdBI+ShEk3IbnFmwyCYDCItbU1rKyswGg0Ymdnh+VslUoF
3W73VPKzTqeDyWSC0+lkAjaZTNBqtbg3FX1Wp9PB7XbD4/HA4/FAo9Gg1Wqh1WqhXq+zzO++rw2B
qiOazeYpyR1Br9fDbrcjEAhgfn4eg8EAwWCQjStpwv5lICcHpSbR1LzR4XAgGo1ibm6O5Z4Gg4E3
aOrPlc/nsb29jbdv3yKVSk1VKLzphudyufheSwk19expt9unvNIKFDx2qFQqzl9aWlriKD+RILlI
mNSglhIy+j9JEK1WK9xuN1wuFywWC/f8E49LETBRijjLhqxYPILIql6v5/VsdXUVCwsLcLlcsoaD
+Lter4dMJoPt7W3s7OxwTrJUYi23v83qNSJVAUUA5UB5Yb1ej0m/9O8K7h5fsmGr4PHhrJywx4Tr
nMOjJGHA2ZI3yoPSarVcjOPVq1f46quvUKlU8PHjR2xubuLw8BCNRoM3fdpYJ5Ofyyk7nU7YbDZu
NtloNJDP51EsFlEsFtHpdHgDfvLkCVZWVmAwGJDNZpHL5XB4eIjBYMAk7L4mlkiaKLeNmjVLI2GU
90YllI1GI5rNJjQazanqVpeF6BXXarUsTaIG2VQJ0W63w2638zXWaDTsGS6VSlhfX8fGxga2t7dx
cHCAo6MjdLtd9Pv9qft1XbhcLmi1WphMplPklO5bp9ORlQYphoKCxwySyLlcLiwvLyMUCp161uXy
nsTfn5cTptFooNPpuHktNW4Vj01EhggY/ZzVZ0uOQOp0OhiNRs4dFkmY3OfFn91uF8fHx3jz5g22
t7dRLpenCv+c5WicZZCq4LzmvFRoqdfrPcpCLAoUKLh9SAnMYyViwCMuUX8RxBOjvAOKsOh0Ovak
qlQqGI1GGAwGLC4u4unTp1hZWcHbt2+xtbWFbDaLdrvNhvdkMpmS1VAvm/n5eXi9XhiNRo7MpFIp
ZLNZlqlRzlk8HsdXX30Fm82G4+NjHB0dYTweo1QqoVwu3+t1Eg0d2hDFSJi4oRsMBrhcLgwGAzYm
ut3uKaPpskaAVM5J94bIFkXBHA4HdDodS1YoH6VSqeD4+BiHh4d49+4d3rx5g1QqhWq1yo1Lb+vh
pNwU8tCL50pVI6l3mpxhqkDBrENuvopz2Ww2w2Qywe/338p3nGd4iw4v8Xfia5bJhpwU0263w+12
IxaLYW5uDnNzcwgGg9xvkD4n/pvOcTgccpXAdrsNg8EAn8/H3wNMR76IsFJRKLpmswTKBdPr9VOR
MPEaUPSTCrN8CTJEBQoUXB+P0a46q2DVVTEzJOwyBQ9o49Pr9fB6vfD5fPB6vSwF7Ha7aLVaGI/H
sFgssFgsWF1dRTweh9VqhcPhgNvtRjAYZEkb9YECwORgdXUVT58+Za+mXq9HJpPB5uYmfvrpJxwc
HLCWvd/vo9frwWAwwOv1IhQKwWazwefzoV6vY29v7+4vngBRjkm5CgaDgSNhcnJEkuU5nU6EQiEM
BoNrl6gH5I0VKsZBL61Wy2Mcj8cs39zf38fHjx+xvr6OVCqFdDrN/djIe39b3mGSIep0ulMPERkJ
cnIZBQq+FIiRqKtCGgkTZYmX3ZSuE2l/KNBaYTAY2KkUDAYRjUYxPz+PhYUF2O127jcoPScp+QQ+
7znUSywej6PT6Uzl2NEaPBwOMRgMUKlUkE6nkU6nub/ade7dXYEiYFICJpXJUw7grBNvBQoU3A8e
cyRMLk/3UckRL1vwgCJgJpMJoVAIyWQSyWQSCwsLWFhYQK1WQ7lcRr/fZ6lbIBBAKBTiMswej4eJ
GkW/2u02JpMJ3G43otEoXr58id/85jdYW1vjXIZqtYqtrS38+OOPyGQy/BmK4JAXc25uDn6/H+12
G6lUClar9b4u46lrJUqC5HLCSHrpdDrhcDhOeaNv4yGQyyORynKIhBWLRaRSKbx58wbfffcdqtXq
VHXC25bnmEwmJqp0THFMlCA/S0aOAgW3CbFXF3C550pKvmitobVFLMJA+BIMbZK5WywW+Hw+BINB
JJNJLC8vT1V+1Ol0p2Sd0kjQcDiESqWC0+lELBZDIBDg95KMm64pybS73S6Ojo6g1+tRr9cBgPP4
ZgXk0LrIiBL3mi9hbihQoOB2IGcjPiZclUDOBAkDzt6ktVrtlITN6XTC6XQiHA4jFApxNaZarcYN
h9VqNSdKU2+vWq0GvV6PWCzGZZlJPpLJZDCZTBAIBOD3+/H06VPEYjG4XC6Wy2m1WpjNZjidTgDg
cu8ulwterxexWAwGgwGtVgvZbJZfYlGOuyzDK40kksFgMBhgMplOkTB632g0Qr/fx2AwmPLQise8
7nikRhpFxaQec5KPkmf5yZMnGI1GnFtXLpfRaDTQbDavPR45ULl+uQTyu6gMqUDBfeOsuUvzulQq
4fDwEOl0mmViF61TYuSLflIOLjl9SKZts9lgs9mg0+mYWMgd56KWHw8FcUx+vx/RaJT3nnA4jEgk
gmg0ilAoBLfbPRVVl6uoKp6z0WiE1+tlIiVdH8V/U9TLZDKhWq0im81CrVZPEehZuHZnGU/S/18n
aqpAgYIvD485AnYRZjYnTLpZSCMv4t+1Wi17HGOxGG+Aer2eq+lVq1UugjEYDGC32xGJROB0OjGZ
TFCv1zl/K5FIIBaLcb4PlSEfj8ewWq2wWq3w+/3wer3QarU8FrPZjGAwiKWlJe7tYrVaEQwGEQqF
EI/HodFokMvl8OHDB7x//x7r6+uoVqv3fXkBTEtnjEYjR/SkkbB+v496vY5Go3FKHnLdh0FOjkj3
iyqniTkTGo0GVquVjTiPx4PV1VVsbW1ha2sLu7u7SKVSaDQat+o5lRLBuyTJChTMEohwZbNZfP/9
9/juu+/YGSPtEyaFSL6IKFB+rijVo96MiURiqkWGuM6L0R461qzJf2kdi0aj+PWvf421tTUEg0EE
AgHY7XZYrVZYLJYpufdlrh/l4lmt1inCJvdZWpe1Wi2y2SyOj485p0z8vlkhr+dBJO5iGXsFChT8
cvGlkbFHIUcUN2Mx/0jcSLRaLQKBANbW1rC8vIx4PI5QKIRWq4Vms4lsNotCoYCdnR0mHVRuWavV
otFocCGNcDgMh8MBs9nMN5kMD5VKNVXJS9T1TyYTWCwWhEIhlh8S2QuHwwgEAlCpVGi32zg6OsKH
Dx/w17/+FScnJywbIdzXJilKEalvjzQSNh6P0W63kc/nkcvlMBwOTzWtvg5EA41eVACAfppMpinv
uF6v57YA8XgcvV4PPp+Pvei9Xg/5fJ5zIG5DgiP1vMsZMV/CYqBAgQha00ajEUqlEj5+/Ig//vGP
7JgiEiZGiEUHBZEIMbpNBMxgMHBZ+kQigW63C41GA7/fz2RNlCtKIz7SvM+HgLgOUF9Dg8HAxZe+
+eYbzkemCrKXhbi20nHlKinSe+lFnxkMBvD7/XC73SgWixzNlxv7Q4DmjlwOmJR8i4WZ7hsXfedN
r6GyZyhQcHmclaryS8C9kjCpLIMMcIrWqFQq7rFF3lC9Xg+fz4elpSWEw2Go1WoUCgWkUikcHBzg
+PiYZWuJRILLA1erVbx+/RrZbBY7OzvI5/NczMNqtXKBCIvFwjJDr9d7qskk/bTb7YjH4zCZTCyN
G41GqNVq3A+s0WggnU5ja2sL6XQa9XqdpSL3DfG6iuSSjByKGmYyGbx+/Rrv3r1jEkbX/iYkTCpD
pOttNpvZcyz2V6Oy9eQpJ/L97Nkz6PV6Pg7dayK3N3lYiXyTISguAmQk0DVToOBLBJExcixRDuR5
zgfx+SZC1ev10Ol0oNVquc0E5eju7+/j6dOnePr0Ka+htN6L6wQ9aw8ZCRPX/clkwvnHoVAIS0tL
iEaj8Hg8MJlMAHBKvi13zc4z6C8inNK/DQYDtFotVCoVtFqtmeth2Ov1oFL9XL1YJIVExKh6opw6
465JpOgclDrhpC/p78X/SyH14Eullr8ko1KBguviS4mEXWXs90bCRLnEZPJzLy+DwQCbzQa73c4D
b7fb/BmdTsckzOl0olQqIZ/PY2NjAz/++CMODg6YuLlcLthsNrjdblSrVRwcHGBnZwcbGxs4Pj7m
Yh30cjgciEQiiEQiiMfjsFgsU1X7xLHb7XYYDAZ4PB7uE0avQqGAo6MjHB0dIZvNolgsolQqPWhR
B/JOS0mYSqXixPBOp4OTkxO8fv0a//Vf/zVVDVDqxbwKxI1H6vU1m818/ePxOBdWITkoecpJhkr3
lI65vr7OlRRv+qASCSOPrAgxz0UhYQq+VFA7Bnr2qWz4ZeRtcs+5SqVCtVqFWq1GJpPBwcEBbDYb
Wq0WrFYr59SSHJkMVtE4fuhCE+J5m0wmRCIRrK2tYXFxEZFIBB6Ph99zkXTzPJIlVxnyrEg8vU9K
wobD4S2d9e2AcrLJkSZVGgA/RxfNZvOpUvZ3DVE6S3NPbJUg5gHL/ZsgrYImzmO53Gd6nwIFCuTx
pT0nMytHJEJgt9vh9/vh9/vZKO/3+9jc3ES73Uan05nynImbNC2cJJ2jhdzpdMLtdsNsNiOVSmF9
fR17e3tIpVJc4IGiX5Qw3mq10O/3odfruVcOeYd7vR7q9TpX6CNvb6lUQqlUQrFYRD6fR6FQQDqd
Rg6LiBEAACAASURBVCaTQaVS4Sa/DykLoSbEtNHRdaPz6/f7aLfbqFar3FiaGqbelIRJIXpG6fpb
LBbUajXUajVUKhU0Gg0MBgOWIFKOhclkwnA4xOLiIsbjMbrdLvL5PDc2vYnB1u12pwwGcbzkIKBy
+qIh9KUsEgoUiAamaHCeJc+9COKzQS1DisUi4vE49vf34fF4EIlE2LFCUTBxbZ8FpweNw2azIRKJ
YHV1lYs1GQyGS/XouujaiQTlrN/R/1utFtrtNk5OTpDP51EsFtFsNk+RsIfOCWu1WnwfDQYDj0k8
H41GA5PJxKkB4tpL77mr86CiXH6/nyW0KpVqau+7zEt8TkRZLr1EB56UwClQoGAaUgL2GGyss9Yp
aQT8onO5cxImHQDJ0OLxOJ49e4anT5/CarXCbDajUqlArVYjl8sBAEstOp0OyuUykwmXy4VgMIhE
IsELPQDMz8/D5/NBp9OhUqlgc3MT2WwWzWaT9fRUerzdbqNWq7EswW63Y35+ngnYYDBAuVzm4hDF
YpFLpjebTTSbTd4YKT+t0Whwc1+5DfYur7GUNOl0OpjNZlgsFvb6iX8nEtZqtdDr9WQbEtMku84D
IfXuUtU1MQrX7XZRKBRweHiIQqGAarWKxcVFLCwscGl/kgRFo1EYjUYuY0+VJ6lVwHVA+SpkBIjn
SSSWSNhZ56ZAwZeAszaLqxjEYqSDjkfFforFIvb39+FyuWA0GhEKhU452B6yUIN0fdRqtdDr9XA4
HAiHw1heXkYoFGIZojT6d96YL/qb9O8iaSF5ZrVaRTqdxvb2No6OjrjBs3Sveei1qdFocE41NW6m
sdE4qdKwy+WCxWKZymsT95y7OBeXy4W1tTW8ePGCKy5rtdqpKPB5LypoIxIxkXTRiwieWq3mPPKH
vjcKFMwyrrKmPgbMZCSMPIuBQABPnjzB3/3d3+G3v/0tl09Pp9PIZrN4+/Yter0eG9jkTaWCDlar
FW63G6FQCEajkavtJRIJuN1u9Ho9VKtV7OzsoFar8Q2lcr5UNp606Xq9not9UISt1+sxkfvTn/6E
g4MDlhqKVcTkMAsTiPqpnUXCSNbSbreZhAGnx35dMindRGkTGwwG3PerWCxiMpnAbDaj0Wig3W5j
NBrB4XAgkUjw541GI8LhMILBIFKpFFclG4/H6HQ61/YyUg6LwWA4RTbp+lEBEQUKfkmQrgGXjeqI
0izg5+e+VCrh4OCAG8JT4SQpAXvoanl0niTnprYZyWQSDoeDSRjwc2uLy0g3z8N5qgOKvJTLZezt
7WF7exvHx8colUpTUshZIGDAZxJGBIzWZem4NBoNO2OpKi5wP95vh8OBlZUV/Pa3v+WWNAaDgVsA
UAoBRcaImEl/L0bEiHSKL8qBVqlU7Cyc1WiY1Pkq97vbeo8CBWfhsZAvqcT6rGjYZXEnJEw6AKPR
yDlY8/PzmJ+fx+LiIpxO51QhCJ1Oxz3AaEHsdDrY3d3lqluU23RycoKTkxMYjUYsLy9jaWkJALC3
tzdVwldubCSJoIpX33zzDV6+fMmFPyha1mq1UCqVcHR0xMUgRPIl58G8zwjYedDpdLBYLLBarSy5
IIiRsE6nc2Zy93XP4TKfEyfvcDhEoVDA1tYWHA4H4vE46vU69Ho954jRZ8gzHYvFAAD1ev3aksRy
ucybps1mmxqb0WjknnS0mZ6Xu6FAwZeEq65l0mdDaoBTsY5SqcSFl2gdpgI4RMpEOeJDrackR2+3
26jX6yiXy9BqtZxjS2OSGx9FS8jh1Ol0ppxccucjFn4gg7/f77Okc2NjA58+fcL29jby+fzMkC4p
SqUSDAYDrFbrqRwqetF6S6kIlB94H+srOQhE2SA5KbVa7VRemBj9ukiOKH0RMaNjnee0fSicNQfv
6j2zblwruD9I7Smp0+8xkLGL8KCRMKk8wmg0wufzIRKJ4MmTJ1haWkIikYDL5ZrK69HpdGxk1+t1
7uG1u7uLUqnEfVjUajXnXSUSCbx69QpPnz7Fzs4OPnz4wIU4ziIXtPGbTCbE43H86le/wosXL+Dx
eJiEEUkpFos4Pj5GsVjk6mHS85Rjw/e9QUo3d/JGWq3WMyNh7Xab5ZPSRfKuNnm5B2w4HKJYLKLT
6cDlcmF1dRWNRgMWi2UqVwT4XKUyFAohGo2iXq9Do9Fcu0IYGQw2m+0UkTMajSxXMRqN/PtZNHwU
KLgpznrerzrfyeiUrkfdbpdJGEUFxCgYvc6KhN1lnpA4dgI5B0USRkWF5D4jjpmM7m63i3K5jEql
gm63ywRAvNbiT9FgHwwGaDQaqFarKJVKLIunqrtSg35W1qVSqQSTyQSPx8NrqnRuabXaKRImVRrc
5bnI5SFSYSbpfZH7v9z5yMmo6F5TNE2n080cCVOg4CFwVrqLnBTxl0DE7lSOSMYzVSFcXl6Gy+Vi
iSHJ4fR6PUajEfeTcrvd3B9qMBhwuWMx14CKO1CRDafTiX6/j+PjY+zs7KBYLJ4ZIRE9sC6XC+Fw
GOFwmCNG5AUjTyhJ5cQN97xJMgsbokjCrhsJuy+Mx2O0Wi10Oh0UCgWUy2UmWCQ3pfGbzeapVgM3
SeLP5/MwmUxwu91Tc4UiYQ6HA06nk0spA+DcNgUKvnTcRiSc/k1FjvL5PI6OjrCzswOLxYLBYMCF
jnq93lSz+PuEnBON8ldJxn7esy8aE0S+SqUSKzZardYpEiZHxKQkrFKpoFwu4/DwEIeHh6hUKmdW
6ZsF5HI5Ln5Ba6rU6abT6bgwF+WF6fX6SxU7uSm63S5LY9vtNprN5lTfULEHHtkvlLJAZE2s+ihi
Mplw5IycxK1WC7VaDdVqFaPRCMvLy3d6fgoUPEZ8KdGv6+BOSNhkMuHFy2g0wu/3Y2FhASsrK8hk
Mnjz5g3MZjP3gKKeISqVivXUVISDQKyZPKh+vx/JZBIrKytwOp1oNBpcvp6SluU2OfF40l4e4vhp
MaUF+TwPpvSzswBKfj4vJ4xI2H2WOT7rXtC97ff7aDabqFarHKUSodfrYbVaOUJ1k4c2k8lwE24p
CTMYDLDb7XC5XHA4HLDb7Wg2m+h2u0xa78M7f9/4JS6CCm4f0uei3++j0Wjg5OQEb968wWQygcFg
wGg0QqPRwMbGBsrl8lR+6nnHu2vQ/kCyMoPBcGa7CjE3QKVSodFoYG9vD5ubmzg4OMDBwQG31JAj
YXQM+knqEMpf7nQ6qFarHEGc5YhKOp2GzWZDIpGYkmCKpdq1Wi3LFT0eD5xOJ6xWKzcLp88At3/f
q9Uq1tfXMRgMWOlgMpmmCBeVsKecYKq67HQ6YTabuZeoCJVKxbnk3W4XmUyGc9yJkI9GI/y///f/
bvV8FCj40vBLI2R3RsKAnw1mn8+HhYUFrK6u4vDwED/99BMmk8+l5SORyFT/GKpKR5WFgOnEZ9qA
AoEAXr58iaWlJTgcDjQaDZTLZeRyOeTzedkxSQmAnISA/k4kDPi5waPUEzrLBvhlqyOSHJFwHzkY
clpgure9Xo/74MjJBClZ3m63w2g03igSdnJyApvNJptXRtJXl8sFp9MJu93OeR7UX4zGP8vz4Cr4
UiQACmYPFEkiEnFycgKtVstrUbFYZBImPosP9WyJuUNEwqj5sPgecU+hv9Xrdezu7uK7777D9vY2
tre3UalUpvaxy8i9z5PDzSrS6TQcDgdqtdqpPDiRhNlsNhiNRiZhFouF1385B91toVKpYGNjA0dH
RzCbzWxrUG4wVcS1WCxM0sLh8FShKLJNpFLU0WiETqeDRqOBg4MDvH//nnP48vk8hsMh/vVf//XW
zkWBgi8JvyTiJeLOcsJ0Oh2CwSDm5uYQjUYxGAy4aEa9XodWq0W73Ua73Ua/32fC0+/30Wq10O12
uWkoGei0ODqdTiwsLGBhYQEOhwOFQgHr6+vY2tpCrVY7MwmUjkUyN+pFRVE3cTGlnmCi8SAeQ25j
eMiiHNLvpCRyqu4nR8JIDvrQckQak/jvs64hGUfShtrXwcHBAc+fRqPBlbrIK0rRRK/Xi3g8zuWG
RW/tLBtEV4F0fihQcJsgxxZVriX5Of2+2WwyAZPOP7GQggiSjd8GxLVbpVLB5XLB7XZjcXERsVgM
fr+fJfJyZGgymXDbjUwmg1Qqhe3tbWSzWbRaLXbcnLd/XAaz/mym02muZlyr1fiaUQVEGj9J+jwe
D+bm5lAoFHB0dMTRvrvaS4fDIVfhpVQIkhlSRUwqL08kLZfLsWR2aWmJHZt0H2msvV4P+Xwe6XQa
W1tb2NzcxO7uLvcancUI5l2Se2mujwIFBNF2EtODpNLfx4irRvLujITp9XqEw2G8ePECdrsdnU4H
GxsbrI83m81MdAaDwVTugFiuHADnCRgMBu4Ptri4iPn5eYzHY7x79w7ffvstjo+PuSS9OBaCuAEY
jUbYbDaYTKZTzYxJVkAkTKzgeN45z5IhS149s9l8ioSRx5F6nd2nHFGK8wizHKTa/Zvg4OAALpcL
hUIB9XqdexgRIaemol6vF4lEgnM95Mb40Pf7NvElnYuC2QDNqcFggHq9zoUqyAikCLNcThjtJ2JP
SPqM2N/wuhDJEf3f7XYjmUziyZMnSCQSCAQC3DNQbnyU11qpVJBOp5FKpbC7u8tORun7r4PH8Fwe
Hx+j3W6jUCigVqvB7XZzQ2bR4CdHmsfjwfz8PKrVKjqdDjKZzJ3KvUejEUvKidyL+4m0bx1VYs7l
ciiXyzCZTEgkEnw8cc70ej3kcjlsbm7i06dPLEed1T5hdD+k1R6Bm89R0RAVFU0KftmQU52JJEx8
PXS7kstA6lCTOh4uM/47IWGUsxMOh/HkyRMMh0NsbW2xZ5D6M9XrdeRyOfh8PvR6PWg0GnQ6HdRq
tSnvIenyacFeW1tDMBiETqfj6oUfPnxAs9nkHmBngaJ0NpsNXq+XS+SKN5xK41MPLYqE3UT6dpeQ
W9xJ1mk2m8+UIzabzZmIhEknMW2AckSLNo3byI3IZrPo9/vI5/MoFotwuVxQqVRTuWYmk4nzD6lh
6qzOg+tCKr2SknYFCm4DYr4TRZMvA71eD5fLBY/Hw5Hq8XjMTqTbiobRc63T6eDz+bC4uIjl5WWE
w2E4HA5ZUkAb7Wg0Qq1Ww9HREQ4PD3F8fIxsNjv1vstC7r2zZsCfhVKphMlkgkKhgFwuB6fTCbVa
DbPZLEvCXC4X5ufn0Wg0kM1mYTQaeT8Sc+1uC5PJhIutXBZEpDUaDVZWVqYaZNMxgc8Ohlqthkwm
w69cLndrY78J5K7hYDBgO6ff73NhnJtErugeq9VqGAwG6PV6jihSKwIRyj6jgJxsVGjPbDazw+us
gMpD4irr0WXeeyckbG5uDna7HdFoFIFAAOVymXXS5XKZ85GOjo744lNuGOV2NRoNXvhIGrKysoKv
v/4az58/R71ex5s3b1j2IcpZpBdBumCaTCYEAgEsLCzA7/fDZDJNGfw0PjrmZS/6Q26U4nlSgvFZ
kbDJZMKRMCkJe8hzIMJNUlExL5AgRilv6gWn6lWFQgEHBwdcEt/hcPB7jEYjgsEgut0ucrkcdnZ2
uJ+M6EF8zCDyZbFY4PP54PP5WD6kQMFd4CpEw263Y3X1/7d3Hk+NZlcf/okGJJRzAEmAECJ1V3fj
qvFmdlNeubzxP+vyxl55PO5xezqSk0A5ZyQkpG/R3zlz9fKKKAm6+z5VKpJ4k244+azhxYsXMJlM
MBgMuLy8RCwWQzwev+Jpus81UJi6uB+trKwgHA7D4XBcsd4q/7/T6SCVSuHz58/Y29tDoVDoW5Pv
EvI16D1fwzrT6XTQbDaRzWZxeHjI4fB2u131/WazGYFAAPV6HcfHx7DZbOh2u2g2m/y5jjrMXzkW
B/18mxw+CpGlz/6uoUmjRDluSSY7OztDLpdDLpdDs9lkI6j4PzchGrAvLy85349C+efn5+FwOFSv
Q/JtcF/jkdi8nQrgmEwmTE9PX5H/nuKYUea8ilV1b1Ptd2RKmMlkgt/vh9frxfn5OWq1Gk5OTtg1
DwBnZ2eoVquYnZ3F8+fPMTU1dUUJI2vZ/Pw81tbWsLm5idevX+Mf//gH3r17h48fPyKRSKBarV65
2UGhbqSELS0tweVysRJGUKPmWq126zCCp7JBkleDLFCDCnNQ2Cd5HB8b2qioiTZdt5oSRg1QxTDW
+0AeWVLCrFYrbDZb33tICdPpdDg8POS+Nu12+5spV0/Cp9lsRjAYxPLycl9vNIlkmKgJpdd5PUgJ
++mnn+B2u+F0OtHpdPDp0yd8/vz5xuiH20BK2MzMTF8UB+UADbLI0vftdhupVAqfPn1iJUy8L/E8
3zLtdptzo2i9dLlcqu/t9XpcYKnT6WBrawt2u50NbK1WS1X5HRZqsoFYMVmZ83WbayAlTCzq9VSU
MKBfAapUKjg6OsJvv/2Gw8NDHB0doVKpsAeL3n/TPYv3Rx41s9mMxcVFLC4uot1usydb7ZlKvg0G
fabK3Fl6L31PSpjD4ehTwsRjjiI0eZgo14jLy8tbpTEBI1LCIpEIVxzKZDJIJBIoFAo4Pz9nzbDT
6XAoycHBAf773//CZrNhb28PuVwO3W6Xe4isr69jfX0dwWAQvV4Px8fHODk5wcnJCRKJBCqVyrWL
BbnHqfLR7OwsQqEQVlZWONaf0Gg0qNfrSKVSiMfjKJfLXCCE/i6+VyzgYDAYAIALjpBVaJwJuWKC
MYUBkCeMno/YjPqx+oQpczAoDM5oNMJkMnG+njI5s9VqoVwuo1gschL3faG8kmw2i/39fW4gOj8/
z89xcnISBoMBExMTmJ2dxeLiIvL5PFsOaWyIm/ZTRk2gMJvN8Hq98Pv9iEQiiEQiUgmTjJTrckFp
XGq1Wuh0OrhcLvh8Pramm81mNBoNaLVaboZ7H5TCvV6v5/MEg0HuRSgW4xCvXaPRcDhXMpnkUMRM
JoN6va56z98D1Pvt8PAQNpsNwWAQ9Xq9r/cW8OV5UNg5hSW+evUKMzMzOD4+RrPZ7PMgjiI08Tpj
gNqL3jPoeGqvp6BwqF1Pu91GrVZDPp/n8NFSqcSFEZT3PQjR29dut7m1Au3ltVqtL/xTesK+D5Rp
JiQvU6Eekk8dDgfC4TCWlpYQDodhs9lUUz6e4ngR9xB6ia1FbuMoGIkStrq6yorW4eEhDg4OkM/n
r0xE6glzcHCAbrfLi28mk4HJZILP50MwGMTm5iY2NzcxMTGBVCqF7e1tfP78GbFYDKVSiXPHlAu2
+KFNTEzAZDJxNabl5WWsra1xM2Nx8a1Wq4jH46rNMQny2lDCuM/ng9frBfClYWU6neZqWWJlxVEi
JjhSZURlThiFTIhVKOlzUbNYjPp66bmT0kjl56kPmHIynp+fo1AoIJfLoV6vP/g6O50OMpkMNBoN
zGYzQqEQC3gUDkk9gnw+HyKRCGq1Gvb29lAqlfpi6L8WIYueKRlEqAjB6uoqQqEQlpaW+oogSCTD
RCnMqlk7NRoN9Ho9rFYr3G433G43XC4XDAYDpqamcHl5iXq9jnw+j1qtNpTrMhqNmJ+fx8uXLzE/
Pw+LxcLe+EFzu16vI5lM4ujoCNFoFPF4nBtPjzqM7qlyeXmJfD6PbrcLu92OSCSCSqXCQpey5+bE
xASMRiNCoRAuLi4wPT3NYeKUQ0go//ehqB1HHJ+0X94l9FxNaXuKAiTJASSntFotlsko5P6uShh9
XtQvjcJK1fI2n+pzkdyP6wziomxK/ffcbjc8Hg+CwSBWVlawsrICv98/MHT5qSPmO9frddTr9VtF
0o1ECVtcXESz2cTx8TGOjo5wfHzMygxNVrG88OnpKQqFQl/ZevpwXrx4gefPn2NjYwPpdBqfPn3C
r7/+isPDQ6TTaVSr1T6XvzgQxBjNiYkJmM1mzM3NYWFhgV/KBbfX66FSqSCZTHK1RWUjX3o/5dFQ
XHs4HOawFmoWTbGhap60YaAUXETFkAa7GN9N8aqUV6XsEzYOlEqLRvOlGIbFYuHmyGK5eHEjaDQa
fUrYQ72Ml5eXKBQKaDQacDqd7LU1m80cGkmhGR6PB8vLy2g0GqhWq4jFYnz+UVhqh41omBArg7nd
biwvL2NjYwNzc3OYm5vD1NTUI1+t5HtBFMbErwaDAW63Gz6fDy6XCzabjavsiVb8SqXyoPPT/mGx
WDA/P4/nz58jEAhw6PEgQbTX66FWqyEej2N/f5+9YMoKvd8TtAdTcS232414PI50Og2Hw8FeFuD3
z50KdwSDQej1epyfnyMWiyEWi7GnUSxbP2rUZIK7KGDKaoOisfEpQNciygIXFxfsxZqYmOirVHpb
JWxiYoIVVko7IaXuJi+i5OtHGUJIaDQarjSq0+lgNBrZ4DU/P89VaFdWVjgXTI2nMn8IcU5TCCIZ
NWq12q1rSoxECZuZmeHeL7FYDMlkUtVaKbrFyftAIWEbGxvY3NzExsYGDAYDEokEDg4OuMpiPp/H
xcXFFXegEvrd5OQkXC4XIpEIFhYWuDm0mFBKlptCoYBisYhyudwXEqFUHoxGIxYXF7GwsIBIJILl
5WXub0ZeErEK2KgHkRiGSP3PSJHRaDTodDpXLF+02I4L0WpGTE5OsocyGAzCarX2VUfsdrtcjrpU
KrGnsVarPeja6RrIcpfNZrG7u8v9gcLhMHuEer0ebDYblpaWcHl5iUqlgmw2i0wmg0qlwuFHotX8
KWw4asp/r/elUTolwq6trWFjYwOhUAgajQbFYhHAF2OKRDJqxDVBXGvtdjv3g6TKpRR+SLnD6XQa
5XL5Xuft9XqsAOj1eszOzmJhYQHhcBgul0vVG0zXSGHmFHb36dMnJJNJtFqtBz2LbwHR2JfP57G9
vQ2j0Yj19XWOMFAKMKR0A0AoFMLm5iY0Gg2nHdRqtb49fpx5drfdt2lcUBrCU/eEicrTTaHBtzmW
2rGVe73k2+VPf/oTgN8rn9LYomgiis4yGo19OWBOpxMej4eLyH0N1aeVc5tkyHq9jlKphFwuh3w+
f6uUmZEoYTqdjqvvqSlhYrggbazkbXK73QgEAlhfX8fm5ibW1taQTCaRSCSwu7uLvb09HBwc9HmY
blLAgN+VsOXlZSwuLvZVwAPAzRvL5TIKhQIKhQLK5TJbcZQLSq/XY21+c3OTNflKpYJisYhoNMrH
I0bhBaOvJFAoS8KSMkP32Gq10Gg0Bipho9zQxGdIVjPyHNrtdiwuLiIQCMBqtfa1DCDLWrPZRKlU
QiaT4byLYShhNP5yuRz29vbYauPz+WCz2Xh8Wa1Wfq65XA7xeJxjgGu12hVh8rGVMHG8Ko0VWq2W
K4Sura1hbW0NgUAA6XQaqVTqUXvHSb4fBq2JSiXMbrdzzsn5+XmfElYqle51blrXqSG7qIRR01Dl
NdHcJsNQoVDA4eEhPn/+jEwmc+9Kjd8aFJpTKBSws7ODdrsNrVaLQCDAVfLEdZKU4ZmZGYRCIXQ6
He7ZmMvlcH5+zoqvmtIOjGbvuksEC40Luk7RE/ZUUSphSjnnNteuVLjE/31qhUkko+Onn37iaCwy
/tOLSs9TGXoqvKZ8DaP/67gQ5zY5XGq1GkqlEjd3f7RwRL1ezx4ksUjFIKs8WcecTifC4TCeP3+O
cDgMs9mMVquFeDyOT58+YWtrC7FYDNVq9caJrVScpqamuACBw+GAXq/vez/lGJDyRb0z1PLLdDod
pqam4Ha74ff7MT8/D51Oh3K5jEwmw0UjlCXzR7EgixvRxMQEu3vpGsVBLbpLKVabKrgMuq5hbWzK
41M4J5UvDgaDWF1dxcLCAvfkIS4uLjgEMZVKoVAooFarPbg6ongt1HcoFosBABwOBzweD+crGI1G
XijcbjfC4TBKpRLnjdGzpV4rynt+bIWMxp7RaIRer8fc3BzW19exsbGBlZUV+Hw+GAwG9HpfciK/
V4u+Uhi5L4M+71HM/2EdU82aDYy+NLh4HmqtYTKZOFQlGAzymkBVXSlSoVKpoFqt3vsayAsfCoWw
uLgIr9cLs9ncd11KyBNOfQPj8TiSyaRqz7LHnvePSa/X45y5y8tLzM3NYXZ2FhqNBlarFVarlfcv
Clki5XthYQETExOc4E4pC5TWMIw+kYNQrttKD9eg91OxAavVyrnmYquPpzYW7qpsSSTX8eLFC1bC
qAAPfU+pMeQNE3uxDvLCPgUGOXeUv282m8hkMohGo4jFYigWi1wP4lGVMDH2m1Bb4Cj2f3FxEZub
m/jjH/8IvV6PVquFnZ0dvHv3Dm/evMHJyQmy2ewV4WDQTZKFTez/YrFYVONOqVojJXqLChhBuWUm
kwk2mw1zc3Pw+XxwOp3IZDLY2dlBNBrF7u4u55ORZXTYIWpqnrlnz55Bp9PBZDL19QdTht2RgkhK
GB1P/KoW9nEfrhvEWq0Wdrsdfr8f4XAYGxsbrISJFs9ms4lUKsV5F6VSCRcXFw/OE1COS+pv02q1
4HA4YDQacXFxgcXFRa6QCHwZ36FQCFqtFkajERMTExx6QwVolMKxqCyPymKrpvQp79FutyMQCGBl
ZQUvX77Eq1ev4PF4YDab0e122YN9l2a6o2aQpXXU5/peULtf0dMwjGehZoRR+54qFFKlzqWlJczO
zsJkMvEcJUtjuVxmg9J9mZychNfrxcbGBiKRCHvcxOtShsFdXFxwW4uTkxPOTSaj0KiV16eMMnSf
Ghh3Oh3s7u7CYDCg2WxidXUVFouFjYT0f1Sgy+12Y3p6Gt1uFyaTCTs7O9je3sb+/j5/5sqQoGGM
U9FoKSpglC91XVsSCvEOBALIZDI4PT3F9PT0lfDEp4I4rpVjXfm6zbGUx1T7u+TbZX5+vi/SSfye
oovopZxjX4Mx4Dr5rV6v4+TkBG/fvsXBwQFKpRIbbG66p5HlhJEnRgwrExEfusVi4eaYL1++xA8/
/IBisYi9vT3s7Ozg/fv3ePPmDXK53LWb+SDE5sVms5krbImQEib2KFNb3KmZr9/v52bUFosFPgx6
uwAAGgNJREFUW1tbePPmDXZ3d5HNZpHNZrmX1F2u9S4oQzLIE0bl3cVQROB3JUz0hNH1qTXFG9b1
DhLk9Ho9XC4X5ufnEQ6Hsbq6yhUmxcnZaDSQSCSwvb2Ns7MzVm4fKjArBQaq6ESFOaiqpF6vRyAQ
4PPodDrMz8/D7/djamoK9Xod5XIZvd6Xoi63KZk9zLFw3XMQxwZ5byORCF69esVVR0lZL5VKHNc8
jN5LXwtKZfk2GwKNTbWv42BYyuJNnr+HKBTK56r8m/KY5Kn1+/1YX1/n0HGfz8fvJyUsl8uhUqlw
WPV9oH3B6/VifX2dyyOLKIVKCj/OZDLY399nw6AYnTHOcfCUISWMwrX39vYAfHmGVIlWNBSSd0ur
1UKv18Nms7FSbrVa0W63kcvlOPJAqdgMy1igZpCk84mWbeWcmZqags1mQyAQQCwW4+unUMqvaUzc
RQGj9w86huT7IBAI3Op9tD4qlZrHVsCuG6uDFDCKoqpWq6yEnZ6eolwu39pJMBIljLwUDocDkUgE
AJBIJJBOp/kmjEYjvF4vPB4P9wgIBoOYmprC/v4+otEoN+M8OTnpK/lL3GWBoAX0OvegWjw3PUiz
2QybzQa3243V1VW25NXrdbx58wZbW1uIRqPI5XKo1WqPsuhSNT8KhVD22Op0Oly5hQqIjNpqJSoB
5KmjpsgL/59/EYlEEA6HOUSUJik1zD4+Psbu7i4+fPiAs7OzoZWkVl6jSD6fx97eXp+A4PF44Ha7
YTKZ2NLj8Xi4t83+/j5cLheSySTy+TyKxeKtLIp3WXxu+3lpNBqukmmz2eDxeOD1erkPWCgUgtvt
7lO+yRNWqVTQaDRufU2jZtTzSClk31YAUbMijxKlN/W+Qo5S8RITqe+7xqpx06ZGawKFojudzr4c
RfJAi8dqNBrc0+ihhXlCoRCsVisbVJxO55UwdWUkBIUtJ5NJ7O7u4uzsrC8cclxj4amjdv/lchnR
aBTT09PQ6XTodruYnZ2F1+vlcFOxfQYAzteLRCLo9XrweDxIJBJIJpPIZrMolUpslFMaPe+DGIFB
45OKhc3OzsJisXDFXvFee70eh9aTQY+MdwcHB9jf339S0QUSybC5ac27LsrqqUWfXCerkV7Q6XQ4
h35nZwefP3/G2dkZCoUCGwZvE0kyMiWs1+txjxCqfphKpfg9FNL18uVLFsKtVitbGD99+oS3b99i
a2uL+1mJ3EUBU1OuBmm0SmsXvddoNCIQCCASiWBzcxN/+MMfUKlU8P79e3z8+BHHx8c4PT1FPp/v
s9KNcjNWfsBUhYZywtSUsEaj0aeEKftcDeOa1cLiNJovMf/0HBcWFrC2tobnz58jEonAYrFgZmam
bzLWajWkUikcHx9jZ2cHHz9+7FMQhq0sitedz+dRr9e5uk273cbGxgZ0Oh2Xrwe+lK2fmZnB7Ows
XC4XzGYzdnd3sb+/j0ql0qf8q3kDlM9r0IRVbvo3/V0MTaWy2xsbG9yIlgRO8XzU46Jarao2m31M
7hoe89DzPOT/RYa1sQw7xE302ohKGHHTeLsryvlFP1MeDfWKWVtbw/r6OlZWVjiZW/zfRqOBXC7H
IYAPUcKWlpa4LD0pYWqtGcTCRlQanwpFiUrYbTbc7wnxefR6PZRKJZyfn7ORtl6v4+XLl5ienobR
aOT8EdqLe70e9Ho9V1ZzOp1YXV3FwcEBDg8PuTdbr9djhfyhBYXomkkBm5ycZCXM5/P1rf0i3W6X
lTBKB/D7/WxYFmUfieRb5Lb9cL8G5UuUA5RGS9ITLi4ucHZ2hg8fPuDjx4/Y2trC2dkZms1mXzTU
TfvnSJSw3d1dLvlOOT/VahXNZpM3/NnZWayurmJtbY03v0qlgtPTU+zt7WFrawv7+/tcKGGQgHAd
9D8kRJfLZSQSCZhMJvR6PS6qoHzIk5OTvDEYDAYuRb+ysoLl5WX4fD5MT0/3hclls1nuNzXKQaW0
0onNKymh3WazqYZckjJweXmJqakp6PV6mM1m/kxo87sNgwao8tqoSg6VgSZr99LSEpaXlxGJRBAM
BvkaqIx+s9nE6ekpVx47Pj5GMpns6zkiXscwoA241/tSUIaaQet0Oi5gMjk5icvLSx4XWq0Wbreb
89gmJycxMzPDxWZqtRqH91FoziCP7F3HDT1vaoJIhUN0Oh30ej3sdjt3o3/x4gXW1ta4D9vU1BQa
jQZKpRJ0Oh10Oh03GSyXy0P3NgL3D2kTBSJ63Re18UrP8NmzZzCbzTCZTDAYDLw+3Pce1BQ6NQHu
PtA4M5vNVwwuNykDoqBJ/fncbjcqlQqePXt2JbxvGN42cT2gl16vh9FohN1ux/r6OtbW1jgE0e/3
952f1qVqtYp0Oo1kMslGjvuytrYGk8nEDULJCzbofpvNJsrlMlKpFJLJJDdmFg2E37sHTIk4FpvN
Js7Pz9Hr9TA5OcnRLVNTU+h0OjCbzTCbzRxGT+Gi4jj1+XzQ6/UwmUywWCywWq2wWCzsEavX69zG
QAwhVBbyUBog6EVjk9bRmZkZBINBhMNhLC8vw+Vy9eWTi/NMLEKg0Wh4TbXb7VypWPJ1My5j4H15
Ctel5umi349CNh7G/d60XwLgGgr1ep2roH/69Anv3r1jgxyFId6FkawKf//737mABVmRJicnEQgE
WFC02WycU1UoFLC/v49UKsVNGgeVHr7rA6f3t1otnJ2d4e3bt2i1WlhbW4Ner+fmkaR8UTw6VVKk
flHBYBB+vx8OhwPFYhG//PIL94dJJBJcAVJUioYJDRJRIBUbXwKAzWaDw+GA2+3mRqMiypBA2tCU
TZHvcu1KxYuKoFAOHpUlpWpYdH1utxtOpxM2m43zBicmJlCv15HL5ZDJZPDu3Tu8f/+eC52Mo5+Z
eO8UVpJIJDiHrlQqIRaLYXFxEaFQCCaTiRs6e71eTE5OcnL2+vo6EokE4vE4MpkMtz4Qi6IoQ8zu
Ao0DElAsFgtcLhc8Hg+HTopfnU4nLi4uuH9FtVpFpVLhv5+fn6NUKqFYLI5ECbsLSg+q2GdEGTJ2
F0TBi8YrPUOytvv9fq6SR2uD2ry4LoeKlGxlw9P7KmHKc9O1BgIB2O32viJI122C4nWS0hkIBLCx
sYFUKoVUKnWlnchdx6XamkBGCVpbzWYzHA4HnE4nexlmZ2fhdDphsVh4wxYtj9QnkBSgSqXyoDWB
wojJqKZ8VnTfZKgrl8s4PT3FwcEBkskk95EUvdyPLQA9RZTjjgqbUNEqanxP7QisVisMBgMrMwBY
QQIAr9fLIawLCwtsAC0Wi6yMiUVbqBWLWDiFlD+xPLZWq+Xy2SaTicepx+PB7OwsfD4f3G43tFpt
X/SIeJ+9Xo8jCmq1GhufSRmUfL2I+/Rtqt6NG1F+u22j7cdgnBED193/oIgt8e/0+06ng2q1yo6c
4+NjnJycsFc+lUqhUqmorgs3MRIl7G9/+xv0ej02Njbw/PlzuN1uzM3NcQ8rsZnw9PQ0jo6O8J//
/AcfPnxAsVhEoVBgz4PIXZUDgnJdzs7OeFM3mUyYm5sDAFYCRCXMZDJhcnISr1+/xo8//oi5uTk4
HA70ej3885//xC+//ILt7W0uT0znvOsHcBdIcBKFUir1OTEx0afkDFLC6H+tVivHuFOp+Pt4wkQL
Ih2HPmOz2cwNgUnQt9lsLEireSGbzSbS6TQODg7w22+/4eeff8bJyUlfEZFRI27UzWYTiUQCiUQC
xWIR8XiclTLKDyAh3ufzwePxYHFxEeVyGcViEVtbW1zVKxqNcgd1Cpt5yFihYhsGgwEulws+n4+7
z4fDYczOzmJ2dpaFmW63i1gshlwuh2QyiUwmg2w2i6WlJb7ncrmMUqn0oLLfD0UptImWaaqaet/n
RscTvYfUJN5kMsHpdMLn88Hn88FisVwRzu+CGN5M80qn0937eOI9kxIWDAbZ0q723kGbHa0ZJpMJ
wWAQpVIJMzMz6PV6fce6j2GG5rW4JlBUgdVqhdfrhdfrhd/vRyAQYGOQXq+/oqTS9Xc6HbRaLZRK
JTZsUMGD+/L69WtMTk7CZrNdq4SJc4OUsEQiwYVBRr3ufwuIa2qr1eJej+VyGbFYDKenp6jVatDp
dOwBo3xA4Pd5S9Us3W43QqEQGo0Gzs/PuTlqJpNBMplEKpXidaxWq7FCRgqz2JeMDIV6vR4Oh4ON
A/Q9RQ9QhU7RO66UMyhklZQwZei/5OtG6Ql7anP+qStg4+K2hu3r9kfxWFR8I5VKYXt7G2/fvsW7
d++Qy+W4j6H4v4+uhBUKBdTrdRweHqLdbsPlcsFms8FqtbKw0+t9qSRXLpexvb2No6MjttCTAvaQ
sDNR2yYBtFwuIx6Pw+VyIZVKIZvNshV5enoaVqsVc3Nz6HQ6sFqtaDabWFxchNFoRLFYZAH2f//7
Hw4PD7lh8DgG++bmJgsMpMhMTU31NcWj/iqLi4twuVyYmZnpO4ZOp4PD4UC328WzZ8/gcDjQbDb7
PGH07G6LMpyLBGatVsvd0Y1GI3tqDAYDh5u0220umV8qldjLdHR0hKOjI+zt7aFQKIxVASPUngWF
QomWcZ/PB6/XC6fTydZTsvxT/yGtVguv14vV1VWupFatVrkXXavV4ubjYi6hGMZFX6emptjzRkIE
haDabDa4XC64XC6YTCY0Gg2cnJxwnle5XOZEUuqHV6lUuJyyRqPB9vY2ksnko1ZHFL0oFosFoVAI
3W4X4XCYc/WAu68JtB6Iz5QUBfKymUwm9tqSckDvV0Lnp7An8tZQ3pAoAJ6fn6Pb7eIvf/nLvZ7J
8+fP8ezZM55Pc3NzWFpawtLSEvx+f593UFz3lPevVM4oR1Oj0bDnX+kFfagnTDQaiV5xCpclgxGV
LlYKEBcXF2ycy2az7IESe0/eB5qrJPiL9yoqfzRPT09PsbOzg93dXWQymb7Q6KeU1/BUURtHFPlA
hrxqtQq/34+5uTn2RpvNZg7xpoq1YtVl8lZTDqzD4cDc3BwraBTF0G63+5Qw0QNGL6PRyDKKyWTi
vopk7KRcEFq3qdowha9T+DkJZ7FYDIeHh6jX699t78WnyJ///Oe+nwetmcr3TE9P8z6/tLSEQCAA
k8nUt4aME1q/KKLh1atXMBqNLGPc1Cz4vlE4atz2/sexVtI+ctPnKd6/OK8pdJr2cYrASKVSiEaj
ODo6QjqdRr1e5xQT5TFvy0iUMMotuLi4QCqVYk/Y7OwsK2ONRoNdeWTFqlarV2rrP2RwiB8CVbW6
uLhALBZjTwA1caaeVSQ8r66ucrgEABwdHeHz588c+0kJ2VQqfdSWkR9++AFarRbz8/NYWFiAwWBg
YYcshCREUol6pdV9ZmYGTqeT+7JFIhFcXl5e6Y1yV8TcGmWoF1nCKXSSQkqow3i5XEYul8PR0REO
Dw9xcnKCk5MTLvNJMbaPYdVRKvJkIGg0GigUCtjb2+MiI5TcPzc3xzl55GV0uVwsiNM9kwJEr2az
ycICeU5EDyMJDORhFIUEg8HAXlFaCDudDnu6kskkYrEYe/OKxSLq9TrnqB0dHXHFx0KhwL3OHhMa
kxaLBZFIBF6vty+06L6InyedQ6mQiUYEUsJofANXk3fpOZJAdn5+zhb5TCbDIZ6Xl5f3VsJev36N
6elp9m6SN4CKwYiVRW9z/4TRaEQwGITD4eBrFz/7h3gcxZe4HojCL0VEKAuDiNdKzdpPT0+RTqdR
qVQGNkW/C9Tjj86vvGcqhU6b8MnJCba3t7Gzs8PRGuL/fM+W59uiXFPJu0lNuI+OjuD3+7GwsICF
hQUEg0EenyaTiQ0iNF6oDc6zZ89gMBhgt9v7DFtiXphoyBPnvdp+Jb7ofNTihUrukxGZFC7xRaHn
FCZJFZMlT4O//vWvANRzhNUQ1zFS2CnCx2KxqOYPj4OJiQnMzMxgYmKCq8mGQiFWJG7yiinl1oes
YU/NEHXb6yF5SzRWkxyUSqU42o289+Rhr1arVxq432cfGIkSRonKZLEmy2Wr1UKxWITFYkG1WsXn
z5+xtbXFSbS0QA9zMPd6Pc7TIotVNptFIpHA2dkZdDodh6NQh3vy1DUaDSSTSSSTSRwcHODdu3f4
8OEDa8fDVBhvYn19HTMzM4hEIlhZWYHRaOQJRsqNmiAjIoYGDQvl5FXGJYsv6kFFFodisYh8Po9k
MomdnR1udp1IJLia1GNPbFFooM29Vqshn8/j2bNnSKVSvPFSA1nyjNntdq4ISaGLlPdGY0iZv0BK
2OXl5RXFQKmEkYV2amqK/4eSRguFAsctn5ycIBqN4vT0lC22oiJDSvyg/jv3eWa3/fmm905PT3NY
0DCOpzZe6ava72jNUBvT9KxE5Yu8X6T4plIp5PP5K0L7XVldXYVWq8XS0hJCoRAcDseVvJlBPQmv
24A1Gg0r9Hflrgqf2u/V4vKVYYCUxxiNRpHJZFCr1dBut28UnG6iWq1yBADNNToveTUpeiIWi2F/
fx9HR0eIxWLsVRGvV3I7xDWVDBjUo3NiYgLpdBq5XI5zvarVKrxeLxwOB4feUqELUp5IGBWNk0rv
htoedd1+1e122ShBBaMajQYajQYLaoVCAZlMBul0Gul0mg1f4roueXr8+OOP/L3SiHwdopGZQuTJ
iPNYShjNhampKVgsFo4cUhajUeO6iuF3JZfL8TWJBk5l4+ZB81P8/ibPpNr+NkgGHbR3UzXVdrvN
+cYUcUHzOBaLIRqNIh6PswFbdM6I13jf5zcSJUz54JrNJifiUtgP5f6IuV+i1woY3uYmxqMDX8oc
x2IxbG1tYXJyEmazue+9FBqXSqVweHiIg4MDRKNRRKNR9n4pjz/qjdjpdHK4BU06Oq/SUn8TDwnz
VDJoYNPgJg8PhYbUajV+vvl8nhUY2sRKpRLq9fqVe3lMQUc8Nz1nGqOlUonHRSKRwM7ODvc8olAr
0WNFQgIALlBjNptV2yiIi5Z4HRrNl1y1SqWCi4sLnJ+fs1WWni09X+pXRtZYMSSHjkVCp/hZPuR5
iwv/IIFHTQC6Tki67bFuOo5YMEM5bpXfi7+j8UwLNinkJJiRskZ5IGJundjq4L643W7odDrY7fa+
dg5UbIDuV7mpqm2y1ymeSgZ5pwZ9r7QsD/peKfiobcxkPGu1Wuwtz2QyQ+u39O9//xtarRaBQADB
YJA9YxqNhufQ2dkZdnZ2OK8zm832KWCS+6FcUwnKvYjH42g0Gtyyhgq4UOEWi8XCoYJUyZQEYjI2
il4zGus0l9VCiNvtdl/EAhmO6XdUObZcLrOxRQw7Fn9H4bKSp4myKftN8pP4NzHnVazk+VjQuSks
Vy2//7r9fFjy688//8whmxQ6TF+V0VCih1lU2JSKm7J/5U0GFJrbJIOKc5vmMoUaimHEYkoMVYcm
I3mxWGSDilqroZue702MpWZqs9lEJpPh2G8S/OgBjVPgprCyeDwOjUbDVRBFa0YymUQ0GsXe3h4+
fPiA9+/fs8ArLqxiGOKocTqdXDZfVMLoOu6qgA3juukzFAe9GJolVuAjRYCKQiQSCWSzWeRyORSL
xb6ywg8pyDIqlIo83TtN2Hg83meNotwsqk7ocrlYMSPPg8Fg4BLj4oIunpNelH9Agn61WmVrcTqd
RjweRzwe51CYUqnUtxCRwEEohWbR+zWMcUFf1ZSeQVZnZUVBtQqDN/2/eJxB7xOFL+XYFX9H76OW
CeKLhDJxEScPZ61WuxIK9VCh3ePxcKi01WrF9PR0X8sD8V4HKZI3WQqVKJWsQZbL65QspYIl/k6Z
76i2+QJfKttms1lWwoblXfj5559hMBjQbre5NDrNwUKhwIa6X3/9Fb/++ivP9WEU1ZFczb+jcVip
VFCv15FKpdhDKRZ08Xq98Hg8nGtut9v7WktQKL4y/L3b7fKcoRwxUTij6rCiokX7V6VS6TMcUmqD
0usghj3SniHHydNDqYTdhdt6a8aFuJaSAgaMf33617/+xe2IyOBMxmcK7ae5SVFn5M0WQ4KVP4t7
gposIe7nynxNUfEi46jSWE1VVZVtLkRDjdI4TgxDjh6LJ0wZj61EvLFxDJxut8sWbMoxEQsikHeB
4r6LxSI3CAZ+t9KOE7EIx0NCcIDhP2M1z4I4KSg+mRQI2tBIMaNWBMpN+SlD10oCPPD7uOh2u7zA
iGXVDQYDWq0WV6EjaxqF14hCA9Bf5pzOSV5YEiiotxeNU4plLpfL1wrXg6xLw3w+gzxSNylQ1ylj
1ylhojB03Xmus5YpFVcaw4MsaLVajb8XlbBhe0rE8SFuTIMUMDXv3nWewfsoYdd5t+glGi/E3ykr
o9JX5SYHgD8zWquH9WypAIlYvY6eBZ2P9oFyuYxGo9HneZQMF3quosIk/k25lpJQRx5psTfYIIs5
jXlxj1IaD8X5TUoYCW+0xlJY/XXerq9hH/te+VZ6tg2KTHgMarUaK0okC4mKlah0URGm6wx4yn1J
TU5RyhTKeU3rAhlSxX1bjB4SFTEx/UDJQ2VvNTRyQ5FIJBKJRCKRSCSS8fF4gawSiUQikUgkEolE
8h0ilTCJRCKRSCQSiUQiGSNSCZNIJBKJRCKRSCSSMSKVMIlEIpFIJBKJRCIZI1IJk0gkEolEIpFI
JJIxIpUwiUQikUgkEolEIhkjUgmTSCQSiUQikUgkkjEilTCJRCKRSCQSiUQiGSNSCZNIJBKJRCKR
SCSSMSKVMIlEIpFIJBKJRCIZI1IJk0gkEolEIpFIJJIxIpUwiUQikUgkEolEIhkjUgmTSCQSiUQi
kUgkkjEilTCJRCKRSCQSiUQiGSNSCZNIJBKJRCKRSCSSMSKVMIlEIpFIJBKJRCIZI1IJk0gkEolE
IpFIJJIxIpUwiUQikUgkEolEIhkjUgmTSCQSiUQikUgkkjEilTCJRCKRSCQSiUQiGSP/BwCfzso1
hHpFAAAAAElFTkSuQmCC
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAABnCAYAAACJvUq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAABnCAYAAACJvUq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAABnCAYAAACJvUq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data-curation_1"&gt;Data curation&lt;a class="anchor-link" href="#Data-curation"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;drop unreadable images&lt;/li&gt;
&lt;li&gt;normalization &lt;/li&gt;
&lt;li&gt;pickle the normalized data by characters / folders &lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Now let's load the data in a more manageable format. Since, depending on your computer setup you might not be able to fit it all in memory, we'll load each class into a separate dataset, store them on disk and curate them independently. Later we'll merge them into a single dataset of manageable size.&lt;/p&gt;
&lt;p&gt;We'll convert the entire dataset into a 3D array (image index, x, y) of floating point values, &lt;strong&gt;normalized&lt;/strong&gt; to have approximately zero mean and standard deviation ~0.5 to make training easier down the road.&lt;/p&gt;
&lt;p&gt;A few images might not be readable, we'll just skip them.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Debugging"&gt;Debugging&lt;a class="anchor-link" href="#Debugging"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;In case of following error occur:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ne"&gt;ImportError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Could&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;the&lt;/span&gt; &lt;span class="nn"&gt;Python&lt;/span&gt; &lt;span class="nn"&gt;Imaging&lt;/span&gt; &lt;span class="nn"&gt;Library&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PIL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;required&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;load&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Follow these steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pip install pillow&lt;/li&gt;
&lt;li&gt;replace  &lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;display&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
to&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;display&lt;/span&gt; 
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;PIL&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Image&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalize image using 
&lt;code&gt;image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth&lt;/code&gt; where &lt;code&gt;pixel_depth == 255&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/41124353/importerror-could-not-import-the-python-imaging-library-pil-required-to-load"&gt;https://stackoverflow.com/questions/41124353/importerror-could-not-import-the-python-imaging-library-pil-required-to-load&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;  &lt;span class="c1"&gt;# Pixel width and height.&lt;/span&gt;
&lt;span class="n"&gt;pixel_depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;255.0&lt;/span&gt;  &lt;span class="c1"&gt;# Number of levels per pixel.&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;load_letter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;folder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_num_images&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;"""Load the data for a single letter label."""&lt;/span&gt;
  &lt;span class="n"&gt;image_files&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;folder&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_files&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                         &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;folder&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;num_images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;image_files&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;image_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;folder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;image_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ndimage&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; 
                    &lt;span class="n"&gt;pixel_depth&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;pixel_depth&lt;/span&gt;
      &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;image_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Unexpected image shape: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;num_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;image_data&lt;/span&gt;
      &lt;span class="n"&gt;num_images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_images&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;IOError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Could not read:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'- it&lt;/span&gt;&lt;span class="se"&gt;\'&lt;/span&gt;&lt;span class="s1"&gt;s ok, skipping.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
  &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;num_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;num_images&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;min_num_images&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Many fewer images than expected: &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; &amp;lt; &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;
                    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_images&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_num_images&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Full dataset tensor:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Mean:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Standard deviation:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;std&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;
        
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;maybe_pickle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_folders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_num_images_per_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;dataset_names&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;folder&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data_folders&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;set_filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;folder&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'.pickle'&lt;/span&gt;
    &lt;span class="n"&gt;dataset_names&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;force&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="c1"&gt;# You may override by setting force=True.&lt;/span&gt;
      &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; already present - Skipping pickling.'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Pickling &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;.'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_letter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;folder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_num_images_per_class&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'wb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HIGHEST_PROTOCOL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Unable to save data to'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set_filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset_names&lt;/span&gt;

&lt;span class="n"&gt;train_datasets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_pickle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_folders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;45000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_datasets&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;maybe_pickle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_folders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1800&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;./datasets/notMNIST_large/A.pickle already present - Skipping pickling.
./datasets/notMNIST_large/B.pickle already present - Skipping pickling.
./datasets/notMNIST_large/C.pickle already present - Skipping pickling.
./datasets/notMNIST_large/D.pickle already present - Skipping pickling.
./datasets/notMNIST_large/E.pickle already present - Skipping pickling.
./datasets/notMNIST_large/F.pickle already present - Skipping pickling.
./datasets/notMNIST_large/G.pickle already present - Skipping pickling.
./datasets/notMNIST_large/H.pickle already present - Skipping pickling.
./datasets/notMNIST_large/I.pickle already present - Skipping pickling.
./datasets/notMNIST_large/J.pickle already present - Skipping pickling.
./datasets/notMNIST_small/A.pickle already present - Skipping pickling.
./datasets/notMNIST_small/B.pickle already present - Skipping pickling.
./datasets/notMNIST_small/C.pickle already present - Skipping pickling.
./datasets/notMNIST_small/D.pickle already present - Skipping pickling.
./datasets/notMNIST_small/E.pickle already present - Skipping pickling.
./datasets/notMNIST_small/F.pickle already present - Skipping pickling.
./datasets/notMNIST_small/G.pickle already present - Skipping pickling.
./datasets/notMNIST_small/H.pickle already present - Skipping pickling.
./datasets/notMNIST_small/I.pickle already present - Skipping pickling.
./datasets/notMNIST_small/J.pickle already present - Skipping pickling.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-2_1"&gt;Problem 2&lt;a class="anchor-link" href="#Problem-2"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's verify that the data still looks good. Displaying a sample of the labels and images from the ndarray. Hint: you can use matplotlib.pyplot.&lt;/p&gt;
&lt;h3 id="Load--test-data-and--show-normalized-images-for-each-pickled-dataset"&gt;Load  test data and  show normalized images for each pickled dataset&lt;a class="anchor-link" href="#Load--test-data-and--show-normalized-images-for-each-pickled-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;notMNIST_small only in order to prevent memory-insufficient problem when load all train data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;use &lt;code&gt;pickle.load(open(file_path, 'rb'))&lt;/code&gt; to load a pickle&lt;/li&gt;
&lt;li&gt;create a figure obj and use &lt;code&gt;fig.add_subplot(1, len(images), i+1)&lt;/code&gt; to add subplot for each image&lt;/li&gt;
&lt;li&gt;render ndarray represent images using &lt;code&gt;matplotlob.pyplot.imshow(image)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;test_datasets&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Number of samples in &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
    &lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:])&lt;/span&gt;
  
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;
&lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;images&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'off'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Number of samples in ./datasets/notMNIST_small/A.pickle: 1872
Number of samples in ./datasets/notMNIST_small/B.pickle: 1873
Number of samples in ./datasets/notMNIST_small/C.pickle: 1873
Number of samples in ./datasets/notMNIST_small/D.pickle: 1873
Number of samples in ./datasets/notMNIST_small/E.pickle: 1873
Number of samples in ./datasets/notMNIST_small/F.pickle: 1872
Number of samples in ./datasets/notMNIST_small/G.pickle: 1872
Number of samples in ./datasets/notMNIST_small/H.pickle: 1872
Number of samples in ./datasets/notMNIST_small/I.pickle: 1872
Number of samples in ./datasets/notMNIST_small/J.pickle: 1872
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAABnCAYAAACJvUq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAAIABJREFUeJzsnVlzG1lythMACRD7TgBcRW3dY0d4HBP2/7/xnX3hiPFM
e77pllpcQWLfFxLAdyE/yayjAldQUvcgIxCUuABVp87J5c03MwOLxULWspa1rGUta1nLWtaylrWs
ZS1fR4Lf+gLWspa1rGUta1nLWtaylrWs5R9J1kHYWtaylrWsZS1rWcta1rKWtXxFWQdha1nLWtay
lrWsZS1rWcta1vIVZR2ErWUta1nLWtaylrWsZS1rWctXlHUQtpa1rGUta1nLWtaylrWsZS1fUdZB
2FrWspa1rGUta1nLWtaylrV8RVkHYWtZy1rWspa1rGUta1nLWtbyFWUdhK1lLWtZy1rWspa1rGUt
a1nLV5R1ELaWtaxlLWtZy1rWspa1rGUtX1HWQdha1rKWtaxlLWtZy1rWspa1fEXZeIk3DQQCi5d4
Xyubm5uysbEhoVBIREQWi4UsFguZz+eyWCwkEAiIiEgwGJRAIKD/53dubm5kNpt5/vZryWKxCDz2
b+yaBgIBCQaDEgqF9LWx8flRzudzmc1mep/BYFAikYhEIhG975ubG12njY0N2draknA4LJPJRCaT
iVxfX8tsNpPZbOZZO77+3z141tz9ufs7Ly3PXdPniHvfgUBAnwv3b7+XyWQkk8lIOByWXq8nvV5P
ptOpzGYzmc/nEolEZGtrS4LBIPcmk8lExuOxBAIB2drakq2tLZlOp/pyn6uVpz6Hp6zp/92/54Ps
HrXrwv1ubGzIxsaGZx1ns5nc3NxIMBiUcDgs4XBY9yT3enNzo+st8nnvz+dzz3519+lD1uAl9+sq
1pQzafUA62fvl/vgd1nnUCgk0+lUrq+vdb3YV5FIRILBoOpH1syuu/18c1/6QjcHAgF9ZlZPcM32
PXh/e4/uc/O7t+esK2vKdVh9yj2IiJ4xu+asJesZCAR0fez9Wn3MZy25FrVVfLXvYfeue42BQED1
A7qGa7R2MhQK6fWhK2azmVxfX8v19bU+W2Q+n38TneraG57N5uambG5u6vdjsZgUCgXJ5XJ6H5PJ
RAaDgfT7fd3boVBIEomEJBIJmUwm0m63pdPpqF4JBAJ6Htxn6No45Kk64qn71G9N/F5WH4iI3Nzc
yPX1ted63fPE/axS77Hu1v9g/7G+6Bd+314T+5Xr5Xd5WVml7XfXkn+zB6z9RS/ae7Hr6acj7efw
1eoSzut8PpfJZOLxC9z3d9/TyrLff6h8S39q1eLq1mAw6OuXoQ+2trYkHo9LIpGQ8Xgs3W5XBoOB
iIhHj+OfiXxeb3SI3RNWdyxb0xcJwr6WuAdla2tLotGoRCIRCYfDEolEZDqdyng8lul0qhv8+vpa
BoOBDIdDz0b/LYifsk2n05JOpyWRSKjCG4/HMhwOZTqdqjIUEd0QrBGvzc1NNU52XezP2cAoxel0
qkHEfD7X9bWK9qGO729ZrOND0ICi5vubm5sSi8UkFovpzzY2NqRUKmmwzF7GSQqHwxKPx2Vra0s6
nY50Oh2ZTCZfBHh2P/OaTCYeI7fsul9SrPMfiUQkGo1KNpuVbDYrm5ubaij8AkgCApyuQCCge20y
mXyx1oFAQIbDoQwGAxmNRjIajeTm5kZ1wvX1tYxGIxmPx18YKLse7vcsePM9iJ/Dxb6yL5FbZ8t1
EqxjGQ6HJRaLSTQaVSf35uZG+v2+9Pt9BWXm87nqm83NTQmHwxoABINBub6+Vj1rjRqAgtVHfL59
7lbPoK8IfkajkfT7fRkMBnoPNsB57npyHnlFIhEPCMU9R6NRtS9cI2f1+vpa9x/BJAEpepHn5X6+
iMhwOJR+vy/T6VRSqZSk02kJh8P6OcPhUEajkcxmM48eZv1Yl3A4LNFoVIG1cDisewA90e/3ZTQa
afCFbbD76luKdWDtM2E/4SCl02nVJ+PxWM+8tUPowUQiIclkUq6vr6XT6Uiv19P7t2As74MeHQwG
HpDrW64J9oHzh+6LRCKes+gG8iJeoKrf7+v9++ngVYoFBCxgjs7BDm5sbMhsNlMgmPMnIvrzfr8v
3W5XRqPRSq/RFdYMu8yacw98RbcRyLsBF2dfRDx6gnXmHFswBwFMGI1GnnXiM2wgawOKQCAg8/lc
BoOB7l0XyHlqYPZblvl8LtFoVBKJhMTjcf3+1taWguLWnthn5/rM1p9mnbvdrrTbbWm327qus9lM
9chd5+o3G4RZZwSjn0qlJJ/PSyaT0cXu9/vSbDal3+/rwR+Px9JsNqXZbHrQ2u9d/FCvzc1NyWaz
srOzI9vb22qU2u223rdFj1AoqVRKUqmUbG1taYBVrVbl8vJSWq2WOrIYvGg06kFTcTouLi7UscUg
jMdjERFPVuIfQXCytra2JJlMSjKZVAUbj8f1sGMcNzY2JBqNegxSKBSSbrcr3W5XYrGYFItFyeVy
cnl5KdVqVQPe2Wym731zcyOtVktfjUZD197PsFrj/JKK2A3CEomE7O7uyqtXryQWi6lzaA0GRiKX
y0k+n5dIJKIOwtXVlVxeXspwONS9lkqlJJlMSigUkkaj4XmNx2NJp9OSy+X0zGMM/ZwTvwBsGZL5
LcQ9+7yi0ahkMhnJ5/NSLBalWCyKyC2CjGMznU5lMplohjEYDEoymZR8Pi+5XE6/NxwOpV6vS61W
U0dgPp9LPB6XeDzuARPY8+PxWJ1bjFQsFpNcLie5XE46nY60Wi3p9/vq/FrHOZPJSDqdlmg0qsEY
+6LVasnV1ZUH2JnP5x4H+qkSDAZla2tL0um0ntl4PK6gRjAYlHQ6LalUSnK5nGSzWYnH4/ocRqOR
BjYY4el0qs8L5z8ajfpmfPl3vV6Xi4sL6Xa7sru7K7u7u5JKpdTwc7YtAGHPDU5iKpWSTCajuj0S
iWjwNRgMpF6vS6PRkG63K+Px+AtdbcGgbyk4ldFoVNLptAe8KpVKUiqVJJ/PSzqdlkwmI71eT7rd
riwWCz0Dk8lEOp2OjMdjfQ6z2Ux6vZ4+r06nI9PpVJ8NQE+r1ZJ6vS4it/ryWwZhCPYbu5xMJnWf
8PysbuO+eKY3NzdyeXmpehR9OB6PV+4Duf6ZdWoTiYRsb29LLpdT4Pj6+lqfDYFwIBBQnXN5eSmT
yeRFgzBrF23GBBB1c3NTQaB4PK7+pnXaLZAYjUY1U821o/NsQMczwtb1+33NsBcKBSkUCho8kLm1
bAZ7fmezmerv4XD4BSj+jwCMW+FeNzc3JZ1OS7FY1LVKp9Oyt7cne3t7qsstUMszjMfj6jMTdIuI
XF5eytXVlVSrVTk7O9PnQLJHRO7dr7/ZIIwsAQc0Ho9LoVCQYrHoUc79fl+NDkhmr9eT8/NziUaj
qmhF5LvP3LgoGEhYpVKRN2/eyN7enuTzeSkUCtJut6XVakm321X0BYcJ5zWdTiuqGwgEpFQqSaPR
kE6no8oCFBjHyiqmyWQi2WxWcrmcXF9fexArkGsQXDc1/r2u8UOFQ2hpBARTOP6ZTEYNTCKRUCeO
4CMYDCpYwN4kCOv1ehKJRFTJF4tFKZfLmgkaj8cepLvT6Ui325VqtSrn5+dydXWlz3A8HqsT7spL
PYdAIKDIdSwWk2QyKdlsVg4ODuSHH36QdDotIp8NMkGnpXzl83nJ5/OytbWlRsQGBhgvAoJgMCi5
XE62t7fVGZ5MJhoEDAYDqdVq0mw2PXRGABiMPmfFUnG/p/3qnseNjQ3J5XJSqVRkd3dXDQqOAhnA
0WikQRgBPGAMe5XzPRqNpNlsSqPRUCRvNpt9kW2zwAy0jX6/r+sFXSyfz2sQxnOGoYDzhx7BmVws
Fhp4BAIBfeY2o885ei56jxOEU5XP53U/hMNh2d7elmKxqCCKDcImk4lmTMhWW8omNopshZuxQOr1
upydnUmn05FKpSLlctkTfAAaQkkOBAKejAaofCqVkmw2K8lkUgM49gBnoFareXQ83yOI+dr73aV/
bW1tqc4oFouyvb0t8Xhc7V2pVJJyuSy5XE5phmQSRUT9gOl0qsEm+3U+n2vwz/6yQVin05F2uy2N
RkPi8bhsbm5Kp9ORfr+vmdyvqUdFbksquMZ0Oi2lUkm2t7d1T8IGsAAbTAHOVCAQkPF4rDp1c3NT
gzCYFZPJZKXPn0A6l8tJPB7X987n87KzsyOFQkEDGMvowCbM53N9dovFQlke6O9VXadb3mH9HfQs
oDfBb6FQkO3tbcnn8x62ENcEwMq6oyvIQvOZFvggsBoOh9Lr9WQ4HCqokEgkPKCXte02e8i5brVa
nnuwGTP7fJDvyc49VyxgiS2MRqNSqVTk9evXeq+ZTEZevXolr169Up3vBmHocHQNOpxAPBqNisjn
rFij0ZDNzU3Z2tpSvUtgvEx+M0GYm1qH2lQsFhUZw8nN5XKKHoxGI2m32zIYDPSw1+t1RV1RRCig
yWQiIt8e9fYT7huUEyrR/v6+/PDDD3J4eOhxOjnEOOBQhDBy8XhcueMiIgcHB55DDYWI9xDxptkD
gYA6vOPxWDNkfK/ZbEqtVpN6ve5BYnif37rAd+dwkoXECSgUCqqIk8mkov0oBcuXt1Qs1p+sWiQS
kWw2K3t7e+ps9Pt92dzc1BoenvHp6al8/PhRTk5O1KEgIG+323rtbh3fqp8HGRqC/VQqJYVCQV69
eiU//PCDZl4Wi4Ua3JubGw0OyEpEIhF9T+6b/cie5H22t7eVJgsNgyC31+vJ1dWVtFotNeAEAsPh
UPcpdJfRaPTF2qBIvxVFMRAI6H7DEEBpffXqlbx+/VqOjo7k6OhIKUbT6VTPsKV8su/QA7FYzEOx
w1kgUMJRA8SBlodjCG3Q0tzC4bBks1kFw3q9nmZucDZACwHNRESNIY7lYDDQLDEvW8/03OdgM8uZ
TEZ2d3d1jyQSCdnZ2ZGdnR11BqFich3oPa4b6ibOj+vU8beW9tdut6Ver0u/39e9n0gk9DM5I9R9
4ZASIKNnLDDJ55DFub6+lkajIc1mU/f5eDyW//3f/5WffvpJg3Qc8a8hNltCNg/ACWBhd3dXEomE
/g42DjsI3ZjgCJBgNptJPp/3AIQE7mQbCGJxggELarWaxGIxiUQi0mw2VY92Oh39e6sHrH+yasG5
J6AqFovy5s0befPmjdoUzoq7pmQPuU4C1V6vpxRA7sWtZ3mOWCc4mUwqUwffoVAoaDbT0qM5d4AO
NstL+QNUvcFgsLI1t2tlywVs8AqYXC6X5YcffpByuSzFYlGy2azaLb/yGBFR+4x/dX197RsAoRPZ
z7AEAH9YP+6fPQwANhgMpN1uezJ2buDF87HPScSfDfJbFWyjDYCSyaQcHBzIv/zLv6j94XsHBwcK
Wro0VHwzC6JZije65PLyUsH4ZDKpDKX7WAW/mSBM5Hbj4ODlcjnZ29uT169fy+vXr7U2KpvNamA2
nU41vQ3adnFxoVSa+XyuCBfFkN+jcO2xWEwPJE7U/v6+vHv3TpVyJpPRIMq+qGuw9QKswWJxWwyL
MphOp0pdaLVa6qzAraXWYzweexQCdLCLiwsR+exUoXhs0bOV39Lht7QdOMUYlXK5LKVSSSqVimxv
bytqlkgkNJ0tcnu/1iEjI2kzhjwbPo/C8na7rUbZGotPnz4ptQqEG0ofRgulTLbnJZwIl46WyWRk
e3tbDg4O5O3bt7K9va2KDiNCUxJQfaiyrBFKD2CF4H8ymXj+1jYiQIF2Oh1PJoxAgzqDT58+fdFk
ASFgXXW9xGOF/QYlAkorQdj79+/l3bt38vbtWy0UBn0lOLDOmQ0oLC3GZv9swIRzhmEii04hOToD
hyUUCmlAYVFGW4uDweNsTCYT1R8AY+12W50ighjuz6WMPkU4Z2QZKpWKvm82m5XDw0M5PDz01HXh
DNk6LwIdS8Hie6w9zgGAC0JdwXA4VH0ADSYWi3mohzwH24yDAMzWT7nUVRFRMKbX66nuDgQCmvkE
SX9per51AllDAMJisShv376Vd+/eyeHhobx69Uri8biHQgtF3tLA7gJHeMY2OLAAA/sdvZLNZlX/
EAxTx0rg6yLtLyXsM8DTQqEgr1+/ln/5l39R8AKwyj5zW8dIIE4geX5+LiKiOnU6nXoo4at4/jzX
ZDIp5XJZDg8PFbAki5TJZDwBNDYB2zUcDvX9hsOhdDodGQwGqr9XITjb0WhU91YymfTQC+v1ujZn
KJfL8sc//lGZR5lMxmPHLeOI5+ICTxYQs4EvP8MmB4NBD7CC3nVps9CMm82mTCYTD+3ZDbj8/u8X
qP2WxYJfIp+fYTwel93dXfnxxx/VRsXjcdnf35e9vT21/a5+Z13chjKAnCQeCJK3trYkkUjIzc2N
ZqHvkt9UEEZtCZQEUDK4xWQioHGI3CIcthtXLpeTg4MDT6QbjUbl5ORE6TTfm9DMYHt7WyqVinKN
w+GwZDIZyeVyHkSMtcK4gXS7dCY2nVXeOHeBQEBpSjaDgyKAQmCdr8lkoqhtvV6Xo6MjOT8/V2SL
xh8EZmxike8/EHPpCqFQSLa3t+XNmzdycHCg1CvoA4VCwUMbhb5lD6WlIvjdv1WaBGOga5ZLzu/l
83l59eqVBz0/PT2Vn3/+WZLJpKfZAfx73ntVwv2yNlBRCMgAELiveDyuwb/tFGUNm3UsFouFpNNp
3X8YNBuw8fs2uAiHw5JKpZTyAt3p+vpa0um05PN5ubq60r2KkwuVi8YQfiDCSwvAyfb2tuzv78vG
xoZmnci+5nI5PefoNtYhEol4aEoYGXv2/dBS9AdZH9ugwwUNeF8RUf1h/48edjtHkeEPh8NK66tW
qzIajSQcDiuP36U5E3w/91lwHbbZB4h8OBxWnYdBtxQf29SC/cbvsH58hv09EW/N7MbGhmavLArL
umPHCAQAynDY0DO2wN/P6YLGLyL6e+gMnPRWq/VVaqSt/YX2E4vFpFKpyOHhobx580bBLHQeGQbA
FptNXBZ88dXqUXQpa8bvuQ1oksmkOre1Wk2Oj481s84esXU+LyHcJ884Ho8r0EzWz6W72uAWdgW0
2Y2NDcnn8wp4wBSC5reKgHJra0upvYVCQYGTWCwmpVJJbWU6ndZ9LCKe8wKFjHNmmwXNZjOlzz5V
LEgECGTrMEVEM8OAeeFwWBKJhNbRZjIZrUm2dhgfzJ5vvkenX3ufrv5BYD/gb2EnB4OBXF5eysXF
hZyfn8vZ2ZkmGwaDgQSDQSkUChKJRFRfokssuOt+9u9FLNsI/x77Uq1W1VdAl5CUsVlklzJuKZ3s
OwI2GgalUim5vr6WarWq9cz36dLvOghz07UYKlB1aCJQETn0HAqRW/TYDykicgU17Pf7cnp6+k3u
9T7JZrMSDoc1+CS7wc+y2aykUil1jCxdxmY/XGeLtbCGmt8NhUKadbNKwzog9jDjXBGMtdttLVw8
Pj6W4+Njubi4UEMPPck6ZN9zIGYREgze9va2vH37Vv7whz9oFjKbzUo+n5dsNqt/i4NmjaQfQmId
M4tSuQ6rpenZPZ3P55XuQRDx6dMnRY1RyCiHlwAdCPptEAaNLp/PK2LPfdGgxN6L/berGHH24/H4
F01nrCK17wHKOR6PpdVqSbPZFBHRhgn5fF5KpZJcXV3pq9vtKqUzFAop4PAtDBZB/Pb2thwdHUkw
GJRmsym9Xk+DsGw2q/VxlvpGAGYd0WVBl/tvWwthAwl3b1q9YJ1anGSQYZwb15jZbCe1jTjp6XRa
9/P5+bnSrHkWz9m/9my5Ooz6mdlspqwBi1C7e8012m4Wyn6m/Wz2NvVffuef52Cfgd/et+/vPisc
Ovtc5vO5FAoFOTw8lGAwqHWXL92EgutBV8TjcXWIyZqgO3K5nO4bu6buerti95hdS37mUkJFbkFb
rocaU5rDAHI0m00Nvtrttm+L/1XpVXsGcfZyuZyUSiW1RZZBYINN9jTApw3C+v2+1Ot1zS4RhK3i
uqFNvvq/LCZnG7tAjSXNUsgs2n3J76MbCCKpGYNO+VQBXN7Z2dGMVjqd1r1CTeFisfCsczKZ9FBi
E4mEiPjrT6tH0YtW7/l9ddffZckQhF1dXcmvv/6qL9sQyAZh3Atigy7LSPiefa/HivUnAS42Nzdl
OBzK5eWl0uQt62aZ34HYJAX7DntHljqVSkm1WlUw977OiCLfeRDmio1qUZLUnHCAksmkxGIxDxfW
dcr4Gg6HVTk1m01tVMHG9DsQ30ps0HN9fa2Gi4YPZBeskRYRRWZdFNAap7uMGVkv+x73CQghaFG5
XNZAsVgsKt0IqqOlP34v6233DWtv62hwGN6+fSvv37+X9+/fK22AfYmBsXvRIuciXqXrrq8NcO2+
xXlw/zYQCKjRSqVSatyYEbexsaEOBZlikFwM8CrE0isthRbkEGqZ37q4RsreG//mvV0KxV37E71B
obQFYghwyIZBlWk0GuqUUntni6FtJuKlhTPK+WcfRiIRD6psz6pfoIC4Rt+PjmKDC/d77nst07M2
QLMZGsQGEextnE07B6vVamlWDV3h1jU+VsjM2aY40+lUOp2OpyZDRDSraINLPyN9V2Br18s1zG6G
nN+7b/3s3rOOh30m7udsbW3JfD7Xrl0AGqlUSnXNSwRh7EkbNNgOf7BZXr16Jfv7+1Iulz3F8MvO
mQ2i+Ry/tXTX3C+Qs8EOOoFGS9lsVjNLl5eXqktp9oEuWDVAA6KPs2dpxNhnnEnLMLD1imT2uDf0
GeUaXP8qr90CHOxhKOp0sLZgnMhttiGdTsvNzY1SP7FftgkWZRdPFfQNWS4LbOCTiIg2P4rFYpLP
53Vf2pblrv5zgyu/PfmYdRS51ZUEAczFs4057OgQEdFeAHe99/fk576EcE7Q771eT5LJpCdDZp/h
MkF/2ZoxxAIelqYoIh4A0/f6VnerX0csokU0Src/DCm/t0ysIUCpxWIxSSQSkslktE0lNQffwwal
9fNi8bm49vDwUH788Ud59+6dFItFbTCyLKDyc2pdA+46R5b3fheq6wYRKDfqpUAaCoWCHB0dqfH6
+9//Ln/961+1sPEl5pQ8VWzmyk1d01Hn8PBQ3r17J+/fv5e9vT1V5jiQy7KP7F3rPFiKF+uJoqXJ
geUo2zV3n62lgi0Wn1s2z+dzSafTcnFxIdVqVYP2ra0t5d/3er2VrB2BQrPZlOPjY83gVCoVSaVS
XwADrIn96hdcWWNkg1M/B9b+vrs2FPkDxIRCIclms54uluVyWWq1mlxdXWmWOZFIKIUTqmen01nJ
mt0ntJE+OzuT8XisXeN2dna0ODyRSHyhB9y1c8UNmlzxy1Bb4Oa+v3d/5j5zG2QAIlQqFQ/9kT1O
i3sbgLn66DGCU23HdQwGAzk/P/fUzNoMrJvhe6zc9ffLwJhl62yfjYvi2r+1v2+fHXVlthObiGgX
u1ULuhQ6XS6XUzArm81KuVzWLNjOzo46SlbHudfF/22W2taEcq92zpcFsfzOB7of3QIDh66Y0WhU
zs7O5Pz8XOfq0VENiv0q148sRigUUkR/Op1q7RpAkkt95V6oa8OetVotT9dUG0Cuwt8JBD7X29FS
fmdnR9k7tp7c2joXtIHOuLm5qV1Vm82mXF1daT303t7eszJh1PfRdZT9yTVZH/Hg4ED17cHBgerZ
6+trT3mCe64fYpcecp2uDia7w/gVm/UJBAJa+4cfa1kDNjj+FtT6ryUW3BXxZgBh3xAzzGazB8UO
ru0jWB+NRtLtdqXRaMj19bX6GDAq7vJrf3NBGOIXhFlFJHI3auum8MluUPvkN2n+WwoOMl1YYrGY
/OlPf5L379/rnAo3pf9Qx8saODYWKJobfN2HqltEm0CMQADkhnbqqVRKlSDzor4XsYi8TVlHIhHZ
3t6W9+/fy5/+9Cc5ODiQ3d1dKRQK+rfu4bfOm8htgGtftj7H/g6UQhHxIFxWXCTXBiYEGul0Wg4O
DuTjx4+STCY94AN8+5cIwjY3N6VYLEokEpFKpaKZOj/xC5qWIdqsmy2mveu9eL9QKPTFwEYR0VlR
7NHxeCzValVrLfkbAATowF8zCLu5uZHz83M5Pz+X169fS6FQ0K5jZMNFvDOf7nOq3EDNzYpZoMAN
ICzlG7lP51jxy2AQhGWzWXUQaSjTbrc9QZgfKPQYoasZTAooT/1+X+lGtq4Gp9Eva3if+O3tZb/j
BrzL/sYvCLPZnWXvZwMTuoMShBEkPRW1v0ugpKZSKalUKrK3t6eMgUKhIAcHB3J4eKizEZPJpF7z
XVmwxWKhNclkAyztkoATUJXv+70XP+O5Q5cUET1jUNdo/z8ejz21Sqtu7sV1E4SFw2ENwgBeLOXY
CvdBIBaJROTTp0/aBp0ztmpnfDKZ6NxRaqfJ3hOE2UDY9UWsbaKRjA3CCOSfc/7JBtP90o4mEfnc
Ta9UKkk0GpXDw0P5t3/7Nzk6OtJ1Jggj0LV+1bLreuga27Nra2jZm9Sm5XI5DSqw9dhHZmXC2rDv
Y9fge/FxVyl+mUn7AljBH7GA7l3vyVfLTIFNRB8EO8ePhnW/2Rb17sEkeqWDFR0B4b5aJ9YPZfcz
LPF4XIrFoh5yGhnQ2vl72aBuS1OMzmAw8BRa32c87/u564hZ/r3Il4fWXe/7ggT+TZMBugmCKMCh
dQcLfu3ngAG2U9ZxzPb29uTdu3dycHAgxWJRW/276+JmGm2nNPe+MN52hhV0NzobTiYTNbh2YKDf
2rsUMowE9TUWrQW93djYeJDSuE+4P5w80vL3IYX2vLvKk/d1M2C8n9vowTqifk6oex0W3eK96epH
g4ZMJqOdqBhKTrfFl96noPhc383NjbZqxvmzP3fX9SFBgPt9935YI7u2NsNgs/Cu/nBRWHutVrfQ
pa3b7Wom8uPHj1Kr1TzP1i2Ef4p0u13NuN3c3EixWJTd3V0plUpKLS4UCrJYLDR7DH3lMeKuvUWg
7fNyM142yLI62b1f92/ZC1ZXYxts7RtZfRz7+XwuvV7Pk2lchXBtDLGndCCdTmt9EJ1lt7e3dTSF
X5aK+wIldkK/AAAgAElEQVTosQO/7X2LiHZ5tN0P7f6xDQ+W0UutWDpdv9+Xq6srDSgA0diXq1w/
9optf00Zhsv+WQZk4S+0Wi0dV2HBaHdu4nOvn/Wlmyt7TES07bwFN9x9Dx2YLqt0vc5ms9qmno66
TxWCdxpZWL0UDAYVkLNdI0W8dGgCXPcsL5P7QDH7e4gtPUCfsq5kugACCFhbrZZ2PgVEgLbItX+v
szBXITaRQAfZdDqtJQgESdTKW/GLHaxPgj82GAy0AyKzXHd3d3VPksEmAF4m320Q5jqWi8VC+fuZ
TEb29vbkxx9/lNevX2vrzmUIxDLUcbH43LZye3tbbm5uPHO16vX6d7UpbVYK54eWrQy+9aOq3SXu
7/kZe1sUaoMja9z92qG6n8H1gUBQy4LxBU0IBoMagNiW9u57rVr8An5b/5VOp2V/f18ODg7k1avP
M5n29vYUXbTKbNn7+gX2GCEcUL7S+Y33tMEABth1GKyTzGfa5xQMBrU5hkXEcFI2Nzfl/PxcefhP
FasA3Za77tq43/f7/7JsjNtJC0eCPclZsVx6kdv6HveZWyQMhyuRSEggEND5UdVqVccMNJtNffZu
x79VC+ff7pfxeCy9Xk+7JOIUPMSh9JNlqCHr4WbE2auj0UjRRVt8jpNHAb3VHfw+VF/WjaHPtVpN
fv75Z/nll1/k5OREa0fRIW5b8qcIw0zJBtE199///d892ZDFYiFnZ2c6/8/W3vrt6/vWGMCFTK7N
tlkdbjO+NmNon4X7vP3+hnOwsbHh0auRSEQzTgRhnU5HgYVVCTqJIIwAjMYX0A9pakRdi9/7iNzW
OtlRFXyG3Rd0gGWwvVvXBxVSRDz1hyJf1trxf+pZe72eBhc4cu6zWJW94swAQhPI2m6o7hq5+5JG
WbVaTUE2MirRaFSm06kGHnzmY8V+9sbGhtJMGarNuRmPxwpy8ncWwAkEAhpkjUYjrcmi83C73ZaT
kxM5OTnxHZz9UMEmcw7tWWQNJpOJZzalHcGxWCy00+EygOSudXqIuPuRdaJBCFQ4ArBarSaXl5cy
GAzUn7KzMvv9vgblNgjjfr8nn/c5slh4Sz5gt7AerAmNue57LysEYe12WxaLhY7LqlQqytYgM8Ye
u0uffrdBmMgtioNDlUqltItZpVJRKo6LILrvIbKcngSKNZ1OtRj/4uJCEabvZWNiTAlEoR+ORiN1
3h96uK2DZZ1bd/4B2RG37bHNODCvCCV2n+BEBYNBRQ92dnbUeWi320qT4OvXaJcs4kWUCcLIgBWL
RTk4OJB3797J0dGRVCoV7dq1LPAkWEYJ2KG5VnEHg0FPQadLQaSgdDKZSCQS0QGklnoIBcc6aC6y
J/J5kGk2m/UEC2RUQdDgSD9VbCBLJ0eXkmnX3P6d5W2zJwnmbKBj6WEitxRIN1hx96VFqf3qmiz4
wLwP6sZAPUOhkIxGI6lWq5LNZnX+Fcr2JYIwzj9rCvXaFgPf3NzcmR1ydaHraPI+fuvv52TQXRPD
Th0VSHEwGFTevX2uXDNZ3Y2NDa1bgFdfr9fl+PhYfv75Z6lWqx5e/UOdnftkMpl46Hvz+VxBORvY
g4bbLrGuk+2HnlqxQRUzfmh9Te3ZMmAgELitabJouB3lwO+B3tsZalbnUgdkHTBb59hsNqVara4s
CLN0uFgspk0ueFErClUZCtqy7Bc2DwCS+WaceVu72+/3pdVqyWAw0KHXAIrYn8lk4mmywHpasMEF
Em3jDjcTtuw5PkfQPYAP3INf9sIFtix6D9WWLKidGWr351PEPY826LazsrA1tuOj33tx9rge21iE
ABu63XOE++a58RnsV9aH+rFOp+M5X9Fo1NPE7S69+9jrsv92AXL8QLI6dBfu9/vSaDRExGt/Nzc3
pdlsevYO7CoXWPse/N3nCutkfVX8B7+M72POLODjeDz2NPApFApSqVTk6upK7ZmdD7dMvusgDK4r
6ff9/X158+aNvH37Vtt/M5huWb2Mn+BkY9xcRJHBfbFYTBfxe9iYpOW3t7elVCopSm+dJetU+Il1
rkBk4YXb6d+tVks7kkErAEGwGRfWCWqHS9Xxy2rwvWg0qrUAbGSGDvJi7b/G+ruGnJQ/xeJHR0dy
eHgolUpFksmkJ+PkGj2cBmqt7JBaO+/IFkfzQsljpKyTRYcmAkAyi4VCQeex8Lt+6C5ccoKW2Wwm
FxcXityQbXuukxsKhSSfz8vr169ld3dXYrGYh/JiAx6E/Wg7D0KzgBJii4zRD7ahCcYFA8PYADtY
OBqN6n2yRqyP3QsUP1snOZFIqMLd29vT4eRQmV+ivgIJBj8Pqs3n81KpVKRUKkmxWJStrS2lZoFu
3/f8bGaFe+90OupkILSFJnNj7w3HhBk0NAhgIHAwGFQE2zpQGCd0yGKx0EYnfM50OpVGo6Gt6G1m
xzqLz1lndBnO/2LxmXb45z//WfcUe8A2E7DyUOQbqjWNP87OzjSbQidTAnnWmTrFRCKhe986yXbv
o/ep7xqPx55mEtgHdA/g3XQ6lV9//VU+fvyo7f97vd5KgC8LZqHfAbQqlYocHBxIqVSSTCbjoQW5
+h47DQWIRkJQr7hf6NzoFYI1aNzUathmIDS2IBgmS+eOeuC5o6/7/b6i6nYOKU7fKs+/rXefTqfS
arXk5OREFouFHBwcqK26S1hTdEilUpHhcChXV1cKglgQ5rliQd5utysXFxf62egsgmI/fyUSiSh9
jGwnc7HI9LC/niroeHwX2/2YfWL3SLPZVJsDsADwZsGrVYFEIqL2zM2moA+5DoIt2z0SJge0u9PT
U/UHyNCwDnxdZQb3W4plTHA+tra2pNvtyocPH3Q01Xw+147I9t7ven74VnbP2I7tjLep1+sem7ZM
vssgzDqNgUBAksmk7OzsyKv/o4G9fftW8vm8iIjOcnlIPRRiMwhsPL8gjFqr76VBRzD4ea7F7u6u
tkm1QZibXnYFxUhBqU2r4nxNJhNpNptycnIip6enHl53qVSSUqmkmQ2KfW9ubrQbzF31Ei7FKRqN
SrFYlJubG8lkMlIqlaRarcrp6akanE6n89XWnntieKgNwl6/fq1BmM2+3kVHosYCo8H+otalVqtp
sIkzMRgM9NkEg0ENbO31gCLzvWw2K7PZTGm5XFMsFtN6B9YQZ8NmecPhsIzHY23NDdr6HGEWDUFY
NBrVLo98rrtu0NFomQzdjuHJtpCcvYoxp9A7FAppTdF8PpeDgwM5ODhQytXW1pYnE4mytsKzZS9b
hz+RSGh3Qjp60nyGYOG56OwywekrlUqys7Mj5XJZCoWCBmEMN36IoAcQqGjn5+ea2QoGgzpTDWMy
mUw8mTSoOdBk4/G4nJ2dydnZmQQCAdnb25O9vT1JJpPaoc1mY0AVGVch8pkmFo1GpdFoeOp9bABm
g8Gn6geAFJyuxWIhFxcXMp/PNZuSz+dlf39ftre3fYOwhwpZw0ajIR8+fJCffvpJms2mbG9vy/b2
tlLrut2uAg3Q7iuViq6z7XIGqEBWIRQKSafTkXq9LsPhUOmTIrfBNIF2t9tVncMYBs7MqgIwnGSX
Qgf7gZpagjBr9/0ygf1+X2q1ms5FAqSbTCYKGlLThtPKmUT3Qhui+QsONnq/Uql4ak5t9klEtA6U
M0KTIxfsspnj59qvVCrlabENDWowGEgkEpFSqfSo50In6X6/L7/++qvqv1UGYSK3tY9kfWezmYJX
qVRKaYt+WWTO33w+l1qtJvV6XS4vL+X8/Fyurq5kOBz66u7HiAXayHpR7mIBg0KhoI2m2u22AifY
NJtZsQE7n/FUsaAioIkNpsmQQim1A7sZcM9oBXSvzZT3+33P570Eg+NbCXuDRkDpdNoThBF8A7jj
07mZURH/LK9t7GeDMEoVoNQz/ueutf3ugjBXcWEkGcQMKnRX+v8uaohLqyEjYIM9KIn1et3TUWmV
FIOnCIYBhUzmwE152iyDvWaXujSdTqXZbMovv/wiHz9+VMSl0+lItVqVarWqMxZoYFIoFBRZAdXa
3t6W2ezzQEir1Cw/36LeZJBAJjOZjF5jr9dTBfyY7OZTxKbh3eC7XC5LpVKRo6MjefPmjRwdHUmp
VJJkMqmFuC5lAGVMLUKv11OHtNfrqfPUaDSkVqtJs9lUh4isGJkUSz+znXygDFarVVUk6XRa2u22
NBoNdRQZllksFj2IozWMzGprNBqeLI5fXeVjhOu3e82m/5cBBbbLEA5/vV6Xjx8/yocPH1ShsecJ
6ghG2XesPxScWq2ms2kwsJlMRkEL9pl735Z+yDNOJpP6rMly2jlrZIcsPXhVyDjXyPVgnMmgsCbL
MuJu0AINlkCIOizqYReLhaLQOFI2COOZuVmbarWqwQzNAKgBikQintoK6rFsbQ/6haCEGkX2B4GI
vZenyGQy0bOyWHyuu7y6upLBYCA7Ozuys7Ojc6xoguDSfJcJz5ysrG00UqvVNLhlHwE4kNUZjUaS
TCal0+loUxKXrmsb/bA3ACAmk4kOJBURHXJLNokMJpkzruG5a4oQwNjussViUV6/fi1v3ryRvb09
TxMO67iiO66vr/VaG42G2qTj42M5Pj6WVqul+oVMKiCW2wCJZ8U5JZjCOeO8NBoNabfbsr29rcG5
bYQE/bHVakmn09Gsr1+DnFUJ2T0AKvSdpa8zD8qvSyx7g4CS9XEDiFU05HDp4WTnbfdAvyDbfQ8/
OroNEMn2rOJ6/bKXVnejd/r9vjZs4mX7ERDwWwDClnI8VvCDsUP831KSRUQZMbZ2n2ALlgL3wNqR
ybH22QXJf8ti/V3WwvpLDGf2u9e7zi5rH4lE9FnD3LDglV1Ll3XiyncXhLkSDAY9bWExmBapcrNg
9oaXHXK+Z7unZLNZ2dzclEajIScnJxKLxXR2in0/3uNbiM1mUasASkIwydpY59ENwlBq9Xpd/ud/
/kf+8z//UxXxaDTS4IB7BulOpVJabLu9va2DY209DPNeLN/bOrisIbzmRCKhXZAsBeQlAzCuyQar
1IBlMhnZ39+X9+/fy9u3b+Xo6EiOjo7UIFux+wHHsl6vy8XFhVxcXMjJyYmcnZ1Js9lUR7nT6Xja
bVvnGYNr3z8QCOjvDIfDL54x2YcPHz4oPzyVSsmbN290X+NI2ODm9PRUaUhkQm291FMFwwWHHsfS
OijuuSSwIQjjfpvNpvz973+X//qv//qi1S50DNB2aAWs03Q6laurKwmFPrdI3tvb07la1NfgKNpA
zAYptuslQRjNODqdjjQaDaVKEhS1Wq0v1nAV2QV7hieTiQbk8Xhc2+vbWk7r+LjC/uH9aMn/t7/9
TY6Pj3Uv4qCznpYVYIPCeDwug8FAEomEZgroPHZxcaGUcgYFQ9XtdDr6u7bdcyh0O2PFOtS20ctz
dXCv11NHiXONo8VoArKNjAFhze46H1ZH022UIOLy8lI7l00mE6XW8exwtPv9voTDYa2Ns0g3+4Cs
lm32g25fLBaK7BMMc36sA44jz9+sCiywM5b4WiqV5IcffpB3795pFsqvCQfPeTgc6kgGwKzz83MN
xqBNujTm+4KJ+XyuexVQjf11dXUlV1dXWvNL8wvOPBm3VqulLIZqtSqdTkeztqumdDE6gACMrC1g
IDXENph1gQLOFXPNCFptptkNQh5zDy74DbAzHA61rop1JHNrbbz7WTi2doi0zUCIiLYWf6pwRm0A
CzWTMg30AQAG+7lYLGpSgGCQ2nyuCeD0OawS6OUAZly3iBc8to2oAMSDwc9Nh5irho23gLOfXv89
CP6EyC3YSOJgb29PCoWCZsAfWsdpA2DAbtu/AP1jGTYP8aO+2yDMKg9QVoua2c5aLKI1Im6Wws8Z
sU4NVL9MJiOfPn1SmkK3212alvwWwiHDaFvDikEimOG+3YgcJxk08OPHj/Lf//3f+vc2Zc3vE/2D
aJZKJen1erK5uan0IdAAWjvbaxb5cp4QKDRtn12n/KWVAteDQSCLl81mZXd3V96/fy/v3r2T3d1d
2dnZ8dSAufdG8Nput6VarcqHDx/kw4cPcnp6KmdnZ1rfYhFpy8m272lRLkvBIsOBo83fRiIRubi4
kGw2q7QvWmtvbW3pM4GCgmP866+/ys8//+wJwnjP5wqOH8G820ba71mz98jsQDM6Pj6Wv/zlL7rH
3X0RCHwukC6Xy9rAAQMO2s9+xbG3WTmy7ZYSxfu6BpTsrYhoLZilIVL8zP7m/lbVXMYizGQxAGFw
qglm/FgBfgg0Di/g088//6yUQVuzaJt08B5kOuLxuAyHQ89sFFsHicMLAhkIBLQRRLfb9QXTLAXx
JXQBnddisZieX9oO/9M//ZO2I89kMpoBXVb34ce4mM/nGpTXajWpVqtyfn4uzWZT9TZBLvdK4Nvr
9WSxWHjQ21Qq5ZkHRSc0aIQ262HrnDlXdxWHr1LcIIyMUqlUkqOjI3n9+rWnjsm12TYLdnFxIf/7
v/8rHz9+VF1KFpGMM/fu2gw/Ngh2r9PpeJp1sD42wNrZ2ZFKpaK1jpaeS/MY+wwIGPwyPs8R3pfG
GuhpygI4835NLrgOm5khM4tetoGr1RnPCSbJApNdjcViGrAQeN/loLpgMfrTMoFsl9KnCkEY52Vj
Y0ODWnudfA8ghgALVhZZULuWUN2eInYP2Zpne91WD2Gr0Mc3NzcKgKIPrJ9oGSCs9e9JrE4gO2g7
wqZSKU9THStWZ7iBGQEW+wBmAVl4O5JnGePHle8yCLMXT6DFBkskEjrbhIBs2WHG+eFhgHZY5WKL
7znsOOLZbFY6nY5vA4avLTz06XQq3W5XmwO4a2AjcFeZWmQfbrnltqPgUSgumoajaZ0manzK5bJm
IuAfLxPbpQbUCEQWx5Jp7yial3DC7HujNFOplFIst7e3JZ/Pf+Gc87fWsZ5MJnJ1dSXHx8fy6dMn
+fTpkxwfH6uTCVoC8sR9LwvwXboVWRaUppv67na76tTFYjFFTcnsYjCo/6tWq3qdDMDEYD53j4N4
zmYz6Xa7agyGw6Hy6C2V2Ab6BPCNRkMdeZ6Npai4Cg50l/VwUX46RtkamGKxKNlsVusU9vf3JZlM
3kkh4TMjkYiUy2XNEs9mnzt7uuMy7PU+Zw9zvkE2oWhTj2IzyO75v+s+aBTTarVkNptpsAQKbBuh
WP2HTnWLxW0rZwsMQSm02TnbZcyeB2vwvgY6y5pZaiZBrXVO3SD0LieS58+ZJDv+6dMn1Xs4fGTJ
LcOBs2j3MF3l+HzOh4uQW+oie9B9dlyjlVWutc2Qbm9vawaa2kybceazObPcf7/fl2q1Kj///LN8
+vRJaYB2YPd91+wGeOhtq1ctLbfRaOgz4BlRdy4icnFxIefn59pAytIRbXOGVa6nBU45bxaYJkjE
5trnbIFXrgcdYrN39ucWvH2ouHbM6udkMqnNrSqViuTzec1ALnsv9D3nkn0eCoW0Bve562uBP5uZ
w+ekFGM6narvSZOcT58+yXA4VIYWlEFrpwiSVyHuWYUJ0e12df/FYjF5+/atpFIpOT8/l9PTU82S
A94BsNtGYKsCCL9H4XnGYjEJBD53gj0/P9eGUfRWsL9/3/tZNkqz2ZSzszOpVquqE5rNpqcZ2337
9LsLwuwhtoXHHAiCMFpH+xXV28yPNZw29cjv8h4o/+l0qpS0XC4nl5eXX2RwvoXgWBGEDQYDmc/n
ev0oPRwKdzNZ+poNwmgYkUwmlS8P0uY6G5aiJHKLxtB2HYf2riDMKj4bILOpbRA2Go08tTWrXnv7
3qAbzK6hA2Uul7szCOOaCML+/ve/y8ePH5U647bbtw0J/AIwP0RXRDxooLsWIIb9fl8LzNvttu73
Wq2m2UYoNHSauri48FBakecEYgyvJgijpggKEEafPWsDlXg8LqFQSPr9viKp8/lcRzLYAMw6mHzW
YDDQ9bFo2GQy0eCTIIwZSblcTiaTiYdq6Ncx0QoF8ZlMRubzzx3AqtWqZ5gvCnsVhtgNwlKplMzn
8y+GzS6jaCOuc0VNEvVJdAKs1WrqWLKWXId1Mm0Gh7k0ftkJHCm7Fq7D+lIZr7vE6kyrh/yCMBwZ
C2gty4ZxnxTAQ1s7Pj7WrmU2CIMSbx1nrk9ElF7kZgrtWRK5m4rvBj78zqrXnM/d2NjQIIyGRtht
PtfqABuAkZW8vLyUX375RY6Pj5VFYAN8v8+24upSCybYTooI9o2ANx6Py3Q6Vcf/5OREPn78KFdX
V1oXZrvjvQRwYNkQoOx+QZibxRe53SN2rWBsQGX1oyM+JQDj3+4rkUhIuVyWg4MDqVQqUigUPDXj
fu9jM16wKmAsoaNXoVf9qKu2+yGUXuwE++HTp0/qn7BPsHus3UPpaA8Vuz7YAcDK4XAosVhM51le
X1/Lhw8flKnhvtxmR79XIQjDh6NT5x/+8AfJ5XJSLpcfTBd1M+owdc7OzuT09FTLTH7zQRgXTOYL
pyCRSGhNErUFfkbQLhBBBQqGuhhaU+O8WDpjIBDQ1DnDI5nS/i25s3BQF4uFziVaLBZ6P7bd9jIH
2ipGizxa5wcEc1kwIPJlkw8MIs/svoYargKFtkPHLkuReEk03L5vIPB5ZpzthkYxvh9ixxpw/9AQ
6dx1eXkpV1dX+nNLHbVr6+fE+d2vn6J0EU+UK59xeXkpm5ub0mq1dO9TR0JzkFar5Slkd9/7KWJH
RtgMwjLHyf4dzhsUEGib1hm262URbrIYfgLtBE489WYYrkwmI5VKRbsp+YE7ds+CyOIM0ZTCztxx
r/E5QgaJrJKdD2jpMbad/jJZBtBYlM9mW92A13Lore7kPLhBhM12umfOOsHWKUfsOXmJYIFgCh1K
7QDdXl096EfzvEvoaGrZG+w/jLR1lJc5RH50obvWb9k68nf2Hla9toFAQFt9p9NpyWazmv3Asfa7
HvYe7cg/ffqkNat0QrTZ1adc87LzaPcpIOTFxYV2ACYIOz09VUopVKSXFkuBtaN1bGBylyOJ3kCf
2rETi8XiC9DG0uHd/f+QNWdv2fbp6Ejque57Hwsa2+dCh8/nNLywYoF+kdsxKegFavC2trakXC5L
JpNRurDVs7bxidUVz7GjIv4ArYh4KOk0iMJPgTVDbamtobYU/JfUrd+TQI229FIaRjUajS9GL1nx
A61EbkF4u6b4v8QV9vfvvL4V3edKZbFYaNMGDFg+n5dsNqvOjm29bY0Qh4ioFGVN1ssGdnYuiXX+
QCrtADac2edMaH+OMO8lELht0mDvCYfwIYqJ9+F3oQGSWbMBlnWeUM6W60+jDtroLhMXJaZLk8jt
BHI6U+EooxxeWkHwWbFYTNvRl0olT+HmMrFI98XFhRwfH8vp6ak0m01ptVpf1HQtM2qruEf7vrPZ
TDqdjgQCAQ3C4K7zvC1IsUpxnVvb2YmfWVowe5G/wRHFkNhrtevlBmSu4+l3XYAY8/nnxgZkP3d2
dmR/f18RM+hHXO+ybDhIG0go9SXoCXTSc58vZ2uxuG0Aw4uOXel0+tEz3qiJSqVSapxAx3GWLWgz
m808zxVnyNapAu6gx9HTfkEYX10QiIyaX/C9KuGz7CwZ1oFRHHafWUfVL9No7RD/h6oUCAR0P9OM
xI6EcDOOd4ldN1s7yj25TjXBsaXFPtc5vEuo4wbcoP7C7YLoJ1AC//rXv8qf//xn+fvf/671X341
gk/dF8vuH4dqNBopS4BmDIFAQLt4AhR+DQeW+6UBUTAY1CxhsVj8otbPro2lfDOOxtI5eU/bURWA
2nXeXR27DKAVuaUUkkmCITCfz7UEgrNn/9bubat7g8HPg8ZrtZqcn5/f23joIYIvY7ueol8tPX46
nUosFpPd3V2pVCpaF0hiwO3Wjdxnj54i6AjrU9BZFTtDLSX71B1jgS6HmnhfC/Xfmrj7k31mGW7D
4VD+9re/yXA4lFevXnlo/Q95ZjxbQNvJZKIZ03a7rQDOQ8ppvqsgzF4sKV6yUcw7IAgT8S+GhvZC
G2+cCaJUGhVYp4bPBmUCCWXWwmg0ksVioa2vv4UwTNR2QAMFx4m4KwhyN5atHSFwFRF14nAibd0W
Ctqdi0AQhqG6Tyx1SuS2lqTVamlnvK9h3KxR2djYkEQiIdvb2/Lq1SspFotKL7hLptOp9Ho9Lbyn
eJyCe5H7ay9WFYDxlXNAe28cZp5tIBBQ2s+yrmjPuSa7ppYybIurXSSOvWAVKAEBjToe46C692AN
IuihDb4PDw/l9PRU0VpmSFlHnfe0OkPktq4UipmlDa0KRCDDRjYVyhZ1gnz+XWvgJzhh1MKxLxaL
hTo5OHEYb7KAOFYEEVDmMOo4jhgjq0vcZ8I6WWTaruFD7uWxwj4EyMpkMtpEYnt729MJlWu7qwbZ
CtcKc2NjY0OpufP5XGub5vO5RKNRTyaItVkmfhkLsh3QuKxz6wZ4fuj6qtYWx5nsByMh3HlaLoBi
r6XRaMhPP/0k//mf/6mjPADmrKx6P9jr4GxdXl56RlVY9oi955e0VZwlzl0oFJLRaKRUNL8sqZuN
4Z5skyScSAINShPwJ2xjDBHxUMHvAkjR6e5AW3TjcDj0NK24C0zj+gGIms2mOriPBZxc4RqpFwLc
JjgJBAJqf+iIeHBwoDXP2Al8L6sbXgLksAEYe8KWcVBWQCaZURVWx6HT7EgjW2v4Wxe/dbeAAPPf
RqOR/Pzzz0rjpPHaQwJnCxSwB3gOk8lEqtWqgk4wcO6S7yIIs84OX8vlss5oomAeqs0ymUwm0u/3
5fLyUv7yl7/IX/7yFwmFQpoKh1q4tbXlaYnsHhwGohKYYByZB2SDoK8l7Xbbc429Xk9OT08llUrJ
5uamttxcVgtihWwfhYn7+/ue7n0452RMBoOB0nSgmJCdLJVKOlC0UCgoMuQinhaVZT1t3YVL24Nq
4abOVy3BYFDREVqXoliXobZcC6getR6NRkMd0GV7Y5X34Idoo5hFbhFwGmHYvQFld9VOmIhobRr7
BWXEZw4AACAASURBVNS/1WpJoVC409HkWugIx6DJSCTiaVW+bD3u+56f83d9fS3n5+fy5z//Wbn2
tAi3YwuYueQ6XdFoVAqFguzs7EipVJJCoSCtVsszYPO5wowXst+LxedmLGdnZ7K7uyvValUDI5wK
7vEufYCBjkajsr29LW/evJFg8LYLnKV50lENhgI6ORwOa+MIOiNSU8N8RxpMYKjG4/EXWVGb/WLf
8kLnWn3wHFqavX8GtFIDyss2D8BpfSwFyuq3ra0tKRQKui/QMaFQSGvGGo2GJ7inoY5t12+zWiK3
gQ9OJRlK2w3NOm9udsPS/J67Vwmit7a2JJFISDab1cYctPnnmhGo1ICc2CDsw0PO9WPFBVLuE9bG
b41eGiy0n0Nzm3w+LwcHBxKPx7VJA/rKT+gKZ53vTCYj/X5fut2u/Prrr5otY94ie4TuqeggN2Nm
s1U4sQSugOJQ+NBfIl6apYgXgOO829p3wAXOIJnIpwp6DbDU6hMYE41GQ+bzufzP//yPbGxsyNnZ
mSewtH7rS2aXEfwOkhS5XE7/TcDIUOnz83NdbzJgPHvuE9CG7/3WgzE3myryGXSt1+vaxXt3d1dB
THx/dOJDmWTYYDqsUkZDd+S9vT3dL2dnZ3d2pv0ugjB7aDlspVJJ3r9/L3/4wx90qCObaZmQlahW
q/LXv/5V/uM//kOi0ajs7OzI7u6u3NzcSDgclmQyqcrIzgdCaKcrchuA0RUQnq1bEP3SihhqGYqv
3+/L2dmZBINBKRQK8vr1a8nn81/cixWLLpFZIwiDZtFqtTwDL4PB29amlh4Kz58gbGdnR+dmoJCX
OYA4ZDYIs46X7dDI3liFg+AnBOl7e3uyu7urQdh9nY1QhtBCTk5OtMB+2bW+xPUvywazb11kxwbD
d9WgPEcIYMgq2CAMKqAVNxuC0XWDMBG5F1VatsZ3obY3NzdycXEhs9lMuzhOJhOlGBYKBdnc3JRM
JuOL4sdiMaUt01HTIqqrEIIWuO2LxUI6nY6cnZ3JxcWFXF5eSiqVknw+r9RlNxPoJzhT0WhUisWi
HB0dydbWltYOch+DwUBnWmH8mdvInEBqE2jzHY1G5fXr13J0dOTpeEfHTBBK+6LBDA0YCNzo8mXr
X1YBhFnqXKlUkt3dXSmXy566YbJMLi31IQLYQRCWz+f1/6lUSgO+09NT+X//7/95nGhGTWQyGdXP
dragzWzZ68Wm0RAIahW63NW7li4q8jw9RebTDcJ2d3c9Qa3NsLpBWL/f/6Iu+KVk2Xu72UJLi30p
QPAusZnSzc1NyeVysr+/7wnCbGMhV7a2tiSbzeqzDoVCks/nZTwea6DTbrdlsVhIPB6XZDKp70ML
d1gT+Gq2DhUKLOfTZgY49wSKlslk96YV9AkAsBuEsRbPeQ4wCwg83OfK8yZzh8/1+vVref36tYh4
6dMvLdY+EnjBgshmswrU0B0xnU4rc4HnbrPi6FN8Hbcr9m9VbDaV5zeZTKRUKimttNls6l62Gcb7
7p01A3wA9KSLar1e1yCMOKNarX7/QZgNwKDIbW1taUcaeOXRaPTOrmWg2NVqVU5OTuSXX37xDDbE
ebCDhf0QMdKWULo6nY7SKhKJhDolVl6akkA2g/oNHB8bNC0zDq5SxpkTEcnlcrKzsyP9fl/q9bps
bW1pE5LJZOIZDmkpoel0WvL5vDotBGD3Fd6iPEHXmKHTbDa1lTlpdbdZxKoFBUq2gyYcy1LSGOLp
dKp0lXq9LmdnZ3J8fCz1el2Gw+GLX/ddYveA5SN/TcUKQsk5tm2GH9oAhDQ/5x7K20ugjQRfi8XC
M5Q8k8nIzc2NxGKxL5SoPe/UlRUKBdnd3ZWjoyNFHW3Xu+eIpQFmMhmtY8CJAiBKpVKPWiNbgJ7P
52U6nUoikfAU78MwKBaLUqvVJBaLeepALR2RAd2dTkei0agcHR3Jq1evdC0orGecgJ33CLh0dXWl
A4x5326368mIW4DhqWuL8cXhoz4rnU57EH2LcrvP8r615jMCgYA+O/bS9fW1lMtlTxfWXC6n75tI
JLQFdrPZ1CHYBFLWiXWzINC+oIjaYe2WysraQl229XxPEYJp7AZnGNtgQdRAIKCAHHW1tH+3Ld+/
tVia4rcQ2+gItJ69QcBD8yJX2J/4P4FAQPVwPB5XoIiz3m63NaNOlpZmKdTYi4jWodpZS9TzWhtJ
G3eyENFoVH//PlYTgFgwGNSyh0KhoOeg1+s9e3/w9+gft1mbyGfdW6vVdIBzPB6Xw8ND1Q9k8h9C
ZXuO2M/gc20jEIT6VurALWvAAgkij88I/1YE/4NyG/zZxWKhjTrI+N5VxnOfWFBwMplIt9vVch23
G/sy+W6CMJAOuuDYwbYcQoy+zUCJ3G4k0sdXV1c6fHZjY0MpMtAJMTLLFsjWj8H3tUMn4U5/TWF9
QNyhHj5EofkJ0XwymZRSqSQ3NzeSSCQkFotJu91W+kG5XFajSgYMigytZ2lLv6yLoP0KRe7m5kba
7bYcHx/rYOOzszNtjU0h9ksW5lvDQf0Re4W1tQJaOxgMlF5xenoqJycncnJyIrVaTVuT2rT+tzLe
d6G8L31NZBh3d3elWCxKLBa797pEblt7k0mDf28N3arFOtjsT1tzeRfSiR4heDs4OJA//vGPWk9A
wfQq9nAoFJJMJiOHh4c6kBOjQjbhsU1WyEaJiLa95yuBM86URbPtAFv2k3XAJpOJZg9p4w/4YumI
tiFLKBSSq6sr+fnnnz1zuwaDgTSbTQmHw6qX7OyypwrG+fLyUp9jKpWScrmsoCBG1nZje4jjYlkH
tksc103TD2YrplIpKRQK8s///M+6z7E7kUhEZwLZzKoN8LhGdBR0PmYcpVIpicfjGny1220Ndplv
g973y1Y/VHBmcUSwT34BM7Qzamo/ffqk7ejtAGprQ1atu5Y9w/vAzK+hQxEcOtv+nGwj1/KQEgTb
cj0ajYrI5zMQi8Xkxx9/lGKx6BmATWBP4DYej7UcYz6f60xBnH18LQI63oeykp2dHXV8+ZtllHSa
q1HTXCwWZX9/X0dpnJ6eapbsqYLuI0BNJpPKuCJ44b5vbj4PP45EIjIYDDy66ykZ8qcKdhDGDVlG
gGv6ITAOJBAIqD622UPXf76L5v9bFPt8EMZPQPlOJpOSzWa1AdtDSnlEbunT6FfsFEBjv9+XxWLh
mb95l3w3QRiHkkAJo08QRnGvVcruglGsenV1pRPsQ6GQ570sz3wZesH1RKNRRRBpuWvbQH9NwSAX
i0V59eqVRCIRzwylhxYVini71xFIcX80JYEWAu2QjGQmk9FsJUGc7RBkP8M1uBaRIQj79OmT/PTT
TxqEtdttT/dH/vYlZFkQNhgMJBqNfqGUQGyhbTabTTk9PZXj42M5OTnRNbsr9fy1xV07y5d+SSfC
BmHQYFzF75eh5W9tEOYWPb+U+AVhtmbJXqelJWGECcKgQJyfnysV4TnZBWRjY0Oy2awcHh5KOBzW
InvbDOSxhtQaq3Q6ra24QYXtjDvAExx+UEbbEALdaIMznrWlKfPZfJ+vnz59kkAgoKilyC29ld9f
FW0GwO/y8lJarZZsbm7K3t6eFmvjJLqNWdgXD1lb9g/6ezabab3jxsaG1tdaWrzV4zhHPAf7bNw9
GAh8Hkbabrel2+3qtUJrzGazqt8uLy/lw4cP8vHjR4nH48pCoXHIU51bG4QB1rnzkuzZd4Own376
Sc7Pz6XT6fg6hl8jAHvM33+NQCwWiykYxNrRUMeOkrhLbKBAIGZLBorFos5LBWCEamUzrABL4/H4
iyAsFApJvV6Xer0u4/FYg5mdnR3Z29uTXC7nySy7tsg+D8o/JpOJDtbtdDo6smQ4HMrZ2dlKdCog
BfNBCVLxUdrttrJ1WAMR0WfykgChFasvRcTTGRGqP8ErIBfZZuaTojetPWb9fw9URMT6uMhsNtOM
O0wOgjB8jPueIdloMr3YIgA9W7bU7XZ/G0EYN3Vzc6NBQSaTkf39fXn16pUcHBxIJpPRom03cMKQ
oswtCgNNhlbUGDybFqemwfLpLRqfTqelVCopzRFqAC3WXbTupYTrxfHZ2NiQTCajGaqHdAqyQQ3/
hlsscksxKJfLioDThpUsGQbB0s3ofOQixdZJIMMEotvpdOSXX37R4Is2xNaR/BrZmlDodhQClIll
Qa2lAXB9cN/9qHbfo/gFP6sWlz5jz7XfIG8/YAVqMYMPyX681J7gWfK5tVpNGwngsCxr5CNyW9RN
Viyfz8ubN29kNptJtVqVy8vLZwXnAEIi4qE4UpthG2W412aN7V3iDhoFjBIR7XBoazh4vnwPvejS
9/j5MvqgDdDoULq/v6/f63Q6Hh0ictu19Tm6l1oInFIRkXq9Ln/7298kkUhol0QaITz03Nh7B6zi
3NGsgDWxNTUuDUrkyxlRi8XC45DbujBenDfWBmo/upssHIE1n0vzhudkwnDGoUOOx2P9vt/8SBt4
4ixaRsIqGtvY/SXitUvL3pvgGV3PXrPPw4+m6r7nKvTVdDpVsJDzQ60hLJX7QFCbmY1Go5LNZj36
CP+HTPhoNFLw2T43ao5oLGOZOHwm8/YAZdD7NiPqp5/s/6nFHY1Gsrm56cnIk90tFovPGhkUCoW0
jpYO3NC58UlZcwCqQqEghULBw87wo6uuysYuo8JCfaMrc7Va1ew354cA0zZBsuIyGH4vAZiI16cg
yIrFYhq80zTKzvXye2ZuIsDqdLLFVkcQiME4oITiLtDumwZh1ihfX19rHUg+n5ejoyN5+/atvHnz
RpLJpIiIIq6WV07XQpx70AARUQ58u92W6+trTTcThFleKC+LSIJYzmYzaTQaasRswPa12ntirEkv
BwKfZ9AUi0XJ5XIeatBDxDpboL6Wmki2invlflkfXpau5ToPHIT5fC69Xk8HGNfrdUU+P3z4IKen
p5pCX0XG4KGC40h3tHQ67XGK3LV0qUlWWbtzrL5neelrtLPByJyANNKu248OIXJLR6SjUa1WU5qU
zWCv+j5A/6FqRSIR2dvb0wwG5477sk6Hze6ipPP5vLx//14d8Kurq2dRZzAk0BxALTm/6XTaU5Mp
8nhHAONi/5ZnZUd62PPvZrpcJ8vPMbFG3wbfOIiFQkEdz42NDWk0GtoYhPV0a3qfItS9MKwzFApJ
rVaTxWKhKP94PJZcLue578d8pgWs6EJp18zVn346xwZXfuwCe21kLiyQZevuuI7FYqHZRv6WzMpz
7Jm1i1CkcMzd9bM2hKyM36DZVQBbdm+z/2wnPL9AgIweZ9y2p+e6eSbosIdmph4j4/FYnT70I+tE
zSzjItx78FsH/Bib+bAgKvdq6Xa833Q6lVQq5cmIWz2wsbGh/ppti26d1YeAxTTvIHNLCYClKG5v
bz9rrbFLOzs7ksvllAkEqGr9EYatVyoVKZfLqjvsvb+U+L3/eDyWTqejTcGOj4812wWYQYBO+Yxl
IfDVbdTxexLONTXM0LHPzs609tYCYA/NZqJDQ6GQ9Ho9PQO29syO1bmPNfHNM2Eityg0iMP+/r4c
Hh7K3t6elMvlLzYQf7NYLDxFva1Wy5OyZmFIG9ZqNeXGY2RBFkFvEIweTSkymYwkk0lP0MYG/hpB
GIedw0cbdRzbZQ0llm0qvo8TwKZ6KC/W79oQe9BtnQhF4I1GQy4vLzXFT6ZjWevyl1IOGAhmnhGY
20NpPxtDbjumwQ1+Sj3O71VQOrQYns1mmlXA2UXcZ4sxYKYNRhdE/CmO8H3CPiWYhr4MymodREtP
dANC69yRec/n8xKLxb7QX48VWwvQarW0YQgNEMhW42CLPKxWxIqfnnVBL97Xfl0my+6X63IbIwUC
n5tX5HI5j3MzHo81E2Dbqz/kGu4SdF4sFlNa1fX1tVJI5vO5Zx/YZ/6YrJjfGlq5D0F3kdRlQayI
3FsMzv61+4aaEhtMPFUsWMfLZu7ce7ZnxtZZ0BDmKWKzPrzswGW/JgXumsGQYF4W9VA2QLHZI/wA
uona+3wOvVPE2+iIawLgAiCx3Xz9nr3dJ7bmie/7ZWH9hPWwjXF4hvP5XOvUbLO1pwiZpmAwqHuB
emzqnfDNniP4PjCtaFICmM8a5/N52d/fl/39fS3fYL1xtJcBhKvIirnvh72ixpbMi93bywBy9z1/
rwEY90WjPeywe25cf8QFiP2EvY8+tcwQES9gj45YJt9FECZyG13m83k5PDyUSqUi6XRaETSrUEVu
6T902Lu8vNRXvV7XegkK5wKBgGZjUqmUFItFraliqKzlXIvcGlCCMeZq2RlLHNyXlk6nI8FgUIOw
zc1NnRPiUgYeItybi6beJcsUi59xtf/nIORyOUULhsOhtNttpTmiUL5mipzBvGQRlwnXg/NCUSw1
YC4V8SUyNb8lAQBhcjzNXUAb/RxSjKA1Lhh7P9rZqtfWzgHiOS8WCw3IQBX9rsUqYgsKVatVOT8/
l36/r/rtqcJMk/l8LsPhUIrFog7EBRxi7pSl/z1WXmLP+r2nC3LwfxqcUF/SbDbl7OxMzs/P5eLi
QmtGbebtqWKNKK2zbTdeqNmJRGIljpTI3bWQj71u3s9+381CukEuThvMEZtlth0unxqIQXcsFApy
dHQku7u72l3U2m/Oum1fjh51s1+P0ad2XwCy0VQLJ4zP5sz6Oas2iKAOmAHvlnoLvRRauu1IiWOO
g/zUs0XmjfmlxWJRwSwbPD0GGOCrG8RbAHUZqGuDPetH2GfGddkSkseKq2PRzzRAoOzkqTKbzbTO
i8wW5R7YAbKM5XJZ/vCHP8jR0ZE2chC53cc2EGNtVi1WdzByALpvJBJRf5feCDQxsbVgrv36PdWB
WbF+rcjnTC81YIx3YGYwpQZ3gWX2ueL/o69gzQHo4+/G43HpdrvanGuZfBdBGIc0HA5LLpfTIIxu
iFZpoDhw5geDgQZh1F7UajXpdDpaRwL61ev1JBgMasMAkAOU7TLnEMpPPp+XSqWiQQQb/msIw5pR
bqlUStvMWtToMYrYos0c8GVKxC9Ye0jGioNPEBYMBpU+2mq11IG0M5UspeMls0vU0oEs+okNCO1h
AyW3w61dB+gfVUCC2+22bG5uyuvXrzUIW9Zlzj3XOIWuQ/ZS68qeWxaEQdXyM/o4Iihz226bIMw2
d3iKoGfozBUMBmV3d/eLIExEPGDASzgDjxG/53XXdW1ubkoqlZJYLKZt2VlH1pK5RfdlmO4T16FO
JpNSLBZlZ2dHqetkbx+a/VsmLoDwnIzuQ5+rdYxZJ0v3s5lmQA/27lPZHQCaNgiLx+Na821BVGhT
NIKghuK5jiHn0Y65gPli6YPQ5Nz5ai7C3Wg09Nr5G/t3rN1oNPpi/h33QhbtKUIgAyhggzA3EHvM
GoncshZs8GW/+oGtbuDn7mP7Hs/JCFl/w+4bMqWj0ehZQdjNzY2OxrH3wrODQp/JZKRcLss//dM/
ydu3bzWotjaLAOwhYPZjxe8sMM4C9kAmk9EMXqfTkZubG2k0Gro3yca6JRO/Zz/F1m/S72Bvb08O
Dw9lZ2fHE4TZ2q37/FpbAkXwZgEfssyTyURB0bv06XcRhDFAOZ/PS7FYlFKpJNlsVgvi/Ta12+6Y
g0GbTpceRqqQGV8U32ezWUXFrANtUR46PVGsbYvU+bnLMV+1kM3DyLmzl576mcvS1H5ZKEs/sMXl
dvP6oWQWXVwsFlIqlb6gPDGrBuSAgdg8x5fi2kOVRFGBiru1b/a+4YvbVvQu3eYfWQA1aBhBraXN
btp95xp6UGWMCgWw9nyt8pzZ97FdjqCZss+X1QpyD1ZXUBdD8XwymXzW/uVv7VBUlwJl6zj8wIDH
AgR2nV3qFp9h62T4HasLcG7tGbaZZYs+26AbWmCj0ZBeryciogNkoSg9dx9wdumMOp/PFaBjrUaj
kTSbTQkGg6r/bd3dQ5Bv9/ps7RDrRzBonWrr6PoBEi411ups9znxPeYz4sDybLCJ7XZbOp3Ok/cq
12udZfSrtQ1cG/rUDQqxd48V9lwkEpFSqSQHBweys7Oj42VoHLIsi4QzFQqF9ExRD9TpdDwNcNy1
Hw6H0mw2tVMdnQSHw+GzM7bYfrJ6NMzCiXxMBsbuB86j/TtLr8RphxFk95zdj25QZj/nKfduz4gF
lSzVvdfrPbsUhHPFXuDe3OwofiNgwWg0Uj3A37oNp54jbqBkgQmbtLBjINCZV1dXMhgMJBT63KE4
Go1KsVjUOkuSE4Clv1fgmPsCICGjbet9WdfHlOFgn6CpA9rS5MWuMTrwuw3CLCJFkwnahGYyGQ/v
1v07lDwvNpXt3Y9YGgQRaqvVUqqU5TfbzxARVTzufA2cNFLWfDaf+xIbGk44yPd8Ppdutyv5fN5X
mT5U3KyY5enbn1uHieAPZQWabJFpFBh/BypRLpe1pg1nnW5YtVpNLi4upFqtep7vc5DEZcLcj3Q6
rdQGDpSdvcY9kPnEsNpZUuFw2GO0fm8K7TGCYWAQOK2Jx+Oxp6uUK3bv0Xp3MBhoEOZSK15C2NsW
mRcRbeDid+0WZIAiaOvAXEfpKWL3GetrqU50oqNA/zF6wA3UbHBjgyebKaSOAoees2CbJxGQkglB
ZxI4koXe2NhQII2f0zqeAehbW1tSqVSk0+koNQxK0lPXFX1NdpFB1Xt7exqQNJtNtReVSkV2dnY8
A+kfq28JqCx4SM0bNalkWFhHAgK3cREZGZos2GAYJw0bynMlEzaZTCQQ+Fy0vlgsdH5Op9O5lz5z
n9iAhACGTJjNbPB/GC3dblcH8RK02WzeQ9eXOXZ7e3vyr//6r/Ljjz9qcAVaTf2f+2IeKYPDe72e
5HI57RpZLBalWCxq7SVrzVloNBrSaDR0diQNZp4ThNkAwWb4XGbBY8UGOn5UUVgA1J9a3cKehL1C
9sgPQHhqEMYzscAd9zudTqXb7T57HIwLttvZfBY87PV6cnFxoWdtNptphpxreuhw3scIe8wdXI49
IOtyfX0tzWZTPn78KCcnJ3q+aLkfDoeVLdZqtRTots/qa5SAfE3hOVAiUKvVZD6fa8dN+jzYMRro
yftANfQtfm8sFpNMJiPb29u6Xwh67wMLvlkQZlESlEo2m9UuX3ZOC2KDBGvIbCYMw7xsFhgOXqfT
8dAW/dKRHE4MJBQVW4zL4eXBvOQmxmjmcjlVALTkt87/sg10F13QdbgIKKySIsNhOdkoX5wyiwbZ
AJogDDQPAxIMfu7WxPM7OztTpNs+VxFZWh/0VKFpBFRCt5jc3TuW9+92v7Fd234vSuypgvOXTqcV
UAmFQpqeX7Y+rB+F2LYw2jq+OD4vsc5kRm1LfIuu22tFrL4AVECxW2R1FULtEkGeZQNMJhNPFzpX
3PXyy9BYxww94AJcnOFQKKSdy+zQSgw7XRsDgYAn4LBDhMlOQEnj5+PxWC4vL3V0RSgU0qHPFnh7
rJNuxVLFqOdjrxHgsg8Hg4HE43EpFotfrOFd9BWbmbKBEKATL/aNnU3Ja2Njw9Oe2xacR6NR2djY
+GJwaDD4uXEBehf9TqCDY0Bddbvdlnq9rhTr51DnoOswr6xQKHgCe5sJ4/osWk2ZwEPPuP09ewap
4/m3f/s3tePUakSjUc1WsS/phJnL5SQcDussyGw2qx07K5WKVCoVD+jGOR+NRjr8emNjQx0/G5w8
RdzOhTbws6DJQzIadj9iz6D32utbLBaaObDnjaCdtvGDwUBExAMcEDC6jUvs87orOLM+CXvDHUkB
mPCcFvUit9lkgi8ALmak0W10MplIvV7X37fgvF/t8ioDMUslRNzsJI7/+fm5HB8fS6FQkGKxqMPg
qX9nTXn2dh895sx972L3GPqWBMJ0OpVisSitVkt9aZvVvus9EeuHEB+k02kpFArajZ1AjMz+Mvlm
QRiODc4NCCG8auY1kXkSud2MUCoYTFmv1xU1bbVa0u/3FaGxB5kiOtt9qdlsKnLAUGJXFouFxGIx
bd9+cXEhJycncn19rUGcNS4vlQkJhULqCBQKBZ29ISJ6f5ZG5yeuMgSFZLYEXYFYN6tQUUwitw6M
S1Ui0HJb19rPRNknk0mtGcAIkuFjvlun01EFaYO15ypfhFqlV69eSblcVgQUJWedZ3uwcQZBEcPh
sIf7+4+cDaOJBKABAQmyzFBdX19Lt9uVer0u8/lccrmclMtldWbY4y8NdFjDjGN8F9WEIMDWuCwW
C0mlUpLL5aRWqyk//zmC0c9kMpLNZiWbzWpdI8ErhcHcyzKx+5NzCh2MLBMv2zGS5gS2MYGLgttg
LZ1OayDGWuFUscaBQEBpcJbGcXl5qVlnnGUGpfd6Pc2aPXUvkEWiO+poNJK//vWvCvoEAgHNOOzs
7EihUPDYo/scLevwWqeSrFO73dbgiueLY0XAAPsCJ9g6fGR1AoGAp8NhIBDQ2rp0Oq3ob7/fl9PT
Uzk7O5N2u63P4fT0VE5OTqRWq6lT/tTAtt/vaxYFug/sAmsTELqmVioVyWazmil/KthmAUPmP2az
WQ0OABL5N2ebmk87J5Kzxtf5fK71ZVyjBR0CgYDuI5uNZl7TU4EYAoHRaCQXFxcSiURkOp1Ko9GQ
crkspVJJ693uaixgywjYE2Q+LegKiGYDf7LFtpMoPhRAFcHAbDbTxhHZbFZubm48gKUFdF27gLD/
AWUIiDn78/n8i0HSjxUAFzJf3HcymZREIiHZbFYznzQLmkwmWn8Lk8fWq+EfuBnB54jVmayTu47c
AzrZNhnCvwYst/drg0f2xe9FLHgOYMfMxJubG6nVatrtvFgsLn1O7veDwaBmSrF/m5ubsrW1JYlE
QoLBoLJpHuKnftMgDCeHjQyCRgt2ZkUgICDWKWi329JoNOTq6krb1OMEIWwyMh4YmvF4rEEYC+m2
R0a4znA4LCcnJ1Iul7UDo8tbXiUK4q4Zw0zz+bwnCHM5qlyLu368LLe60+loN51Go6Edd0RuobtG
aQAAIABJREFUaQZMladZiq31QPnysjPLrMPsZsaY2cbQRZxIns3V1ZUaVZQQzsMqgjAUk18QhmF2
f9/elw3CGAxuHYh/VGFGSSAQUCfSFsT7BQAgVt1uV66urjQI6/f7cnV1JZubmx5w4CXF0lO4/rua
anA/UO5wEnDg0U3PbeLDeqbTacnlcsocwJi6NWx3ATF2HTmXIKm1Wk1rM+2MHhpl4GyEw2EPIIRT
QjAnIv+/vfN6biRLrn4C9J4wNGCz2X57drWxUiik//9VLwpJoZ3dnhl2Ny1AeE9P4nvo75c8uF2g
A8gZzVZGMNqQLFTdujfNyZOZrjN0HdXYA75xbVgJoJdabN5sNv3a1DQNc86igrC///3vtr29bevr
65bL5fwdvnv3zp/vPhIGYIpmE4RVq9W+LltaO6UOL3OXzG4cMuZqUo9cr9etXq+bmblDkE6nHbBC
t+/s7NjOzo53Tru4uPDAFvBpmDUlECQIQyfSNIY1wU4ShDUaDQcUqKe8bxaMP7muAigEYVH0OPwO
nNQwu8R+BURQ6lmYfeNP9hHXBMwjY/IYmZub82zo0dGR28F8Pm9//vOfHRzFMY8SdeTJcrfbbatU
KlapVPycJZNJP7PsV5gBx8fHNjc3Z0tLSzY/Px+ZoSIwm5ub86AWf42sIY3OouqoWFN+jiw7AZj6
d2TlHiu8e4JKPnN+ft6Wl5dtbW3NXr58aVtbW74OUJa1FkuzlGb9DX8em/1U0TOPABQQhIVNZubm
5nz4NGuMH6dBGD6MMql+b74L1FYz8/d9cXFhpVLJxzwh9/HdVb8oYDszM+NBGKDXfejyv3omDOee
9CmFhGzuKGqH/hvFCLVleXm5j06jFDNV/Dp0NSx0j6r7AKGkg9bLly/dSalWq8/iHOpzEwRoAwHl
3Zt9P79Lfx/DX61W7eDgwPL5vCtkitRBWzm4KHsMpQ5y5memp6ctk8n4NHIUtdIV1ODBrUfJ8EyJ
RMI3dDKZtE6n00cbDFGcx4g6qiFKGKWMFGFdWlqylZUVazabbhyGzXT8XoS1PD099WYrdGBTQ4Vo
EKONCthPijqP2kBEnXNFae8q2I3SSfp3UDil1Q4j6tSzblofi5OlTultogaeou7Dw0MPEsiwdDod
D4S0iU21Wo0MwlqtlqPVZBO1pkSdYbLejUbD9ZJ+kV0Mu5EOK4osU+PSbDZ9IC21ylDkFekPg9xw
HwDUhM2izs/PnbJWrVY92IX6qLV12LS5uTnPyitAiNN1fX3t70YzYQRwAG3UQRcKBWu1Wq7vyDTq
PLTHChT1qBET4bV7vZ6Pf1leXu4bAUMt3mMyYdiH6+tvHWzr9XrfOioQCbiCnQmBSvyG2/QA/681
fLrH1d49RtgPjOMhiGGNNRAKhf/jGjS0IAArFApWLBY90wzQMzs7689Fx9d2u+31dhpU6xoAKszN
zfnncFa477m5uYHPGqW30FG8E3TzMFkw1oZrhwET9wHrCuol+1WZXOyREFzSDOEwEhWsmlmfXSEZ
QEAAuAIjIZlMWqvV6qut15rLp6yz/rVEwUZtbIVfQebwtnpt9qGCagCQgA7Yxlar5SyShzTpe/Yg
jIdiY01OTloqlbKtrS17//69bW1t2fr6uqNi4e9qEwiMVDqdtlwu545bKpXyjQklgQzL+fm5d2PU
tsQEDefn531F0SocqlQqZW/evPH2+IVCwQ/sU2ZBrq+v+146CEg6nfbP5vNDZRYawW63a81m0w4P
D+3Lly+OjlIYjcOgvOjQkFD3QbcmOja9efPGETUcC5RvlDLhvZqZt7GnfSiGA/rp5eWl74thBnqa
3WQMu92ulUolDzCXlpYiMwlkRxYXFy2Xy/UhyaVSyZ3s31NK/zHCujabTdvf3/dswtramhtvdcI1
AMaIUKdAcEZ92KjXNgwI0Ctk724zUGFGjwAO7j1nbBRZGz4PahAOzsLCgjvQ6viGzxX13GSYCbLI
lpRKJZ/LBUKutVwER4A5tVrNAwJqYzBEStcIB/miY8mcQIUO65vCurRRNeg5Pj72omreMZ/DbCCy
YYnEzZBfgof7dENrt9tWKpWs2Wy6g8q7q9VqVigULJ/P9wWf0EAx9gp2heAXoJs2NgHswFZqp0I+
WwMufl4d9sdK2CCEz6b5SEhJZB9CCXr9+rWvQavVuvPz1Nbp9SYmJrzGmI6XL1686GM3oF/0nPD3
KAcqtKH6/VCX6XUBSh6bCaMmkutRx8IYH/TUIB2lZwiGic7eKxaLfVkyDUJpREFWmjoYgir2I4GR
MlrwLbLZbB8wq4GLivosnH11ngE/CTiG7YzIuQHQJvBkvzabTbu+/tb8DBtElkyDdM3u6xfndxgB
UCHIQ9CXZLGr1arvk6mpKQ8IyIpPTk76O9RGSiGo93sRDb5CNhZU7dXVVVtbW7sVFIi6ppn5/m21
WlYul61YLHpDuVar5SDZffboswZhqug0CEun07a1tWXv3r2zzc1NW11ddQQ8/H3lwmoQRrctuLCg
sQxmXlhYcDSn1+v1ZeFWVlYsnU7bxMSEGyeCDVW4HKzl5WV79eqVO5kzMzNeD/LU6VwMKa2SZ2Zm
+lryK5I3yFjg9FQqFTs4OLAvX77Yzz//7B3BKI4+OTnxdp7KAcfZMzOvO1heXrbl5WXvhLe8vNzX
YCORSPShZ6ECBjGCR/7y5UsvbmQOHMWVOHAoz2EyYWbf6hiKxaItLCx4Ewk1zFyfAIGhmaD+7AH2
1u9JmT1GOLfQ2xiOqC39WftQWQKk0CzB7KZt/KibnoQUJBQ09Yc42ffhyuvvg8IfHx9bq9VyQz+s
aBBGVkgDpDCTeBe6Z2Z9CDsgDE7a7u6uX1+H7eJoAUDo+kEvDGlKfC5OgjpjZKHCpix6v1x/lIwD
qI8EdpqNnZmZsbW1NVtbW3NavCLy982OdDodOzo6slKp5I4TwVaj0bD9/X3b3t72QJ2sA13pEKjw
NJZg6Dn3oFktisG1DbXW7GDHcKLVZgxLSVK6m9LZtIueBjno85mZGctms/bq1St3bO4roX3jmqen
p1YoFBz1XllZ+c4G3fb+VP/fxS7h5zQIC7NQjwUPTk5O+vba1dWV16gvLCz0Zff0/sNMAD5KqVSy
z58/297enuXzeSsWi/47SgNWoIFMGV8XFxeeUSBzNj097XsOcD2VStn79+/tw4cPXlunNaRR664Z
ftZMu0IqYDGMPSCTAcCH/sZnMTOnw/PzdMnkDAF0cC8azGIHHiO6LwFcVHgPZLhrtVpfl1Uy7Wbm
jZzYA2HG/fdWC2bWnwXTs4tuYAbkysqKB2EhcBJ1TdWddHwul8t2eHhoxWLR65ivr6+/6xY+SJ41
CFMEEf4kReYUEZItua2mIZH4VlA5Pz//XTeo5eVlz0gomoOh0oLwqakp29ra6itqhZoY9dm8RDoU
ZjIZW15edv40G1uLKEcltM2Fb3p5eWnz8/O2vr7u3wudykGCgiPDRE0YlBaQdZ6HlHbIKTczT9cT
4Ha7XeeMU6CMMkJxhllG3fD692w2az/88INdXn4bIlooFBzF0e5ojxWc41Kp1AcIbG5ufoegKJKi
e4SsaiqV8qG8yG0G+zlFsyKjdGIHCXRfePNavBwlOIhksdnLp6enIy1wjhKUNc7EysqKbW5u2tu3
bx0QWlpa+o5+Y/Y9QKONOcjqjCp7R2E/jgMUXyhn1CmoHrjv82uzI2iB0Cs0s4JoDYFm3snARQVf
+nnqsHCW1GkftF6DaMLDiL47DaRZa30+PUN3rS/3iONIN96DgwN/PnQmDi76NaoxBu+IdQCk0Bom
sxs6GMyI8Dl17TSo5GeGXVscu26364NwT09PI7NGZjfAls6/AmCk42zUvavo8ytbhBEy09PTTk1U
ByqsoVQ6oln//CfN4umahs8ORUzbU2OzHhuEhfdkZl5/irNHfWN4T+xp6u1brZaPXtA6cNZXZxtp
jRlrBejJeSe45tnZwzQJw1FljcPnGfQ+1W8DmODeG41G5Po/RrhHMsYEMpwr6Mh0zVxeXrb5+Xmf
HajXUXrw9fV1ZCJhVIKt6Xa7XqYB4yuTydinT588OwbbQYNxZU783gIws36dMD097TacVv7ZbLZP
90WB7uHf9Sxx/giCoXpyLmAm3MdHfXY6IlksupSAlrDB6TgSooxqBMNiWlK2pKp7vZ7T43Asjo+P
/ZAQgNFGW4Owuzi8BGHQApg1wAT3YTpL3SbUJCQSCW95OTc3Z2traw8OwsysLwhrtVrf1SfgFNGe
WREqNYoMBaTLUqfTceTl8vLSstmsZbPZPkoE6xh1j2EQxjykQqFgv/zyiyP3IMfDCJmZYrHoPPat
ra0+ZJx7AgEJgwIdr1CtVr/LoP7agZjuCZDwp87WcYZ1tsxtxghEkYANtLNer/fVWYwyEAtR7snJ
Sc+Kv3jxwt68eWObm5tepzqoBgKliwNDEKajI0bBt0ffmZnz+rln5gZqEHZfwTAPCsLCLqi6f24L
RqJQeT5PAz8NIhQBD68bgiGjFHSTttfWrFGUYztIQqMO22Jqaso6nY7t7e31Ie7oW81cRX0mTi56
O2w0wRfrGu658MyzzqOmIbGWBGHU+UXpHM499pxGJNpRVVH6296FAkxhEDY1NeWNKMzsO3qW1o7r
56F3aNwS5ReEa0oTC6UMDxuEKQWQQBFqIcA2tDcNdnSNsJsahOkXtlnBFV1Xtfk8c1TGkz0F2JpM
Jj0Ii8osDhK1o8x5oht2s9m8Nx34NiEg146c1MVhEyYmJiyVStm7d+/s/fv3trS0ZKVSyUqlUt/a
6wBvnpHnfwrB1qA3zMzB74uLC6tUKvbTTz959j0EWkLq5O9JdJ+hg+k1QZMXgtcooPC26yaTST97
7Xbb7SWApQZh+Om/ehAWLghKkawV9ViLi4uOgEU5W2FKUWdSoMSJ7pPJpLdGbrfbVi6Xrd1uOzIP
ykaWBlqMGuBBDh+fNTY25i1Mc7mcH2BqIUbtfCsqhEIFlVK0Lgxe70KczG5QVs10hciYrn+UQ8Tv
M4OhXC57QbtSUKhVCO8jCn1gnck6ZjIZ50GD/jwE9Q+Fe2Zdq9WqzyrSAxqFhqB8mR+HAqRgehj6
yTAStSaK0oUI2FM4tYoqK/oWUmbDe9YAYmJiwh1Ofm9U96uOG/eLE7i4uOi0WtpRhy32QyGrQ33U
wcGBHR0d9dVXDrNPuddEIuHvDQMMGEE2QQeG3vfzcJx5Txo4ch3WXjP86qANuudQQicu6j6jrvdU
oAE2iW5XFG5Dm1InE12r6zJIeE46ldEUQgMtAnatsxvUcESdp6hn0GD2IefkKdZVM2EwLKCS00wh
PIM4Smtra7aysuIZB+hi93UUYW4QBIFUkwlSGiwZHwXYcErHxr6Ng5mfn/f3qEAIwtm4vr52xysM
vNSmPkZ4RwBVUe3uFRCJQvc542F2HltGB0P2X1RWQP9fdQJfGsCxHtBCNZPGPMPb1kOBQzJVBPfN
ZtMpesOCcjw/zjMO9PX1t6ZkMBomJibcBwEgVD9RfbCnEqW1kvHW4B49xnqF+loTDJrVeWpQ9qEy
aO895HcRvQb6h3EUrVbL6vW6d/oMy1AGXT8qORT2qgCABjC97VmeNAgLFW0ikXDHlY6IGxsblslk
bG5uzjfQXYugBkdRdDZoIpFwvjICUkEBaUg1CLv2Rd2DLjiNJ168eGHv37+3q6srzwbhdJmNzshp
23gz82YQh4eHPpjyrnlGoWMedj3EYKCQtMZkUEDCnyhdM3PFhTHTrmjqTOg6h+uFMSXYpEaDOVJm
N9TAx4oGYGNjY57NJIuhaKD+mUzejFfQhiR0+CJDeHx83IdePqUjybXDmjmMCQEFtUTU9DxFR0cy
jKwl1BzaDbOuuqfC8wb6SWfFcAA78pA1jXKgtBsiDtpDs244OMxh+vHHH61QKFi9XvdZUKCuj5WQ
3txsNu3o6Mjm5uYslUo5ckuwfd/7132JHiVoYGYfn897vS0DFl77PvKcQVcoicS3bnCpVMpWV1ct
lUpZJpOxly9fuk7UxhKcr0EItwZC6D9tlZ7NZj1Ar9frztwIA+e7nj/K2fitOFPUptHkpVwue40X
tiCUiYkJy2azZmZWq9W8XqnZbH4XGKhEZQyxG5VKxXZ2dpw1Qu0Hug9HiTpHwMZe71t7+o2NDdvY
2HCqND+LzeFdX1xceFaToE8bqwzrmHMG0eMAfsyII7jBCQzXRvcVz7K8vOx074mJCSuVSh4o8fOc
8xAgjQJfwmxlMpnsawaCHeA9qM4dJABz1PkDtDebzZEzI9Qv0XWAXri6umpbW1t+//wdsCAqQB+1
ACRoBkzfsdpdutgqAIt9MLsBoLmeztX9NUT3qOrAYYELwC7GXmWzWXv9+rUlEgkrFAp2dfVtpl02
m/UxBXf5lJRTJRIJT8RAd+50OpZOp71LLLrvtvKkZ8uEaQZrenr6uyCMmVd3FTuH3+N6g4TaFO0W
ZXZz6JR7fNdzhMaSrku85MPDw76s2igzDVrn1uv1rNFoWLFYtMPDQ8vlcu5A3UcR4BDqHCTogxqY
4GgMSllHBWEU9oIAsGFZ47voTIosQoU8Ozuz6elpW1tbs1Kp5AHdfd/dIIkKwhhafRt9hCAMpHRh
YcGdrEwm4wqOIaxhNmGUEj47ZwwU//Ly0jnRNJ8xu1FwdyGfjxEc1uPjY6dhafAXlfXkHjhntFJu
tVrelnyYewt1hwI4GCfNit8GxoTCOrbbbTs4OLC//vWvPm9Pu9ANCxioo9BsNq1QKNjY2Ji9ffvW
er1e37DOhwjXJQuk4AIoHufhMW3DfwuBwSCBXk4zoFevXtnW1lbfDC4cSYC9u5xqzQCj/zQIY25c
oVD4bnxK6PSGMmg//lYCMLNv5wGaX7lc9kBsZmbG0ul05O8QhC0tLVm5XLZffvnFdnZ27PLy0mmE
9xGCol6vZ+Vy2ZLJb625ARxPTk68hiOXy1kul/MGS/o5BCnYyIWFBbcHoV6AygvVj+CaIGwYG8Uz
mX0fhOEIkl3i83Qv6L7iiy6D1JVOT0/7QGT9Hf3sqPvRfytTAT+J4FDpmdhMKJ53CS3htXs1Mwif
Iujp9XruuwAYHh8f2+bmplWrVe+ml0ql3HdCJzwV9RDRuj7odOpTnJ6e2tnZWR+VHP+XZj6zs7Nm
dlM7qsHyr0lLDPeo2Wi6TPd63zpgNhoNy+Vyls1m7ePHj7a7u2t7e3vW6XQ8MNPM622iiYV0Om3t
dtuurq48s5jJZBzchWF1mzxLTZg667Ozsz4PZGNjwzY3N215edkRh6gDfh8ETD8n/F2lGGpxKL/z
2MMM1SSVStn8/HzfbCHlBo/COILMQEegW2G5XPbiZzr8hM0hQolqLkL9nHLN70JXQ6QM56NWq9n2
9rYPDH316pW3uVejdFuwzYY+PT31WS90GEskEu4k0h1qGEHhtlotKxQK9vnzZ29VPwgdIYhdWlqy
XC7nQSvo3vX1tbdYfmrniPVSlB7jxayjlZUVNxxTU1OOxD/Gqb5L2Kt0IaLlPO3aw4JYFfbQzMyM
ra6uWi6Xs/39fR93EDaJeGzwCMpJwEEt2MuXL21zc9NevHjhYzKi9inUHrjhdHRLJpOWy+XcCWS/
Disoec7//Py8AwcM/2WAM6DUoDVWUaQ5k8n4zLtisdg3UwYK00P1ZdT7ve3fzy04XYAEADM4pyGF
/bYMWNS1yeZWKhXP6EMVSiQSHpydnZ25c3Vb06GH2MNfU0Kd+uXLF28Nra32zW6eiWB0cXHRB+UC
ZqI7QkZIVNBKUEA27vT01DMBvGs63DFYntoZBSbv27QEW5BMfptnmc/nrVQqWa1W+24cwGME+8Mz
XVx8G9SNPk8kbupS9XP0fsfHxz0jWywW+6j4Chzr7z4kkx1mx3gHYX0i/wfNlPpGDVQ5kzQ+4Gfw
WbLZ7MjqwtHjPLuOzQBsOT8/t93dXfuP//gPK5fLtrm5aVtbW5ZKpfzdP8f5w78giE4mkzYzM9OX
HWMP7+/vOxtGm7iQ8VLaOUCk1uz/GhIFKGtgFDbTifpdZQTh9xOIkelWxgdZzIdkVgHYtFTi7OzM
Go2GHR4e+v/d1WAQebZMGH+fnZ21bDZruVzOgzC4+IqmhM79bfSLqFSmfiaHSn9m0M+Hh+m2BUSx
0dWRAEMP8qiyH9ANJicnbXl52fmmlUqlr6PhXU0QeCbWPJvNehBWrVadkqd1PbdJlAGsVCqejmWo
NQ6vNlQZdC3NwGE0q9Wq5fN5D2yY77a2tvZougf3gJFoNpt2cHBgc3Nztri46J0nFf0OA/vl5eU+
RHF+ft4SiYRnRjmwT40ykeXV5gJLS0vOY+c9U5SeSCRccYxaMJo0jqArEY5UVBBl1p9BYA5OtVq1
3d1dW15e9gHAOA+3yaD9pXtPB29DN3nz5o29evXKXr586aCB/j7XptCfoIXW7hMTE/b69Wu7vLx0
NHJUQRgoNs4XdRLMokqlUh50h0Zp0D3QYTGZTHp31FKpZMlk0h1VrZXRbM1tTl+Ufv2tBQrcm6LH
OCugnVDW6HTGs9/nnfZ6PWu1Wu6Uk02jlmVsbMzHnXQ6HQ/OzG6aHgy67m9ZOMfszaOjI/v8+bPP
5gGV14ytAkkLCwu2vr5ur169MrMbxoI2TlAJfQw+n+5k0Nd0Zhr1y4xYwKGiW7PWAN4F9Cjbo9Pp
2OHhoR0dHXmzK97jMEEYmaV2u21nZ2c+HxRdflvTkl6v52ALdlnr4cLGR+p33VfCMxEGYQiZZT7/
9PTUu+fq75+cnHgTDqidc3NztrKyYvV63X2MYexqr9dzcElpe+rDJRLfmDK7u7ve2v/f/u3f3M8i
KHrqLJjZTU2TWb/vyd6FcTI5OWnb29t9+53zELUGPAfr8WvrF/WxtFxgYmLCuzyGpSKhhIwgnT2Z
SNw066AR0H0p/Oxr9i5lEicnJ1apVGx/f79vT9znzD9rJgzDBjUqm83aysrKgzIZYdYl6nuDAqso
5RIGBLcZ2BB1I6KmIQNZBhSddgQaVjAi8/Pzls1mfeikZgfuG/CxwXHaOXzanANH/q41jXo+siuN
RqMvbc7P34Wm831FyLQmRbMYIKvDCIcaWmm5XHbKig5A1Htmz0KpwGGnyLNWq1mlUvEOXCjC2/bE
fZVfCCYopQ462uzsrG1sbNjW1pZnwRYXF/1rYmLCG0loce4oMrecIWoP5ubmPOi7r5LHyFD7EDVz
IzR8UYGB6p4QHCGgWVtb87b0r1+/to2NDctms5FBhgbuDJTFKajX63Z9fe36gM8ahVHDIZyfn7fV
1VWbmprybAk0FS2sv08Gm2fD0IXNVDQQ4P85lyHqret0198f4+Q9lUCjho4GmKXzg8xu5luFMuj/
+FLEVJ16fZ8rKyvera/Vag38rP9Lgr4/OTmxWq1mR0dHTtMbBEqxZgsLC5bL5bzzLvoN6lTYPGpQ
dpX3yH5XUJFsS7vd7ltrQCPtOAobIkoP8Kx0q6NWmywYmbuHZpBVdGQCtpSOfIOuq0CJgtXoTAIk
AqJQLz/mbIZ+FSAXoIOCrASOg3wWKJ7UTELFzGazXnNXq9UefI+hwBqBhs39Mh4B571er9vh4aHV
63Xb2NhwXTsoI/MUQmAR5dxrjX0ikfBnogEKAQi2Xtlh92lIMQoZBMzhX5FR1LpC/FRYZtBuw+vp
2dS9DoDIGqE3CMIWFxc9IXEXbZhrc3Z07qnZTR27rvlvokW9Ii1aHAi/fnp62pWjog9m3xvs8O9h
UKSbDK69difS7A4vQxtz8JnIXUZXgxl444uLi66Q74PY31dSqZRNTk46RYtGJDQIGdQKPAodu76+
9iLi/f19+/r1q21vb7tBoqUvDp122+FLuythIHDYaFDx6tUrDxhB8ghQozobhf+em5uz1dVVa7fb
tr6+bqurq05xYRZLvV4fWUciDaoTiYQXFCvdIERFARZQBDMzM25c5ufnbXd313Z3dz3LGA6hRW47
qFFKh8/GQYE6RYo9nU7bDz/8YD/88IOtrq46D79arVq1WrWlpSXvEKTDL0fRhRBK5vz8vKVSKaf1
afe+cC3185LJb0O+CW5odU3LV86ddqfS4EHXjZ+bm5uzhYUFrws5OTnxmXCvX7+2P/zhD/bx40d7
8eKFpVKp7yi9tzk7fC4ZlWKxaI1Go+9d6/M+RtCfy8vLtrm56U77+fl5X50ImbtB6L3q0EQi4TTR
Wq1mOzs79tNPP9nOzo51Oh0fmq31kWEDCe2kOIjOpDYgdL5GFaQ+RtgzZNtbrZa3wmb/tVot6/W+
jTzR2q27BOcunU47gr2zs2PlcrnPeQtpM0/RNv7XEt4zAB+2Jaq7H8Jas8eXl5dtdXXVm6bMzc15
hkRbQIcBQFRWNgo04D0Bor18+dI+fvxoHz58sLdv39r6+rqlUil31FTX8Pdms2mVSsV2d3etXC57
e3wzc0rYMPtcO69pAyF1yAcNhuUddLvdPko/v9tut61SqVij0ejrgjysTE9P28rKiq2vr9vKyopn
7XW2IXT5KPtNwEEQfH197cA9g4jx7x4rY2Nj3tmYLx0FhK/RarX8XWNjtTnKfYfyDisaRJ+dnTnQ
yxd0Zs7H0tKS17SRBQt9avxjzulT6R3VczyHNg7jjANuauMw7GtYu6ZBfWhbzG7qqGmOBE0fHxQq
+H1mEyMhSKmNl9LptK2srFir1bJSqdTXmfU2edIgLMwahTO6cBxZPJwmFVV64TX5PhIWjqMAiUi1
axzoD/dh1j+b4q5MDX+ixCm+XlxctOPj43tF1g8RqEarq6u2sbHhRarX19e2sLBw54wgRe8IworF
ou3t7dmXL19se3vbMylTU1NO5dAgFWOi7wLjoGgDFJvXr197EJZIJPrq2m7LXnGvIJEnJycehEGf
oxZnWAU4KLOZSCQ80JubmxuYIcW5pJYAqtj8/Lytra3Zf/7nf3rqGvTV7P4OebjX9P+F2j0gAAAg
AElEQVRAiLSjHcX/Gxsb9pe//MX+9V//1TMnExMTPhdmbm7O6zXIAIDsDKuMOVPMT1teXnb+eojk
hY44zwlVslwuexCGg6rnTh3YqIwr+xMq1OLiohfPZzIZ29zctA8fPtjHjx/thx9+sHQ6/eDOW2SS
wyAMR0zf2WMF/ZlKpWxzc9MmJiasXq9bp9Nx50GDMP3c8LN1LxOEHR0d2e7urn369Mn29vbs5OTE
GxoRpGu9q+o2AmOMoRpCDShYV0UkR1HfN4wQhCUSCZ/rRIdb6HTz8/O2sbHRF9TfJno+U6mULS0t
2fj4uFMS0du6j7GBBLX/14V3qM4TQRjUzkE6lTqNTCZjq6urtrm5adls1gOhg4ODvtEpul5RWdnw
e3yfL5osLSws2NbWlv3xj3+0P/7xj7a+vm65XO67uWXoK+wOYObe3l5fEAYwoej+Y4Rzh20Ou6Bq
LXDUM9PavVwu29HRkZ2cnDiNsd1uO81/lEEYvsq7d+9saWnJa9rQxToPTu9VAUayOZw5aPXpdNod
52FqmJT6urq6aisrK5ZOp/19dTodnwfGPsM/QN+q3/Uc2Wve99nZmVP1d3Z27OvXr32dhBOJhK97
tVr1GVbqw6FvRjXL8q77VvbV2NiYf+7MzIytr6/bhw8fnMYPINbpdLwWFEAwKgZgj2CLeDayxnNz
c31BGJRoZhNrEBYF4oQJCA3ClN1H0oCzdp+GJ8/Sop7Un84FY3ha2JEkdNBA60EnMd4Uz/Z6PUe2
mVLNYZmamuqjsdEdJpG4acHOYmpThdnZWQ8AtHsVSkJTnSD+q6ur9vr1azey9XrdN364Ho8RNl+j
0bCjoyNvqEExPunz+0Tymq6FMra2ttZH11LDqSgt6VeeP8xmJhIJ+/jxo/3hD3+wd+/e+XV1g9/m
FJLmhe9N639q4nD+KFLW4OShEh5mFNve3p4DBqwJmcawm5l+NkaRzlPj4+NOx1xaWvL6IfYcihBK
FK1iubY6vOxVKKkYAp1lNT097Y5LLpezd+/e2erqqs88wgEmrU993eHhoRUKhT765LBce9DXWq3m
daCrq6vukN73vdD8JpPJ9K2J2fcBhma8eU+8RxSkcuhXVlbs3bt39vbtW9vY2LCFhYU7i6z1fXU6
Hc8iVSoVK5VKViwWHQXTIGxY4Xw1Gg3b3d21xcVFryli2D1NUO5rTDU40nXWGWTz8/N9dCWyWpwB
pQyF70YlpDeGomeBewsdhlEHJ5wJqEjU9BwdHfnazMzM9OlBtQODJLxnngm6Mgbb7Nu6QGXFeX9q
h+gpJXRgqFWhpvfr16+e0QWc0d/ljPN3nBgCVzpZzs/Pe+MbutCa3QTV+Ars2xCwwUkFwaY0IioD
RuZO9Q0007OzM8vn8/bLL7/Y9va2B9o6i2vYbC+MGkBCgo9Op+N+0KCmMWrnl5aWvAMw1E6ARm3C
MwrBmS4Wi64zKHPANwspniroIwIOugJS4gAraBgdq35cr9dznY4dwQcB5Hz58qWtra3Zixcv+nwe
ZVnptUchIQOMa6s+RU/ipwCKQ1E069evykS4jRL6FKL+C37/8vKyAx9m5h2qtasyf+dL37sGycQB
PM/U1JS9ePHCNjc37dWrV7a6uuoAMbYzqn4ritGhPh+2Dl+AQeLVatX3KPd4l7/z5EEYCHgmk/G5
G+vr65ZOpz1DEuWgs0HOz8+tXC7b/v6+tVot5+lns1mfK0ILXBxIMlwEYRwmnBWdWUVm4OrqyhYW
FjyDsba2ZplMxgMyfUEoZJCaZPJbRzRSqCBjo8yEtdttf+mtVssNxbt377wlJko0pFLxp24mUv3p
dNq2trbcadQOMlyTgAyjA32DAFRpBVNTU/bx40f7+PGjra+ve9CrDrSuSXj4QeYJYs/Pzz3VrhQe
gu9ROLrcz8nJieXzeet0On3oPvVJoCeDOiYq6EDm8uLiwqanp21jY8PK5bJVKhVXFDi3l5eXTr1j
aGBYkArQMD097dnQXC5n6+vrHmSNjY1ZNpt1ZA/HXI0dXbw2NzdtfHzccrmc/fjjj/bXv/7V38Ww
7eA5t41Gww4ODmxxcdFbfwMYhGumaBNZAhCsbDbr9CSQUR04HVLb+Dkdyg5FFvoBAQfDYe8TwGD8
oK9BQyoWi5bP570gH+dQUdphjVwi8a0uslAoWKfTsVwuZ1tbW7a2tmbpdNrS6bQHuGF9QHgd7gek
nnqL9fV1pyEy40yzWwAFmr3BKBLcK3CA0zs2NmatVssbs/A9zbKDcuq75GwoVXaUQuE2836mpqas
2+3a4eGh6zf04UNaUOu9o8NOTk5sYmLCKStra2v+c8zDognB/+UgLBRtKf7582enQb99+9YHWJvd
gHrqB0BJg9o2MzNjuVzOz3GhULBGo2GNRsMDK/QO8/lYYy2WZ9/jnL18+dK7ouJX0KwqbDHPvTEQ
Glv/6dMn++WXX/rmbY2KWqogAPoPumwikeijSqqo/VpYWPC1pIMj5QGwXljDUeiqs7MzOzo68gBv
cnKyD+zWOrHQ7zMzrwE0s77MQj6ft1qtZuPj4/bixYuh7hVbQ6YQ303ZILBcNjY2fL9gixSYjkoi
jEoUkAoDBVhYS0tL7qdeX197oyGl8vH3MKszKl1zm1+nAB5D2fGnVldX7U9/+pP96U9/8n2iNYEE
341Gw6mXOv4H3wibrH7iwsKCvXv3zv7yl7/YxsaGLS4uur5nJAZxyH0Ee4ZfAdhQKpUsn8/bzs6O
l56g0+7aE08WhIUObDqdducwfPioG+VFdDodKxaL9uXLF3duzs7OPKDr9Xp2cHBgBwcH7hBcXFz4
QdfappWVFVtZWelLPx4cHNjh4aGdn597tu7Nmzf+O6QcQ4QXBwNHj4Ft3W7XHU+GfGox4WOl2+06
8kxNz/j4uK2trXmbdkU+Br0TDgfNG7LZrL1588bT7+1221O4NBnRVDCdmZQbTXEjiPKHDx/sw4cP
3lb87OysLxUd3qMGhwy9rdVqjohARyMAR3HgsIxCEomEO5nVarVvdtTU1JTNzc1ZOp12xafZ2/AZ
2HvQGik0L5VKViqVfJ9CAWQeDQic1k6yv0D/FhYW7OXLl/b+/Xvb2tqyV69eWSaT8fvgnCmtTu+P
d4Dzubm5aZeXl1atVp1Koz//GEHpg4S+evXKKQdRc5ZC5Y3TC71zY2PDZ8XNzs5aMpl0BFyzJ+gQ
LbJmHclAkPUlK0ZtwqBnDulNZNZ1bEKxWLRCoWCFQsHpk6MOGAgACfouLy+90xyjGmZnZ78z2IP0
Ds+FYwctp9freZahUql4QNvr9TyQQu+NjY1Zu9129Jj9puABgVa5XLZisehdAAFs2A8YUnUWOI90
R4tChYfZp0p5wuGmhoJzHAatUVn8ULh/aoMZ3G5mrjPT6bQdHx9bu922Wq3muneU2dNfQ8L1wIbT
YQ7QksAKQGtQEKF1QYCu7PlMJmPVatVqtZrv+ePjYysUCn0Z28vLSwdY0T1jY2O2tbVlf/jDH+z9
+/f25s0be/PmTV9zI6X86bP1ej0PLqH0b29v29evX/sGy48yCONsQeUncKCGaRAlX5lGBHDMikJP
R42feOw9awZTa5NyuZzr6Si7FL579gRZRWo2G42Gtdttp5I9lgXDZwPSm91kiwD4yNguLS3Z+vq6
/fnPf/Y9Qo08a6iMoag1GUaidDqg9uTkpNckAYSRpSUg0YArZBuMEuyJyiTxd2wBjYgAZJeXly2X
y3n9Ovbd7GaWGc2varWa21md6Ud5Qa1W66MkTk5OWiaTsXfv3tm//Mu/uP5IJpPOIiMjp/c8yA8I
AWOASW3ORc2lxg13JWOeJAhT1EY7DUEH1Ba13KA+OMFGrVazYrFou7u7tr+/704iivbvf/+709XI
kmkbSl3UZDJptVrN9vf3+1DyWq1m1WrVLi4u3Okgc0bG7fT01B06Mgn6Urj+xMSELS0t2Zs3b+zs
7Mx+/vlnH158F4XlLgENY53o7NRoNFyp3qdegfWdmpry4GBiYsLW1tbcsVV6p2bH1EDhRNGMBEOJ
cSXQ5b5CPrA6VeEGp9aJ4b4YO9rEHh8fj7SIVK/D/YBwgixdXl7au3fvHHVCgYcHGDqnmXm9XiKR
8Kwjw71PTk68KLpSqTjlgRo0UGKUJvt5cXHR0biVlRXLZrNuiJPJpNNodR+oEuZ9ktkEpefs6PeH
Wc/Q+bgPIsQ6Eriur6/b5OSk04S4tqLdBMg6+oBzqvtVa1ABDqAb3/Yc4bkFAWeW1sHBgeXzeSsW
i9797SmyGDpUG4eVbkzq+IXMgkHC90DHe72eZ65XV1edVUAWiiG3ZL4zmYwtLCy4ngD5v7q6+k5P
hJkwhPfCUEsNWqhhKZfLXqPFvsRJuo3eeN817fV6ng1Ip9P2+vVre/XqlTvhmUzGJiYmrFKp+NkK
6+6QkH6YTCY9CCHTpbPycPg4f7+HWrBQcFTPz8+tWq3a169fHUlOJpMOiCwuLkbWdgHGmN04Pysr
K9br9Wx5edn3CvuwVqv10bH0/Gs9+szMjOvRXC7ns0oBbZTpoDoA/Vgul21nZ8e+fPliOzs7ViqV
vK5Kz8IogjCuQ1aGrrF0cryPzYeGSMCP7UJ/jvJcAaLh60Ef5b1Ah1T9oCA3Op5zSW0lswxpQFGp
VIaizQOao1PDYAWAiKwdQJ6ygwBuBgWToxAN8NDrsJCWlpZcZyp9r9FoOG0vmfw2Y429q0C23vMo
7JbaH3w+apkBVN++fWtv3rz5jg6MX6gUUf4OAM1oIp4NppQmAWjAtbCwYKurq/bx40fb3Ny0VCpl
ZjcZskEzQFXCQJXM29HRkRWLRatWq86cIsgkOGatB3WDRZ4kCAN5YaNguJm7oii1KjpVdsfHx3Z0
dGQ7Ozu2t7dnBwcHPpiY+jBQEnXmzW6MIehsSB1DkdEpTduN8rtsCJwbuuHogeW+eebx8XEPwtj0
hULBisXi0GuqnRa5r06nY41Goy9Dc9/3AwLJUFwQfoKeo6MjLyxkg0F7ItBgM7PptWBYs0Vsdg5n
VIDAu2cdqXGjdokgrNlsWrfbfRKHRfcPtASC+vPzc2/7jqHgcIVUGl1nmqak02nfkyiPRqNhX79+
7cu0XVxcuMHBYJ2cnDiSSxo9k8l4sIaxYN1C6hSGheyCOu363rkvaLWPlZAeaNZfPDtIWFfWbWJi
wrLZbB/KfXx87LOsmI21trZmS0tLfZ/DekTV8OGIsVbh50ftC94roEoYhNGWelgq5yAJB6uCNlO4
zDu7baCwCutBJginifVmzXUOGq33s9msUyHZQ+hj5v7g/OJg8X2l4AK2cNavr6998HSlUrGvX7/6
PfI7ChBp96zHCL9Lxm1qaspev35t//7v/+4/w/6pVqvu1Id1g+wNpf2w1wiUAQopnkd3KAjyewzC
zG6CiEql4jZb9zBBhdn37d8JjNRRBOTL5XJ+bdBwsmC8T0ZzsN/JGuD8QeNlzieBmtp4hODg+PjY
9+ePP/7oQRi0y1FTvbS+R4Mw7G6YBYvam2RGKpWKB2EAVnNzc55t5vcfuhdDNgMUSBppkGmmllsb
s6hvgHBuoPGmUimfeVkul61ardr+/v53HWgfIgRh+uw8C3sTJgBBGPMq0T8a0DxFAKb3o1+wOzQA
A5Cg2yUZaLKfmsHRjBifYTZcIKYZOvw+AI8XL17Yy5cv7fXr1/b+/Xt7+/at17PPzs468MFeUFYF
YP/V1ZUP6uZZAa35LJqBLS4uenfODx8+2IsXL1wPaE3XXWAla4JfQhBWLBZte3u7r/4U9hN2DV/r
Lhv1JEGYZj7YxESoZE5YuKiHxeFCaUBHq9frjiZq/ZfWH7DRMNoahIHwgP5CAdP5WNRdkF1SekjU
oGF1ZpSmpy0rG42GG/rHOgwcciJ8an3Cupj7KALul4PCuoHikYWB9sCaoQQ15UtgHYUehp+JhGug
QY3WgRAMqpOr/PVRSng9rY0bHx/3VuDUNAEmhIpDU8+sa+jog+qz/5LJZN8sMVqOq5HgnQNoqNOg
WQfdn6pYCf5wCJlhc3p6avl83uvu4DIPorfcR1gPaMiLi4u+V1nPQXuV/2M/md3QxjjzADjQFUHS
EaXgaME07zjUF4P2gOoEHP69vT3vKPr582fb39/3gekKCo1aMALo0Uwm413kcDqPj4+dYXBfowro
oWuhf6pjStdPukpCwSajQzCvtV6sP7pX11NF3zEF0wRIUGwuLy+9/kebHj3W+VEknrXAXmkmAyBm
bm7uVv0dOpRhcEY9BoE8TmbUnKbfiyhYSefiUqlkX7588b1Dxh8dFzbeUZ3a6/U88MAGmZlnXWCq
ALKmUilbWFhwvwL7Gc721DpfbeCh9w/qns/n7fPnz/b582dnZ5A15p5HSfXi/rAdx8fHToGiGQO+
VFTgmEjc1LJSGoAfhu2+z3zBu0RBLHQHQ6wvLy8dROt0Om6zBjnB6sxrC3V0hzayGoXo2eVzGdLO
yJ5Wq9XXDAZdOyhov00e8rPaYIZ7JdClMQsZ0dPTU7dFZPOoT6fOt91uuy+q60+A9ljBXnN/rOHy
8rK9fPnS/vSnP3kTrI2NDb93QJZQd+r518/Axz4+PrbFxUXfZ+l02n2ahYUFz7Dlcjnf67ftt6h3
ovGBUmS73a7TxwEYqXlkLdXm/WpBmEbEIFDMY4iaacNDg85rhA8CShQMZVA3jj4oykczFvx82HEp
/KrX67azs+POPpmKbDbbR6FEQKhR6GbfmhtMT0/bixcv7PLy0orFohWLxaEyDGNjY86hzeVyfZ3m
NPM3KBAK1zr8N4dgenraWwJrMIuRTCZvBuDpvBJF4KMcJBS8dqTE4JGpgYJAe9ivX7/a169fXfmF
G/qpHBf2AhnZVqvlBuv8/NwLujUwRxHfB2FJJBLexndubq4PUYM6Y2auABShVZQIxXAbBU1pTxgS
uvg0Gg3b3t62g4MDb2VLYPdY4d5o+rK6uurIkDZ1YB3MvkdvNWumSh1aAkgrQQmUJX4+KhjVP8NM
YZSwZszUa7Va9unTJ/v06ZN9/frVCoWCHR0debbyLmU7rFDU/OLFC29wlEqlbHx83J0bMlr6XHft
wxCJ1nOqRf3Mn4MGQ0ao1+v1BS9RxjSk+hBgMRxZ58iB8qL/AYNwRDqdzkiyDegymu2YmVO2CLpB
kam3u+2z2NsIjhI6OSzmrlar37Ewfs/C++p2u7a/v2/NZtP128nJib1+/TqyU5n+PnY91A8Ah3T7
ffPmjTtsmrmEoaOO36B6Ze5BbcHe3p797//+r33+/Nn29vasUChYq9XqY6qMMgAzM3c0zcw6nY6V
y2Wvnen1eq4Hw7XSZ9C1o/kYnUB5ZhzOUexD1SvM26rVapbJZLymC+pW1PsmmDazvuYMAPLn5+d+
ph4rgC50FNRzSndGunien5/b3t5e3/BtnX8JUHQfyv1DBH9VBwMTjJuZs1/wQ6CdorvxF7PZrB0e
Htrh4aGVy2VrNBrfdX0dVgfxLjRo5DxubW3ZP/3TP9nr168dRNbxQviPUXZI14L7xReCYZdKpTzw
vLq6ctCQfcb66HVuW3O+T+0ldfs6GsrMPDPOz8AKoQ4YxtFt+uBJgjAt/sdxoiAZHijtRxENmHDE
McJapwQKoTzLqPS5OmHhImizDn6W65iZD4ZlVg6t9ckIhVkCgjBQE7JK0NfMzDnxHKTHyNjYmC0u
LroDpp3vCGxC5GCQhA67UgOo5ctms+78mN3Mfxq0gUP62aAADGWvmRutCSFbAx11d3e3r9vVfVH+
YQSHgfuhWQmobSKRcMogikEzu4OadujaUO+Uy+X6nNbbgmfAAxxEjFhY7Bzud5Qzs7cIIIrFon39
+tUODw+tVqv1da56rBCQEjAAXpydnfW1/h/0GYP2DsqXgMDshi4W1hSo8O+QpqeZ9/DzQb6p24Oe
+z//8z/2X//1X7a7u+uZOUXLn3JPJpNJP/8bGxu2srLinTFpFkKwEPX8g9Y7XBcMmQZh8/Pzff+n
mUok6p3p98L93Wq1PCsMLXJsbMzm5+ft4uKirxEIzjqNmjQAe6zjgA2CSk2Ax0BlwI9EIuHjUG6T
EIgiy6O1EVCyyGSofv29C3sCFHlvb8/3FA5bLpfrYxeEZwt9q/qVIAw0XJ2526i56FGllEc50ejc
Tqdj+/v79t///d/29etX76wMI4f7HLWQHWR/VioVB/yWlpZsc3Oz77MH3QO2ExYF9eRcG9s8KuG8
h5RcWB+AFOE9mlkfYHF1deVAGAPUH0K9vu3+dIZUWD+o1NWLiws7ODiwer3ujWGoAQo79d4GIvC5
9xH2PEFY2LQHvxOAlrXudrv+LEtLS7a1tWVv3rzxjB46t91uu++ADzkMqAWtXPcRnXdzuZy9f//e
Xr161eer8pwhsBIGX/rvEDRZXl52HaLPc9s7CAOx8OzwJ+uJbb2+vnbqP+UdNKeClqiB2X3O1JME
YWHr32w2a2tra569UZTD7IYzrhPKidYZnsnh5UGjIuSozfOQDaWbAnSuVqtZPp/3YnUWVA2sZiZm
Z2ctk8k4UnN1dWWNRsM36KiUNAaJDR2+7PsU54fPDpIb5ZTyp6I9YTAU/p5SekgTU7g/OTnpm7fd
bvtGr9Vq3nHul19+saOjI68BfE7RwF6dxr29PVd2IHo4kIw2YCggSjIM3EOq3H0QVF1j9lroaGiW
UWvP6CzVarVsf3/f65gILMgykjEbFgklyIZSjIJSNPahgpIGsdO1UOcsFDV8fLYWniuFWQ3e6emp
j74oFAregRXnS5FJPucpAzA+gxpJmh2FNAjed7jvHrLmutYqauCgB4VZNO4z6t5DIasJmkyDEBgI
ZDamp6fd+Ck1NLQDD5Vut+v6e3p62lqtln358sVarZYPb8V+rays2NLSUiTyHpV1QDcT5DF0HqQd
ClGUPfu9CnvG7Oa8MDBex3/gI0xPT7sTPD4+7k6u6rwodDt8D4MEsEgBSK4LZRTgql6v29HRkW1v
b3vnXp1b+pTnn30D4KSDoM1u2EO3AXlkAKHAa+1v2KhhFMJ5PT4+9gCHPR9VusB7Uj2itf2A5mTJ
obqNImunGZawrIR9mUh86548NjbmMyczmYwtLi72ZaG0gRIBUhT4dx9hLQD41TdTUIs1TSaT/m7Z
K/ifh4eH1mg0+kC02dnZkTaRUR8NZgHZ1r/97W82OTlpP//8s79XkjJ0LQZQVN8y6s+oYBY/QG25
fv823yAU9i4BFnW8fE6j0bC9vT378ccf3YcNu6Lqmt4lTxaEcVhSqZQPamWmUVhoy0E7OTlxpJ46
C5x0HHVNBYaBmMpjlaKmZaGm5PN529zc9EJHNhGbGWcaKhBzu+BBk3o1+74e6jH3F2XsUVQ8tzYk
iFqfKIlCcHC8+H0cBpyxQevMvYG6EARcXV15J6pOp2N7e3uehaFTJYX5UDjb7bY7zYOC7VGLKiTW
hCAMJJeOaaA9P/zwgzuM/D60kbDmJjT+99mvmtGJcpLZCxhYzk2z2XRHYm9vz/b3932m1dHRkTc6
QGkMQ5k16w/CWq2WdzJSQxvuy9uCBL7HOmoGiy+lt+p1QwFggYpBoMLanZyc+HoReO3v79vu7q7t
7u56S2zW67n2I/eu75URENyHos6M/3hMbR8OSUjZRA+ozlHU8aEB9sTEhAeTvDulHQJuTE1N+XqH
Qdgw+rTb7fpnXF9f+7ru7e3ZP//zP/tw8UwmY+vr6w4u3mZ3WAfulSBsdnbWOp2OAygEZs+9h35N
iXLy2u22FQoFD4RpAAXltdfrOUVRa8huC/zD7FmURO1x/X1qkiuVih0eHtr+/r4DWARh1AoOuw/v
Eg3CJiYmXJdqBgv7OKg2SesdocBqEDYsEBACsYDq3W7XwQvq9AjCQvBQAR30DOedLJBmrqj1G5Vo
HwOCMGoNwxmpq6ur3vURGjZAI3uBLONDs3VhoIGO4h0RgLP/YYcAMJ6fn3stHkEYFGh0Ns/IeyKA
GjYII7vI/ZC4+Nvf/uYjFTjHNOsgk8ucs9Bf0n0SxbYI/Qndg6xh6H+p76Drjv+P74JN0DFLjUbD
dnd37ccff3Tf6fr6phOr1j7fR54kCCM9ylC2XC7nyMHc3JynoHkZKBGyC+Vy2bufVatVazabrvSe
ooB50MvV+6HjTLvddkRJDYOZuSFZXFy0iYkJT/eT4iYdPMx94tyC0mkErkYOZcCfURsyzJRFORQ4
cqpc9Jp6EDg8WnsHhbRWq1mlUnGFen19bYVCwT5//mzb29sefDFbhKCNA/CY7MmwEh5Qsh/QWFqt
Vh8NhkYU+j4WFxft8vLS98FdHPb7BGKh8tAzRPE18+QIGghwDw8PvaU63w/f5bCC0qRldL1e92wY
5zdEPEMHTR2kKCBBFaauS5i91MBNAy06YuFYQ3cGBCqXy86hJxg7ODjo68x3mzP+FAJCR2BNhzQd
8KvvMDQ2IeI8SA8Mep4w2Ar3YBRKG14naq+p0Y26l6urK58XSDF0qOseI2QUer2e153R+ez169dm
Zh4sUXODY6j3fFvAj11jsG+lUnEnaXl52SnPv/d6MLPooIgzh2NIBzQykL1ezzMT6FQyKqpLQ9Q7
RMVVos4FXzhP0F4LhYLt7Ox4Ew7qaKlTJxB7yvOvNeycdWqWdGQOe1PPuepRgA5sV7vd9oBsFIFk
qA+p7b++vvb6PM5TVIZI/RR9HwSMOLUAzINGRTzkfjmf2OZBOoxMou49pcRx31HPcNd6Rekx1YPK
nOFnFDAlkKa+Ff+Tfcz7xjfAfnGvBOHDCoE0zw/1ERDh7OzMad29Xs/1HsAUa4vPqX521LqwZvex
X+qnDrIb/Aw2tlKp9J0RMmPMFmbgOWMA2NthHdhdvuuTBWEzMzOWzWbt1atX3klrYWHBh3yqwsOg
Xl1dOef56OjInSAi+aeUQY4Fw9hqtZo7Z3SbUVqOZsOYP0THmkQi4dmSYRRHr1wrrzoAABSkSURB
VPeNT1+tVp2mwzqTvYDuoggZB5XNrTV7oTMcpYT4N4eBa2J8ULJQ5PhsdRihGNLogJTu3//+d9ve
3vbsA7V4dFr7rSDF6sQTXJycnHiHrW6367QlFN7l5aWl02lHA3GauR7vQ7MJ90FpUKaqkFkv1q7d
btvR0ZEPECbg4gtgI4qGMOxaY2RPT08dUNnY2HD6php7gvUwo6MNX/i52xx33e+qmEFcFfED3TIz
/wzWpVQq+UBIDWKZB6I6axRr9RDBQDCagqYDqVTK3yXZJaUiaocn3re27w+b+dy2/8KsJP9WYx41
JgFh/4aBlDpBvd43pJd93Wg03Bmu1Wp9oMwwwAHvEJRe54apU4Kzo0E+bA/WRkWBq5OTEyuXy7a/
v29fv361nZ0dOz8/t7m5OVtfX7fLy0trNpv/MJTEULATzGVst9veOn5tbc0ZJ7Ozs65T6dILyyDK
TqnDavY9ak7WOBysDMCpY1pgDxwcHDjwSY2OUhKfShRgws7TKIw29VDRuBcFhgm8sGE0vWIG332a
B9xX9F3o/ZL9pckNQRifSRYcCr12RgRU1BEXoxDOuu4NgjuyOdjmxcVFy2azlkqlbHp62uuu8KO0
Jhy9dlfNGu9JgalQvyqorfuXWnUYLq1Wy8bGxmx9fd16vZvRIq1Wy3U8+xU/QUGEUQl+vVl/Rg/W
AeBnIpGwer1u5XLZ/WXWsNfreUY8nU77LDYz6/OXED374efqn4P8B0QZPIygoQSKrPH5+bnt7OxY
sVjsG/Nj1u+H6Zreda6eJAgDMWCezMuXLz0I4+EVuUdxXl9f+5wDDcJwIIYxuPeRMBADpTSzviBs
cnLSUqmUO8UcOA1yCJJ40WTI4Mo+RjAS1Wq1L2WOc2h205mONWMOjdYjoGRCBEGNiRozNXS8O81o
8fxKUUR5MvenVCpZPp+3drvt08V3dnY8CGPQIAjNU7/rhwj7QtEubQFLu1SCMGp1qCvAePR6PV93
HE2uresclRniZ1jXVqvl39eW12RIm82m7e3t2e7urhWLRatUKh5IkJXS5xul4BydnZ1ZuVy2TCbj
WQxa76tQyHpxceHroIgY98i68P+azdFgjvVSKghBGJ226vW6UwjMzOlG+oVDxvnRQcy/1v7Umi8c
hbW1NTs5OfEAaH5+/jvABIMLeALKyDVCYx9mz/X8ax2sshkU7NF2xbpe6HyKlnmfqi/NrC8Iazab
VigU7MuXL+406P0+VrgngjA6n4UZWw0wVc+Gz4foviUI293dte3tbfv555+9Rnpubs6dp6jr/CMI
++Hq6lvzhf39fc+CVatVD8BmZ2d9PAn7V2uydX9GAVphkJtIJLwEQp0pnNdqtep0+P39fZ9Vys8p
sPEcwh5kNANlD/gUnBf0gIIF+AOcFw3CFDAcRSCpa6/gBZkOssrKJELno7+Pj4+dTYW94z2hwwZl
zR8ivV7Pgz4cf3wjnVvV6/Usm83a+vq6raysmNlNUAHFU32q+wRhCupq8Kz7GJBM7R5rpXPf6vW6
tdttGx8ft/X1dZudnbVPnz7ZwcGBtdttvyY+m2bPVM+PSjSzhg7tdrtmZt4hOZlMWr1e7wvIzczB
K2h91AnrmqqvqVlvs+iu3GGwi90PgzCl0FIDStfjs7MzL5OBSYQPiH7hfT5UniQIY2FOTk58gCIP
oW21idBxcGjGQMtssg36gE9tpMLrcxhOTk4sn887vYxOhTwD0bLZDR2T2VbUtuEIPUbYdBgOauUo
upyYmOhDEWnxr8NNQRp0rpRmJM0sUgFogTkdzBKJb/xjjFYicdOhCsXSarU8G0MmrNvt+nX4P2ZW
qVH7rTkjUYgKRgbHPp/P2/z8vM3MzPizACgwMZ4sqg4LpiYJg0VBMIoTJaCDbnFQec/QZEBiut2u
I7nQaDudzpPOskLo3NjrfaNxnJ6eWqFQsOnpaUe/GJDK/9Xr9b6Oj8or18JzbWgCqKD1j4lEwhuR
nJ+f+1gFqMUEYPV63R2ay8tLy+fz3r6X7BfIoXZR+7VEO1YquNJut61UKtn8/Hwfks/6XV1deZdB
Apjr6+u+2UjsQYxz6AxowIvh4v+hkABM6NDmsbGbsRY4kVrsrI4FOgn91u12fRbTwcGBnZ6eetv6
sDvuY0XXM0SFu92uO+AKAvKZrJsaYAT9cHFxYZ8+fbJffvnFdnZ2LJ/PW7Va9UwvdiNEvP+RJMqu
dzodfzfQQGdnZ/3nOp2OVatVb+CBIwyijn5EP1Abo+ChOqM4/gxhLpfLbrdbrZYVi0X3RRR0eC59
gO5jf5yenlqlUrG9vT0zM69TYoYq94a9p6YSSm8+n/dZUhqcjUIUwGadsI2MCri6uvKxIugPnG3e
Dfq7VqvZ0dGRd0bEER5FEGbWPzOSGn6CWcaf0AGRZjEMr6dd/vLysv+cdlnk+aE8st/CLw3C0K8w
i9i/YcBQqVQcWGX+F9kaLVU5OTnx31XWi67fUzCNwutx9vSza7Wamd1Qko+OjlynTk5OOh2YEibA
MgI31oU9o4BIuH74sgpEaj2n+lOc+VKp5H5Tt9t1OwqgrD0YNFB8qDxJEGZmnvYul8t2dXVlpVLJ
i6ynpqZ8+vjy8rJVKhUrlUq2u7trnz59sp9++sm7I56enkais88hehgIwpReyOyAiYkJPxBXV1fe
0alQKHgtGQ0KHtv0QA8SCpXZGXt7e153tbm56UoM5xvHCKWsFCQcEIai6tyJyclJ/91E4ttcjKWl
JS+mTyQSdnh4aF++fLHLy0sPHnhfzWbTa2qoDSIjNzY2Zp1Ox+r1eh8vPUwj/5ZEnTCzmyYuZKby
+bw7uOxV1mRhYcHHM/BFxgggotPp2NXVlbcgHxsbc0VKkHV5eemGCwon9XblctkdyfPzc6cqgOaM
ivt/l8CxN/sWPJyentrh4aF1u13L5/M+xJziZjLMFD7rzBZ17nVWGopcabko6GKx6PUbZCfPzs58
PfhiXeiECCBA4KWKOqw1e25R6rBm9ahdgaLCnqCovNfr+d7QQJK1VESRvab0Yg3SQsM9MfFtgHs2
m/XPPz4+tnw+b4VCwRKJhG1ubvqsRDKe7GXQZ3UycBRxFvP5vDe0SKVS7oSOMgjTTCyUWBpGzMzM
9KHvZtZnj5SajQBCnZ+fO6i4t7dnxWLRGo1GH4BwcnLSxwT5RxMcF80sArwCWHa7XW9yMD4+bpVK
xQ4ODnw+ls5zmpycdCeUJg7UYlMjQ90xOub8/Nx1QrFYtKOjIweFyDwDFJpF1+U+pQBOsT8ArLe3
ty2RSPSBvqVSydeUGvWZmRl/7lqtZsVi0WsfRw16qv3GBkI1paat0+m4/aMBy9LSUl/DNg0yoM/D
RiqVSiMJwPDv0IPsj+PjY0smk331PbTEn5yctE6nYwcHBzY+Pu6zb7PZrGWzWS870Izs5eVl5Lgl
gHsNBvg97SOgtVEEbOjIer3uYAFBGPuVz1K6Oc+NznnqPRxmRZXlA2hYq9U82MLOML5nZWXFR1ox
5mp5edlnu42Pj7vNg7WGX4A/gC0kuMZuwlIiGCYI01FYlCLU63X3hZnJGQVmP4bR8CRBGMqzXq87
6oLhQWEsLi76Ih8dHVk+n7e9vT37/Pmzc8NxhlR+LSfo+PjYisWi85XNzHnpU1NTVigULJ/P2+Xl
pRuEfD5vlUrFM1LawvShoqgttM1ms2mTk5NOUaSjZLPZ9CwZM65wEjh8/B1n7vT0tI+qSMDMZuz1
epZKpSydTvvzjY2N2c8//2w//fSTnZ2deX0U94ojUygUvLulGjJNjw+DJDynhJQWRUUputfZJ+x3
bXnL+tEVDsej3W7b9fW1G0gCVZrDAGjw+7xzvsrlshtVzYrgWD6XsMfJYGEQyNgsLCz4fLSVlRVX
dDgboGFKaz09Pe0riub7BGEo6MXFRcvn87a9vW3lctlbjUPfABCh7SxKF4NGdkypTM/tdEWJ1sZp
QMP+AQhgxMP8/LwDJeyT6+v+znK6J3q9Xt9Z14A3bHWvND7GMpDxPD4+tp2dHdvZ2TEz82Y7ZBww
gGQ7QDRxdFqtlu9nEOder+eOmtacjkLQQ91uty/r3+l07PDw0Hq9ngNeSn3FqdfMNKIZF7pqkpFm
oDa2UGcfPucZ/a1IeLbQqTjsgLnYWYINnCz2eSaTsXQ6bdPT076/ZmdnPeOOowXNqFKpeCbm4uLC
HX4Q8Far5ff43NTDUJQGj14vFotmdqMPJicnvYEYa6nlBwCe7EGlpY+aYRRS7XBY8X+Oj4+dMTI7
O+v2jAzH+Pi4+w31et3nMaITGo3GyM6LNi4Ja+oApHq9ngc9Y2NjXjfc6/XcrsOeSKVSrquUYUD2
n3WHWhsyLDQTxhf7FH+NGkpsGetDNohyBG0gBdARAmlPlQkLBSaEUiDRu1FZv4mJCSuVSp5l5Et9
J/Y2GdJut+vPCPCtX1dXV75WgC50buZLG8CYmesEGpgpwKY6f5i9+CRBWLPZ9EK7s7Mzp7BhQDHy
LI6m+crlsi9MaGif2wkiPY6h1KChUCg4Ejc9Pe1O3OXlpTuGvLBROHCsBRQeonQUMOnb/f19p19R
dAoioAGXoi/Kk1UEHLoMyoh0vE67JzjAgda0uTZB0HS8UhW0ucdvPQALRe8XhN6sf/itZhd5TwQT
oFucCzIQZLHMzIMwlEav1/NMmipikB1tZAKA8Rh0Zhhhr7bbbUdkUfY4UgcHB7a9ve2NSrg/9kaU
QtT6JaUckeEF9YIrjyMNCqb0Qu0URSAWZmJ/S1nZKPCGdYLH3mg0nPbDXqPWAjoNXTo5l2qkNQjR
tQ6pP0otYS9C+bq4uPCgutfr2dHRkX369Ok7tFcpiIlEwru1aV0jSK5Zf1OSx1K6Q+GZoe/ybNzP
/v6+Z7iXlpb8d0I6T1TzGAK1qKwDepFC9ZAF8I8sur5kEK6urnzeVDgShn0+Pz9v8/PzfSyExcVF
b3eP3YPeVi6XHRS7vr7u68rb7Xb7zttzUg9vExzZTqfj4ECtVrPPnz/7YGNtEoYNUD0HqwAQhwDp
KQIxBX5ZP4ISwBcF5vlzYmLCgTKAW4AywJJRBGD4dPpv1YVkla6uruzTp092dnZmqVTKAykFX8g4
MshZKXQEzuxBdIHqQdW32Dd8Jr5PYAhdGz0ZZtTI7OqzhYBb6Ls8lXBt9he+iWbD8JOhZicSCfc9
m81mH4OOgJR9ApAFq4U9pQANv0OASuMNWFgKpIV0cx3ErH5ruGbDrGHiKV7A9PR0L5lMuvOvES4L
pk6/oopRnbN+LeNEWlgdaW3XjuM3MzPjh+zy8tI3PFSoiYkJz5T9f1TkwRokkUj05O99BkgbEHAQ
Ocyzs7OOVne7XSuXy4740xRFa8TCQEoDTzYhn827C1FhFTWq/FuDU/25YaTX6w21psPKII566KyF
/yZDjIJRHjrF6jorz8w8mwTFQesmda3N7jczZ5A8Zk3//zP3FM0z66cd6bNrFyQCUA3eKc4NA9aQ
2212k3XU/cie1bVm/cnOaIespzZOj13TZDLZdzOsIZQjGpmEiD1IKlmBdDptU1NT3vSIzBeZLUUl
Mfyqi8m6ETwoXZF3q017wr1IUyNqI/kMmiAo+qz7mffHuw2d4seef2hHUINDQEizCUqH1zXCIeD7
etYBGGFDkOGGXqqZ9N9aEPZr61Szm8yANkDQs43gxCrIlUqlvCEYwT01uuVy2UFgM3OnVhsWIKPM
hD92TaFYMTMtvDcFtTnHCoioTlCQ4CkCMIQzqywofEIyeHw+gJqeJc06oO/1fsW2De1PRQV1qmMJ
rubn521xcdFHg3C2eQZtyqYdVLX+Cx9R6XLz8/N93T4JFKDNAqaxTwmm1S8LAxvsHvuBZwpB8AFB
xcjP/qA1jvr3IL8prJnTDrUK7BEQUyeq9cY6gB17oz4znTxnZmacuYGdDPXCQ2TQmj5JJowNoK2n
2UhEokStmh3TjSE3/hS3eG/RDY5yRinQdQjqhHbV6vW+NVjgYJoNPuwPFdaKwwyqAgoCJY7P1faa
UIa4Xy3ejWpbH3bTwfEKD7YWn6qoIsZ4PHdt33PIXUY6fO/qXJJF0CYwodIF9QIloo6M9xh+tiqz
X0MUCeXvUeuTTCZtamrKEWmQQqVShgGcnkH2JI4ImRVFMzkfCjRoIwptSqP3/1uSKOSNL7pKmlnf
fuj1el6QnEgknHoFyggSro4cs5rComX9fLLjzEdhD0d1TAyzCCCaOBxmN91Gla4cGmPdQ6NG7EPj
anZT12X2LZAFCSVThgNAUxJdKw32tQ5TARGu81sMvn5LwnvhnGshvu5L6knZv9fX3+aJQbMnm6Jf
2tAHMCYEHcx+W7og9JPQX2QINYDBfgBmqQ3Waz3V83F9BRvUJ9TmFJR54Isg6lfou3kKHRBF0Q6p
iSQPGGmBHtVn0M6zBAlRAadZP6CumTD11fATyMzBBgj9zSg9pqUn4TM/t0T5KI99l8rWwO7QlAe/
mNiCc65BGP6UvleuoX9XGzbqfefr8FtSMLHEEkssscQSSyyxxBJLLL93GTxJLpZYYoklllhiiSWW
WGKJJZaRSxyExRJLLLHEEkssscQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJLLLHEEkss
scQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKPEQVgsscQSSyyx
xBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJLLLHE
EkssscQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKPEQVgsscQS
SyyxxBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJL
LLHEEkssscQSSyyxPKPEQVgsscQSSyyxxBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKPEQVgs
scQSSyyxxBJLLLHEEsszShyExRJLLLHEEkssscQSSyyxPKP8P1FhT5WvXKEnAAAAAElFTkSuQmCC
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-3_1"&gt;Problem 3&lt;a class="anchor-link" href="#Problem-3"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;We expect the data to be balanced across classes.&lt;br/&gt;
By problem 2 above, we already see the data is balanced in test set, verify data is balanced in train data as well&lt;/p&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_datasets&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Number of samples in &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Number of samples in ./datasets/notMNIST_large/A.pickle: 52909
Number of samples in ./datasets/notMNIST_large/B.pickle: 52911
Number of samples in ./datasets/notMNIST_large/C.pickle: 52912
Number of samples in ./datasets/notMNIST_large/D.pickle: 52911
Number of samples in ./datasets/notMNIST_large/E.pickle: 52912
Number of samples in ./datasets/notMNIST_large/F.pickle: 52912
Number of samples in ./datasets/notMNIST_large/G.pickle: 52912
Number of samples in ./datasets/notMNIST_large/H.pickle: 52912
Number of samples in ./datasets/notMNIST_large/I.pickle: 52912
Number of samples in ./datasets/notMNIST_large/J.pickle: 52911
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Merge-seperate-character-dataset-together-(for-all-training/test/valid)"&gt;Merge seperate character dataset together (for all training/test/valid)&lt;a class="anchor-link" href="#Merge-seperate-character-dataset-together-(for-all-training/test/valid)"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Merge and prune the training data as needed. Depending on your computer setup, you might not be able to fit it all in memory, and you can tune &lt;code&gt;train_size&lt;/code&gt; as needed. The labels will be stored into a separate array of &lt;strong&gt;integers 0 through 9.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Also create a validation dataset for hyperparameter tuning.&lt;/p&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why we need vaild/test set? Our goal is to make sure the model we train can generalize to brand-new data. If we only divide the whole dataset into training/test set and try to get the best model by tuning parameters on test set, chances are that we actully give the model 'hints' on training set by our eyes. Because eventually, the best model will use the parameters incorporating our knowledge about training dataset, and when the very brand-new data comes, our model can't actually generalize to it and make wrong predictions. So we have to use vaild/dev set to tune our model, and only test the performance on test set to simulate model's 'real-world' performance after deploying it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_arrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;nb_rows&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;nb_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ndarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nb_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;merge_datasets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_files&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;num_classes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_files&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_arrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_arrays&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;image_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;vsize_per_class&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;num_classes&lt;/span&gt;
  &lt;span class="n"&gt;tsize_per_class&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_size&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;num_classes&lt;/span&gt;
    
  &lt;span class="n"&gt;start_v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;start_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="n"&gt;end_v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;end_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vsize_per_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tsize_per_class&lt;/span&gt;
  &lt;span class="n"&gt;end_l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vsize_per_class&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;tsize_per_class&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_files&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;       
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'rb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;letter_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# let's shuffle the letters to have random validation and training set&lt;/span&gt;
        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;letter_set&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
          &lt;span class="n"&gt;valid_letter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;letter_set&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;vsize_per_class&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
          &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_v&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_letter&lt;/span&gt;
          &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_v&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_v&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;
          &lt;span class="n"&gt;start_v&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;vsize_per_class&lt;/span&gt;
          &lt;span class="n"&gt;end_v&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;vsize_per_class&lt;/span&gt;
                    
        &lt;span class="n"&gt;train_letter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;letter_set&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;vsize_per_class&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_l&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
        &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_letter&lt;/span&gt;
        &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;start_t&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;end_t&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;
        &lt;span class="n"&gt;start_t&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tsize_per_class&lt;/span&gt;
        &lt;span class="n"&gt;end_t&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;tsize_per_class&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Unable to process data from'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="k"&gt;raise&lt;/span&gt;
    
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;
            
            
&lt;span class="n"&gt;train_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;200000&lt;/span&gt;
&lt;span class="n"&gt;valid_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;
&lt;span class="n"&gt;test_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;

&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;merge_datasets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="n"&gt;train_datasets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;merge_datasets&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_datasets&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Validation:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Testing:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training: (200000, 28, 28) (200000,)
Validation: (10000, 28, 28) (10000,)
Testing: (10000, 28, 28) (10000,)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Randomize-data"&gt;Randomize data&lt;a class="anchor-link" href="#Randomize-data"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Next, we'll randomize the data. It's important to have the labels well shuffled for the training and test distributions to match. The purpose of randomizing data is to perserve the assumption that we get the data randomly as predict phase. We don't want to train models sequantially on training instances like AAA ... BBB ... CCC.&lt;/p&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;train set and test set should apply the same shuffle &lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;shuffled_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;,:,:]&lt;/span&gt;
&lt;span class="n"&gt;shuffled_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;Although we do only one randomization here, we may do it multiple times when we are going to use the same dataset many times.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;randomize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;permutation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;shuffled_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;,:,:]&lt;/span&gt;
    &lt;span class="n"&gt;shuffled_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;permutation&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;shuffled_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shuffled_labels&lt;/span&gt;
&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;randomize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;randomize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;randomize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-4---Sanity-check-after-shuffling-dataset"&gt;Problem 4 - Sanity check after shuffling dataset&lt;a class="anchor-link" href="#Problem-4---Sanity-check-after-shuffling-dataset"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Convince yourself that the data is still good after shuffling!&lt;br/&gt;
Randomly sample data instances to make sure X is corresponding to y for both training and test set after shuffling.&lt;br/&gt;
Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;label is start from 0 to 9 for A to J&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;lookup_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s1"&gt;'ABCDEFGHIJ'&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sanity_check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;m1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;m2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# randomly choose 10 images to check label&lt;/span&gt;
    &lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;m1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:],&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lookup_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
        &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'off'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
&lt;span class="n"&gt;sanity_check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Training dataset:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training dataset:
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAAByCAYAAADaptmXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sanity_check&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Test dataset:'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Test dataset:
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA2EAAAByCAYAAADaptmXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Serialize-dataset-for-later-usage"&gt;Serialize dataset for later usage&lt;a class="anchor-link" href="#Serialize-dataset-for-later-usage"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Everything looks good, finally, let's save the data for later reuse:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'notMNIST.pickle'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'wb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'train_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'train_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'valid_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'valid_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'test_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'test_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HIGHEST_PROTOCOL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Unable to save data to'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;statinfo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Compressed pickle size:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Compressed pickle size: 690800503
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-5---Remove-overlapping-samples-in-test/valid-set"&gt;Problem 5 - Remove overlapping samples in test/valid set&lt;a class="anchor-link" href="#Problem-5---Remove-overlapping-samples-in-test/valid-set"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;By construction, this dataset might contain a lot of overlapping samples, including training data that's also contained in the validation and test set! Overlap between training and test can skew the results if you expect to use your model in an environment where there is &lt;strong&gt;never&lt;/strong&gt; an overlap, but are actually ok if you expect to see training samples recur when you use it.
Measure how much overlap there is between training, validation and test samples.&lt;/p&gt;
&lt;p&gt;Optional questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What about near duplicates between datasets? (images that are almost identical)&lt;/li&gt;
&lt;li&gt;Create a sanitized validation and test set, and compare your accuracy on those in subsequent assignments.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Find-duplicate-images-in-test-set"&gt;Find duplicate images in test set&lt;a class="anchor-link" href="#Find-duplicate-images-in-test-set"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;I used Cosine Similarity to measure whether image A in training set is identical to those image B in valid/test set.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/cosine_sim.png" width="50%"/&gt;&lt;/p&gt;
&lt;p&gt;As formula suggested, I reshape every image in training set into column vectors, and do the same for images in valid/test set and compute similarity between the vectors. Although we can compute cosine similarity for every (train image vector, test image vector) explicitly, it's better to use vectorization to speed up computation since that we have 200,000 training images and 10,000 valid/test images. (Although it still take about 10 minutes to run in my computer)&lt;/p&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vectorize both training/test images and compute cosine similarity using &lt;code&gt;cosine_sim = np.inner(X, Y) / np.inner(np.abs(X), np.abs(Y))&lt;/code&gt;. The output matrix cosine_sim will be shape (m1, m2) where m1 is the number of training images and m2 the number of test images. cosine_matrix(i, j) mean the cosine similarity between training image #i and test image #j.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
def get_duplicate_data(source_dataset, target_dataset, threshold=1, num_duplicate_to_show=0):
    X = source_dataset.reshape(source_dataset.shape[0], -1)
    Y = target_dataset.reshape(target_dataset.shape[0], -1)
    assert(X.shape[1] == Y.shape[1])
    
    dim = X.shape[1]
    cosine_sim = np.inner(X, Y) / np.inner(np.abs(X), np.abs(Y))
    assert(cosine_sim.shape == (X.shape[0], Y.shape[0]))
    
    # for each image in training set, find corresponding duplicate in test/valid set
    dup_target_indices = []
    show_duplicate_counter = 0
    for source_idx in range(cosine_sim.shape[0]):
        dup_indices = list(np.where(cosine_sim[source_idx, :] &amp;gt;= threshold)[0])
    
        # render duplicate images when is available. may omit if visual output is not required
        if dup_indices and num_duplicate_to_show and (show_duplicate_counter &amp;lt; num_duplicate_to_show):
            # show only non-redudent duplicate images
            for i in dup_indices:
                if i in dup_target_indices:
                    dup_indices.remove(i)
            if not dup_indices: continue
            
            if len(dup_indices) == 1:
            
                fig = plt.figure(figsize=(3, 15))
                fig.add_subplot(1, len(dup_indices) + 1, 1)
                plt.imshow(source_dataset[source_idx, :, :], cmap='gray')
                plt.title('Source: ' + str(source_idx))
                plt.axis('off')
            
            
                for i, target_idx in enumerate(dup_indices):
                    fig.add_subplot(1, len(dup_indices) + 1, i + 2)
                    plt.imshow(target_dataset[target_idx, :, :], cmap='gray')
                    plt.title('Target: ' + str(target_idx))
                    plt.axis('off')

                show_duplicate_counter += 1
        
        dup_target_indices.extend(dup_indices)
    return list(set(dup_target_indices))
        
    
dup_indices_test = get_duplicate_data(train_dataset, test_dataset, num_duplicate_to_show=5)
print('Number of duplicates in test dataset: {}'.format(len(dup_indices_test)))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Number of duplicates in test dataset: 1768
CPU times: user 5min 11s, sys: 4min 17s, total: 9min 29s
Wall time: 7min 40s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz
AAALEgAACxIB0t1+/AAADPhJREFUeJztnX+QJGdZxz/fmbmZ3Z3MZH/ewrGye7eJqUtdrAsIieGX
gnVEOAv+UFAoSYESQKCCCaIFiAUif4iVP4JSKbWCgqJYwSJyWiZVSmkK4yUQygsuJGbvciZ4JHe7
l7vsrbeb2Xn8o9+e652bnd253ZntGZ5P1dZ2P/12v8/7dn/7fZ63e2ZkZjiOA5ntdsBx0oKLwXEC
LgbHCbgYHCfgYnCcgIvBcQK5TlYm6X2AgAFgt5m9v5P1bxZJrwKuJbqJ7DCzzwb7LwEvBPLAQ2b2
L8H+NWCYqM2LZvb6Nvt3E/A6YBHYEfz8hpl9sZ31bhWSXgP8JfAIUZ/tBl4GvKSR3cyek/Q7wIlg
+7yZ/SAc63rgpcAgcJeZnVjXATPryB9wGXB3Yv3OTtW9hW34p8TyXwCTRBf7PQn7lxLLn+iwf+8A
ysBNwM1h+R0drP89m9z/NeEij9d/ax37QeC3E9fXHyfK/Hn4PwD80Ubq73SYNJxY/nSzgpKuD3c6
JF0j6YOJbRlJ+Tb52BRJxbC4BBSBK4DZRJHTkibi4p30Dfi6mZ2NV8Ly15vtsFV9KenlwHs2eZhn
gO+G4/0c8I117FcDMwBmtgBMhDJXAz8M9kXgxRupvGNiCM7+h6Q/kJQzs6fibZJ+VtJHJN0q6XXB
/C3gDWH5u0R3h5g3AbdLeq+kb0u6JhxnQtLtkm6W9OnE8a8K9X5A0juTfkn6kKR/2GAbbjSzc5IG
gGkzmwEeBa6RlA3FXgjsCss5Sb8s6eOSbthIHZvBzE6vZZP04dBfn5C0O1Fkrb781fD3UUl/KOmr
wf4KSZ+S9JuS3pg4zh7grKS3Sdqf9EHS30n6yAb8/56Z/V9YfaOZPdjMDhwGXhvquBy4Mth/HPjf
xKEXJY2tV/92hBo3A/8KTIT1PHAosf3vieJxiGI96pfD+n8CQ0TxZDHY/goYC8v3Jex/A/SH5S8C
lyeO8yrgnS224XeBn0qsvyzY3gX8KfDyYH8vUV6WJbqbjXSoj28Cbq6zfTP4MQx8pllfEoVXt4dt
Cm3aGdaTIeE9dce5aw1/fg24oQX/B4HPbcQOvA24DfgF4HCwvZ1EyEYU0u5Zr96OJtAAZvYnkr4F
fBl4NdFQdzRR5DiwFzhC8zDj2xbd9ZJ3w0kzOxnqOZCw7wV+XpKA/wFGgDOh3P3A/Rv1X9JLgKfN
7IFEmx4CHgrbXw3MBfudif3+EXglcM9G69pifgZ4K5Egxuu2repLSTng8rBtCJg3s2ckDQEvkPQW
onMzK6lkZs81q9jM/qxFXw8SJcvr2s3sy/GypA+FxeeAnYliA8HWlI6FSZL2SXopgJk9DJyStAsw
oJosSnTCLoW13jpcNLO/NbOvmNnHzezoGuWaIqkA3Bhf5JLGw/8PSor78sXAE8H+1sTumSb+tRVJ
O4C/Br5pZl9inVzGzCrAyRBSvgn4ZNhUJRJG3Je3rieES+SnCblAM7uksqR3xcvAfNh0jNWCLwCn
1qu0kwl0lmj4jskDzwLfJ5qViZnigvpXEvbLWU2jE/qMpB8DkDQt6UXB/pSkqWB/ZSIJRtJ1kt69
wTbcBNwR9hskutsC/DqQD3XPmtmKpBKrJwmuJwpVOkWyf64GnjKz4yHfUfjfqGwsnp8kOkePEc6D
mZ0BCqFtSLqxYcXSnrr1Xwkj5kbZx4ULu5l9EnhzWH4DcHfw8xEuJNNF4IcW4qVmdDpMOi/pFqJp
sK9alOkj6fOSPkwkzjvDnQng/nChLgBlSTeY2b9L+kVgv6TdZnYscfzbgE9KehR4xsy+EOy3Ap+S
9H3gcTM7l9jntcAriOLiNZE0AtwCvDmEW9NcuNh/H3g3URL5UQCL5sA/K+k3iIT8FTOba6m3LgFJ
w8CNQJ+ku0OdjwJDYU5+HigBB4CvrdGX08A/A98jeq7yGUnvs2jC4BbgDkkzwHfqqv8vSZ8jyteS
o+/bw/H+bYPNOA/8YD27mT0i6bCk9wMvAj6WKHuXpI+FtjaduYzRBgSTCiTtMLPnt9uPHwUkfYAo
pPpOWH8L8AIzu2N7PWsvXSMGp3OEUfA24L+JRuufAH7PzNaNu7sZF4PjBPxFPccJuBgcJ+BicJxA
u6ZWVyUidY/PkYQk5ubmePrpp3nyySe57777uPfee5mZmaltT+6bNhr5uG/fPg4cOMCBAweYmJhg
fHyckZGRhm2P900echPuNOzvpK8AZ8+e5fTp05w4cYJDhw5x6NAhjhw5solqt5f9+/dz8OBBDh48
yPj4OENDQ5TLZYBV/Z38n+Aig48MjhNwMThOwMXQozQIC5x1cDH0KGnMs9KOi8FxAi4Gxwm4GHoU
zxlax8XQo3jO0DouBscJuBh6FA+TWsfF0KN4mNQ6LgbHCbgYHCfgYuhRPGdoHRdDj+I5Q+u4GBwn
4GJwnICLoUfxnKF1XAw9iucMreNicJyAi6FH8TCpdVwMPYqHSa3T8R8rcdJHN44i7RC7i8EBLnyf
U5pHlNi/dvmYqjCpG+9QaaXVvmzyZVupoBP+pXJkWOMb51JFvY/132C33f63eveMy6d1ZDCztvdp
KsTQqJHbfTGtR/3XSybt3UbS/7SKIUm7fEyFGLrhBPQCkshkMuRyOfr6+iiVSgwODta2xaTxfDTy
r1Qq0dfXRzabJZPJbPpGlAoxNCI5bKfx5KxFWnxtlAxLIpfLkc/nKZfLjI2NsWvXrppIID3+NyKZ
QJsZY2NjlEol8vk8uVyu1oZLJVViaBS3doMY6v1Lg8+N6s9kMmSz2VViWFhYIJPJbPpC6iTVapVq
tcrY2Bjlcpl8Pk82m+2+kSEZa+dyOQYGBhgcHGRqaoprr72WwcHBVUNeGi6sRtTnDNVqlT179jA1
NcXg4CADAwPs2LGjVjYu10n/6uvLZrMUCgVKpRKTk5MsLS0xMTGxamTotJ8bJXmhV6tVzIzx8XEm
Jydr4VIut7nLuWNiaKTafD5PsVhkdHSUq666imw2yxVXXFETQ7vnlTdDvX/VapWdO3cyPT3N6Ogo
l112WU0M9ft00sfkcpwrZLNZpqenGRoaYnFxsWuT/mKxWPtNhnh0iLmUNrXrBw4v+vGMRlQqFZaX
l1laWmJ+fp75+XnOnTt30bCdVjHExMN2sVhkeHiY4eFhCoVCLZZdb//YtAl3NtxBaezLrSC+MbUg
gosKbmvOEN+tzIxSqUQmk6FcLqdinr4V4tEhHukKhcKWJHRbTaMp1G4WR/JB3Fa0Y1vFEIdDcWLX
399PtVoFumu+Pj4R2WyWXC5XE8JabUhD29IafrZCPBJsVX92JExyNkTbw6T66epuF0QshOQI3LVh
krM91CfW3cxW+u9i+BGl2/KyTtARMaw1FCenJSuVCpVKpZYzdCPxqw7JnCFt713F52JlZaU2C9aI
ZFJan6A2W+9UWaA26xhPqXbdQ7cYSaysrLCyskKlUuHcuXMsLCywvLzcdXetWNSFQoFisUixWFwl
ikZPqLejfcmbz9LSEsvLy1QqlY77sVXEr5YUCoVa3rCZft02McQnplKpsLS0xNmzZ5mfn689BErb
tGQz4ieiAwMDrKys1J4tpO01h+QovLS0xOLiIsvLy9vt1iWTz+cxs1X9vRk6Kob6X21//vnnWVxc
5MyZM8zOzjI7O8upU6e66sUxuCCGsbExpqenkVR7XhKfqPq2t5NmDzljERw/fpzjx48zNzfXdn/a
xcjICJOTk0xNTdHf309fX9+agthIv3dMDPFIkHRqeXmZhYUF5ubmeOyxx3jwwQd54oknLhJDGgWR
DOViMezevZuVlZXa+1X5fJ7+/v7aPp0URKP6KpUKi4uLzM/PMzMzw+HDhzl69GhXhaQxZsb09DTX
XXcd5XKZ4eFhstls7RWYS+nrjodJSSfjk3P69GmOHTvGww8/zMzMzEUvwaVdDLGPzz77LGNjY1x5
5ZUUi0VKpdKq7Z2kUX2VSoXz589z5swZHn/8cR544AGOHDnSUb+2kpMnTzI6OsrevXtrI8NmSNXU
avLxetrvVmn/2KfTOqkSQ5K0X0y99LFPJyIVUx1+AW093qetk4qRoVF86x/73Bxp8aObSIUY6vGP
fTrbQSrCpBi/gJztJFVicLYOzxlax8XQo/go2zouBscJuBh6FA+TWsfF0KN4mNQ6LgbHCbgYHCfg
YuhRPGdoHRdDj+I5Q+u4GBwn4GJwnICLoUfxnKF1XAw9iucMreNicJyAi6FH8TCpdVwMPYqHSa3j
YnCcgIvBcQIuhh7Fc4bWcTH0KJ4ztI6LwXECLgbHCbgYehTPGVrHxdCjeM7QOi4Gxwm063egHafr
8JHBcQIuBscJuBgcJ+BicJyAi8FxAi4Gxwm4GBwn4GJwnICLwXECLgbHCbgYHCfgYnCcgIvBcQIu
BscJuBgcJ+BicJyAi8FxAi4Gxwm4GBwn4GJwnMD/A0dGWk7q6LhuAAAAAElFTkSuQmCC
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Duplicate-images-in-validation-set"&gt;Duplicate images in validation set&lt;a class="anchor-link" href="#Duplicate-images-in-validation-set"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
dup_indices_valid = get_duplicate_data(train_dataset, valid_dataset, num_duplicate_to_show=5)
print('Number of duplicates in validation dataset: {}'.format(len(dup_indices_valid)))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Number of duplicates in validation dataset: 1507
CPU times: user 7min 52s, sys: 5min 7s, total: 12min 59s
Wall time: 8min 57s
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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==
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMMAAAB3CAYAAAC+JPTJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Serialize-sanitized-dataset-for-later-model-performance-comparison"&gt;Serialize sanitized dataset for later model performance comparison&lt;a class="anchor-link" href="#Serialize-sanitized-dataset-for-later-model-performance-comparison"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Remove duplicates in test/valid set&lt;/li&gt;
&lt;li&gt;Save dataset&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Keypoints:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do the same operation to both X and y&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Number of duplicate images in test set: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dup_indices_test&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Number of duplicate images in valid set: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dup_indices_valid&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Number of duplicate images in test set: 1768
Number of duplicate images in valid set: 1507
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dup_indices_test&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sanitized_test_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;sanitized_test_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dup_indices_valid&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;sanitized_valid_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;sanitized_valid_labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;valid_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;non_duplicate_indices&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data_root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'notMNIST_sanitized.pickle'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'wb'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;save&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'train_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'train_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'valid_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sanitized_valid_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'valid_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sanitized_valid_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'test_dataset'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sanitized_test_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'test_labels'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;sanitized_test_labels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;HIGHEST_PROTOCOL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Unable to save data to'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;':'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;statinfo&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Compressed pickle size:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;statinfo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;st_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Compressed pickle size: 680517003
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;hr/&gt;
&lt;h2 id="Problem-6---Build-naive-classifier-using-logistic-regression_1"&gt;Problem 6 - Build naive classifier using logistic regression&lt;a class="anchor-link" href="#Problem-6---Build-naive-classifier-using-logistic-regression"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let's get an idea of what an off-the-shelf classifier can give you on this data. It's always good to check that there is something to learn, and that it's a problem that is not so trivial that a canned solution solves it.&lt;/p&gt;
&lt;p&gt;Train a simple model on this data using 50, 100, 1000 and 5000 training samples. Hint: you can use the LogisticRegression model from sklearn.linear_model.&lt;/p&gt;
&lt;p&gt;Optional question: train an off-the-shelf model on all the data!&lt;/p&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LogisticRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.metrics&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'ggplot'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_sizes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# train models using different size of training set&lt;/span&gt;
&lt;span class="n"&gt;test_scores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_scores_sanitized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[[]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;train_size&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_sizes&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# random choose #train_size of training instances&lt;/span&gt;
    &lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;train_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# reshape images to (train_size, dim * dim) for easier processing&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;\
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_labels&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        
    &lt;span class="c1"&gt;# train model&lt;/span&gt;
    &lt;span class="n"&gt;clf&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;LogisticRegression&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;solver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'lbfgs'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;multi_class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'multinomial'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
    &lt;span class="c1"&gt;# test on original test set and the sanitized one&lt;/span&gt;
    &lt;span class="n"&gt;y_pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;y_pred_sanitized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;clf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sanitized_test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sanitized_test_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

    &lt;span class="n"&gt;test_score&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_score_sanitized&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;accuracy_score&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_pred_sanitized&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sanitized_test_labels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_scores&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_score&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;test_scores_sanitized&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;test_score_sanitized&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    
    
&lt;span class="c1"&gt;#     print(classification_report(test_labels, y_pred))&lt;/span&gt;
&lt;span class="c1"&gt;#     print(accuracy_score(test_labels, y_pred))&lt;/span&gt;

    
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Training size'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Accuracy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_sizes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_scores&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{:.2f}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_sizes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_scores_sanitized&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{:.2f}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_sizes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_scores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Test score'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'blue'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_sizes&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test_scores_sanitized&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Test score(Sanitized)'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'red'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Test set Accuracy vs Training size'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAegAAAHZCAYAAABNdqgEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As show above, there are seveal things worth mentioning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Our model became better on classifiying labels in test set by using more data in training phase. By training a simple logistic regression model on all available training data, we can expect to get about 90% accuracy. &lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;There is a performance gap (2~3% on accuracy) between test set with duplicate images and the one without. Depends on our application, choose the one which best fit our use case.&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;Notice that we just want to have a off-the-shelf model quickly, so we don't even tune hyper-parameters using validation set. We may be able to further improve model's predictive performance by tuning hyper-parameters or using Neural Network in another notebook.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="Matplotlib"></category><category term="Data Preprocessing"></category><category term="Data Cleaning"></category><category term="NotMNIST"></category><category term="Sklearn"></category><category term="Machine Learning"></category><category term="Image Recognition"></category><category term="Udacity"></category></entry><entry><title>Purpose of this blog</title><link href="https://leemeng.tw/purpose-of-this-blog.html" rel="alternate"></link><published>2017-09-17T12:30:00+09:00</published><updated>2017-09-17T12:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-17:/purpose-of-this-blog.html</id><summary type="html">&lt;p&gt;第一篇文章做一點 blog 的簡介，打算把自己在學 data science 還有 machine learning 過程中寫的筆記還有在 MOOC 上課的 code (主要是 jupyter notebook) 記錄下來方便自己以後搜尋。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一篇文章做一點 blog 的簡介，打算把自己在學 data science 還有 machine learning 過程中寫的筆記還有在 MOOC 上課的 code (主要是 jupyter notebook) 記錄下來方便自己以後搜尋。 雖然目前為止我都將 jupyter notebook render 成 HTML 然後存到 Evernote 搜尋, 但是如果該 notebook 一直更新的話就變得很不實際..&lt;/p&gt;
&lt;p&gt;&amp;lt;/br&amp;gt;
這次利用 python 的 pelican 將 jupyter notebook 轉成靜態網頁, 讓我可以不斷更新 notebooks 而且也希望 code 可以幫助到其他也在做 data science / machine learning 的人當作一些參考。 blog 的走向目前看來應該會是中英夾雜 ..&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is the first post of my blog.&lt;/p&gt;
&lt;p&gt;&amp;lt;/br&amp;gt;
I decided to record my learning path toward data scientist / machine learning engineer and make it easier for my future self to review what I have learnt. This blog will include codes from the courses on MOOC like Coursera, Udacity and also some pet projects. It would also be wonderful if these code and thought can help someone who want to become a data scientist.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="pelican"></category><category term="資料科學"></category><category term="blogging"></category></entry></feed>