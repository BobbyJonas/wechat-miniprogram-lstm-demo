<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>LeeMeng - Miscellaneous</title><link href="https://leemeng.tw/" rel="alternate"></link><link href="https://leemeng.tw/feeds/miscellaneous.atom.xml" rel="self"></link><id>https://leemeng.tw/</id><updated>2019-06-17T05:40:00+09:00</updated><entry><title>淺談神經機器翻譯 &amp; 用 Transformer 與 TensorFlow 2 英翻中</title><link href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html" rel="alternate"></link><published>2019-06-17T05:40:00+09:00</published><updated>2019-06-17T05:40:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-06-17:/neural-machine-translation-with-transformer-and-tensorflow2.html</id><summary type="html">&lt;p&gt;本文分為兩大部分。前半將帶讀者簡單回顧 Seq2Seq 模型、自注意力機制以及 Transformer 等近年在機器翻譯領域裡頭的重要發展與概念；後半段則將帶著讀者實作一個可以將英文句子翻譯成中文的 Transformer。透過瞭解其背後運作原理，讀者將能把類似的概念應用到如圖像描述、閱讀理解以及語音辨識等各式各樣的機器學習任務之上。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;style&gt;
   pre {
      overflow-x: auto;
      word-wrap: break-word;
   }
&lt;/style&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        那時，全世界的語言都一樣。人們說：『來吧，我們要建一座塔，塔頂通天，為了揚我們的名，免得我們被分散到世界各地。』耶和華說：『看哪！他們成爲一樣的人民、用同樣的語言。如今既蓋起塔來，以後就沒有他們無法完成的事情了。我們下去！在那裏變亂他們的口音，使他們的言語彼此不通。』
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ 《創世記》第十一章&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是聖經中著名的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B7%B4%E5%88%A5%E5%A1%94"&gt;巴別塔&lt;/a&gt;橋段，用來解釋為何當今世上有那麼多種語言。當年的上帝或許過於杞人憂天，但近年多虧了&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;，&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"&gt;機器翻譯&lt;/a&gt;的快速發展讓人不禁覺得，或許巴別塔很快就不再只是虛幻傳說了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/google-translate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/google-translate.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        以往被視為非常困難的中 -&amp;gt; 英翻譯如今在深度學習的加持下也有不錯的水準
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器翻譯的研究之所以如此重要且迷人，是因為它將有機會讓未來任何人都不受語言的限制，獲得世界上任何他或她想要的資訊與知識。&lt;/p&gt;
&lt;p&gt;在這篇文章的前半部分，我們會先花點時間來回顧&lt;a href="https://en.wikipedia.org/wiki/Neural_machine_translation"&gt;神經機器翻譯&lt;/a&gt;裡頭的一些重要概念。接著在具備這些概念以及&lt;a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA"&gt;其他背景知識&lt;/a&gt;的前提之下，利用最新的 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow 2&lt;/a&gt; 來實作一個可以將英文句子翻譯成中文的神經網路架構：&lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer"&gt;Transformer&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-high-level-view.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Transformer 將法文句子翻譯成英文
                        （&lt;a href="http://jalammar.github.io/illustrated-transformer/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是一個非常簡化的示意圖。Transformer 實際上是一種基於自注意力機制的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=3208"&gt;Seq2Seq 模型&lt;/a&gt;，近年在&lt;a href="https://paperswithcode.com/task/image-captioning"&gt;圖像描述&lt;/a&gt;、&lt;a href="https://zh.wikipedia.org/wiki/%E8%81%8A%E5%A4%A9%E6%A9%9F%E5%99%A8%E4%BA%BA"&gt;聊天機器人&lt;/a&gt;、&lt;a href="https://zh.wikipedia.org/zh-hant/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB"&gt;語音辨識&lt;/a&gt;以及機器翻譯等各大領域大發異彩。但因為其相對複雜，到現在還是有種現象：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        了解 Transformer 相關技術的人已經用了好一陣子且用得很開心，不知道的人還是不知道。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這並不僅限於 Transformer，因為深度學習牽涉的研究範圍實在太廣了。透過這篇文章，我希望能幫助你開始了解神經機器翻譯以及 Transformer 的相關知識。&lt;/p&gt;
&lt;p&gt;當我們完成實作並訓練出一個 Transformer 以後，除了可以英翻中以外，我們還能清楚地了解其是如何利用強大的&lt;a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;amp;feature=youtu.be"&gt;注意力機制&lt;/a&gt;（我們在 &lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;Encoder-Decoder 模型 + 注意力機制&lt;/a&gt;一節會仔細探討此概念）來做到精準且自然的翻譯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Transformer 在將英文句子翻譯成中文時會「關注」需要注意的英文詞彙來生成對應的中文字詞
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了翻譯出來的中文正確無誤以外，從上圖你可以發現很有趣的現象。&lt;/p&gt;
&lt;p&gt;給定左側的英文，Transformer 在生成其對應的中文翻譯時都會給每個英文詞彙不同的「注意程度」。小方格越亮則代表模型在生成某中文字時放越多的注意力在左側對應的英文詞彙上。&lt;/p&gt;
&lt;p&gt;仔細看你會發現這個已經訓練好的 Transformer 在翻譯：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「必」、「須」時會關注「must」&lt;/li&gt;
&lt;li&gt;「希」、「望」時會關注「hope」&lt;/li&gt;
&lt;li&gt;「公」、「民」時會關注「citizens」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;乍看之下好像稀鬆平常，但事實上我們在訓練模型時並不會告訴它這些詞彙之間的對應關係或是任何語言學的知識。我們就只是餵給它多組相同意思的中英句子，並讓它自己學會怎麼做翻譯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        好黑魔法，不學嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在英翻中的情境下，神經網路要做的事情就是讀入左側的英文句子，接著生成右側的中文句子（繁中對英文的翻譯資料集稀少，此文將以簡體為例）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-zh-training-sentences.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        訓練資料是多組相同語義的成對中英句子（當然仍需前處理）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一些你需先具備的基礎知識"&gt;一些你需先具備的基礎知識&lt;a class="anchor-link" href="#一些你需先具備的基礎知識"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我在文中會盡量言簡意賅地介紹所有你需要了解的深度學習概念，並附上相關連結供你參考。但就像在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;天龍八部&lt;/a&gt;或是眾多武俠小說都有提過的重要準則：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        武功修習有先後順序，勿求一步登天。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管在 &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;2017 年就已被提出&lt;/a&gt;，本文即將探討並實作的 &lt;a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf"&gt;Transformer&lt;/a&gt; 仍算是相當進階的神經網路架構。因此具備以下的基礎知識能幫助你更順利地理解本文內容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一點點&lt;a href="https://demo.leemeng.tw/"&gt;卷積神經網路&lt;/a&gt;的概念&lt;/li&gt;
&lt;li&gt;清楚理解&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;循環神經網路&lt;/a&gt;的運算方式&lt;/li&gt;
&lt;li&gt;基本的&lt;a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/"&gt;自然語言處理&lt;/a&gt;知識&lt;/li&gt;
&lt;li&gt;基本的&lt;a href="https://youtu.be/uUrt8xgdMbs?list=PLJV_el3uVTsNmr39gwbyV-0KjULUsN7fW"&gt;線性代數&lt;/a&gt;如矩陣相乘運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/nlp-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        中研院這篇文章清楚地說明了自然語言處理在中文上的研究與應用
                        （圖片來源：&lt;a href="http://research.sinica.edu.tw/nlp-natural-language-processing-chinese-knowledge-information/" target="_blank"&gt;研之有物&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望這樣的要求沒把你嚇跑，因為事實上你大約需要好幾倍的相關知識來成功實作 Transformer。&lt;a href="#%E5%B8%AB%E5%82%85%E5%BC%95%E9%80%B2%E9%96%80%EF%BC%8C%E4%BF%AE%E8%A1%8C%E5%9C%A8%E5%80%8B%E4%BA%BA"&gt;儘管在實作前你會看到一些額外要求&lt;/a&gt;，本文的前半部分還是相當平易近人的，還請放心閱讀。&lt;/p&gt;
&lt;p&gt;當你想要深入了解某些細節的時候，可以參考這節附上的連結或是文內說明概念時附上的圖片來源。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        想更深入了解文中講述的各種概念，點擊相關的「圖片來源」就對了。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前言很長，但好戲才在後頭。如果你已經準備好進入神經機器翻譯的世界的話，現在就讓我們正式開始這趟旅程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器翻譯近代史"&gt;機器翻譯近代史&lt;a class="anchor-link" href="#機器翻譯近代史"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;鑑往知來。了解一點機器翻譯的歷史以及 Transformer 是怎麼跑出來的會對實作很有幫助。&lt;/p&gt;
&lt;p&gt;機器翻譯（&lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;T&lt;/strong&gt;ranslation）本身的概念&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E6%AD%B7%E5%8F%B2"&gt;最早可追溯到 17 世紀&lt;/a&gt;。自從那開始，人們嘗試並研究了各式各樣的方法，寫了一大堆規則、蒐集了數以萬計的翻譯結果來嘗試自動化翻譯。隨著時代演進，我們有了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基於規則的機器翻譯 RBMT&lt;/li&gt;
&lt;li&gt;基於範例的機器翻譯 EBMT&lt;/li&gt;
&lt;li&gt;統計機器翻譯 SMT&lt;/li&gt;
&lt;li&gt;近年的神經機器翻譯 NMT&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/mt-history.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        近代機器翻譯發展簡史
                        （&lt;a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多遠古時代的東西我們不會討論，而 NMT 當然是本文的重點。不過在那之前讓我們非常簡短地看一下 SMT。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="統計機器翻譯：基於短語的翻譯"&gt;統計機器翻譯：基於短語的翻譯&lt;a class="anchor-link" href="#統計機器翻譯：基於短語的翻譯"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器翻譯的歷史很長，但一直要到 21 世紀初期&lt;a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91"&gt;統計機器翻譯（&lt;strong&gt;S&lt;/strong&gt;tatistical &lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;T&lt;/strong&gt;ranslation，簡稱 SMT）&lt;/a&gt;技術成熟以後，機器翻譯的品質才稍微使人滿意。其中最知名的例子當屬 &lt;a href="https://ai.googleblog.com/2006/04/statistical-machine-translation-live.html"&gt;Google 在 2006 年發布的 SMT 翻譯系統&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;不限於 Google，當時不少最先進的 SMT 系統都採用了&lt;a href="https://en.wikipedia.org/wiki/Statistical_machine_translation#Phrase-based_translation"&gt;基於短語的機器翻譯（Phrase-Based MT）&lt;/a&gt; 演算法。PBMT 最大的特色是先將來源語言（Source Language）的句子切成短語或是詞彙，接著大致上獨立地將這些詞彙翻譯成目標語言（Target Language）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/pbmt.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        基於短語的 SMT（Phrase-Based SMT）
                        （&lt;a href="https://www.freecodecamp.org/news/a-history-of-machine-translation-from-the-cold-war-to-deep-learning-f1d335ce8b5/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;PBMT 的翻譯結果相較於早年基於規則（Rule-Based）的手法已經進步很多，但仍然需要大量的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B9%B3%E8%A1%8C%E8%AF%AD%E6%96%99"&gt;平行語料&lt;/a&gt;、對齊語料來取得較好的結果。且因為是以短語為單位在做翻譯，這些短語拼湊出來的句子仍然不夠自然。&lt;/p&gt;
&lt;p&gt;如果你跟我一樣有用過早年的 Google 翻譯，應該還能隱約記得當年那些充斥著「機械感」的翻譯結果。&lt;/p&gt;
&lt;p&gt;（如果你有當年 Google 翻譯結果的截圖的話歡迎提供）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="神經機器翻譯：Encoder-Decoder-模型"&gt;神經機器翻譯：Encoder-Decoder 模型&lt;a class="anchor-link" href="#神經機器翻譯：Encoder-Decoder-模型"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;顧名思義，神經機器翻譯 NMT 即代表使用&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;類神經網路（Neural Network）&lt;/a&gt;來做機器翻譯。&lt;/p&gt;
&lt;p&gt;不管是英文、法文還是中文，一個自然語言的句子基本上可以被視為一個有時間順序的序列數據（Sequence Data）。而&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1"&gt;我們曾提過 RNN 很適合用來處理有時間關係的序列數據&lt;/a&gt;。給定一個向量序列，RNN 就是回傳一個一樣長度的向量序列作為輸出。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 很適合拿來處理具有時間順序的序列數據（下方的詞在丟入 RNN 前會被轉成詞向量）
                        （&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當我們把來源語言以及目標語言的句子都視為一個獨立的序列以後，機器翻譯事實上就是一個&lt;a href="https://youtu.be/ZjfjPzXw6og"&gt;序列生成（Sequence Generation）&lt;/a&gt;任務：對一個輸入序列（來源語言）做些有意義的轉換與處理以後，輸出一個新的序列（目標語言）。&lt;/p&gt;
&lt;p&gt;而在深度學習時代，我們一般會使用以 RNN 為基礎的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=3208"&gt;Encoder-Decoder 架構（又被稱作 Sequence to Sequence / Seq2Seq 模型）&lt;/a&gt;來做序列生成：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-animate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-animate.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        一個以 RNN 為基礎的 Encoder-Decoder / Seq2Seq 模型將法文翻譯成英文的步驟
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Seq2Seq 模型裡頭 Encoder 跟 Decoder 是各自獨立的 RNN。Encoder 把輸入的句子做處理後所得到的隱狀態向量（圖中的 &lt;code&gt;Hidden State#3&lt;/code&gt;）交給 Decoder 來生成目標語言。&lt;/p&gt;
&lt;p&gt;你可以想像兩個語義相同的法英句子雖然使用的語言、語順不一樣，但因為它們有相同的語義，Encoder 在將整個&lt;strong&gt;法文&lt;/strong&gt;句子濃縮成一個嵌入空間（Embedding Space）中的向量後，Decoder 能利用隱含在該向量中的語義資訊來重新生成具有相同意涵的&lt;strong&gt;英文&lt;/strong&gt;句子。&lt;/p&gt;
&lt;p&gt;這樣的模型就像是在模擬人類做翻譯的&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91#%E7%BF%BB%E8%AD%AF%E6%B5%81%E7%A8%8B"&gt;兩個主要過程&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（Encoder）解譯來源文字的文意&lt;/li&gt;
&lt;li&gt;（Decoder）重新編譯該文意至目標語言&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然人類在做翻譯時有更多步驟、也會考慮更多東西，但 Seq2Seq 模型的表現已經很不錯了。&lt;/p&gt;
&lt;p&gt;有些人閱讀到這裡可能會問：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如果我們利用 Seq2Seq 模型將多種語言的句子都轉換到某個嵌入空間裡頭，該空間會長成什麼樣子呢？是相同語言的句子靠得比較近，還是不同語言但擁有同語義的句子會靠得比較近呢？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是一個很好的研究問題。&lt;/p&gt;
&lt;p&gt;而如果我們試著把這個問題圖像化，則結果可能長得像這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/multi-lang-emb.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        大哉問：神經網路將句子轉換完所形成的向量空間比較靠近左邊還是右邊？
                        （&lt;a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=1035" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;圖中的點代表不同句子，不同顏色則代表不同語言。如果結果是左邊，代表神經網路並沒有創出一個「語義」空間，而只是把不同語言都投射到該嵌入空間裡頭的不同位置，接著才在該空間裡進行不同語言之間的轉換（中轉英、英轉法 etc.）。&lt;/p&gt;
&lt;p&gt;我們比較想要的是右邊的情況：無關語言，只要句子的語義接近，彼此的距離就相近的語義空間。&lt;/p&gt;
&lt;p&gt;而 &lt;a href="https://aclweb.org/anthology/Q17-1024"&gt;Google 在 2016 年的研究結果&lt;/a&gt;發現，在此空間裡頭語言相異但擁有同語義的句子之間的距離 &lt;code&gt;d1&lt;/code&gt;，要比同語言但不同語義的句子之間的距離 &lt;code&gt;d2&lt;/code&gt; 要小得多（即  &lt;code&gt;d1 &amp;lt;&amp;lt; d2&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;換句話說，在此空間中同語義的句子會靠得比較近，我們實際得到的空間比較像右邊。&lt;/p&gt;
&lt;p&gt;而如果我們將這些句子做 &lt;a href="https://distill.pub/2016/misread-tsne/"&gt;t-SNE&lt;/a&gt; ，甚至可以得到這樣的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/gnmt-multilingual.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/gnmt-multilingual.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在 Seq2Seq 模型創造出來的「語義」空間裡頭，不同語言但同語義的句子彼此相當接近
                        （&lt;a href="https://projector.tensorflow.org/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;此研究告訴我們，只要對自然語言做正確的轉換，就能將語言相異但同語義的句子都轉換成彼此距離相近的語義向量，並以此做出好的翻譯。&lt;/p&gt;
&lt;p&gt;以下是我隨意挑選出來的一組句子，它們在該空間裡的距離相近：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;英文：
From low-cost pharmacy brand moisturizers to high-priced cosmetics brand moisturizers, competition is fierce.

日文：
低価格の薬品ブランドの保湿剤から高価な百貨店の化粧品ブランドのためには, 競争が激しい

韓文：
싸구려백화점화장품브랜드 moisturizers 에 저렴한약국브랜드 moisturizers 에서 , 경쟁이큰있습니다
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這些句子都代表著類似的意思：「從低價的保濕劑到高價的化妝品牌，競爭都十分激烈」。&lt;/p&gt;
&lt;p&gt;如果你想進一步了解這個視覺化結果，可以閱讀 &lt;a href="https://youtu.be/ulLx2iPTIcs?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=789"&gt;Google Brain 的詳細解說&lt;/a&gt;或是上 &lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt; 自己試看看。&lt;/p&gt;
&lt;p&gt;另外值得注意的是，機器翻譯本身是一種&lt;a href="https://youtu.be/ZjfjPzXw6og?t=2816"&gt;有條件的序列生成任務（Conditional Sequence Generation）&lt;/a&gt;：給定一個特定的輸入句子（文字序列），依此條件輸出另外一個句子（文字序列）。這跟在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸&lt;/a&gt;一文中會隨機生成天龍八部文章的&lt;a href="https://zh.wikipedia.org/wiki/%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B"&gt;語言模型（Language Model）&lt;/a&gt;是有所差異的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/lstm-sequence-generation.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/lstm-sequence-generation.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        隨機序列生成的例子：一個以 LSTM 實作的簡單語言模型
                        （&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說，語言模型可以在不給定任何輸入的情況下生成非常隨機的文字序列；但針對機器翻譯這種有條件的序列生成任務，我們通常希望給定相同輸入，輸出的結果越穩定越好（或是每次都一模一樣）。&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#TODO"&gt;實作的時候&lt;/a&gt;會看到怎麼達成這件事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder-Decoder-模型-+-注意力機制"&gt;Encoder-Decoder 模型 + 注意力機制&lt;a class="anchor-link" href="#Encoder-Decoder-模型-+-注意力機制"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，你現在應該已經了解如何使用 Seq2Seq 模型來做 NMT 了，不過現在讓我們再次複習其運作方式。這次我們把用 RNN 實作的 Encoder / Decoder 在每個時間點做的事情從左到右一字排開：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="{filename}images/transformer/seq2seq-unrolled-no-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-no-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        以 RNN 為基礎的 Seq2Seq 模型做 NMT 的流程
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基本款的 Seq2Seq 模型表現得不錯，但其實有可以改善的地方。你有看出來了嗎？上圖的輸入句子只有 3 個詞彙，但如果我們想輸入一個很長的句子呢？&lt;/p&gt;
&lt;p&gt;我們前面曾提過 Seq2Seq 模型裡的一個重要假設是 Encoder 能把輸入句子的語義 / 文本脈絡全都壓縮成&lt;strong&gt;一個&lt;/strong&gt;固定維度的語義向量。之後 Decoder 只要利用該向量裡頭的資訊就能重新生成具有相同意義，但不同語言的句子。&lt;/p&gt;
&lt;p&gt;但你可以想像當我們只有一個向量的時候，是不太可能把一個很長的句子的所有資訊打包起來的。&lt;/p&gt;
&lt;p&gt;這時候怎麼辦呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        與其只把 Encoder 處理完句子產生的最後「一個」向量交給 Decoder 並要求其從中萃取整句資訊，不如將 Encoder 在處理每個詞彙後所生成的「所有」輸出向量都交給 Decoder，讓 Decoder 自己決定在生成新序列的時候要把「注意」放在 Encoder 的哪些輸出向量上面。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這事實上就是&lt;a href="https://www.youtube.com/watch?v=jd9DtlR90ak&amp;amp;feature=youtu.be"&gt;注意力機制（Attention Mechanism）&lt;/a&gt;的中心思想：提供更多資訊給 Decoder，並透過類似資料庫存取的概念，令其自行學會該怎麼提取資訊。兩篇核心論文分別在 &lt;a href="https://arxiv.org/abs/1409.0473"&gt;2014 年 9 月&lt;/a&gt;及 &lt;a href="https://arxiv.org/abs/1508.04025"&gt;2015 年 8 月&lt;/a&gt;釋出，概念不難但威力十分強大。&lt;/p&gt;
&lt;p&gt;以下就是將注意力機制加到 Seq2Seq 模型後的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq-unrolled-with-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        注意力機制讓 Decoder 在生成新序列時能查看 Encoder 裡所有可能有用的隱狀態向量
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以拉回去跟沒有注意力機制的 Seq2Seq 模型比較一下差異。&lt;/p&gt;
&lt;p&gt;現在你會看到 Encoder 把處理完每個詞彙所產生的向量都交給 Decoder 了。且透過注意力機制，Decoder 在生成新序列的每個元素時都能&lt;strong&gt;動態地&lt;/strong&gt;考慮自己要看哪些 Encoder 的向量（還有決定從中該擷取多少資訊），因此這種運用注意力機制的 Seq2Seq 架構又被稱作&lt;a href="https://youtu.be/ZjfjPzXw6og?t=3528"&gt;動態的條件序列生成（Dynamic Conditional Generation）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/seq2seq_detail.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/seq2seq_detail.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        法翻英時，Decoder 在生成每個英文詞彙時都在 Encoder 的每個輸出向量上放不同的注意程度
                        （&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際構想並證明其有效的研究者們十分厲害，且其概念也挺符合人類直覺的，對吧？&lt;/p&gt;
&lt;p&gt;為了方便讀者理解，上面動畫實際上隱藏了一些細節：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;呈現算好的注意程度而不是計算過程&lt;/li&gt;
&lt;li&gt;Encoder / 跟 Decoder 的實際架構&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;既然是深度學習，Encoder / Decoder 一般來說都是由多個 &lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;LSTM&lt;/a&gt; / &lt;a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit"&gt;GRU&lt;/a&gt; 等 RNN Layers 所疊起來的。而注意力機制在這種情境下實際的運作方式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/attention_mechanism_luong.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        英翻法情境下，Decoder 在第一個時間點進行的注意力機制
                        （&lt;a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;左右兩邊分別是 Encoder 與 Decoder ，縱軸則是多層的神經網路區塊 / 層。&lt;/p&gt;
&lt;p&gt;雖然上張動畫是法翻英（這邊是英翻法），但該動畫也是以一樣的概念將圖中的注意權重（attention weights ）視覺化出來（注意權重和為 1）。&lt;/p&gt;
&lt;p&gt;現在讓我們看一下注意力機制實際的計算步驟。在 Decoder 的每個時間點，我們都會進行注意力機制以讓 Decoder 從 Encoder 取得語境資訊：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;拿 Decoder 當下的紅色隱狀態向量 &lt;code&gt;ht&lt;/code&gt; 跟 Encoder 所有藍色隱狀態向量 &lt;code&gt;hs&lt;/code&gt; 做比較，利用 &lt;code&gt;score&lt;/code&gt; 函式計算出 &lt;code&gt;ht&lt;/code&gt; 對每個 &lt;code&gt;hs&lt;/code&gt; 的注意程度&lt;/li&gt;
&lt;li&gt;以此注意程度為權重，&lt;strong&gt;加權平均&lt;/strong&gt;所有 Encoder 隱狀態 &lt;code&gt;hs&lt;/code&gt; 以取得上下文向量 &lt;code&gt;context vector&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將此上下文向量與 Decoder 隱狀態結合成一個注意向量 &lt;code&gt;attention vector&lt;/code&gt; 並作為該時間的輸出&lt;/li&gt;
&lt;li&gt;該注意向量會作為 Decoder 下個時間點的輸入&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;定義 &lt;code&gt;score&lt;/code&gt; 函式的方式不少，現在就先讓我們假設有這麼一個函式。&lt;/p&gt;
&lt;p&gt;至此為止，你應該已經能夠看懂注意力機制的計算公式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/attention-equation.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        注意力機制前 3 步驟的數學式子
                        （&lt;a href="https://github.com/tensorflow/nmt#background-on-the-attention-mechanism" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而之所以稱為注意權重（attention weights），是因為注意力機制可以被視為是一個學習來源語言和目標語言&lt;strong&gt;每一個單詞之間關係&lt;/strong&gt;的小型神經網路，而這些權重是該神經網路的參數。&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#TODO"&gt;後面的章節&lt;/a&gt;會實際看到，在訓練還沒開始前，這些權重都是隨機且無意義的。是透過訓練，神經網路才知道該為這些權重賦予什麼值。&lt;/p&gt;
&lt;p&gt;你也會發現我在文中提及多次的「注意程度」就是這裡的「注意權重」，而前者是一種擬人化的說法。你可以想像這些權重值讓當下的 Decoder 曉得該放多少關注在 Encoder 個別的隱狀態身上，並依此從它們身上取得上下文資訊（步驟 2）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        而事實上神經網路並沒有意識，因此也不會有感知層次上的「注意」。它學到的是讓注意力機制產生最好結果的「參數權重」，而不是我們人類想像的「注意程度」。只有人類可以賦予神經網路裡頭的計算意義。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有點扯遠了，畢竟這裡應該沒有人文學系的讀者。&lt;/p&gt;
&lt;p&gt;讓我們拉回注意力機制。&lt;/p&gt;
&lt;p&gt;將此機制加入 Seq2Seq 模型後，NMT 系統的翻譯水準再次起飛。Google 在 2016 年推出的 &lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html"&gt;Google Neural Machine Translation system（GNMT）&lt;/a&gt; 是一個知名的案例。除了注意力機制以外，GNMT &lt;a href="https://arxiv.org/abs/1609.08144"&gt;在 Encoder 跟 Decoder 都採用了多達 8 層的 LSTM 神經網路&lt;/a&gt;，讓更多人見識到深度學習的威力。&lt;/p&gt;
&lt;p&gt;跟 Google 10 年前推出的 PBMT 系統比起來，翻譯錯誤率平均下降了 60 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/nmt-model-fast.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/nmt-model-fast.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        利用注意力機制的 GNMT 讓 Decoder 在生成「Knowledge」時能放注意力在 Encoder 處理完「知」與「識」的兩個輸出向量 e0 &amp;amp; e1
                        （&lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上圖為 GNMT 做中翻英的過程。Encoder 跟 Decoder 之間的線條代表注意力（Attention），線條越粗代表下面的 Decoder 在生成某英文字時越關注上方的某些中文字。模型自己學會在翻譯時該看來源句子中的哪些資訊，很聰明，不是嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為其卓越的翻譯品質，在 GNMT 推出的那段時間，搭配注意力機制的 Seq2Seq 模型基本上就是拿來做 NMT 系統的不二人選。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/nmt-vs-pbmt.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        NMT、PBMT 以及人類在中英翻譯時的結果比較
                        （&lt;a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;話說當年 Google 導入 GNMT 時釋出了 8 個語言之間的對應翻譯，&lt;a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/"&gt;涵蓋了約 1/3 的世界人口以及超過 35 % 的 Google 翻譯查詢&lt;/a&gt;，是機器翻譯發展的一個重要里程碑。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Transformer：Seq2Seq-模型-+-自注意力機制"&gt;Transformer：Seq2Seq 模型 + 自注意力機制&lt;a class="anchor-link" href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好酒沉甕底，萬眾矚目的時刻來了。&lt;/p&gt;
&lt;p&gt;標題已經破梗。你已經知道我們將探討本文主角 Transformer，且理論上越後面出來的 BOSS 越強。&lt;/p&gt;
&lt;p&gt;但你現在可能在想：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        Seq2Seq 模型搭配注意力機制感覺已經很猛了，難道還有什麼可以改善的嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案是肯定的 Yes。&lt;/p&gt;
&lt;p&gt;不過這次問題不是出在 Encoder 跟 Decoder 中間交換的資訊不夠，也不是 Seq2Seq 架構本身有什麼問題，問題是出在我們是用 &lt;strong&gt;RNN&lt;/strong&gt; 來實作 Encoder 以及 Decoder。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-09-NN-Types-FP/"&gt;循環神經網路 RNN&lt;/a&gt; 時常被拿來處理序列數據，但其運作方式存在著一個困擾研究者已久的問題：無法有效地平行運算。以一個有 4 個元素的輸入序列為例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[a1, a2, a3, a4]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要獲得最後一個時間點的輸出向量 &lt;code&gt;b4&lt;/code&gt; 得把整個輸入序列跑過一遍才行：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/rnn-vs-self-attn-layer.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        自注意層可以做到跟雙向 RNN 一樣的事情，還可以平行運算
                        （&lt;a href="https://www.youtube.com/watch?v=ugWDIIOHtPA" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1706.03762"&gt;Google 在 2017 年 6 月的一篇論文：Attention Is All You Need&lt;/a&gt; 裡參考了注意力機制，提出了&lt;strong&gt;自&lt;/strong&gt;注意力機制（Self-Attention mechanism）。這個機制不只跟 RNN 一樣可以處理序列數據，還可以平行運算。&lt;/p&gt;
&lt;p&gt;以剛剛的輸入序列 &lt;code&gt;a[]&lt;/code&gt; 為例：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[a1, a2, a3, a4]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;一個自注意層（Self-Attention Layer）可以利用矩陣運算在等同於 RNN 的一個時間點內就回傳所有 &lt;code&gt;bi&lt;/code&gt; ，且每個 &lt;code&gt;bi&lt;/code&gt; 都包含了整個輸入序列的資訊。相比之下，RNN 得經過 4 個時間點依序看過 &lt;code&gt;[a1, a2, a3, a4]&lt;/code&gt; 以後才能取得序列中最後一個元素的輸出 &lt;code&gt;b4&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;雖然我們還沒講到實際的運作過程，但在給定一個輸入序列的情境下，自注意力機制的基本精神就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在建立序列中每個元素的 repr. 時，同時去「注意」並擷取同個序列中其他元素的語義資訊。接著將這些語義資訊合併成上下文資訊並當作自己的 repr. 回傳。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;repr. 為 &lt;a href="https://dictionary.cambridge.org/zht/%E8%A9%9E%E5%85%B8/%E8%8B%B1%E8%AA%9E-%E6%BC%A2%E8%AA%9E-%E7%B9%81%E9%AB%94/representation"&gt;representation&lt;/a&gt; 縮寫，在本文的機器翻譯情境裡頭，其意味著可以用來描述某個詞彙、句子意涵的多維實數張量。&lt;/p&gt;
&lt;p&gt;雖然我們一直強調自注意力機制的平行能力，如果你還記得我們在&lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;上一節&lt;/a&gt;講述的注意力機制，就會發現在 Seq2Seq 架構裡頭自注意力機制跟注意力機制講的根本是同樣一件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注 Encoder 的輸出序列，從中獲得上下文資訊&lt;/li&gt;
&lt;li&gt;自注意力機制讓 Encoder 在生成輸入元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊&lt;/li&gt;
&lt;li&gt;自注意力機制讓 Decoder 在生成輸出元素的 repr. 時關注自己序列中的其他元素，從中獲得上下文資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現一個非常重要的模式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        注意力機制跟自注意力機制都是讓序列 q 關注序列 k 來將上下文資訊 v 匯總到序列 q 的 repr. 裡頭，只是使用的序列不同。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這也是為何&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt;在後面實作時我們只需要一個注意函式&lt;/a&gt;就好了。總之透過新設計的自注意力機制以及原有的注意力機制，&lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention Is All You Need 論文&lt;/a&gt;作者們打造了一個完全不需使用 RNN 的 Seq2Seq 模型：Transformer。以下是 Transformer 中非常簡化的 Encoder-Decoder 版本，讓我們找找哪邊用到了（自）注意力機制：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/Transformer_decoder.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在 Transformer 裡頭共有 3 個地方用到（自）注意力機制
                        （&lt;a href="http://jalammar.github.io/illustrated-transformer/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Transformer 裡頭，Decoder 利用注意力機制關注 Encoder 的輸出序列（Encoder-Decoder Attention），而 Encoder 跟 Decoder 各自利用自注意力機制關注自己處理的序列（Self-Attention）。無法平行運算的 RNN 完全消失，名符其實的 Attention is all you need.&lt;/p&gt;
&lt;p&gt;以下則是 Transformer 實際上將英文句子翻譯到法文的過程：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-nmt-encode-decode.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        用 Transformer 將英文句子翻譯到法文的例子
                        （&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以 Transformer 實作的 NMT 系統基本上可以分為 6 個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Encoder 為輸入序列裡的每個詞彙產生初始的 repr. （即詞向量），以空圈表示&lt;/li&gt;
&lt;li&gt;利用自注意力機制將序列中所有詞彙的語義資訊各自匯總成每個詞彙的 repr.，以實圈表示&lt;/li&gt;
&lt;li&gt;Encoder 重複 N 次自注意力機制，讓每個詞彙的 repr. 彼此持續修正以完整納入上下文語義&lt;/li&gt;
&lt;li&gt;Decoder 在生成每個法文字時也運用了自注意力機制，關注自己之前已生成的元素，將其語義也納入之後生成的元素&lt;/li&gt;
&lt;li&gt;在自注意力機制後，Decoder 接著利用注意力機制關注 Encoder 的所有輸出並將其資訊納入當前生成元素的 repr.&lt;/li&gt;
&lt;li&gt;Decoder 重複步驟 4, 5 以讓當前元素完整包含整體語義&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上面動畫的 N 為 3，代表著 Encoder 與 Decoder 的層數。這是一個可以依照任務調整的超參數。&lt;/p&gt;
&lt;p&gt;如果你看懂這張圖的資訊流動，就等於瞭解 Transformer 的核心精神了，恭喜！如果仍然有不明瞭的地方，可以搭配我上面的說明多看幾遍動畫或是直接閱讀 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Google AI 部落格的原文介紹&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-ge-bleu-comparison.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Transformer 釋出時與其他模型在英德翻譯資料集上的比較
                        （&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;自注意力機制解開了 RNN 加在 GPU 上的拘束器。作者們用了 8 個 &lt;a href="https://www.nvidia.com.tw/object/tesla-p100-tw.html"&gt;NVIDIA P100 GPU&lt;/a&gt;，花了 3 天半訓練了一個 Transformer，而該模型在 &lt;a href="http://statmt.org/wmt14/"&gt;WMT 2014&lt;/a&gt;  英法 / 英德翻譯都取得了最高水準的成績。&lt;/p&gt;
&lt;p&gt;跟其他模型相比，這訓練時間跟其創造的優異成績在當時可以說是逆天的存在。自此「大注意時代」展開，該論文至今超過 1800 次引用，所有研究領域都被自注意力機制相關的論文洗了一波。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/ramona-flwrs-1310216-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒能趕上開心洗論文的最佳時機也別傷心難過，對我們來說仍然有個十分重要的訊息：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        多數以 RNN 做過的研究，都可以用自注意力機制來取代；多數用 Seq2Seq 架構實現過的應用，也都可以用 Transformer 來替換。模型訓練速度更快，結果可能更好。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這也是我決定寫這篇文章的理由之一。雖然本文是以機器翻譯的角度來介紹 Transformer，但事實上只要是能用 RNN 或 Seq2Seq 模型進行的研究領域，你都會看到已經有大量跟（自）注意力機制或是 Transformer 有關的論文了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;文本摘要（Text Summarization）&lt;/li&gt;
&lt;li&gt;圖像描述（Image Captioning）&lt;/li&gt;
&lt;li&gt;閱讀理解（Reading Comprehension）&lt;/li&gt;
&lt;li&gt;語音辨識（Voice Recognition）&lt;/li&gt;
&lt;li&gt;語言模型（Language Model）&lt;/li&gt;
&lt;li&gt;聊天機器人（Chat Bot）&lt;/li&gt;
&lt;li&gt;其他任何可以用 RNN 的潛在應用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然不是每個人都喜歡或需要看論文。如果你只是想要應用 Transformer 也沒問題。除了閱讀學術論文以外，Google 的 &lt;a href="https://github.com/google-research/bert"&gt;BERT（Github 上現在超過 1.5 萬顆星）&lt;/a&gt;顛覆以往自然語言的處理方式，讓你可以進行 NLP 的遷移學習（transfer learning），輕鬆利用前人智慧來完成手上的 NLP 任務； &lt;a href="https://openai.com/blog/better-language-models/"&gt;OpenAI 的 GPT&lt;/a&gt; 則是非常厲害的語言模型，能產生非常順暢的文章。你可以在這邊看到一個&lt;a href="https://talktotransformer.com"&gt;線上產生各種文章的 demo&lt;/a&gt;，或是最近&lt;a href="https://lexfridman.com/deeptweets/"&gt; Lex Fridman 使用 GPT-2 產生名人 Tweets&lt;/a&gt; 的例子 。&lt;/p&gt;
&lt;p&gt;這些都是 Transformer 的應用。想了解更多，我推薦李宏毅教授最近&lt;a href="https://www.youtube.com/watch?v=UYPa347-DdE"&gt;講解 ELMO、BERT 以及 GPT 的 YouTube 影片&lt;/a&gt;，十分通俗易懂 ：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/UYPa347-DdE"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        李宏毅教授講解目前 NLP 領域的最新研究是如何讓機器讀懂文字的
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你接下來想往深度學習領域發展（尤其是自然語言處理這塊），了解（自）注意力機制以及 Transformer 的運作方式幾乎可以說是必經之路。就算沒打算自己手刻 Transformer，你現在應該也稍微能夠體會現代的神經網路到底在在對自然語言做些什麼了。&lt;/p&gt;
&lt;p&gt;至此本文的上半部分結束。在下半段我們將實作一個能進行英翻中的 Transformer。等等會說明一項要你完成的事情，不過現在先離開位置喝點東西、讓眼睛跟腦袋休息一下吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/adam-jaime-119551-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="師傅引進門，修行在個人_1"&gt;師傅引進門，修行在個人&lt;a class="anchor-link" href="#師傅引進門，修行在個人"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你回來了嗎？還是等不及待地想繼續往下閱讀？&lt;/p&gt;
&lt;p&gt;接下來我們會進入實際的程式實作。但跟前半段相比難度呈指數型上升，因此我只推薦符合以下條件的讀者閱讀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想透過實作 Transformer 來徹底了解其內部運作原理的人&lt;/li&gt;
&lt;li&gt;願意先花 1 小時了解 Transformer 的細節概念與理論的人&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你馬上就會知道 1 個小時代表什麼意思。如果你覺得這聽起來很 ok，那可以繼續閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/obama-not-bad.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="#機器翻譯近代史"&gt;機器翻譯近代史&lt;/a&gt;一章我們已經花了不少篇幅講解了許多在實作 Transformer 時會有幫助的重要概念，其中包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#神經機器翻譯：Encoder-Decoder-模型"&gt;Seq2Seq 模型的運作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Encoder-Decoder-模型-+-注意力機制"&gt;注意力機制的概念與計算過程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;自注意力機制與 Transformer 的精神&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;壞消息是，深度學習裡頭理論跟實作的差異常常是很大的。儘管這些背景知識對理解 Transformer 的精神非常有幫助，對從來沒有用過 &lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;RNN 實現文本生成&lt;/a&gt;或是以&lt;a href="https://www.tensorflow.org/alpha/tutorials/text/nmt_with_attention"&gt; Seq2Seq 模型 + 注意力機制實現過 NMT&lt;/a&gt; 的人來說，要在第一次就正確實現 Transformer 仍是一個巨大的挑戰。&lt;/p&gt;
&lt;p&gt;就算不說理論跟實作的差異，讓我們看看 &lt;a href="https://www.tensorflow.org/alpha/tutorials/text/transformer"&gt;TensorFlow 官方釋出的最新 Transformer 教學&lt;/a&gt;裡頭有多少內容：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tf-tutorial-oveview.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/tf-tutorial-oveview.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        TensorFlow 官方的 Transformer 教學
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面是我用這輩子最快的速度捲動該頁面再加速後的結果，可以看出內容還真不少。儘管中文化很重要，我在這篇文章裡不會幫你把其中的敘述翻成中文（畢竟你的英文可能比我好）&lt;/p&gt;
&lt;p&gt;反之，我將利用 TensorFlow 官方的程式碼，以最適合「初心者」理解的實作順序來講述 Transformer 的重要技術細節及概念。在閱讀本文之後，你將有能力自行理解 TensorFlow 官方教學以及其他網路上的實作（比方說 HarvardNLP 以 &lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 實現的 &lt;a href="http://nlp.seas.harvard.edu//2018/04/03/attention.html#additional-components-bpe-search-averaging"&gt;The Annotated Transformer&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;但在實作前有件事情要請你完成：觀看個 YouTube 影片。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        教授講解 self-attention 計算方式及 Transformer 的運作原理，強力推薦
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在閱讀此文的讀者真的很幸福。&lt;/p&gt;
&lt;p&gt;李宏毅教授前陣子才在&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;他 2019 年的台大機器學習課程&lt;/a&gt;發佈了 &lt;a href="https://www.youtube.com/watch?v=ugWDIIOHtPA"&gt;Transformer 的教學影片&lt;/a&gt;，而這可以說是世界上最好的中文教學影片。如果你真的想要深入理解 Transformer，在實作前至少把上面的影片看完吧！你可以少走很多彎路。&lt;/p&gt;
&lt;p&gt;實作時我會盡量重述關鍵概念，但如果有先看影片你會比較容易理解我在碎碎念什麼。如果看完影片你的小宇宙開始發光發熱，也可以先讀讀 &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Transformer 的原始論文&lt;/a&gt;，跟很多學術論文比起來相當好讀，真心不騙。&lt;/p&gt;
&lt;p&gt;重申一次，除非你已經了解基本注意力機制的運算以及 Transformer 的整體架構，否則我不建議繼續閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/you-should-not-pass.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="11-個重要-Transformer-概念回顧"&gt;11 個重要 Transformer 概念回顧&lt;a class="anchor-link" href="#11-個重要-Transformer-概念回顧"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;怎麼樣？你應該已經從教授的課程中學到不少重要概念了吧？我不知道你還記得多少，但讓我非常簡單地幫你複習一下。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;自注意層（Self-Attention Layer）跟 RNN 一樣，輸入是一個序列，輸出一個序列。但是該層可以平行計算，且輸出序列中的每個向量都已經看了整個序列的資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意層將輸入序列 &lt;code&gt;I&lt;/code&gt; 裡頭的每個位置的向量 &lt;code&gt;i&lt;/code&gt; 透過 3 個線性轉換分別變成 3 個向量：&lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt;，並將每個位置的 &lt;code&gt;q&lt;/code&gt; 拿去跟序列中其他位置的 &lt;code&gt;k&lt;/code&gt; 做匹配，算出匹配程度後利用 softmax 層取得介於 0 到 1 之間的權重值，並以此權重跟每個位置的 &lt;code&gt;v&lt;/code&gt; 作加權平均，最後取得該位置的輸出向量 &lt;code&gt;o&lt;/code&gt;。全部位置的輸出向量可以同時平行計算，最後輸出序列 &lt;code&gt;O&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;計算匹配程度（注意）的方法不只一種，只要能吃進 2 個向量並吐出一個數值即可。但在 Transformer 論文原文是將 2 向量做 dot product 算匹配程度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;我們可以透過大量矩陣運算以及 GPU 將概念 2 提到的注意力機制的計算全部平行化，加快訓練效率（也是本文實作的重點）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多頭注意力機制（Multi-head Attention）是將輸入序列中的每個位置的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt; 切割成多個 &lt;code&gt;qi&lt;/code&gt;、&lt;code&gt;ki&lt;/code&gt; 和 &lt;code&gt;vi&lt;/code&gt; 再分別各自進行注意力機制。各自處理完以後把所有結果串接並視情況降維。這樣的好處是能讓各個 head 各司其職，學會關注序列中不同位置在不同 representaton spaces 的資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意力機制這樣的計算的好處是「天涯若比鄰」：序列中每個位置都可以在 O(1) 的距離內關注任一其他位置的資訊，運算效率較雙向 RNN 優秀。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意層可以取代 Seq2Seq 模型裡頭以 RNN 為基礎的 Encoder / Decoder，而實際上全部替換掉後就（大致上）是 Transformer。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自注意力機制預設沒有「先後順序」的概念，而這也是為何其可以快速平行運算的原因。在進行如機器翻譯等序列生成任務時，我們需要額外加入位置編碼（Positioning Encoding）來加入順序資訊。而在 Transformer 原論文中此值為手設而非訓練出來的模型權重。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Transformer 是一個 Seq2Seq 模型，自然包含了 Encoder / Decoder，而 Encoder 及 Decoder 可以包含多層結構相同的 blocks，裡頭每層都會有 multi-head attention 以及 Feed Forward Network。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在每個 Encoder / Decoder block 裡頭，我們還會使用殘差連結（Residual Connection）以及 Layer Normalization。這些能幫助模型穩定訓練。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Decoder 在關注 Encoder 輸出時會需要遮罩（mask）來避免看到未來資訊。我們後面會看到，事實上還會需要其他遮罩。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這些應該是你在看完影片後學到的東西。如果你想要快速複習，這裡則是&lt;a href="https://bit.ly/2QT4loG"&gt;教授課程的 PDF 檔&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你之後也可以隨時透過左側導覽的圖片 icon 來快速回顧 Transformer 的整體架構以及教授添加的註解。我相信在實作的時候它可以幫得上點忙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-left-nav.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-left-nav.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這些背景知識以後，在理解程式碼時會輕鬆許多。你也可以一邊執行 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb"&gt;TensorFlow 官方的 Colab 筆記本&lt;/a&gt;一邊參考底下實作。&lt;/p&gt;
&lt;p&gt;好戲登場！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="安裝函式庫並設置環境"&gt;安裝函式庫並設置環境&lt;a class="anchor-link" href="#安裝函式庫並設置環境"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊我們引進一些常用的 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 函式庫，這應該不需要特別說明。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mpl&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pprint&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pprint&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.display&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;clear_output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較值得注意的是我們將以&lt;a href="https://pypi.org/project/tf-nightly-2.0-preview/"&gt;最新的 TensorFlow 2 Beta 版本&lt;/a&gt;來實作本文的 Transformer。另外也會透過 &lt;a href="https://www.tensorflow.org/datasets"&gt;TensorFlow Datasets&lt;/a&gt; 來使用前人幫我們準備好的英中翻譯資料集：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;pip install tensorflow-gpu&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.0.0-beta0
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow_datasets&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tfds&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__version__&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;2.0.0-beta0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外為了避免 TensorFlow 吐給我們太多不必要的資訊，在此文中我也將改變 logging 等級。&lt;a href="https://www.tensorflow.org/alpha/guide/effective_tf2#api_cleanup"&gt;在 TensorFlow 2 裡頭因為 &lt;code&gt;tf.logging&lt;/code&gt; 被 deprecated&lt;/a&gt;，我們可以直接用 &lt;code&gt;logging&lt;/code&gt;  模組來做到這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;logging&lt;/span&gt;
&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"error"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_printoptions&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;suppress&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們同時也讓 numpy 不要顯示科學記號。這樣可以讓我們之後在做一些 Tensor 運算的時候版面能乾淨一點。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著定義一些之後在儲存檔案時會用到的路徑變數：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"nmt"&lt;/span&gt;
&lt;span class="n"&gt;en_vocab_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"en_vocab"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zh_vocab_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"zh_vocab"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;checkpoint_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"checkpoints"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;log_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'logs'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;download_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"tensorflow-datasets/downloads"&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;makedirs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立輸入管道"&gt;建立輸入管道&lt;a class="anchor-link" href="#建立輸入管道"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現行的 GPU 以及 TPU 能透過平行運算幫我們顯著地縮短訓練一個 step 所需的時間。而為了讓平行計算能發揮最佳性能，我們需要最佳化&lt;a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn"&gt;輸入管道（Input pipeline）&lt;/a&gt;，以在當前訓練步驟完成之前就準備好下一個時間點 GPU 要用的數據。&lt;/p&gt;
&lt;p&gt;而我們將透過 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data"&gt;tf.data API&lt;/a&gt; 以及前面導入的 &lt;a href="https://www.tensorflow.org/datasets"&gt;TensorFlow Datasets&lt;/a&gt; 來建置高效的輸入管道，並將&lt;a href="http://www.statmt.org/wmt19/"&gt;機器翻譯競賽 WMT 2019&lt;/a&gt; 的中英資料集準備好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="下載並準備資料集"&gt;下載並準備資料集&lt;a class="anchor-link" href="#下載並準備資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先看看 &lt;code&gt;tfds&lt;/code&gt; 裡頭 WMT 2019 的中英翻譯有哪些資料來源：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tmp_builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"wmt19_translate/zh-en"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subsets&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;{NamedSplit('train'): ['newscommentary_v14',
                       'wikititles_v1',
                       'uncorpus_v1',
                       'casia2015',
                       'casict2011',
                       'casict2015',
                       'datum2015',
                       'datum2017',
                       'neu2017'],
 NamedSplit('validation'): ['newstest2018']}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;可以看到在 WMT 2019 裡中英對照的數據來源還算不少。其中幾個很好猜到其性質：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聯合國數據：&lt;code&gt;uncorpus_v1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;維基百科標題：&lt;code&gt;wikititles_v1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;新聞評論：&lt;code&gt;newscommentary_v14&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然大量數據對訓練神經網路很有幫助，本文為了節省訓練 Transformer 所需的時間，在這裡我們就只選擇一個資料來源當作資料集。至於要選哪個資料來源呢？&lt;/p&gt;
&lt;p&gt;聯合國的數據非常龐大，而維基百科標題通常內容很短，&lt;a href="http://www.casmacat.eu/corpus/news-commentary.html"&gt;新聞評論&lt;/a&gt;感覺是一個相對適合的選擇。我們可以在設定檔 &lt;code&gt;config&lt;/code&gt; 裡頭指定新聞評論這個資料來源並請 TensorFlow Datasets 下載：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;translate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wmt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WmtConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"0.0.2"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="n"&gt;language_pair&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"zh"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
  &lt;span class="n"&gt;subsets&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Split&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"newscommentary_v14"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"wmt_translate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;download_and_prepare&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;download_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;download_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;clear_output&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/tfds-demo.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/tfds-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的指令約需 2 分鐘完成，而在過程中 &lt;code&gt;tfds&lt;/code&gt; 幫我們完成不少工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下載包含原始數據的壓縮檔&lt;/li&gt;
&lt;li&gt;解壓縮得到 CSV 檔案&lt;/li&gt;
&lt;li&gt;逐行讀取該 CSV 裡頭所有中英句子&lt;/li&gt;
&lt;li&gt;將不符合格式的 row 自動過濾&lt;/li&gt;
&lt;li&gt;Shuffle 數據&lt;/li&gt;
&lt;li&gt;將原數據轉換成 &lt;a href="https://www.tensorflow.org/alpha/guide/data#consuming_tfrecord_data"&gt;TFRecord 數據&lt;/a&gt;以加速讀取&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多花點時間把相關 &lt;a href="https://www.tensorflow.org/datasets/datasets#wmt19_translate"&gt;API 文件&lt;/a&gt;看熟，你就能把清理、準備數據的時間花在建構模型以及跑實驗上面。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="切割資料集"&gt;切割資料集&lt;a class="anchor-link" href="#切割資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們只下載了一個新聞評論的數據集，裡頭還是有超過 30 萬筆的中英平行句子。為了減少訓練所需的時間，讓我們使用 &lt;code&gt;tfds.Split&lt;/code&gt; 定義一個將此數據集切成多個部分的 &lt;code&gt;split&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_perc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;val_prec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;drop_prec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;train_perc&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;val_prec&lt;/span&gt;

&lt;span class="n"&gt;split&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tfds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Split&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TRAIN&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subsplit&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;train_perc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_prec&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;drop_prec&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;split&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(NamedSplit('train')(tfds.percent[0:20]),
 NamedSplit('train')(tfds.percent[20:21]),
 NamedSplit('train')(tfds.percent[21:100]))&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個 &lt;code&gt;split&lt;/code&gt; 請 &lt;code&gt;tfds&lt;/code&gt; 將剛剛處理好的新聞評論資料集再進一步切成 3 個部分，數據量分佈如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Split 1：20% 數據&lt;/li&gt;
&lt;li&gt;Split 2：1% 數據&lt;/li&gt;
&lt;li&gt;Split 3：79% 數據&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們將前兩個 splits 拿來當作訓練以及驗證集，剩餘的部分（第 3 個 split）捨棄不用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;builder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_dataset&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;as_supervised&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;val_examples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;examples&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;&amp;lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&amp;gt;
&amp;lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&amp;gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以在&lt;a href="https://github.com/tensorflow/datasets/blob/master/docs/splits.md"&gt;這邊&lt;/a&gt;找到更多跟 &lt;code&gt;split&lt;/code&gt; 相關的用法。&lt;/p&gt;
&lt;p&gt;這時候 &lt;code&gt;train_examples&lt;/code&gt; 跟 &lt;code&gt;val_examples&lt;/code&gt; 都已經是 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset"&gt;tf.data.Dataset&lt;/a&gt;。我們在&lt;a href="#前處理數據"&gt;前處理數據&lt;/a&gt;一節會看到這些數據在被丟入神經網路前需要經過什麼轉換，不過現在先讓我們簡單讀幾筆數據出來看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tf.Tensor(b'Making Do With More', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97', shape=(), dtype=string)
----------
tf.Tensor(b'If the Putins, Erdo\xc4\x9fans, and Orb\xc3\xa1ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.', shape=(), dtype=string)
tf.Tensor(b'\xe5\xa6\x82\xe6\x9e\x9c\xe6\x99\xae\xe4\xba\xac\xe3\x80\x81\xe5\x9f\x83\xe5\xb0\x94\xe5\xa4\x9a\xe5\xae\x89\xe5\x92\x8c\xe6\xac\xa7\xe5\xb0\x94\xe7\x8f\xad\xe5\xb8\x8c\xe6\x9c\x9b\xe7\xbb\xa7\xe7\xbb\xad\xe4\xba\xab\xe6\x9c\x89\xe5\xbc\x80\xe6\x94\xbe\xe5\x9b\xbd\xe9\x99\x85\xe4\xbd\x93\xe7\xb3\xbb\xe6\x8f\x90\xe4\xbe\x9b\xe7\x9a\x84\xe7\xbb\x8f\xe6\xb5\x8e\xe5\x88\xa9\xe7\x9b\x8a\xef\xbc\x8c\xe5\xb0\xb1\xe4\xb8\x8d\xe8\x83\xbd\xe7\xae\x80\xe5\x8d\x95\xe5\x9c\xb0\xe5\x88\xb6\xe5\xae\x9a\xe8\x87\xaa\xe5\xb7\xb1\xe7\x9a\x84\xe8\xa7\x84\xe5\x88\x99\xe3\x80\x82', shape=(), dtype=string)
----------
tf.Tensor(b'This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.', shape=(), dtype=string)
tf.Tensor(b'\xe5\x8f\xaa\xe6\x9c\x89\xe5\x9c\xa8\xe5\x8f\x91\xe7\x94\x9f\xe6\xb7\xb1\xe5\xba\xa6\xe8\x90\xa7\xe6\x9d\xa1\xe6\x88\x96\xe5\x85\xb6\xe4\xbb\x96\xe5\x8f\x8d\xe5\xb8\xb8\xe4\xba\x8b\xe4\xbb\xb6\xe6\x97\xb6\xef\xbc\x8c\xe8\xbf\x99\xe4\xb8\x80\xe4\xb8\x8a\xe9\x99\x90\xe6\x89\x8d\xe8\x83\xbd\xe5\x81\x9a\xe5\x87\xba\xe8\xb0\x83\xe6\x95\xb4\xef\xbc\x8c\xe4\xbb\xa5\xe4\xbe\xbf\xe8\xae\xa9\xe5\x8f\x8d\xe5\x91\xa8\xe6\x9c\x9f\xe6\x94\xbf\xe7\xad\x96\xe5\xae\x9e\xe6\x96\xbd\xe8\xb6\xb3\xe5\xa4\x9f\xe7\x9a\x84\xe9\x95\xbf\xe5\xba\xa6\xef\xbc\x8c\xe4\xbd\xbf\xe4\xba\xba\xe4\xbb\xac\xe4\xb8\x80\xe8\x87\xb4\xe8\xae\xa4\xe4\xb8\xba\xe5\xa2\x9e\xe5\x8a\xa0\xe7\x9a\x84\xe8\xb5\xa4\xe5\xad\x97\xe6\x98\xaf\xe5\x91\xa8\xe6\x9c\x9f\xe6\x80\xa7\xe7\x9a\x84\xef\xbc\x8c\xe8\x80\x8c\xe4\xb8\x8d\xe6\x98\xaf\xe7\xbb\x93\xe6\x9e\x84\xe6\x80\xa7\xe7\x9a\x84\xe3\x80\x82', shape=(), dtype=string)
----------
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟預期一樣，每一個例子（每一次的 &lt;code&gt;take&lt;/code&gt;）都包含了 2 個以 unicode 呈現的 &lt;code&gt;tf.Tensor&lt;/code&gt;。它們有一樣的語義，只是一個是英文，一個是中文。&lt;/p&gt;
&lt;p&gt;讓我們將這些 Tensors 實際儲存的字串利用 &lt;code&gt;numpy()&lt;/code&gt; 取出並解碼看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;num_samples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"utf-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"utf-8"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 之後用來簡單評估模型的訓練情況&lt;/span&gt;
  &lt;span class="n"&gt;sample_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Making Do With More
多劳应多得
----------
If the Putins, Erdoğans, and Orb&amp;aacute;ns of the world want to continue to benefit economically from the open international system, they cannot simply make up their own rules.
如果普京、埃尔多安和欧尔班希望继续享有开放国际体系提供的经济利益，就不能简单地制定自己的规则。
----------
This ceiling can be raised only in a deep depression or other exceptional circumstances, allowing for counter-cyclical policy so long as it is agreed that the additional deficit is cyclical, rather than structural.
只有在发生深度萧条或其他反常事件时，这一上限才能做出调整，以便让反周期政策实施足够的长度，使人们一致认为增加的赤字是周期性的，而不是结构性的。
----------
Fascist and communist regimes of the past, which followed a similar instrumentalist approach to democracy, come to mind here.
在此我们想起了过去的法西斯主义和共产主义。 它们都相似地将民主作为实现其目的的工具。
----------
This phase culminated with the collapse of communism in 1989, but the chance to overcome the Continent&amp;rsquo;s historical divisions now required a redefinition of the European project.
这种状态随着1989年共产主义崩溃而达至巅峰，但是克服欧洲大陆历史性分裂的机遇现在需要重新定义欧洲计划。
----------
The eurozone&amp;rsquo;s collapse (and, for all practical purposes, that of the EU itself) forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。
----------
With energy and enthusiasm, Burden turned that operation into a thriving health (not health-care) agency that covers three cities and about 300,000 people on the western edge of Los Angeles.
在能量与激情的推动下，波顿将BCHD打造成了欣欣向荣的健康（而非医疗）机构，其服务范围覆盖了洛杉矶西侧三座城市的30万人。
----------
The result could be a world of fragmented blocs &amp;ndash; an outcome that would undermine not only global prosperity, but also cooperation on shared challenges.
其结果可能是一个四分五裂的世界 &amp;mdash; &amp;mdash; 这一结果不但会破坏全球繁荣，也会破坏面对共同挑战的合作。
----------
Among the questions being asked by NGOs, the UN, and national donors is how to prevent the recurrence of past mistakes.
现在NGO们、联合国和捐助国们问得最多的一个问题就是如何避免再犯过去的错误。
----------
Managing the rise of NCDs will require long-term thinking, and government leaders will have to make investments that might pay off only after they are no longer in office.
管理NCD的增加需要长期思维，政府领导人必须进行要在他们离任多年后才能收回成本的投资。
----------
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想像一下沒有對應的中文，要閱讀這些英文得花多少時間。你可以試著消化其中幾句中文與其對應的英文句子，並比較一下所需要的時間差異。&lt;/p&gt;
&lt;p&gt;雖然只是隨意列出的 10 個中英句子，你應該跟我一樣也能感受到機器翻譯研究的重要以及其能帶給我們的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建立中文與英文字典"&gt;建立中文與英文字典&lt;a class="anchor-link" href="#建立中文與英文字典"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就跟大多數 NLP 專案相同，有了原始的中英句子以後我們得分別為其建立字典來將每個詞彙轉成索引（Index）。&lt;code&gt;tfds.features.text&lt;/code&gt; 底下的 &lt;code&gt;SubwordTextEncoder&lt;/code&gt; 提供非常方便的 API 讓我們掃過整個訓練資料集並建立字典。&lt;/p&gt;
&lt;p&gt;首先為英文語料建立字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
try:
  subword_encoder_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)
  print(f"載入已建立的字典： {en_vocab_file}")
except:
  print("沒有已建立的字典，從頭建立。")
  subword_encoder_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(
      (en.numpy() for en, _ in train_examples), 
      target_vocab_size=2**13) # 有需要可以調整字典大小
  
  # 將字典檔案存下以方便下次 warmstart
  subword_encoder_en.save_to_file(en_vocab_file)
  

print(f"字典大小：{subword_encoder_en.vocab_size}")
print(f"前 10 個 subwords：{subword_encoder_en.subwords[:10]}")
print()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;載入已建立的字典： /content/gdrive/My Drive/nmt/en_vocab
字典大小：8135
前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'that_', 'is_']

CPU times: user 41 ms, sys: 7.43 ms, total: 48.4 ms
Wall time: 391 ms
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你的語料庫（corpus） 不小，要掃過整個資料集並建立一個字典得花不少時間。因此實務上我們會先使用 &lt;code&gt;load_from_file&lt;/code&gt; 函式嘗試讀取之前已經建好的字典檔案，失敗才 &lt;code&gt;build_from_corpus&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;這招很基本，但在你需要重複處理巨大語料庫時非常重要。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;subword_encoder_en&lt;/code&gt; 則是利用 &lt;a href="https://arxiv.org/pdf/1609.08144.pdf"&gt;GNMT 當初推出的 wordpieces&lt;/a&gt; 來進行斷詞，而簡單來說其產生的子詞（subword）介於這兩者之間：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用英文字母分隔的斷詞（character-delimited）&lt;/li&gt;
&lt;li&gt;用空白分隔的斷詞（word-delimited）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在掃過所有英文句子以後，&lt;code&gt;subword_encoder_en&lt;/code&gt; 建立一個有 8135 個子詞的字典。我們可以用該字典來幫我們將一個英文句子轉成對應的索引序列（index sequence）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Taiwan is beautiful.'&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[2700, 7911, 10, 2942, 7457, 1163, 7925]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣的索引序列你應該已經見怪不怪了。我們在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;以前的 NLP 入門文章&lt;/a&gt;也使用 &lt;code&gt;tf.keras&lt;/code&gt; 裡頭的 &lt;code&gt;Tokenizer&lt;/code&gt; 做過類似的事情。&lt;/p&gt;
&lt;p&gt;接著讓我們將這些索引還原，看看它們的長相：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{0:10}{1:6}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Index"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Subword"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;subword&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{0:5}{1:6}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Index     Subword
---------------
 2700     Taiwan
 7911      
   10     is 
 2942     bea
 7457     uti
 1163     ful
 7925     .
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當 subword tokenizer 遇到從沒出現過在字典裡的詞彙，會將該詞拆成多個子詞（subwords）。比方說上面句中的 &lt;code&gt;beautiful&lt;/code&gt; 就被拆成 &lt;code&gt;bea uti ful&lt;/code&gt;。這也是為何這種斷詞方法比較不怕沒有出現過在字典裡的字（out-of-vocabulary words）。&lt;/p&gt;
&lt;p&gt;另外別在意我為了對齊寫的 &lt;code&gt;print&lt;/code&gt; 語法。重點是我們可以用 &lt;code&gt;subword_encoder_en&lt;/code&gt; 的 &lt;code&gt;decode&lt;/code&gt; 函式再度將索引數字轉回其對應的子詞。編碼與解碼是 2 個完全可逆（invertable）的操作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Taiwan is beautiful.'&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;decoded_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;decoded_string&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;sample_string&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;decoded_string&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;('Taiwan is beautiful.', 'Taiwan is beautiful.')
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;酷！接著讓我們如法炮製，為中文也建立一個字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%%&lt;/span&gt;&lt;span class="k"&gt;time&lt;/span&gt;
try:
  subword_encoder_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)
  print(f"載入已建立的字典： {zh_vocab_file}")
except:
  print("沒有已建立的字典，從頭建立。")
  subword_encoder_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(
      (zh.numpy() for _, zh in train_examples), 
      target_vocab_size=2**13, # 有需要可以調整字典大小
      max_subword_length=1) # 每一個中文字就是字典裡的一個單位
  
  # 將字典檔案存下以方便下次 warmstart 
  subword_encoder_zh.save_to_file(zh_vocab_file)

print(f"字典大小：{subword_encoder_zh.vocab_size}")
print(f"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}")
print()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;載入已建立的字典： /content/gdrive/My Drive/nmt/zh_vocab
字典大小：4201
前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']

CPU times: user 27.6 ms, sys: 121 &amp;micro;s, total: 27.7 ms
Wall time: 337 ms
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在使用 &lt;code&gt;build_from_corpus&lt;/code&gt; 函式掃過整個中文資料集時，我們將 &lt;code&gt;max_subword_length&lt;/code&gt; 參數設置為 1。這樣可以讓每個漢字都會被視為字典裡頭的一個單位。畢竟跟英文的 abc 字母不同，一個漢字代表的意思可多得多了。而且如果使用 n-gram 的話可能的詞彙組合太多，在小數據集的情況非常容易遇到不存在字典裡頭的字。&lt;/p&gt;
&lt;p&gt;另外所有漢字也就大約 4000 ~ 5000 個可能，作為一個分類問題（classification problem）還是可以接受的。&lt;/p&gt;
&lt;p&gt;讓我們挑個中文句子來測試看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_examples&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sample_string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;多劳应多得
[48, 557, 116, 48, 81]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好的，我們把中英文斷詞及字典的部分都搞定了。現在給定一個例子（example，在這邊以及後文指的都是一組包含同語義的中英平行句子），我們都能將其轉換成對應的索引序列了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"The eurozone&amp;rsquo;s collapse forces a major realignment of European politics."&lt;/span&gt;
&lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"欧元区的瓦解强迫欧洲政治进行一次重大改组。"&lt;/span&gt;

&lt;span class="c1"&gt;# 將文字轉成為 subword indices&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"[英中原文]（轉換前）"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"[英中序列]（轉換後）"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[英中原文]（轉換前）
The eurozone&amp;rsquo;s collapse forces a major realignment of European politics.
欧元区的瓦解强迫欧洲政治进行一次重大改组。

--------------------

[英中序列]（轉換後）
[17, 965, 11, 6, 1707, 676, 8, 211, 2712, 6683, 249, 3, 85, 1447, 7925]
[45, 206, 171, 1, 847, 197, 236, 604, 45, 90, 17, 130, 102, 36, 7, 284, 80, 18, 212, 265, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們針對這些索引序列（index sequence）做一些前處理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="前處理數據"&gt;前處理數據&lt;a class="anchor-link" href="#前處理數據"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在處理序列數據時我們時常會在一個序列的前後各加入一個特殊的 token，以標記該序列的開始與完結，而它們常有許多不同的稱呼：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;開始 token、&lt;strong&gt;B&lt;/strong&gt;egin &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;S&lt;/strong&gt;entence、BOS、&lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;結束 token、&lt;strong&gt;E&lt;/strong&gt;nd &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;S&lt;/strong&gt;entence、EOS、&lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這邊我們定義了一個將被 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 使用的 &lt;code&gt;encode&lt;/code&gt; 函式，它的輸入是一筆包含 2 個 &lt;code&gt;string&lt;/code&gt; Tensors 的例子，輸出則是 2 個包含 BOS / EOS 的索引序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 因為字典的索引從 0 開始，&lt;/span&gt;
  &lt;span class="c1"&gt;# 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值&lt;/span&gt;
  &lt;span class="c1"&gt;# 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值&lt;/span&gt;
  &lt;span class="n"&gt;en_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="c1"&gt;# 同理，不過是使用中文字典的最後一個索引 + 1&lt;/span&gt;
  &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
      &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 裡頭都是在操作 Tensors（而非 Python 字串），所以這個 &lt;code&gt;encode&lt;/code&gt; 函式預期的輸入也是 TensorFlow 裡的 &lt;a href="https://www.tensorflow.org/guide/eager"&gt;Eager Tensors&lt;/a&gt;。但只要我們使用 &lt;code&gt;numpy()&lt;/code&gt; 將 Tensor 裡的實際字串取出以後，做的事情就跟上一節完全相同。&lt;/p&gt;
&lt;p&gt;讓我們從訓練集裡隨意取一組中英的 Tensors 來看看這個函式的實際輸出：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'英文 BOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'英文 EOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'中文 BOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'中文 EOS 的 index：'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;輸入為 2 個 Tensors：'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'輸出為 2 個索引序列：'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文 BOS 的 index： 8135
英文 EOS 的 index： 8136
中文 BOS 的 index： 4201
中文 EOS 的 index： 4202

輸入為 2 個 Tensors：
(&amp;lt;tf.Tensor: id=306, shape=(), dtype=string, numpy=b'Making Do With More'&amp;gt;,
 &amp;lt;tf.Tensor: id=307, shape=(), dtype=string, numpy=b'\xe5\xa4\x9a\xe5\x8a\xb3\xe5\xba\x94\xe5\xa4\x9a\xe5\xbe\x97'&amp;gt;)
---------------
輸出為 2 個索引序列：
([8135, 4682, 19, 717, 7911, 298, 2701, 7980, 8136],
 [4201, 48, 557, 116, 48, 81, 4202])
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到不管是英文還是中文的索引序列，前面都加了一個代表 BOS 的索引（分別為 8135 與 4201），最後一個索引則代表 EOS（分別為 8136 與 4202）&lt;/p&gt;
&lt;p&gt;但如果我們將 &lt;code&gt;encode&lt;/code&gt; 函式直接套用到整個訓練資料集時會產生以下的錯誤訊息：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/tf-dataset-map-error.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是因為目前 &lt;code&gt;tf.data.Dataset.map&lt;/code&gt; 函式裡頭的計算是在&lt;a href="https://www.tensorflow.org/guide/graphs"&gt;計算圖模式（Graph mode）&lt;/a&gt;下執行，所以裡頭的 Tensors 並不會有 &lt;a href="https://www.tensorflow.org/alpha/guide/eager"&gt;Eager Execution&lt;/a&gt; 下才有的 &lt;code&gt;numpy&lt;/code&gt; 屬性。&lt;/p&gt;
&lt;p&gt;解法是使用 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/py_function"&gt;tf.py_function&lt;/a&gt; 將我們剛剛定義的 &lt;code&gt;encode&lt;/code&gt; 函式包成一個以 eager 模式執行的 TensorFlow Op：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors&lt;/span&gt;
  &lt;span class="c1"&gt;# 要到 `tf.py_funtion` 裡頭才是&lt;/span&gt;
  &lt;span class="c1"&gt;# 另外因為索引都是整數，所以使用 `tf.int64`&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;en_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_t&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，&lt;/span&gt;
&lt;span class="c1"&gt;# 我們會從頭建立一個正式的 `train_dataset`&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stderr output_text"&gt;
&lt;pre&gt;W0616 23:46:10.571188 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.573221 140648854296320 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tf.Tensor([8135 4682   19  717 7911  298 2701 7980 8136], shape=(9,), dtype=int64)
tf.Tensor([4201   48  557  116   48   81 4202], shape=(7,), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有點 tricky 但任務完成！注意在套用 &lt;code&gt;map&lt;/code&gt; 函式以後，&lt;code&gt;tmp_dataset&lt;/code&gt; 的輸出已經是兩個索引序列，而非原文字串。&lt;/p&gt;
&lt;p&gt;為了讓 Transformer  快點完成訓練，讓我們將長度超過 40 個 tokens 的序列都去掉吧！我們在底下定義了一個布林（boolean）函式，其輸入為一個包含兩個英中序列 &lt;code&gt;en, zh&lt;/code&gt; 的例子，並在只有這 2 個序列的長度都小於 40 的時候回傳真值（True）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# en, zh 分別代表英文與中文的索引序列&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logical_and&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;簡單檢查是否有序列超過我們指定的長度，順便計算過濾掉過長序列後剩餘的訓練集筆數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 因為我們數據量小可以這樣 count&lt;/span&gt;
&lt;span class="n"&gt;num_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_indices&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cond1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;
  &lt;span class="n"&gt;cond2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;
  &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;cond1&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;cond2&lt;/span&gt;
  &lt;span class="n"&gt;num_examples&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"訓練資料集裡總共有 {num_examples} 筆數據"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;訓練資料集裡總共有 29914 筆數據
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;過濾掉較長句子後還有接近 3 萬筆的訓練例子，看來不用擔心數據太少。&lt;/p&gt;
&lt;p&gt;最後值得注意的是每個例子裡的索引序列長度不一，這在建立 batch 時可能會發生問題。不過別擔心，輪到 &lt;code&gt;padded_batch&lt;/code&gt; 函式出場了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="c1"&gt;# 將 batch 裡的所有序列都 pad 到同樣長度&lt;/span&gt;
&lt;span class="n"&gt;tmp_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tmp_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"英文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"中文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stderr output_text"&gt;
&lt;pre&gt;W0616 23:46:10.753194 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.760091 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0616 23:46:10.768630 140648845903616 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文索引序列的 batch
tf.Tensor(
[[8135 4682   19 ...    0    0    0]
 [8135   17  965 ... 8136    0    0]
 [8135 6602    2 ...    0    0    0]
 ...
 [8135 1097  270 ...    0    0    0]
 [8135 1713   70 ...    0    0    0]
 [8135 2731 4553 ...    0    0    0]], shape=(64, 34), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201   48  557 ...    0    0    0]
 [4201   45  206 ...    0    0    0]
 [4201   58    5 ...  683    3 4202]
 ...
 [4201   29  120 ...    0    0    0]
 [4201  297  161 ...    0    0    0]
 [4201  279  149 ... 4202    0    0]], shape=(64, 40), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;padded_batch&lt;/code&gt; 函式能幫我們將每個 batch 裡頭的序列都補 0 到跟當下 batch 裡頭最長的序列一樣長。&lt;/p&gt;
&lt;p&gt;比方說英文 batch 裡最長的序列為 34；而中文 batch 裡最長的序列則長達 40 個 tokens，剛好是我們前面設定過的序列長度上限。&lt;/p&gt;
&lt;p&gt;好啦，現在讓我們從頭建立訓練集與驗證集，順便看看這些中英句子是如何被轉換成它們的最終形態的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;40&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;15000&lt;/span&gt;

&lt;span class="c1"&gt;# 訓練集&lt;/span&gt;
&lt;span class="n"&gt;train_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_examples&lt;/span&gt;  &lt;span class="c1"&gt;# 輸出：(英文句子, 中文句子)&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 輸出：(英文索引序列, 中文索引序列)&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 同上，且序列長度都不超過 40&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cache&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# 加快讀取數據&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BUFFER_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 將例子洗牌確保隨機性&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;# 將 batch 裡的序列都 pad 到一樣長度&lt;/span&gt;
                               &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
                 &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prefetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;experimental&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;AUTOTUNE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 加速&lt;/span&gt;
&lt;span class="c1"&gt;# 驗證集&lt;/span&gt;
&lt;span class="n"&gt;val_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;val_examples&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filter_max_length&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
               &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                             &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;建構訓練資料集時我們還添加了些沒提過的函式。它們的用途大都是用來提高輸入效率，並不會影響到輸出格式。如果你想深入了解這些函式的運作方式，可以參考 &lt;a href="https://www.tensorflow.org/guide/performance/datasets?hl=zh_cn"&gt;tf.data 的官方教學&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在讓我們看看最後建立出來的資料集長什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh_batch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"英文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;en_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"中文索引序列的 batch"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zh_batch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;英文索引序列的 batch
tf.Tensor(
[[8135  222    1 ...    0    0    0]
 [8135 3812  162 ...    0    0    0]
 [8135 6267  838 ...    0    0    0]
 ...
 [8135   17 1042 ...    0    0    0]
 [8135 7877 1165 ...    0    0    0]
 [8135 6414 7911 ...    0    0    0]], shape=(128, 40), dtype=int64)
--------------------
中文索引序列的 batch
tf.Tensor(
[[4201  109   54 ...    3 4202    0]
 [4201   30    4 ...    0    0    0]
 [4201  402    4 ...    0    0    0]
 ...
 [4201  626  515 ...    0    0    0]
 [4201   49  249 ...    0    0    0]
 [4201  905  209 ...    0    0    0]], shape=(128, 40), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嘿！我們建立了一個可供訓練的輸入管道（Input pipeline）！&lt;/p&gt;
&lt;p&gt;你會發現訓練集：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一次回傳大小為 128 的 2 個 batch，分別包含 128 個英文、中文的索引序列&lt;/li&gt;
&lt;li&gt;序列開頭皆為 BOS，英文的 BOS 索引是 8135；中文的 BOS 索引則為 4201&lt;/li&gt;
&lt;li&gt;兩語言 batch 裡的序列都被「拉長」到我們先前定義的最長序列長度：40&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;驗證集也是相同的輸出形式。&lt;/p&gt;
&lt;p&gt;現在你應該可以想像我們在每個訓練步驟會拿出來的數據長什麼樣子了：2 個 shape 為 (batch_size, seq_len) 的 Tensors，而裡頭的每一個索引數字都代表著一個中 / 英文子詞（或是 BOS / EOS）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這一節我們建立了一個通用資料集。「通用」代表不限於 Transformer，你也能用&lt;a href="https://www.tensorflow.org/beta/tutorials/text/nmt_with_attention"&gt;一般搭配注意力機制的 Seq2Seq 模型&lt;/a&gt;來處理這個資料集並做中英翻譯。&lt;/p&gt;
&lt;p&gt;但從下節開始讓我們把這個數據集先擺一邊，將注意力全部放到 Transformer 身上並逐一實作其架構裡頭的各個元件。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="理解-Transformer-之旅：跟著多維向量去冒險_1"&gt;理解 Transformer 之旅：跟著多維向量去冒險&lt;a class="anchor-link" href="#理解-Transformer-之旅：跟著多維向量去冒險"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實作 Transformer 及注意力機制這種高度平行運算的模型時，你將需要一點「空間想像力」，能夠想像最高高達 4 維的向量是怎麼在 Transformer 的各個元件被處理與轉換的。&lt;/p&gt;
&lt;p&gt;如果你跟我一樣腦袋並不是那麼靈光的話，這可不是一件簡單的事情。不過別擔心，從這節開始我會把 Transfomer （主要針對注意力機制）裡頭的矩陣運算過程視覺化（visualize）出來，讓你在這個多維空間裡頭也能悠遊自在。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/the-matrix-world.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Welcome to matrix, 準備進入多維空間
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就好像一般你在寫程式時會追蹤某些變數在函式裡頭的變化，一個直觀理解 Transformer 的方法是將幾個句子丟入其中，並觀察 Transformer 對它們做了些什麼轉換。&lt;/p&gt;
&lt;p&gt;首先讓我們建立兩個要拿來持續追蹤的中英平行句子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;demo_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"It is important."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"这很重要。"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"The numbers speak for themselves."&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"数字证明了一切。"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;pprint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[('It is important.', '这很重要。'),
 ('The numbers speak for themselves.', '数字证明了一切。')]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著利用&lt;a href="#建立輸入管道"&gt;之前建立資料集的方法&lt;/a&gt;將這 2 組中英句子做些前處理並以 Tensor 的方式讀出：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;demo_examples&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_tensor_slices&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;en&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zh&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）&lt;/span&gt;
&lt;span class="c1"&gt;# 並添加 padding token: &amp;lt;pad&amp;gt; 來確保 batch 裡的句子有一樣長度&lt;/span&gt;
&lt;span class="n"&gt;demo_dataset&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;demo_examples&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf_encode&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
  &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;padded_batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padded_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;

&lt;span class="c1"&gt;# 取出這個 demo dataset 裡唯一一個 batch&lt;/span&gt;
&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;iter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;demo_dataset&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'inp:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tar:'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)

tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上節建立的數據集屍骨未寒，你應該還記得 &lt;code&gt;inp&lt;/code&gt;  shape 裡頭第一個維度的 &lt;code&gt;2&lt;/code&gt; 代表著這個 batch 有 2 個句子，而第二維度的 &lt;code&gt;8&lt;/code&gt; 則代表著句子的長度（單位：子詞）；&lt;code&gt;tar&lt;/code&gt; 則為中文子詞序列（subword sequence），不過因為中文我們以漢字為單位作斷詞，長度一般會比對應的英文句子來的長（shape 中的 &lt;code&gt;10&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;2 維矩陣還很容易想像，但我擔心等到你進入 3 維空間後就會想放棄人生了。所以還是先讓我們用人類比較容易理解的方式來呈現這些數據。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="視覺化原始句子"&gt;視覺化原始句子&lt;a class="anchor-link" href="#視覺化原始句子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們把這 2 個 batch 用你比較熟悉的方式呈現的話會長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/inp_tar.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/inp_tar.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣清楚多了不是嗎？現在點擊播放鍵，將索引序列還原成原始的子詞序列。&lt;/p&gt;
&lt;p&gt;你可以清楚地看到每個&lt;strong&gt;原始&lt;/strong&gt;句子前後都有 &lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt; 與 &lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt;。而為了讓同個 batch 裡頭的序列長度相同，我們在較短的序列後面也補上足夠的 0，代表著 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;這個視覺化非常簡單，但十分強大。我現在要你記住一些本文會使用的慣例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不管&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F"&gt;張量（Tensor）&lt;/a&gt;變幾維，其第一個維度 &lt;code&gt;shape[0]&lt;/code&gt; 永遠代表 &lt;code&gt;batch_size&lt;/code&gt;，也就代表著句子的數目&lt;/li&gt;
&lt;li&gt;不同句子我們用不同顏色表示，方便你之後對照這些句子在轉換前後的差異&lt;/li&gt;
&lt;li&gt;x 軸（橫軸）代表張量的最後一個維度 &lt;code&gt;shape[-1]&lt;/code&gt;，以上例來說分別為 &lt;code&gt;8&lt;/code&gt; 和 &lt;code&gt;10&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;x, y 軸上的標籤分別代表倒數兩個維度 &lt;code&gt;shape[-2]&lt;/code&gt; 及 &lt;code&gt;shape[-1]&lt;/code&gt; 其所代表的物理含義，如圖中的&lt;strong&gt;句子&lt;/strong&gt;與&lt;strong&gt;子詞&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;圖中張量的 &lt;code&gt;name&lt;/code&gt; 會對應到程式碼裡頭定義的變數名稱，方便你對照並理解實作邏輯。我也會秀出張量的 shape  幫助你想像該向量在多維空間的長相。一個簡單的例子是：&lt;code&gt;(batch_size, tar_seq_len)&lt;/code&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些準則與資訊現在看似多餘，但我保證你很快就會需要它們。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="視覺化-3-維詞嵌入張量"&gt;視覺化 3 維詞嵌入張量&lt;a class="anchor-link" href="#視覺化-3-維詞嵌入張量"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在將索引序列丟入神經網路之前，我們一般會做&lt;a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B5%8C%E5%85%A5"&gt;詞嵌入（word embedding）&lt;/a&gt;，將一個維度為字典大小的高維離散空間「嵌入」到低維的連續空間裡頭。&lt;/p&gt;
&lt;p&gt;讓我們為英文與中文分別建立一個詞嵌入層並實際對 &lt;code&gt;inp&lt;/code&gt; 及 &lt;code&gt;tar&lt;/code&gt; 做轉換：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# + 2 是因為我們額外加了 &amp;lt;start&amp;gt; 以及 &amp;lt;end&amp;gt; tokens&lt;/span&gt;
&lt;span class="n"&gt;vocab_size_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;vocab_size_zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="c1"&gt;# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer_en&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size_en&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer_zh&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size_zh&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;emb_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer_en&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;emb_tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer_zh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意你的詞嵌入層的隨機初始值會跟我不同，結果可能會有一點差異。&lt;/p&gt;
&lt;p&gt;但重點是你能在腦海中理解這兩個 3 維張量嗎？花了幾秒鐘？我相信在座不乏各路高手，而且事實上在這一行混久了，你也必須能直覺地理解這個表示方式。&lt;/p&gt;
&lt;p&gt;但如果有更好的呈現方式幫助我們理解數據，何樂而不為呢？讓我們再次視覺化這兩個 3 維詞嵌入張量：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/emb_inp_tar.jpeg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/emb_inp_tar.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照前面提過的準則，張量中第一個維度的 &lt;code&gt;2&lt;/code&gt; 代表著句子數 &lt;code&gt;batch_size&lt;/code&gt;。在 3 維空間裡頭，我會將不同句子畫在 z 軸上，也就是你現在把臉貼近 /  遠離螢幕這個維度。你同時也能用不同顏色來區分句子。&lt;/p&gt;
&lt;p&gt;緊跟著句子的下一個維度則一樣是本來的子詞（subword）。只是現在每個子詞都已從一個索引數字被轉換成一個 4 維的詞嵌入向量，因此每個子詞都以 y 軸來表示。最後一維則代表著詞嵌入空間的維度，一樣以 x 軸來表示。&lt;/p&gt;
&lt;p&gt;現在再次點擊播放鍵。&lt;/p&gt;
&lt;p&gt;在學會怎麼解讀這個 3 維詞嵌入張量以後，你就能明白為何 &lt;code&gt;emb_tar&lt;/code&gt; 第一個中文句子裡頭的倒數 3 行（row) 都長得一樣了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar[0]:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar[0]:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)
--------------------
emb_tar[0]: tf.Tensor(
[[-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]
 [-0.00285894  0.02392108 -0.03126474  0.01345349]], shape=(3, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;它們都是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token（以 &lt;code&gt;0&lt;/code&gt; 表示），理當有一樣的詞嵌入向量。&lt;/p&gt;
&lt;p&gt;不同顏色也讓我們可以很直觀地理解一個句子是怎麼從一個 1 維向量被轉換到 2 維的。你後面就會發現，你將需要能夠非常直覺地理解像是 &lt;code&gt;emb_tar&lt;/code&gt; 這種 3 維張量裡頭每個維度所代表的意義。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="遮罩：Transformer-的祕密配方"&gt;遮罩：Transformer 的祕密配方&lt;a class="anchor-link" href="#遮罩：Transformer-的祕密配方"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在前面並沒有仔細談過遮罩（masking）的概念，但事實上它可以說是在實作 Transformer 時最重要卻也最容易被搞砸的一環。它讓 Transformer 在進行自注意力機制（Self-Attention Mechanism）時不至於偷看到不該看的。&lt;/p&gt;
&lt;p&gt;在 Transformer 裡頭有兩種 masks：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;padding mask&lt;/li&gt;
&lt;li&gt;look ahead mask&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;padding mask 是讓 Transformer 用來識別序列實際的內容到哪裡。此遮罩負責的就是將序列中被補 0 的地方（也就是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;）的位置蓋住，讓 Transformer 可以避免「關注」到這些位置。&lt;/p&gt;
&lt;p&gt;look ahead mask 人如其名，是用來確保 Decoder 在進行自注意力機制時每個子詞只會「往前看」：關注（包含）自己之前的字詞，不會不小心關注「未來」Decoder 產生的子詞。我們後面還會看到 look ahead mask 的詳細介紹，但不管是哪一種遮罩向量，那些值為 1 的位置就是遮罩存在的地方。&lt;/p&gt;
&lt;p&gt;因為 padding mask 的概念相對簡單，讓我們先看這種遮罩：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# padding mask 的工作就是把索引序列中為 0 的位置設為 1&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;#　broadcasting&lt;/span&gt;

&lt;span class="n"&gt;inp_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;inp_mask&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193029, shape=(2, 1, 1, 8), dtype=float32, numpy=
array([[[[0., 0., 0., 0., 0., 0., 1., 1.]]],


       [[[0., 0., 0., 0., 0., 0., 0., 0.]]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;登登！我們的第一個 4 維張量！不過別緊張，我們在中間加了 2 個新維度是為了之後可以做 &lt;a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html"&gt;broadcasting&lt;/a&gt;，現在可以忽視。喔！不過如果這是你第一次聽到 broadcasting，我強烈建議你現在就閱讀 &lt;a href="https://www.numpy.org/devdocs/user/theory.broadcasting.html"&gt;numpy 官方的簡短教學&lt;/a&gt;了解其概念。我們後面也會看到實際的 broadcasting 例子。&lt;/p&gt;
&lt;p&gt;回到我們的 &lt;code&gt;inp_mask&lt;/code&gt; 遮罩。現在我們可以先將額外的維度去掉以方便跟 &lt;code&gt;inp&lt;/code&gt; 作比較：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tf.squeeze(inp_mask):"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
tf.squeeze(inp_mask): tf.Tensor(
[[0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到 &lt;code&gt;inp_mask&lt;/code&gt; 將 &lt;code&gt;inp&lt;/code&gt; 裡頭為 &lt;code&gt;0&lt;/code&gt; 的對應位置設為 1 凸顯出來，這樣之後其他函式就知道要把哪邊「遮住」。 讓我們看看被降到 2 維的 &lt;code&gt;inp_mask&lt;/code&gt; 是怎麼被套用在 &lt;code&gt;inp&lt;/code&gt; 身上的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/padding_mask.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很好懂，不是嗎？但這只是小暖身，等到之後要將遮罩 broadcast 到 3、4 維張量的時候你可能會黑人問號，所以最好做點心理準備（笑&lt;/p&gt;
&lt;p&gt;至於另外一種遮罩 look ahead mask，等我們說明完下節的注意函式以後你會比較容易理解它的作用，所以先賣個關子。現在讓我們進入 Tranformer 最核心的部分：注意力機制。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Scaled-dot-product-attention：一種注意函式"&gt;Scaled dot product attention：一種注意函式&lt;a class="anchor-link" href="#Scaled-dot-product-attention：一種注意函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在文中以及教授的影片已經多次看到，所謂的注意力機制（或稱注意函式，attention function）概念上就是拿一個查詢（query）去跟一組 key-values 做運算，最後產生一個輸出。只是我們會利用矩陣運算同時讓多個查詢跟一組 key-values 做運算，最大化計算效率。&lt;/p&gt;
&lt;p&gt;而不管是查詢（query）、鍵值（keys）還是值（values）或是輸出，全部都是向量（vectors）。該輸出是 values 的加權平均，而每個 value  獲得的權重則是由當初 value 對應的 key 跟 query 計算匹配程度所得來的。（&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文原文&lt;/a&gt;稱此計算匹配程度的函式為 compatibility function）&lt;/p&gt;
&lt;p&gt;將此運算以圖表示的話則會長得像這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/scaled-dot-product.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        左右兩邊大致上講的是一樣的事情，不過右側省略 Scale 以及 Mask 步驟，而左側則假設我們已經拿到經過線性轉換的 Q, K, V
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們是第一次秀出論文裡頭的圖片（左），但右邊你應該不陌生才對。&lt;/p&gt;
&lt;p&gt;Scaled dot product attention 跟以往 multiplicative attention 一樣是先將維度相同的 Q 跟 K 做&lt;a href="https://zh.wikipedia.org/wiki/%E7%82%B9%E7%A7%AF"&gt;點積&lt;/a&gt;：將對應維度的值兩兩相乘後相加得到單一數值，接著把這些數值除以一個 scaling factor &lt;code&gt;sqrt(dk)&lt;/code&gt; ，然後再丟入 &lt;a href="https://www.youtube.com/watch?v=mlaLLQofmR8"&gt;softmax 函式&lt;/a&gt;得到相加為 1 的注意權重（attention weights）。&lt;/p&gt;
&lt;p&gt;最後以此權重對 V 作加權平均得到輸出結果。&lt;/p&gt;
&lt;p&gt;除以 scaling factor 的目的是為了讓點積出來的值不會因為 Q 以及 K 的維度 &lt;code&gt;dk&lt;/code&gt; 太大而跟著太大（舌頭打結）。因為太大的點積值丟入 softmax 函式有可能使得其梯度變得極小，導致訓練結果不理想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/softmax-function.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Softmax 函式讓某個 Q 與多個 K 之間的匹配值和為 1
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;說完概念，讓我們看看 Transformer 論文中的這個注意函式怎麼運作吧！首先我們得先準備這個函式的輸入 Q, K, V 才行。我們在 &lt;a href="#Multi-head-attention：你看你的，我看我的"&gt;Multi-head attention&lt;/a&gt; 一節會看到，在進行 scaled dot product attention 時會需要先將 Q、K 以及 V 分別做一次線性轉換，但現在讓我們先忽略這部分。&lt;/p&gt;
&lt;p&gt;這邊我們可以拿已經被轉換成詞嵌入空間的英文張量 &lt;code&gt;emb_inp&lt;/code&gt; 來充當左圖中的 Q 以及 K，讓它自己跟自己做匹配。V 則讓我隨機產生一個 binary 張量（裡頭只有 1 或 0）來當作每個 K 所對應的值，方便我們直觀解讀 scaled dot product attention 的輸出結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 設定一個 seed 確保我們每次都拿到一樣的隨機結果&lt;/span&gt;
&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;9527&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`&lt;/span&gt;
&lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="c1"&gt;# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193043, shape=(2, 8, 4), dtype=float32, numpy=
array([[[1., 0., 0., 0.],
        [0., 1., 0., 1.],
        [0., 0., 0., 1.],
        [1., 0., 1., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [0., 0., 1., 0.],
        [0., 1., 0., 1.]],

       [[1., 0., 1., 1.],
        [1., 0., 1., 0.],
        [1., 0., 0., 0.],
        [1., 0., 1., 0.],
        [0., 1., 0., 1.],
        [1., 1., 1., 1.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，我想你現在應該能快速地解讀 3 維張量了，但還是讓我雞婆點，將現在的 Q, K, V 都畫出來讓你參考：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/q_k_v.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意顏色。雖然我們將拿 Q 跟 K 來做匹配，這個匹配只會發生在同個句子（同個顏色）底下（即 &lt;code&gt;shape[1:]&lt;/code&gt;）。在深度學習世界，我們會為了最大化 GPU 的運算效率而一次將 64 個、128 個或是更多個 &lt;code&gt;batch_size&lt;/code&gt; 的句子丟入模型。習慣 batch 維度的存在是非常實際的。&lt;/p&gt;
&lt;p&gt;接著讓我們看看 scaled dot product attention 在 TensorFlow 裡是&lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#scaled_dot_product_attention"&gt;怎麼被實作&lt;/a&gt;的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="sd"&gt;"""Calculate the attention weights.&lt;/span&gt;
&lt;span class="sd"&gt;  q, k, v must have matching leading dimensions.&lt;/span&gt;
&lt;span class="sd"&gt;  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.&lt;/span&gt;
&lt;span class="sd"&gt;  The mask has different shapes depending on its type(padding or look ahead) &lt;/span&gt;
&lt;span class="sd"&gt;  but it must be broadcastable for addition.&lt;/span&gt;
&lt;span class="sd"&gt;  &lt;/span&gt;
&lt;span class="sd"&gt;  Args:&lt;/span&gt;
&lt;span class="sd"&gt;    q: query shape == (..., seq_len_q, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    k: key shape == (..., seq_len_k, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    v: value shape == (..., seq_len_v, depth_v)&lt;/span&gt;
&lt;span class="sd"&gt;    mask: Float tensor with shape broadcastable &lt;/span&gt;
&lt;span class="sd"&gt;          to (..., seq_len_q, seq_len_k). Defaults to None.&lt;/span&gt;
&lt;span class="sd"&gt;    &lt;/span&gt;
&lt;span class="sd"&gt;  Returns:&lt;/span&gt;
&lt;span class="sd"&gt;    output, attention_weights&lt;/span&gt;
&lt;span class="sd"&gt;  """&lt;/span&gt;
  &lt;span class="c1"&gt;# 將 `q`、 `k` 做點積再 scale&lt;/span&gt;
  &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transpose_b&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, seq_len_k)&lt;/span&gt;
  
  &lt;span class="n"&gt;dk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 取得 seq_k 的序列長度&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# scale by sqrt(dk)&lt;/span&gt;

  &lt;span class="c1"&gt;# 將遮罩「加」到被丟入 softmax 前的 logits&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均&lt;/span&gt;
  &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, seq_len_k)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 以注意權重對 v 做加權平均（weighted average）&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matmul&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (..., seq_len_q, depth_v)&lt;/span&gt;

  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別被嚇到了。除了遮罩的運算部分我們還沒解釋，這 Python 函式事實上就是用 TensorFlow API 來實現剛剛才說的注意力機制邏輯罷了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將 &lt;code&gt;q&lt;/code&gt; 和 &lt;code&gt;k&lt;/code&gt; 做點積得到 &lt;code&gt;matmul_qk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將 &lt;code&gt;matmul_qk&lt;/code&gt; 除以 scaling factor &lt;code&gt;sqrt(dk)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;有遮罩的話在丟入 softmax &lt;strong&gt;前&lt;/strong&gt;套用&lt;/li&gt;
&lt;li&gt;通過 softmax 取得加總為 1 的注意權重&lt;/li&gt;
&lt;li&gt;以該權重加權平均 &lt;code&gt;v&lt;/code&gt; 作為輸出結果&lt;/li&gt;
&lt;li&gt;回傳輸出結果以及注意權重&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;扣掉註解事實上也就只有 8 行代碼（當然有很多實作細節）。現在先讓我們實際將 &lt;code&gt;q&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; 輸入此函式看看得到的結果。假設沒有遮罩的存在：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;output: tf.Tensor(
[[[0.37502408 0.37503672 0.37488326 0.49993956]
  [0.37513658 0.37514552 0.37500778 0.49994028]
  [0.37483314 0.37482613 0.3749625  0.50006175]
  [0.37516367 0.37501514 0.3750258  0.49997073]
  [0.37503195 0.3751256  0.3750621  0.49998796]
  [0.37512696 0.37512186 0.37502852 0.49996266]
  [0.3748441  0.3749599  0.37492597 0.50001484]
  [0.3748441  0.3749599  0.37492597 0.50001484]]

 [[0.62516296 0.2500847  0.6250717  0.37522966]
  [0.62490153 0.24994145 0.62504375 0.37497035]
  [0.62509674 0.2501282  0.6249581  0.37518966]
  [0.62518024 0.25003165 0.6250133  0.37507355]
  [0.6250232  0.25011832 0.62486345 0.37516582]
  [0.6251376  0.25018096 0.625095   0.37525034]
  [0.62478966 0.24995528 0.6248975  0.37490302]
  [0.62492853 0.24997747 0.62507135 0.37497336]]], shape=(2, 8, 4), dtype=float32)
--------------------
attention_weights: tf.Tensor(
[[[0.12517719 0.12502946 0.12490283 0.12493535 0.12491155 0.12497091
   0.12503636 0.12503636]
  [0.12505189 0.12512855 0.12479477 0.1250193  0.12506542 0.12509388
   0.12492308 0.12492308]
  [0.12497574 0.12484524 0.1252356  0.12496044 0.12489695 0.1248758
   0.12510511 0.12510511]
  [0.12500346 0.12506503 0.1249556  0.12519364 0.12496658 0.12508455
   0.12486558 0.12486558]
  [0.12494988 0.12508136 0.12486238 0.12493681 0.12514524 0.12506418
   0.12498005 0.12498005]
  [0.12500885 0.12510943 0.12484082 0.12505434 0.12506378 0.12510203
   0.12491038 0.12491038]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]
  [0.1250592  0.12492351 0.12505497 0.12482036 0.12496454 0.12489527
   0.12514108 0.12514108]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;scaled_dot_product_attention&lt;/code&gt; 函式輸出兩個張量：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;output&lt;/code&gt; 代表注意力機制的結果&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attention_weights&lt;/code&gt; 代表句子 &lt;code&gt;q&lt;/code&gt; 裡頭每個子詞對句子 &lt;code&gt;k&lt;/code&gt; 裡頭的每個子詞的注意權重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而因為你知道目前的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都代表同個張量 &lt;code&gt;emb_inp&lt;/code&gt;，因此 &lt;code&gt;attention_weights&lt;/code&gt; 事實上就代表了 &lt;code&gt;emb_inp&lt;/code&gt; 裡頭每個英文序列中的子詞對其他位置的子詞的注意權重。你可以再次參考之前 Transformer 是如何做 encoding 的動畫。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;output&lt;/code&gt; 則是句子裡頭每個位置的子詞將 &lt;code&gt;attention_weights&lt;/code&gt; 當作權重，從其他位置的子詞對應的資訊 &lt;code&gt;v&lt;/code&gt; 裡頭抽取有用訊息後匯總出來的結果。你可以想像 &lt;code&gt;ouput&lt;/code&gt; 裡頭的每個子詞都獲得了一個包含自己以及周遭子詞語義資訊的新 representation。而因為現在每個字詞的注意權重都相同，最後得到的每個 repr. 都長得一樣。&lt;/p&gt;
&lt;p&gt;下面則是我們實作的注意函式的所有輸入與輸出張量。透過多次的矩陣運算，注意力機制能讓查詢 Q 跟鍵值 K 做匹配，再依據此匹配程度將值 V 做加權平均獲得新的 representation。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/scaled_dot_product_attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/scaled_dot_product_attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Scaled dot product attention 的實際運算過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別只聽我碎碎念，自己點擊播放鍵來了解背後到底發生什麼事情吧！&lt;/p&gt;
&lt;p&gt;動畫裡包含許多細節，但只要有矩陣運算的基本概念，你應該已經能夠直觀且正確地理解注意函式是怎麼運作的了。在真實世界裡我們當然會用更長的序列、更大的 &lt;code&gt;batch_size&lt;/code&gt; 來處理數據，但上面呈現的是程式碼的實際結果，而非示意圖而已。這是注意力機制真正的「所見即所得」。&lt;/p&gt;
&lt;p&gt;一般來說注意函式的輸出 &lt;code&gt;output&lt;/code&gt;張量維度會跟 &lt;code&gt;q&lt;/code&gt; 張量相同（假設圖上的 &lt;code&gt;depth_v&lt;/code&gt; 等於 &lt;code&gt;depth&lt;/code&gt;）。此張量也被稱作「注意張量」，你可以將其解讀為 &lt;code&gt;q&lt;/code&gt; 在關注 &lt;code&gt;k&lt;/code&gt; 並從 &lt;code&gt;v&lt;/code&gt; 得到上下文訊息後的所獲得的新 representation。而注意權重 &lt;code&gt;attention_weights&lt;/code&gt; 則是 &lt;code&gt;q&lt;/code&gt; 裡頭每個句子的每個子詞對其他位置的子詞的關注程度。&lt;/p&gt;
&lt;p&gt;P.S. 一般注意函式只需輸出注意張量。而我們在這邊將注意權重 &lt;code&gt;attention_weights&lt;/code&gt; 也輸出是為了方便之後觀察 Transformer 在訓練的時候將「注意力」放在哪裡。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="直觀理解遮罩在注意函式中的效果"&gt;直觀理解遮罩在注意函式中的效果&lt;a class="anchor-link" href="#直觀理解遮罩在注意函式中的效果"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剛剛為了讓你消化注意函式裡頭最重要的核心邏輯，我刻意忽略了遮罩（masking）的存在。現在讓我們重新把 &lt;code&gt;scaled_dot_product_attention&lt;/code&gt; 裡頭跟遮罩相關的程式碼拿出來瞧瞧：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="c1"&gt;# 將 `q`、 `k` 做點積再 scale&lt;/span&gt;
&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;matmul_qk&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將遮罩「加」到被丟入 softmax 前的 logits&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 取 softmax 是為了得到總和為 1 的比例做加權平均&lt;/span&gt;
&lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你剛剛有仔細看上面的動畫的話（17 秒之後），應該能想像 &lt;code&gt;scaled_attention_logits&lt;/code&gt; 的 shape 為 （batch_size, seq_len_q, seq_len_k）。其最後一個維度代表某個序列 &lt;code&gt;q&lt;/code&gt; 裡的某個子詞與序列 &lt;code&gt;k&lt;/code&gt; 的&lt;strong&gt;每個&lt;/strong&gt;子詞的匹配程度，但加總不為 1。而為了之後跟與 &lt;code&gt;k&lt;/code&gt; 對應的 &lt;code&gt;v&lt;/code&gt; 做加權平均，我們針對最後一個維度做 softmax 運算使其和為 1，也就是上圖 &lt;code&gt;axis=-1&lt;/code&gt; 的部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/softmax.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/softmax.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        對最後一維做 softmax。模型還沒經過訓練所以「注意力」非常平均
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果序列 &lt;code&gt;k&lt;/code&gt; 裡頭的每個子詞 &lt;code&gt;sub_k&lt;/code&gt; 都是實際存在的中文字或英文詞彙，這運算當然沒問題。我們會希望序列 &lt;code&gt;q&lt;/code&gt; 裡頭的每個子詞 &lt;code&gt;sub_q&lt;/code&gt; 都能從每個 &lt;code&gt;sub_k&lt;/code&gt; 獲得它所需要的語義資訊。&lt;/p&gt;
&lt;p&gt;但李組長眉頭一皺，發現案情並不單純。&lt;/p&gt;
&lt;p&gt;回想一下，我們的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都是從 &lt;code&gt;emb_inp&lt;/code&gt; 來的。&lt;code&gt;emb_inp&lt;/code&gt; 代表著英文句子的詞嵌入張量，而裡頭的第一個句子應該是有 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 的。啊哈！誰會想要放注意力在沒有實際語義的傢伙上呢？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1e9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 是 -1e9 不是 1e-9&lt;/span&gt;

&lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;softmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention_logits&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因此在注意函式裡頭，我們將遮罩乘上一個接近&lt;strong&gt;負&lt;/strong&gt;無窮大的 &lt;code&gt;-1e9&lt;/code&gt;，並把它加到進入 softmax &lt;strong&gt;前&lt;/strong&gt;的 logits 上面。這樣可以讓這些被加上極小值的位置變得無關緊要，在經過 softmax 以後的值趨近於 0。這效果等同於序列 &lt;code&gt;q&lt;/code&gt; 中的某個子詞 &lt;code&gt;sub_q&lt;/code&gt; 完全沒放注意力在這些被遮罩蓋住的子詞 &lt;code&gt;sub_k&lt;/code&gt; 之上（此例中 &lt;code&gt;sub_k&lt;/code&gt; 指是的 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;（動腦時間：為何遮罩要放在 softmax 之前而不能放之後？）&lt;/p&gt;
&lt;p&gt;聽我說那麼多不如看實際的運算結果。讓我們再次為英文句子 &lt;code&gt;inp&lt;/code&gt; 產生對應的 padding mask：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# padding mask 的工作就是把索引序列中為 0 的位置設為 1&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;#　broadcasting&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;inp_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
inp_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，&lt;strong&gt;第一個&lt;/strong&gt;英文序列的最後 2 個位置是不具任何語義的 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;（圖中為 &lt;code&gt;0&lt;/code&gt; 的部分）。而這也是為何我們需要將遮罩 &lt;code&gt;inp_mask&lt;/code&gt; 輸入到注意函式，避免序列中的子詞關注到這 2 個傢伙的原因。&lt;/p&gt;
&lt;p&gt;我們這次把 &lt;code&gt;inp_mask&lt;/code&gt; 降到 3 維，並且將其跟剛剛的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 和 &lt;code&gt;v&lt;/code&gt; 一起丟進注意函式裡頭，看看注意權重有什麼變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 這次讓我們將 padding mask 放入注意函式並觀察&lt;/span&gt;
&lt;span class="c1"&gt;# 注意權重的變化&lt;/span&gt;
&lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# (batch_size, 1, seq_len_q)&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;attention_weights: tf.Tensor(
[[[0.16691911 0.1667221  0.16655324 0.16659662 0.1665649  0.16664404
   0.         0.        ]
  [0.16670164 0.16680385 0.1663589  0.16665822 0.16671969 0.16675764
   0.         0.        ]
  [0.16668104 0.16650699 0.16702762 0.16666064 0.16657597 0.16654775
   0.         0.        ]
  [0.16661155 0.16669361 0.16654776 0.16686502 0.16656238 0.16671962
   0.         0.        ]
  [0.16659099 0.16676629 0.16647433 0.16657357 0.16685146 0.16674338
   0.         0.        ]
  [0.16663864 0.16677272 0.16641466 0.16669929 0.16671185 0.16676286
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]
  [0.16680835 0.16662736 0.1668027  0.16648975 0.16668208 0.1665897
   0.         0.        ]]

 [[0.12514497 0.1249882  0.12503006 0.12493392 0.1250188  0.12506588
   0.1248794  0.12493874]
  [0.1250289  0.12513264 0.12493595 0.12481083 0.12494826 0.12499319
   0.12507208 0.12507817]
  [0.12506142 0.12492662 0.12505917 0.12498691 0.12506557 0.12506266
   0.12491715 0.12492047]
  [0.12504192 0.12487808 0.1250636  0.12521076 0.12504579 0.12498584
   0.12487733 0.12489669]
  [0.12504749 0.12493626 0.12506288 0.12496644 0.12510824 0.12501009
   0.12496544 0.12490314]
  [0.12506938 0.12495602 0.1250348  0.12488137 0.12498492 0.12519602
   0.12488527 0.12499221]
  [0.12494776 0.12509981 0.1249542  0.12483776 0.12500516 0.12495013
   0.12514311 0.12506206]
  [0.12499588 0.12509465 0.12494626 0.12484587 0.1249316  0.12504588
   0.12505081 0.12508905]]], shape=(2, 8, 8), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;加了 padding mask 後，第一個句子裡頭的每個子詞針對倒數兩個字詞的「注意權重」的值都變成 0 了。上句話非常饒舌，但我相信已經是非常精準的說法了。讓我把這句話翻譯成 numpy 的 slice 語法：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 事實上也不完全是上句話的翻譯，&lt;/span&gt;
&lt;span class="c1"&gt;# 因為我們在第一個維度還是把兩個句子都拿出來方便你比較&lt;/span&gt;
&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193086, shape=(2, 8, 2), dtype=float32, numpy=
array([[[0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ],
        [0.        , 0.        ]],

       [[0.1248794 , 0.12493874],
        [0.12507208, 0.12507817],
        [0.12491715, 0.12492047],
        [0.12487733, 0.12489669],
        [0.12496544, 0.12490314],
        [0.12488527, 0.12499221],
        [0.12514311, 0.12506206],
        [0.12505081, 0.12508905]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一個英文句子的最後 2 個位置因為是 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; 所以被遮罩「蓋住」而沒有權重值（上方 2 維陣列）；第二個句子的序列（下方 2 維陣列）則因為最後 2 個位置仍是正常的英文子詞，因此都有被其他子詞關注。&lt;/p&gt;
&lt;p&gt;如果聽完我的碎碎念你還是無法理解以上結果，或是不確定有遮罩的注意函式到底怎麼運作，就實際看看其中的計算過程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/padding_mask_in_attn_func.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        將 padding mask 應用到自注意力機制運算（q = k）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一張圖勝過千言萬語。在 padding mask 的幫助下，注意函式輸出的新序列 &lt;code&gt;output&lt;/code&gt; 裡頭的每個子詞都只從序列 &lt;code&gt;k&lt;/code&gt; （也就是序列 &lt;code&gt;q&lt;/code&gt; 自己）的前 6 個實際子詞而非 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; 來獲得語義資訊（最後一張圖的黑框部分）。&lt;/p&gt;
&lt;p&gt;再次提醒，因為我們輸入注意函式的 &lt;code&gt;q&lt;/code&gt; 跟 &lt;code&gt;k&lt;/code&gt; 都是同樣的英文詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt;，事實上這邊做的就是讓英文句子裡頭的每個子詞都去關注同句子中其他位置的子詞的資訊，並從中獲得上下文語義，而這就是所謂的自注意力機制（self-attention）：序列關注自己。&lt;/p&gt;
&lt;p&gt;當序列 &lt;code&gt;q&lt;/code&gt; 換成 Decoder 的輸出序列而序列 &lt;code&gt;k&lt;/code&gt; 變成 Encoder 的輸出序列時，我們就變成在計算一般 Seq2Seq 模型中的注意力機制。這點觀察非常重要，且&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;我們在前面就已經提過了&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;打鐵趁熱，讓我們看看前面提過的另一種遮罩 look ahead mask：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立一個 2 維矩陣，維度為 (size, size)，&lt;/span&gt;
&lt;span class="c1"&gt;# 其遮罩為一個右上角的三角形&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;band_part&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;  &lt;span class="c1"&gt;# (seq_len, seq_len)&lt;/span&gt;

&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# 注意這次我們用中文的詞嵌入張量 `emb_tar`&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"look_ahead_mask"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
look_ahead_mask tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們已經知道 demo 用的中文（目標語言）的序列長度為 &lt;code&gt;10&lt;/code&gt;，而 look ahead 遮罩就是產生一個 2 維矩陣，其兩個維度都跟中文的詞嵌入張量 &lt;code&gt;emb_tar&lt;/code&gt; 的倒數第 2 個維度（序列長度）一樣，且裡頭是一個倒三角形（1 的部分）。&lt;/p&gt;
&lt;p&gt;我們&lt;a href="#%E9%81%AE%E7%BD%A9%EF%BC%9ATransformer-%E7%9A%84%E7%A5%95%E5%AF%86%E9%85%8D%E6%96%B9"&gt;前面曾經說過&lt;/a&gt; &lt;code&gt;look_ahead_mask&lt;/code&gt; 是用來確保 Decoder 在進行自注意力機制時輸出序列裡頭的每個子詞只會關注到自己之前（左邊）的字詞，不會不小心關注到未來（右邊）理論上還沒被  Decoder 生成的子詞。&lt;/p&gt;
&lt;p&gt;運用從 padding mask 學到的概念，想像一下如果把這個倒三角的遮罩跟之前一樣套用到進入 softmax &lt;strong&gt;之前&lt;/strong&gt;的 &lt;code&gt;scaled_attention_logits&lt;/code&gt;，輸出序列 &lt;code&gt;output&lt;/code&gt; 裡頭的每個子詞的 repr. 會有什麼性質？&lt;/p&gt;
&lt;p&gt;溫馨小提醒：&lt;code&gt;scaled_attention_logits&lt;/code&gt; 裡頭的每一 row 紀錄了某個特定子詞對其他子詞的注意權重。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 讓我們用目標語言（中文）的 batch&lt;/span&gt;
&lt;span class="c1"&gt;# 來模擬 Decoder 處理的情況&lt;/span&gt;
&lt;span class="n"&gt;temp_q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp_k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;
&lt;span class="n"&gt;temp_v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 look_ahead_mask 放入注意函式&lt;/span&gt;
&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;temp_q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;temp_k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;temp_v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;attention_weights: tf.Tensor(
[[[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.49974996 0.50025004 0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33338806 0.33309633 0.3335156  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24980238 0.2497976  0.25013384 0.25026616 0.         0.
   0.         0.         0.         0.        ]
  [0.19975185 0.19982941 0.19989952 0.199991   0.20052823 0.
   0.         0.         0.         0.        ]
  [0.16658378 0.16686733 0.16656147 0.16657883 0.1664059  0.16700274
   0.         0.         0.         0.        ]
  [0.14259693 0.1427213  0.14279391 0.1429158  0.14314583 0.14267854
   0.14314772 0.         0.         0.        ]
  [0.12491751 0.12487698 0.12503591 0.12508857 0.12503389 0.12487747
   0.12507991 0.12508978 0.         0.        ]
  [0.11102892 0.1109929  0.11113416 0.11118097 0.11113235 0.11099333
   0.11117328 0.11118205 0.11118205 0.        ]
  [0.09991965 0.09988723 0.10001437 0.10005648 0.10001273 0.09988762
   0.10004956 0.10005745 0.10005745 0.10005745]]

 [[1.         0.         0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.4994912  0.5005088  0.         0.         0.         0.
   0.         0.         0.         0.        ]
  [0.33261845 0.33340293 0.3339786  0.         0.         0.
   0.         0.         0.         0.        ]
  [0.24919374 0.25002357 0.25033304 0.25044966 0.         0.
   0.         0.         0.         0.        ]
  [0.19997214 0.19964042 0.20002526 0.19986893 0.20049322 0.
   0.         0.         0.         0.        ]
  [0.16662474 0.16674054 0.16659829 0.16668092 0.16645522 0.16690029
   0.         0.         0.         0.        ]
  [0.14276491 0.14288287 0.14274995 0.14281946 0.1427529  0.14282054
   0.14320944 0.         0.         0.        ]
  [0.12491003 0.1250709  0.12497466 0.12504703 0.12481265 0.1251362
   0.12493407 0.12511446 0.         0.        ]
  [0.11102156 0.11105824 0.11103692 0.11106326 0.11112017 0.11104742
   0.11128615 0.11106552 0.11130078 0.        ]
  [0.09983386 0.10001399 0.10016464 0.10015456 0.09999382 0.09989963
   0.0998925  0.09993652 0.099891   0.10021948]]], shape=(2, 10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案呼之欲出，套用 look ahead mask 的結果就是讓序列 &lt;code&gt;q&lt;/code&gt; 裡的每個字詞只關注包含自己左側的子詞，在自己之後的位置的字詞都不看。比方說兩個中文句子的第一個字詞都只關注自己：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193126, shape=(2, 10), dtype=float32, numpy=
array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意到了嗎？兩個句子的第一個子詞因為自己前面已經沒有其他子詞，所以將全部的注意力 &lt;code&gt;1&lt;/code&gt;都放在自己身上。讓我們看看第二個子詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193131, shape=(2, 10), dtype=float32, numpy=
array([[0.49974996, 0.50025004, 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ],
       [0.4994912 , 0.5005088 , 0.        , 0.        , 0.        ,
        0.        , 0.        , 0.        , 0.        , 0.        ]],
      dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;兩個句子的第 2 個子詞因為只能看到序列中的第一個子詞以及自己，因此前兩個位置的注意權重加總即為 1，後面位置的權重皆為 0。而現在 2 個值都接近 0.5 是因為我們還沒開始訓練，Transformer 還不知道該把注意力放在哪裡。&lt;/p&gt;
&lt;p&gt;就跟一般的 &lt;a href="#%E7%A5%9E%E7%B6%93%E6%A9%9F%E5%99%A8%E7%BF%BB%E8%AD%AF%EF%BC%9AEncoder-Decoder-%E6%A8%A1%E5%9E%8B"&gt;Seq2Seq 模型&lt;/a&gt;相同，Transformer 裡頭的 Decoder 在生成輸出序列時也是一次產生一個子詞。因此跟輸入的英文句子不同，中文句子裡頭的每個子詞都是在不同時間點產生的。所以理論上 Decoder 在時間點 &lt;code&gt;t - 1&lt;/code&gt; （或者說是位置 &lt;code&gt;t - 1&lt;/code&gt;）已經生成的子詞 &lt;code&gt;subword_t_minus_1&lt;/code&gt; 在生成的時候是不可能能夠關注到下個時間點 &lt;code&gt;t&lt;/code&gt;（位置 &lt;code&gt;t&lt;/code&gt;）所生成的子詞 &lt;code&gt;subword_t&lt;/code&gt; 的，儘管它們在 Transformer 裡頭同時被做矩陣運算。&lt;/p&gt;
&lt;p&gt;一個位置的子詞不能去關注未來會在自己之後生成的子詞，而這就像是&lt;a href="https://zh.wikipedia.org/wiki/%E7%A5%96%E7%88%B6%E6%82%96%E8%AB%96"&gt;祖父悖論&lt;/a&gt;一樣有趣。&lt;/p&gt;
&lt;p&gt;實際上 look ahead mask 讓 Decoder 在生成第 1 個子詞時只看自己；在生成第 2 個子詞時關注前 1 個子詞與自己； 在生成第 3 個子詞時關注前兩個已經生成的子詞以及自己，以此類推。透過 look ahead mask，你可以想像 Transformer 既可以平行運算，又可以像是 RNN 一樣，在生成子詞時從前面已生成的子詞獲得必要的語義資訊。&lt;/p&gt;
&lt;p&gt;挺酷的，不是嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/look_ahead_mask_in_attn_func.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        look ahead mask 讓每個子詞都只關注序列中自己與之前的位置
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實際做矩陣運算的時候我們當然還是會讓注意權重為 0 的位置跟對應的 &lt;code&gt;v&lt;/code&gt; 相乘，但是上圖的黑框才是實際會對最後的 &lt;code&gt;output&lt;/code&gt; 值造成影響的權重與 &lt;code&gt;v&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;我們在這節了解 Transformer 架構裡頭的兩種遮罩以及它們的作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;padding mask：遮住 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 不讓所有子詞關注&lt;/li&gt;
&lt;li&gt;look ahead mask：遮住 Decoder 未來生成的子詞不讓之前的子詞關注&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你現在應該能夠想像遮罩在注意力機制裡頭顯得有多麽重要了：它讓注意函式進行高效率的矩陣平行運算的時候不需擔心會關注到不該關注的位置，一次獲得序列中所有位置的子詞各自應有的注意權重以及新的 reprsentation。&lt;/p&gt;
&lt;p&gt;如果 Transformer 是&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%98%E5%BD%A2%E9%87%91%E5%88%9A"&gt;變形金剛&lt;/a&gt;的話，注意力機制跟遮罩就是&lt;a href="https://www.easyatm.com.tw/wiki/%E7%81%AB%E7%A8%AE%E6%BA%90"&gt;火種源&lt;/a&gt;了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-movie.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Multi-head-attention：你看你的，我看我的"&gt;Multi-head attention：你看你的，我看我的&lt;a class="anchor-link" href="#Multi-head-attention：你看你的，我看我的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有好好聽教授講解 Transformer 的話，你應該還記得所謂的多頭注意（multi-head attention）概念。如果你到現在還沒看課程影片或者想複習一下，我把 multi-head attention 的開始跟結束時間都設置好了，你只需觀看大約 1 分半左右的影片：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; 
                            autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube-nocookie.com/embed/ugWDIIOHtPA?start=1526&amp;amp;end=1676"&gt;
&lt;/iframe&gt;
&lt;/div&gt;
&lt;center&gt;
                        李宏毅教授講解 multi-head attention 的概念
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;複習完了嗎？mutli-head attention 的概念本身並不難，用比較正式的說法就是將 Q、K 以及 V 這三個張量先&lt;strong&gt;個別&lt;/strong&gt;轉換到 &lt;em&gt;d_model&lt;/em&gt; 維空間，再將其拆成多個比較低維的 &lt;em&gt;depth&lt;/em&gt; 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出&lt;/p&gt;
&lt;p&gt;而為何要那麼「搞剛」把本來 &lt;code&gt;d_model&lt;/code&gt; 維的空間投影到多個維度較小的子空間（subspace）以後才各自進行注意力機制呢？這是因為這給予模型更大的彈性，讓它可以同時關注不同位置的子詞在不同子空間下的 representation，而不只是本來 &lt;code&gt;d_model&lt;/code&gt; 維度下的一個 representation。&lt;/p&gt;
&lt;p&gt;我們在文章最開頭看過的英翻中就是一個活生生的 mutli-head attention 例子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/en-to-ch-attention-map.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在經過&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt;前面 2 節注意函式&lt;/a&gt;的洗禮之後，你應該已經能夠看出這裏每張小圖都是一個注意權重（為了方便渲染我做了 transpose）。而事實上每張小圖都是 multi-head attention 裡頭某一個 head 的結果，總共是 8 個 heads。&lt;/p&gt;
&lt;p&gt;你會發現每個 head 在 Transformer 生成同樣的中文字時關注的英文子詞有所差異：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Head 4 在生成「們」與「再」時特別關注「renewed」&lt;/li&gt;
&lt;li&gt;Head 5 在生成「必」與「須」時特別關注「must」&lt;/li&gt;
&lt;li&gt;Head 6 &amp;amp; 8 在生成「希」與「望」時特別關注「hope」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這樣同時關注多個不同子空間裡頭的子詞的 representation，Transformer 最終可以生成更好的結果。&lt;/p&gt;
&lt;p&gt;話是這麼說，但程式碼該怎麼寫呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/multi-head-imagining.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了要實現 multi-head attention，得先能把一個 head 變成多個 heads。而這實際上就是把一個 &lt;code&gt;d_model&lt;/code&gt; 維度的向量「折」成 &lt;code&gt;num_heads&lt;/code&gt; 個 &lt;code&gt;depth&lt;/code&gt; 維向量，使得：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;num_heads * depth = d_model
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;讓我們實作一個可以做到這件事情的函式，並將英文詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt; 實際丟進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# x.shape: (batch_size, seq_len, d_model)&lt;/span&gt;
  &lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度&lt;/span&gt;
  &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;  &lt;span class="c1"&gt;# 這是分成多頭以後每個向量的維度 &lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將最後一個 d_model 維度分成 num_heads 個 depth 維度。&lt;/span&gt;
  &lt;span class="c1"&gt;# 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維&lt;/span&gt;
  &lt;span class="c1"&gt;# (batch_size, seq_len, num_heads, depth)&lt;/span&gt;
  &lt;span class="n"&gt;reshaped_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量&lt;/span&gt;
  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len, depth)&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;reshaped_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;

&lt;span class="c1"&gt;# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="c1"&gt;# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;

&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"x:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;x: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
output: tf.Tensor(
[[[[ 0.00695511 -0.03370368]
   [-0.02707888 -0.03917687]
   [ 0.0355427   0.04111305]
   [ 0.02443342 -0.03273199]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]
   [-0.00680635  0.02136201]
   [-0.00680635  0.02136201]]

  [[-0.03656032 -0.03336458]
   [-0.01213828  0.00909697]
   [ 0.00751223 -0.01974255]
   [ 0.01267544  0.03127003]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]
   [-0.02036932 -0.04211974]
   [-0.02036932 -0.04211974]]]


 [[[ 0.00695511 -0.03370368]
   [-0.0325227  -0.03433502]
   [ 0.00144588 -0.00377025]
   [ 0.04524285  0.02524642]
   [-0.0159062   0.01108797]
   [ 0.00240784 -0.04652226]
   [-0.04879753 -0.00119017]
   [-0.02148524 -0.03413673]]

  [[-0.03656032 -0.03336458]
   [-0.01849879  0.01439226]
   [-0.00798036 -0.04099905]
   [-0.00924555 -0.01368124]
   [-0.0177028  -0.0435766 ]
   [ 0.01821991 -0.04349295]
   [-0.00157104  0.01117355]
   [ 0.00708324  0.0121879 ]]]], shape=(2, 2, 8, 2), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;觀察 &lt;code&gt;output&lt;/code&gt; 與 &lt;code&gt;emb_inp&lt;/code&gt; 之間的關係，你會發現 3 維詞嵌入張量 &lt;code&gt;emb_inp&lt;/code&gt; 已經被轉換成一個 4 維張量了，且最後一個維度 &lt;code&gt;shape[-1] = 4&lt;/code&gt; 被拆成兩半。&lt;/p&gt;
&lt;p&gt;不過如果你不熟 TensorFlow API 或是矩陣運算，或許無法馬上理解 head 的維度在哪裡、還有不同 heads 之間有什麼差異。為了幫助你直觀理解 &lt;code&gt;split_heads&lt;/code&gt; 函式，我將運算過程中產生的張量都視覺化出來給你瞧瞧：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/split_heads.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/split_heads.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        split_heads 函式將 3 維張量轉換為 multi-head 的 4 維張量過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;觀察 &lt;code&gt;split_heads&lt;/code&gt; 的輸入輸出，你會發現序列裡每個子詞原來為 &lt;code&gt;d_model&lt;/code&gt; 維的 reprsentation 被拆成多個相同但較短的 &lt;code&gt;depth&lt;/code&gt; 維度。而每個 head 的 2 維矩陣事實上仍然代表原來的序列，只是裡頭子詞的 repr. 維度降低了。&lt;/p&gt;
&lt;p&gt;透過動畫，你現在應該已經能夠了解要產生 multi-head 就是將輸入張量中本來是 &lt;code&gt;d_model&lt;/code&gt; 的最後一個維度平均地「折」成想要的 head 數，進而產生一個新的 head 維度。一個句子裡頭的子詞現在不只會有一個 &lt;code&gt;d_model&lt;/code&gt; 的 repr.，而是會有 &lt;code&gt;num_heads&lt;/code&gt; 個 &lt;code&gt;depth&lt;/code&gt; 維度的 representation。&lt;/p&gt;
&lt;p&gt;接下來只要把 3 維的 Q、K 以及 V 用 &lt;code&gt;split_heads&lt;/code&gt; 拆成多個 heads 的 4 維張量，利用 broadcasting 就能以之前定義的&lt;a href="#Scaled-dot-product-attention：一種注意函式"&gt; Scaled dot product attention&lt;/a&gt; 來為每個句子裡頭的每個 head 平行計算注意結果了，超有效率！&lt;/p&gt;
&lt;p&gt;在明白如何產生 multi-head 的 4 維張量以後，multi-head attention 的實現就比較容易理解了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 實作一個執行多頭注意力機制的 keras layer&lt;/span&gt;
&lt;span class="c1"&gt;# 在初始的時候指定輸出維度 `d_model` &amp;amp; `num_heads，&lt;/span&gt;
&lt;span class="c1"&gt;# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`&lt;/span&gt;
&lt;span class="c1"&gt;# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：&lt;/span&gt;
&lt;span class="c1"&gt;# output.shape            == (batch_size, seq_len_q, d_model)&lt;/span&gt;
&lt;span class="c1"&gt;# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 在初始的時候建立一些必要參數&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="c1"&gt;# 指定要將 `d_model` 拆成幾個 heads&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="c1"&gt;# 在 split_heads 之前的基底維度&lt;/span&gt;
    
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="c1"&gt;# 前面看過，要確保可以平分&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt;  &lt;span class="c1"&gt;# 每個 head 裡子詞的新的 repr. 維度&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 分別給 q, k, v 的 3 個線性轉換 &lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 注意我們並沒有指定 activation func&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dense&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 多 heads 串接後通過的線性轉換&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 這跟我們前面看過的函式有 87% 相似&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Split the last dimension into (num_heads, depth).&lt;/span&gt;
&lt;span class="sd"&gt;    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;depth&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="c1"&gt;# multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度&lt;/span&gt;
    &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_q, depth)&lt;/span&gt;
    &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_k, depth)&lt;/span&gt;
    &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split_heads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, num_heads, seq_len_v, depth)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸出會多一個 head 維度&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)&lt;/span&gt;
    &lt;span class="c1"&gt;# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape&lt;/span&gt;
    &lt;span class="c1"&gt;# 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度&lt;/span&gt;
    &lt;span class="n"&gt;scaled_attention&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;perm&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="c1"&gt;# (batch_size, seq_len_q, num_heads, depth)&lt;/span&gt;
    &lt;span class="n"&gt;concat_attention&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scaled_attention&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
    &lt;span class="c1"&gt;# (batch_size, seq_len_q, d_model)&lt;/span&gt;

    &lt;span class="c1"&gt;# 通過最後一個線性轉換&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;concat_attention&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len_q, d_model)&lt;/span&gt;
        
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;是的，就算你有自己實作過 keras layer，multi-head attention layer 也不算短的實作。如果這是你第一次碰到客製化的 keras layer，別打退堂鼓，你可以多看幾次我寫給你的註解，或是參考等等下方的動畫來加深對 multi-head attention 的理解。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;split_heads&lt;/code&gt; 函式我們在前面就已經看過了，你應該還有印象。&lt;code&gt;call&lt;/code&gt; 函式則定義了這個 multi-head attention layer 實際的計算流程，而這流程跟我在本節開頭講的可以說是有 87% 相似：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        將 Q、K 以及 V 這三個張量先個別轉換到 d_model 維空間，再將其拆成多個比較低維的 depth 維度 N 次以後，將這些產生的小 q、小 k 以及小 v 分別丟入前面的注意函式得到 N 個結果。接著將這 N 個 heads 的結果串接起來，最後通過一個線性轉換就能得到 multi-head attention 的輸出
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;差別只在於實際上我們是利用矩陣運算以及 broadcasting 讓 GPU 一次計算整個 batch 裡所有句子的所有 head 的注意結果。&lt;/p&gt;
&lt;p&gt;定義了一個新 layer 當然要實際試試。現在讓我們初始一個 multi-head attention layer 並將英文詞嵌入向量 &lt;code&gt;emb_inp&lt;/code&gt; 輸入進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# emb_inp.shape == (batch_size, seq_len, d_model)&lt;/span&gt;
&lt;span class="c1"&gt;#               == (2, 8, 4)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;  &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"d_model: {d_model}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"num_heads: {num_heads}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 multi-head attention layer&lt;/span&gt;
&lt;span class="n"&gt;mha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 簡單將 v, k, q 都設置為 `emb_inp`&lt;/span&gt;
&lt;span class="c1"&gt;# 順便看看 padding mask 的作用。&lt;/span&gt;
&lt;span class="c1"&gt;# 別忘記，第一個英文序列的最後兩個 tokens 是 &amp;lt;pad&amp;gt;&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;
&lt;span class="n"&gt;padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"q.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"k.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"v.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"padding_mask.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"output.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;output:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;d_model: 4
num_heads: 2

q.shape: (2, 8, 4)
k.shape: (2, 8, 4)
v.shape: (2, 8, 4)
padding_mask.shape: (2, 1, 1, 8)
output.shape: (2, 8, 4)
attention_weights.shape: (2, 2, 8, 8)

output: tf.Tensor(
[[[ 0.00862424  0.00463534  0.00123856  0.01982255]
  [ 0.00860434  0.00464583  0.00125165  0.01984711]
  [ 0.00863869  0.00461318  0.00122942  0.01981261]
  [ 0.00858585  0.00465442  0.00125683  0.0198578 ]
  [ 0.0086211   0.00462923  0.0012448   0.01983759]
  [ 0.00860078  0.00464716  0.00125472  0.01985404]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]
  [ 0.00865074  0.00461071  0.00122681  0.01980557]]

 [[-0.00233657  0.02963993  0.01171194  0.03959805]
  [-0.00234752  0.02964369  0.01171828  0.03960991]
  [-0.00232748  0.02962957  0.01170804  0.03959192]
  [-0.00233163  0.02963142  0.0117076   0.03959151]
  [-0.00231678  0.02962143  0.01170276  0.03957902]
  [-0.00234718  0.02964409  0.01171941  0.03961902]
  [-0.00233476  0.029631    0.01171241  0.03959794]
  [-0.00235306  0.02964601  0.01172148  0.03961948]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該明白為何&lt;a href="#遮罩：Transformer-的祕密配方"&gt;我們當初要在 padding mask 加入兩個新維度了&lt;/a&gt;：一個是用來遮住同個句子但是不同 head 的注意權重，一個則是用來 broadcast 到 2 維注意權重的（詳見&lt;a href="#直觀理解遮罩在注意函式中的效果"&gt;直觀理解遮罩&lt;/a&gt;一節）。&lt;/p&gt;
&lt;p&gt;沒意外的話你也已經能夠解讀 mutli-head attention 的輸出了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;output&lt;/code&gt;：序列中每個子詞的新 repr. 都包含同序列其他位置的資訊&lt;/li&gt;
&lt;li&gt;&lt;code&gt;attention_weights&lt;/code&gt;：包含每個 head 的每個序列 &lt;code&gt;q&lt;/code&gt; 中的字詞對序列 &lt;code&gt;k&lt;/code&gt; 的注意權重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你還無法想像每個計算步驟，讓我們看看 multi-head attention 是怎麼將輸入的 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;v&lt;/code&gt; 轉換成最後的 &lt;code&gt;output&lt;/code&gt; 的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/multi-head-attention.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/multi-head-attention.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Multi-head attention 完整計算過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這應該是你這輩子第一次看到 multi-head 注意力機制是怎麼處理 4 維張量的。&lt;/p&gt;
&lt;p&gt;細節不少，我建議將動畫跟程式碼比較一下，確保你能想像每一個步驟產生的張量以及其物理意義。到此為止，我們已經把 Transformer 裡最困難的 multi-head attention 的概念以及運算都看過一遍了。&lt;/p&gt;
&lt;p&gt;如果你腦袋還是一團亂，只要記得最後一個畫面：在 &lt;code&gt;q&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;v&lt;/code&gt; 的最後一維已經是 &lt;code&gt;d_model&lt;/code&gt; 的情況下，multi-head attention 跟 scaled dot product attention 一樣，就是吐出一個完全一樣維度的張量 &lt;code&gt;output&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;multi-head attention 的輸出張量 &lt;code&gt;output&lt;/code&gt; 裡頭每個句子的每個字詞的 repr. 維度 &lt;code&gt;d_model&lt;/code&gt; 雖然跟函式的輸入張量相同，但實際上已經是從同個序列中&lt;strong&gt;不同位置且不同空間&lt;/strong&gt;中的 repr. 取得語義資訊的結果。&lt;/p&gt;
&lt;p&gt;要確保自己真的掌握了 multi-head attention 的精神，你可以試著向旁邊的朋友（如果他 / 她願意聽的話）解釋一下整個流程。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/explain-mha.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;喔對了，不用擔心我們做 multi-head 以後計算量會大增。因為 head 的數目雖然變多了，每個子空間的維度也下降了。跟 single-head attention 使用的計算量是差不多的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="打造-Transformer：疊疊樂時間_1"&gt;打造 Transformer：疊疊樂時間&lt;a class="anchor-link" href="#打造-Transformer：疊疊樂時間"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;以前我們曾提到&lt;/a&gt;深度學習模型就是一層層的幾何運算過程。Transformer 也不例外，剛才實作的 mutli-head attention layer 就是一個最明顯的例子。而它正好是 Transformer 裡頭最重要的一層運算。&lt;/p&gt;
&lt;p&gt;在這節我們會把 Transformer 裡頭除了注意力機制的其他運算通通實作成一個個的 layers，並將它們全部「疊」起來。&lt;/p&gt;
&lt;p&gt;你可以點擊下方的影片來了解接下來的實作順序：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/steps-to-build-transformer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/steps-to-build-transformer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        一步步打造 Transformer
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果這是你第一次看到 Transformer 的架構圖 ... 代表你沒認真上教授的課，等等別忘記&lt;a href="#師傅引進門，修行在個人_1"&gt;去前面領補課號碼牌&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;影片中左側就是我們接下來會依序實作的 layers。&lt;a href="#Transformer：Seq2Seq-模型-+-自注意力機制"&gt;Transformer 是一種使用自注意力機制的 Seq2Seq 模型&lt;/a&gt; ，裡頭包含了兩個重要角色，分別為 Encoder 與 Decoder：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最初輸入的英文序列會通過 Encoder 中 N 個 Encoder layers 並被轉換成一個&lt;strong&gt;相同長度&lt;/strong&gt;的序列。每個 layer 都會為自己的輸入序列裡頭的子詞產生&lt;strong&gt;新的&lt;/strong&gt; repr.，然後交給下一個 layer。&lt;/li&gt;
&lt;li&gt;Decoder 在生成（預測）下一個中文子詞時會一邊觀察 Encoder 輸出序列裡&lt;strong&gt;所有&lt;/strong&gt;英文子詞的 repr.，一邊觀察自己前面已經生成的中文子詞。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值得一提的是，N = 1 （Encoder / Decoder layer 數目 = 1）時就是最陽春版的 Transformer。但在深度學習領域裡頭我們常常想對原始數據做多層的轉換，因此會將 N 設為影片最後出現的 2 層或是 Transformer 論文中的 6 層 Encoder / Decoder layers。&lt;/p&gt;
&lt;p&gt;Encoder 裡頭的 Encoder layer 裡又分兩個 sub-layers，而 Decoder 底下的 Decoder layer 則包含 3 個 sub-layers。真的是 layer layer 相扣。將這些 layers 的階層關係簡單列出來大概就長這樣（位置 Encoding 等實作時解釋）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer&lt;ul&gt;
&lt;li&gt;Encoder&lt;ul&gt;
&lt;li&gt;輸入 Embedding&lt;/li&gt;
&lt;li&gt;位置 Encoding&lt;/li&gt;
&lt;li&gt;N 個 Encoder layers&lt;ul&gt;
&lt;li&gt;sub-layer 1: Encoder 自注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 2: Feed Forward&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Decoder&lt;ul&gt;
&lt;li&gt;輸出 Embedding&lt;/li&gt;
&lt;li&gt;位置 Encoding&lt;/li&gt;
&lt;li&gt;N 個 Decoder layers&lt;ul&gt;
&lt;li&gt;sub-layer 1: Decoder 自注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 2: Decoder-Encoder 注意力機制&lt;/li&gt;
&lt;li&gt;sub-layer 3: Feed Forward&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Final Dense Layer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不過就像影片中顯示的一樣，實作的時候我們傾向從下往上疊上去。畢竟地基打得好，樓才蓋得高，對吧？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Position-wise-Feed-Forward-Networks"&gt;Position-wise Feed-Forward Networks&lt;a class="anchor-link" href="#Position-wise-Feed-Forward-Networks"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同影片中所看到的， Encoder layer 跟 Decoder layer 裡頭都各自有一個 Feed Forward 的元件。此元件構造簡單，不用像前面的 multi-head attention 建立&lt;a href="https://www.tensorflow.org/beta/tutorials/eager/custom_layers"&gt;客製化的 keras layer&lt;/a&gt;，只需要寫一個 Python 函式讓它在被呼叫的時候回傳一個&lt;strong&gt;新的&lt;/strong&gt; &lt;a href="https://www.tensorflow.org/beta/tutorials/quickstart/beginner"&gt;tf.keras.Sequential 模型&lt;/a&gt;給我們即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
      &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'relu'&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, dff)&lt;/span&gt;
      &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;
  &lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;此函式在每次被呼叫的時候都會回傳一組新的全連接前饋神經網路（Fully-connected &lt;strong&gt;F&lt;/strong&gt;eed &lt;strong&gt;F&lt;/strong&gt;orward &lt;strong&gt;N&lt;/strong&gt;etwork，FFN），其輸入張量與輸出張量的最後一個維度皆為 &lt;code&gt;d_model&lt;/code&gt;，而在 FFN 中間層的維度則為 &lt;code&gt;dff&lt;/code&gt;。一般會讓 &lt;code&gt;dff&lt;/code&gt; 大於 &lt;code&gt;d_model&lt;/code&gt;，讓 FFN 從輸入的 &lt;code&gt;d_model&lt;/code&gt; 維度裡頭擷取些有用的資訊。在論文中 &lt;code&gt;d_model&lt;/code&gt; 為 512，&lt;code&gt;dff&lt;/code&gt; 則為 4 倍的 2048。兩個都是可以調整的超參數。&lt;/p&gt;
&lt;p&gt;讓我們建立一個 FFN 試試：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;64&lt;/span&gt;
&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2048&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"x.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"out.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;x.shape: (64, 10, 512)
out.shape: (64, 10, 512)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在輸入張量的最後一維已經是 &lt;code&gt;d_model&lt;/code&gt; 的情況，FFN 的輸出張量基本上會跟輸入一模一樣：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：（batch_size, seq_len, d_model）&lt;/li&gt;
&lt;li&gt;輸出：（batch_size, seq_len, d_model） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;FFN 輸出 / 輸入張量的 shape 相同很容易理解。比較沒那麼明顯的是這個 FFN  事實上對序列中的所有位置做的線性轉換都是一樣的。我們可以假想一個 2 維的 &lt;code&gt;duumy_sentence&lt;/code&gt;，裡頭有 5 個以 4 維向量表示的子詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="c1"&gt;# FFN 的輸入輸出張量的最後一維皆為 `d_model`&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;

&lt;span class="c1"&gt;# 建立一個小 FFN&lt;/span&gt;
&lt;span class="n"&gt;small_ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 懂子詞梗的站出來&lt;/span&gt;
&lt;span class="n"&gt;dummy_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                              &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;small_ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dummy_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=193585, shape=(5, 4), dtype=float32, numpy=
array([[ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 2.8674245, -2.174698 , -1.3073452, -6.4233937],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995],
       [ 3.650207 , -0.973258 , -2.4126565, -6.5094995]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現同一個子詞不會因為&lt;strong&gt;位置的改變&lt;/strong&gt;而造成 FFN 的輸出結果產生差異。但因為我們實際上會有多個 Encoder / Decoder layers，而每個 layers 都會有不同參數的 FFN，因此每個 layer 裡頭的 FFN 做的轉換都會有所不同。&lt;/p&gt;
&lt;p&gt;值得一提的是，儘管對所有位置的子詞都做一樣的轉換，這個轉換是獨立進行的，因此被稱作 Position-wise Feed-Forward Networks。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder-layer：Encoder-小弟"&gt;Encoder layer：Encoder 小弟&lt;a class="anchor-link" href="#Encoder-layer：Encoder-小弟"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了 &lt;strong&gt;M&lt;/strong&gt;ulti-&lt;strong&gt;H&lt;/strong&gt;ead &lt;strong&gt;A&lt;/strong&gt;ttention（MHA）以及 &lt;strong&gt;F&lt;/strong&gt;eed-&lt;strong&gt;F&lt;/strong&gt;orward &lt;strong&gt;N&lt;/strong&gt;etwork（FFN），我們事實上已經可以實作第一個 Encoder layer 了。讓我們複習一下這 layer 裡頭有什麼重要元件：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/encoder-layer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/encoder-layer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Encoder layer 裡的重要元件
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想上面的動畫已經很清楚了。一個 Encoder layer 裡頭會有兩個 sub-layers，分別為 MHA 以及 FFN。在 Add &amp;amp; Norm 步驟裡頭，每個 sub-layer 會有一個&lt;a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf"&gt;殘差連結（residual connection）&lt;/a&gt;來幫助減緩梯度消失（Gradient Vanishing）的問題。接著兩個 sub-layers 都會針對最後一維 &lt;code&gt;d_model&lt;/code&gt; 做 &lt;a href="https://arxiv.org/abs/1607.06450"&gt;layer normalization&lt;/a&gt;，將 batch 裡頭每個子詞的輸出獨立做轉換，使其平均與標準差分別靠近 0 和 1 之後輸出。&lt;/p&gt;
&lt;p&gt;另外在將 sub-layer 的輸出與其輸入相加之前，我們還會做點 regularization，對該 sub-layer 的輸出使用 &lt;a href="http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf"&gt;dropout&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;總結一下。如果輸入是 &lt;code&gt;x&lt;/code&gt;，最後輸出寫作 &lt;code&gt;out&lt;/code&gt; 的話，則每個 sub-layer 的處理邏輯如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;Sublayer&lt;/code&gt; 則可以是 MHA 或是 FFN。現在讓我們看看 Encoder layer 的實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA &amp;amp; FFN&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# Transformer 論文內預設 dropout rate 為 0.1&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 一樣，一個 sub-layer 一個 dropout layer&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
  &lt;span class="c1"&gt;# 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 1: MHA&lt;/span&gt;
    &lt;span class="c1"&gt;# Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己&lt;/span&gt;
    &lt;span class="c1"&gt;# 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 &amp;lt;pad&amp;gt; token&lt;/span&gt;
    &lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="n"&gt;attn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;attn_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    
    &lt;span class="c1"&gt;# sub-layer 2: FFN&lt;/span&gt;
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 記得 training&lt;/span&gt;
    &lt;span class="n"&gt;out2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟當初 MHA layer 的實作比起來輕鬆多了，對吧？&lt;/p&gt;
&lt;p&gt;基本上 Encoder layer 裡頭就是兩個架構一模一樣的 sub-layer，只差在一個是 MHA，一個是 FFN。另外為了方便 residual connection 的計算，所有 sub-layers 的&lt;strong&gt;輸出&lt;/strong&gt;維度都是 &lt;code&gt;d_model&lt;/code&gt;。而 sub-layer 內部產生的維度當然就隨我們開心啦！我們可以為 FFN 設置不同的 &lt;code&gt;dff&lt;/code&gt; 值，也能設定不同的 &lt;code&gt;num_heads&lt;/code&gt; 來改變 MHA 內部每個 head 裡頭的維度。&lt;/p&gt;
&lt;p&gt;論文裡頭的 &lt;code&gt;d_model&lt;/code&gt; 為 512，而我們 demo 用的英文詞嵌入張量的 &lt;code&gt;d_model&lt;/code&gt; 維度則為 4：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 之後可以調的超參數。這邊為了 demo 設小一點&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="c1"&gt;# 新建一個使用上述參數的 Encoder Layer&lt;/span&gt;
&lt;span class="n"&gt;enc_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 建立一個當前輸入 batch 使用的 padding mask&lt;/span&gt;
&lt;span class="n"&gt;enc_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, seq_len, d_model)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;emb_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
emb_inp: tf.Tensor(
[[[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.02707888 -0.03917687 -0.01213828  0.00909697]
  [ 0.0355427   0.04111305  0.00751223 -0.01974255]
  [ 0.02443342 -0.03273199  0.01267544  0.03127003]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]
  [-0.00680635  0.02136201 -0.02036932 -0.04211974]]

 [[ 0.00695511 -0.03370368 -0.03656032 -0.03336458]
  [-0.0325227  -0.03433502 -0.01849879  0.01439226]
  [ 0.00144588 -0.00377025 -0.00798036 -0.04099905]
  [ 0.04524285  0.02524642 -0.00924555 -0.01368124]
  [-0.0159062   0.01108797 -0.0177028  -0.0435766 ]
  [ 0.00240784 -0.04652226  0.01821991 -0.04349295]
  [-0.04879753 -0.00119017 -0.00157104  0.01117355]
  [-0.02148524 -0.03413673  0.00708324  0.0121879 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在本來的輸入維度即為 &lt;code&gt;d_model&lt;/code&gt; 的情況下，Encoder layer 就是給我們一個一模一樣 shape 的張量。當然，實際上內部透過 MHA 以及 FFN sub-layer 的轉換，每個子詞的 repr. 都大幅改變了。&lt;/p&gt;
&lt;p&gt;有了 Encoder layer，接著讓我們看看 Decoder layer 的實作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Decoder-layer：Decoder-小弟"&gt;Decoder layer：Decoder 小弟&lt;a class="anchor-link" href="#Decoder-layer：Decoder-小弟"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個 Decoder layer 裡頭有 3 個 sub-layers：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Decoder layer 自身的 &lt;strong&gt;Masked&lt;/strong&gt; MHA 1&lt;/li&gt;
&lt;li&gt;Decoder layer 關注 Encoder 輸出序列的 MHA 2&lt;/li&gt;
&lt;li&gt;FFN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你也可以看一下影片來回顧它們所在的位置：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/decoder-layer.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/decoder-layer.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Decoder layer 中的 sub-layers
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟實作 Encoder layer 時一樣，每個 sub-layer 的邏輯同下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sub_layer_out = Sublayer(x)
sub_layer_out = Dropout(sub_layer_out)
out = LayerNorm(x + sub_layer_out)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Decoder layer 用 MHA 1 來關注輸出序列，查詢 Q、鍵值 K 以及值 V 都是自己。而之所以有個 masked 是因為（中文）輸出序列除了跟（英文）輸入序列一樣需要 padding mask 以外，還需要 look ahead mask 來避免 Decoder layer 關注到未來的子詞。look ahead mask 在&lt;a href="#直觀理解遮罩在注意函式中的效果"&gt;前面章節&lt;/a&gt;已經有詳細說明了。&lt;/p&gt;
&lt;p&gt;MHA1 處理完的輸出序列會成為 MHA 2 的 Q，而 K 與 V 則使用 Encoder 的輸出序列。這個運算的概念是讓一個 Decoder layer 在生成新的中文子詞時先參考先前已經產生的中文字，並為當下要生成的子詞產生一個包含前文語義的 repr. 。接著將此 repr. 拿去跟 Encoder 那邊的英文序列做匹配，看當下字詞的 repr. 有多好並予以修正。&lt;/p&gt;
&lt;p&gt;用簡單點的說法就是 Decoder 在生成中文字詞時除了參考已經生成的中文字以外，也會去關注 Encoder 輸出的英文子詞（的 repr.）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Decoder 裡頭會有 N 個 DecoderLayer，&lt;/span&gt;
&lt;span class="c1"&gt;# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA &amp;amp; FFN&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="c1"&gt;# 3 個 sub-layers 的主角們&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;MultiHeadAttention&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;point_wise_feed_forward_network&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 
    &lt;span class="c1"&gt;# 定義每個 sub-layer 用的 LayerNorm&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LayerNormalization&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 定義每個 sub-layer 用的 Dropout&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)&lt;/span&gt;
    &lt;span class="c1"&gt;# attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)&lt;/span&gt;

    &lt;span class="c1"&gt;# sub-layer 1: Decoder layer 自己對輸出序列做注意力。&lt;/span&gt;
    &lt;span class="c1"&gt;# 我們同時需要 look ahead mask 以及輸出序列的 padding mask &lt;/span&gt;
    &lt;span class="c1"&gt;# 來避免前面已生成的子詞關注到未來的子詞以及 &amp;lt;pad&amp;gt;&lt;/span&gt;
    &lt;span class="n"&gt;attn1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;attn1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm1&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn1&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 2: Decoder layer 關注 Encoder 的最後輸出&lt;/span&gt;
    &lt;span class="c1"&gt;# 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 &amp;lt;pad&amp;gt;&lt;/span&gt;
    &lt;span class="n"&gt;attn2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mha2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;attn2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;out1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# sub-layer 3: FFN 部分跟 Encoder layer 完全一樣&lt;/span&gt;
    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ffn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;out2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;

    &lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;out3&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layernorm3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ffn_output&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;out2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, target_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;out3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights_block2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Decoder layer 的實作跟 Encoder layer 大同小異，不過還是有幾點細節特別需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在做 Masked MHA（MHA 1）的時候我們需要同時套用兩種遮罩：&lt;strong&gt;輸出&lt;/strong&gt;序列的 padding mask 以及 look ahead mask。因此 Decoder layer 預期的遮罩是兩者結合的 &lt;code&gt;combined_mask&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MHA 1 因為是 Decoder layer 關注自己，multi-head attention 的參數 &lt;code&gt;v&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 以及 &lt;code&gt;q&lt;/code&gt; 都是 &lt;code&gt;x&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;MHA 2 是 Decoder layer 關注 Encoder 輸出序列，因此，multi-head attention 的參數 &lt;code&gt;v&lt;/code&gt;、&lt;code&gt;k&lt;/code&gt; 為 &lt;code&gt;enc_output&lt;/code&gt;，&lt;code&gt;q&lt;/code&gt; 則為 MHA 1 sub-layer 的結果 &lt;code&gt;out1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;產生 &lt;code&gt;comined_mask&lt;/code&gt; 也很簡單，我們只要把兩個遮罩取大的即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"look_ahead_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"combined_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 10), dtype=float32)
--------------------
look_ahead_mask: tf.Tensor(
[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意 &lt;code&gt;combined_mask&lt;/code&gt; 的 shape 以及裡頭遮罩所在的位置。利用 broadcasting 我們將 &lt;code&gt;combined_mask&lt;/code&gt; 的 shape 也擴充到 4 維：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(batch_size, num_heads, seq_len_tar, seq_len_tar)
= (2, 1, 10, 10)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這方便之後 multi-head attention 的計算。另外因為我們 demo 的中文 batch 裡頭的第一個句子有 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;，&lt;code&gt;combined_mask&lt;/code&gt; 除了 look ahead 的效果以外還加了 padding mask。&lt;/p&gt;
&lt;p&gt;因為剛剛實作的是 Decoder layer，這次讓我們把中文（目標語言）的詞嵌入張量以及相關的遮罩丟進去看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;dec_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 來源、目標語言的序列都需要 padding mask&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算&lt;/span&gt;
&lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_self_attn_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_enc_attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"emb_tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;emb_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_self_attn_weights.shape:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_self_attn_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_enc_attn_weights:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_enc_attn_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;emb_tar: tf.Tensor(
[[[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [ 0.02129837 -0.00746276  0.03881821 -0.01586295]
  [-0.01179456  0.02825376  0.00738146  0.02963744]
  [ 0.01171205  0.04350302 -0.01190796  0.02526634]
  [ 0.03814722 -0.03364048 -0.03744673  0.04369817]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]
  [-0.00285894  0.02392108 -0.03126474  0.01345349]]

 [[-0.0441955  -0.01026772  0.03740635  0.02017349]
  [-0.00359621 -0.01380367 -0.02875998 -0.03855735]
  [ 0.04516688 -0.04480755 -0.03278694 -0.0093614 ]
  [ 0.04131394 -0.04065727 -0.04330624 -0.03341667]
  [ 0.03572228 -0.04500845  0.0470326   0.03095007]
  [-0.03566641 -0.03730996 -0.00597564 -0.03933349]
  [ 0.01850356  0.03993076  0.02729526 -0.04848848]
  [-0.02294568 -0.02494572 -0.0136737  -0.04278342]
  [ 0.0280853   0.01269842  0.04268574 -0.04069148]
  [ 0.04029209 -0.00619308 -0.04934603  0.02242902]]], shape=(2, 10, 4), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[ 1.2521563   0.3273945  -1.5237452  -0.0558054 ]
  [-1.0591918  -0.42765176 -0.14816867  1.6350121 ]
  [ 0.299005    1.3632457  -1.4101827  -0.252068  ]
  [ 0.7023785  -1.479373   -0.32433346  1.1013279 ]
  [-1.6220697   1.0153029   0.02592759  0.5808392 ]
  [-1.0757908  -0.7200314   0.30136684  1.4944555 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]
  [-0.22072682  1.5675467  -1.215218   -0.1316019 ]]

 [[ 1.475371    0.30539253 -1.1591307  -0.6216327 ]
  [-1.4569639   0.00421676  0.08528362  1.3674635 ]
  [ 0.61611307  1.3085197  -0.79488575 -1.1297472 ]
  [ 0.80156547  0.9995991  -1.5072922  -0.29387245]
  [-0.11611538  1.6353902  -1.0406278  -0.47864679]
  [ 0.9602699  -0.3459822   0.8696089  -1.4838965 ]
  [-1.6676238   0.9936579   0.2892594   0.38470644]
  [-1.2698565  -0.67637944  1.1073651   0.8388707 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.4073423  -1.3681166   0.4482983   1.3271605 ]
  [ 0.9023904  -1.6660724   0.1386456   0.6250363 ]
  [-0.68705463  0.04485544 -0.9672582   1.6094574 ]
  [ 0.40446007  0.7378753  -1.7199682   0.5776328 ]
  [ 0.66626793 -0.7429294  -1.1866593   1.2633208 ]
  [ 1.3847514   0.0595071  -0.00241444 -1.441844  ]
  [ 0.77179515 -0.15832207 -1.5698854   0.9564123 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]
  [ 0.19740774  0.9835156  -1.6620107   0.4810872 ]]

 [[-0.35176337 -1.3861214   0.39734656  1.3405383 ]
  [ 1.0155624   0.28156188 -1.6605129   0.36338854]
  [ 0.9295503  -0.96635836 -1.0307404   1.0675484 ]
  [ 1.2389433  -0.7855455  -1.1608163   0.70741844]
  [ 0.11645091 -1.565496    0.23167732  1.2173678 ]
  [-0.44791234 -1.3678643   1.2819183   0.53385824]
  [-0.05676413  0.90384555  0.7641177  -1.611199  ]
  [-0.4362856  -1.3157362   1.397403    0.35461882]
  [ 0.21431251 -0.8140781   1.5471766  -0.94741106]
  [ 0.4220932  -0.4875322  -1.3055642   1.3710032 ]]], shape=(2, 10, 4), dtype=float32)
--------------------
dec_self_attn_weights.shape: (2, 2, 10, 10)
dec_enc_attn_weights: (2, 2, 10, 8)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟 Encoder layer 相同，Decoder layer 輸出張量的最後一維也是 &lt;code&gt;d_model&lt;/code&gt;。而 &lt;code&gt;dec_self_attn_weights&lt;/code&gt; 則代表著 Decoder layer 的自注意權重，因此最後兩個維度皆為中文序列的長度 &lt;code&gt;10&lt;/code&gt;；而 &lt;code&gt;dec_enc_attn_weights&lt;/code&gt; 因為 Encoder 輸出序列的長度為 &lt;code&gt;8&lt;/code&gt;，最後一維即爲 &lt;code&gt;8&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;都讀到這裡了，判斷每一維的物理意義對你來說應該是小菜一碟了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Positional-encoding：神奇數字"&gt;Positional encoding：神奇數字&lt;a class="anchor-link" href="#Positional-encoding：神奇數字"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;透過多層的自注意力層，Transformer 在處理序列時裡頭所有子詞都是「天涯若比鄰」：想要關注序列中&lt;strong&gt;任何&lt;/strong&gt;位置的資訊只要 O(1) 就能辦到。這讓 Transformer 能很好地 model 序列中長距離的依賴關係（long-range dependencise）。但反過來說 Transformer 則無法 model 序列中字詞的順序關係，所以我們得額外加入一些「位置資訊」給 Transformer。&lt;/p&gt;
&lt;p&gt;這個資訊被稱作位置編碼（Positional Encoding），實作上是直接加到最一開始的英文 / 中文詞嵌入向量（word embedding）裡頭。其直觀的想法是想辦法讓被加入位置編碼的 word embedding 在 &lt;code&gt;d_model&lt;/code&gt; 維度的空間裡頭不只會因為&lt;strong&gt;語義相近&lt;/strong&gt;而靠近，也會因為&lt;strong&gt;位置靠近&lt;/strong&gt;而在該空間裡頭靠近。&lt;/p&gt;
&lt;p&gt;論文裡頭使用的位置編碼的公式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/position-encoding-equation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯 ... 第一次看到這函式的人會黑人問號是很正常。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文裡頭提到&lt;/a&gt;他們之所以這樣設計位置編碼（&lt;strong&gt;P&lt;/strong&gt;ositional &lt;strong&gt;E&lt;/strong&gt;ncoding, PE）是因為這個函數有個很好的特性：給定任一位置 &lt;code&gt;pos&lt;/code&gt; 的位置編碼 &lt;code&gt;PE(pos)&lt;/code&gt;，跟它距離 &lt;code&gt;k&lt;/code&gt; 個單位的位置 &lt;code&gt;pos + k&lt;/code&gt; 的位置編碼 &lt;code&gt;PE(pos + k)&lt;/code&gt; 可以表示為 &lt;code&gt;PE(pos)&lt;/code&gt; 的一個線性函數（linear function）。&lt;/p&gt;
&lt;p&gt;因此透過在 word embedding 裡加入這樣的資訊，作者們認為可以幫助 Transformer 學會 model 序列中的子詞的相對位置關係。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        子曰：「由！誨女知之乎？知之為知之，不知為不知，是知也。」
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ 《論語 為政篇》&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就算我們無法自己想出論文裡頭的位置編碼公式，還是可以直接把 &lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer#positional_encoding"&gt;TensorFlow 官方&lt;/a&gt;的實作搬過來使用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 以下直接參考 TensorFlow 官方 tutorial &lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_angles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;angle_rates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;pos&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;angle_rates&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;angle_rads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_angles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;position&lt;/span&gt;&lt;span class="p"&gt;)[:,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
                          &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:],&lt;/span&gt;
                          &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# apply sin to even indices in the array; 2i&lt;/span&gt;
  &lt;span class="n"&gt;sines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle_rads&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="c1"&gt;# apply cos to odd indices in the array; 2i+1&lt;/span&gt;
  &lt;span class="n"&gt;cosines&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;angle_rads&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;::&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  
  &lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;sines&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cosines&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;newaxis&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="n"&gt;seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;

&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pos_encoding&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=194541, shape=(1, 50, 512), dtype=float32, numpy=
array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,
          1.        ,  1.        ],
        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,
          1.        ,  1.        ],
        ...,
        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,
          0.99998724,  0.99998814],
        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,
          0.9999867 ,  0.9999876 ],
        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,
          0.9999861 ,  0.9999871 ]]], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一路看下來你應該也可以猜到位置編碼的每一維意義了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第 1 維代表 batch_size，之後可以 broadcasting&lt;/li&gt;
&lt;li&gt;第 2 維是序列長度，我們會為每個在輸入 / 輸出序列裡頭的子詞都加入位置編碼&lt;/li&gt;
&lt;li&gt;第 3 維跟詞嵌入向量同維度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為是要跟詞嵌入向量相加，位置編碼的維度也得是 &lt;code&gt;d_model&lt;/code&gt;。我們也可以把位置編碼畫出感受一下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pcolormesh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'RdBu'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'d_model'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlim&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Position'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;colorbar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/positional-encoding.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這圖你應該在很多教學文章以及教授的影片裡都看過了。就跟我們前面看過的各種 2 維矩陣相同，x 軸代表著跟詞嵌入向量相同的維度 &lt;code&gt;d_model&lt;/code&gt;，y 軸則代表序列中的每個位置。之後我們會看輸入 / 輸出序列有多少個子詞，就加入幾個位置編碼。&lt;/p&gt;
&lt;p&gt;關於位置編碼我們現在只需要知道這些就夠了，但如果你想知道更多相關的數學計算，可以參考&lt;a href="https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb"&gt;這個筆記本&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Encoder"&gt;Encoder&lt;a class="anchor-link" href="#Encoder"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Encoder 裡頭主要包含了 3 個元件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入的詞嵌入層&lt;/li&gt;
&lt;li&gt;位置編碼&lt;/li&gt;
&lt;li&gt;N 個 Encoder layers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大部分的工作都交給 Encoder layer 小弟做了，因此 Encoder 的實作很單純：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：&lt;/span&gt;
  &lt;span class="c1"&gt;# - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`&lt;/span&gt;
  &lt;span class="c1"&gt;# - input_vocab_size: 用來把索引轉成詞嵌入向量&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 建立 `num_layers` 個 EncoderLayers&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enc_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;EncoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
                       &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸入的 x.shape == (batch_size, input_seq_len)&lt;/span&gt;
    &lt;span class="c1"&gt;# 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;input_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)&lt;/span&gt;
    &lt;span class="c1"&gt;# 再加上對應長度的位置編碼&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;input_seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;

    &lt;span class="c1"&gt;# 對 embedding 跟位置編碼的總合做 regularization&lt;/span&gt;
    &lt;span class="c1"&gt;# 這在 Decoder 也會做&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 通過 N 個 EncoderLayer 做編碼&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;enc_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;enc_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      &lt;span class="c1"&gt;# 以下只是用來 demo EncoderLayer outputs&lt;/span&gt;
      &lt;span class="c1"&gt;#print('-' * 20)&lt;/span&gt;
      &lt;span class="c1"&gt;#print(f"EncoderLayer {i + 1}'s output:", x)&lt;/span&gt;
      
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較值得注意的是我們依照論文將 word embedding 乘上 &lt;code&gt;sqrt(d_model)&lt;/code&gt;，並在 embedding 跟位置編碼相加以後通過 dropout 層來達到 regularization 的效果。&lt;/p&gt;
&lt;p&gt;現在我們可以直接將索引序列 &lt;code&gt;inp&lt;/code&gt; 丟入 Encoder：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 2 層的 Encoder&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 記得加上 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 Encoder&lt;/span&gt;
&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 2 維的索引序列丟入 Encoder 做編碼&lt;/span&gt;
&lt;span class="n"&gt;enc_out&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;inp: tf.Tensor(
[[8135  105   10 1304 7925 8136    0    0]
 [8135   17 3905 6013   12 2572 7925 8136]], shape=(2, 8), dtype=int64)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意因為 Encoder 已經包含了詞嵌入層，因此我們不用再像呼叫 &lt;a href="#Encoder-的小弟"&gt;Encoder layer&lt;/a&gt; 時一樣還得自己先做 word embedding。現在的輸入及輸出張量為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：（batch_size, seq_len）&lt;/li&gt;
&lt;li&gt;輸出：（batch_size, seq_len, d_model）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有了 Encoder，我們之後就可以直接把 2 維的索引序列 &lt;code&gt;inp&lt;/code&gt; 丟入 Encoder，讓它幫我們把裡頭所有的英文序列做一連串的轉換。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Decoder"&gt;Decoder&lt;a class="anchor-link" href="#Decoder"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Decoder layer 本來就只跟 Encoder layer 差在一個 MHA，而這邏輯被包起來以後呼叫它的 Decoder 做的事情就跟 Encoder 基本上沒有兩樣了。&lt;/p&gt;
&lt;p&gt;在 Decoder 裡頭我們只需要建立一個專門給中文用的詞嵌入層以及位置編碼即可。我們在呼叫每個 Decoder layer 的時候也順便把其注意權重存下來，方便我們了解模型訓練完後是怎麼做翻譯的。&lt;/p&gt;
&lt;p&gt;以下則是實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Layer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 為中文（目標語言）建立詞嵌入層&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;positional_encoding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dec_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;DecoderLayer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
                       &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 呼叫時的參數跟 DecoderLayer 一模一樣&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="n"&gt;tar_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;  &lt;span class="c1"&gt;# 用來存放每個 Decoder layer 的注意權重&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 這邊跟 Encoder 做的事情完全一樣&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pos_encoding&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;tar_seq_len&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropout&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dec_layers&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;block2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dec_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      
      &lt;span class="c1"&gt;# 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察&lt;/span&gt;
      &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;_block1'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block1&lt;/span&gt;
      &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;_block2'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;block2&lt;/span&gt;
    
    &lt;span class="c1"&gt;# x.shape == (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們初始並呼叫一個 Decoder 看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 2 層的 Decoder&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="c1"&gt;# 記得加上 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;

&lt;span class="c1"&gt;# 遮罩&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個 Decoder&lt;/span&gt;
&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將 2 維的索引序列以及遮罩丟入 Decoder&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"combined_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"enc_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"inp_padding_mask:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_out&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"dec_out:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_out&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;block_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{block_name}&lt;/span&gt;&lt;span class="s2"&gt;.shape: &lt;/span&gt;&lt;span class="si"&gt;{attn_weights.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
combined_mask: tf.Tensor(
[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]]


 [[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 10, 10), dtype=float32)
--------------------
enc_out: tf.Tensor(
[[[-0.80654097 -0.5846039  -0.31439844  1.7055433 ]
  [-0.46891153 -0.57408124 -0.6840381   1.727031  ]
  [-0.319709   -0.17782518 -1.1191479   1.616682  ]
  [-0.49274105  0.26990706 -1.2412689   1.4641027 ]
  [-0.88477194  0.16279429 -0.8493918   1.5713693 ]
  [-0.96625364 -0.25279218 -0.4533522   1.6723981 ]
  [-0.8476429  -0.5615218  -0.28872433  1.6978891 ]
  [-0.61957765 -0.5919263  -0.51938564  1.7308894 ]]

 [[-0.8083886  -0.56457365 -0.33460823  1.7075704 ]
  [-0.50152016 -0.5214133  -0.7037289   1.7266623 ]
  [-0.34244898 -0.11313835 -1.1444559   1.6000432 ]
  [-0.5072439   0.21401608 -1.2050328   1.4982607 ]
  [-0.88611245  0.26368466 -0.9036027   1.5260304 ]
  [-0.96629447 -0.21083635 -0.49055386  1.6676848 ]
  [-0.86832803 -0.5383212  -0.28836083  1.6950101 ]
  [-0.6246328  -0.57586765 -0.5305909   1.7310913 ]]], shape=(2, 8, 4), dtype=float32)
--------------------
inp_padding_mask: tf.Tensor(
[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]


 [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)
--------------------
dec_out: tf.Tensor(
[[[-0.5437632  -1.055963    1.6090912  -0.0093651 ]
  [-0.35729456 -1.2363737   1.5295789   0.06408926]
  [ 0.35950443 -1.4217519   1.3327445  -0.27049693]
  [ 0.00910451 -1.3681054   1.4556323  -0.09663116]
  [-0.39842203 -1.0891637   1.6237149  -0.13612938]
  [-0.41910946 -1.0254465   1.6521797  -0.20762381]
  [-0.36797434 -1.036104    1.6521349  -0.2480565 ]
  [-0.19375193 -1.1218892   1.6165614  -0.30092025]
  [ 0.40127647 -1.3597702   1.3540744  -0.39558053]
  [ 0.17590097 -1.419068    1.3905344  -0.14736754]]

 [[-0.54991776 -1.0509207   1.6102997  -0.00946123]
  [-0.3790077  -1.2450974   1.514628    0.10947719]
  [ 0.1746773  -1.3877552   1.415193   -0.20211506]
  [-0.03870562 -1.3375971   1.4825788  -0.10627584]
  [-0.43508232 -1.067575    1.6293938  -0.12673649]
  [-0.41048303 -1.0317237   1.6503688  -0.20816201]
  [-0.3626595  -1.0360833   1.652463   -0.25372016]
  [-0.24817836 -1.1092765   1.6238651  -0.26641032]
  [ 0.1850568  -1.3670969   1.4271388  -0.2450987 ]
  [ 0.09142628 -1.3988855   1.4218552  -0.11439597]]], shape=(2, 10, 4), dtype=float32)
--------------------
decoder_layer1_block1.shape: (2, 2, 10, 10)
decoder_layer1_block2.shape: (2, 2, 10, 8)
decoder_layer2_block1.shape: (2, 2, 10, 10)
decoder_layer2_block2.shape: (2, 2, 10, 8)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;麻雀雖小，五臟俱全。雖然我們是使用 demo 數據，但基本上這就是你在呼叫 Decoder 時需要做的所有事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始時給它中文（目標語言）的字典大小、其他超參數&lt;/li&gt;
&lt;li&gt;輸入中文 batch 的索引序列&lt;/li&gt;
&lt;li&gt;也要輸入兩個遮罩以及 Encoder 輸出 &lt;code&gt;enc_out&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Decoder 的輸出你現在應該都可以很輕鬆地解讀才是。基本上跟 Decoder layer 一模一樣，只差在我們額外輸出一個 Python dict，裡頭存放所有 Decoder layers 的注意權重。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第一個-Transformer"&gt;第一個 Transformer&lt;a class="anchor-link" href="#第一個-Transformer"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒錯，終於到了這個時刻。在實作 Transformer 之前先點擊影片來簡單回顧一下我們在這一章實作了什麼些玩意兒：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/transformer-imple.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/transformer-imple.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        Transformer 本身只有 3 個 layers
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在我們前面已經將大大小小的 layers 一一實作並組裝起來以後，真正的 Transformer  模型只需要 3 個元件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Encoder &lt;/li&gt;
&lt;li&gt;Decoder&lt;/li&gt;
&lt;li&gt;Final linear layer&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;馬上讓我們看看 Transformer  的實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 初始參數包含 Encoder &amp;amp; Decoder 都需要超參數以及中英字典數目&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
               &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                           &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                           &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;final_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，&lt;/span&gt;
  &lt;span class="c1"&gt;# 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;call&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="n"&gt;enc_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, inp_seq_len, d_model)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# dec_output.shape == (batch_size, tar_seq_len, d_model)&lt;/span&gt;
    &lt;span class="n"&gt;dec_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;enc_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將 Decoder 輸出通過最後一個 linear layer&lt;/span&gt;
    &lt;span class="n"&gt;final_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;final_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, tar_seq_len, target_vocab_size)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;final_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;扣掉註解，Transformer 的實作本身非常簡短。&lt;/p&gt;
&lt;p&gt;被輸入 Transformer 的多個 2 維英文張量 &lt;code&gt;inp&lt;/code&gt; 會一路通過 &lt;strong&gt;Encoder&lt;/strong&gt; 裡頭的詞嵌入層，位置編碼以及 N 個 Encoder layers 後被轉換成 Encoder 輸出 &lt;code&gt;enc_output&lt;/code&gt;，接著對應的中文序列 &lt;code&gt;tar&lt;/code&gt; 則會在 &lt;strong&gt;Decoder&lt;/strong&gt; 裡頭走過相似的旅程並在每一層的 Decoder layer 利用 MHA 2 關注 Encoder 的輸出 &lt;code&gt;enc_output&lt;/code&gt;，最後被 Decoder 輸出。&lt;/p&gt;
&lt;p&gt;而 Decoder 的輸出 &lt;code&gt;dec_output&lt;/code&gt; 則會通過 &lt;strong&gt;Final linear layer&lt;/strong&gt;，被轉成進入 Softmax 前的 logits &lt;code&gt;final_output&lt;/code&gt;，其 logit 的數目則跟中文字典裡的子詞數相同。&lt;/p&gt;
&lt;p&gt;因為 Transformer 把 Decoder 也包起來了，現在我們連 Encoder 輸出 &lt;code&gt;enc_output&lt;/code&gt; 也不用管，只要把英文（來源）以及中文（目標）的索引序列 batch 丟入 Transformer，它就會輸出最後一維為中文字典大小的張量。第 2 維是輸出序列，裡頭每一個位置的向量就代表著該位置的中文字的機率分佈（事實上通過 softmax 才是，但這邊先這樣說方便你理解）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入：&lt;ul&gt;
&lt;li&gt;英文序列：（batch_size, inp_seq_len）&lt;/li&gt;
&lt;li&gt;中文序列：（batch_size, tar_seq_len）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;輸出：&lt;ul&gt;
&lt;li&gt;生成序列：（batch_size, tar_seq_len, target_vocab_size）&lt;/li&gt;
&lt;li&gt;注意權重的 dict&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們馬上建一個 Transformer，並假設我們已經準備好用 demo 數據來訓練它做英翻中：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="c1"&gt;# + 2 是為了 &amp;lt;start&amp;gt; &amp;amp; &amp;lt;end&amp;gt; token&lt;/span&gt;
&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;output_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;

&lt;span class="c1"&gt;# 重點中的重點。訓練時用前一個字來預測下一個中文字&lt;/span&gt;
&lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

&lt;span class="c1"&gt;# 來源 / 目標語言用的遮罩。注意 `comined_mask` 已經將目標語言的兩種遮罩合而為一&lt;/span&gt;
&lt;span class="n"&gt;inp_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化我們的第一個 transformer&lt;/span&gt;
&lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                          &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將英文、中文序列丟入取得 Transformer 預測下個中文字的結果&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;inp_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_inp:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"tar_real:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predictions:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;tar: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0    0]
 [4201  162  467  421  189   14    7  553    3 4202]], shape=(2, 10), dtype=int64)
--------------------
tar_inp: tf.Tensor(
[[4201   10  241   80   27    3 4202    0    0]
 [4201  162  467  421  189   14    7  553    3]], shape=(2, 9), dtype=int64)
--------------------
tar_real: tf.Tensor(
[[  10  241   80   27    3 4202    0    0    0]
 [ 162  467  421  189   14    7  553    3 4202]], shape=(2, 9), dtype=int64)
--------------------
predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了前面的各種 layers，建立一個 Transformer 並不難。但要輸入什麼數據就是一門大學問了：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;為何是丟少了尾巴一個字的 &lt;code&gt;tar_inp&lt;/code&gt; 序列進去 Transformer，而不是直接丟 &lt;code&gt;tar&lt;/code&gt; 呢？&lt;/p&gt;
&lt;p&gt;別忘記我們才剛初始一個 Transformer，裡頭所有 layers 的權重都是隨機的，你可不能指望它真的會什麼「黑魔法」來幫你翻譯。我們得先訓練才行。但訓練時如果你把整個正確的中文序列 &lt;code&gt;tar&lt;/code&gt;都進去給 Transformer 看，你期待它產生什麼？一首新的中文詩嗎？&lt;/p&gt;
&lt;p&gt;如果你曾經實作過序列生成模型或是看過&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;我之前的語言模型文章&lt;/a&gt;，就會知道在序列生成任務裡頭，模型獲得的正確答案是輸入序列往左位移一個位置的結果。&lt;/p&gt;
&lt;p&gt;這樣講很抽象，讓我們看個影片了解序列生成是怎麼運作的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video controls="" muted="" playsinline="" poster="https://leemeng.tw/images/transformer/how-sequence-generation-work.jpg"&gt;
&lt;source src="https://leemeng.tw/images/transformer/how-sequence-generation-work.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        了解序列生成以及如何訓練一個生成模型
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該明白 Transformer 在訓練的時候並不是吃整個中文序列，而是吃一個去掉尾巴的序列 &lt;code&gt;tar_inp&lt;/code&gt;，然後試著去預測「左移」一個字以後的序列 &lt;code&gt;tar_real&lt;/code&gt;。同樣概念當然也可以運用到以 RNN 或是 CNN-based 的模型上面。&lt;/p&gt;
&lt;p&gt;從影片中你也可以發現給定 &lt;code&gt;tar_inp&lt;/code&gt; 序列中的任一位置，其對應位置的 &lt;code&gt;tar_real&lt;/code&gt; 就是下個時間點模型應該要預測的中文字。&lt;/p&gt;
&lt;p&gt;序列生成任務可以被視為是一個分類任務（Classification），而每一個中文字都是一個分類。而 Transformer 就是要去產生一個中文字的機率分佈，想辦法跟正解越接近越好。&lt;/p&gt;
&lt;p&gt;跟用已訓練的 Transformer 做&lt;strong&gt;預測&lt;/strong&gt;時不同，在&lt;strong&gt;訓練&lt;/strong&gt;時為了穩定模型表現，我們並不會將 Transformer 的輸出再度丟回去當做其輸入（人形蜈蚣？），而是像影片中所示，給它左移一個位置後的序列 &lt;code&gt;tar_real&lt;/code&gt; 當作正解讓它去最小化 error。&lt;/p&gt;
&lt;p&gt;這種無視模型預測結果，而將正確解答丟入的訓練方法一般被稱作 &lt;a href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/"&gt;teacher forcing&lt;/a&gt;。你也可以參考教授的 &lt;a href="https://youtu.be/ZjfjPzXw6og?t=1952"&gt;Sequence-to-sequence Learning 教學&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="定義損失函數與指標_1"&gt;定義損失函數與指標&lt;a class="anchor-link" href="#定義損失函數與指標"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為被視為是一個分類任務，我們可以使用 cross entropy 來計算序列生成任務中實際的中文字跟模型預測的中文字分佈（distribution）相差有多遠。&lt;/p&gt;
&lt;p&gt;這邊簡單定義一個損失函式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;loss_object&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SparseCategoricalCrossentropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;from_logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;reduction&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'none'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 假設我們要解的是一個 binary classifcation， 0 跟 1 個代表一個 label&lt;/span&gt;
&lt;span class="n"&gt;real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;constant&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;loss_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;tf.Tensor: id=197487, shape=(3,), dtype=float32, numpy=array([0.31326166, 0.31326166, 1.3132616 ], dtype=float32)&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你曾做過分類問題，應該能看出預測序列 &lt;code&gt;pred&lt;/code&gt; 裡頭的第 3 個預測結果出錯因此 entropy 值上升。損失函數 &lt;code&gt;loss_object&lt;/code&gt; 做的事情就是比較 2 個序列並計算 cross entropy：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;real&lt;/code&gt;：一個包含 N 個正確 labels 的序列&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pred&lt;/code&gt;：一個包含 N 個維度為 label 數的 logit 序列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們在這邊將 &lt;code&gt;reduction&lt;/code&gt; 參數設為 &lt;code&gt;none&lt;/code&gt;，請 &lt;code&gt;loss_object&lt;/code&gt; 不要把每個位置的 error 加總。而這是因為我們之後要自己把 &lt;code&gt;&amp;lt;pad&amp;gt;&lt;/code&gt; token 出現的位置的損失捨棄不計。&lt;/p&gt;
&lt;p&gt;而將 &lt;code&gt;from_logits&lt;/code&gt; 參數設為 &lt;code&gt;True&lt;/code&gt; 是因為從 Transformer 得到的預測還沒有經過 softmax，因此加總還不等於 1：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predictions:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;predictions: tf.Tensor(
[[[ 0.00929452 -0.01123782  0.05421777 ... -0.01170466  0.00628542
   -0.07576236]
  [ 0.03640017 -0.01885041  0.05113849 ... -0.02349908  0.01716622
   -0.06729948]
  [ 0.05617092 -0.02265774  0.04667147 ... -0.02913139  0.0241506
   -0.05331099]
  ...
  [ 0.00905135 -0.01058669  0.05486142 ... -0.01039154  0.0058039
   -0.07445519]
  [ 0.02215609 -0.01478041  0.05375389 ... -0.0170105   0.01135763
   -0.07241639]
  [ 0.0478656  -0.02148081  0.04837158 ... -0.02759764  0.02148173
   -0.06043392]]

 [[ 0.00996658 -0.01115559  0.05453676 ... -0.0114185   0.00637141
   -0.07500792]
  [ 0.03897631 -0.01930442  0.0508956  ... -0.02409907  0.01803425
   -0.0656432 ]
  [ 0.05387272 -0.02244362  0.04702405 ... -0.02893805  0.02348556
   -0.05554678]
  ...
  [ 0.01048942 -0.01085559  0.05502523 ... -0.01070841  0.0062833
   -0.07385261]
  [ 0.02370835 -0.01504852  0.05381611 ... -0.01732858  0.01186723
   -0.07158875]
  [ 0.04920105 -0.02166032  0.0481827  ... -0.02781233  0.02190085
   -0.05933255]]], shape=(2, 9, 4203), dtype=float32)
--------------------
tf.Tensor(
[[1.4971986 3.1899047 4.1454954 3.7353938 2.869739  1.8605256 1.3746347
  2.2779167 3.8190796]
 [1.4881071 3.303587  4.0757227 3.7524652 2.836317  1.9132937 1.4376438
  2.3432927 3.8689976]], shape=(2, 9), dtype=float32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了 &lt;code&gt;loss_object&lt;/code&gt; 實際算 cross entropy 以後，我們需要另外一個函式來建立遮罩並加總序列裡頭不包含 `&lt;pad&gt; token 位置的損失：&lt;/pad&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loss_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 這次的 mask 將序列中不等於 0 的位置視為 1，其餘為 0 &lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logical_not&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# 照樣計算所有位置的 cross entropy 但不加總&lt;/span&gt;
  &lt;span class="n"&gt;loss_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loss_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pred&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;loss_&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="n"&gt;mask&lt;/span&gt;  &lt;span class="c1"&gt;# 只計算非 &amp;lt;pad&amp;gt; 位置的損失 &lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduce_mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我另外再定義兩個 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics"&gt;tf.keras.metrics&lt;/a&gt;，方便之後使用 &lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard?hl=zh-cn"&gt;TensorBoard&lt;/a&gt; 來追蹤模型 performance：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train_loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'train_loss'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train_accuracy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SparseCategoricalAccuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'train_accuracy'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設置超參數"&gt;設置超參數&lt;a class="anchor-link" href="#設置超參數"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前面實作了那麼多 layers，你應該還記得有哪些是你自己可以調整的超參數吧？&lt;/p&gt;
&lt;p&gt;讓我幫你全部列出來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;num_layers&lt;/code&gt; 決定 Transfomer 裡頭要有幾個 Encoder / Decoder layers&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d_model&lt;/code&gt; 決定我們子詞的 representation space 維度&lt;/li&gt;
&lt;li&gt;&lt;code&gt;num_heads&lt;/code&gt; 要做幾頭的自注意力運算&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dff&lt;/code&gt; 決定 FFN 的中間維度&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dropout_rate&lt;/code&gt; 預設 0.1，一般用預設值即可&lt;/li&gt;
&lt;li&gt;&lt;code&gt;input_vocab_size&lt;/code&gt;：輸入語言（英文）的字典大小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_vocab_size&lt;/code&gt;：輸出語言（中文）的字典大小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;論文裡頭最基本的 Transformer 配置為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;num_layers=6&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d_model=512&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dff=2048&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有大量數據以及大的 Transformer，你可以在很多機器學習任務都達到不錯的成績。為了不要讓訓練時間太長，在這篇文章裡頭我會把 Transformer 裡頭的超參數設小一點：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt; 
&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;span class="n"&gt;dff&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;num_heads&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="n"&gt;input_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;dropout_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;  &lt;span class="c1"&gt;# 預設值&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"input_vocab_size:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"target_vocab_size:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;input_vocab_size: 8137
target_vocab_size: 4203
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;4 層 Encoder / Decoder layers 不算貪心，小巫見大巫（笑&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設置-Optimizer"&gt;設置 Optimizer&lt;a class="anchor-link" href="#設置-Optimizer"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這邊跟&lt;a href="https://arxiv.org/pdf/1706.03762.pdf"&gt;論文&lt;/a&gt;一致，使用 &lt;a href="optimization-6be9a291375c"&gt;Adam optimizer&lt;/a&gt; 以及自定義的 learning rate scheduler：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/lr-equation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這 schedule 讓訓練過程的前 &lt;code&gt;warmup_steps&lt;/code&gt; 的 learning rate 線性增加，在那之後則跟步驟數 &lt;code&gt;step_num&lt;/code&gt; 的反平方根成比例下降。不用擔心你沒有完全理解這公式，我們一樣可以直接使用 &lt;a href="https://www.tensorflow.org/beta/tutorials/text/transformer?authuser=1#optimizer"&gt;TensorFlow 官方教學的實作&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;schedules&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LearningRateSchedule&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 論文預設 `warmup_steps` = 4000&lt;/span&gt;
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;4000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;
    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;
    
  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__call__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;arg1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;arg2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rsqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;minimum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arg1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;arg2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
&lt;span class="c1"&gt;# 將客製化 learning rate schdeule 丟入 Adam opt.&lt;/span&gt;
&lt;span class="c1"&gt;# Adam opt. 的參數都跟論文相同&lt;/span&gt;
&lt;span class="n"&gt;learning_rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;optimizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;beta_2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.98&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                     &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1e-9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以觀察看看這個 schedule 是怎麼隨著訓練步驟而改變 learning rate 的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;d_models&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;128&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;warmup_steps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;schedules&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;colors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"blue"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"red"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"black"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d_models&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;schedules&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;CustomSchedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;labels&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"d_model: {d}, warm: {s}"&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;warmup_steps&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedule&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedules&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labels&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;schedule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt; 
           &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;colors&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Learning Rate"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Train Step"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/transformer/transformer-custom-lr.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        不同 d_model 以及 warmup_steps 的 learning rate 變化
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以明顯地看到所有 schedules 都先經過 &lt;code&gt;warmup_steps&lt;/code&gt; 個步驟直線提升 learning rate，接著逐漸平滑下降。另外我們也會給比較高維的 &lt;code&gt;d_model&lt;/code&gt; 維度比較小的 learning rate。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實際訓練以及定時存檔"&gt;實際訓練以及定時存檔&lt;a class="anchor-link" href="#實際訓練以及定時存檔"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，什麼都準備齊全了，讓我們開始訓練 Transformer 吧！記得使用前面已經定義好的超參數來初始化一個全新的 Transformer：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_layers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_heads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dff&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="n"&gt;input_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dropout_rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"""這個 Transformer 有 &lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt; 層 Encoder / Decoder layers&lt;/span&gt;
&lt;span class="s2"&gt;d_model: &lt;/span&gt;&lt;span class="si"&gt;{d_model}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;num_heads: &lt;/span&gt;&lt;span class="si"&gt;{num_heads}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;dff: &lt;/span&gt;&lt;span class="si"&gt;{dff}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;input_vocab_size: &lt;/span&gt;&lt;span class="si"&gt;{input_vocab_size}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;target_vocab_size: &lt;/span&gt;&lt;span class="si"&gt;{target_vocab_size}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;
&lt;span class="s2"&gt;dropout_rate: &lt;/span&gt;&lt;span class="si"&gt;{dropout_rate}&lt;/span&gt;&lt;span class="s2"&gt;&lt;/span&gt;

&lt;span class="s2"&gt;"""&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;這個 Transformer 有 4 層 Encoder / Decoder layers
d_model: 128
num_heads: 8
dff: 512
input_vocab_size: 8137
target_vocab_size: 4203
dropout_rate: 0.1


&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;打遊戲時你會記得要定期存檔以防任何意外發生，訓練深度學習模型也是同樣道理。設置 &lt;a href="https://www.tensorflow.org/beta/guide/checkpoints"&gt;checkpoint&lt;/a&gt; 來定期儲存 / 讀取模型及 optimizer 是必備的。&lt;/p&gt;
&lt;p&gt;我們在底下會定義一個 checkpoint 路徑，此路徑包含了各種超參數的資訊，方便之後比較不同實驗的結果並載入已訓練的進度。我們也需要一個 checkpoint manager 來做所有跟存讀模型有關的雜事，並只保留最新 5 個 checkpoints 以避免佔用太多空間：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 方便比較不同實驗/ 不同超參數設定的結果&lt;/span&gt;
&lt;span class="n"&gt;run_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt;layers_&lt;/span&gt;&lt;span class="si"&gt;{d_model}&lt;/span&gt;&lt;span class="s2"&gt;d_&lt;/span&gt;&lt;span class="si"&gt;{num_heads}&lt;/span&gt;&lt;span class="s2"&gt;heads_&lt;/span&gt;&lt;span class="si"&gt;{dff}&lt;/span&gt;&lt;span class="s2"&gt;dff_&lt;/span&gt;&lt;span class="si"&gt;{train_perc}&lt;/span&gt;&lt;span class="s2"&gt;train_perc"&lt;/span&gt;
&lt;span class="n"&gt;checkpoint_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;checkpoint_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;run_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;log_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;run_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取&lt;/span&gt;
&lt;span class="c1"&gt;# 一般來說你會想存下模型以及 optimizer 的狀態&lt;/span&gt;
&lt;span class="n"&gt;ckpt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Checkpoint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西&lt;/span&gt;
&lt;span class="c1"&gt;# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除&lt;/span&gt;
&lt;span class="n"&gt;ckpt_manager&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CheckpointManager&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;checkpoint_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_to_keep&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 如果在 checkpoint 路徑上有發現檔案就讀進來&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;ckpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;restore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 用來確認之前訓練多少 epochs 了&lt;/span&gt;
  &lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;latest_checkpoint&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'已讀取最新的 checkpoint，模型已訓練 &lt;/span&gt;&lt;span class="si"&gt;{last_epoch}&lt;/span&gt;&lt;span class="s1"&gt; epochs。'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;last_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"沒找到 checkpoint，從頭訓練。"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;已讀取最新的 checkpoint，模型已訓練 50 epochs。
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/am-i-a-joke-to-you.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;「誒！？ 你不當場訓練嗎？」「直接載入已訓練的模型太狗了吧！」&lt;/p&gt;
&lt;p&gt;拜託，我都訓練 N 遍了，每次都重新訓練也太沒意義了。而且你能想像為了寫一個章節我就得重新訓練一個 Transformer 來 demo 嗎？這樣太沒效率了。比起每次重新訓練模型，這才是你在真實世界中應該做的事情：盡可能回復之前的訓練進度來節省時間。&lt;/p&gt;
&lt;p&gt;不過放心，我仍會秀出完整的訓練程式碼讓你可以執行第一次的訓練。當你想要依照本文訓練自己的 Transformer 時會感謝有 checkpoint manager 的存在。現在假設我們還沒有 checkpoints。&lt;/p&gt;
&lt;p&gt;在實際訓練 Transformer 之前還需要定義一個簡單函式來產生所有的遮罩：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 為 Transformer 的 Encoder / Decoder 準備遮罩&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 英文句子的 padding mask，要交給 Encoder layer 自注意力機制用的&lt;/span&gt;
  &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 同樣也是英文句子的 padding mask，但是是要交給 Decoder layer 的 MHA 2 &lt;/span&gt;
  &lt;span class="c1"&gt;# 關注 Encoder 輸出序列用的&lt;/span&gt;
  &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# Decoder layer 的 MHA1 在做自注意力機制用的&lt;/span&gt;
  &lt;span class="c1"&gt;# `combined_mask` 是中文句子的 padding mask 跟 look ahead mask 的疊加&lt;/span&gt;
  &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="n"&gt;dec_target_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_padding_mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;combined_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;maximum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dec_target_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;look_ahead_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果沒有本文前面針對遮罩的詳細說明，很多第一次實作的人得花不少時間來確實地掌握這些遮罩的用途。不過對現在的你來說應該也是小菜一碟。&lt;/p&gt;
&lt;p&gt;一個數據集包含多個 batch，而每次拿一個 batch 來訓練的步驟就稱作 &lt;code&gt;train_step&lt;/code&gt;。為了讓程式碼更簡潔以及容易優化，我們會定義 Transformer 在一次訓練步驟（處理一個 batch）所需要做的所有事情。&lt;/p&gt;
&lt;p&gt;不限於 Transformer，一般來說 &lt;code&gt;train_step&lt;/code&gt; 函式裡會有幾個重要步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;對訓練數據做些必要的前處理&lt;/li&gt;
&lt;li&gt;將數據丟入模型，取得預測結果&lt;/li&gt;
&lt;li&gt;用預測結果跟正確解答計算 loss&lt;/li&gt;
&lt;li&gt;取出梯度並利用 optimizer 做梯度下降&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有了這個概念以後看看程式碼：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nd"&gt;@tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;function&lt;/span&gt;  &lt;span class="c1"&gt;# 讓 TensorFlow 幫我們將 eager code 優化並加快運算&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="c1"&gt;# 前面說過的，用去尾的原始序列去預測下一個字的序列&lt;/span&gt;
  &lt;span class="n"&gt;tar_inp&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;tar_real&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 建立 3 個遮罩&lt;/span&gt;
  &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 紀錄 Transformer 的所有運算過程以方便之後做梯度下降&lt;/span&gt;
  &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GradientTape&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;tape&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loss_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數&lt;/span&gt;
  &lt;span class="n"&gt;gradients&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tape&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainable_variables&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
  &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_gradients&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;gradients&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;trainable_variables&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要&lt;/span&gt;
  &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tar_real&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你曾經以TensorFlow 2 實作過稍微複雜一點的模型，應該就知道  &lt;code&gt;train_step&lt;/code&gt; 函式的寫法非常固定：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對輸入數據做些前處理（本文中的遮罩、將輸出序列左移當成正解 etc.）&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;tf.GradientTape&lt;/code&gt; 輕鬆記錄數據被模型做的所有轉換並計算 loss&lt;/li&gt;
&lt;li&gt;將梯度取出並讓 optimzier 對可被訓練的權重做梯度下降（上升）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你完全可以用一模一樣的方式將任何複雜模型的處理過程包在 &lt;code&gt;train_step&lt;/code&gt; 函式，這樣可以讓我們之後在 iterate 數據集時非常輕鬆。而且最重要的是可以用 &lt;a href="https://www.tensorflow.org/beta/tutorials/eager/tf_function"&gt;tf.function&lt;/a&gt; 來提高此函式裡頭運算的速度。你可以點擊連結來了解更多。&lt;/p&gt;
&lt;p&gt;處理一個 batch 的 &lt;code&gt;train_step&lt;/code&gt; 函式也有了，就只差寫個 for loop 將數據集跑個幾遍了。我之前的模型雖然訓練了 50 個 epochs，但事實上大概 30 epochs 翻譯的結果就差不多穩定了。所以讓我們將 &lt;code&gt;EPOCHS&lt;/code&gt; 設定為 30：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 定義我們要看幾遍數據集&lt;/span&gt;
&lt;span class="n"&gt;EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"此超參數組合的 Transformer 已經訓練 &lt;/span&gt;&lt;span class="si"&gt;{last_epoch}&lt;/span&gt;&lt;span class="s2"&gt; epochs。"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"剩餘 epochs：{min(0, last_epoch - EPOCHS)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="c1"&gt;# 用來寫資訊到 TensorBoard，非必要但十分推薦&lt;/span&gt;
&lt;span class="n"&gt;summary_writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_file_writer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;log_dir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 比對設定的 `EPOCHS` 以及已訓練的 `last_epoch` 來決定還要訓練多少 epochs&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;last_epoch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 重置紀錄 TensorBoard 的 metrics&lt;/span&gt;
  &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_states&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_states&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 &lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;step_idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss&lt;/span&gt;
    &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  

  &lt;span class="c1"&gt;# 每個 epoch 完成就存一次檔    &lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;ckpt_save_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ckpt_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Saving checkpoint for epoch &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; at &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                         &lt;span class="n"&gt;ckpt_save_path&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    
  &lt;span class="c1"&gt;# 將 loss 以及 accuracy 寫到 TensorBoard 上&lt;/span&gt;
  &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;summary_writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;as_default&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train_loss"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scalar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"train_acc"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Epoch &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; Loss &lt;/span&gt;&lt;span class="si"&gt;{:.4f}&lt;/span&gt;&lt;span class="s1"&gt; Accuracy &lt;/span&gt;&lt;span class="si"&gt;{:.4f}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                &lt;span class="n"&gt;train_loss&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; 
                                                &lt;span class="n"&gt;train_accuracy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Time taken for 1 epoch: &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt; secs&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;此超參數組合的 Transformer 已經訓練 50 epochs。
剩餘 epochs：0
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如訊息所示，當指定的 &lt;code&gt;EPOCHS&lt;/code&gt; 「落後」於之前的訓練進度我們就不再訓練了。但如果是第一次訓練或是訓練到指定 &lt;code&gt;EPOCHS&lt;/code&gt; 的一部分，我們都會從正確的地方開始訓練並存檔，不會浪費到訓練時間或計算資源。&lt;/p&gt;
&lt;p&gt;這邊的邏輯也很簡單，在每個 epoch 都：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（非必要）重置寫到 TensorBoard 的 metrics 的值&lt;/li&gt;
&lt;li&gt;將整個數據集的 batch 取出，交給 &lt;code&gt;train_step&lt;/code&gt; 函式處理&lt;/li&gt;
&lt;li&gt;（非必要）存 checkpoints&lt;/li&gt;
&lt;li&gt;（非必要）將當前 epoch 結果寫到 TensorBoard&lt;/li&gt;
&lt;li&gt;（非必要）在標準輸出顯示當前 epoch 結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是的，如果你真的只是想要訓練個模型，什麼其他事情都不想考慮的話那你可以：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 87 分，不能再高了。&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;epoch&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;train_dataset&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;train_step&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/transformer/go-home-every-body.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯 ... 話是這麼說，但我仍然建議你至少要記得存檔並將訓練過程顯示出來。我知道你會好奇訓練一個這樣的 Transformer 要多久時間，讓我把之前訓練的一些 log 顯示出來給你瞧瞧：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;

Saving checkpoint for epoch 1 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-1
Epoch 1 Loss 5.2072 Accuracy 0.0179
Time taken for 1 epoch: 206.54558181762695 secs

Saving checkpoint for epoch 2 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-2
Epoch 2 Loss 4.2652 Accuracy 0.0560
Time taken for 1 epoch: 68.48831677436829 secs

Saving checkpoint for epoch 3 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-3
Epoch 3 Loss 3.7987 Accuracy 0.0910
Time taken for 1 epoch: 68.41022562980652 secs


...


Saving checkpoint for epoch 29 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-29
Epoch 29 Loss 1.2693 Accuracy 0.3929
Time taken for 1 epoch: 69.18679404258728 secs

Saving checkpoint for epoch 30 at nmt/checkpoints/4layers_128d_8heads_512dff_20train_perc/ckpt-30
Epoch 30 Loss 1.2426 Accuracy 0.3965
Time taken for 1 epoch: 68.7313539981842 secs



&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上我們定義的 4 層 Transformer 大約每 70 秒就可以看完一遍有 3 萬筆訓練例子的數據集，而且你從上面的 loss 以及 accuracy 可以看出來 Transformer 至少在訓練集裡頭進步地挺快的。&lt;/p&gt;
&lt;p&gt;而就我自己的觀察大約經過 30 個 epochs 翻譯結果就很穩定了。所以你大約只需半個小時就能有一個非常簡單，有點水準的英翻中 Transformer（在至少有個一般 GPU 的情況）。&lt;/p&gt;
&lt;p&gt;但跟看上面的 log 比起來，我個人還是比較推薦使用 TensorBoard。在 TensorFlow 2 裡頭，你甚至能直接在 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;Jupyter Notebook 或是 Colab&lt;/a&gt; 裡頭開啟它：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;load_ext&lt;/span&gt; &lt;span class="n"&gt;tensorboard&lt;/span&gt;
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;tensorboard&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;logdir&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;your_log_dir&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline=""&gt;
&lt;source src="https://leemeng.tw/images/transformer/tensorboard.mp4" type="video/mp4"/&gt;
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    使用 TensorBoard 可以讓你輕鬆比較不同超參數的訓練結果
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過 TensorBoard，你能非常清楚地比較不同實驗以及不同點子的效果，知道什麼 work 什麼不 work，進而修正之後嘗試的方向。如果只是簡單寫個 &lt;code&gt;print&lt;/code&gt;，那你永遠只會看到最新一次訓練過程的 log，然後忘記之前到底發生過什麼事。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實際進行英翻中"&gt;實際進行英翻中&lt;a class="anchor-link" href="#實際進行英翻中"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了已經訓練一陣子的 Transformer，當然得拿它來實際做做翻譯。&lt;/p&gt;
&lt;p&gt;跟訓練的時候不同，在做預測時我們不需做 teacher forcing 來穩定 Transformer 的訓練過程。反之，我們將 Transformer 在每個時間點生成的中文索引加到之前已經生成的序列尾巴，並以此新序列作為其下一次的輸入。這是因為 Transformer 事實上是一個&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E8%BF%B4%E6%AD%B8%E6%A8%A1%E5%9E%8B"&gt;自迴歸模型（Auto-regressive  model）&lt;/a&gt;：依據自己生成的結果預測下次輸出。&lt;/p&gt;
&lt;p&gt;利用 Transformer 進行翻譯（預測）的邏輯如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將輸入的英文句子利用 Subword Tokenizer 轉換成子詞索引序列（還記得 &lt;code&gt;inp&lt;/code&gt; 吧？）&lt;/li&gt;
&lt;li&gt;在該英文索引序列前後加上代表英文 BOS / EOS 的 tokens&lt;/li&gt;
&lt;li&gt;在 Transformer 輸出序列長度達到 &lt;code&gt;MAX_LENGTH&lt;/code&gt; 之前重複以下步驟：&lt;ul&gt;
&lt;li&gt;為目前已經生成的中文索引序列產生新的遮罩&lt;/li&gt;
&lt;li&gt;將剛剛的英文序列、當前的中文序列以及各種遮罩放入 Transformer&lt;/li&gt;
&lt;li&gt;將 Transformer 輸出序列的最後一個位置的向量取出，並取 argmax 取得新的預測中文索引&lt;/li&gt;
&lt;li&gt;將此索引加到目前的中文索引序列裡頭作為 Transformer 到此為止的輸出結果&lt;/li&gt;
&lt;li&gt;如果新生成的中文索引為 &lt;code&gt;&amp;lt;end&amp;gt;&lt;/code&gt; 則代表中文翻譯已全部生成完畢，直接回傳&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;將最後得到的中文索引序列回傳作為翻譯結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是的，一個時間點生成一個中文字，而在第一個時間點因為 Transformer 還沒有任何輸出，我們會丟中文字的 &lt;code&gt;&amp;lt;start&amp;gt;&lt;/code&gt; token 進去。你可能會想：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        為何每次翻譯開頭都是 start token，Transformer 還能產生不一樣且正確的結果？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;答案也很簡單，因為 Decoder 可以透過「關注」 Encoder 處理完不同英文句子的輸出來獲得語義資訊，了解它在當下該生成什麼中文字作為第一個輸出。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在讓我們定義一個 &lt;code&gt;evaluate&lt;/code&gt; 函式實現上述邏輯。此函式的輸入是一個完全沒有經過處理的英文句子（以字串表示），輸出則是一個索引序列，裡頭的每個索引就代表著 Transformer 預測的中文字。&lt;/p&gt;
&lt;p&gt;讓我們實際看看 &lt;code&gt;evaluate&lt;/code&gt; 函式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 給定一個英文句子，輸出預測的中文索引數字序列以及注意權重 dict&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 準備英文句子前後會加上的 &amp;lt;start&amp;gt;, &amp;lt;end&amp;gt;&lt;/span&gt;
  &lt;span class="n"&gt;start_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;end_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  
  &lt;span class="c1"&gt;# inp_sentence 是字串，我們用 Subword Tokenizer 將其變成子詞的索引序列&lt;/span&gt;
  &lt;span class="c1"&gt;# 並在前後加上 BOS / EOS&lt;/span&gt;
  &lt;span class="n"&gt;inp_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;start_token&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;end_token&lt;/span&gt;
  &lt;span class="n"&gt;encoder_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inp_sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 跟我們在影片裡看到的一樣，Decoder 在第一個時間點吃進去的輸入&lt;/span&gt;
  &lt;span class="c1"&gt;# 是一個只包含一個中文 &amp;lt;start&amp;gt; token 的序列&lt;/span&gt;
  &lt;span class="n"&gt;decoder_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;decoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# 增加 batch 維度&lt;/span&gt;
  
  &lt;span class="c1"&gt;# auto-regressive，一次生成一個中文字並將預測加到輸入再度餵進 Transformer&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_LENGTH&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 每多一個生成的字就得產生新的遮罩&lt;/span&gt;
    &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;create_masks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;encoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
    &lt;span class="c1"&gt;# predictions.shape == (batch_size, seq_len, vocab_size)&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;encoder_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                 &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;enc_padding_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;combined_mask&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                 &lt;span class="n"&gt;dec_padding_mask&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    

    &lt;span class="c1"&gt;# 將序列中最後一個 distribution 取出，並將裡頭值最大的當作模型最新的預測字&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;  &lt;span class="c1"&gt;# (batch_size, 1, vocab_size)&lt;/span&gt;

    &lt;span class="n"&gt;predicted_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cast&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 遇到 &amp;lt;end&amp;gt; token 就停止回傳，代表模型已經產生完結果&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
    
    &lt;span class="c1"&gt;#將 Transformer 新預測的中文索引加到輸出序列中，讓 Decoder 可以在產生&lt;/span&gt;
    &lt;span class="c1"&gt;# 下個中文字的時候關注到最新的 `predicted_id`&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_id&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# 將 batch 的維度去掉後回傳預測的中文索引序列&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道這章節程式碼很多很長，但搭配註解後你會發現它們實際上都不難，而且這也是你看這篇文章的主要目的：實際了解 Transformer 是怎麼做英中翻譯的。你不想只是紙上談兵，對吧？&lt;/p&gt;
&lt;p&gt;有了 &lt;code&gt;evaluate&lt;/code&gt; 函式，要透過 Transformer 做翻譯非常容易：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 要被翻譯的英文句子&lt;/span&gt;
&lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"China, India, and others have enjoyed continuing economic growth."&lt;/span&gt;

&lt;span class="c1"&gt;# 取得預測的中文索引序列&lt;/span&gt;
&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;_&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 過濾掉 &amp;lt;start&amp;gt; &amp;amp; &amp;lt;end&amp;gt; tokens 並用中文的 subword tokenizer 幫我們將索引序列還原回中文句子&lt;/span&gt;
&lt;span class="n"&gt;target_vocab_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;
&lt;span class="n"&gt;predicted_seq_without_bos_eos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;target_vocab_size&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;predicted_sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq_without_bos_eos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_seq:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
predicted_sentence: 中国、印度和其他国家都享受了经济增长的持续发展。
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;考慮到這個 Transformer 不算巨大（約 400 萬個參數），且模型訓練時用的數據集不大的情況下，我們達到相當不錯的結果，你說是吧？在這個例子裡頭該翻的詞彙都翻了出來，句子本身也還算自然。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;transformer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Model: "transformer_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_2 (Encoder)          multiple                  1834624   
_________________________________________________________________
decoder_2 (Decoder)          multiple                  1596288   
_________________________________________________________________
dense_137 (Dense)            multiple                  542187    
=================================================================
Total params: 3,973,099
Trainable params: 3,973,099
Non-trainable params: 0
_________________________________________________________________
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="視覺化注意權重"&gt;視覺化注意權重&lt;a class="anchor-link" href="#視覺化注意權重"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了其運算高度平行以及表現不錯以外，Transformer 另外一個優點在於我們可以透過視覺化注意權重（attention weights）來了解模型實際在生成序列的時候放「注意力」在哪裡。別忘記我們當初在 Decoder layers 做完 multi-head attention 之後都將注意權重輸出。現在正是它們派上用場的時候了。&lt;/p&gt;
&lt;p&gt;先讓我們看看有什麼注意權重可以拿來視覺化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 在這邊我們自動選擇最後一個 Decoder layer 的 MHA 2，也就是 Decoder 關注 Encoder 的 MHA&lt;/span&gt;
&lt;span class="n"&gt;layer_name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"decoder_layer&lt;/span&gt;&lt;span class="si"&gt;{num_layers}&lt;/span&gt;&lt;span class="s2"&gt;_block2"&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"sentence:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"predicted_seq:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"attention_weights.keys():"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;attn&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{layer_name}&lt;/span&gt;&lt;span class="s2"&gt;.shape: &lt;/span&gt;&lt;span class="si"&gt;{attn.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"layer_name:"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;sentence: China, India, and others have enjoyed continuing economic growth.
--------------------
predicted_seq: tf.Tensor(
[4201   16    4   37  386  101    8   34   32    4   33  110  956  186
   14   22   52  107   84    1  104  292   49  218    3], shape=(25,), dtype=int32)
--------------------
attention_weights.keys():
decoder_layer1_block1.shape: (1, 8, 25, 25)
decoder_layer1_block2.shape: (1, 8, 25, 15)
decoder_layer2_block1.shape: (1, 8, 25, 25)
decoder_layer2_block2.shape: (1, 8, 25, 15)
decoder_layer3_block1.shape: (1, 8, 25, 25)
decoder_layer3_block2.shape: (1, 8, 25, 15)
decoder_layer4_block1.shape: (1, 8, 25, 25)
decoder_layer4_block2.shape: (1, 8, 25, 15)
--------------------
layer_name: decoder_layer4_block2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;block1&lt;/code&gt; 代表是 Decoder layer 自己關注自己的 MHA 1，因此倒數兩個維度都跟中文序列長度相同；&lt;code&gt;block2&lt;/code&gt; 則是 Decoder layer 用來關注 Encoder 輸出的 MHA 2 ，在這邊我們選擇最後一個 Decoder layer 的 MHA 2 來看 Transformer 在生成中文序列時關注在英文句子的那些位置。&lt;/p&gt;
&lt;p&gt;但首先，我們得要有一個繪圖的函式才行：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;mpl&lt;/span&gt;
&lt;span class="c1"&gt;# 你可能會需要自行下載一個中文字體檔案以讓 matplotlib 正確顯示中文&lt;/span&gt;
&lt;span class="n"&gt;zhfont&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mpl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;font_manager&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FontProperties&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fname&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'/usr/share/fonts/SimHei/simhei.ttf'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;use&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"seaborn-whitegrid"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 這個函式將英 -&amp;gt; 中翻譯的注意權重視覺化（注意：我們將注意權重 transpose 以最佳化渲染結果&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_attention_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    
  &lt;span class="n"&gt;fig&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  
  &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 只顯示中文序列前 `max_len_tar` 個字以避免畫面太過壅擠&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;predicted_seq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;max_len_tar&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將某一個特定 Decoder layer 裡頭的 MHA 1 或 MHA2 的注意權重拿出來並去掉 batch 維度&lt;/span&gt;
  &lt;span class="n"&gt;attention_weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
  &lt;span class="c1"&gt;# (num_heads, tar_seq_len, inp_seq_len)&lt;/span&gt;
  
  &lt;span class="c1"&gt;# 將每個 head 的注意權重畫出&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# [注意]我為了將長度不短的英文子詞顯示在 y 軸，將注意權重做了 transpose&lt;/span&gt;
    &lt;span class="n"&gt;attn_map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transpose&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;][:&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:])&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;matshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attn_map&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'viridis'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# (inp_seq_len, tar_seq_len)&lt;/span&gt;
    
    &lt;span class="n"&gt;fontdict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"fontproperties"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;zhfont&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xticklabels&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;predicted_seq&lt;/span&gt; 
                        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;subword_encoder_zh&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
                       &lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fontsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_yticklabels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'&amp;lt;start&amp;gt;'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;subword_encoder_en&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;decode&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'&amp;lt;end&amp;gt;'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
        &lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fontdict&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Head &lt;/span&gt;&lt;span class="si"&gt;{}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"x"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tick_params&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"y"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;labelsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tight_layout&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fig&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個函式不難，且裡頭不少是調整圖片的細節設定因此我將它留給你自行參考。&lt;/p&gt;
&lt;p&gt;比較值得注意的是因為我們在這篇文章是做英文（來源）到中文（目標）的翻譯，注意權重的 shape 為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;(batch_size, num_heads, zh_seq_len, en_seq_len)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你直接把注意權重繪出的話 y 軸就會是每個中文字，而 x 軸則會是每個英文子詞。而英文子詞繪在 x 軸太佔空間，我將每個注意權重都做 transpose 並呈現結果，這點你得注意一下。&lt;/p&gt;
&lt;p&gt;讓我們馬上畫出剛剛翻譯的注意權重看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plot_attention_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;attention_weights&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                       &lt;span class="n"&gt;predicted_seq&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;layer_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_len_tar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABMUAAAHvCAYAAABUoWiWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;很美，不是嗎？&lt;/p&gt;
&lt;p&gt;如果你還記得，我在本文開頭就曾經秀過這張圖甚至開玩笑地跟你說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        好黑魔法，不學嗎？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我不知道你當初跟現在的感受，但我相信在你閱讀完本文，尤其是對自注意機制以及 Transformer 有了深刻理解之後，這之間的感受肯定是有不少差異的。&lt;/p&gt;
&lt;p&gt;儘管其運算機制十分錯綜複雜，閱讀本文後 Transformer 對你來說不再是黑魔法，也不再是遙不可及的存在。如果你現在覺得「Transformer 也不過就這樣嘛！」那就達成我寫這篇文章的目的了。&lt;/p&gt;
&lt;p&gt;自注意力機制以及 Transformer 在推出之後就被非常廣泛地使用並改進，但在我自己開始接觸相關知識以後一直沒有發現完整的繁中教學，因此寫了這篇當初的我殷殷期盼的文章，也希望能幫助到更多人學習。&lt;/p&gt;
&lt;p&gt;在進入結語之前，讓我們看看文中的 Transformer 是怎麼逐漸學會做好翻譯的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline=""&gt;
&lt;source src="https://leemeng.tw/images/transformer/attention_weights_change_by_time.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：S
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    Transformer 在訓練過程中逐漸學會關注在對的位置
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在你離開之前"&gt;在你離開之前&lt;a class="anchor-link" href="#在你離開之前"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        這篇是當初在學習 Transformer 的我希望有人分享給自己的文章。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我相信人類之所以強大是因為集體知識：我們能透過書籍、影片以及語言將一個人腦中的知識與思想共享給其他人，讓寶貴的知識能夠「scale」，在更多人的腦袋中發光發熱，創造更多價值。&lt;/p&gt;
&lt;p&gt;我希望你有從本文中學到一點東西，並幫助我將本文的這些知識「scale」，把文章分享給更多有興趣的人，並利用所學應用在一些你一直想要完成的任務上面。&lt;/p&gt;
&lt;p&gt;最後一點提醒，就算 Transformer 比古早時代的方法好再多終究也只是個工具，其最大價值不會超過於被你拿來應用的問題之上。就好像現在已有不少超越基本 Transformer 的翻譯方法，但我們仍然持續在追尋更好的機器翻譯系統。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        工具會被淘汰，需求一直都在。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="自然語言處理"></category><category term="NLP"></category><category term="Tensorflow"></category></entry><entry><title>用 CartoonGAN 及 TensorFlow 2 生成新海誠與宮崎駿動畫</title><link href="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html" rel="alternate"></link><published>2019-05-05T02:20:00+09:00</published><updated>2019-05-05T02:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-05-05:/generate-anime-using-cartoongan-and-tensorflow2.html</id><summary type="html">&lt;p&gt;本文展示 3 種可以讓你馬上運用 CartoonGAN 來生成動漫的方法。其中包含了我們的 Github 專案、TensorFlow.js 應用以及一個事先為你準備好的 Colab 筆記本。有興趣的同學還可學習如何利用 TensorFlow 2.0 來訓練自己的專屬 CartoonGAN。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link href="https://leemeng.tw/tfjs-apps/cartoongan/cartoongan.css" rel="stylesheet"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如果你能用 AI 為圖片添加新海誠或是宮崎駿等人的動漫風格，你會選擇什麼圖片？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇文章將簡單介紹最近我與夥伴 &lt;a href="https://github.com/mnicnc404"&gt;mnicnc404&lt;/a&gt; 以 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0 Alpha&lt;/a&gt; 實作的 CartoonGAN（&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;Github 連結&lt;/a&gt;）。我們同時也會展示一個 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 應用，讓你可以直接在瀏覽器上產生動漫。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;CartoonGAN（原論文）&lt;/a&gt; 於 2018 &lt;a href="http://cvpr2019.thecvf.com/"&gt;CVPR&lt;/a&gt; 推出，是一個嘗試將真實世界圖片轉換成動漫的&lt;a href="https://youtu.be/yFBFl1cLYx8?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;amp;t=1879"&gt;對抗生成網路（Generative Adversarial Network，以下簡稱 GAN）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/cat_cover.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/cat_cover.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        左上為原圖，其餘三圖則為我們使用 CartoonGAN 將不同動漫風格套用到原圖上的結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當初看到這篇&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;論文&lt;/a&gt;覺得很有趣，且裡頭正好展示了我喜愛的兩位日本動畫作家：&lt;a href="https://zh.wikipedia.org/wiki/%E6%96%B0%E6%B5%B7%E8%AA%A0"&gt;新海誠&lt;/a&gt;及&lt;a href="https://zh.wikipedia.org/zh-tw/%E5%AE%AB%E5%B4%8E%E9%AA%8F"&gt;宮崎駿&lt;/a&gt;的風格轉換結果，因此決定寫個 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 應用，讓更多人可以實際體驗這個有趣的 CartoonGAN。&lt;/p&gt;
&lt;p&gt;使用方法很直覺，選擇風格並上傳照片，完成！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/generate-anime-using-cartoongan-and-tensorflow2.html"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/tfjs-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow.js 在瀏覽器裡運行，其背後處理主要分為兩個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下載模型&lt;/li&gt;
&lt;li&gt;轉換圖片&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因手機的運算能力有限，強烈建議：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用桌筆電等&lt;strong&gt;計算能力&lt;/strong&gt;強的設備開啟本頁面&lt;/li&gt;
&lt;li&gt;並在網速快的環境測試（減少&lt;strong&gt;載入模型&lt;/strong&gt;時間）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="動手玩-CartoonGAN"&gt;動手玩 CartoonGAN&lt;a class="anchor-link" href="#動手玩-CartoonGAN"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以下就是實際的應用：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="row" id="container"&gt;
&lt;div class="column50"&gt;
&lt;div&gt;
&lt;img class="cartoongan_image" id="input" src="https://leemeng.tw/tfjs-apps/cartoongan/cat.png"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="column50"&gt;
&lt;div&gt;
&lt;img class="cartoongan_image" id="pregenerated_output" src="https://leemeng.tw/tfjs-apps/cartoongan/cat_shinkai.jpg"/&gt;
&lt;canvas id="output" style="display:none"&gt;&lt;/canvas&gt;
&lt;/div&gt;
&lt;div id="app-status" style="display:none;padding:70px 0"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="row" style="margin-bottom:6rem;"&gt;
&lt;div class="column50"&gt;
&lt;label class="btn" style="margin-top: 2rem;height: 3rem;line-height:2.8rem;color:white;padding: 0 1rem"&gt;
            選擇圖片
            &lt;input id="files" multiple="" name="files[]" style="display:none" type="file"/&gt;
&lt;/label&gt;
&lt;/div&gt;
&lt;div class="column50"&gt;
&lt;select id="styles" name="styles" style="margin: auto;display: block;margin-top: 0.8rem"&gt;
&lt;option selected="selected" value="shinkai"&gt;&lt;b&gt;新海誠&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="hayao"&gt;&lt;b&gt;宮崎駿&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="hosoda"&gt;&lt;b&gt;細田守&lt;/b&gt;風格&lt;/option&gt;
&lt;option value="paprika"&gt;&lt;b&gt;盜夢偵探&lt;/b&gt;風格&lt;/option&gt;
&lt;/select&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;結果出來了嗎？如果上傳圖片後一直停在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Loading Models&lt;/code&gt;：代表仍在下載模型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cartoonizing images&lt;/code&gt;：代表設備運算資源的不足&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也先別走開！你可以使用下一節介紹的方法來生成動漫，保證有效。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="TensorFlow-2-畫動漫"&gt;TensorFlow 2 畫動漫&lt;a class="anchor-link" href="#TensorFlow-2-畫動漫"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;適逢 &lt;a href="https://tensorflow.devpost.com/"&gt;PoweredByTF 2.0 挑戰&lt;/a&gt;，我們也用 TensorFlow 2.0 Alpha 完整地實作了 CartoonGAN 的訓練以及推論邏輯。如果你想要轉換大張圖片或是動圖，可以執行&lt;a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX"&gt;這個 Colab 筆記本&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/colab-demo.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/colab-demo.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        執行我們準備的 Colab 筆記本可以讓你用 CartoonGAN 轉換任何圖片（上圖顯示該筆記本的部分內容）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://colab.research.google.com/"&gt;Google Colaboratory&lt;/a&gt; 是一個雲端 &lt;a href="https://jupyter.org/"&gt;Jupyter 筆記本&lt;/a&gt;環境，提供 GPU 讓任何人都可以立即開始一個深度學習專案。&lt;/p&gt;
&lt;p&gt;在&lt;a href="https://colab.research.google.com/drive/1WIZBHix_cYIGsBKa4phIwCq5qXwO8fRX"&gt;這個筆記本&lt;/a&gt;裡頭，以下步驟都幫你寫好了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;建置 TensorFlow 2.0 環境&lt;/li&gt;
&lt;li&gt;下載&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案及預訓練模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下載任意網路圖片 / gif&lt;/li&gt;
&lt;li&gt;使用 CartoonGAN 轉換圖片&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;你只需打開筆記本並依照指示一步步執行，即可為你的圖片添加動漫風格。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一些轉換後的動漫結果"&gt;一些轉換後的動漫結果&lt;a class="anchor-link" href="#一些轉換後的動漫結果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;獨樂樂不如眾樂樂。這一節和你分享一些我們用 CartoonGAN 得到的結果。&lt;/p&gt;
&lt;p&gt;以下每張圖片都分為四個區塊，從左到右、由上而下分別為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始圖片&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E6%96%B0%E6%B5%B7%E8%AA%A0"&gt;新海誠&lt;/a&gt;風格&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/zh-tw/%E5%AE%AB%E5%B4%8E%E9%AA%8F"&gt;宮崎駿&lt;/a&gt;風格&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%B4%B0%E7%94%B0%E5%AE%88"&gt;細田守&lt;/a&gt;風格&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;點擊下圖左右兩側的小箭頭可以切換不同圖片：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;style&gt;
&lt;!-- https://www.w3schools.com/w3css/w3css_slideshow.asp --&gt;
.w3-content,
.w3-auto {
    margin-left: auto;
    margin-right: auto
}

.w3-content {
    max-width: 980px
}

.w3-display-container:hover .w3-display-hover {
    display: block
}

.w3-display-container:hover span.w3-display-hover {
    display: inline-block
}

.w3-display-container {
    position: relative
}

.w3-button:hover {
    color: #000!important;
    background-color: inherit;
}

.w3-button {
    border: none;
    display: inline-block;
    padding: 8px 16px;
    vertical-align: middle;
    overflow: hidden;
    text-decoration: none;
    color: inherit;
    background-color: inherit;
    text-align: center;
    cursor: pointer;
    white-space: nowrap
}

.w3-button {
    -webkit-touch-callout: none;
    -webkit-user-select: none;
    -khtml-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none
}

.w3-button:disabled {
    cursor: not-allowed;
    opacity: 0.3
}

.w3-display-left {
    position: absolute;
    top: 50%;
    left: 0%;
    transform: translate(0%, -50%);
    -ms-transform: translate(-0%, -50%)
}

.w3-display-right {
    position: absolute;
    top: 50%;
    right: 0%;
    transform: translate(0%, -50%);
    -ms-transform: translate(0%, -50%)
}

.mySlides {display:none;}
&lt;/style&gt;&lt;div class="w3-content w3-display-container"&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/dance.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--marvel--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/iron-man-face.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/iron-man.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;img class="mySlides" src="https://leemeng.tw/images/cartoongan/gallery/static-woman-face.jpg" style="width:100%"/&gt;
&lt;img class="mySlides" src="https://leemeng.tw/images/cartoongan/gallery/static-temple.jpg" style="width:100%"/&gt;
&lt;!--cat--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-shake-meme.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-being-poked.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/cat-computer.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--scenary--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/big-ben.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/city-street.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/church.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--idol--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/demo.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/arakaki.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/harry-potter.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;!--virtual character--&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/pikachu.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;video autoplay="" class="mySlides" loop="" muted="" playsinline="" style="width:100%"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/gallery/kumamon.mp4" type="video/mp4"/&gt;
        您的瀏覽器不支援影片標籤，請留言通知我：S
  &lt;/video&gt;
&lt;button class="w3-button w3-black w3-display-left" onclick="plusDivs(-1)"&gt;❮&lt;/button&gt;
&lt;button class="w3-button w3-black w3-display-right" onclick="plusDivs(1)"&gt;❯&lt;/button&gt;
&lt;/div&gt;&lt;script&gt;
var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("mySlides");
  if (n &gt; x.length) {slideIndex = 1}
  if (n &lt; 1) {slideIndex = x.length}
  for (i = 0; i &lt; x.length; i++) {
    x[i].style.display = "none";  
  }
  x[slideIndex-1].style.display = "block";  
}
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;從漫威電影到可愛貓咪，從自然風景到人氣偶像，任何你想得到的圖片都可以拿來進行轉換。一旦訓練完成，我們就能使用 CartoonGAN 在彈指之間將各式各樣的圖片跟動漫做連結。&lt;/p&gt;
&lt;p&gt;在&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;裡頭，你甚至只需要執行一個指令就能取得上面展示的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python cartoonize.py &lt;span class="se"&gt;\&lt;/span&gt;
    --styles shinkai hayao hosoda
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;當然，接下來數年類似應用的效果會更加卓越。未來誰都能用這些 apps 來創造自己的動漫，而動漫作家可以據此更快速地畫出草稿、測試新點子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        如 CartoonGAN 這樣的生成模型能讓我們看到未來更多的可能性。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;順帶一提，我們在&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部&lt;/a&gt;也已經看過類似的概念。只是在該篇裡頭，我們是讓機器生成武俠小說而非動漫圖片。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="訓練你自己的-CartoonGAN"&gt;訓練你自己的 CartoonGAN&lt;a class="anchor-link" href="#訓練你自己的-CartoonGAN"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可能發現本文非常注重在 CartoonGAN 的實際應用而非演算法細節。這是因為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比起&lt;a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf"&gt;論文細節&lt;/a&gt;，多數人應該都對如何生成有趣的動漫比較感興趣&lt;/li&gt;
&lt;li&gt;網上已有不少 &lt;a href="#推薦的-GAN-學習資源"&gt;CartoonGAN 的介紹文章以及 GAN 的學習資源&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對 CartoonGAN 的實作細節有興趣的讀者可以參考&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;。基本上只要依照指示裝好開發環境以及準備好資料集，你甚至可以一鍵訓練 CartoonGAN：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/train-demo.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們的 Python 腳本提供了詳盡訊息，方便你理解訓練過程究竟發生了什麼事情
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為所有邏輯皆以 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0 Alpha&lt;/a&gt; 實作，非常適合想要跟上最新 TensorFlow 發展的讀者學習：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/alpha/guide/keras/overview"&gt;tf.keras&lt;/a&gt; 實作 Layers 以及 GAN&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/alpha/guide/data_performance"&gt;tf.data&lt;/a&gt; 讀取大量圖片並進行前處理&lt;/li&gt;
&lt;li&gt;寫訓練邏輯並使用 &lt;a href="https://youtu.be/Up9CvRLIIIw?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;tf.function&lt;/a&gt; 加快處理速度&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;TensorBoard&lt;/a&gt; 來即時觀測模型表現&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;訓練 GAN 本身並不是一件非常容易的事情。你會需要時時觀察模型的表現以評估如何調整超參數。因此我們的&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow/blob/master/train.py"&gt;訓練腳本&lt;/a&gt;也整合了 &lt;a href="https://www.tensorflow.org/tensorboard/r2/get_started#using_tensorboard_with_other_methods"&gt;TensorBoard&lt;/a&gt;，讓你可以在執行後即時地監控模型表現：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tensorboard-metrics.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們訓練 CartoonGAN 的其中一次實際結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了指標與損失函數以外，在訓練 GAN 的過程中觀察模型生成的圖片也是一件非常重要的事情。因此我們也將 CartoonGAN 生成的圖片寫入 TensorBoard 以方便你觀測比較：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tensorboard-image-demo.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        在腳本執行的過程中可以直接在 TensorBoard 上觀察 CartoonGAN 當下生成的圖片
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們只紀錄專屬於 CartoonGAN 的指標以及生成圖片，你完全可以運用類似的方法來監測任何想要訓練的模型。&lt;/p&gt;
&lt;p&gt;最後，為了方便了解 CartoonGAN 在訓練過程的表現，我們可以事先存一組真實世界的圖片當作驗證集（Validation Set），並固定讓模型在訓練一段時間後都試著將其轉換成動漫。&lt;/p&gt;
&lt;p&gt;我們可以用驗證集的轉換結果來評估模型在當下的表現。將這些圖片依時間排序後可以得到這樣的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/cartoongan/training_progress.jpg"&gt;
&lt;source src="https://leemeng.tw/images/cartoongan/training_progress.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        CartoonGAN 學習將真實世界圖片轉換為動漫的過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管尚未訓練完成，你可以看到模型逐漸學會將原始圖片轉換成簡單的動漫：線條變得清晰、顏色變得平滑。&lt;/p&gt;
&lt;p&gt;跟訓練一個&lt;a href="https://www.tensorflow.org/tutorials/keras/basic_classification"&gt;簡單分類器&lt;/a&gt;比起來，訓練一個 GAN 的難度可說是完全不同級別。但我們盡量讓&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt; Github 專案&lt;/a&gt;裡頭的程式碼邏輯簡單易懂，希望能讓更多人入門 TensorFlow 2.0 以及 GAN 的實作。&lt;/p&gt;
&lt;p&gt;當然，具備理論基礎能讓你更容易理解 TensorFlow 2 的程式碼。下節將列出推薦的學習資源供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="推薦的-GAN-學習資源"&gt;推薦的 GAN 學習資源&lt;a class="anchor-link" href="#推薦的-GAN-學習資源"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;近年以深度學習為基礎的生成模型（Generative Models）領域蓬勃發展，其中最亮眼的發展之一當屬對抗生成網路了。而本文的 CartoonGAN 也是&lt;a href="https://github.com/hindupuravinash/the-gan-zoo"&gt;眾多 GANs&lt;/a&gt; 裡頭的其中一個小夥子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/tf-dcgan.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        對抗生成網路 GAN 實際上由兩個獨立的神經網路相互「對抗」
                        （&lt;a href="https://www.tensorflow.org/alpha/tutorials/generative/dcgan" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對 GAN 的理論 &amp;amp; 基礎知識有興趣的讀者，我推薦以下的學習資源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=DQNNMiAP5lw&amp;amp;list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw"&gt;李宏毅教授在 Youtube 上的 GAN 教學影片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=yFBFl1cLYx8&amp;amp;index=1&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI"&gt;MIT 6.S191 的 Deep Generative Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab 讓你在瀏覽器上訓練並學習 GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/gan/"&gt;Andrej Karpathy 的簡單 GAN Demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/generative/dcgan"&gt;TensorFlow 官方教學帶你生成 MNIST&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jiqizhixin.com/articles/CVPR2018-CartoonGAN"&gt;機器之心講解 CartoonGAN 運作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/syncedreview/reproducing-japanese-anime-styles-with-cartoongan-ai-cf30d583736e"&gt;Synced: Reproducing Japanese Anime Styles With CartoonGAN AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://distill.pub/2019/gan-open-problems/"&gt;Open Questions about Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/cartoongan/mit-gan.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        MIT 6.S191 的 Deep Generative Models 適合入門
                        （&lt;a href="https://www.youtube.com/watch?v=yFBFl1cLYx8&amp;amp;index=1&amp;amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;生成模型及 GAN 的研究領域博大精深，但我相信參考過以上資源，你將具備實作一個簡單 GAN 所需的基礎知識。&lt;/p&gt;
&lt;p&gt;更多學習資源則請參閱&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;由淺入深的深度學習資源整理&lt;/a&gt;。另外如果你有其他推薦的學習資源，還請不吝留言與我及其他讀者分享，謝謝！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        要讓深度學習、人工智慧等研究與應用的發展加快，我們應該想辦法先讓更多人實際體驗其應用，進而理解其運作原理，最後參與其中。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以 CartoonGAN 為例，本文先專注在&lt;strong&gt;如何讓每個人都能實際體驗並應用此技術&lt;/strong&gt;，接著才簡單介紹讀者可以如何使用&lt;a href="https://github.com/mnicnc404/CartoonGan-tensorflow"&gt;我們的 Github 專案&lt;/a&gt;來訓練自己的模型。最後我也附上了一些實用的學習資源供對背後原理有興趣的讀者做些參考。&lt;/p&gt;
&lt;p&gt;這是我第一次用 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0&lt;/a&gt; 以及 &lt;a href="https://www.tensorflow.org/js"&gt;TensorFlow.js&lt;/a&gt; 實作 GAN，感謝 CartoonGAN 原作者的研究、TensorFlow / TensorFlow.js 團隊的努力、夥伴 &lt;a href="https://github.com/mnicnc404"&gt;mnicnc404&lt;/a&gt; 強大的實作支援以及許多寶貴見解，獲益良多。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望透過此文能讓更多人進一步探索 GAN 以及生成模型的相關知識，嘗試更多新的可能性，做出更多有趣的 AI 應用。&lt;/p&gt;
&lt;p&gt;也別忘了跟我分享你生成的動漫！你可以在 &lt;a href="https://twitter.com/leemengtw"&gt;Twitter&lt;/a&gt; 或是 &lt;a href="https://www.facebook.com/LeeMengTaiwan"&gt;Facebook&lt;/a&gt; 上標註我：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/cartoongan/dist/tf.js"&gt;&lt;/script&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/cartoongan/cartoongan.js"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="GAN"></category><category term="TensorFlow"></category><category term="TensorFlow.js"></category></entry><entry><title>讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部</title><link href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html" rel="alternate"></link><published>2019-03-27T09:00:00+09:00</published><updated>2019-03-27T09:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-03-27:/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html</id><summary type="html">&lt;p&gt;這篇文章展示一個由 TensorFlow 2.0 以及 TensorFlow.js 實現的文本生成應用。本文也會透過深度學習專案常見的 7 個步驟，帶領讀者一步步了解如何實現一個這樣的應用。閱讀完本文，你將對開發 AI 應用的流程有些基礎的了解。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link href="https://leemeng.tw/tfjs-apps/lstm-text-generation/index.css" rel="stylesheet"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote style="margin-bottom: 1rem"&gt;
&lt;p&gt;
        木婉清轉頭向他，背脊向著南海鱷神，低聲道：「你是世上第一個見到我容貌的男子！」緩緩拉開了面幕。段譽登時全身一震，眼前所見，如新月清暉，如花樹堆雪，一張臉秀麗絕俗。
        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;第四回：崖高人遠&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://bit.ly/2TUycBQ"&gt;《天龍八部》&lt;/a&gt;一直是我最喜歡的&lt;a href="https://zh.wikipedia.org/wiki/%E9%87%91%E5%BA%B8%E4%BD%9C%E5%93%81"&gt;金庸著作&lt;/a&gt;之一，最近重新翻閱，有很多新的感受。&lt;/p&gt;
&lt;p&gt;閱讀到一半我突發奇想，決定嘗試用&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;深度學習&lt;/a&gt;以及 &lt;a href="https://www.tensorflow.org/alpha"&gt;TensorFlow 2.0&lt;/a&gt; 來訓練一個能夠生成《天龍八部》的&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF"&gt;循環神經網路&lt;/a&gt;。生成結果仍不完美，但我認為已經很有娛樂性質，且有時能夠產生令人驚嘆或是捧腹大笑的文章了。&lt;/p&gt;
&lt;p&gt;因此我決定使用 &lt;a href="https://www.tensorflow.org/js"&gt;Tensorflow.js&lt;/a&gt; 將訓練出來的模型弄上線，讓你也能實際看看這個 AI 嗑了什麼藥。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/dali-old-castle.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        大理古城一隅，段譽出身之地
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 demo 之後，我將以此文的 AI 應用為例，用 TensorFlow 2.0 帶你走過深度學習專案中常見的 7 個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#1.-定義問題及要解決的任務"&gt;定義問題及要解決的任務&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#2.-準備原始數據、資料清理"&gt;準備原始數據、資料清理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#3.-建立能丟入模型的資料集"&gt;建立能丟入模型的資料集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#4.-定義能解決問題的函式集"&gt;定義能解決問題的函式集&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#5.-定義評量函式好壞的指標"&gt;定義評量函式好壞的指標&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#6.-訓練並選擇出最好的函式"&gt;訓練並選擇出最好的函式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#7.-將函式-/-模型拿來做預測"&gt;將函式 / 模型拿來做預測&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;希望閱讀本文後能讓你學到點東西，從中獲得些啟發，並運用自己的想像力創造點新的東西。&lt;/p&gt;
&lt;p&gt;前言夠長了，讓我們馬上進入 demo 吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="生成新的天龍八部橋段"&gt;生成新的天龍八部橋段&lt;a class="anchor-link" href="#生成新的天龍八部橋段"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本篇使用一個十分簡單的&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶 RNN&lt;/a&gt; 來生成文章。在多次「閱讀」天龍八部之後，這個模型可以在給定一段文本的情況下，逐字產生類似天龍八部小說的文章。&lt;/p&gt;
&lt;p&gt;比方說給定書中的一個橋段：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;烏老大偏生要考一考慕容復，說道：「慕容公子，你瞧這不是大大的
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你會怎麼接下去？&lt;/p&gt;
&lt;p&gt;本文的模型順著上面的話生成的其中一次結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;不算？」馬夫人道：「不錯，咱們非要尋死不可。」

段譽大喜，說道：「小姑娘，你待我這麼好，鬼鬼祟祟，一切又不聽你的話，你管甚麼老兄弟不相干，我去幫過彥之。」

王夫人哼了一聲，說道：「這裏是甚麼話？」段譽道：「不行！你別過來。用真蠻子，我便將這件事了，一大惡人擠在地下，立時便會斃命，那便如何是好？」
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;文章內容很ㄎ一ㄤ，惹人發笑，但用詞本身很天龍八部。（至少我自己寫不出這樣的內容）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/antony-xia-522590-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        姑蘇慕容家所在的蘇州
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在馬上就讓我們產生一些新的橋段吧！首先將已經訓練好的模型載入你的瀏覽器。&lt;/p&gt;
&lt;p&gt;（建議在網速快的地方載入模型以減少等待時間，或者點擊載入後先閱讀&lt;a href="#模型是怎麼被訓練的"&gt;模型是怎麼被訓練的&lt;/a&gt;，等等再回來查看）&lt;/p&gt;
&lt;p&gt;成功載入模型後，你將可以用它不斷地產生新的橋段：&lt;/p&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;button id="load-model" style="display:inline-block"&gt;載入模型&lt;/button&gt;
&lt;div id="app-status" style="display:inline-block"&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你會發現有 2 個可供你調整的參數：&lt;/p&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成長度（字單位）&lt;/span&gt;
&lt;input id="generate-length" value="150"/&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成溫度（隨機度）&lt;/span&gt;
&lt;input id="temperature" value="0.6"/&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;p&gt;第一次可以直接使用預設值。現在點擊&lt;strong&gt;生成文章&lt;/strong&gt;來產生全新的天龍八部橋段：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;button disabled="true" id="generate-text"&gt;生成文章&lt;/button&gt;
&lt;button disabled="true" id="initialize-seed"&gt;重置輸入&lt;/button&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;起始句子：&lt;/span&gt;
&lt;span id="text-generation-status" style="display: none"&gt;&lt;/span&gt;
&lt;textarea id="seed-text" rows="1" style="min-height: 6em" value=""&gt;蕭峯吃了一驚，心想：「哥哥大喜之餘，說話有些忘形了，眼下亂成&lt;/textarea&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;section style="margin-bottom: 3rem"&gt;
&lt;div&gt;
&lt;span class="input-title"&gt;生成結果：&lt;/span&gt;
&lt;textarea id="generated-text" readonly="true" rows="10" value=""&gt;&lt;/textarea&gt;
&lt;/div&gt;
&lt;/section&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如何？希望模型產生的結果有成功令你嘴角上揚。當初它可快把我逗死了。&lt;/p&gt;
&lt;p&gt;現在你可以嘗試幾件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;點&lt;strong&gt;生成文章&lt;/strong&gt;來讓模型依據同輸入產生新橋段&lt;/li&gt;
&lt;li&gt;點&lt;strong&gt;重置輸入&lt;/strong&gt;來隨機取得一個新的起始句子&lt;/li&gt;
&lt;li&gt;增加模型生成的&lt;strong&gt;文章長度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;調整&lt;strong&gt;生成溫度&lt;/strong&gt;來改變文章的變化性&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/chris-rhoads-254898-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;生成溫度是一個實數值，而當溫度越高，模型產生出來的結果越隨機、越不可預測（也就越ㄎㄧㄤ）；而溫度越低，產生的結果就會越像天龍八部原文。優點是真實，但同時字詞的重複性也會提升。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        機器並沒有情感，只有人類可以賦予事物意義。我們無法讓機器自動找出最佳的生成溫度，因為人的感覺十分主觀：找出你自己覺得最適合的溫度來生成文章。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你沒有打算深入探討技術細節，那只需要記得在這篇文章裡頭的模型是一個以「字」為單位的語言模型（Character-based Language Model）即可：給定一連串已經出現過的字詞，模型會想辦法去預測出下一個可能出現的字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/raychan-1229841-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得注意的是，我們並不單純是拿出現機率最高的字出來當生成結果，這樣太無趣了。&lt;/p&gt;
&lt;p&gt;每次機器做預測前都會拿著一個包含大量中文字的機率分布 p，在決定要吐出哪個字時，會對該機率分佈 p 做抽樣，從中隨機選出一個字。&lt;/p&gt;
&lt;p&gt;因此就跟你在上面 demo 看到的一樣，就算輸入的句子相同，每次模型仍然會生成完全不同的文章。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/max-felner-448887-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        抽樣的過程類似擲骰子，儘管有些結果較易出現，你還是有機會骰到豹子
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為隨機抽樣的關係，每次模型產生的結果基本上都是獨一無二的。&lt;/p&gt;
&lt;p&gt;如果你在生成文章的過程中得到什麼有趣的虛擬橋段，都歡迎與我分享：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/chris-ried-512801-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文接著將詳細解說此應用是怎麼被開發出來的。如果你現在沒有打算閱讀，可以直接跳到&lt;a href="#結語"&gt;結語&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="模型是怎麼被訓練的"&gt;模型是怎麼被訓練的&lt;a class="anchor-link" href="#模型是怎麼被訓練的"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在看完 demo 以後，你可能會好奇這個模型是怎麼被訓練出來的。&lt;/p&gt;
&lt;p&gt;實際的開發流程大致可以分為兩個部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;用 TensorFlow 2.0 訓練一個 LSTM 模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;使用 TensorFlow.js 部屬該模型&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些在 TensorFlow 以及 TensorFlow.js 的官網都有詳細的教學以及程式碼供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tf-demo.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這篇文章參考了不少 TensorFlow 官網（左）及 TensorFlow.js 線上 demo（右）的程式碼
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你也想開發一個類似的應用，閱讀官方教學中你所熟悉的語言版本（Python / JavaScript）是最直接的作法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;TensorFlow 2.0 Alpha - Text generation with an RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;TensorFlow.js Example: Train LSTM to Generate Text&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為官方已經有提供能在 &lt;a href="https://colab.research.google.com/"&gt;Google Colab&lt;/a&gt; 上使用 GPU &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;訓練 LSTM 的教學筆記本&lt;/a&gt;，本文便不再另行提供。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/simon-abrams-286276-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外，具備以下背景可以讓你更輕鬆地閱讀接下來的內容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;熟悉 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;碰過 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 或是 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;具備&lt;a href="https://leemeng.tw/deep-learning-resources.html#courses"&gt;機器學習 &amp;amp; 深度學習基礎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;了解何謂&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF"&gt;循環神經網路&lt;/a&gt;以及&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你是喜歡先把基礎打好的人，可以先查閱我上面附的這些資源連結。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="TensorFlow-2.0-開發"&gt;TensorFlow 2.0 開發&lt;a class="anchor-link" href="#TensorFlow-2.0-開發"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;平常有在接觸深度學習的讀者或許都已經知道，最近 TensorFlow 隆重推出 &lt;a href="https://www.tensorflow.org/alpha"&gt;2.0 Alpha 預覽版&lt;/a&gt;，希望透過全新的 API 讓更多人可以輕鬆地開發機器學習以及深度學習應用。&lt;/p&gt;
&lt;p&gt;當初撰寫本文的其中一個目的，也是想趁著這次大改版來讓自己熟悉一下 TensorFlow 2.0 的開發方式。&lt;/p&gt;
&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube.com/embed/TTQQiJ-mHYA"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 值得關注的&lt;a href="https://youtu.be/YzLnnGiLNRE?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;更新&lt;/a&gt;不少，但以下幾點跟一般的 ML 開發者最為相關：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.tensorflow.org/alpha/guide/keras/overview"&gt;tf.keras&lt;/a&gt; 被視為官方高級 API，強調其地位&lt;/li&gt;
&lt;li&gt;方便除錯的 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb"&gt;Eager Execution&lt;/a&gt; 成為預設值&lt;/li&gt;
&lt;li&gt;負責讀取、處理大量數據的 &lt;a href="https://www.tensorflow.org/alpha/guide/data_performance"&gt;tf.data&lt;/a&gt; API&lt;/li&gt;
&lt;li&gt;自動幫你建構計算圖的 &lt;a href="https://youtu.be/Up9CvRLIIIw?list=PLQY2H8rRoyvzoUYI26kHmKSJBedn3SQuB"&gt;tf.function&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇文章裡頭會看到前 3 者。下節列出的程式碼皆在 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;Google Colab&lt;/a&gt; 上用最新版本的 TensorFlow 2.0 Nightly 執行。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install tf-nightly-gpu-2.0-preview
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果有 GPU 則強烈建議安裝 GPU 版本的 TF Nightly，訓練速度跟 CPU 版本可以差到 10 倍以上。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="深度學習專案步驟"&gt;深度學習專案步驟&lt;a class="anchor-link" href="#深度學習專案步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好戲終於登場。&lt;/p&gt;
&lt;p&gt;如同多數的深度學習專案，要訓練一個以 LSTM 為基礎的語言模型，你大致需要走過以下幾個步驟：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/deep-learning-pj-steps-menglee.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        開發一個 DL 專案時我常用的流程架構
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個流程是一個大方向，依據不同情境你可能需要做些調整來符合自己的需求，且很多步驟需要重複進行。&lt;/p&gt;
&lt;p&gt;這篇文章會用 TensorFlow 2.0 簡單地帶你走過所有步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="1.-定義問題及要解決的任務"&gt;1. 定義問題及要解決的任務&lt;a class="anchor-link" href="#1.-定義問題及要解決的任務"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，在訓練模型前首先得確認我們的問題（Problem）以及想要交給機器解決的任務（Task）是什麼。&lt;/p&gt;
&lt;p&gt;前面已經提過，我們的目標就是要找出一個天龍八部的語言模型（Language Model），讓該模型在被餵進一段文字以後，能吐出類似天龍八部的文章。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;div class="resp-container"&gt;
&lt;iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="resp-iframe" frameborder="0" src="https://www.youtube.com/embed/f1KUUz7v8g4?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9"&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;center&gt;
    十分推薦李宏毅教授講解序列生成的影片
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這實際上是一個&lt;a href="https://youtu.be/f1KUUz7v8g4?list=PLJV_el3uVTsPMxPbjeX7PicgWbY7F8wW9"&gt;序列生成（Sequence Generation）&lt;/a&gt;問題，而機器所要解決的任務也變得明確：給定一段文字單位的序列，它要能吐出下一個合理的文字單位。&lt;/p&gt;
&lt;p&gt;這邊說的文字單位（Token）可以是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字（Character，如劍、寺、雲）&lt;/li&gt;
&lt;li&gt;詞（Word，如吐蕃、師弟、阿修羅）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文則使用「字」作為一個文字單位。現在假設有一個天龍八部的句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;『六脈神劍經』乃本寺鎮寺之寶，大理段氏武學的至高法要。
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這時候句子裡的每個字（含標點符號）都是一個文字單位，而整個句子就構成一個文字序列。我們可以擷取一部份句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;『六脈神劍經』乃本寺鎮寺之寶，大理段氏武
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著在訓練模型時要求它讀入這段文字，並預測出原文裡頭出現的下一個字：&lt;code&gt;學&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;一旦訓練完成，就能得到你開頭看到的那個語言模型了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="2.-準備原始數據、資料清理"&gt;2. 準備原始數據、資料清理&lt;a class="anchor-link" href="#2.-準備原始數據、資料清理"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;巧婦難為無米之炊，沒有數據一切免談。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/caroline-attwood-243834-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我在網路上蒐集天龍八部原文，做些簡單的數據清理後發現整本小說總共約含 120 萬個中文字，實在是一部曠世巨作。儘管因為版權問題不宜提供下載連結，你可以 Google 自己有興趣的文本。&lt;/p&gt;
&lt;p&gt;現在假設我們把原文全部存在一個 Python 字串 &lt;code&gt;text&lt;/code&gt; 裡頭，則部分內容可能如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 隨意取出第 9505 到 9702 的中文字&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9505&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;9702&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;咱們見敵方人多，不得師父號令，沒敢隨便動手。」左子穆道：「嗯，來了多少人？」干光豪道：「大約七八十人。」左子穆嘿嘿冷笑，道：「七八十人，便想誅滅無量劍了？只怕也沒這麼容易。」

龔光傑道：「他們用箭射過來一封信，封皮上寫得好生無禮。」說著將信呈上。

左子穆見信封上寫著：「字諭左子穆」五個大字，便不接信，說道：「你拆來瞧瞧。」龔光傑道：「是！」拆開信封，抽出信箋。

那少女在段譽耳邊低聲道：
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們也可以看看整本小說裡頭包含多少中文字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"天龍八部小說共有 &lt;/span&gt;&lt;span class="si"&gt;{n}&lt;/span&gt;&lt;span class="s2"&gt; 中文字"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"包含了 &lt;/span&gt;&lt;span class="si"&gt;{w}&lt;/span&gt;&lt;span class="s2"&gt; 個獨一無二的字"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;天龍八部小說共有 1235431 中文字
包含了 4330 個獨一無二的字
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;相較於英文只有 26 個簡單字母，博大精深的中文裡頭有非常多漢字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/raychan-1061280-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;裡頭說過的，要將文本數據丟入只懂數字的神經網路，我們得先做些前處理。&lt;/p&gt;
&lt;p&gt;具體來說，得將這些中文字對應到一個個的索引數字（Index）或是向量才行。&lt;/p&gt;
&lt;p&gt;我們可以使用 &lt;code&gt;tf.keras&lt;/code&gt; 裡頭的 &lt;code&gt;Tokenizer&lt;/code&gt; 幫我們把整篇小說建立字典，並將同樣的中文字對應到同樣的索引數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tensorflow&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;tf&lt;/span&gt;

&lt;span class="c1"&gt;# 初始化一個以字為單位的 Tokenizer&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;char_level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;filters&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 讓 tokenizer 讀過天龍八部全文，&lt;/span&gt;
&lt;span class="c1"&gt;# 將每個新出現的字加入字典並將中文字轉&lt;/span&gt;
&lt;span class="c1"&gt;# 成對應的數字索引&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_on_texts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;text_as_int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;])[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 隨機選取一個片段文本方便之後做說明&lt;/span&gt;
&lt;span class="n"&gt;s_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;21004&lt;/span&gt;
&lt;span class="n"&gt;e_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;21020&lt;/span&gt;
&lt;span class="n"&gt;partial_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;s_idx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;e_idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;partial_texts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;partial_indices&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# 渲染結果，可忽略&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"原本的中文字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"轉換後的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;原本的中文字序列：

['司', '空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前', '。']

--------------------

轉換後的索引序列：

[557, 371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111, 2]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，現在整部天龍八部都已經被轉成一個巨大的數字序列，每一個數字代表著一個獨立的中文字。&lt;/p&gt;
&lt;p&gt;我們可以換個方向再看一次：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;人類看的中文字   機器看的輸入索引  
------------------------------
司                557
空                371
玄                215
雙                214
掌                135
飛                418
舞               1209
，                  1
逼                837
得                 25
牠               1751
無                 49
法                147
近                537
前                111
。                  2
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="3.-建立能丟入模型的資料集"&gt;3. 建立能丟入模型的資料集&lt;a class="anchor-link" href="#3.-建立能丟入模型的資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;做完基本的數據前處理以後，我們需要將 &lt;code&gt;text_as_int&lt;/code&gt; 這個巨大的數字序列轉換成神經網路容易消化的格式與大小。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[1639, 148, 3, 3, 280, 5, 192, 819, 374, 800]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;_type&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"text_as_int 是一個 &lt;/span&gt;&lt;span class="si"&gt;{_type}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"小說的序列長度： &lt;/span&gt;&lt;span class="si"&gt;{n}&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"前 5 索引："&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;text_as_int 是一個 &amp;lt;class 'list'&amp;gt;

小說的序列長度： 1235431

前 5 索引： [1639, 148, 3, 3, 280]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在建立資料集時，你要先能想像最終交給模型的數據長什麼樣子。這樣能幫助你對數據做適當的轉換。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照當前機器學習任務的性質，你會需要把不同格式的數據餵給模型。&lt;/p&gt;
&lt;p&gt;在本文的序列生成任務裡頭，理想的模型要能依據前文來判斷出下一個中文字。因此我們要丟給模型的是一串代表某些中文字的數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"實際丟給模型的數字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"方便我們理解的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;實際丟給模型的數字序列：
[557, 371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111]

方便我們理解的文本序列：
['司', '空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而模型要給我們的理想輸出應該是向左位移一個字的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"實際丟給模型的數字序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_indices&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"方便我們理解的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partial_texts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;實際丟給模型的數字序列：
[371, 215, 214, 135, 418, 1209, 1, 837, 25, 1751, 49, 147, 537, 111, 2]

方便我們理解的文本序列：
['空', '玄', '雙', '掌', '飛', '舞', '，', '逼', '得', '牠', '無', '法', '近', '前', '。']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為什麼是這樣的配對？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/bruce-mars-559223-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們將輸入序列及輸出序列拿來對照看看：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;司 空 玄 雙 掌 飛 舞 ， 逼 得 牠 無 法 近

空 玄 雙 掌 飛 舞 ， 逼 得 牠 無 法 近 前
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;從左看到右你會發現，一個模型如果可以給我們這樣的輸出，代表它：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;看到第一個輸入字 &lt;code&gt;司&lt;/code&gt; 時可以正確輸出 &lt;code&gt;空&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司&lt;/code&gt;，且新輸入字為 &lt;code&gt;空&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;玄&lt;/code&gt; &lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司空&lt;/code&gt;，且新輸入字為 &lt;code&gt;玄&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;雙&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;在之前看過 &lt;code&gt;司空玄雙掌飛&lt;/code&gt;，且新輸入字為 &lt;code&gt;舞&lt;/code&gt; 的情況下，可以輸出 &lt;code&gt;，&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當一個語言模型可以做到這樣的事情，就代表它已經掌握了&lt;strong&gt;訓練文本&lt;/strong&gt;（此文中為天龍八部）裡頭用字的統計結構，因此我們可以用它來產生新的天龍八部文章。&lt;/p&gt;
&lt;p&gt;你現在應該也可以了解，這個語言模型是專為天龍八部的文本所誕生的。畢竟日常生活中，給你 &lt;code&gt;舞&lt;/code&gt; 這個字，你接 &lt;code&gt;，&lt;/code&gt; 的機率有多少呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/niketh-vellanki-202943-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你加深印象，讓我把序列擺直，再次列出模型的輸入以及輸出關係：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;時間點 輸入字  輸入索引   輸出字  輸出索引  
-------------------------------------
   1    司     557      空      371
   2    空     371      玄      215
   3    玄     215      雙      214
   4    雙     214      掌      135
   5    掌     135      飛      418
   6    飛     418      舞      1209
   7    舞     1209     ，      1
   8    ，     1        逼      837
   9    逼     837      得      25
  10    得     25       牠      1751
  11    牠     1751     無      49
  12    無     49       法      147
  13    法     147      近      537
  14    近     537      前      111
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;每一列（row）是一個時間點，而&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;輸入索引&lt;/strong&gt;代表模型在當下時間吃進去的輸入&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;輸出索引&lt;/strong&gt;則代表我們要模型輸出的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;輸入字・輸出字則只是方便我們理解對照，實際上模型只吃數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/pop-zebra-754186-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在我們了解一筆輸入・輸出該有的數據格式了。兩者皆是一個固定長度的數字序列，而後者是前者往左位移一個數字的結果。&lt;/p&gt;
&lt;p&gt;但這只是一筆數據（以下說的一筆數據，都隱含了輸入序列以及對應的輸出序列的 2 個數字序列）。&lt;/p&gt;
&lt;p&gt;在有 GPU 的情況下，我們常常會一次丟一批（batch）數據，讓 GPU 可以平行運算，加快訓練速度。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/gpu.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在假設我們想要一個資料集，而此資料集可以一次給我們 128 筆長度為 10 的輸入・輸出序列，則我們可以用 &lt;code&gt;tf.data&lt;/code&gt; 這樣做：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 方便說明，實際上我們會用更大的值來&lt;/span&gt;
&lt;span class="c1"&gt;# 讓模型從更長的序列預測下個中文字&lt;/span&gt;
&lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;  &lt;span class="c1"&gt;# 數字序列長度&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt; &lt;span class="c1"&gt;# 幾筆成對輸入/輸出&lt;/span&gt;

&lt;span class="c1"&gt;# text_as_int 是一個 python list&lt;/span&gt;
&lt;span class="c1"&gt;# 我們利用 from_tensor_slices 將其&lt;/span&gt;
&lt;span class="c1"&gt;# 轉變成 TensorFlow 最愛的 Tensor &amp;lt;3&lt;/span&gt;
&lt;span class="n"&gt;characters&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dataset&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_tensor_slices&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將被以數字序列表示的天龍八部文本&lt;/span&gt;
&lt;span class="c1"&gt;# 拆成多個長度為 SEQ_LENGTH (10) 的序列&lt;/span&gt;
&lt;span class="c1"&gt;# 並將最後長度不滿 SEQ_LENGTH 的序列捨去&lt;/span&gt;
&lt;span class="n"&gt;sequences&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;characters&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;drop_remainder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 天龍八部全文所包含的成對輸入/輸出的數量&lt;/span&gt;
&lt;span class="n"&gt;steps_per_epoch&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text_as_int&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="n"&gt;SEQ_LENGTH&lt;/span&gt;

&lt;span class="c1"&gt;# 這個函式專門負責把一個序列&lt;/span&gt;
&lt;span class="c1"&gt;# 拆成兩個序列，分別代表輸入與輸出&lt;/span&gt;
&lt;span class="c1"&gt;# （下段有 vis 解釋這在做什麼）&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;build_seq_pairs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;input_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;target_text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;input_text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;target_text&lt;/span&gt;

&lt;span class="c1"&gt;# 將每個從文本擷取出來的序列套用上面&lt;/span&gt;
&lt;span class="c1"&gt;# 定義的函式，拆成兩個數字序列&lt;/span&gt;
&lt;span class="c1"&gt;# 作為輸入／輸出序列&lt;/span&gt;
&lt;span class="c1"&gt;# 再將得到的所有數據隨機打亂順序&lt;/span&gt;
&lt;span class="c1"&gt;# 最後再一次拿出 BATCH_SIZE（128）筆數據&lt;/span&gt;
&lt;span class="c1"&gt;# 作為模型一次訓練步驟的所使用的資料&lt;/span&gt;
&lt;span class="n"&gt;ds&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sequences&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;build_seq_pairs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;steps_per_epoch&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;batch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
           &lt;span class="n"&gt;drop_remainder&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這段建構 &lt;code&gt;tf.data.Dataset&lt;/code&gt; 的程式碼雖然不短，但有超過一半是我寫給你的註解。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上用 &lt;code&gt;tf.data&lt;/code&gt; 架構一個資料集並不難，且學會以後你每次都可用類似的方式呼叫 &lt;a href="https://www.tensorflow.org/guide/datasets"&gt;TensorFlow Data API&lt;/a&gt; 來處理&lt;strong&gt;任何&lt;/strong&gt;文本數據，而不需要每次遇到新文本都從頭開始寫類似的功能（&lt;code&gt;batch&lt;/code&gt;、&lt;code&gt;shuffle&lt;/code&gt; etc）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/avi-richards-183715-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再次提醒，如果你想自己動手可以參考&lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/text_generation.ipynb"&gt;官方用 TensorFlow 2.0 訓練 LSTM 的 Colab 筆記本&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;雖然我不是酷拉皮卡，但如果要把上面 &lt;code&gt;build_seq_pairs&lt;/code&gt; 的處理具現化的話，大概就像是下面這樣（假設序列長度為 6）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;擷取的片段序列       輸入/輸出序列
-------------------------------
                 -&amp;gt; 烏老大拱手還
                 |
烏老大拱手還禮 -----
                 |
                 -&amp;gt; 老大拱手還禮


                 -&amp;gt; 星宿派人數遠
                 |
星宿派人數遠較 -----
                 |
                 -&amp;gt; 宿派人數遠較


                 -&amp;gt; 過不多時，賈
                 |
過不多時，賈老 -----
                 |
                 -&amp;gt; 不多時，賈老
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現針對序列長度 &lt;code&gt;SEQ_LENGTH&lt;/code&gt; 為 6 的情況，我會刻意將天龍八部文本切成長度為 &lt;code&gt;SEQ_LENGTH + 1&lt;/code&gt;：7 的句子，再從這些句子建立出輸入及輸出序列。&lt;/p&gt;
&lt;p&gt;到此為止，我們已經用 &lt;code&gt;tf.data&lt;/code&gt; 建立出一個可以拿來訓練語言模型的資料集了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mika-baumeister-703680-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 預設就是 &lt;a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb"&gt;Eager Execution&lt;/a&gt;，因此你不再需要使用老朋友 &lt;code&gt;tf.Session()&lt;/code&gt; 或是 &lt;code&gt;tf.placeholder&lt;/code&gt; 就能非常直覺地存取數據：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# print 是用來幫你理解 tf.data.Dataset&lt;/span&gt;
&lt;span class="c1"&gt;# 的內容，實際上存取資料集非常簡單&lt;/span&gt;
&lt;span class="c1"&gt;# 現在先關注下面的 print 結果&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"起始句子的 batch："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"目標句子的 batch："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個起始句子的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個目標句子的索引序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;first_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    
    &lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個起始句子的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;first_i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"第一個目標句子的文本序列："&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;first_t&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;起始句子的 batch：
tf.Tensor(
[[1440   10   12 ... 1882   15  175]
 [ 157   16  212 ...   11  206   92]
 [  36   14   36 ...  368  384   63]
 ...
 [  61    8    3 ...   11    5  219]
 [ 123  189  587 ...   65  120   51]
 [   1    5  620 ...    2    8 1272]], shape=(128, 10), dtype=int32) 

目標句子的 batch：
tf.Tensor(
[[  10   12    7 ...   15  175   99]
 [  16  212   67 ...  206   92    1]
 [  14   36   36 ...  384   63    2]
 ...
 [   8    3    3 ...    5  219    1]
 [ 189  587  884 ...  120   51  196]
 [   5  620  597 ...    8 1272 1275]], shape=(128, 10), dtype=int32) 

-------------------- 

第一個起始句子的索引序列：
[1440   10   12    7   63   19   17 1882   15  175] 

第一個目標句子的索引序列：
[  10   12    7   63   19   17 1882   15  175   99] 

-------------------- 

第一個起始句子的文本序列：
['陵', '道', '：', '「', '想', '來', '他', '嫌', '你', '本']

第一個目標句子的文本序列：
['道', '：', '「', '想', '來', '他', '嫌', '你', '本', '事']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你理解資料集回傳的內容，上面用了不少 &lt;code&gt;print&lt;/code&gt;。但事實上這個資料集 &lt;code&gt;ds&lt;/code&gt; 負責的就是每次吐出 2 個 128 筆數據的 Tensor，分別代表輸入與輸出的批次數據（Batch）。&lt;/p&gt;
&lt;p&gt;而每筆數據則包含了一個長度為 10 的數字序列，代表著天龍八部裡頭的一段文本。&lt;/p&gt;
&lt;p&gt;減少一些 &lt;code&gt;print&lt;/code&gt;，你要從資料集 &lt;code&gt;ds&lt;/code&gt; 取得一個 batch 的輸入／輸出非常地簡單：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b_tar&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# 蒙多想去哪就去哪&lt;/span&gt;
    &lt;span class="c1"&gt;# 想怎麼存取 b_iup, b_tar 都可以&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"b_inp 是個 Tensor：&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_inp&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;b_tar 也是個 Tensor，"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"只是每個數字序列都是"&lt;/span&gt;
          &lt;span class="s2"&gt;"對應的輸入序列往左位"&lt;/span&gt;
          &lt;span class="s2"&gt;"移一格的結果&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b_tar&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;b_inp 是個 Tensor：

tf.Tensor(
[[   2  953 1214 ...    1   52  219]
 [   6    2   15 ...   36  189    5]
 [2456 1167 3142 ...  110 1186   56]
 ...
 [ 422  244   19 ...    2    8   46]
 [ 254   51  237 ...  123   64   27]
 [1561   25   55 ...   66    2    3]], shape=(128, 10), dtype=int32)

b_tar 也是個 Tensor，
只是每個數字序列都是對應的輸入序列往左位移一格的結果

tf.Tensor(
[[ 953 1214   41 ...   52  219   52]
 [   2   15  189 ...  189    5  189]
 [1167 3142 1294 ... 1186   56    5]
 ...
 [ 244   19  145 ...    8   46   41]
 [  51  237  202 ...   64   27  569]
 [  25   55    9 ...    2    3    3]], shape=(128, 10), dtype=int32)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="4.-定義能解決問題的函式集"&gt;4. 定義能解決問題的函式集&lt;a class="anchor-link" href="#4.-定義能解決問題的函式集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;呼！我們花了不少時間在建構資料集，是時候捲起袖子將這些資料丟入模型了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/How_to_Roll_Up_Sleeves_01.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回想資料集內容，你現在應該已經很清楚我們想要模型解決的問題是什麼了：丟入一個數字序列，模型要能產生包含下個時間點的數字序列，最好是跟當初的&lt;strong&gt;輸出&lt;/strong&gt;序列一模一樣！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在 &lt;a href="https://demo.leemeng.tw/"&gt;AI 如何找出你的喵&lt;/a&gt;裡頭說過的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        任何類型的神經網路本質上都是一個映射函數。它們會在內部進行一連串特定的數據轉換步驟，想辦法將給定的輸入數據轉換成指定的輸出形式。 
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們現在要做的就是定義一個神經網路架構，讓這個神經網路（或稱函式）幫我們把輸入的數字序列轉換成對應的輸出序列。&lt;/p&gt;
&lt;p&gt;我們期待這個模型具有「記憶」，能考慮以前看過的所有歷史資訊，進而產生最有可能的下個中文字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        循環神經網路非常適合處理具有順序關係的數據
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而在&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;自然語言處理與深度學習入門指南&lt;/a&gt;我們也已經看到，循環神經網路中的 LSTM 模型非常適合拿來做這件事情。&lt;/p&gt;
&lt;p&gt;因此雖然理論上你可以用任意架構的神經網路（如基本的前饋神經網路）來解決這個問題，使用 LSTM（或 GRU，甚至是 1D CNN）是一個相對安全的起手式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/playing-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用 Keras 開發深度學習模型
                        （&lt;a href="https://youtu.be/Lx3l4lOrquw?t=277" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 TensorFlow 裡頭，使用 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"&gt;Keras API&lt;/a&gt; 建立一個神經網路就像是在疊疊樂，一層一層蓋上去：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數&lt;/span&gt;
&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;

&lt;span class="c1"&gt;# 使用 keras 建立一個非常簡單的 LSTM 模型&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="c1"&gt;# 將每個索引數字對應到一個高維空間的向量&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;output_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;batch_input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="c1"&gt;# 負責將序列數據依序讀入並做處理&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;return_sequences&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;stateful&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;recurrent_initializer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'glorot_uniform'&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層&lt;/span&gt;
&lt;span class="c1"&gt;# 負責 model 每個中文字出現的可能性&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/model_summary.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們建立了一個由&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/word_embeddings"&gt;詞嵌入層&lt;/a&gt;、LSTM 層以及全連接層組成的簡單 LSTM 模型。此模型一次吃 128 筆長度任意的數字序列，在內部做些轉換，再吐出 128 筆同樣長度，4330 維的 Tensor。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/yifeng-lu-1230629-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你還記得，4330 實際上是天龍八部裡頭所有出現過的中文字數目。&lt;/p&gt;
&lt;p&gt;&lt;div id="supervised" style="display: inline"&gt;因此&lt;/div&gt;事實上我們已經把本來看似沒有正解的生成問題轉變成一個&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式&lt;/a&gt;且有 4330 個&lt;a href="https://en.wikipedia.org/wiki/Statistical_classification"&gt;分類的問題&lt;/a&gt;了。我們希望訓練模型，使得其每次預測出來的字都跟正確解答（即輸出序列裡的字）一樣。&lt;/p&gt;
&lt;p&gt;值得一提的是，儘管這個神經網路（或稱映射函數）看起來非常有希望能解決我們的序列生成問題，我們並不僅僅是建立了 1 個映射函數而已。事實上，我們用 &lt;code&gt;tf.keras&lt;/code&gt; 定義了一個有接近 1,300 萬參數的函式&lt;strong&gt;集合&lt;/strong&gt;（Function set）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/antoine-dautry-428776-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這跟你懷疑一個資料集的特徵 &lt;code&gt;x&lt;/code&gt; 跟目標值 &lt;code&gt;y&lt;/code&gt; 成線性關係，然後想用 &lt;code&gt;a * x + b = y&lt;/code&gt; 的直線去 fit &lt;code&gt;y&lt;/code&gt; 的道理是一樣的。&lt;/p&gt;
&lt;p&gt;你相信 &lt;code&gt;a * x + b = y&lt;/code&gt; 形式的映射函數能幫你把輸入 &lt;code&gt;x&lt;/code&gt; 有效地對應到目標 &lt;code&gt;y&lt;/code&gt;，你只是還不知道最佳的參數組合 &lt;code&gt;(a, b)&lt;/code&gt; 該設多少罷了。&lt;/p&gt;
&lt;p&gt;同理，很多研究結果顯示 LSTM 模型能很好地處理序列數據，我們只是還不知道最適合生成天龍八部文章的參數組合是什麼而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/backpropagation-example.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        深度學習中我們常使用梯度下降與反向傳播來從函數集合中找出最好的函數（某個特定參數組合的神經網路架構）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;參數 &lt;code&gt;a&lt;/code&gt; 以及 &lt;code&gt;b&lt;/code&gt; 有無限多種組合，而每一組 &lt;code&gt;a&lt;/code&gt; 與 &lt;code&gt;b&lt;/code&gt; 的組合都對應到一個實際的&lt;strong&gt;函數&lt;/strong&gt;。每個函數都能幫你把 &lt;code&gt;x&lt;/code&gt; 乘上 &lt;code&gt;a&lt;/code&gt; 倍再加上 &lt;code&gt;b&lt;/code&gt; 去 fit 目標值 &lt;code&gt;y&lt;/code&gt;，只是每個函數的表現不一而已。而把所有可能的函數放在一起，就是所謂的函數集合。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/jeremy-thomas-99326-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文的 LSTM 模型架構因為參數組合無窮無盡，本身就像是一個巨大的函數空間。而我們得從裡頭找出能解決問題的特定函數（參數組合）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對 &lt;code&gt;a * x + b = y&lt;/code&gt; 這個簡單例子，我們可以直接用線性代數從整個函式集合裡頭瞬間找出最佳的函數 &lt;code&gt;f&lt;/code&gt;（即最佳的 &lt;code&gt;(a, b)&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;而在深度學習領域裡頭，我們會透過&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"&gt;梯度下降（Gradient Descent）&lt;/a&gt;以及&lt;a href="https://www.youtube.com/watch?v=ibJpTrp5mcE"&gt;反向傳播算法（Backpropagation）&lt;/a&gt;來幫我們在浩瀚無垠的函式集合（如本文中的 LSTM 網路架構）裡頭找出一個好的神經網路（某個 1,300 萬個參數的組合）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/deep-learning-framework.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        深度學習框架
                        （&lt;a href="https://agi.io/2018/02/09/survey-machine-learning-frameworks/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;幸好我們後面會看到，像是 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt;、&lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 等深度學習框架幫我們把這件事情變得簡單多了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="5.-定義評量函式好壞的指標"&gt;5. 定義評量函式好壞的指標&lt;a class="anchor-link" href="#5.-定義評量函式好壞的指標"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;有了&lt;a href="#建立能丟入模型的資料集"&gt;資料集&lt;/a&gt;以及 &lt;a href="#定義能解決問題的函式集"&gt;LSTM 模型架構&lt;/a&gt;以後，我們得定義一個&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%B1%BA%E5%AE%9A%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%A1%A8%E7%8F%BE"&gt;損失函數（Loss Function）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在監督式學習裡頭，一個損失函數評估某個模型產生出來的預測結果 &lt;code&gt;y_pred&lt;/code&gt; 跟正確解答 &lt;code&gt;y&lt;/code&gt; 之間的差距。一個好的函式／模型，要能最小化損失函數。&lt;/p&gt;
&lt;p&gt;有了損失函數以後，我們就能讓模型計算當前預測結果與正解之間的差異（Loss），據此調整模型內的參數以降低這個差異。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/robot_thinking.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        機器學習模型或 AI 不會幫我們定義損失函數，因為只有我們能決定什麼是對的，什麼是錯的（至少在 2019 年是這樣）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照不同情境、不同機器學習任務你會需要定義不同的損失函數。&lt;/p&gt;
&lt;p&gt;如同&lt;a href="#supervised"&gt;前述&lt;/a&gt;，其實我們要 LSTM 模型做的是一個分類問題（Classification Problem）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        給定之前看過的文字序列以及當下時間點的新輸入字，從 4330 個字裡頭預測下一個出現的字。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此本文的問題可以被視為一個有 4330 個分類（字）的問題。而要定義分類問題的損失相對簡單，使用 &lt;a href="https://keras.io/zh/losses/#sparse_categorical_crossentropy"&gt;sparse_categorical_crossentropy&lt;/a&gt; 是個不錯的選擇：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 超參數，決定模型一次要更新的步伐有多大&lt;/span&gt;
&lt;span class="n"&gt;LEARNING_RATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.001&lt;/span&gt;

&lt;span class="c1"&gt;# 定義模型預測結果跟正確解答之間的差異&lt;/span&gt;
&lt;span class="c1"&gt;# 因為全連接層沒使用 activation func&lt;/span&gt;
&lt;span class="c1"&gt;# from_logits= True &lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;losses&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;y_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_pred&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;from_logits&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 編譯模型，使用 Adam Optimizer 來最小化&lt;/span&gt;
&lt;span class="c1"&gt;# 剛剛定義的損失函數&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;\
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;optimizers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Adam&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;learning_rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;LEARNING_RATE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;model.compile&lt;/code&gt; 讓我們告訴模型在訓練的時候該使用什麼&lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers"&gt;優化器（optimizers）&lt;/a&gt;來最小化剛剛定義的&lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses"&gt;損失函數&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;完成這個步驟以後，我們就能開始訓練模型了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="6.-訓練並選擇出最好的函式"&gt;6. 訓練並選擇出最好的函式&lt;a class="anchor-link" href="#6.-訓練並選擇出最好的函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在完成前 5 個步驟以後，訓練一個 Keras 模型本身是一件非常簡單的事情，只需要呼叫 &lt;code&gt;model.fit&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="c1"&gt;# 決定看幾篇天龍八部文本&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="c1"&gt;# 前面使用 tf.data 建構的資料集&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/fit-logging.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Keras 模型在訓練時就會不斷吐出結果供你參考
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很多時候你需要跑很多次 &lt;code&gt;fit&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;一般來說，你事先並不知道要訓練多少個 epochs 模型才會收斂，當然也不知道怎麼樣的超參數會表現最好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/diz-play-31367-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;大多時候，你會想要不斷地驗證腦中的點子、調整超參數、訓練新模型，並再次依照實驗結果嘗試新點子。&lt;/p&gt;
&lt;p&gt;這時候 TensorFlow 的視覺化工具 &lt;a href="https://www.tensorflow.org/tensorboard"&gt;TensorBoard&lt;/a&gt; 就是你最好的朋友之一：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tensorboard.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 TensorBoard 記錄下實驗結果，方便記錄自己做了什麼實驗，什麼 work 什麼不 work
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;TensorFlow 2.0 新增了 &lt;a href="https://github.com/tensorflow/tensorboard/blob/master/docs/r2/tensorboard_in_notebooks.ipynb"&gt;JupyterNotebook 的 Extension&lt;/a&gt;，讓你可以直接在筆記本或是 &lt;a href="https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/r2/tensorboard_in_notebooks.ipynb"&gt;Google Colab&lt;/a&gt; 上邊訓練模型邊查看結果。&lt;/p&gt;
&lt;p&gt;跟以往使用 TensorBoard 一樣，你需要為 Keras 模型增加一個 &lt;a href="https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/callbacks/TensorBoard"&gt;TensorBoard Callback&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt;\
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TensorBoard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"logs"&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="c1"&gt;# 你可以加入其他 callbacks 如&lt;/span&gt;
    &lt;span class="c1"&gt;# ModelCheckpoint,&lt;/span&gt;
    &lt;span class="c1"&gt;# EarlyStopping&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;ds&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EPOCHS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;callbacks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;callbacks&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著在訓練開始之後（之前也行）載入 Extension 並執行 TensorBoard 即可：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;load_ext&lt;/span&gt; tensorboard.notebook
&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;tensorboard&lt;/span&gt; --logdir logs
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/tensorboard-demo2.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了確保模型有一直努力在降低損失函數以外，我們也可以觀察模型在訓練過程中生成的文章內容。比方說給定一個句子：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;模型在完全沒有訓練的情況下生成的結果為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，鑠淆孤癸抑私磚簧麥笠簸殯膽稼匿聲罪殖省膻臆啟殖
》斥酒燥弄咪薔鬃衝矚理蝗驗吞柢舌滴漂撿毛等櫈磁槃鞭爛辣諱輝母犢楊拜攜戛婉額虐延久鋒幟懸質迸飭南軌忸瑩娘檔麵獎逍菌包怖續敗倨凍赭彈暖顴衽劑街榻裝貨啕畿驛吳
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/black-man-question.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這模型並沒有中邪。只不過模型中 1,300 萬個參數的值完全隨機，你可不能期待模型能做什麼有意義的數據處理。&lt;/p&gt;
&lt;p&gt;而在模型看了 20 遍天龍八部以後產生的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，說道：「我不知道，不是你的好人，你就是你的好。」木婉清道：「他&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;師父是誰？」

段正淳道：「王姑娘，你還是不是？」段譽道：「你說過的話，他&amp;hellip;&amp;hellip;我&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;你&amp;hellip;&amp;hellip;」

那女郎道：「嗯
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;結果差強人意，「你我他」後面只會加一大堆點點點。&lt;/p&gt;
&lt;p&gt;但如果你仔細觀察，其實也已經有不少值得注意的地方：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型已經知道怎麼產生正確的人名&lt;/li&gt;
&lt;li&gt;知道 &lt;code&gt;道&lt;/code&gt; 後面要接冒號以及上括號&lt;/li&gt;
&lt;li&gt;知道有上括號時後面應該要有下括號&lt;/li&gt;
&lt;li&gt;知道要適時加入換行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這其實已經是不小的成就了！&lt;/p&gt;
&lt;p&gt;而在看過 100 遍天龍八部以後產生的結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;喬峯指著深谷，往前走去。

段譽見到這等慘狀，心下大驚，當即伸手去撫摸她的頭髮，心想：「我想叫你滾出去！」一面說，一面擤了些鼻涕拋下。

那大漢掙扎著要站起身來，只見一條大漢身披獸皮，眼前青光閃閃，雙手亂舞
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;擤了些鼻涕拋下&lt;/code&gt; 很不段譽，但我還是笑了。&lt;/p&gt;
&lt;p&gt;文章本身順暢很多，而且內容也豐富不少。另外用字也挺天龍八部的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/theodor-lundqvist-438530-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你應該也已經注意到，句子之間沒有太大的故事關聯性。而這邊帶出一個很重要的概念：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        這個語言模型只能學會天龍八部裡頭字與字之間的統計關係，而無法理解金庸的世界觀。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此不要期待模型每次都能產生什麼深具含義的結果。&lt;/p&gt;
&lt;p&gt;儘管還不完美，到此為止我們手上已經有訓練過的模型了。讓我們拿它來產生新的文本了吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="7.-將函式-/-模型拿來做預測"&gt;7. 將函式 / 模型拿來做預測&lt;a class="anchor-link" href="#7.-將函式-/-模型拿來做預測"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;大部分你在深度學習專案裡頭訓練出來的模型可以直接拿來做預測。&lt;/p&gt;
&lt;p&gt;不過因為循環神經網路傳遞狀態的方式，一旦建好模型，&lt;code&gt;BATCH_SIZE&lt;/code&gt; 就不能做變動了。但在實際生成文章時，我們需要讓 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 等於 1。&lt;/p&gt;
&lt;p&gt;因此在這邊我們會重新建立一個一模一樣的 LSTM 模型架構，將其 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 設為 1 後讀取之前訓練時儲存的參數權重：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 跟訓練時一樣的超參數，&lt;/span&gt;
&lt;span class="c1"&gt;# 只差在 BATCH_SIZE 為 1&lt;/span&gt;
&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;
&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# 專門用來做生成的模型&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Sequential&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;input_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;output_dim&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;batch_input_shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
            &lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RNN_UNITS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;return_sequences&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;stateful&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keras&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# 讀入之前訓練時儲存下來的權重&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ckpt_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TensorShape&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation#restore_the_latest_checkpoint"&gt;讀取權重&lt;/a&gt;，這段程式碼對你來說應該已經十分眼熟。有了 &lt;code&gt;infer_model&lt;/code&gt; 以後，接著我們要做的就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將起始文本丟入模型&lt;/li&gt;
&lt;li&gt;抽樣得到新的中文字&lt;/li&gt;
&lt;li&gt;將新得到的字再丟入模型&lt;/li&gt;
&lt;li&gt;重複上述步驟&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而實際預測的流程大概就長這個樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/sampling.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        重複抽樣取得新的中文字
                        （&lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation#the_prediction_loop" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="#生成新的天龍八部橋段"&gt;生成新的天龍八部橋段&lt;/a&gt;所看到的，依照你設定的&lt;strong&gt;生成長度&lt;/strong&gt;，我們需要重複上述步驟數次。&lt;/p&gt;
&lt;p&gt;而要執行一次的抽樣也並沒有非常困難：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 代表「喬」的索引&lt;/span&gt;
&lt;span class="n"&gt;seed_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;234&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 

&lt;span class="c1"&gt;# 增加 batch 維度丟入模型取得預測結果後&lt;/span&gt;
&lt;span class="c1"&gt;# 再度降維，拿掉 batch 維度&lt;/span&gt;
&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;seed_indices&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 利用生成溫度影響抽樣結果&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="n"&gt;temperature&lt;/span&gt;

&lt;span class="c1"&gt;# 從 4330 個分類值中做抽樣&lt;/span&gt;
&lt;span class="c1"&gt;# 取得這個時間點模型生成的中文字&lt;/span&gt;
&lt;span class="n"&gt;sampled_indices&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;\
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;num_samples&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;抽樣的程式碼為了方便解說有稍作刪減，如果你要實際動手跑看看，請參考官方的 &lt;a href="https://www.tensorflow.org/alpha/tutorials/sequences/text_generation"&gt;Text generation with an RNN&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;這邊我想要你看到的重點是如何利用&lt;strong&gt;生成溫度&lt;/strong&gt; &lt;code&gt;temperature&lt;/code&gt; 的概念來影響最後的抽樣結果。&lt;/p&gt;
&lt;p&gt;如同 demo 時說明的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        生成溫度是一個實數值，而當溫度越高，模型產生出來的結果越隨機、越不可預測
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;模型的輸出為一個 4330 維度的 Tensor，而其中的每一維都對應到一個中文字。維度值越大即代表該字被選到的機會越大。&lt;/p&gt;
&lt;p&gt;而當我們把整個分佈 &lt;code&gt;predictions&lt;/code&gt;除以一個固定值 &lt;code&gt;temperature&lt;/code&gt; 時，越大的值被縮減的程度越大，進而讓各維度之間的絕對差異變小，使得原來容易被選到的字被抽到的機會變小，少出現的字被選到的機會稍微提升。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/temperature_dist.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        溫度越高，分佈會變得越平滑，罕見字被選到的機會上升，生成結果越隨機
                        （&lt;a href="https://www.manning.com/books/deep-learning-with-python" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是為何我們會想手動調整生成溫度的原因。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何使用-TensorFlow.js-跑模型並生成文章_1"&gt;如何使用 TensorFlow.js 跑模型並生成文章&lt;a class="anchor-link" href="#如何使用-TensorFlow.js-跑模型並生成文章"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;雖然本文以天龍八部為例，事實上你已經了解如何使用 TensorFlow 2.0 來架構出一個能產生任意文本的 LSTM 模型了。&lt;/p&gt;
&lt;p&gt;一般而言，只要你把剛剛生成文本的 Keras 模型儲存下來，接著就可以在任何機器或雲端平台（如 GCP、AWS）上進行生成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;infer_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"model.h5"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;最近適逢 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt; 推出 &lt;a href="https://github.com/tensorflow/tfjs/releases/tag/v1.0.0"&gt;1.0.0 版本&lt;/a&gt;，我決定嘗試使用 &lt;a href="https://github.com/tensorflow/tfjs-converter"&gt;tfjs-converter&lt;/a&gt; 將 Keras 模型轉換成 TensorFlow.js 能夠運行的格式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensorflowjs_converter &lt;span class="se"&gt;\&lt;/span&gt;
    --input_format&lt;span class="o"&gt;=&lt;/span&gt;keras &lt;span class="se"&gt;\&lt;/span&gt;
    model.h5 &lt;span class="se"&gt;\&lt;/span&gt;
    tfjs_model_folder
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;轉換完成後會得到 tfjs 的模型，接著只要把它放到伺服器或是 Github 上就能在任何靜態網頁上載入模型：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nx"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;tf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;loadLayersModel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"url"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="kr"&gt;const&lt;/span&gt; &lt;span class="nx"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nx"&gt;model&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;input&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在&lt;a href="https://leemeng.tw/deep-learning-resources.html#tensorflow.js"&gt;由淺入深的深度學習資源整理&lt;/a&gt;就曾介紹過 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;，他們有很多有趣的 &lt;a href="https://www.tensorflow.org/js/demos/"&gt;Demos&lt;/a&gt;，想要在瀏覽器上實作 AI 應用的你可以去了解一下。&lt;/p&gt;
&lt;p&gt;使用 TensorFlow.js 好處在於：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隱私有保障。使用者上傳、輸入的內容不會被上傳到伺服器&lt;/li&gt;
&lt;li&gt;開發者不需租借伺服器或是建置 API 端點，無部署成本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當你能把模型讀入瀏覽器以後，只要將我們剛剛在前面介紹過的 Python 邏輯利用 &lt;a href="https://js.tensorflow.org/api/latest/"&gt;TensorFlow.js API&lt;/a&gt; 實現即可。&lt;/p&gt;
&lt;p&gt;熟悉 JavaScript 的你甚至還可以&lt;a href="https://github.com/tensorflow/tfjs-examples/tree/master/lstm-text-generation"&gt;直接在瀏覽器上訓練類似本文的 LSTM 模型並生成文章&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;感謝你花費那麼多時間閱讀本文！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/matt-jones-42954-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回顧一下，我們在文中談了非常多的東西：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何利用深度學習 7 步驟開發 AI 應用&lt;ol&gt;
&lt;li&gt;定義問題及要解決的任務&lt;/li&gt;
&lt;li&gt;準備原始數據、資料清理&lt;/li&gt;
&lt;li&gt;建立能丟入模型的資料集&lt;/li&gt;
&lt;li&gt;定義能解決問題的函式集&lt;/li&gt;
&lt;li&gt;定義評量函式好壞的指標&lt;/li&gt;
&lt;li&gt;訓練並選擇出最好的函式&lt;/li&gt;
&lt;li&gt;將函式 / 模型拿來做預測&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;了解如何利用深度學習解決序列生成任務&lt;/li&gt;
&lt;li&gt;熟悉 TensorFlow 2.0 的重要功能&lt;ul&gt;
&lt;li&gt;tf.keras&lt;/li&gt;
&lt;li&gt;tf.data&lt;/li&gt;
&lt;li&gt;TensorBoard&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們也看到你可以如何運用 &lt;a href="https://github.com/tensorflow/tfjs-converter"&gt;tfjs-converter&lt;/a&gt; 將 Python 與 JavaScript 這兩個世界結合起來，建立可以給任何人在任何裝置上執行的 AI 應用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/robin-worrall-749755-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了可以被用來解決「被動」的分類、迴歸問題，近年深度學習在「主動」的&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"&gt;生成任務&lt;/a&gt;上也展現了卓越的成果。&lt;/p&gt;
&lt;p&gt;廣為人知的應用有 Google 的 &lt;a href="https://en.wikipedia.org/wiki/DeepDream"&gt;DeepDream&lt;/a&gt;、神經風格轉換以及最近 &lt;a href="https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/"&gt;NVIDIA 將塗鴉轉成風景照&lt;/a&gt;的例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/lstm-text-generation/nvidia_gaugan_gif.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        將塗鴉轉成風景照的 GauGAN 能讓沒有美術背景的人繪出美麗圖片，也能幫助藝術家更快將點子實現出來
                        （&lt;a href="https://blogs.nvidia.com/blog/2019/03/18/gaugan-photorealistic-landscapes-nvidia-research/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就像本文的天龍八部生成，儘管還未臻完美，讓機器自動生成全新、沒人看過的事物一直是人類追求的夢想之一。&lt;/p&gt;
&lt;p&gt;但這些人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence）的研究並不是一味地追求如何&lt;strong&gt;取代&lt;/strong&gt;人類智慧；反之，AI 更像是&lt;strong&gt;增強&lt;/strong&gt;我們的智慧（&lt;strong&gt;A&lt;/strong&gt;ugmented &lt;strong&gt;I&lt;/strong&gt;ntelligence）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        最好的 AI 是為了讓我們的生活充滿更多智慧，而非取代我們的智慧。AI 能擴充我們對世界的想像，讓我們看到更多不同的可能性。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文已經很長，我就不再佔用你的時間了。&lt;/p&gt;
&lt;p&gt;能一路聽我碎碎唸到這裡，代表你對 AI 以及深度學習的應用是抱持著很大的興趣的。希望在此之後你能運用本文學到的知識與技術，實踐你的瘋狂點子並分享給我以及更多人知道。&lt;/p&gt;
&lt;p&gt;現在我得回去看還沒看完的天龍八部了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="致敬"&gt;致敬&lt;a class="anchor-link" href="#致敬"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;僅用這篇微不足道的文章向&lt;a href="https://zh.wikipedia.org/wiki/%E9%87%91%E5%BA%B8"&gt;金庸&lt;/a&gt;致敬，感謝他帶給我們那麼多膾炙人口的故事。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;script src="https://leemeng.tw/tfjs-apps/lstm-text-generation/dist/lstm-text-generation.03657dc5.js"&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="TensorFlow"></category><category term="TensorFlow.js"></category><category term="自然語言處理"></category></entry><entry><title>我從 AI For Everyone 學到的 10 個重要 AI 概念</title><link href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html" rel="alternate"></link><published>2019-03-05T08:00:00+09:00</published><updated>2019-03-05T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-03-05:/10-key-takeaways-from-ai-for-everyone-course.html</id><summary type="html">&lt;p&gt;AI For Everyone 是由吳恩達教授開授的一堂線上課程，這篇文章則記錄了我個人在修習完這堂線上課程後整理出的 10 個最重要 AI 概念。除了將這些概念條列出來以外，本文也將逐一介紹每個概念所代表的涵意，幫助讀者快速掌握該課程裡頭的重要 AI 概念，並開始自己的 AI 之旅。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在這個人機共存的年代，每個人都應該去嘗試瞭解並運用人工智慧這個超能力。思考自己未來在這個變化快速的世界的定位。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;曾經領導 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授這幾天公開了新的 &lt;a href="https://www.coursera.org/"&gt;Coursera&lt;/a&gt; 課程：&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;。這堂課不談技術術語，專注在與非技術人士以及企業經理人說明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;何謂 AI&lt;/li&gt;
&lt;li&gt;如何建立 AI 專案&lt;/li&gt;
&lt;li&gt;如何在企業內部建立 AI 基礎&lt;/li&gt;
&lt;li&gt;AI 與社會的關係&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;課程內容精要，總結了不少他多年在 Google Brain、百度裡領導 AI 團隊所累積的寶貴經驗。這堂課也提到了不少 &lt;a href="https://landing.ai/ai-transformation-playbook/"&gt;AI Transformation Playbook&lt;/a&gt; 裡頭的內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/course.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Coursera 上的 AI For Everyone
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然課程中很多時候是以 CEO 或是企業管理者的角度說明 AI 概念，但我認為每個人都可以用&lt;strong&gt;個人&lt;/strong&gt;角度，從本課學到不少有用的建議以及思考框架。有了這些概念，可以幫助我們在這個變化快速的 AI 潮流中掌握好自己手上的船舵並順利航行。&lt;/p&gt;
&lt;p&gt;本文將列舉出我認為本課中最值得記住的 10 個 AI 概念，希望能讓你馬上學到些東西。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/kaleidico-754605-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，這篇不少概念是我自己的心得總結，而你在上完課後肯定會有其他重要見解。事實上，我會推薦你在閱讀本文後就找時間實際去上這堂課，或是透過&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;其他方式&lt;/a&gt;進一步了解 AI。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="30-秒-AI-大局觀"&gt;30 秒 AI 大局觀&lt;a class="anchor-link" href="#30-秒-AI-大局觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以下就是 10 個我認為 AI For Everyone 這堂課傳達的重要概念懶人包。如果你一秒鐘幾十萬上下，可以只看這節就好：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;/li&gt;
&lt;li&gt;多數 AI 應用是讓機器學會一個對應關係&lt;/li&gt;
&lt;li&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;/li&gt;
&lt;li&gt;只需花費你 1 秒的任務，大都可由 AI 自動化&lt;/li&gt;
&lt;li&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;/li&gt;
&lt;li&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;/li&gt;
&lt;li&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;/li&gt;
&lt;li&gt;機器學習和資料科學的產出分別是系統和洞見&lt;/li&gt;
&lt;li&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;/li&gt;
&lt;li&gt;終身學習在這個年代前所未有地重要&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ben-white-131241-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;是的，既然是 AI For Everyone，自然沒有什麼艱深內容。但就像吳恩達教授在課程裡頭所說的，我相信這些基本的核心思想可以引導我們在這個 AI 時代更有方向且順利地前進。&lt;/p&gt;
&lt;p&gt;本文接著會搭配課程投影片，針對上面提到的一些概念做點簡單的補充說明，供你參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="講到-AI，我們通常是指狹義的-AI-而非終結者"&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;a class="anchor-link" href="#講到-AI，我們通常是指狹義的-AI-而非終結者"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在媒體整天報導的人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence, AI）應用如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;智慧音響&lt;/li&gt;
&lt;li&gt;自動駕駛&lt;/li&gt;
&lt;li&gt;人臉辨識&lt;/li&gt;
&lt;li&gt;圖像分類&lt;/li&gt;
&lt;li&gt;推薦系統&lt;/li&gt;
&lt;li&gt;機器翻譯&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;背後皆是狹義的 AI（&lt;strong&gt;A&lt;/strong&gt;rtificial &lt;strong&gt;N&lt;/strong&gt;arrow &lt;strong&gt;I&lt;/strong&gt;ntelligence, ANI）。&lt;/p&gt;
&lt;p&gt;儘管很多 AI 應用的表現甚至已經比人類還優秀，這些 AI 基本上都專注在完成「特定」的任務；這跟科幻電影如魔鬼終結者裡頭，能跟人類以一樣的方式思考並做「任何」事情的通用 AI（&lt;strong&gt;A&lt;/strong&gt;rtificial &lt;strong&gt;G&lt;/strong&gt;eneral &lt;strong&gt;I&lt;/strong&gt;ntelligence, AGI）是有很大差異的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ani-vs-agi.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        ANI 與 AGI 的差異
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管開發出 AGI 是很多研究者的終極夢想，但事實上現行的科技離實現 AGI 還有好一段距離。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="多數-AI-應用是讓機器學會一個對應關係"&gt;多數 AI 應用是讓機器學會一個對應關係&lt;a class="anchor-link" href="#多數-AI-應用是讓機器學會一個對應關係"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在以前的文章裡頭看過的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html"&gt;進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://demo.leemeng.tw/"&gt;AI 如何找出你的喵：直觀理解卷積神經網路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;大部分的機器學習以及 AI 應用本質上都是讓電腦學會一個映射函數（Mapping Function），幫我們將輸入的數據 A 對應到理想的輸出 B：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;郵件分類：電子郵件 -&amp;gt; 是否為垃圾郵件&lt;/li&gt;
&lt;li&gt;語音辨識：音訊檔案 -&amp;gt; 文本&lt;/li&gt;
&lt;li&gt;機器翻譯：英文文本 -&amp;gt; 中文文本&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/learning-a-to-b.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        抽離技術細節，許多 AI 應用事實上就是一個個幫我們將輸入 A 轉換成輸出 B 的映射函數
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要實現這種 AI 應用，最常被使用的方法是&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式學習（Supervised Learning）&lt;/a&gt;：給予機器大量的成對數據，告訴它什麼樣的 A 要對應到什麼樣的 B，並讓機器最後自己學會如何將任意的 A 轉換成理想的 B，達到自動化的目的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-data-source-nn.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        現在多數的 AI 應用是透過人工神經網路，讓機器學會如何將輸入 A 轉成輸出 B
                        （&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="大數據、神經網路及運算能力是-AI-成功關鍵"&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;a class="anchor-link" href="#大數據、神經網路及運算能力是-AI-成功關鍵"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要實現能幫助人類做複雜判斷的 AI 技術有很多種，但近年真正讓 AI 大紅大紫的是&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;以及&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;人工神經網路（Artifical Neural Network）&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/neural-network-plyaground.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Google 的 TensorFlow 團隊讓你可以在瀏覽器裡頭體驗深度學習以及神經網路
                        （&lt;a href="https://playground.tensorflow.org" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，你或許常聽到「神經網路跟人腦運作方式相同」的這種說法，但事實上如果你問相關人士對這種意見的看法的話，得到的答案常常是「兩者天差地遠」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管神經網路的運作方式跟我們神奇的大腦不完全一致，搭配大量數據以及前面提到的監督式學習，越大的神經網路通常可以在特定任務有越好的表現。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/big-data-and-deep-neural-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        先不論所需的計算資源，「越大量的數據以及越大型的神經網路能帶來更好的表現」這件事情對許多大企業來說，是件美好到不行的事情
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然這樣的現象令人振奮，但別忘記&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大型神經網路的運作&lt;/li&gt;
&lt;li&gt;大量數據的處理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩件事情都意味著需要更大量的電腦運算能力。而很多時候一般人是沒有這樣的運算資源的。&lt;/p&gt;
&lt;p&gt;值得慶幸的是，很多以深度學習為基礎的 AI 常常有個很好的特性：透過&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習（Transfer Learning）&lt;/a&gt;，我們能將事先已經用大量計算資源做訓練，並在任務 A 表現優異的 AI 做些簡單修改，就能讓修改過後的 AI' 能在相似的任務 B 也表現不錯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/cnn-with-pretrained-model.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一個利用遷移學習，把在圖像辨識中表現優異的 AI 拿來辨識貓咪的例子
                        （&lt;a href="https://demo.leemeng.tw/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這時候就算你只有少量數據以及不多的計算資源，也能利用 AI 完成以往難以想像的任務。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="只需花費你-1-秒的任務，（未來）大都可由-AI-自動化"&gt;只需花費你 1 秒的任務，（未來）大都可由 AI 自動化&lt;a class="anchor-link" href="#只需花費你-1-秒的任務，（未來）大都可由-AI-自動化"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這項概念是吳恩達教授在課程裡所提到的「一秒原則」，可以讓你用來判斷一個任務是否能用 AI 做自動化的準則。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/one-second-rule.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一秒原則
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過監督式學習以及大量成對 A &amp;amp; B 數據，我們可以讓很多以往被認為非常複雜，但人腦僅需 1 秒鐘就能解決的任務透過 AI 來自動化，讓我們的生活更加輕鬆。&lt;/p&gt;
&lt;p&gt;當然，這個簡化的原則並不是放諸四海皆準，但可以做為一個不錯的參考基準。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="對-AI-的態度不應過度樂觀，但也不必太悲觀"&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;a class="anchor-link" href="#對-AI-的態度不應過度樂觀，但也不必太悲觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;儘管我們已經清楚現代 AI 的威力，仍需注意 AI 並不是萬能藥，無法（完美地）解決或自動化所有人類的課題。&lt;/p&gt;
&lt;p&gt;比方說&lt;a href="https://demo.allennlp.org/atis-parser/NjMwMzQw/"&gt;有研究嘗試把自然語言轉成 SQL&lt;/a&gt;，但短期內一個資料科學家自己寫 SQL 查詢數據可能還是比較有效率。儘管 AI 不能（完美地）做到任何事情，我們也不該對 AI 失望，斷定下一個 AI 冬天必定會到來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/goldilocks-rule-for-ai.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        AI 的金髮女孩原理：對 AI 的態度不要過熱（樂觀），也不要過冷（悲觀），而是要剛剛好
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在可以肯定的是 AI 已經，而且也會繼續改變我們未來以及下一代的生活型態。&lt;/p&gt;
&lt;p&gt;最重要的是理性地理解 AI 能做到什麼，在能活用的時候善加利用它，同時不抱著「 AI 能解決所有問題」的不切實際幻想。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/goldilocks.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;小知識：著名格林童話故事「金髮女孩與三隻熊」，講述金髮小女孩走進了三隻熊的房子，她發現當中有三碗粥，一碗太熱，一碗太冷，最後她揀選了不冷不熱的第三碗。之後她又試了三張椅子及睡床，最後她揀選了最合適的小椅子及睡床坐下及睡覺。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AI-偏見難解，但或許比消除人類偏見簡單"&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;a class="anchor-link" href="#AI-偏見難解，但或許比消除人類偏見簡單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在利用監督式學習的方式訓練 AI 的時候，我們常常會使用現實世界的資料讓機器學習。&lt;/p&gt;
&lt;p&gt;好消息是因為現在數位化以及網際網路的發達，我們有非常多數據可以交給 AI 學習；壞消息是這些數據時常反映了人類數十年甚至幾個世紀的偏見。&lt;/p&gt;
&lt;p&gt;用這些數據訓練出來的 AI 系統就像是面照妖鏡，也會不可避免地學會這些偏見（Bias）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/ai-for-everyone/human-bias-to-technology.jpg"&gt;
&lt;source src="https://leemeng.tw/images/ai-for-everyone/human-bias-to-technology.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在我們將具有人類偏見的數據交給 AI 學習時，不可避免地會創造出具有偏見的系統
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;知名的例子有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以白人照片訓練出來的人臉辨識系統在辨識深色膚色的人種時表現很差&lt;/li&gt;
&lt;li&gt;自動化雇用的 AI 系統對女性存有偏見&lt;/li&gt;
&lt;li&gt;銀行的自動信用評比 AI 系統對某些族群產生偏見&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以下則是另一個課堂中提出的例子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ai-bias-word-embedding.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        讓 AI 從維基百科學習英文詞彙之間的統計關係後，發現 AI 認為「男人之於電腦工程師」的關係等於「女人之於家庭主婦」
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上例或許稱不上歧視，但很明顯是偏見，一種長久存在於人類社會的性別偏見。&lt;/p&gt;
&lt;p&gt;因為很多時候這些 AI 系統是學習一種統計關係，因此在此例中，AI 只是忠誠地呈現我們社會的用字習慣罷了。&lt;/p&gt;
&lt;p&gt;要消除 AI 的這些偏見並不容易，但仔細想想，這可能比消除人們腦中數十年的偏見要來的簡單，而且振奮人心。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/ai-for-everyone/remove-human-bias-from-technology.jpg"&gt;
&lt;source src="https://leemeng.tw/images/ai-for-everyone/remove-human-bias-from-technology.mp4" type="video/mp4"/&gt;
                    您的瀏覽器不支援影片標籤，請留言通知我：S
                &lt;/video&gt;
&lt;center&gt;
                        在享有強大 AI 科技的同時，我們希望最終也能將人類的偏見從這些 AI 系統中摒除
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這件事情當然不簡單，但卻非常值得一試。&lt;/p&gt;
&lt;p&gt;當然，你可以選擇不思考這些 AI 倫理、偏見問題，相信建立 AI 系統的這些工程師們立意良善以及夠細心，能幫我們將 AI 系統裡的偏見移除，並讓其做出最合適的判斷。&lt;/p&gt;
&lt;p&gt;儘管如此，意識到再厲害的 AI 系統內部也可能存在如同人類的偏見，進而導致各種不公平的社會問題這件事情也是很有幫助的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="擁抱-AI-的最好方法是將其與領域專業結合"&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;a class="anchor-link" href="#擁抱-AI-的最好方法是將其與領域專業結合"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;想要學習 AI，不需要打掉重練。&lt;/p&gt;
&lt;p&gt;雖然現在 AI 相關領域十分熱門，究其根本也就只是一種工具/技術。而且 AI 技術接下來會越來越平民化，上手的門檻會越來越低。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/rawpixel-633846-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此比起現在轉行當 AI 工程師，你要先做的應該是想辦法利用自己工作累積的領域知識（Domain Knowledge）以及洞見（Insight），找出能應用 AI 改善的地方，進而創造出專屬於你或企業的競爭優勢。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器學習和資料科學的產出分別是系統和洞見"&gt;機器學習和資料科學的產出分別是系統和洞見&lt;a class="anchor-link" href="#機器學習和資料科學的產出分別是系統和洞見"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;機器學習（&lt;strong&gt;M&lt;/strong&gt;achine &lt;strong&gt;L&lt;/strong&gt;earning, ML）以及資料科學（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cience, DS）這兩個詞彙常常結伴出現，且依照不同企業其定義都有所不同。因此，不在這塊領域裡的人常常不知道兩者的差異。&lt;/p&gt;
&lt;p&gt;一般來說，在企業內的 ML 專案大都分為 3 個階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集數據&lt;/li&gt;
&lt;li&gt;訓練模型&lt;/li&gt;
&lt;li&gt;部署模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ml-project-key-steps.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一般的 ML 專案的最終產物為機器學習模型，或是能夠持續運作的 AI 系統
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而 DS 專案的步驟則為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集數據&lt;/li&gt;
&lt;li&gt;分析數據&lt;/li&gt;
&lt;li&gt;建議行動/假說&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ds-project-key-steps.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一般的 DS 專案的最終產物為有用的假說或是洞見
                        （&lt;a href="https://www.coursera.org/learn/ai-for-everyone" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;兩者皆需原始數據做為輸入，且皆有機會使用 AI / ML 技術來解決、分析問題，但最終的產出形式時常不同。&lt;/p&gt;
&lt;p&gt;總結來說，ML 專案較注重在軟體工程方面，且最終希望產出一個以 AI 為基礎的線上系統；DS 專案的結果則可能是一份幫助經營者做重大投資決策的投影片報告。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/ml-vs-ds.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AI-時代，你得思考未來自己想要扮演的角色"&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;a class="anchor-link" href="#AI-時代，你得思考未來自己想要扮演的角色"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;AI 目前正是顯學，不少人決定進入這塊領域，而現在跟 AI 相關的職業就有好多種，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家&lt;/li&gt;
&lt;li&gt;機器學習工程師&lt;/li&gt;
&lt;li&gt;機器學習研究者&lt;/li&gt;
&lt;li&gt;軟體工程師&lt;/li&gt;
&lt;li&gt;資料工程師&lt;/li&gt;
&lt;li&gt;AI 專案管理人&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等。而且隨著 AI 的影響力持續擴大，未來可能還會出現新的相關職業。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/diablo-3-characters.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        AI 時代裡有各式各樣的相關職業，找尋最適合你的職業很重要
                        （&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這邊不會一一列出每個職業的工作內容，但忠實讀者會發現，事實上我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html"&gt;數據科學 MMORPG 上線！你，選好自己的角色了嗎？&lt;/a&gt;一文中就已經討論過類似的話題了。&lt;/p&gt;
&lt;p&gt;要踏入 AI 這塊領域，除了資料科學家以外，你還有很多選擇。思考你的強處以及興趣所在，選擇最適合的職業發揮所長是最理想的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="終身學習在這個年代前所未有地重要"&gt;終身學習在這個年代前所未有地重要&lt;a class="anchor-link" href="#終身學習在這個年代前所未有地重要"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;如同課程中吳恩達教授所說的，你並不需要取得一個 AI master 才能開始進行 AI 專案。很多時候利用&lt;a href="https://leemeng.tw/deep-learning-resources.html#xian%20shang%20ke%20cheng_1"&gt;線上課程&lt;/a&gt;或是&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;網路上的深度學習資源&lt;/a&gt;就可以開始你的第一個 AI 專案了。&lt;/p&gt;
&lt;p&gt;事實上，學習 &lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt; 這堂課就是一個不錯的開始。網路上也有很多優質的部落格或教學文章等待你的探索。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/le-tan-674393-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 領域近年發展神速，要學習 AI，用上一代「讀幾年書，出來用一輩子」的概念是行不通的。台大電機系的&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/"&gt;李宏毅教授&lt;/a&gt;就曾說過：「在深度學習的領域，超過五年就是遠古時代了」。&lt;/p&gt;
&lt;p&gt;因此如果你決定踏上學習 AI 的這條路，就做好跟我一起終身學習的心理準備吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;看到這裡，相信你已經了解 AI For Everyone 裡頭 10 個最重要的概念了，恭喜！&lt;/p&gt;
&lt;p&gt;這些概念大多是我將課程裡頭擷取出的核心概念，佐以自己從事資料科學家以來的心得感想。希望閱讀完此文的你有學到點東西，或是獲得些啟發。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/ai-for-everyone/fabrizio-magoni-219347-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        課堂內容是主菜，我的個人心得是調味料，希望你喜歡這道菜，並分享給朋友知道
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了幫助你回憶，現在讓我再次將本文提到的概念一一列出：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;講到 AI，我們通常是指狹義的 AI 而非終結者&lt;/li&gt;
&lt;li&gt;多數 AI 應用是讓機器學會一個對應關係&lt;/li&gt;
&lt;li&gt;大數據、神經網路及運算能力是 AI 成功關鍵&lt;/li&gt;
&lt;li&gt;只需花費你 1 秒的任務，大都可由 AI 自動化&lt;/li&gt;
&lt;li&gt;對 AI 的態度不應過度樂觀，但也不必太悲觀&lt;/li&gt;
&lt;li&gt;AI 偏見難解，但或許比消除人類偏見簡單&lt;/li&gt;
&lt;li&gt;擁抱 AI 的最好方法是將其與領域專業結合&lt;/li&gt;
&lt;li&gt;機器學習和資料科學的產出分別是系統和洞見&lt;/li&gt;
&lt;li&gt;AI 時代，你得思考未來自己想要扮演的角色&lt;/li&gt;
&lt;li&gt;終身學習在這個年代前所未有地重要&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 當然有其侷限性，但只要你能找出應用它的任務，就能將其轉換成你的超能力，可能性無窮大。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟隨完我的思路歷程，現在輪到你動腦回答下面問題了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你有什麼個人或是企業的課題，是可以透過 AI 改善或是提升價值的呢？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="人工智慧"></category><category term="資料科學"></category><category term="機器學習"></category></entry><entry><title>由淺入深的深度學習資源整理</title><link href="https://leemeng.tw/deep-learning-resources.html" rel="alternate"></link><published>2019-01-08T08:00:00+09:00</published><updated>2019-01-08T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2019-01-08:/deep-learning-resources.html</id><summary type="html">&lt;p&gt;這裡紀錄了我在學習深度學習時蒐集的一些線上資源。內容由淺入深，而且會一直被更新，希望能幫助你順利地開始學習：）&lt;/p&gt;</summary><content type="html">&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                            不聞不若聞之，聞之不若見之，見之不若知之，知之不若行之，學至於行之而止矣。
                            &lt;br/&gt;
&lt;span style="float:right"&gt;── 《荀子．儒效》&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem"&gt;
&lt;p&gt;
        這段話翻成白話文就是「沒聽過比不上聽過；聽過比不上實際看過；看過則比不上實際了解；而了解又不如動手實踐。唯有身體力行才能真正地學到東西。」
    &lt;/p&gt;
&lt;p&gt;
        這句古老的諺語向我們傳達了「實踐」的重要以及學習的幾個過程。
    &lt;/p&gt;
&lt;p&gt;
        做為一門學問，&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" target="_blank"&gt;深度學習&lt;/a&gt;也是同樣道理。
        僅說自己對深度學習有興趣或是有關注（聞、見），但卻沒有實際花時間去深入了解或實際應用（知、行）是無法真正學會深度學習的。
    &lt;/p&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="/images/patrick-tomasso-71909-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
        雖說如此，不了解深度學習能拿來做什麼的人或許還不少。
    &lt;/p&gt;
&lt;p&gt;
        我嘗試將自己在學習過程中蒐集到的重要資源由淺入深地做些整理。
        希望透過此文，能讓在各個學習階段的你都能從這裡獲得些什麼，並實際動手學習、探索發展快速的深度學習世界。
    &lt;/p&gt;
&lt;p&gt;
        本文內容會持續被更新，你可以定期回來看看或是關注這個 
        &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank"&gt;Github Repo&lt;/a&gt;。
    &lt;/p&gt;
&lt;/div&gt;
&lt;div align="center"&gt;
&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/general/paper-ball.jpg"/&gt;
&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;這裡紀錄了我在學習&lt;a href="https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;時蒐集的一些線上資源。內容由淺入深，而且會不斷更新，希望能幫助你順利地開始學習：）&lt;/p&gt;
&lt;h2 id="ben wen zhang jie"&gt;本文章節&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#playground"&gt;遊玩空間&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#courses"&gt;線上課程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tools"&gt;實用工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tutorials"&gt;其他教材&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#blogs"&gt;優質文章&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#papers"&gt;經典論文&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#collections"&gt;其他整理&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="you wan kong jian"&gt;&lt;div id="playground"&gt;遊玩空間&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這節列舉了一些透過瀏覽器就能馬上開始遊玩 / 體驗深度學習的應用。作為這些應用的使用者，你可以先高層次、直觀地了解深度學習能做些什麼。之後有興趣再進一步了解背後原理。&lt;/p&gt;
&lt;p&gt;這小節最適合：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想要快速體會深度學習如何被應用在真實世界的好奇寶寶&lt;/li&gt;
&lt;li&gt;想要直觀理解&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;類神經網路（Artifical Neural Network）&lt;/a&gt;運作方式的人&lt;/li&gt;
&lt;li&gt;想從別人的深度學習應用取得一些靈感的開發者&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;Deep Playground&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html"&gt;ConvNetJS&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/deep-playground.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/index.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/convnetjs.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="deep playground"&gt;&lt;a href="https://playground.tensorflow.org/"&gt;Deep Playground&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 &lt;a href="https://github.com/tensorflow/playground"&gt;Tensorflow 團隊&lt;/a&gt;推出，模擬訓練一個類神經網路的過程並了解其運作原理&lt;/li&gt;
&lt;li&gt;可以搭配這篇 &lt;a href="https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises"&gt;Introduction to Neural Networks: Playground Exercises&lt;/a&gt; 學習&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="convnetjs"&gt;&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/"&gt;ConvNetJS&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;訓練類神經網路來解決經典的 &lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html"&gt;MNIST 手寫數字辨識問題&lt;/a&gt;、&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/image_regression.html"&gt;圖片生成&lt;/a&gt;以及&lt;a href="https://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html"&gt;增強式學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;由 Tesla 的 AI 負責人 &lt;a href="https://cs.stanford.edu/people/karpathy/"&gt;Andrej Karpathy&lt;/a&gt; 建立&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;Magenta&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;Google AI Experiments&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/magenta.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/google-ai-experiment.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="magenta"&gt;&lt;a href="https://magenta.tensorflow.org/"&gt;Magenta&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個利用&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;來協助人們進行音樂以及藝術創作的開源專案&lt;/li&gt;
&lt;li&gt;可以在網站上的 &lt;a href="https://magenta.tensorflow.org/demos"&gt;Demo 頁面&lt;/a&gt;嘗試各種由深度學習驅動的音樂 / 繪畫應用（如彈奏鋼琴、擊鼓）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="google ai experiments"&gt;&lt;a href="https://experiments.withgoogle.com/collection/ai"&gt;Google AI Experiments&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;這邊展示了接近 40 個利用圖片、語言以及音樂來與使用者產生互動的機器學習 Apps，值得慢慢探索&lt;/li&gt;
&lt;li&gt;知名例子有 &lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt; 以及 &lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;，將在下方介紹&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/quickdraw.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/teachable-machine.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="quick draw"&gt;&lt;a href="https://quickdraw.withgoogle.com/"&gt;Quick Draw&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 Google 推出的知名手寫塗鴉辨識，使用的神經網路架構有常見的&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;卷積神經網路 CNN &lt;/a&gt;以及&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E6%9C%89%E8%A8%98%E6%86%B6%E7%9A%84%E5%BE%AA%E7%92%B0%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF_1"&gt;循環神經網路 RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;該深度學習模型會不斷將最新的筆觸當作輸入來預測使用者想畫的物件。你會驚嘆於她精準且即時的判斷&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="teachable machine"&gt;&lt;a href="https://teachablemachine.withgoogle.com/"&gt;Teachable Machine&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;利用電腦 / 手機上的相機來訓練能將影像對應到其他圖片、音訊的神經網路，饒富趣味&lt;/li&gt;
&lt;li&gt;透過這例子，你將暸解機器學習的神奇之處以及其侷限所在&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;Fast Neural Style&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/fast-neural-style.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://js.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/human-pose-estimation.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="fast neural style"&gt;&lt;a href="https://tenso.rs/demos/fast-neural-style/"&gt;Fast Neural Style&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;展示如何使用 WebGL 在瀏覽器快速地進行&lt;a href="https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398"&gt;神經風格轉換 Neural Style Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;你可以選擇任何一張圖片，並在此網站上將其畫風轉變成指定的藝術照&lt;/li&gt;
&lt;li&gt;&lt;a href="https://deepart.io/"&gt;Deepart.io&lt;/a&gt; 也提供類似服務&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="tensorflow.js"&gt;&lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TensorFlow.js 頁面有多個利用 JavaScript 實現的深度學習應用，如上圖中的&lt;a href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5"&gt;人類姿勢估計 Human Pose Estimation&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;你可以在該應用裡頭打開自己的攝影機，看該應用能不能偵測到你與朋友的姿勢。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://talktotransformer.com/"&gt;Talk to Transformer&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/gan-lab.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://talktotransformer.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/playground/talk_to_transformer.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="gan lab"&gt;&lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN Lab&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"&gt;對抗生成網路（&lt;strong&gt;G&lt;/strong&gt;enerative &lt;strong&gt;A&lt;/strong&gt;dversarial &lt;strong&gt;N&lt;/strong&gt;etwork，簡稱GAN）&lt;/a&gt;是非監督式學習的一種方法，通過讓兩個神經網路相互博弈的方式進行學習。此網站以 &lt;a href="https://js.tensorflow.org/"&gt;TensorFlow.js&lt;/a&gt; 實作 GAN 中兩個神經網路的學習過程，幫助有興趣的你更直觀地理解神奇的 GAN 的運作方式&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="talk to transformer"&gt;&lt;a href="https://talktotransformer.com/"&gt;Talk to Transformer&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;展示了一個由 OpenAI 推出，名為 &lt;a href="https://openai.com/blog/better-language-models/"&gt;GPT-2 的無監督式語言模型&lt;/a&gt;。該模型以 Google 發表的神經網路架構 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Transformer&lt;/a&gt; 為基底，在給定一段魔戒或是復仇者聯盟的文字內容，該模型可以自己生成唯妙唯俏的延伸劇情。&lt;/li&gt;
&lt;li&gt;想要進一步瞭解何謂 Transformer，推薦閱讀 &lt;a href="http://jalammar.github.io/illustrated-transformer/"&gt;The Illustrated Transformer&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;你也可以參考&lt;a href="https://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html"&gt;讓 AI 寫點金庸：如何用 TensorFlow 2.0 及 TensorFlow.js 寫天龍八部&lt;/a&gt;來看如何使用 LSTM 達到類似的文本生成效果&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="xian shang ke cheng_1"&gt;&lt;div id="courses"&gt;線上課程&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;看完&lt;a href="#playground"&gt;遊玩空間&lt;/a&gt;的大量實際應用，相信你已經迫不及待地想要開始學習強大的深度學習技術了。&lt;/p&gt;
&lt;p&gt;這節列舉了一些有用的線上課程以及學習教材，幫助你掌握深度學習的基本知識（沒有特別註明的話皆為免費存取）。&lt;/p&gt;
&lt;p&gt;另外值得一提的是，大部分課程都要求一定程度的 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 程式能力。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;李宏毅教授的機器學習 / 深度學習課程&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning Specialization @ Coursera&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/Hung-Yi-Lee-ml-courses.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/deep-learning-specification-coursera.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="li hong yi jiao shou de ji qi xue xi  / shen du xue xi ke cheng"&gt;&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html"&gt;李宏毅教授的機器學習 / 深度學習課程&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;大概是全世界最好、最完整的 Deep Learning &lt;b&gt;中文&lt;/b&gt;學習資源。&lt;/li&gt;
&lt;li&gt;影片內容涵蓋基本理論（約 10 小時觀看時間）一直到進階的&lt;a href="https://zh.wikipedia.org/wiki/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C"&gt;生成對抗網路 GAN&lt;/a&gt; 以及&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"&gt;強化學習 RL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;你也可以從&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists"&gt;這邊&lt;/a&gt;看到教授的 Youtube 課程清單&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning specialization @ coursera"&gt;&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning Specialization @ Coursera&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;原 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授開授的整個深度學習專項課程共分五堂課，從&lt;a href="https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning"&gt;神經網路的基礎&lt;/a&gt;到能夠進行機器翻譯、語音辨識的&lt;a href="https://www.coursera.org/learn/nlp-sequence-models"&gt;序列模型&lt;/a&gt;，每堂課預計 1 個月完成，收費採訂閱制&lt;/li&gt;
&lt;li&gt;程式作業會交互使用 &lt;a href="http://www.numpy.org/"&gt;Numpy&lt;/a&gt;、&lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 以及 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt; 來實作深度學習模型&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;Practical Deep Learning For Coders @ fast.ai&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;Deep Learning @ Kaggle Learn&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/fast-ai.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/kaggle-learn-dl.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="practical deep learning for coders @ fast.ai"&gt;&lt;a href="https://course.fast.ai/index.html"&gt;Practical Deep Learning For Coders @ fast.ai&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;7 週課程，一週約需安排 10 小時上課。該課程由&lt;a href="https://www.kaggle.com/jhoward"&gt;傑里米&amp;middot;霍華德&lt;/a&gt;來講解深度學習，其在知名數據建模和數據分析競賽平台 &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 維持兩年的世界第一&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning @ kaggle learn"&gt;&lt;a href="https://www.kaggle.com/learn/deep-learning"&gt;Deep Learning @ Kaggle Learn&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;14 堂課程，主要使用 TensorFlow 實作深度學習模型&lt;/li&gt;
&lt;li&gt;內容主要專注在&lt;a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"&gt;電腦視覺（Computer Vision）&lt;/a&gt;以及如何應用&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習（Transfer Learning）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://www.elementsofai.com/"&gt;Elements of Artificial Intelligence&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://deeplearning.mit.edu/"&gt;MIT Deep Learning&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://www.elementsofai.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/elementsofai.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/mlt-deep-learning.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="elements of artificial intelligence"&gt;&lt;a href="https://www.elementsofai.com/"&gt;Elements of Artificial Intelligence&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;芬蘭最高學府&lt;a href="https://zh.wikipedia.org/wiki/%E8%B5%AB%E5%B0%94%E8%BE%9B%E5%9F%BA%E5%A4%A7%E5%AD%A6"&gt;赫爾辛基大學&lt;/a&gt;推出的 AI 課程。此課程目的在於讓所有人都能了解 AI，不需要任何程式經驗。這堂課非常適合完全沒有接觸過深度學習或是相關領域的人&lt;/li&gt;
&lt;li&gt;課程分 6 個部分，包含「何謂 AI ？」、「真實世界的 AI」、「機器學習」以及「神經網路」等章節&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="mit deep learning"&gt;&lt;a href="https://deeplearning.mit.edu/"&gt;MIT Deep Learning&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;麻省理工學院推出的深度學習課程，內容包含深度學習基礎、深度強化學習以及自動駕駛相關知識。&lt;a href="https://github.com/lexfridman/mit-deep-learning"&gt;Github Repo&lt;/a&gt; 包含了多個教學筆記本，值得參考&lt;/li&gt;
&lt;li&gt;上圖是 &lt;a href="https://selfdrivingcars.mit.edu/deeptraffic/"&gt;DeepTraffic&lt;/a&gt;，由 MIT 的研究科學家 &lt;a href="https://lexfridman.com/"&gt;Lex Fridman&lt;/a&gt; 推出的一個深度強化學習競賽。此競賽目標是建立一個可以在高速公路上駕駛汽車的神經網路。你可以在&lt;a href="https://selfdrivingcars.mit.edu/deeptraffic/"&gt;這裡&lt;/a&gt;看到線上 Demo 以及詳細說明&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://introtodeeplearning.com"&gt;6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://introtodeeplearning.com"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/intro-to-deeplearning-mit.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/courses/ai-for-everyone.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="6.s191: introduction to deep learning"&gt;&lt;a href="http://introtodeeplearning.com"&gt;6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;麻省理工學院推出的另一堂基礎深度學習課程，介紹深度學習以及其應用。內容涵蓋機器翻譯、圖像辨識以及更多其他應用。此課程使用 Python 以及 TensorFlow 來實作作業，並預期學生具備基礎的微積分（梯度 &amp;amp; Chain Rule）以及線性代數（矩陣相乘）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="ai for everyone"&gt;&lt;a href="https://www.coursera.org/learn/ai-for-everyone"&gt;AI For Everyone&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Coursera 課程。&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;教授在這堂簡短的課程裡頭，針對非技術人士以及企業經理人說明何謂 AI、如何建立 AI 專案以及闡述 AI 與社會的關係。此課程十分適合沒有技術背景的讀者。&lt;a href="https://leemeng.tw/10-key-takeaways-from-ai-for-everyone-course.html"&gt;從 AI For Everyone 學到的 10 個重要 AI 概念&lt;/a&gt;則是我個人上完課後整理的心得分享。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="shi yong gong ju_1"&gt;&lt;div id="tools"&gt;實用工具&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這節列出一些在你的深度學習路上可以幫得上些忙的工具。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;TensorBoard&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/colab.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/tensorboard.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="colaboratory"&gt;&lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;由 Google 提供的雲端 &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; 筆記本環境，讓你只要用瀏覽器就能馬上開始訓練深度學習模型。你甚至還可以使用一個免費的 &lt;a href="https://www.nvidia.com/en-gb/data-center/tesla-k80/"&gt;Tesla K80&lt;/a&gt; GPU 或 &lt;a href="https://colab.research.google.com/notebooks/tpu.ipynb"&gt;TPU&lt;/a&gt; 來加速訓練自己的模型&lt;/li&gt;
&lt;li&gt;該計算環境也能與自己的 &lt;a href="https://colab.research.google.com/notebooks/io.ipynb"&gt;Google Drive&lt;/a&gt; 做連結，讓運算雲端化的同時將筆記本 / 模型結果都同步到自己的筆電上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="tensorboard"&gt;&lt;a href="https://www.tensorflow.org/guide/summaries_and_tensorboard"&gt;TensorBoard&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;TensorBoard 是一個視覺化工具，方便我們了解、除錯並最佳化自己訓練的深度學習模型&lt;/li&gt;
&lt;li&gt;除了 TensorFlow 以外，其他基於 Python 的機器學習框架大多也可以透過 &lt;a href="https://github.com/lanpa/tensorboardX"&gt;tensorboardX&lt;/a&gt; 來使用 TensorBoard&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;Lucid&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/embedding-projector.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/lucid.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="embedding projector"&gt;&lt;a href="https://projector.tensorflow.org/"&gt;Embedding Projector&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;我們時常需要將圖片、文字轉成&lt;a href="https://en.wikipedia.org/wiki/Tensor"&gt;高維數字向量 Embedding&lt;/a&gt; 以供神經網路處理，而 Projector 能將此高維向量投影到 2、3 維空間上方便我們理解這些數據&lt;/li&gt;
&lt;li&gt;Projector 網站讓你在線上探索幾個常見的資料集，但事實上你也可以&lt;a href="https://www.tensorflow.org/guide/embedding"&gt;利用 Tensorboard 來視覺化自己的數據&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="lucid"&gt;&lt;a href="https://github.com/tensorflow/lucid"&gt;Lucid&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Lucid 是一個嘗試讓神經網路變得更容易解釋的開源專案，裡頭包含了很多視覺化神經網路的筆記本&lt;/li&gt;
&lt;li&gt;你可以直接在 Colab 上執行這些筆記本並了解如何視覺化神經網路&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://paperswithcode.com/"&gt;Papers with Code&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;What-If Tool&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://paperswithcode.com/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/papers-with-code.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/what-if-tool.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="papers with code"&gt;&lt;a href="https://paperswithcode.com/"&gt;Papers with Code&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;將機器學習的學術論文、程式碼實作以及 SOTA 的評價排行榜全部整理匯總在一起的網站，非常適合想要持續追蹤學術及業界最新研究趨勢的人&lt;/li&gt;
&lt;li&gt;在這邊可以瀏覽包含電腦視覺、自然語言處理等各大領域在不同任務上表現最好的論文、實作以及資料集&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="what-if tool"&gt;&lt;a href="https://pair-code.github.io/what-if-tool/"&gt;What-If Tool&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個與 &lt;a href="#tensorboard"&gt;TensorBoard&lt;/a&gt; 以及 Jupyter Notebook 整合的探索工具，讓使用者不需寫程式碼就能輕鬆觀察機器學習模型的內部運作以及嘗試各種 What-if 問題（如果 ~ 會怎麼樣？）&lt;/li&gt;
&lt;li&gt;基本上就是用來觀察&lt;strong&gt;已訓練&lt;/strong&gt;的模型在測試資料集上的表現。利用此工具，使用者可以了解（不僅限於）以下的問題：模型在各類別數據上的表現有無差距？模型是否存在偏見？應該如何調整 Native / Positive False 的比例？&lt;/li&gt;
&lt;li&gt;此工具的一大亮點在於讓非專業領域人士也能探索、理解 ML 模型表現。且只要給定模型與資料集, 就不需要每次為了 What-if 問題就寫用過即丟的程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="qi ta jiao cai_1"&gt;&lt;div id="tutorials"&gt;其他教材&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;除了&lt;a href="#courses"&gt;線上課程&lt;/a&gt;以外，網路上還有無數的學習資源。&lt;/p&gt;
&lt;p&gt;這邊列出一些推薦的深度學習教材，大多數皆以數據科學家常用的 &lt;a href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt; 筆記本的方式呈現。&lt;/p&gt;
&lt;p&gt;你可以將感興趣的筆記本導入&lt;a href="#tools"&gt;實用工具&lt;/a&gt;裡提到的 &lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Colaboratory（Colab）&lt;/a&gt;，馬上開始學習。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;Seedbank&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;Deep Learning with Python&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/seedbank.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/fchollet-deep-learning-with-python.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="seedbank"&gt;&lt;a href="https://research.google.com/seedbank/"&gt;Seedbank&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;讓你可以一覽 Colab 上超過 100 個跟機器學習相關的筆記本，並以此為基礎建立各種深度學習應用&lt;/li&gt;
&lt;li&gt;熱門筆記本包含&lt;a href="https://research.google.com/seedbank/seed/5695159920492544"&gt;神經機器翻譯&lt;/a&gt;、&lt;a href="https://research.google.com/seedbank/seed/5681034041491456"&gt;音樂生成&lt;/a&gt;以及 &lt;a href="https://research.google.com/seedbank/seed/5631986051842048"&gt;DeepDream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;因為是 Google 服務，筆記本大多使用 TensorFlow 與 Keras 來實現模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="deep learning with python"&gt;&lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;Deep Learning with Python&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 作者 &lt;a href="https://ai.google/research/people/105096"&gt;Fran&amp;ccedil;ois Chollet&lt;/a&gt; 在 &lt;a href="https://www.amazon.com/Deep-Learning-Python-Francois-Chollet/dp/1617294438"&gt;Deep Learning with Python&lt;/a&gt; 一書中用到的所有筆記本。每個筆記本裡頭都清楚地介紹該如何使用 Keras 來實現各種深度學習模型，十分適合第一次使用 Python 實現深度學習的讀者 &lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#top"&gt;進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南&lt;/a&gt;一文的 Keras 程式碼大多基於此&lt;/li&gt;
&lt;li&gt;繁體中文的翻譯書籍則為 &lt;a href="https://www.tenlong.com.tw/products/9789863125501?list_name=i-r-zh_tw"&gt;Deep learning 深度學習必讀 - Keras 大神帶你用 Python 實作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Keras 在 TensorFlow 2.0 中&lt;a href="https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a"&gt;為其最重要的高層次 API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;Stanford CS230 Cheatsheets&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;practicalAI&lt;/a&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/cs230-deep-learning-cheatsheet.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tutorials/practical-ai-pytorch.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="stanford cs230 cheatsheets"&gt;&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;Stanford CS230 Cheatsheets&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;史丹佛大學的&lt;a href="http://cs230.stanford.edu/"&gt;深度學習課程 CS230&lt;/a&gt; 釋出的深度學習小抄總結了目前最新的&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"&gt;卷積神經網路&lt;/a&gt;及&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks"&gt;循環神經網路&lt;/a&gt;知識，還包含了&lt;a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks"&gt;訓練深度學習時需要使用到的技巧&lt;/a&gt;，十分強大&lt;/li&gt;
&lt;li&gt;此小抄最適合已經熟悉基礎知識的同學隨時複習運用。你也可以從他們的 &lt;a href="https://github.com/afshinea/stanford-cs-230-deep-learning"&gt;Github Repo&lt;/a&gt; 下載包含上述所有內容的&lt;a href="https://github.com/afshinea/stanford-cs-230-deep-learning/blob/master/en/super-cheatsheet-deep-learning.pdf"&gt;超級 VIP 小抄&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;除了深度學習以外，你也可以查看 &lt;a href="https://stanford.edu/~shervine/teaching/cs-229.html"&gt;CS229 機器學習課程的小抄&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="practicalai"&gt;&lt;a href="https://github.com/GokuMohandas/practicalAI"&gt;practicalAI&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 Github 上超過 1 萬星的 Repo。除了深度學習，也有介紹 &lt;a href="https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/01_Python.ipynb"&gt;Python 基礎&lt;/a&gt;及 &lt;a href="https://colab.research.google.com/github/GokuMohandas/practicalAI/blob/master/notebooks/03_Pandas.ipynb"&gt;Pandas&lt;/a&gt; 的使用方式&lt;/li&gt;
&lt;li&gt;使用 &lt;a href="https://pytorch.org/"&gt;Pytorch&lt;/a&gt; 框架來實現深度學習模型，且所有內容都是 Jupyter 筆記本，可以讓你在 Colab 或本地端執行&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;&lt;a href="http://demo.allennlp.org/"&gt;AllenNLP Demo&lt;/a&gt;&lt;/th&gt;
&lt;th align="center"&gt;To Be Updated&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;&lt;a href="http://demo.allennlp.org/"&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/tools/allennlp-demo.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td align="center"&gt;&lt;a href=""&gt;&lt;img src="https://github.com/leemengtaiwan/deep-learning-resources/raw/master/images/general/to-be-updated.jpg"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id="allennlp demo"&gt;&lt;a href="http://demo.allennlp.org/"&gt;AllenNLP Demo&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;清楚地展示了如&lt;a href="https://demo.allennlp.org/machine-comprehension"&gt;機器理解&lt;/a&gt;、&lt;a href="https://demo.allennlp.org/named-entity-recognition"&gt;命名實體識別&lt;/a&gt;等多個自然語言處理任務的情境。每個任務的情境包含了任務所需要的輸入、SOTA 模型的預測結果以及模型內部的注意力機制，對理解一個 NLP 任務的實際應用情境有很大幫助&lt;/li&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/"&gt;AllenNLP&lt;/a&gt; 是一個由 &lt;a href="https://allenai.org/"&gt;AI2&lt;/a&gt; 以 &lt;a href="https://pytorch.org/"&gt;PyTorch&lt;/a&gt; 實現的自然語言處理函式庫&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="you zhi wen zhang_1"&gt;&lt;div id="blogs"&gt;優質文章&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊列舉了一些幫助我釐清重要概念的部落格以及網站，希望能加速你探索這個深度學習世界。&lt;/p&gt;
&lt;p&gt;只要 Google 一下就能發現這些部落格裡頭很多文章都有中文翻譯。但為了尊重原作者，在這邊都列出原文連結。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://distill.pub/about/"&gt;Distill&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;用非常高水準且互動的方式來說明複雜的深度學習概念。&lt;a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html"&gt;Yoshua Bengio&lt;/a&gt;、&lt;a href="http://www.iangoodfellow.com/"&gt;Ian Goodfellow&lt;/a&gt; 及 &lt;a href="http://cs.stanford.edu/people/karpathy/"&gt;Andrej Karpathy&lt;/a&gt; 等知名人士皆參與其中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.r2d3.us/%E5%9C%96%E8%A7%A3%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E7%AC%AC%E4%B8%80%E7%AB%A0/"&gt;R2D3: 圖解機器學習&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;利用非常直覺易懂的視覺化來說明機器學習，連結為中文版&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/"&gt;Christopher Olah's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;詳細解釋不少深度學習概念。作者在&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;這篇&lt;/a&gt;就詳細地解釋了&lt;a href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html#%E8%A8%98%E6%86%B6%E5%8A%9B%E5%A5%BD%E7%9A%84-LSTM-%E7%B4%B0%E8%83%9E"&gt;長短期記憶 LSTM&lt;/a&gt; 的概念與變形；在&lt;a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/"&gt;這篇&lt;/a&gt;則解釋何為 CNN 的卷積運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jalammar.github.io/"&gt;Jay Alammar's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;以清楚易懂的視覺化解釋深度學習概念。&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"&gt;這篇&lt;/a&gt;用大量易懂的動畫說明&lt;a href="https://en.wikipedia.org/wiki/Neural_machine_translation"&gt;神經機器翻譯&lt;/a&gt;，而在&lt;a href="https://jalammar.github.io/illustrated-bert/"&gt;這篇&lt;/a&gt;則介紹如何利用如 &lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt;、&lt;a href="https://github.com/google-research/bert"&gt;BERT&lt;/a&gt; 等預先訓練過的強大模型在自然語言處理進行&lt;a href="https://en.wikipedia.org/wiki/Transfer_learning"&gt;遷移學習&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://karpathy.github.io/"&gt;Andrej Karpathy's blog&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;現為 Tesla AI 負責人的 Andrej Karpathy 在&lt;a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/"&gt;這篇&lt;/a&gt;明確說明何謂循環神經網路 RNN。文中提供不少應用實例及視覺化來幫助我們理解 RNN 模型究竟學到了什麼，是學習 RNN 的朋友幾乎一定會碰到的一篇文章&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="jing dian lun wen"&gt;&lt;div id="papers"&gt;經典論文&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊依發表時間列出深度學習領域的經典 / 重要論文。&lt;/p&gt;
&lt;p&gt;為了幫助你快速掌握論文內容以及歷年的研究趨勢，每篇論文下會有非常簡短的介紹（WIP）。&lt;/p&gt;
&lt;p&gt;但我們推薦有興趣的人自行閱讀論文以深入了解。&lt;/p&gt;
&lt;h3 id="zi ran yu yan chu li  natural language processing (nlp)"&gt;自然語言處理 Natural Language Processing (NLP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf"&gt;2003/02 A Neural Probabilistic Language Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1301.3781"&gt;2013/01 Efficient Estimation of Word Representations in Vector Space&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1308.0850"&gt;2013/08 Generating Sequences With Recurrent Neural Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.0473"&gt;2014/09 Neural Machine Translation by Jointly Learning to Align and Translate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1508.04025"&gt;2015/08 Effective Approaches to Attention-based Neural Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1511.01432"&gt;2015/12 Semi-supervised Sequence Learning&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;推出一套無監督式的預訓練方法。使用無標籤數據訓練後的 RNN 模型在之後的監督式任務表現更好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.03762"&gt;2017/06 Attention Is All You Need&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Google 推出新的神經網路架構 &lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Transformer&lt;/a&gt;。這個基於自注意力機制的架構特別適合語言理解任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.05137"&gt;2017/06 One Model To Learn Them All&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1801.06146"&gt;2018/01 Universal Language Model Fine-tuning for Text Classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1802.05365"&gt;2018/02 Deep contextualized word representations&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/elmo"&gt;ELMo 詞向量&lt;/a&gt;，利用兩獨立訓練的 LSTM 獲取雙向訊息&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf"&gt;2018/06 Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.openai.com/language-unsupervised/"&gt;OpenAI&lt;/a&gt; 利用無監督式預訓練以及 Transformer 架構訓練出來的模型表現在多個 NLP 任務表現良好。約使用 8 億詞彙量的資料集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;2018/10 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;Google 暴力美學。利用深層 Transformer 架構、2 個精心設計的預訓練任務以及約 33 億詞彙量的資料集訓練後，得到表現卓越的語言代表模型，打破 11 項 NLP 任務紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="dian nao shi jue  computer vision (cv)"&gt;電腦視覺 Computer Vision (CV)&lt;/h3&gt;
&lt;h4 id="lei shen jing wang lu jia gou  neural network architecture"&gt;類神經網路架構 Neural Network Architecture&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"&gt;1998/01 Gradient-Based Learning Applied to Document Recognition (LeNet-5)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"&gt;2012/12 ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.cs.toronto.edu/~ranzato/publications/taigman_cvpr14.pdf"&gt;2014/06 DeepFace: Closing the Gap to Human-Level Performance in Face Verification (DeepFace)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.1556"&gt;2014/09 Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1409.4842"&gt;2014/09 Goint deeper with convolutions (GoogLeNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1411.4038"&gt;2014/11 Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1505.04597"&gt;2015/05 U-Net: Convolutional Networks for Biomedical Image Segmentation (U-Net)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1512.03385"&gt;2015/12 Deep Residual Learning for Image Recognition (ResNet)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1704.04861"&gt;2017/04 MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (MobileNets)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1707.01083"&gt;2017/07 ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices (ShuffleNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="zi liao ji  dataset"&gt;資料集 Dataset&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.image-net.org/papers/imagenet_cvpr09.pdf"&gt;2009/06 ImageNet: A Large-Scale Hierarchical Image Database (ImageNet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="wu ti zhen ce yu qie ge  object detection and segmentation"&gt;物體偵測與切割 Object Detection and Segmentation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1311.2524"&gt;2013/11 Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1312.6229"&gt;2013/12 OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks (OverFeat)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1504.08083"&gt;2015/04 Fast R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1506.01497"&gt;2015/06 Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Faster R-CNN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1506.02640"&gt;2015/06 You Only Look Once: Unified, Real-Time Object Detection (YOLO)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1512.02325"&gt;2015/12 SSD: Single Shot MultiBox Detector (SSD)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1612.08242"&gt;2016/12 YOLO9000: Better, Faster, Stronger (YOLOv2)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1703.06870"&gt;2017/03 Mask R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.02767"&gt;2018/04 YOLOv3: An Incremental Improvement (YOLOv3)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="sheng cheng mo xing  generative models"&gt;生成模型 Generative Models&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1406.2661"&gt;2014/06 Generative Adversarial Networks (GAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1511.06434"&gt;2015/13 Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1701.07875"&gt;2017/01 Wasserstein GAN (WGAN)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1703.10593"&gt;2017/03 Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="qi ta zheng li_2"&gt;&lt;div id="collections"&gt;其他整理&lt;/div&gt;&lt;/h2&gt;
&lt;p&gt;這邊列出其他優質的資源整理網站 / Github Repo，供你繼續探索深度學習。&lt;/p&gt;
&lt;h3 id="deep-learning-ocean"&gt;&lt;a href="https://github.com/osforscience/deep-learning-ocean"&gt;deep-learning-ocean&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;整理了不少深度學習資源，但最值得參考的是數據集以及論文的分類整理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dai ban shi xiang_1"&gt;待辦事項&lt;/h2&gt;
&lt;p&gt;還有不少內容正在整理，以下是目前我們打算增加的一些項目：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;深度學習中英術語對照表&lt;/li&gt;
&lt;li&gt;值得追蹤的業界 / 學界影響人物清單&lt;/li&gt;
&lt;li&gt;無圖的資源列表版本&lt;/li&gt;
&lt;li&gt;一些 Jupyter Notebook 範例&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而我們也會持續將新資源加入如&lt;a href="#tools"&gt;實用工具&lt;/a&gt;、&lt;a href="#blogs"&gt;優質文章&lt;/a&gt;等列表裡頭。&lt;/p&gt;
&lt;h2 id="ru he gong xian"&gt;如何貢獻&lt;/h2&gt;
&lt;p&gt;非常歡迎你一起加入改善這個 Repo，讓更多人有方向地學習 Deep Learning：）&lt;/p&gt;
&lt;p&gt;如果你有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其他值得推薦的深度學習資源&lt;/li&gt;
&lt;li&gt;針對此 Repo 內容的改善建議&lt;/li&gt;
&lt;li&gt;其他任何你想得到的東西&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都歡迎你&lt;a href="https://github.com/leemengtaiwan/deep-learning-resources/issues/new"&gt;提出新的 Issue&lt;/a&gt; 來讓我們知道。&lt;/p&gt;
&lt;p&gt;如果是想增加新資源的話，只附上連結也是沒有問題的，謝謝！
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 2rem"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="/images/general/maxwell-ridgeway-685077-unsplash.jpg"&gt;
&lt;br/&gt;
&lt;/img&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
        最後，如果你覺得本文實用，還請幫我分享此文並給 &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources" target="_blank"&gt;Github Repo&lt;/a&gt; 一個小星星。
        這樣可以讓更多人注意到這些寶貴資源的存在並開始有方向的學習，謝謝！
    &lt;/p&gt;
&lt;p&gt;
        有再多資源，沒有親自動手做都是無法真正地學到東西的。因此，最後的最後讓我再次強調主動學習的重要：
    &lt;/p&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                            告訴我資訊，我只會忘記；教導我知識，我會記得；讓我實際參與，我將能真正地學到東西。
                            &lt;br/&gt;
&lt;span style="float:right"&gt;── 班傑明&amp;middot;富蘭克林&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered" style="margin-top: 8rem"&gt;
&lt;p&gt;
        所以，現在就開始學習吧！
    &lt;/p&gt;
&lt;/div&gt;&lt;/p&gt;</content><category term="深度學習"></category><category term="Python"></category><category term="Keras"></category><category term="TensorFlow"></category></entry><entry><title>進入 NLP 世界的最佳橋樑：寫給所有人的自然語言處理與深度學習入門指南</title><link href="https://leemeng.tw/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html" rel="alternate"></link><published>2018-12-24T08:00:00+09:00</published><updated>2018-12-24T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-12-24:/shortest-path-to-the-nlp-world-a-gentle-guide-of-natural-language-processing-and-deep-learning-for-everyone.html</id><summary type="html">&lt;p&gt;在此文中，我們以一個假新聞分類的 Kaggle 競賽做為引子，不用深奧的數學計算式，而是直觀且高層次地理解目前常見的 NLP 手法以及基本的深度學習、機器學習概念。透過建立一個能夠分類假新聞的神經網路，你將會學到如文本數據前處理、循環神經網路以及深度學習 3 步驟等基礎知識，並在未來利用此基礎進一步探索 NLP 世界。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        希望這篇文章能成為你前往自然語言處理世界的最佳橋樑。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;自從&lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html"&gt; 11 月從比利時 EMNLP&lt;/a&gt; 回來後，最近工作之餘都在學習&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"&gt;自然語言處理&lt;/a&gt;（Natural Language Processing, 後簡稱為 NLP）。&lt;/p&gt;
&lt;p&gt;上上週陰錯陽差地參加了一個 &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 競賽。在該比賽中，我實際應用到不少前陣子所學的 NLP 知識，也獲得不少心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/nlp-word-cloud.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此我想借此機會，在文中鉅細靡遺地介紹自己在這次比賽運用以及學到的 NLP 概念，希望能幫助更多對人工智慧、&lt;a href="https://zh.wikipedia.org/zh-tw/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習&lt;/a&gt;或是 NLP 有興趣但卻不知如何開始的你，在閱讀本故事之後能得到一些啟發與方向，並展開自己的 NLP 之旅。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/chris-ried-512801-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然不是必備，但有點程式經驗會讓你比較好理解本文的內容，因為在文中有不少 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 程式碼；另外，如果你熟悉&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;以及&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;神經網路（Neural Network）&lt;/a&gt;，那你可以趁機複習一些以前學過的東西。&lt;/p&gt;
&lt;p&gt;依據維基百科，NLP 的定義為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        自然語言處理（NLP）是計算機科學以及人工智慧的子領域，專注在如何讓計算機處理並分析大量（人類的）自然語言數據。NLP 常見的挑戰有語音辨識、自然語言理解、機器翻譯以及自然語言的生成。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文章裡頭，我將描述如何利用最近學到的 NLP 知識以及深度學習框架 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt; 來教會神經網路如何辨別眼前的假新聞。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/robot-read.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管此文的 NLP 任務是假新聞分類，你將可以把從此文學到的基礎知識運用到如機器翻譯、教機器寫詩、語音辨識等大部分的 NLP 任務。我也會在文末附上&lt;a href="#3-門推薦的線上課程"&gt;推薦的學習資源以及文章&lt;/a&gt;供你進一步探索。&lt;/p&gt;
&lt;p&gt;如果你已經準備好展開一趟刺激的 NLP 冒險之旅的話，就繼續往下閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本文章節"&gt;本文章節&lt;a class="anchor-link" href="#本文章節"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class="toc-href" href="#30-秒重要訊息" title="30 秒重要訊息"&gt;30 秒重要訊息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#意料之外的-Kaggle-競賽" title="意料之外的 Kaggle 競賽"&gt;意料之外的 Kaggle 競賽&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#假新聞分類任務" title="假新聞分類任務"&gt;假新聞分類任務&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#用直覺找出第一條底線" title="用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a class="toc-href" href="#資料前處理：讓機器能夠處理文字" title="資料前處理：讓機器能夠處理文字"&gt;資料前處理：讓機器能夠處理文字&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#有記憶的循環神經網路_1" title="有記憶的循環神經網路"&gt;有記憶的循環神經網路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#記憶力好的-LSTM-細胞" title="記憶力好的 LSTM 細胞"&gt;記憶力好的 LSTM 細胞&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#詞向量：將詞彙表達成有意義的向量" title="詞向量：將詞彙表達成有意義的向量"&gt;詞向量：將詞彙表達成有意義的向量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#一個神經網路，兩個新聞標題" title="一個神經網路，兩個新聞標題"&gt;一個神經網路，兩個新聞標題&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a class="toc-href" href="#深度學習-3-步驟" title="深度學習 3 步驟"&gt;深度學習 3 步驟&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#進行預測並提交結果_1" title="進行預測並提交結果"&gt;進行預測並提交結果&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#我們是怎麼走到這裡的" title="我們是怎麼走到這裡的"&gt;我們是怎麼走到這裡的&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#3-門推薦的線上課程" title="3 門推薦的線上課程"&gt;3 門推薦的線上課程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="toc-href" href="#結語：從掌握基礎到運用巨人之力" title="結語：從掌握基礎到運用巨人之力"&gt;結語：從掌握基礎到運用巨人之力&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;本文編排已將手機讀者放在第一位，但我仍然建議你使用較大的螢幕閱讀。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/toc-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用畫面左側的章節傳送門能讓你更輕鬆地在各章節之間跳轉（目前手機不支援，抱歉）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="30-秒重要訊息"&gt;30 秒重要訊息&lt;a class="anchor-link" href="#30-秒重要訊息"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;沒錯，光看上面的章節數，你應該了解無法在 10 分鐘內 KO 這篇文章，但我相信這篇文章會是你學習 NLP 基礎的最短捷徑之一。&lt;/p&gt;
&lt;p&gt;針對那些時間寶貴的你，我在這邊直接列出本文想傳達的 3 個重要訊息：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;深度學習發展神速，令人不知從何開始學習。但你總是要&lt;a href="#3-門推薦的線上課程"&gt;從某個地方開始好好地學習基礎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NLP 接下來的發展只會更加快速，就連一般人也能弄出厲害的語言處理模型&lt;/li&gt;
&lt;li&gt;站在巨人的肩膀之上，活用前人成果與經驗能讓你前進地更快，更有效率&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這些陳述看似陳腔濫調，但希望好奇心能讓你實際閱讀本文，找出構成這些結論的蛛絲馬跡。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="意料之外的-Kaggle-競賽"&gt;意料之外的 Kaggle 競賽&lt;a class="anchor-link" href="#意料之外的-Kaggle-競賽"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; 是一個資料科學家以及機器學習愛好者互相切磋的數據建模和數據分析競賽平台。&lt;/p&gt;
&lt;p&gt;本文提到的 Kaggle 競賽是 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge"&gt;WSDM - Fake News Classification&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;此競賽的目的在於想辦法自動找出假新聞以節省人工檢查的成本。資料集則是由中國的手機新聞應用：&lt;a href="https://www.toutiao.com/"&gt;今日頭條&lt;/a&gt;的母公司&lt;a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8"&gt;字節跳動&lt;/a&gt;所提出的。（知名的抖音也是由該公司的產品）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/wsdm-intro.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文的 Kaggle 競賽
                        （&lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而因為我所任職的 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 主打產品也是手機新聞應用（主要針對日本與美國用戶），像是這種哪個企業又辦了 Kaggle 競賽、又開發什麼新功能等等的消息都會在公司內部流動。&lt;/p&gt;
&lt;p&gt;話雖如此，在我從同事得知這個為期一個月的競賽時，事實上離截止時間只剩一個禮拜了！（傻眼）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-entrance.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        今年 10 月底參加的 EMNLP
                        （&lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但心念一轉，想說從 &lt;a href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html"&gt;EMNLP 會議&lt;/a&gt;回來後也學了一些不少 NLP 知識，不仿就趁著這個機會，試著在一週內兜出個模型來解決這個問題。&lt;/p&gt;
&lt;p&gt;名符其實的「志在參加」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="假新聞分類任務"&gt;假新聞分類任務&lt;a class="anchor-link" href="#假新聞分類任務"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;既然決定要參加了，當然得看看資料集長的什麼樣子。訓練資料集（Training Set）約有 32 萬筆數據、測試資料集（Test Set）則約為 8 萬筆。而訓練資料集一部份的內容如下所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/view-data-on-kaggle.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要了解此資料集，讓我們先專注在第一列（Row），大蒜與地溝油新聞的每一個欄位。&lt;/p&gt;
&lt;p&gt;（部分讀者可能會對簡體中文表示意見，但請體諒我沒有辦法事先將此大量數據全部轉為繁體）&lt;/p&gt;
&lt;p&gt;第一欄位 &lt;code&gt;title1_zh&lt;/code&gt; 代表的是「已知假新聞」 A 的中文標題：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;用大蒜鉴别地沟油的方法,怎么鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而第二欄位 &lt;code&gt;title2_zh&lt;/code&gt; 則是一筆新的新聞 B 的中文標題，我們還不知道它的真偽：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;翻炒大蒜可鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要判斷第二欄中的新聞標題是否為真，我們可以把它跟已知的第一篇假新聞做比較，分為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;unrelated&lt;/code&gt;：B 跟 A 沒有關係&lt;/li&gt;
&lt;li&gt;&lt;code&gt;agreed&lt;/code&gt;：B 同意 A 的敘述&lt;/li&gt;
&lt;li&gt;&lt;code&gt;disagreed&lt;/code&gt;：B 不同意 A 的敘述&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果新聞 B 同意假新聞 A 的敘述的話，我們可以將 B 也視為一個假新聞；而如果 B 不同意假新聞 A 的敘述的話，我們可以放心地將 B 新聞釋出給一般大眾查看；如果 B 與 A 無關的話，可以考慮再進一步處理 B。（這處理不在本文討論範疇內）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/chris-liverani-552022-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        如果 B 新聞「同意」假新聞 A 的話，我們大可將 B 新聞也視為假新聞，最後將其屏除
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著看到資料集（下圖）第一列最右邊的 &lt;code&gt;label&lt;/code&gt; 欄位為 &lt;code&gt;agreed&lt;/code&gt;，代表 B 同意 A 的敘述，則我們可以判定 B 也是假新聞。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/view-data-on-kaggle.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是一個簡單的「假新聞分類問題」：給定一個成對的新聞標題 A &amp;amp; B，在已知 A 為假新聞的情況下，預測 B 跟 A 之間的關係。其關係可以分為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unrelated&lt;/li&gt;
&lt;li&gt;agreed&lt;/li&gt;
&lt;li&gt;disagreed&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;順帶一提，上圖同時包含了 3 個類別的例子供你了解不同分類的實際情況。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第 3、 4 欄位則為新聞標題的英文翻譯。而因為該翻譯為機器翻譯，不一定能 100% 正確反映本來中文新聞想表達的意思，因此接下來的文章會忽視這兩個欄位，只使用簡體中文的新聞標題來訓練 NLP 模型。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;a class="anchor-link" href="#用直覺找出第一條底線"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在任務目標很明確了，我們就是要將有 32 萬筆數據的訓練資料集（Training Set）交給我們的 NLP 模型，讓它「閱讀」每一列裡頭的假新聞 A 與新聞 B 的標題並瞭解它們之間的關係（不相關、B 同意 A、B 不同意 A）。&lt;/p&gt;
&lt;p&gt;理想上，在看過一大堆案例以後，我們的模型就能夠「學會」一些法則，讓它在被給定一組從來沒看過的假新聞標題 A 以及新聞標題 B 的情況下，也能正確判斷新聞 A 與新聞 B 的關係。&lt;/p&gt;
&lt;p&gt;而所謂的「模型從來沒看過的數據」，指的當然就是 8 萬筆的測試資料集（Test Set）了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/Train-Test-Split-Diagram.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們利用訓練資料集教模型學習，並用測試資料集挑戰模型
                        （&lt;a href="https://elitedatascience.com/model-training" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這樣的陳述是一個非常典型的&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習（Machine Learning, ML）&lt;/a&gt;問題。我們當然希望不管使用什麼樣的模型，該模型都能夠幫我們減少人工檢查的成本，並同時最大化分類的準確度。&lt;/p&gt;
&lt;p&gt;但在開始使用任何 ML 方法之前，為了衡量我們的自動化模型能提供多少潛在價值，讓我們先找出一個簡單方法作為底線（Baseline）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAB7HUlEQVR4nO3dd3xW5f3/8de5d+4kZCfMhD3CEIKICIoKWnEB7m1b66rfWrW29ds97U/br53O2traOqqigCBSQFxMAQEhjISVkEASsuc9z+8Pek7vkDBsUQL3+9mHj5J7nPucc5+c8851fa7rGKZpmoiIiIjEEceJXgERERGRz5sCkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbijACQiIiJxRwFIRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3HGd6BU4UaLRKNFo9Jhf73A4cDj+87wYDoftfzudTgzD+I+X9Z+yttkwDEzTPOI2xe6f/3bbTyamadr7yNrmzh47VCQSwTRN4OTaX9a2WRwOR4djMxqNYpqm/bhhGPYxZL33SPvmRDqW7ROR+GSY1llb4lLshS3eRaPRY7qIH+vrTgUnw/FxsoZPETmx4i4AWSf0hQsXsm3bNrxe7xFbghwOB21tbYwePZrJkyd/qguC9dqWlhZee+01wuEw4XCYKVOmMGDAgM/tQmp9zrp161i6dCmJiYm0tLQwatQopk6d2m6brH+/9dZbFBUVYZomQ4YMYdq0aSfFxfA/ZW1bbW0tCxYsYOvWrdTX1xOJROjWrRvp6elMmjSJM888s93rLbNnz6akpIRIJMKoUaOYMmVKl95f1rqVl5fz97//3W4pufrqqxk4cGC7dd+1axcLFiygvr6e1tZWTjvtNK688ko2bNjAm2++idvtxu12c8cdd5CUlNQltvvTbJ+IxKe47QKbM2cOr7/+OikpKUQikcMGEZfLRU1NDbfddtunDkCWhoYGHn30Udra2mhrayMzM5MBAwbweWVPKwCtXLmShx9+mOzsbFpbW8nJyWHIkCH07t27QxibPXs28+fPxzRNZsyYwbRp0z6XdT0RrG2fM2cOv//97yktLcXhcOByuTAMg0gkQjgc5vnnn2fcuHE89NBDDBo0qN0+e/XVV/nggw8IBoPccsstJ00AOnDgAH/5y18wTZNwOMyECRMYOHAgkUgEl8vFtm3buP322ykvL8fr9VJXV8dVV13FlVdeSVFREc8++ywJCQn4fD5uuukmkpKSPvdtefvtt9m9ezfRaJSRI0dy9tlnE41GcTqdh92+rvzdiMjnI24DULdu3cjKyqJbt26Ew2FaWlo6DSROpxOv14vT6ezwnGma7d4TWyMRyzAM0tPTCQaDtLW14fF4Oizn0Ncfy2d92hN4QkICWVlZpKenA1BdXc3TTz/Nz372sw7rkJycTFZWFqZpkpyc3OnyDl0noNMg2dk+6uy5Q58/2n6xPr+z+pRjZYWY559/np///Of4fD4yMjJoa2ujpaWFaDSKy+UiJSUFwzBYtmwZd999N0899VS7C2lKSgqZmZmEQqHDhoBjPV6O9J5j3cZD982n3S/WZ7788suUl5eTk5NDMBgkFArh9/s7vO5Y1uU/Wf+jvcc0TV5++WUWL15MOBzm1ltvZdKkSXYAOlax+yv28w63np19j8fjd1REPj9xG4Csv+pDoRCGYXDBBRfg8/nsYleL1YU1atQo++dDT5KdLfvQk6/1eeFwuN1J8mh/iR7ps2KfOxbRaJRwOGyvS3JyMvPnz+eKK66goKCgXUuY9dpDi0hjl3W4gtJDW5OOtH7/yXPWheZwn9/Z/u+MtZ4rVqzgl7/8JcnJybhcLmpraxk8eDBnnXUWSUlJVFVVsXjxYhoaGkhPT2fv3r389Kc/5dlnn8XlctmfaX2/h+6vY1nfzp6ztuNw+7izYyL2ezlcYIz9rIyMDG655Rb783r16gVgb1dJSQkJCQm0tLTQr18/Hn30Ufr27QvA4MGDufPOO+0usNhgdLTtjn3ucNt1LN+tFT6zsrLsY9owDPs1GRkZ3HrrrZim2W77Ypd9pGM59vlYR9rvR3uviHQNcRuA4OBJLBqNkpCQwM9+9rMOJ/AjvQ+goqKCqqoqWlpa8Pl8pKam0rt372P+y9MKP5FIhLa2NhwOhz3iJikpqd3Jc//+/ZSVlREIBEhISKBnz57k5OS0W86n5XQ6aW5u5vHHH+eZZ575VLVNDoeDlpYWdu7cSWNjIw6Hg8zMTPr374/D4bDXKRAI0NLSYgfHpKQk3G63vZz6+noA+3tISEiwP6e1tZXW1lZ7H1itMNZ/1dXVVFRUUFlZSUJCAmlpaeTm5uLz+Y5pn1j7/tlnnyUSieB2u2lqamLSpEk8/PDDZGVl2a+99tpr+eY3v0lZWRmZmZmsXbuWJUuWcNFFFx2xhiy2BcZa36amJjweD6mpqfTs2bNDi6D1PqfTSSAQYO/evVRWVhIKhUhPTycnJ8det0Prt6x9VVpaSmVlJQ0NDaSlpZGRkUGfPn3s78F6T8+ePXnggQfsz7WCj2matLa2sm/fPjweD83NzRQUFHDeeefZrx01apT9h8Gh+zV2u6uqqti3bx9tbW1069aNtLQ0cnJyOqxL7PqXl5dz4MABWltbSUxMbPe7Zb3HCuehUMgOn6FQyC6Kdjgc9OzZk/vvv7/D9h36ma2trRQXF7Nv3z5aW1tJT0+nT58+9O3bt93xbGlubiYSiQDg9Xrxer3U19dTWlpKOBymW7du5OXltVtfEela4joAxWppacHtdnd6soodWWIYBqWlpfzud79j2bJlRCKRds3tAwYM4PLLL+fqq68+6knP5XJRUVHBvffeS0VFBW63m8bGRn74wx8ybdo0HA4HFRUV/O53v2Pp0qWEQiH7hO3xeDjnnHP42te+Ro8ePT71Sda6wCUnJ7NixQoWLFjApZdeesTWk9gWp5dffpnnn3+eqqoq+3nDMBg0aBB33303kyZNwjRN1qxZw4MPPojP56Ouro4HH3yQG2+8ETh4kbvlllsIhUI0NTVxzTXX8NBDD9nB7zvf+Q7Lli3D6XSSn5/PM888g9PppKmpiT/96U+8/vrrBAIBgsGgfWHr0aMH119/Pdddd90RW8iszygqKmL9+vUkJiba9VmPPPII6enphMNh+0I7bNgw7rnnHu6++26CwSDV1dW8++67XHTRRe32zaH7y+FwUFNTwx/+8AcWL15MIBCwHzdNk969e3PxxRdzww03kJCQ0G6d33nnHR5//HFKS0vti73T6cTv93POOedwzz33kJOT0+49W7Zs4Xe/+x0ff/yxHQ48Hg8Oh4MxY8Zwxx13MHr0aPt73rJlC3feeafd4vfYY48xceJEfvOb37Bs2TJqa2sxDAO/38/SpUtZv349Y8aM4bvf/S5vv/02P/rRj/D5fHg8Hv7617/So0cPe99WVVXx+OOPs2TJknbb7XK5mDBhArfeeisjR45st/5bt27l97//PevWrbOnYnA6nTgcDoYOHcqVV17JJZdcAsDf//53Xn/9daqqqvB6vbjdbt5//32uu+46Jk6cyH333UdhYSF33nmn3QL02GOPcdZZZ7VrdXv11Vd57rnnqKioIBKJ2GHY5XIxZswY7r//foYOHWpvl2ma3HfffWzevJmWlhbuvfdeevfuzSOPPEJjY6P93ffv358HHniA8ePHKwSJdEEKQBw88WZkZBy1K8owDOrr6/n617/Ohg0bSE9Pp7W1lUAggMPhwO/388knn7B8+XIOHDjAPffc0+myrFaehoYG7rvvPjZs2EBSUhL19fXce++9dsHx/v37ueuuu9i0aROpqam0tbURDAbtkWuvvPIKmzdv5umnn6Z79+7HfJKNRCIkJyfTt29f1q9fj8fj4emnn+bcc88lMTHxqPvq0Ucf5ZlnniEpKcnuInQ4HCQmJrJhwwbuuOMOfv7znzNz5kz69++PYRg0NDTQ2NjI9u3b7WXt3LmTyspKPB4PgUCAdevWEQqFcLvd1NbWsmbNGkKhEDU1NQwcONBuEfnud7/L3LlzSU1NtT87HA6TmJjInj17+N73vkdjYyO33377YWtUrMdXrlxJc3Mz6enpNDQ0cMMNN5Cenm4XAVuvjUajTJ48mf/3//4fkUiEUChE//79gc7rnqx9FQwGefDBB1m6dCkZGRkEg0FaW1vtULFjxw5+8pOfUFxczMMPP2xf8OfMmcO3v/1tPB6PHWQAu0Xh73//Ozt27OCJJ56gW7duGIZBUVERd911FxUVFXi9XlpbW3E6nbS0tJCUlMSSJUv45JNPePrppxk2bJh9LDQ3N9tFwtZ8VYWFhbz33nv069fP/tyqqio2bNiA1+sFDrbQ1dbWkpCQgMfjsVtErFafu+++m48//pi0tDTC4TCBQAC3243H4+HNN9/k/fff58knn2Ts2LHAwe62e+65h9LSUrp160ZLSwuhUMgOfatWreL999+nsbGR6667ju3bt/POO+8wcOBAu9urrq6OjRs3kpGRAdCuvi92+6zflSeeeIJf//rXJCYm4na7aWtrs8OR0+nkvffeo7CwkKeeeorhw4fbXXfNzc3U19fjcrmYPXs2+/bto7a2Frfbjc/nw+VysXHjRr7+9a/z/PPPM3jwYHWHiXQxcR2ArJNgMBjkt7/9LX6/v8Okaa2trYwbN44JEyYAMGvWLD755BO6d+9OY2MjBQUFjBkzxm4RsE7yr776KjfccANpaWkdan6suo7vfe97rF27lqysLKqrq7ntttv42te+Zr/+4YcfZvPmzWRnZ9PU1ERBQQHDhg1j48aNbNq0iZycHAoLC3n00Uf5v//7v2Pa5tgapvvvv59vf/vbVFZWUlRUxAsvvMCdd9552Pc6HA7eeust/vSnP5GZmUlraytZWVlMnDiRxsZG3n33XRISEgiHwzzyyCOMGTOGvn37MmbMGN577z2SkpLYsmULgUAAr9fLhg0baGtrs+s2SktLqaiooHfv3pSWltLW1obb7SYpKYmzzjoLgMWLF7Nw4UK75ePSSy9l2LBh1NTU8Oabb1JRUUFycjLPPPMMM2bMsAu5OytMB9i7d6/d0uD1eu2/1g99rRVYrrvuusPu187219tvv82HH35Iz549aWxsZPDgwZx55pm0tLTw3nvvUVdXR05ODosXL+auu+4iLy+P+vp6fvvb3+Lz+eyWD6ul6cMPP2TFihXk5OSwfPly5s+fzw033ADAH//4R/bv309KSgoZGRlcdtllpKSksGXLFhYsWEBqairl5eW88MIL/PznP7fX0+Vy2dtsXaAvvPBCevTowfvvv09TUxOhUIihQ4dyzTXX2DVATqfTrv+xujWtffHYY4+xfv16unfvTkNDA7169WL06NFs3bqVXbt2kZ2dTU1NDU8++SRPP/00TqeTv//975SUlJCdnU1LSwuTJ09myJAhlJWV8d577+HxeHA6nbz88stcddVVTJo0iXA4zMcff0xlZSXRaJT+/ftz+eWXk5+fb29P7PZZ35PL5WLZsmX84Q9/IC0tzW4Bmzp1KtnZ2axbt45t27aRnp5OdXU1P/7xj/nrX/9KQkKCHVKdTicJCQns2bMHgHPOOYesrCxWrlxJfX09aWlpVFVV8cYbb/Dtb3/7cxv1KSLHJq4DEBw8QYZCIZ588skOJyiXy8WBAwf42te+Zl+AN2zYYHdrjBgxgmeeeQafzwfAs88+y6OPPmq31tTV1ZGWlmYvz1q+1+vl6aefZsGCBWRnZ1NVVcUVV1zBt771LbtrYuvWrSxfvpz09HTq6+uZPn06P/nJT3C5XAQCAb7//e/z1ltvkZ6ezgcffEBxcXGHodlH2ubW1lb69evHl7/8Zb7//e/TrVs3/v73v3PxxRfbw+IPXe9IJMI//vEP3G43oVCI7t2789RTT9mtBPPnz+d73/sePp+P6upq3njjDe6//35GjRrF4sWLSUhIoKSkhMrKSvr06UN5ebm9PYZh0NbWxs6dO+nduzcff/wxjY2NJCUlkZ6ezogRIwBYv349AKFQiKysLH7605/a61lQUMDXv/51uzWiqKjoqAEoEAjgdDrtAGS1BB5uxJG1X6zunKPt63Xr1hGJRGhoaCArK4unn37abp1YsmQJ9913n12zVFVVRV5eHjt27KChoQG3200gEODOO+9k8uTJANx8881cffXVlJSUkJKSYreoNTQ0sH79epKTk6mvr+fKK6/kq1/9qr0eTqeTN954g+zsbLZu3Upzc7Pd2nfoCCiAa665hmuuuYZrr72W7du309rayvjx4/nGN77RYZ8c+v7du3fzzjvvkJaWRmNjI/n5+fzmN7+hR48e1NXV8bWvfY0PPviAxMREVqxYQUlJCf369WPdunV4vV4qKyu58MILefzxx+3P+cUvfsFzzz1HSkoKVVVVNDQ08IUvfIEvfOELfO1rX6OsrIxwOExBQQHf+9732n3Pna1jNBrl73//O/Dvc8BPfvITLrvsMnt/fuc732Hp0qWkpqayceNGFi1axOWXX24H5thlfvOb3+Smm27CMAzWrFnDV7/6VcLhMG632+4mVuuPSNcS9wEIDp4kY+t/rJOky+XC4/G0G+nz5S9/meuvvx6fz0f37t3ti31FRQVr1qyxu6esgmb4d4AwTRO/389zzz1HUVERaWlpNDQ0cP755/PDH/7QLsqGg10zTU1NdOvWDb/fz6233moXHickJHDLLbewZMkSABobG1m5ciWDBg065r8yrQLoGTNm8Morr1BcXExTU5M9LD6WtcyKigq2b9+O3++nrq6Om266iX79+tHW1obL5eKSSy7h9ddfZ/Xq1Xi9XjZv3gzAxIkTefrpp+26o927d9OnTx82bdqEYRj07NmT+vp6ysrK2LBhA+eccw47duzAMAxaW1s599xz7dBgFbhaF5avfOUrTJw4kYKCAvLz81myZAkOh4PGxka6desGHPnCE9slYnW1HOk4+TQXMdM0ue6667jwwgtJTEy0i5Hr6uo4cOAAH3zwQYfbbcC/u0it1otf/vKXrFq1inHjxpGfn8+f//xnu2vLen8kErG7epKSkpg/fz6NjY2MGzeO0047jQceeIBvfvObdpeQ1Y11OFaLSOy2WwXGoVDIDv2Hvgdg1apV9v43TZPbb7+dHj16EAwGSU1N5c4776Rbt24kJSXZNTcA3/jGN3C5XLhcLnJzc4lEItTW1rJ3714KCwvtUZpWHU5nwc0ahWfV8RzOvn372LBhA4mJidTX13PJJZdw2WWX2e/t1q0b3/jGN1i5cqW9H1atWsXll1/ebvqC1tZWCgoKuPnmm+19cPrppzN27Fg++OADe1Sh9XoR6TriPgBZF76LL764wzB4wzBobm5uN9LltNNOIxwOM3/+fObOncuuXbvYs2cPjY2NtLS0kJiYaJ/QD2fTpk323ELBYJBhw4aRkJBAJBJpN8LM+tk0Tb773e+2a36vq6vD6XTak/VVVFR86m0Ph8N4PB7uuece7r33XpKTk5k3bx7XXXcdycnJHaYEqKmpsYfGJyYmsmjRIrtY1QpvZWVldldiSUkJbW1tDBo0iF69elFeXk5zczObNm3itNNOY//+/ZimycyZM1myZAklJSX2Y9Ys3cFg0K4RARgzZgx//etf7QvcypUr+fDDD0lKSiI1NZUJEybwhS98gUmTJh31ez80+IbDYRoaGo74vk9zEYtGowwdOhQ4OFnf/Pnz2bVrF7t377Zrovx+v30Rt5bdv39/e7i91W317LPP8uKLL5KQkMCIESM4//zzmTFjhn1MpKWlMXbsWObOnUtOTg6tra289tprzJkzB7/fT9++fTnnnHOYPn06vXv3blevc7jt7Gzot9PpPOrxXVpaSigUIhqNkpyczODBgzFN0+6KmjRpUofvxzRNJkyYQHNzMwsWLGDOnDkUFxezd+9eGhoaCAaD+P3+dtNIdNZSZ6334UbmxYb5YDBob8/IkSPtlh3rmMjNzaV///5s27YNt9ttH5vWfrFmibfmg4oNZ1b4E5GuK64DUOww+B//+MfthmAfygoeW7Zs4cEHH2Tbtm1207nT6SQtLY20tDQCgcBRPzchIcF+XXJyMi+88ALTpk1j8ODB9l+b4XC43Zw8H330UYf6JJfLhdPppKamxh598mlYyz/33HM5//zzWbx4MQ6Hg9///vd2vUXsfZba2trssONyuSguLmbjxo3tLkLWOllFry0tLaSnpzN27FiKi4vxeDzs27ePLVu20NbWRmJiIpMnT6a0tJRly5bZNSJlZWX2/rFuPxGNRpk2bRqFhYW8+OKLNDc34/f77Ykaa2treeWVV3j11Ve55ppr+N73vofb7T5sdxaA3++3ux2bm5vZt28fo0aN6vTiFY1G2b9/v91Ck5CQQGZm5hH3b2lpKQ8++CBr1qzB6XTa806lpqaSnp5OW1ub/XprPdPT0/nf//1ffvrTn1JWVobT6bQLncPhMCtWrOCdd97h5Zdf5rHHHmPAgAFEIhHuv/9+ampq+Oijj+yQahVNb926lbVr1/K3v/2NH/zgB1x88cXHfqAcI2v9Q6GQHQQcDgder7fdHxWH1uNY4e+9997jBz/4AeXl5fZy3G43GRkZ+Hw+gsHgf72O1me3trbaxc5er5esrCx7na11czqddO/encLCQvv46Kw79dC5mmK3UUS6rrgOQLHa2trwer2HrRexiqV//OMfU1xcTGZmJtFolHPPPZeRI0cyduxYtmzZwo9//ONO53WJXVZrays9e/bkwIEDuFwuGhoa+MMf/sDvfvc7+3Wxzfwej4f777/frhWBf7dcWfU8Y8aMsd/3aRmGwT333MPy5csxTZOPPvrIHtXW0NBg7w9rODUcvDhdfvnldmizTvrWxSAajeL3++1QOXbsWGbNmoVhGBQWFpKQkEBraysZGRnk5eXZcxo1NDTw4Ycf2nO6jBw5kj59+rSrufn2t7/Nddddx1tvvcVHH33Etm3baGxsJBQKkZqaChwcIj1y5EiuvvrqIw7tHzJkiN1VEo1GWbx4cYeh7dZf9oWFhdx+++24XC7q6uq45ZZb+OY3v3nY1gbDMPjNb37DRx99RPfu3QmFQpx11lmMHj2a0aNH09zczAMPPNCu5c9y/vnnM2nSJBYsWMAHH3zAhg0bqK6utmt3unXrRmFhYbsJGfv27cvf/vY3Vq5cyeLFi1m9ejX79u2jsbERt9tNdnY2DQ0NPPLIIxQUFNC9e/cjzmH0aVn7yxq5Zj0WG6Jjf79iW77q6+v5+c9/zoEDB0hLS8PlcjFlyhSGDRvGmWeeyezZs3nqqadISUn5r9bR+uyEhAT7WA0EAlRVVdnB1lo3K/BaNWKJiYkKNyKnEAWgf7GazjsLQNYFcN++fezcuZPU1FQaGxv56le/2m6o++rVq2ltbe20PgKwa3gmTpzIj370Ix566CHWrFlDSkoKS5YsYdGiRVxwwQUApKWltVuP22677bC3pDh0Oz6tSCTC4MGDueaaa3j22WftYcuHSklJsfdRc3Mzp512ml37cDSnn346ycnJtLa22t0aDoeD4cOH43K5GDlyJCkpKbS0tPDiiy/atSYFBQV210kwGGTdunV2d8oNN9zAXXfdxd69e9m0aRNLlizh/fffxzAMvF4va9euPex8TFaQGz9+PGlpabS1tZGUlMQ777zD8uXL7aJ3wA5Pf/3rX6mpqSElJcXusumMdYG0hvJnZGRQW1vLlVde2a6+aunSpbS0tNitUJbt27fbQ9nz8/OZPn06tbW1FBcXs2zZMt566y2qqqpITU1ly5Ytdo3Jli1b8Hg8JCUl8b3vfY+Wlhb27NnD6tWrmTdvHkVFRSQlJVFbW8vmzZvtqROOtz59+uByuXA4HDQ3N1NSUkLPnj3t0X/z58/n+eefJzk5mXA4zC9+8QvKysrYv3+/fYx861vf4qqrruqwT4/GCt9HCqUA2dnZuN1uwuEwTqeTTz75pF24d7vdlJSUsGvXLrxeLw0NDfbkjUfrAhSRk4OGJXwKdXV1wL8D0ejRo+3nWlpaWLJkiV1HBIefHO+yyy6jR48e3H777XYXhdPp5PHHH6epqQnTNBk3bhwJCQl2Qe/DDz/crgvg2WefZezYsUyePJmCggK7IPo//YveNE2+/OUvk5uba89KbYmdNbhPnz4EAgGSk5PtuWgsW7Zs4cILL2TSpEmMHj2ahx56yF6nnJwchg8fTjAYJBqNUltbSzQatUeQ5eXl4ff7aW1tpbKyEjjYPWWFDKv75wc/+AF33XUXN954I9/97ncxDIM+ffowbdo0fvWrX5Gbm0swGGxXB9JZALIulD179mTKlCk0NDTYxe4PPvggr732mt3isnv3br7//e+zcOFCOywNHDjQrk06tNXN+t7r6+vtdQmFQgwaNKjda2bPnm13KVrz1AC89tprfPGLX+Tuu+/m2muvZceOHaSlpTFu3Djuu+8+Lr30UpqamuzPdblcFBUV2YH86quvtmt/hg0bxq233sp3vvMd+7uwhnAfbt/8p6z1yc/PJzEx0W79+cMf/kBdXZ1d0/XKK6+wZs0aVq5cyaZNm0hLS6O2ttZ+vdvtpqCgwF6uVTAeO03F4QKR1f12pFZYODhh5siRI2lubqZbt24sWbKEefPm4XA47AlJ/+///o+Wlhb7uBg/fvwRP1tETi5x2wJkdWsdbshzZ6ybiFr1Ab/+9a+prq7G7XYza9Ys1qxZQ3Jyst2lceg9i2ILNK1i0KlTp7JgwQLS0tLYsmWLPRfPyJEjGTNmDMuWLSMzM5P58+dz4MABTjvtNPbs2cPixYvtyen69u1rX4yPtC2H22arVScjI4PbbrvNnt039j0Abrebq6++mu985ztkZ2ezf/9+7rnnHs4//3xM02TJkiXs378fr9dLU1MT55xzDvDvYuvRo0fz3nvv2Z+XkJDAyJEjAcjJyaFfv35s2rQJv99PIBAgOzub4cOHAwdbqfx+v92VlpmZybJly7j33nspKCjA6/WyadMmSktL8fl8NDQ02AXIR7oxpmma3HPPPaxevdoeWt7a2sqPf/xjuxaqsbGRxsZGu8XCMAweeughuwA59t5bsfsrNTUVt9tNS0sLycnJvPrqq/j9flJTU5k/fz5Lliyxb3kSW3R8+umn87e//Q2Px0NbWxsPPPAAU6dOJSsri6qqKt5++217Esjhw4eTmppK//79SU5OJhgMkpiYyP/93/+xefNm8vLyCIVC/POf/7SPPY/Hw8CBA9sdF4c7do72O9LZdufn53PWWWfxz3/+k/T0dNavX8+tt97K+PHjKS4uZsOGDfTs2ZP9+/fzpS99yb4BrRXMWltb+dGPfsT1119PIBDghRdeYOvWraSmphIMBjsUaFufm5iYyMqVK/nhD39IQUEB06dPb9eiG7uOTqeTm2++mQ8//ND+A+QHP/gBixYtIjMzkw0bNrB161ZSUlKoq6tj5MiRXHjhhfbvy+Hut3ak/SIiXUvcBqDYm1d21t0Ty7pw9OjRgzPOOIN58+aRnZ3Ntm3b+N///V+7u2bw4MFUVVXZQ5L37t1rt3DEflbsSfmuu+7ivffeo7W1lYSEBP785z9z/vnnM2jQIH7wgx/w9a9/na1bt5KcnMzy5ct59913cblcJCYm2rey+OEPf0hqaupR5wCy1jN26LfFaoWYOXMmc+bMYf369SQlJbW7uWc0GuXKK69ky5YtvPTSS/h8Pvbv38+zzz6LYRycKNAaofbVr36Viy++2O6uAjjzzDN55plnCAaDRCIRvF6vHVLcbjdDhgxh1apVJCQk2PO8HDoa7fbbb2fVqlWUlZWRnJzMokWLWLhwof0dJSYmUldXx7hx45g5c2a7UTudfa+maZKTk8Njjz3GN77xDYqLi0lOTiYhIYGmpiZ73yQmJtLU1EQkEuH73/8+Z555Zrv9Hfv9WvsrNTWVadOm8dRTT5GdnU1paak93UFjYyPDhg2jurqaaDRKS0sLu3fv5owzzuD888/nsssu49VXXyUjI4Pdu3fz+9//HpfLZd+N3Qpid955J4Zh0L17d+655x5+/OMf4/f7aWpq4i9/+YtdyG4VtdfX1/O///u/9O7d294265g89Ea9h9suizVUPrZg39qvd999N6tXr6a2tpbk5GT27NnDtm3bcLlcJCQkUF5ezhlnnMGXv/xlotEogwcPZtiwYXz00Uekp6ezbt06Pv74Y1pbW/F4PPTt25f9+/cDBwuYKyoq7D9IMjMzqauro3v37tTU1PDMM88wc+ZMpk+f3u6mvrHbFw6HOfvss7nnnnv4zW9+g9/vx+12s3jxYnt/JSQkUF1dTXZ2Nj/4wQ/sW5VY++xw+8X6XYv9XBHpeuK2C8wqJE1OTiY1NfWoxcPWyKcf/OAHTJ8+HcA+SWZkZPDggw/y5JNPkp6eTkpKCj6fjzfeeAM42EVhfZb1HGCHphtvvBGn00lWVhahUIhXXnkFgH79+vH8889z11132aOdkpOTSUxMxOFwcOaZZ/LHP/6R8ePHHzH8WOEhKSmJtLQ0kpOT6datmx1MrNeYponX6+V//ud/SE9Pt9fXmjDP2gc/+tGP+O1vf0v//v3xer32nC7WqJmf/OQnPPDAAx1G+wwZMoT+/fvj9/tJTExk4MCB7e5lNWTIEFJTU0lOTiY9Pb1dl4MVVvr3788TTzzB+eefj8vlIikpyb6JalpaGklJSXzxi1/kt7/9rT0J5dFaxaLRKPn5+fzlL3/hi1/8IikpKUQiEYLBIC0tLfaFrKCggGeeeYYbbrihwxQB1j6N3V/RaJT/+Z//4ZZbbrFH7Vnf4x133MGf//xn+vfvT0JCAunp6cyaNYvW1lZcLhc//OEPue+++0hMTMTr9ZKYmIjH4yEjI4OEhATGjx/PM888w3nnnWfvv5tuuonf/OY3DBgwwB6Z6PV6SU1NJTExkb59+/LII4/wla98xb5ou91uunXrZq97bNeRYRjtnjt0jiSfz0dKSor9GquVLRKJMGzYMPs2F9a+sm4a6nQ6ueaaa/jd735nf0dJSUk8/PDDnH322XY49nq99O7dmx/96Ec89thjpKam2kXus2fPto+NL3/5y8yYMcO+I32PHj3scHS47bOO93vuuYeHH37YDoTW57rdbhwOB+effz5//OMf7WHyVovOkfYL/Pv8Yv0nIl2PYcZph3YgELCHJBuGQUJCwqdqqt65c6c9QiQvL4/u3bsDB+8SbbFaRawJAK1d7fP57NofS3Nzc7umeqvewQo1NTU1VFRUsG/fPnw+Hz169LBblzor3O6MNTTd+ozOttlaVmtrq91V53a7O504LxgMUlZWRnl5OcFgkKysLDvgHG6dAoGAHSg8Hk+7C240GqW1tbXdPjhU7HLLy8vZu3cvNTU1+P1+MjMzyczMJDs7+1PtF+uzrX1dW1vLrl27qKiooLGxkczMTHJzc+1uo86Wa91DKna7Yl9XUlJCeXk5pnnwBqh9+vSx94dVtxI70shSV1dHWVkZ+/btwzRNsrKySE1NtW9HceioKmtUU1lZGTU1NdTU1NhD7nv16tWuFePQfQ7/PjaPtF2WIx1P1meYpklxcbE9B1Rqaiq5ubl24Ih9nfXebdu2UVVVhc/ns+dEAuyJHq0uq0OnrbDuHg8HA0h6evpRt8/63La2Nnbs2EFFRQWBQICUlBR69epFXl5ep9/5kfZL7PdqdYUfbmCEiJw4cRuA/lOHtmpYYv86PN6fd6RunM/iBovHEhyONLT8s77p49GW/59+F0fb18fy2Z0tEzoeL4d7/L9dlyN9L8fy/PF0pH3V2fYf7vVH+z6Pti//2/U82vcgIienuA1Ah272pz15xvb7x56cD7fcQ+ttPu36WCdiK5z8p2HraOtxrOsT+5pPs17Hsp3Hsn6xn3u4Qtf/VOxyY9flSBfBY/l+Yy/URzteDrcux7qPY7+bo+2bI637pzluj7Tdx7r+ne33//Z36FiOqf9kPY9lmUd7jYicOHEbgERERCR+qV1XRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbijACQiIiJxRwFIRERE4o4CkIiIiMQdBSARERGJOwpAIiIiEncUgERERCTuKACJiIhI3FEAEhERkbjjOtEr0BWYpolhGPb/H4toNIphGPbrTdNst5zDcTgc9vs7E7vMY1332PWOXZ/Y/z/ScmNfc6ys9be2p7P1OZblHWlffZr1ERER+TQM80hXoDhwaOjpbHeciAuxaZpEo1GcTudhnz8e63W8lvNZfLYVpg4NWSIiIv+tuA5A0WgUh8PBhg0bePXVV5k8eTIXXHDBUd8XDAbZsWMHubm5vP3227S1tXHRRRexa9cu0tLS2LdvX4fgEolESE1NZcSIEYRCIbZt29bu4m4YBqFQiOTkZPr379/uvdu3b+fVV1/loosuYuzYse2CQ0tLCxs2bODjjz/mkksuIS8vj3A4TCQSoaWlhT179rBx40ZCoRC33HILbre7XbB49913WbVqFddeey19+/YlGAzyxBNPkJSUxJe+9KUO4cMwDKLRKHPnzsXpdHLJJZfgcDjsfVlcXMySJUuYPHkyQ4cOtR/vbL8vW7aMVatWMWPGDHr16kUoFLL3m2EY+Hw+e/tfeeUVpk2bxtixYztdpoiIyKcRt11g1kW0pqaGv/3tb+zdu5fm5mZ27txJOBzG4XDgcDgwDIMZM2aQnZ1tv6eqqopf/OIXTJ8+ne3bt1NbW0tzczNr164lPz+f5cuXk5CQ0K5LLBAIkJ+fz4gRI2hoaOCJJ56gqamJUCgEYH/esGHD+M53vsO2bdsoLS1l8uTJNDQ0sGLFCkaOHMnYsWMJh8PMnTuXwsJCSktLqaurw+Fw0Lt3b+rq6njppZdobm6mqamJ1tZWHA4HKSkpnH322QwePNgOP+FwmPfff5+NGzcydepU+vbtSyQSYfPmzWRkZBy29SkSibBgwQISExO5+OKLgX+3nJWVlfHGG2/Qp08fhg4desQWtdWrV7NmzRr2799PY2MjHo+HYDBIMBgkIyODG264AZfLRVNTE6tWrWLUqFF2ABQREflvxGUAsgJAW1sbf/rTnzhw4AC9evUiGo2yevVqfD4foVCI1tZWAKZNmwZgh5levXoxadIktmzZgsvlwuv14na7mTp1Kueffz6TJ0/G5XLx2muvUVVVxW233Ybb7cbv99vLiUaj9O/fnwkTJtjdXbNnz7bX8f3332fhwoWcfvrpeDwe/H4/brcbOBhA3n33XUKhEGeccQa5ubmMHDmSHj16sGjRInbv3s2YMWPo3r076enpDBo0iD59+uD1etvth8LCQrZt28bIkSMZPXo0cDCIJSQk4HQ627VkWfssKysLgKSkJPx+v10LZf2/2+0mJSUFt9tNNBptV+sU29pVXV1NYWEhw4YN47zzzuP111+nvr6egQMHkpCQQLdu3Zg7dy6tra1Mnz6dxMREe/tFRET+W3EZgAzD4MCBA/zpT39iw4YNOJ1OUlJSuP322+nRowelpaX8+c9/Ztu2bVxxxRX06dOnXU3OihUr2Lx5M8nJyTQ2NhIIBEhOTqaoqIju3buza9cuSktLKSsro62tjbfffhvDMLj88suBg2EiGAySl5fHF77wBXu9FixYYLdueDweEhMT7ddHo9F2xcoul4tBgwbxla98BTgYiiKRCC6XC7fbzTXXXEO/fv0Ouw9M02TRokVEIhGmTJnSLug4nU7279/Pd7/7XbsVKxwOk5GRwS9/+UscDgeRSATADiVWuDFNk3A4jMvlslu1YllBac2aNdTV1XHppZcyadIktm/fzrJly7jvvvtISEgA4Fe/+hWhUMgOWGr5ERGR4yUuA1AkEuHpp59m1apVTJkyhdTUVBYuXMizzz7LBRdcwLx589ixYwdTpkxhxowZnY6S6t27N4mJiWzduhWPx4NpmqSkpBCNRlm7di3hcJiJEyficrnYvXs369evZ8KECcDBkODxeCgvL2fFihV2d1QoFGoXJA43Usx6/yeffMKDDz4IQCgUYuLEieTk5BCNRqmpqSEzM5NAIGAHEafTSWJiIg6Hg7fffpu1a9cycOBAzjjjjHbhIhqNkpCQwKhRo+xtjkajJCUltav3aW5u5oMPPsDhcBAMBsnOzsY0TVwuF3v37mXDhg3U19fT2tpKW1sbZ599Nunp6dTX1/PPf/6Tbt26MXLkSOBg15nD4eCVV14hGo0ycODAo46oExER+U/FXQCyLqjnnnsuOTk5dgtKNBpl6dKl7Ny5k2g0ytSpU7nttts6vNc0TSZMmEBDQwM7d+4kKyuLpqYmgsEgI0eOZPLkycyaNYvMzEyGDh1qh49t27bhcrnsz4pEIhQXF1NcXExrayuGYRCJRMjJyTnmi77L5bK71Xbu3El9fT05OTk4HA6eeeYZotEoLpcLj8dDc3MziYmJ/PrXv6aoqIjZs2fj9XrtrjUr6LhcLiKRCOnp6dxxxx2dfq7VwlNVVcXjjz8OHCzGnjBhAhMnTsTv97NkyRLmzZtnb4vT6WT48OGkp6czb948KisrSU5Oxuv1Ul9fT1lZGQDLli2jtraWs846q8OQfhERkeMl7gKQYRg4nU4mTpzI+PHj2bx5M8uXL2fjxo2YpklSUhL19fV8/PHH/PGPf+T0009n0KBBdusHwPz58/nLX/7C2WefbV+chw4dyssvv0xzczMJCQmUlpbypz/9CcMw7BBkvdYaYbVgwQIOHDjAXXfdhcfjIRQKkZqaetQ5iQzDoK2tjaFDh3LPPfcQCoX41re+ZT9nmib9+vUjPT2dkpISysrKGDBgALm5uZimyezZs2lqasLr9dp1Os3NzUSj0XZdTjU1NTidTiKRCA6Hg27dutmF4ZFIhLS0NHukWDAYJCcnh9raWgKBAOPGjWPo0KH4/X6SkpJISEggNzeXhoYGli1bhtvtJhKJ4PF42LBhA9XV1dx1112MGDGC//3f/yUjI4Pa2lqFHxER+UzEXQCKRqMsXLiQLVu2UFpaSm1tLQD9+/fnqquuYuzYsRQWFrJ48WI+/PBDli1bRmJiIj169GDEiBHMmDGDXbt2MWbMGO6++26efvppkpKSOP/882loaCA7O5tgMEj//v258cYb8Xg8fPzxx7z00kt2gEpISOCss87iww8/pLKyEq/Xi8vlwuVy0djYSGNjI06n86gXf7fbbb8vttbGNE1mzJjB0KFDefPNN/nb3/7GzJkzGT58OADp6emcccYZ7NixA4DW1lZ+9rOf0djYSDgcJhgM0tjYyLe+9S07vKWnp/PDH/4Qr9drd88lJSVxzjnntFunZcuWEQgEKCgoYPLkyZ2ud9++famoqKC5uZn6+nref/99/H4/+fn5NDc309jYSI8ePWhqajqh8xSJiMipK64CkHUx3bt3L2vXriUnJ4fs7GzGjx9Pfn4+SUlJVFRU0KNHD6644go2b97MJ598QigUori4mD59+gBw11132d1ZW7ZsYcyYMTz11FOkpqZywQUX8NZbb7Fr1y5+8Ytf2EXFLperXaAJBoPU19cTCAR45JFH7NcBfP/737fn6zl0/eHfhcQlJSXMmjWLcDhMU1NTu5qZSCTSro7I+hlg+vTpeL1evve979nLbmlpwTAMRo8e3a61yjRNNm3aRFtbW4f9abUYWa1EsXP4BAKBdoXZ1jLdbje33347s2bNYs2aNfzzn/9kx44dRCIR/vCHP5CSkoLP56N3795s3br1v/zGRUREOhdXAQgOXpyvv/56pk+fzoEDB3jiiSdYtGgRs2bNIhKJ2CHCGhnmdDr5yle+woABA+wLfFlZGXv37iUUChEIBDhw4ADJycl89NFHfPLJJzidTnJycjjvvPMAKCkpYenSpe1uVxEMBqmtrbVHgjkcDtasWcOqVavsmpzDzcPT1NREOBymqqqKN9980+6y8nq9BAIBe/0PbTmxXpeZmUkoFLLnILIe7927N/fcc0+Hz/ve975Hc3Nzpy0xVguRFcpiP8taB2t7rWLxtLQ0OxClpaWRk5PDhAkTWLRoESUlJXTv3p1+/fq1mxhRRETkeIqrAGRdoJOSkkhKSqKhoYHGxkaGDBnCyJEjO9wTbMuWLWzYsAHDMEhOTrZbU1asWMHrr79OWloaTqeTPXv22BfqnTt32sPErVFdVkuI9X7TNNm3bx91dXVMnDiRs846C4DKyko+/PBD3G43bW1tNDQ0dNoN1tLSQmNjI1OmTOGSSy4hFAoRDodJS0tj4cKFOBwOPB5Pu22OZbUMHXoLkNgWI2sfxLYcdcaaGsBqETt0eVb4eeSRRxgxYgQzZ85s9/gZZ5zBWWedRV5eHtFolBdeeIERI0bg8/nsiRxFRESOt7gKQBarqBcODh8fOXIkl112WYfXeTwe1qxZY4ciKwhceOGFnHPOObz55pt88MEHdO/eneuvv57s7GxcLhdr166lvLycV1991f6c9PR0OyQYhsHKlSsJhULk5eXZ69PW1mYHqZEjRxKNRvH5fB1usrpv3z6CwSBDhw4lIyOj3TrX1tbidrtJSko67PYf7kalVsF2LKvo+dDHrP+35gGqqamhqanJfo3L5WrX4rVnzx68Xm+7xyKRCG63m9zcXCorK1m2bBmpqal2y9nIkSMJh8OqARIRkeMuLgOQFQCsOWv27dtn3wLD6g5yu92UlZW1Cy3We9LT06moqGDTpk2kpqbS3NzMK6+8wr333kuPHj245ZZbeOyxxzj99NMZO3Ysv/rVr7jgggvseYB27NjBBx98QJ8+fRg7dqxdQ1NSUmIXRI8dO5axY8cC2N1aVhBYv349brebnj172q02VkvTjh07SElJITk5+VPtEyuA7d69G2jfAhQIBNoFsIaGBkKhEG1tbSxYsIDt27ezadMmvF4vU6dOxev1UlVVRUtLCwCbNm0iGAzSu3fvDp/rcrmoqanhj3/8I3v27OHqq6+2R6vNnDkTgHXr1mk0mIiIHFdxGYAsVgvLypUree+99zo8b82TE9st5HA4WL58OS+++CLV1dU88MADpKWl8bOf/YyHH36YmTNnsnjxYurr6xk5ciT9+vVj1KhRzJ49G8MwuPLKK3nxxRepqqrixhtvpLi4mMWLF9PW1sbGjRvp1asXmZmZtLa28txzz+F2uyktLcU0TRISEohEIqxZs4Z+/frRo0cPO5hZXXY7duzgrLPOsm8keqTJBGMLnV0uF6WlpfzgBz9o1z1mzTqdkZFh74cdO3ZQX19PfX09f/7zn0lKSqJXr16cfvrpZGVl4XK5mD9/PkuWLAEOBrhgMEjfvn3bfbY1nP8vf/kLH330EZMnT2bGjBl2QfWGDRtYsWIFNTU1ugGqiIgcV3EdgBwOB6FQiIEDBzJ8+HC7BcgarbR161Y2b97coVZm9+7dtLS0cPvttzNu3DgA7r77bnbt2oVpmlRXV3Pvvffaz91333089thj1NfX43Q6mTBhAsnJyUyePJmNGzdSXFyMx+NhzJgxXHLJJXg8HrvIedeuXSQkJHD66adz2mmn4XA4mDx5Munp6TidznazRbtcLrKzsxk6dGi7ANNZQbS1/bEtW6mpqYwbN65dHZRpmqxcubLdKLWBAwcycuRIunfvTv/+/enfvz/du3e3A0pjY6M9xN4yZMgQxo8fby/XWrbf7ycvLw+fz8edd96Jx+Oxt8nlcrF69WpcLhfDhw9n1KhR9nqLiIj8NwwzDvsWrItwIBCgpKSE7OxsUlJSOryusbGR8vJy+vTpg9/vb9cNVVVVRVZWVqe3yaipqSE9Pb3dc6FQqN3NPGNbNKyZoQ+92adV3Gy1/sR+hjWq6lBW0bB1P62GhgZqa2vJzs7ucIf6kpIS3G433bt3p6SkhISEBHJycjoss6ysjGg0ak8DELsPY32aVpoDBw5QX19PXl6e3QLV2QSQzc3NRCIR/H5/h0JrERGR/1RcBqDOWEPgLbEtHocTe7E+NAgd+tyxFvIe6bVHW87xmDSws/uPHS7UWK89tKj60BFm1rodLRx9HtsnIiICCkD2xfpww8UPd+H+tEHlP724d9bCdCSHLudI74997lhfd7wc6zI/i88WERGJ+wAkIiIi8SfuqkmV90REROSkDECHu0fWsVBXioiIiJw0ASg25FghJvZeVsciGo2yd+/eTgt9RUREJH50uXHFoVCIF154gZaWFpxOZ7sbe/br148pU6ZQV1fHwoULKS8vx+/3M27cOAoKCo667Gg0yq5du9rNWSMiIiLxp8sFIIfDwcCBAwkGg/borLa2NpYtW8aQIUMAeOONN6itrWXq1KlUVVUxd+5cfD4f+fn5Rx1t1dncOSIiIhJfulwAcjqdTJo0qd1j8+bNY/DgwZx99tmUlpayd+9errvuOgYNGgRARUUFq1atIj8//6jLVxG0iIiIdMl+IGtmZNM02bhxIx9//DFf+MIXgIOzElt3EI9Go5imSV5eHtXV1R0mMzyUCqBFREQEumALEPx75uFwOMy7777LGWecQXZ2NnDwxpputxu32213kfl8PiKRCKFQqMPszVaYMgyDcDj8uW+LiIiIdD1dMgBZdTybN2+mpaWFiRMntruJ5qEFzNaortjHrdeXlZWxe/duPB4PkUik09s0iIiISHzpkgHIujXDihUrGDx4MElJSUQiEZxOJ36/n2AwaN8M1DAMmpub8fl87W4maoWcXr160b17d7sFaP369aoDEhERiXNdrgbICicHDhygtraW4cOHt3s+Ly+PYDBIYWEhDocD0zQpLCykb9++7e5pZXE4HLjdblwuV4e7rYuIiEh86nItQFbX1bZt2wgGg/Tp0wfAnhMoKyuLgoIC5s+fz/79+6msrKS+vp6ZM2e2e//hli0iIiLS5QKQFV5ycnKYNm0afr+/w3PTpk0jMzOToqIikpKSuPnmm+nRoweAJjgUERGRozpl7gZ/tAkQ4eCosjVr1nD66afjcnW57CciIiKfky6bAkzTxDTNw7boRKNRuwYIjm2On89q9JfJKZEhuzwDjd4TEZHjo8sGIGvI++FYwejThBprcsXjTRdmERGRk0uXDUDHk9U9VlFRQSAQOK51QqFoiEAkoBD0GTIxcRkufC7fiV4VERE5RcRFAIotrN67d6/dffbfCEfDuBwuXt76Mr9Y9QvSEtKIRCPHY3UlhsNw0Bxs5vy88/n1ub8+0asjIiKniLgIQBan03nc64CCkSD1gXqcTqcC0GfAYThoCjTREmo50asiIiKnkLgKQJ9J/Y9h4HK4cBku3WLjM+AwHLgcLpyG8+gvFhEROUZxFYA+K2bM/+T40r4VEZHPgmYNFBERkbgTVwFIXVQiIiICcRaAPqt5gEREROTkEhcByAo9n8U8QCIiInLyiYskEDsPkNfrJRqNnuA1EhERkRMpLgKQ5bOYB0hEREROPnEVgFT/IyIiIhBnAUhEREQEFIBEREQkDsVVAFL9j4iIiECcBSDNAyQiIiIQJwFI8wCJiIhIrLhIApoHSERERGLFRQCyaB4gERERgTgLQKr/EREREYizACQiIiICCkAiIiIShxSAREREJO7EVQBSAbSIiIhAnAUgTYQoIiIiECcBSBMhioiISKwumwQObamJ/flIz3VGEyGKiIhIrC4bgKzQEggEiEaj7ep3rH+HQqF2Px+NJkIUERERANeJXoHDKS4uZvHixbS0tOB2uzn77LMZPXo0pmlSX1/PwoULKS8vx+/3M27cOAoKCo66TNX/iIiICHSxFiAroFRVVfHKK6+Qnp7OZZddRm5uLq+99hrl5eUYhsEbb7xBWVkZU6ZMYeDAgcydO5fCwsJ2yxARERE5nC7ZArRu3Tq6devGNddcA8CgQYPweDwA7N+/n9LSUq6//noGDRoEHCxuXrVqFfn5+SdsnUVEROTk0aUCkFWfU1JSQv/+/dm4cSM7duwgKyuL8847D5/Px8qVK/F4POTm5tq1QXl5eaxYsYJIJILT6Tzq8kVERCS+dakuMIBwOEwkEmHz5s2sWLGCcDjM8uXLeeaZZ2hrayMUCuF2u3G73RiGgWEY+Hw+IpGIXRQdKxqNEgqFCIfDnT4vIiIi8adLtQBZwuEwycnJ3Hrrrfh8Pg4cOMDjjz/O9u3b8fl8HV5vDWuPnd/HNE0Mw6CsrIzdu3fj8XiIRCIdRpSJiIhI/OlyAcjlcuF0OsnNzbVbdjIzM8nKyqK2tpbMzEyCwSDBYBCPx4NhGDQ3N+Pz+XC73fZyrJDTq1cvunfvjmEYhMNh1q9fr0JpERGRONelusCsYNKjRw/27NmDaZo4nU4aGxupra0lNTWV3NxcgsEghYWFOBwOTNOksLCQvn37YhhGh3DjcDhwu924XK52AUlERETiV5drAQKYOHEif/nLX/jzn//MgAED2LhxI5mZmQwdOhSv18vYsWOZP38++/fvp7Kykvr6embOnAn8u+urM2r5EREREehiAcgKLllZWdx6662sWrWK0tJShg8fzvjx4/F6vQBcfPHFZGVlUVRURFJSEjfffDM9evQA0H2+RERE5Ki6VACymKZJdnY2l112WafPOxwOxo8fz/jx49u9R8XNIiIiciy6ZHOJVctjdVlFo9EO3VfWyC/rdccSfhSQREREBLpoCxC0DyuddWtZj32aUBOJRFQHJCIiIl2zBeh4s0JPRUUFgUBAdUIiIiJxLi6SgNVKlJOTg9frtbvPREREJD7FRQCyOJ1O1QGJiIhIfAUg1f+IiIgIxFkAEhEREQEFIBEREYlDcRWAVP8jIiIiEGcBSPMAiYiICMRJANI8QCIiIhIrLpKA5gESERGRWHERgCyaB0hEREQgzgKQ6n9EREQE4iwAiYiIiIACkIiIiMShuApAqv8RERERiLMApHmAREREBOIkAGkeIBEREYkVF0lA8wCJiIhIrLgIQBbNAyQiIiIQZwFI9T8iIiICcRaAREREREABSEREROKQApCIiIjEnbgKQCqAFhEREYizAKSJEEVERATiJABpIkQRERGJdVImgUNbcY7WqqOJEEVERCRWlw1ARwo1VqAJhULtfj4aTYQoIiIiAK4TvQKxTNPEMAza2tqYNWsWjY2NGIZBNBrF6/Vyww034PP5qKurY+HChZSXl+P3+xk3bhwFBQXHtHwRERGRLhWALDU1NZSWljJu3Dg8Hg+RSAS3243T6SQajTJnzhyqq6uZOnUqVVVVzJ07F5/PR35+vh2iRERERA6nywagtLQ0pkyZ0uG50tJSSkpKuO666xg0aBBwsLh51apV5Ofnf96rKiIiIiehLhWArNabpqYmgsEgixYtorq6mp49ezJmzBiSk5MpLy/H7XaTm5tLNBrFMAzy8vJYsWIFkUgEp9N52OWrZUhERESgixZBV1dXU1FRQVVVFX6/nw8++ICXXnqJcDhMIBDA7XbjdrsxDAPDMPD5fEQiEbsoOlY0GiUUChEOhzt9XkREROJPl2oBsubnGT58OAMGDGDo0KEAjB07lmeeeYaioiISEhI6FDNbw9pj5/exWpPKysrYvXu3XUtktRqJiIhI/OpSAcjSu3dvXC4X0WgU0zTp1asXKSkp1NXVkZKSQigUIhgM4vF4MAyD5uZmfD4fbrfbXoYVcnr16kX37t0xDINwOMz69es1GkxERCTOdbkusGg0yuOPP87ixYtxOBw4nU727dtHY2Mj6enp9O7dm2AwSGFhIQ6HA9M0KSwspG/fvhiG0SHcOBwO3G43LperXUASERGR+NWlWoBM08ThcDB69GiWLl1KU1MTycnJrF27lr59+zJgwABcLhdjx45l/vz57N+/n8rKSurr65k5c6a9jMN1canlR0RERKCLBSAruEyePJm0tDQKCwtpbW1l4sSJjB07Fpfr4OpefPHFZGVlUVRURFJSEjfffDM9evQA0H2+RERE5Ki6VACKNWrUKEaNGtXpcw6Hg/HjxzN+/Hj7MU2AKCIiIseqyzaXWAXQpmna/z70ecB+zbGEHwUkERERgS7cAhTbldVZcLGe/zShJhKJqA5IREREum4L0PFkhZ6KigoCgYDqhEREROJcXCQBq5UoJycHr9drd5+JiIhIfIqLAGRxOp2qAxIREZH4CkCq/xERERGIswAkIiIiAgpAIiIiEofiKgCp/kdEREQgzgKQ5gESERERiJMApHmAREREJFZcJAHNAyQiIiKx4iIAWTQPkIiIiECcBSDV/4iIiAjEWQASERERAQUgERERiUNxFYBU/yMiIiIQZwFI8wCJiIgIxEkA0jxAIiIiEisukoDmARIREZFYcRGALJoHSERERCDOApDqf0RERATiLACJiIiIgAKQiIiIxCEFIBEREYk7cRWAVAAtIiIiEGcBSBMhioiICMRJANJEiCIiIhKryyeBzlpsDn3saK06mghRREREYnXpAGSaJoZhEAqF2oUWK9CEQqF2Px+NJkIUERERANeJXoHDscLP3r17efnll5k+fTqDBg3CNE3q6+tZuHAh5eXl+P1+xo0bR0FBwTEtU0RERKRLBiArqLS1tfHmm2/S1NREJBKxn5szZw7V1dVMnTqVqqoq5s6di8/nIz8/3w5OIiIiIofTZQOQw+FgwYIFGIZBSkqKHYBKS0spKSnhuuuuY9CgQcDB4uZVq1aRn59/IldbREREThJdrgbICj/r1q1j586dTJ8+HdM07Rqgffv24Xa7yc3NJRqNYpomeXl5VFdXE4lEjtj6o5YhERERgS4WgKzuq+rqav75z39y2WWXkZOTQygUsoeut7S04Ha7cbvdGIaBYRj4fD4ikYhdFB0rGo0SCoUIh8OdPi8iIiLxp8t0gVl1P6FQiNmzZzNo0CAGDhxIfX09DoeDUChEJBLB6XR2mMfHah2KfdwKU2VlZezevRuPx0MkEiEajaolSEREJM51mQAEB7uo6uvrqayspKmpiccff9wOMgsWLKC+vp6UlBSCwSDBYBCPx4NhGDQ3N+Pz+XC73e2WBdCrVy+6d++OYRiEw2HWr1+v0WAiIiJxrssEICuwpKSkcMMNNxAOhzEMg0AgwIIFCxg/fjwjRowgEokQDAYpLCykoKAA0zQpLCykb9++GIbRYRSYw+GwW4bU8iMiIiLQhQKQxe12k5eXZ/8cDod55ZVX6NGjBxkZGQAUFBQwf/589u/fT2VlJfX19cycORPgiMPg1fIjIiIi0AUDEBwMKlaQMU2TCy64gIyMDPuxadOmkZmZSVFREUlJSdx888306NEDQPf5EhERkaPqkgHIGt0FB1uEzjrrrHbPOxwOxo8fz/jx4+3HNAGiiIiIHKuTornEmu/n0MegfWvR0SggiYiICHTRFqBDddat9Z8UNkciEdUBiYiIyMnRAvTfskJPRUUFgUBAdUIiIiJxLi6SgNVKlJOTg9frtbvPREREJD59LgHo0BqeExVAnE6n6oBERETk8wlADocDwzA6vWXF50n1PyIiIgKfQRF07Igs69/FxcUsWLCAyspKEhMTOeecczoMbRcRERH5vBz3phirpccKP7W1tfz+97/n448/xjRNysrKePLJJ/nkk0+AE9cdJiIiIvHruLYAtbW14Xa7cTqddgjas2cPgUCAX/3qV6SnpwPwwx/+kA0bNjBy5MjPtVtK9T8iIiICxykARaNRHA4HO3bs4Pnnn+eqq65i3LhxAGRmZhIOh3n55ZfJy8ujoaGB0tJSJk6cCHy+oUTzAImIiAgcpwBkhZg+ffowcOBA/vCHPzBw4ECuuOIKhg8fzjXXXMMLL7zAhx9+iMPh4Mwzz+Tss89u997PktUdp3mAREREBI5zAOrWrRu33347U6ZMYdasWfy///f/GD16NNdeey1PPvkkVVVVuN1uevbs2eG9n6XYeYD27t1rt1iJiIhIfDruKSAajdK/f3+++c1v8qMf/YiWlha+853v8PLLL5OammqHnxNR/Kx5gERERASOcwAyTROHw0FtbS2ffPIJDoeDb3/729x///1s3bqVBx54gJdeeonGxsYT0gKj+h8RERGB4zgKzKqzWbFiBc8++ywtLS1EIhF69uzJQw89xCOPPMKSJUt48803ee+997j++uuZPHnyMd/JXUREROR4OS7NMFaICQaDvPrqqwwdOpTbb7+dO+64A5/Px4svvohhGEydOpVHHnmEc889lw0bNij8iIiIyAlxXOcBikQitLS0tBvlVV5eTnFxMXCw7sfn83HdddcRDAaP50cfE4UtERERgeM4Csw0TRISEhgzZgy///3v+cc//kEkEqG6uppbbrml3etM08Tj8RyPj/5UNA+QiIiIwGdwL7CbbrqJrKwsdu7cicPh4Morr+S8886znzcM43NvidE8QCIiIhLruAUgK9QkJiZyxRVXHPE1nzfNAyQiIiKxjnsKME2z3Rw/Xelmp5oHSEREROAz6AI7tIurK7W0qP5HRERE4DNoARIRERHp6hSAREREJO4oAImIiEjciasApAJoERERgTgLQJoIUURERCBOApAVejQRooiIiEAXDkCHttTE/nyk5zoTOxGi1+vtUnMTiYiIyOevywYgwzCIRqOEw2H759jnAEKhUIfnjkQTIYqIiAh8BhMhHg+RSIR3332XwsJCQqEQ6enpTJ06ld69ewNQV1fHwoULKS8vx+/3M27cOAoKCo66XNX/iIiICHSxFiAroHz44YcsX76csWPHcv7559PW1sasWbMIBoMAzJ49m7KyMqZMmcLAgQOZO3cuhYWF7ZYhIiIicjhdqgXI6p765JNPOP300znrrLMASE9P569//StNTU0EAgFKSkq4/vrrGTRoEHCwuHnVqlXk5+efsHUXERGRk0eXagGyXHbZZUyYMIFQKER9fT0bN24kJSWFbt26UVZWhsfjITc3l2g0imma5OXlUV1dTSQSOWKNj+p/REREBLpYC5AlLy8PgKVLl7J8+XLa2tqYOnUqLpeLxsZG3G43brfbvvGqz+cjEokQCoVwOp3tlhWNRu1gZBVUi4iISHzrkgHIctppp9GzZ0+Ki4v58MMPGTx4MAkJCR1eZw1rj53fxzRNDMOgrKyM3bt34/F4iEQiRKNRtQSJiIjEuS4TgKzA0tLSwpo1axgxYgTp6emkp6czZMgQNm7cyJ49e+jWrRvBYJBgMIjH48EwDJqbm/H5fLjdbnt5Vsjp1asX3bt3t1uA1q9fr0JpERGRONflaoAcDgdLlixhw4YN9mM1NTVEIhESEhLo06cPwWCQwsJCHA4HpmlSWFhI3759MQyjQ7hxOBy43W5cLle7gCRyKjJNMK3/13/H979/7VcROTV0mRYgK7z4fD4mT57M+++/T0NDA4mJiaxfv57MzEwGDhxIYmIiY8eOZf78+ezfv5/Kykrq6+uZOXMm8O+WpM6o5UdOdfahr17ez4b2q8gpo8sEIPh3t9V5551HSkoK27dvp7GxkYKCAs444wwSExMBuPjii8nKyqKoqIikpCRuvvlmevToAaD7fEncCoSjBMNRVOL22TFN8LgceF06z4ic7LpUALIYhsHYsWMZO3Zsp887HA7Gjx/P+PHj7ceO1PIjciqLRE2cDoNH397KHz/YSbrfQziq1s7jzeUwqGkJcvvZ/fn+pfn2fheRk1OXDECAPVrLuieY9e/Y560aIDi2OX4UkORU1hqKUNsSwmkYCkCfAZfDoLYlRGsocqJXRUSOgy4bgGK7sjrr1rIe+zShJhKJqA5ITlkOw8DtNHA5DNWqfAZc/9q/Dv0hJXJK6LIB6HiyuscqKioIBAKqE5JTlkYrfXZMQ/tV5FQSF0nAaiXKycnB6/XaEyeKiIhIfIqLAGRxOp2qAxIREZH4CkCq/xERERGIswAkIiIiAgpAIiIiEofiKgCp/kdEREQgzgKQ5gESERERiJMAZIUezQMkIiIiECcBSPMAiYiISKy4CEAWzQMkIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETikAKQiIiIxJ24CkAqgBYRERGIswCkiRBFREQE4iQAaSJEERERiRUXSUATIYqIiEisuAhAFk2EKCIiIhBnAUj1PyIiIgJxFoBEREREQAFIRERE4lBcBSDV/4iIiAjEWQDSPEAiIiICcRKANA+QiIiIxOqySeDQlprYn4/0XGc0D5CIiIjE6rIByAotoVCo3c9He+5INA+QiIiIALhO9AoczurVq1mzZg3BYBCv18vZZ5/NiBEjME2T+vp6Fi5cSHl5OX6/n3HjxlFQUHDUZar+R0RERKCLtQBZAWXTpk0sWLCAQYMGcdFFF5GZmcnrr7/O3r17MQyD2bNnU1ZWxpQpUxg4cCBz586lsLCw3TJEREREDqdLtgCtXr2a3r17c8EFFwAwZMgQHn30UXbv3o3P52PPnj3ccMMNDBo0CDhY3Lxq1Sry8/NP5GqLiIjISaJLBSCrPqegoICkpCQikQhOp5OmpiaCwSBJSUns27cPt9tNbm4u0WgUwzDIy8tjxYoV9uuPtnwRERGJb10qAFlGjx5t/3vfvn28/vrrJCYmMnToUD766CO8Xi9utxvDMDAMA5/PRyQSIRQKdQhA0WiUSCSCYRiEw+HPeUtERESkK+qSAQigtbWVd999l7Vr15KXl8dFF12Ez+cjGo12mMfHGtYe+7hpmhiGQVlZGbt378bj8RCJROxWIxEREYlfXSoAWaGlsbGRF198kcbGRmbOnMnw4cPt5xMTEwkGgwSDQTweD4Zh0NzcjM/nw+1228uyQk6vXr3o3r273QK0fv16FUqLiIjEuS41CsyyfPlyAoEA//M//2OHH8Cu9wkGgxQWFuJwODBNk8LCQvr27YthGB3CjcPhwO1243K52gUkERERiV9dqgXIMAyi0Sjbt28nGAzy6quvEggEcDqdtLa2cuaZZ1JQUMDo0aOZP38++/fvp7Kykvr6embOnAn8uxWpM2r5EREREehiAQgO1vOcccYZBAIBu3jZMAyCwSCpqakAXHzxxWRnZ1NUVERSUhI333wzPXr0ANB9vkREROSoulwAcrlcjB8//oivcTqdjB8/vt3rjtTyIyIiIhKrywUg4LA3K7Vag6zXWDVA1nNHo4AkIiIi0EUD0LF0Y1mv+TShJhKJqA5IREREuuYosOPNCj0VFRUEAgHVCYmIiMS5uEgCVitRTk4OXq/3sF1sIiIiEh/iIgBZnE6n6oBEREQkvgKQ6n9EREQE4iwAiYiIiIACkIiIiMShuApAqv8RERERiLMApHmAREREBOIkAGkeIBEREYkVF0lA8wCJiIhIrLgIQBbNAyQiIiIQZwFI9T8iIiICcRaAREREREABSEREROKQApCIiIjEnbgKQCqAFhEREYizAKSJEEVERATiJABpIkQRERGJFRdJQBMhioiISKy4CEAWTYQoIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETiUFwFINX/iIiICMRZANI8QCIiIgJxEoA0D5CIiIjEOimTwKGtOEdr1dE8QCIiIhKrywYg0zQxTZNoNNohsFiBJhQKtfv5aDQPkIiIiAC4TvQKHI4VVP72t78xYsQICgoKiEQiOJ1O6urqWLhwIeXl5fj9fsaNG0dBQcFRl6n6HxEREYEuGoACgQC7d+9m586dFBcXM2zYMOBgKIpGo8yZM4fq6mqmTp1KVVUVc+fOxefzkZ+fj2maauURERGRI+pSAcgKL3V1dbzzzjuEw2E8Ho8daBwOByUlJZSUlHDdddcxaNAg4GBx86pVq8jPzz+Rqy8iIiIniS5VA2QFnezsbO644w7uvPNOPB5Puxqgffv24Xa7yc3NJRqNYpomeXl5VFdXE4lEjtj6o5YhERERgS7WAmQxDAOn09npc21tbbjdbtxuN4ZhYBgGPp+PSCRCKBTq8L5oNGoHo3A4/HmsvoiIiHRxXTIAWTorWjYMo8M8PlYLUezjVndaWVkZu3fvxuPxEIlEiEajagkSERGJc106AHXG7/cTDAYJBoN2fVBzczM+nw+3222/zgo5vXr1onv37nYL0Pr16zUaTEREJM51qRqgzjgcjnYtNnl5eQSDQQoLC3E4HJimSWFhIX379sUwjA7hxuFw4Ha7cblc7QKSiIiIxK8u3wLU1NRkT3gYiUTIysqioKCA+fPns3//fiorK6mvr2fmzJkARxwGr5YfERERgS4egBwOBxdccAF5eXn2zwDTpk0jMzOToqIikpKSuPnmm+nRo0e714iIiIgcTpcPQBMnTrR/jp0PaPz48YwfP95+ThMgioiIyLHq8s0l1lw/nT0O/75n2LGEHwUkERERgS7eAgSH79KyHv80oSYSiagOSERERLp+C9DxYIWeiooKAoGA6oRERETiXFwkAauVKCcnB6/X2+7WGiIiIhJ/4iIAWZxOp+qAREREJL4CkOp/REREBOIsAImIiIiAApCIiIjEobgKQKr/EREREYizAKR5gERERATiJABpHiARERGJFRdJQPMAiYiISKy4CEAWzQMkIiIiEGcBSPU/IiIiAnEWgERERERAAUhERETikAKQiIiIxJ24CkAqgBYRERGIswCkiRBFREQE4iQAaSJEERERiRUXSUATIYqIiEgs14legc+TJkIUEfkcmFEwTdDp9rNjAoYDdE37j8VVAFL9j4jI58BwKPx81rR//2txFYBERORzsG89NFWCQ5eYz4YBkSBkD4XUvH+1tikRfVo6OkVE5DgxAQMW/xg2zwZvNzAjJ3qlTj0OFzTXw/THYNL9B/exocv5pxVXe0z1PyIinwPDAQ4HOJwHM5EcXw7nwSFMRlyMY/rMxNXe0zxAIiIiAnESgDQPkIiIiMQ6KZPAoa04R2vV0TxAIiIiEuukDEBWoAmFQu1+PhrNAyQiIiJwkhVBm6aJYRjU1dWxcOFCysvL8fv9jBs3joKCgmN6v4iIiMhJFYAAotEoc+bMobq6mqlTp1JVVcXcuXPx+Xzk5+fbIUlERETkcE6aAGQFm9LSUkpKSrjuuusYNGgQcLC4edWqVeTn55+QdTNi/ifHl/brp2PE/CfHl/brp6Wj8bOj/Xo8nHQBaN++fbjdbnJzc4lGoxiGQV5eHitWrCASieB0Og+7DKtl6Hi0ENnLMCAS8z85vkxMIkQwNZnIYVnHoolBxMT+T44v41/71eT4nUdOPdY+MQ9Ozmf9d1L41ySOJwPTODj7s0XH4n/kpAlAlra2NtxuN263G8MwMAwDn89HJBIhFAp1CEDRaJRIJIJhGITDYUzTJBQK/df1QOFoGNNhYkQM/IafBCOBiHFy/KIbhnHS1EM5DAdRI4rbdBMOh0/06nRJkaiJ02HgIoLfBQkuiJwkAx1PpmPR6QC/C1xECIfD9n6XWP8KEYYHXIng9AMnx8FocBLN2Wg4wRUA0wHhMETD4Pjv1t40TZxOZ1xNE3PSBSDDMDp8Qdaw9tjHrRajsrIydu/ejcfjwTRNotEo69evP27rMzAykCeGPHHwRH4y/PqYEIlGcDqcJ8UfOwYHL5Auh4s1a9ac6NXp0s7PiDDp8oyDLRMnwaEIHLXVtksxDp5XPM5GHYtHk3sH9P4yJ8VJ5l9OqmMR/nX/Lx8ch2PRMAyCwSB9+/alT58+cVNLe9IFIL/fTzAYJBgM4vF4MAyD5uZmfD4fbrfbfp315fXq1Yvu3bu36/46nn9xGhg4TqLpyMPhMB9//DFjxozB5Tp5vn4Tk6h5cvwleaI4jJOrW+akPRZNk+hJEjBPGMPxr9s0nBw7KhyO8PHH6xg9pgCX62QJQca/uhiPzz62WoDg5DqP/DdOmrOO9YXk5eURDAYpLCykoKAA0zQpLCykb9++driJ/fIcDkdcNekdjYGBaZgYLgPDefIc5AYGjpNz2io5DMN5sJ7GcLowHCfLRedgm4aOxGN1cpxjDCc4iOJ2cpJ1a548vzdd0UkVgEzTJCsri4KCAubPn8/+/fuprKykvr6emTNnAsRN091/yoyaBINBzKip3x05ocxo9F/HYhROpq4HOeVEoybBYIho1NShGEcM82SpQIwRjUb56KOPKCoqwufzceaZZ9K7d+8TvVonhWg0Snl5OT179lTLmJxQOhalq9CxGJ9OygDUGbX8iIiIyLE6aaOuNfLLNE2Fn0/pFMm8cgrQsShdhY7F+HPKtADJZ0PhUkRETkUnbQuQfD4UfkRE5FSkANSFHNoYF/uz9W+ry+/Q5472eKwFCxawYcOGTt8b+9pwOExDQwORSPsZrg+33NjnAObPn9/uc+TUYU0qeqRjIPaYPfTxYzlOD33+aM/peDv1mKZJJBLBNE22bNnC7NmzAVixYgVvvfVWu9cdy/F4tHPWkc65nS3vSJ/VGWtbSkpKeOWVVzS7/QmmANSFHNraEvtz7ESO1n/WL1nsY/Z9of7VdXXoYwDFxcVUVlYC2PdTi/3Pqq/at28fzz77LE1NTfZrD7cOsetpfd6ePXuorq5u99lyarBmZD/0mO3suOvs2D2W4/TQ4zv2sdj10PF2arKODafTiWEY1NbWsmvXrnbPx74u9ng89LnOzlmdHV9HOufGPt7Z+e9YjmVrWxobG9m5c6d9TpUTQwHoBLN+MZqbm+2TNxwMG1VVVQfnSTFNDhw4AMCBAwcoKiqiqanJ/iWrq6ujtbWVpqYmdu3aZf8itrS0UFxcTEVFBfDvX2iPx2PPvOt0OmltbWX79u1s27aNxsZGHA4HkUiEyspKQqEQ+/fvJxQK2cNDy8vL2bFjB4FAoMMF8MCBA+zZs4dIJEJCQsLJNbW8HLOSkhIKCwvZt2+f/Zh13DU2NlJcXExjYyPRaNQO0I2NjTQ2NtLW1saOHTvs8N3c3NzpcWr9f2lpKbt27SIcDut4iyOGYdjHSmtrK16vF6/XC8Bpp53GOeecY7+uqamJLVu2sGPHDkKhULtjqLGxka1bt1JUVERra2uH42vv3r2UlJQAB8/D1j0jDxw4QDQaZe/evVRVVdnrdbjz35HOuYZhEAqF2LlzJw0NDbjdbntb5MQ5aSZCPFVZF421a9eyadMm7r77bvui8Ne//pUrrriC7OxsXnjhBTIyMqiurrZ/wa+++mpyc3NZvHgxTU1NNDY24na7ueuuu/jkk094++23cbvdBAIB+vbty2WXXYbf72/XVFxSUsKsWbNwOp32DWVnzJhBRkYGH3zwAYZhsGDBAq666ioyMzN57bXXKC8vx+PxEIlEmDZtGvn5+UQiERYuXMiGDRtISEjA7/fT0NDAwIEDT/AeluPBOk6DwSCvv/46JSUlJCQk0NDQwMiRI7nkkktwOp2sW7eOxYsX43Q6SUhIwO12k5KSwjXXXMPKlSvZuXMnAE1NTXzjG99g06ZNLFiwoN1xeumll+L3+6mrq2PWrFnU1dXZN2mcPn06ffv21fF2CrOOtW3btvHmm2/icDjwer04nU77D7f33nuPyspKbr31Vnbs2MGcOXPsc1hCQgJXXnkl2dnZFBYWMn/+fHw+H8FgEMMwuOKKK+jbty+NjY288cYb7Nu3D7fbTUZGBvX19VxxxRVkZGTw0ksvkZWVxZYtW5g2bRopKSn84x//YN++fR3OfwAbN25k4cKFHY7lxMRE9u7dy+uvv04wGLSDnMvlUkvlCaYA1EVYfd2xrP5ih8NBc3MzCQkJ3HTTTXi9Xv74xz/y0UcfkZubi8PhYPfu3VxwwQXk5+dTWVnJ/PnzOfvss5k4cSIHDhzgueeeY+XKlZx//vntPmPp0qXk5ORwww03APDqq6/y/vvvc9tttzFt2jTmzJnDtddeS/fu3Zk3bx41NTXceeedpKSksHjxYubOncuAAQMoKipi1apVXH311QwePJg1a9Ywf/58/UV+irAuSlu3bmXXrl3ccccdZGRksGXLFmbNmsWkSZNwOBy89dZbnHHGGUyePJk9e/bw8ssv061bN+DgbWn27t3L5MmTOe2006isrGTevHmdHqdTpkxh3rx5GIbBPffcg9frZfbs2cyePZv77ruPwsJCVq9ezVVXXaXj7RQS23o9b948O0QcOHCAf/zjHyQnJwMHz43W+fK9996je/fu3HDDDQSDQf70pz/x8ccf84UvfIF33nmHYcOGcemll2KaJs8++yxr1qyhb9++LF26lIqKCm655RaSk5OZP38+u3fvBg4eqy0tLdTU1HDjjTfSv39/Fi5cSG1tbbvz35tvvkm/fv1obW1l/vz5nHPOOe2O5VWrVnHeeecxe/ZsunXrxpVXXkkgEODVV18lGAxq0sUTTHu/CzlSDRDAOeecQ0ZGBklJSfTv35/m5mbgYLHygAEDmDhxImlpaRQVFQHQu3dv9uzZQzAYpFevXhQWFtqBynLZZZdx4YUXsmfPHjZs2EB9fb3dh2010fr9fgC2bNnCwIEDaWpqYs+ePfTs2ZNAIMCOHTsoKipi0KBBjBgxAo/Hw1lnnUV2draK/E4R1jEzePBgbrvtNsLhMFu2bGHXrl04nU5M02THjh243W6mTJmC1+tl8ODBDB8+nFAoBBy8aOXk5DB16lSysrLYvn070P447dmzJ0VFRdTV1VFWVsbAgQOprq5m79699O7d235827ZtOt5OQVaLyM6dOwkGg3zhC1/A5/PRu3dvTj/9dNra2oD2dTmJiYmUlpayfPlyamtrue2225g6dSoA119/PWeeeSa7du1i/fr1tLW12cfy9u3bmTBhAj169CApKYnzzz/fPudZtZATJ05k8ODB9j0nY89/vXr1oqWlxe6iNU2zw7FcXFzM3r17aWxsZMqUKSQnJ5OZmcmECRM6/MErnz+1AHUxhxuN4HQ6cbvd9uMOh8P+dzQaJTEx0f65paWFaDTKwoUL7cdcLhc9e/bs0OS6Y8cOPvjgA5xOJ+np6YRCIfskEDvZZHNzMw6Hg507d1JaWmqvU+/evTEMg/r6erKzs9sVSiclJanI7xQRW98zb948qqurSU1Ntbsm4OBxl5SUhMPhsL93v99vB/VDj9PW1tYOx6nD4aBXr15UV1fjdDrZvHkzW7dutZ/r168foVCIxsZGcnJydLydopqamnC73fj9fntUld/vb/fHm3XMzJgxg0WLFrFy5Uree+89UlJSuPjii+nbty+bN29m1apV+Hw+UlNTiUajOBwOQqEQ0WiUbt262ceM2+22u6Wi0ajdjRuNRu3ayM7Of06nk6ampsMeyzU1NbhcLpKSkuxtSUhIUBdYF6AA1EVYIwqsX/CmpqZ2hcexr+uMdYGCg0XOPp+P2267zR4dUVJSQlNTkx2cXC4XgUCABQsWMGnSJM455xxcLhcLFy60m4GtZbpcLvx+P+FwmDPOOIMzzjiDaDRKJBJh06ZN9OzZE4/HQ21tbbv1tU4acupYtGgRbW1t3HnnnXTr1o19+/bx3HPP4XQ68fl8tLW1tfvrvKqqql231NGO0z179tDa2kpaWhqhUIjzzjuPYcOGYZomLS0tbNu2jR49euD1eqmrq9Pxdory+/0Eg0FaWlpITk62w3dsYLCOq507d3LBBRdwySWXUF5ezltvvcXSpUuZMmUK7777LhdffDFjxozB6XTy8ssvEw6HcbvddpG1dczU1tYSCAQ6HEMOh4PExETC4TBnn312u/Pfxo0bycnJYd++fSQkJHQ4ltva2uz6o+bmZtLS0uyi7XA4rOP1BNPe7yJSU1OpqamhuLiYqqoqFi9eTDAYtJ8/dI4L668U69+xzw0aNIjm5maWL19u3+TvxRdfpLS0FPh3bZH1HrfbDUBhYSHr1q2zR4G53W6CwSClpaUYhsGgQYNYsWIFNTU1RKNRFi9ezFtvvYXb7SY/P5/t27dTWFhIMBjk/fffp6Kiwi5alFNDJBLB5XLhdrupqqpi0aJFhEIhmpqa6NevH01NTSxevJiamho++OADdu7cicfjAdofs9D5cfrSSy+xZ88e0tPTyc7OZtmyZTQ2NhIIBJg/fz7vvPMObrebYcOGsW3bNh1vpxgrHPft2xeXy2UH7tLSUtasWWOfq2KPpQULFjB37ly7izUlJcXuloWD57doNMqaNWvYtm0b0WiUaDTKgAEDeP/999m7dy+lpaUsWrSo3Xk09pzr9XoZMGBAh/Pf22+/jWEYDB48mJaWlg7n3D179tC7d2+Sk5NZsmQJzc3NVFZWsmLFinYtpXJi6Gxxglm/8AMHDmTgwIG89tpreDwecnNzycrKsl9z6BBft9uNz+cD2g9rN02Tnj17Mm3aNJYuXcratWsJBoP069ePc889F8B+n8/n44wzzuCDDz5gzZo1JCcnM27cOFavXs3y5cuZMGECOTk5zJ07l5SUFC666CJeffVV/vSnP9knlZkzZ+L3+xkxYgR79+5lzpw5eL1eMjIy6Nev3+e1G+VzMnHiRN544w0ef/xx3G43Q4cOJRAIMG/ePO666y6uvfZa3n77bTZu3EhaWhq5ubl2rcOhQ38Pd5xOnjwZ0zSZPn06r7/+Os888wwOhwOn08nVV1+Nw+Fg5MiRlJWV6Xg7xVgt4d26dePSSy/lrbfe4vHHHychIYE+ffrYfxS63W47DF1yySXMmzePJ554wm5VueKKK8jNzWX48OG89dZbvPPOO2RkZHDmmWeyevVqNm3axPTp05k1axYvv/wyHo+Hnj170tzcbE/P4PP57HOuaZpceOGFzJ49u8P5LzExkcTExA7H8oABAzjnnHNwOp1Mnz6d2bNn89RTT+HxeMjKyqKhoUFdYCeY7gXWxVRWVmIYBllZWYRCIXv4bzAYxOVy2U2m1lwVbrfbHhZ/6F+/zc3N7N+/n6SkJHJycuzHD339/v37CYfD9OzZE4fDQVVVFT6fj+TkZILBIE1NTfZfVXBwHoy2tjZ69uyJz+dr161RWVlJW1sbffr0sf9K01/lp5ampiYOHDhAZmYmSUlJNDc309LSgsfjobq6mry8PEKhED6fjxdffBG/38+MGTPsYmjrwmU53HEKBy88e/fuJRKJ0Lt37w7Hko63U5N1TmlubqaiooKcnBwSExMJBoN4PJ525z84eAzt27cPh8Nhn5csZWVlOBwOevToAUBFRQXJyclUVFSQkpJCcnIybreb8vJy/va3v/GVr3yFjIwMAoEAbre7QzfVkc5/nR3L1vOBQIDy8nLS0tJITU21t0VOHAWgU1TsL+Xxel9nz/2nnyMnp0O/79if9+3bx1NPPcWZZ55Jfn4+RUVFrFy5khtuuIH+/fsf0/KO9pyOt/hxrN/1pzlOYh+fNWsWxcXFXHHFFUQiERYtWkRaWho33njjUd/b2WOf9liWE08BqIuJnZ79eC3raMs79DM7+/nQi97hlns811+6pkO//9jvfNOmTSxfvpxQKERCQoIdhj7N8g73/Kd9Tk5+n/Yc1tlrDz1GrC6upqYmlixZwt69e+1RslOnTrVHnh0pzBxunf7T5+TEUAASkeMuFAp16OoS6YqsuiGNyIo/CkAictwcqYtMpCs5Wsu3nPoUgERERCTuqM1PRERE4o4CkIgcV4dOzPl5LeNI7zke6yQipxZ1gYlIp6xZag8tDj3SEGPoOALn09ZUHGnU4aHLj0Qi9q0HYtc79jWq6RCRzqgFSEQ6sO5L19nImNih74c+bhgGtbW1HDhwwH7s07DCS2VlJbt27bIn7Yz9L5Y1USgcvBdYa2srDoejw+vD4TAHDhwgEAh8qvURkVOXpkwVkQ4Mw+DDDz8kJSWFESNGMHv2bLZu3YrD4WDixIlMmjSpXUtNKBTi+eefZ/To0axevZrGxkbGjh3L1q1bSUhIYPfu3fj9frxeL4FAgNbWVrKzs7nrrrvs+zZZd+A+cOAAv/rVr2hpaeGBBx6gR48e7e7LlJiYaM8SvHLlSqqrq6mqqmLdunWMHj2a7Oxsqqur7Xs+1dTUUFVVRVNTExdffDHXXnutRqeJiAKQiPxbNBq172T9xBNPMGTIEIYPH05jYyPV1dVUV1dTUVFBQUEBCQkJ7W442dbWxty5c+1p/lesWEHPnj3JzMwkEolQW1vL2rVrGTlyJHl5efbtCqww4nQ62bt3L0888QS7du3C5/Pxi1/8gkgkgsPhwO/343Q6+eY3v0nPnj0JBAK89NJLtLa24nQ6GTZsGGPGjGHjxo3s2rWLhIQEmpqa6NWrFwMHDqSkpMS+9YDCj4ioC0xEgPa1NrNmzbJvSOpwOLjhhhv45S9/yW233UZZWRmzZs2yu8JM06SxsZFu3boBB+/P1dzcTHZ2Nunp6YwcOZK+ffuSlpaGw+EgIyODnJwcxo8fj9PpxDAMgsEgixYt4uc//zk1NTVcffXVzJgxg/POO49p06YxefJkWlpaCAQCdnBKTU3ll7/8JV/72tcwDIOrrrqKSZMmEQwGOfPMM/nSl75EXV0d55xzDjfddBMVFRU0Nzd32FYRiU9qARIR4N81PHPnzmX58uWcd955jBo1yp4pNxqNMmHCBFatWsXcuXPJysrioosuAuDAgQOsW7cOv99PXV0dpmnS1tbG7t27CQaDzJ49m7S0NPLy8tiyZQtz5szhpptuYsCAAWzfvp1nnnmGkpISevbsybBhwxg4cCAFBQX2uv3jH/+gqamJL3/5y6SnpwPQ2trKnj17KCkpweFwsHr1agKBAKZpsnTpUs477zx69OhBeXk58+bNo6amhqlTp56QfSsiXY8CkIhgmibBYJA5c+bwxhtvMGbMGO66665OC6Hvvvtu6urqeP7556mpqeGyyy6jX79+3Hnnnaxdu5bS0lIaGxvJyMjgsssuIxqNsmDBAi655BL69+9PQ0MDTz75pN2Sk5WVRXp6OgUFBUycOJF//OMfPPzww0ydOpULLriAefPmsXTpUm644QYuvPBCIpEITqeTqqoqfv3rX+NwOPB6vbz99tts2rSJyy+/nD59+lBeXo7D4aC2tpaMjAzOPPNMdYGJiE3D4EXinFWDs3PnTn7605+SmJjI8OHD6dWrF8FgEIfD0W4eHbfbTWNjI5s3b6a8vJxHH32UtrY2fvGLX9C9e3fcbjfBYJDMzEy2bdvGOeecw9KlS3E4HPb9waqqqrjmmmuYPn16pwXJzz//PIsWLbJD0syZM7n44ovbvcZqAZozZw4bN27k4osv5uyzz+all15iz549GIZBW1sbDoeDlJQU6urquOCCC7j22mvtWicRiV9qARKJc1b46N+/Pw899BCmafLEE0+wbNkynE4n4XDYHm5u3UV76NCh3HvvvVRUVJCTk8N7771HcnIyDzzwAP/4xz8IhUJcdNFF+P1+3G43kUiEiy66iGHDhlFVVcXTTz/dYd6gpqYmioqK2LBhA0VFRfj9flJSUrjyyisZMmQI+/fvJxqNkpiYSEpKCgkJCeTm5lJRUYHX62X9+vWcfvrpdvi68cYb+f3vf8/gwYO58MILefjhh1X7IyI2tQCJSAfV1dW43W6ef/55PvnkEx566CHS0tKIRqM88cQThMNhfvSjHwEdJy584IEHGDFiBHv27GHChAkMGDCAn//85yQnJ9shqqqqimuvvZbLL7+c2bNnU1hYSElJCa2trUSjUXvkl8fjsUeYuVwuIpEIU6dO5aabbgLghRdeYMGCBaSnp9Pa2kpmZibJycns2rWL5ORkmpubcblcJCQkUFFRwWWXXcY111yjFiARUQuQiPybNftzRkYGra2tbNmyhX79+tGvXz/7NcFgkMTExHZz91RUVPD+++8TiURoaWmhvLycYDDIO++8g8/nw+12M3nyZAYMGEB9fT3PPfec/VkNDQ1s376d008/naqqKiorK7n00kvxeDz2/D8Oh4PW1lZmzZpFKBQCYP369SxdupSzzjqLwsJCLr30Uk477TRefPFF0tPTueiii3jttdfIzc1l/PjxPPfcc6r9ERGbApCI2AzDsIPJ/Pnz2b9/v91iYgWe2tpaunfv3m6m5draWlasWEEwGCQcDlNVVUV6ejoej4eamhpCoRDbtm1jz549OBwOAoGAPSvztddey4wZM+jWrRt//etfKSsr45JLLumwbpFIhLlz59rdWBUVFfTu3ZuzzjqLlStXMmDAAHbv3k1xcTFZWVns2LGD5uZmDhw4QFFREW63m40bN3LppZfacxgpEInELwUgEbFZExK+8847vPHGG4waNYrJkyfbz9fV1VFfX28PRbcMGTKExx57jJdffpnZs2fj9Xq59NJLGTt2LBUVFezYsYPi4mKGDx/Ojh076NevH6NGjQLA4/Hg9XoxTdNu3amvr8fv97erE6qvr7dbgwBOP/10BgwYYA99D4fDNDc343Q6CQQC1NTUMHbsWOBgK5MV7tTrLyKgACQi/2KaJgcOHGDBggW89dZb9OnTh9tuu41t27bhcDgIh8MsWbKEQCBAbm6u/R7rv1WrVjFv3jzGjRuHy+XiV7/6FXfddRfDhg2zg8l1113Hs88+S0VFBT6fr937rVFikUiEn/3sZ50GFavLDSA9PZ2MjAzWr1+Py3XwVHbJJZewatUqUlNTeeCBB4CDXXalpaX89Kc/ZdSoUfj9ftUAiYgCkIj8+xYY69atY9asWUyYMIEvfvGLdO/enfvvv5/KykqcTifBYJBhw4Zx2mmnAf+ePHHVqlU8+uijDB06lNtuu42UlBQaGxtZsWIFy5YtY9u2bdx3331kZWXx5S9/mV/+8pc8+eST/OxnP7NrfQCam5tpaGjgtNNOs+8RZn1OKBRi586dtLa2AtjzAUUiERoaGgiHw/bjVkuPYRgUFRXxy1/+EoC+fft+zntWRLoqjQITETssBINB1q5da7fimKZJYWGhHYC8Xi/5+fkkJye3e19LSwvLli3j9NNPJy0tDTg4rN3r9bJjxw7C4TAjRoywg9a+fftobm5m4MCB7ULOunXrKCsr49JLL+1QnxOJRJg/fz65ubmMHj3aXlZFRQVr1qzhjDPOICsri+LiYrxeL3369AEgEAjw8ccfk5GRwaBBgz7HvSoiXZkCkIh06khFwv/Jc9bjx1p8fOipSQXLInI8KQCJSDvRaLTdCC+re8oS+9yR3hcbeGKLl63nrGUdugzTNO06n0NFIhEMw+iwLKs1yPq8Q5dtbYPqfkTEogAkIiIicUd/DomIiEjcUQASERGRuKMAJCIiInFHAUhERETijgKQiIiIxB0FIBEREelyPutB6gpAIiIi0qXEziMWiUQ+k89QABIREZETxmrpWbFiBatXr7bDz5o1a3jppZdoaWlp1xrU2b8P97w1Ceru3btZtGhRu+cVgEREROSEsQLJgQMHOHDgAIZhsGLFCt555x3OPPNMkpOTMQyDSCRCMBhsN8u7daPkQ2egj0aj9gzxcPDehPv377ffY5qm7gYvIiIiJ57T6SQxMZEtW7awcuVKbrzxRnr16gXAmjVr2LRpEw6Hg5ycHC644ALC4TBvv/02VVVVZGVlEY1GmTFjBjt27OCdd94hNTUV0zQpKCjA7/fbt9gpKirigw8+UAuQiIiInHher5cNGzbwxhtvkJubS69evYhGo4RCIXbu3Mmll17KjBkz2LRpE9XV1axZs4YDBw5wzTXXkJyczO7du2loaGDBggVMnDiR888/n5KSEurr6+17CDY3N/P2229z9tlnKwCJiIhI1xAOh7n66qspLS1l7dq1OBwO3G43p512GitXrmThwoU4nU7a2tooKytj7NixJCcnM27cODIyMigtLSU5OZn8/HwyMjI47bTTCIfDALhcLsrKygiFQhQXFysAiYiIyIkXDAYZOXIkgwYN4rzzzuOf//wnTU1N1NbWsmjRIgYMGMAFF1xAUlISbrcbh8Nhh5vGxkaCwSAul8t+DKCurg6Hw2G3ABmGgcvlYsSIEaoBEhERkRMvEAgQiUQwTZPTTjuN4uJiXnjhBc477zy70PmTTz5h37597N+/n0GDBvHhhx8SDAYpKiqitbWV3NxcHA4H8+fPJzU1lW3btjF48GBCoRANDQ306dMHn8/Hzp07MczPeqYhERERkcOwRm4VFxdjGAYDBgwAoK2tjdWrV5Ofn09ZWRlFRUUMGDAAn89HfX09Y8eOZevWrVRXV+P3+9m4cSNf+tKXqKmpobCwkKSkJIqLi+nbty9DhgyhpKSEUaNGUVVVxapVqxSARERE5OSzbNkyqqqqmDJlCh999BH19fVcfPHFvPjii5x77rkkJSUxZ84cLrjgAvLy8jq8//8DAufHVGOz5J4AAAAASUVORK5CYII=
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖顯示了訓練資料集（Training Set）裏頭各個分類所佔的比例。是一個常見的 Unbalanced Dataset：特定的分類佔了數據的大半比例。&lt;/p&gt;
&lt;p&gt;我們可以看到接近 70 % 的「成對新聞」都是不相關的。這邊的「成對新聞」指的是資料集裡，每一行的假新聞標題 A 以及對應的標題 B 所組成的 pairs。&lt;/p&gt;
&lt;p&gt;現在假設測試資料集（Test Set）的數據分佈跟訓練資料集相差不遠，且衡量一個分類模型的指標是準確度（Accuracy）：100 組成對新聞中，模型猜對幾組。&lt;/p&gt;
&lt;p&gt;這時候如果要你用一個簡單法則來分類所有成對新聞，並同時最大化準確度，你會怎麼做？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對沒錯，就是全部猜 &lt;code&gt;unrelated&lt;/code&gt; 就對了！&lt;/p&gt;
&lt;p&gt;事實上，此競賽在 Evaluation 階段使用 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge#evaluation"&gt;Weighted Categorization Accuracy&lt;/a&gt;，來稍微調降猜對 &lt;code&gt;unrelated&lt;/code&gt; 的分數。畢竟（1）能正確判斷出兩個新聞是 &lt;code&gt;unrelated&lt;/code&gt; 跟（2）能判斷出新聞 B &lt;code&gt;disagreed&lt;/code&gt; 假新聞 A 的價值是不一樣的。（後者的價值比較高，因為比較稀有）&lt;/p&gt;
&lt;p&gt;但使用&lt;a href="https://en.wikipedia.org/wiki/Majority_rule"&gt;多數票決（Majority Votes）&lt;/a&gt;的簡單方法還是能得到 0.666 的成績（滿分為 1）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/major-baseline.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過當你前往該 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/leaderboard"&gt;Kaggle 排行榜&lt;/a&gt;的時候，卻會發現不少人低於這個標準：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/find-the-baseline-for-ml.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一次參加 Kaggle 的人可能會覺得這現象很奇怪。&lt;/p&gt;
&lt;p&gt;但這是由於 Kaggle 競賽 1 天只能提交 2 次結果，因此通常不會有人浪費提交次數來上傳「多數票決」的結果（儘管分數會上升，大家還是會想把僅僅 2 次的上傳機會用來測試自己的 ML 模型的準確度）；另外也是因為不少人是上傳 1、2 次就放棄比賽了。&lt;/p&gt;
&lt;p&gt;但如果你的 ML 或深度學習模型怎樣都無法超過一個簡單法則的 baseline 的話，或許最後上傳該 baseline 的結果也不失為提升排名的最後手段（笑）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        找出 Baseline，可以讓我們判斷手上訓練出來的機器學習模型有多少潛在價值、值不值得再繼續花費自己的研究時間與電腦計算能力。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在我們知道，要保證做出來的模型有點價值，最少要超過 baseline 才可以。以本文來說，就是多數票決法則得到的 0.666 準確度。&lt;/p&gt;
&lt;p&gt;（ baseline 的定義依照研究目的以及比較方法而有所不同）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料前處理：讓機器能夠處理文字"&gt;資料前處理：讓機器能夠處理文字&lt;a class="anchor-link" href="#資料前處理：讓機器能夠處理文字"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要讓電腦或是任何 NLP 模型理解一篇新聞標題在說什麼，我們不能將自己已經非常習慣的語言文字直接扔給電腦，而是要轉換成它熟悉的形式：數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mika-baumeister-703680-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此這章節就是介紹一系列的數據轉換步驟，來將人類熟悉的語言如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;用大蒜鉴别地沟油的方法,怎么鉴别地沟油
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;轉換成人腦不易理解，但很「機器友善」的數字序列（Sequence of Numbers）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[217, 1268, 32, 1178, 25, 489, 116]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你對此步驟已經非常熟悉，可以假設我們已經對數據做完必要的處理，直接跳到下一章的&lt;a href="#有記憶的循環神經網路_1"&gt;有記憶的循環神經網路&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;這章節的數據轉換步驟包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#文本分詞"&gt;文本分詞（Text Segmentation）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#建立字典並將文本轉成數字序列"&gt;建立字典並將文本轉成數字序列&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#序列的-Zero-Padding"&gt;序列的 Zero Padding&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你現在不知道上述所有詞彙的意思，別擔心！&lt;/p&gt;
&lt;p&gt;你接下來會看到文字數據在丟入機器學習 / 深度學習模型之前，通常需要經過什麼轉換步驟。搭配說明，我相信你可以輕易地理解以下每個步驟的邏輯。&lt;/p&gt;
&lt;p&gt;在這之前，先讓我們用 &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; 將訓練資料集讀取進來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;TRAIN_CSV_PATH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;tid1&lt;/th&gt;
&lt;th&gt;tid2&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title1_en&lt;/th&gt;
&lt;th&gt;title2_en&lt;/th&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;There are two new old-age insurance benefits f...&lt;/td&gt;
&lt;td&gt;Police disprove "bird's nest congress each per...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;"If you do not come to Shenzhen, sooner or lat...&lt;/td&gt;
&lt;td&gt;Shenzhen's GDP outstrips Hong Kong? Shenzhen S...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;"If you do not come to Shenzhen, sooner or lat...&lt;/td&gt;
&lt;td&gt;The GDP overtopped Hong Kong? Shenzhen clarifi...&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟我們在 Kaggle 預覽的數據一致。不過為了畫面簡潔，讓我們只選取 2 個中文新聞標題以及分類結果（Label）的欄位：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cols&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="s1"&gt;'label'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="n"&gt;cols&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;unrelated&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了必要的欄位以後，我們可以開始進行數據的前處理了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="文本分詞"&gt;文本分詞&lt;a class="anchor-link" href="#文本分詞"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Text_segmentation"&gt;文本分詞（Text Segmentation）&lt;/a&gt;是一個將一連串文字切割成多個有意義的單位的步驟。這單位可以是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個中文漢字 / 英文字母（Character）&lt;/li&gt;
&lt;li&gt;一個中文詞彙 / 英文單字（Word）&lt;/li&gt;
&lt;li&gt;一個中文句子 / 英文句子（Sentence）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照不同的 NLP 任務會有不同切割需求，但很常見的切法是以單字（Word）為單位，也就是 Word Segmentation。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/word-segmentation.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以英文來說，Word Segmentation 十分容易。通常只要依照空白分割，就能得到一個有意義的詞彙列表了（在這邊讓我們先無視標點符號）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'I am Meng Lee, a data scientist based in Tokyo.'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['I', 'am', 'Meng', 'Lee,', 'a', 'data', 'scientist', 'based', 'in', 'Tokyo.']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很明顯地，中文無法這樣做。這時候我們將藉助 &lt;a href="https://github.com/fxsjy/jieba"&gt;Jieba&lt;/a&gt; 這個中文斷詞工具，來為一連串的文字做有意義的切割：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jieba.posseg&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pseg&lt;/span&gt;

&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'我是李孟，在東京工作的數據科學家'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[pair('我', 'r'),
 pair('是', 'v'),
 pair('李孟', 'nr'),
 pair('，', 'x'),
 pair('在', 'p'),
 pair('東京', 'ns'),
 pair('工作', 'vn'),
 pair('的', 'uj'),
 pair('數據', 'n'),
 pair('科學家', 'n')]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如上所示，Jieba 將我們的中文文本切成有意義的詞彙列表，並為每個詞彙附上對應的詞性（Flag）。&lt;/p&gt;
&lt;p&gt;假設我們不需要標點符號，則只要將 &lt;code&gt;flag == x&lt;/code&gt; 的詞彙去除即可。&lt;/p&gt;
&lt;p&gt;我們可以寫一個很簡單的 Jieba 斷詞函式，此函式能將輸入的文本 &lt;code&gt;text&lt;/code&gt; 斷詞，並回傳除了標點符號以外的詞彙列表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以利用 Pandas 的 &lt;code&gt;apply&lt;/code&gt; 函式，將 &lt;code&gt;jieba_tokenizer&lt;/code&gt; 套用到所有新聞標題 A 以及 B 之上，做文本分詞：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
         &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
         &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新聞標題 A 的斷詞結果如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title1_tokenized&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017养老保险又新增两项，农村老人人人可申领，你领到了吗&lt;/td&gt;
&lt;td&gt;2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;"你不来深圳，早晚你儿子也要来"，不出10年深圳人均GDP将超香港&lt;/td&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;"用大蒜鉴别地沟油的方法,怎么鉴别地沟油&lt;/td&gt;
&lt;td&gt;用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新聞標題 B 的結果則為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title2_tokenized&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;警方辟谣&amp;ldquo;鸟巢大会每人领5万&amp;rdquo; 仍有老人坚持进京&lt;/td&gt;
&lt;td&gt;警方 辟谣 鸟巢 大会 每人 领 5 万 仍 有 老人 坚持 进京&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;深圳GDP首超香港？深圳统计局辟谣：只是差距在缩小&lt;/td&gt;
&lt;td&gt;深圳 GDP 首 超 香港 深圳 统计局 辟谣 只是 差距 在 缩小&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;GDP首超香港？深圳澄清：还差一点点&amp;hellip;&amp;hellip;&lt;/td&gt;
&lt;td&gt;GDP 首 超 香港 深圳 澄清 还 差 一点点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;去年深圳GDP首超香港？深圳统计局辟谣：还差611亿&lt;/td&gt;
&lt;td&gt;去年 深圳 GDP 首 超 香港 深圳 统计局 辟谣 还 差 611 亿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;吃了30年食用油才知道，一片大蒜轻松鉴别地沟油&lt;/td&gt;
&lt;td&gt;吃 了 30 年 食用油 才 知道 一片 大蒜 轻松 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;太棒了，將新聞標題切割成一個個有意義的詞彙以後，我們就能進入下一個步驟了！&lt;/p&gt;
&lt;p&gt;另外值得一提的是，不管最後是使用哪種切法，切完之後的每個文字片段在 NLP 領域裡頭習慣上會被稱之為 Token。（如上例中的警方、GDP）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建立字典並將文本轉成數字序列"&gt;建立字典並將文本轉成數字序列&lt;a class="anchor-link" href="#建立字典並將文本轉成數字序列"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當我們將完整的新聞標題切成一個個有意義的詞彙（Token）以後，下一步就是將這些詞彙轉換成一個數字序列，方便電腦處理。&lt;/p&gt;
&lt;p&gt;這些數字是所謂的索引（Index），分別對應到特定的詞彙。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/erik-mclean-1118005-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了方便你理解這小節的概念，想像個極端的例子。假設我們現在就只有一個新聞標題：「狐狸被陌生人拍照」。&lt;/p&gt;
&lt;p&gt;這時候要怎麼將這個句子轉成一個數字的序列呢？跟上一小節相同，我們首先會對此標題做斷詞，將句子分成多個有意義的詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'狐狸被陌生人拍照'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['狐狸', '被', '陌生人', '拍照']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了詞彙的列表以後，我們可以建立一個字典 &lt;code&gt;word_index&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;該 dict 裏頭將上面的 4 個詞彙當作鍵值（Key），每個鍵值對應的值（Value）則為不重複的數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;  
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;word_index&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;{'狐狸': 0, '被': 1, '陌生人': 2, '拍照': 3}&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這個字典以後，我們就能把該句子轉成一個數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['狐狸', '被', '陌生人', '拍照']
[0, 1, 2, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;簡單明瞭，不是嗎？&lt;/p&gt;
&lt;p&gt;如果來了一個新的句子：「陌生人被狐狸拍照」，我們也能利用手上已有的字典 &lt;code&gt;word_index&lt;/code&gt; 如法炮製：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'陌生人被狐狸拍照'&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pseg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;word_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['陌生人', '被', '狐狸', '拍照']
[2, 1, 0, 3]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個簡單的狐狸例子裡頭，&lt;code&gt;word_index&lt;/code&gt; 就是我們的字典；我們利用該字典，將 1 句話轉成包含多個數字的序列，而每個數字實際上代表著一個 Token。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同理，我們可以分 4 個步驟將手上的新聞標題全部轉為數字序列：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將已被斷詞的新聞標題 A 以及新聞標題 B 全部倒在一起&lt;/li&gt;
&lt;li&gt;建立一個空字典&lt;/li&gt;
&lt;li&gt;查看所有新聞標題，裏頭每出現一個字典裡頭沒有的詞彙，就為該詞彙指定一個字典裡頭還沒出現的索引數字，並將該詞彙放入字典&lt;/li&gt;
&lt;li&gt;利用建好的字典，將每個新聞標題裡頭包含的詞彙轉換成數字&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/text-corpus.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這種文字前處理步驟因為出現頻率實在太過頻繁，Keras 有專門的文字前處理模組來提升我們的效率：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt;
&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;
&lt;span class="n"&gt;tokenizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tokenizer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_words&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Tokenizer 顧名思義，即是將一段文字轉換成一系列的詞彙（Tokens），並為其建立字典。這邊的 &lt;code&gt;num_words=10000&lt;/code&gt; 代表我們限制字典只能包含 10,000 個詞彙，一旦字典達到這個大小以後，剩餘的新詞彙都會被視為 Unknown，以避免字典過於龐大。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同上述的步驟 1，我們得將新聞 A 及新聞 B 的標題全部聚集起來，為它們建立字典：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;corpus_x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title1_tokenized&lt;/span&gt;
&lt;span class="n"&gt;corpus_x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title2_tokenized&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="n"&gt;corpus_x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;corpus_x2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(641086,)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為訓練集有大約 32 萬列（Row）的成對新聞（每一列包含 2 筆新聞：A &amp;amp; B），因此將所有新聞放在一起的話，就有 2 倍的大小。而這些文本的集合在習慣上被稱作語料庫（Text Corpus），代表著我們有的所有文本數據。&lt;/p&gt;
&lt;p&gt;以下是我們語料庫的一小部分：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
             &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;title&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;2017 养老保险 又 新增 两项 农村 老人 人人 可 申领 你 领到 了 吗&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;你 不 来 深圳 早晚 你 儿子 也 要 来 不出 10 年 深圳 人均 GDP 将 超 香港&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;td&gt;用 大蒜 鉴别 地沟油 的 方法 怎么 鉴别 地沟油&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了語料庫以後，接下來就是呼叫 &lt;code&gt;tokenizer&lt;/code&gt; 為我們查看所有文本，並建立一個字典（步驟 2 &amp;amp; 3）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit_on_texts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以我們的語料庫大小來說，這大約需時 10 秒鐘。而等到 &lt;code&gt;tokenizer&lt;/code&gt; 建好字典以後，我們可以進行上述第 4 個步驟，請 &lt;code&gt;tokenizer&lt;/code&gt; 利用內部生成的字典分別將我們的新聞標題 A 與 新聞 B 轉換成數字序列：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_x1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corpus_x2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們看看結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;320543&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[[217, 1268, 32, 1178, 5967, 25, 489, 2877, 116, 5559, 4, 1850, 2, 13]]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;x1_train&lt;/code&gt; 為一個 Python &lt;code&gt;list&lt;/code&gt;，裡頭包含了每一筆假新聞標題 A 對應的數字序列。&lt;/p&gt;
&lt;p&gt;讓我們利用 &lt;code&gt;tokenizer.index_word&lt;/code&gt; 來將索引數字對應回本來的詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;['2017', '养老保险', '又', '新增', '两项', '农村', '老人', '人人', '可', '申领', '你', '领到', '了', '吗']
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;輕鬆寫意，不是嗎？&lt;/p&gt;
&lt;p&gt;到此為止，我們已經將所有新聞標題轉換成電腦容易處理的數字序列，進入下個步驟！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="序列的-Zero-Padding"&gt;序列的 Zero Padding&lt;a class="anchor-link" href="#序列的-Zero-Padding"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們已經將每個新聞標題的文本轉為一行行的數字序列，你會發現每篇標題的序列長度並不相同：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s1"&gt;' ...'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;14 [217, 1268, 32, 1178, 5967]  ...
19 [4, 10, 47, 678, 2558]  ...
19 [4, 10, 47, 678, 2558]  ...
19 [4, 10, 47, 678, 2558]  ...
9 [31, 320, 3372, 3062, 1]  ...
19 [4, 10, 47, 678, 2558]  ...
6 [7, 2221, 1, 2072, 7]  ...
19 [4, 10, 47, 678, 2558]  ...
14 [1281, 1211, 427, 3, 3244]  ...
9 [31, 320, 3372, 3062, 1]  ...
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最長的序列甚至達到 61 個詞彙：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;max_seq_len&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;max&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;
    &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;max_seq_len&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;61&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而為了方便之後的 NLP 模型處理（見&lt;a href="#有記憶的循環神經網路"&gt;循環神經網路&lt;/a&gt;一章），一般會設定一個 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt; 來讓所有序列的長度一致。&lt;/p&gt;
&lt;p&gt;長度超過此數字的序列尾巴會被刪掉；而針對原來長度不足的序列，我們則會在詞彙前面補零。Keras 一樣有個方便函式 &lt;code&gt;pad_sequences&lt;/code&gt; 來幫助我們完成這件工作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
&lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                   &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;x2_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                   &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt; 可以設定成最長序列的長度（此例中的 61）。但這邊為了讓模型可以只看前 20 個詞彙就做出判斷以節省訓練時間，我們先暫時使用 20 這個數字。&lt;/p&gt;
&lt;p&gt;讓我們看看經過 Zero Padding 的第一篇假新聞標題 A 變成什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([   0,    0,    0,    0,    0,    0,  217, 1268,   32, 1178, 5967,
         25,  489, 2877,  116, 5559,    4, 1850,    2,   13], dtype=int32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以清楚看到，因為該新聞標題原本的序列長度並沒有達到剛剛設定的 &lt;code&gt;MAX_SEQUENCE_LENGTH&lt;/code&gt;，因此在總長度為 20 的序列中，前面 6 個值被 Keras 補上 0 以說明該序列中的前 6 個詞彙並不存在。&lt;/p&gt;
&lt;p&gt;我們還可以發現，所有的新聞標題都被轉成長度為 20 的數字序列了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x1_train&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
    
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"所有新聞標題的序列長度皆為 20 !"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;所有新聞標題的序列長度皆為 20 !
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再看一次轉換後的新聞標題：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[   0,    0,    0,    0,    0,    0,  217, 1268,   32, 1178, 5967,
          25,  489, 2877,  116, 5559,    4, 1850,    2,   13],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    4,   10,   47,  678, 2558,    4,  166,   34,   17,   47,
        5150,   63,   15,  678, 4502, 3211,   23,  284, 1181],
       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
          31,  320, 3372, 3062,    1,   95,   98, 3372, 3062]],
      dtype=int32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，可以看到前 5 個新聞標題都已經各自被轉換為長度為 20 的數字序列，而序列裡頭的每個數字則對應到字典裡頭一個特定的 Token，整整齊齊。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/pop-zebra-754186-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，我們已經將原本以自然語言呈現的新聞標題轉換成機器容易理解的數字序列了。很神奇，不是嗎？&lt;/p&gt;
&lt;p&gt;喔不過，別忘了還有 &lt;code&gt;label&lt;/code&gt; 這個文字欄位等著我們的處理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;a class="anchor-link" href="#將正解做-One-hot-Encoding"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到目前為止，我們已經將所有的新聞標題以數字型態表示，只剩分類欄位 &lt;code&gt;label&lt;/code&gt; 要進行從文本到數字的轉換了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;id
0    unrelated
3    unrelated
1    unrelated
2    unrelated
9       agreed
Name: label, dtype: object&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過 &lt;code&gt;label&lt;/code&gt; 的處理相對簡單。跟新聞標題相同，我們一樣需要一個字典將分類的文字轉換成索引：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt; 

&lt;span class="c1"&gt;# 定義每一個分類對應到的索引數字&lt;/span&gt;
&lt;span class="n"&gt;label_to_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'unrelated'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'agreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'disagreed'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# 將分類標籤對應到剛定義的數字&lt;/span&gt;
&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;label_to_index&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asarray&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; \
            &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'float32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([0., 0., 0., 0., 1.], dtype=float32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在每個分類的文字標籤都已經被轉成對應的數字，接著讓我們利用 Keras 做 &lt;a href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f"&gt;One Hot Encoding&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utils&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to_categorical&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([[1., 0., 0.],
       [1., 0., 0.],
       [1., 0., 0.],
       [1., 0., 0.],
       [0., 1., 0.]], dtype=float32)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上述矩陣的每一列即為 1 個 label，而你可以看到現在每個 label 都從 1 個數字變成一個 3 維的向量（Vector）。&lt;/p&gt;
&lt;p&gt;每 1 維度則對應到 1 個分類：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;[1, 0, 0]&lt;/code&gt; 代表 label 為 &lt;code&gt;unrelated&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[0, 1, 0]&lt;/code&gt; 代表 label 為 &lt;code&gt;agreed&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[0, 0, 1]&lt;/code&gt; 代表 label 為 &lt;code&gt;disagreed&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用這樣的方式表達 label 的好處是我們可以把分類結果想成機率分佈。&lt;code&gt;[1, 0, 0]&lt;/code&gt; 就代表一組新聞標題 A、B 為 &lt;code&gt;unrelated&lt;/code&gt; 的機率等於 100 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-encoding.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        One Hot Encoding 示意圖
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="#決定如何衡量模型的表現"&gt;決定如何衡量模型的表現&lt;/a&gt;一節我們會看到，給定一組新聞標題 A、B，我們的模型會預測此成對標題屬於每個分類的機率值，比方說 &lt;code&gt;[0.7,  0.2, 0.1]&lt;/code&gt;。而此預測結果代表模型認為這 2 個新聞標題的關係有 70 % 的機率為 &lt;code&gt;unrelated&lt;/code&gt;、20 % 的機率是 &lt;code&gt;agreed&lt;/code&gt; 而 10 % 為 &lt;code&gt;disagreed&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，如果正解也事先用同樣的方式表達的話，會讓我們比較好計算以下兩者之間的差距：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正確的分類的機率分佈（&lt;code&gt;[1, 0, 0]&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;模型預測出的機率分佈（&lt;code&gt;[0.7,  0.2, 0.1]&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在知道預測結果跟正確解答之間差距多少之後，深度學習模型就會自動修正學習方向，想盡辦法拉近這個差距。&lt;/p&gt;
&lt;p&gt;好，到此為止所有的數據都已經被我們轉換成方便機器使用的格式了。最後，讓我們將整個資料集拆成&lt;a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets"&gt;訓練資料集 &amp;amp; 驗證資料集&lt;/a&gt; 以方便之後測試模型的效能。&lt;/p&gt;
&lt;p&gt;（別哀號，我保證這是最後的前處理步驟了！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="切割訓練資料集-&amp;amp;-驗證資料集"&gt;切割訓練資料集 &amp;amp; 驗證資料集&lt;a class="anchor-link" href="#切割訓練資料集-&amp;amp;-驗證資料集"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這部分很簡單，我們只需決定要將整個訓練資料集（Training Set）的多少比例切出來當作驗證資料集（Validation Set）。此例中我們用 10 %。&lt;/p&gt;
&lt;p&gt;但為何要再把本來的訓練資料集切成 2 個部分呢？&lt;/p&gt;
&lt;p&gt;一般來說，我們在訓練時只會讓模型看到訓練資料集，並用模型沒看過的驗證資料集來測試該模型在真實世界的表現。（畢竟我們沒有測試資料集的答案）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/train-valid-test-split.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們會反覆在 Train / Valid Set 上訓練並測試模型，最後用 Test Set 一決生死
                        （&lt;a href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;等到模型在驗證資料集也表現得夠好後，便在最終的測試資料集（Test Set）進行最後一次的預測並將該結果上傳到 Kaggle。&lt;/p&gt;
&lt;p&gt;要了解為何我們需要驗證資料集可以查看&lt;a href="https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set"&gt;這邊的討論&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;簡而言之，當你多次利用驗證資料集的預測結果以修正模型，並讓它在該資料集表現更好時，&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適（Overfitting）&lt;/a&gt;的風險就已經產生了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/cat-peep.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        反覆利用驗證資料集的結果來修正模型表現，事實上就等於讓模型「偷看」到驗證資料集本身的資訊了
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管你沒有直接讓模型看到驗證資料集（Validation Set）內的任何數據，你還是間接地洩漏了該資料集的重要資訊：你讓模型知道怎樣的參數設定會讓它在該資料集表現比較好，亦或表現較差。&lt;/p&gt;
&lt;p&gt;因此有一個完全跟模型訓練過程獨立的測試資料集（Test Set）就顯得重要許多了。（這也是為何我到現在都還沒有碰它的原因）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        機器學習模型努力從夏令營（訓練及驗證資料集）學習技能，並在真實世界（測試資料集）展示其學習結果。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;回歸正題，要切訓練資料集 / 驗證資料集，&lt;a href="https://scikit-learn.org/stable/documentation.html"&gt;scikit-learn&lt;/a&gt; 中的 &lt;code&gt;train_test_split&lt;/code&gt; 函式是一個不錯的選擇：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; \
    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;train_test_split&lt;/span&gt;

&lt;span class="n"&gt;VALIDATION_RATIO&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;
&lt;span class="c1"&gt;# 小彩蛋&lt;/span&gt;
&lt;span class="n"&gt;RANDOM_STATE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;9527&lt;/span&gt;

&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x1_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
&lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;test_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;VALIDATION_RATIO&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;RANDOM_STATE&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，我們分別將新聞標題 A &lt;code&gt;x1_train&lt;/code&gt;、新聞標題 B &lt;code&gt;x2_train&lt;/code&gt; 以及分類標籤 &lt;code&gt;y_train&lt;/code&gt; 都分成兩個部分：訓練部分 &amp;amp; 驗證部分。&lt;/p&gt;
&lt;p&gt;以假新聞 A 的標題 &lt;code&gt;x1_train&lt;/code&gt; 為例，本來完整 32 萬筆的 &lt;code&gt;x1_train&lt;/code&gt; 會被分為包含 90 % 數據的訓練資料集 &lt;code&gt;x1_train&lt;/code&gt; 以及 10 % 的驗證資料集 &lt;code&gt;x1_val&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Training Set"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x1_train: &lt;/span&gt;&lt;span class="si"&gt;{x1_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x2_train: &lt;/span&gt;&lt;span class="si"&gt;{x2_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"y_train : &lt;/span&gt;&lt;span class="si"&gt;{y_train.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x1_val:   &lt;/span&gt;&lt;span class="si"&gt;{x1_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"x2_val:   &lt;/span&gt;&lt;span class="si"&gt;{x2_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"y_val :   &lt;/span&gt;&lt;span class="si"&gt;{y_val.shape}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"-"&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Test Set"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;Training Set
----------
x1_train: (288488, 20)
x2_train: (288488, 20)
y_train : (288488, 3)
----------
x1_val:   (32055, 20)
x2_val:   (32055, 20)
y_val :   (32055, 3)
----------
Test Set
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以看到，切割後的訓練資料集有 288,488 筆資料。每一筆資料裡頭，成對新聞標題 A &amp;amp; B 的長度皆為 20 個 Tokens，分類結果則有 3 個；驗證資料集的內容一模一樣，僅差在資料筆數較少（32,055 筆）。&lt;/p&gt;
&lt;p&gt;到此為此，資料前處理大功告成！&lt;/p&gt;
&lt;p&gt;既然我們已經為機器準備好它們容易理解的數字序列資料，接著就讓我們來看看要使用怎麼樣的 NLP 模型來處理這些數據。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="有記憶的循環神經網路_1"&gt;有記憶的循環神經網路&lt;a class="anchor-link" href="#有記憶的循環神經網路"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對這次的 Kaggle 競賽，我們將使用&lt;a href="https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;循環神經網路（Recurrent Neural Network, 後簡稱 RNN）&lt;/a&gt;來處理剛剛得到的序列數據。&lt;/p&gt;
&lt;p&gt;RNN 是一種有「記憶力」的神經網路，其最為人所知的形式如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同上圖等號左側所示，RNN 跟一般深度學習中常見的&lt;a href="https://en.wikipedia.org/wiki/Feedforward_neural_network"&gt;前饋神經網路（Feedforward Neural Network, 後簡稱 FFNN）&lt;/a&gt;最不一樣的地方在於它有一個迴圈（Loop）。&lt;/p&gt;
&lt;p&gt;要了解這個迴圈在 RNN 裏頭怎麼運作，現在讓我們想像有一個輸入序列 X（Input Sequence）其長相如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = [ x0, x1, x2, ... xt ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;不同於 FFNN，RNN 在第一個時間點 &lt;code&gt;t0&lt;/code&gt; 並不會直接把整個序列 X 讀入。反之，在第一個時間點 &lt;code&gt;t0&lt;/code&gt;，它只將該序列中的第一個元素 &lt;code&gt;x0&lt;/code&gt; 讀入中間的細胞 A。細胞 A 則會針對 &lt;code&gt;x0&lt;/code&gt; 做些處理以後，更新自己的「狀態」並輸出第一個結果 &lt;code&gt;h0&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在下個時間點 &lt;code&gt;t1&lt;/code&gt;，RNN 如法炮製，讀入序列 X 中的下一個元素 &lt;code&gt;x1&lt;/code&gt;，並利用剛剛處理完 &lt;code&gt;x0&lt;/code&gt; 得到的細胞狀態，處理 &lt;code&gt;x1&lt;/code&gt; 並更新自己的狀態（也被稱為記憶），接著輸出另個結果 &lt;code&gt;h1&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剩下的 &lt;code&gt;xt&lt;/code&gt; 都會被以同樣的方式處理。但不管輸入的序列 X 有多長，RNN 的本體從頭到尾都是等號左邊的樣子：迴圈代表細胞 A 利用「上」一個時間點（比方說 &lt;code&gt;t1&lt;/code&gt;）儲存的狀態，來處理當下的輸入（比方說 &lt;code&gt;x2&lt;/code&gt; ）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-static.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但如果你將不同時間點（&lt;code&gt;t0&lt;/code&gt;、&lt;code&gt;t1&lt;/code&gt; ...）的 RNN 以及它的輸入一起截圖，並把所有截圖從左到右一字排開的話，就會長得像等號右邊的形式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將 RNN 以右邊的形式表示的話，你可以很清楚地了解，當輸入序列越長，向右展開的 RNN 也就越長。（模型也就需要訓練更久時間，這也是為何我們在資料前處理時&lt;a href="#序列的-Zero-Padding"&gt;設定了序列的最長長度&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;為了確保你 100 % 理解 RNN，讓我們假設剛剛的序列 X 實際上是一個內容如下的英文問句：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;X = [ What, time, is, it, ? ]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而且 RNN 已經處理完前兩個元素 &lt;code&gt;What&lt;/code&gt; 和 &lt;code&gt;time&lt;/code&gt; 了。&lt;/p&gt;
&lt;p&gt;則接下來 RNN 會這樣處理剩下的句子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-animate.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 一次只讀入並處理序列的「一個」元素
                        （&lt;a href="https://www.youtube.com/watch?time_continue=2&amp;amp;v=LHXXI4-IEns" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你可以想像為何 RNN 非常適合拿來處理像是自然語言這種序列數據了。&lt;/p&gt;
&lt;p&gt;就像你現在閱讀這段話一樣，你是由左到右逐字在大腦裡處理我現在寫的文字，同時不斷地更新你腦中的記憶狀態。&lt;/p&gt;
&lt;p&gt;每當下個詞彙映入眼中，你腦中的處理都會跟以下兩者相關：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前面所有已讀的詞彙&lt;/li&gt;
&lt;li&gt;目前腦中的記憶狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然，實際人腦的閱讀機制更為複雜，但 RNN 抓到這個處理精髓，利用內在迴圈以及細胞內的「記憶狀態」來處理序列資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/thought-catalog-196661-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        RNN 按照順序，處理一連串詞彙的機制跟我們理解自然語言的方式有許多相似之處
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，你應該已經了解 RNN 的基本運作方式了。現在你可能會問：「那我們該如何實作一個 RNN 呢？」&lt;/p&gt;
&lt;p&gt;好問題，以下是一個簡化到不行的 RNN 實現：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;input_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;output_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output_t&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在 RNN 每次讀入任何新的序列數據前，細胞 A 中的記憶狀態 &lt;code&gt;state_t&lt;/code&gt; 都會被初始化為 0。&lt;/p&gt;
&lt;p&gt;接著在每個時間點 &lt;code&gt;t&lt;/code&gt;，RNN 會重複以下步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;讀入 &lt;code&gt;input_sequence&lt;/code&gt; 序列中的一個新元素 &lt;code&gt;input_t&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;f&lt;/code&gt; 函式將當前細胞的狀態 &lt;code&gt;state_t&lt;/code&gt; 以及輸入 &lt;code&gt;input_t&lt;/code&gt; 做些處理產生 &lt;code&gt;output_t&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;輸出 &lt;code&gt;output_t&lt;/code&gt; 並同時更新自己的狀態 &lt;code&gt;state_t&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不需要自己發明輪子，在 Keras 裏頭只要 2 行就可以建立一個 RNN layer：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;rnn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SimpleRNN&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用深度學習框架可以幫我們省下非常多的寶貴時間並避免可能的程式錯誤。&lt;/p&gt;
&lt;p&gt;我們後面還會看到，一個完整的神經網路通常會分成好幾層（layer）：每一層取得前一層的結果作為輸入，進行特定的資料轉換後再輸出給下一層。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/nn-layers.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        常見的神經網路形式。中間紅框內有迴圈的就是 RNN 層
                        （&lt;a href="https://www.slideshare.net/microlife/from-neural-networks-to-deep-learning" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，相信你現在已經掌握基本 RNN 了。事實上，除了 &lt;code&gt;SimpleRNN&lt;/code&gt; 以外，Keras 裡頭還有其他更常被使用的 Layer，現在就讓我們看看一個知名的例子：長短期記憶。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="記憶力好的-LSTM-細胞"&gt;記憶力好的 LSTM 細胞&lt;a class="anchor-link" href="#記憶力好的-LSTM-細胞"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們再看一次前面的簡易 RNN 實作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
&lt;span class="c1"&gt;# 細胞 A 會重複執行以下處理&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;input_t&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;input_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;output_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;input_t&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;state_t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;state_t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;output_t&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在了解 RNN 的基本運作方式以後，你會發現 RNN 真正的魔法，事實上藏在細胞 A 的 &lt;code&gt;f&lt;/code&gt; 函式裏頭。&lt;/p&gt;
&lt;p&gt;要如何將細胞 A 當下的記憶 &lt;code&gt;state_t&lt;/code&gt; 與輸入 &lt;code&gt;input_t&lt;/code&gt; 結合，才能產生最有意義的輸出 &lt;code&gt;output_t&lt;/code&gt; 呢？&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;SimpleRNN&lt;/code&gt; 的細胞 A 裡頭，這個 &lt;code&gt;f&lt;/code&gt; 的實作很簡單。而這導致其記憶狀態 &lt;code&gt;state_t&lt;/code&gt; 沒辦法很好地「記住」前面處理過的序列元素，造成 RNN 在處理後來的元素時，就已經把前面重要的資訊給忘記了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/forget-what-had-said-before.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就好像一個人在講了好長一段話以後，忘了前面到底講過些什麼的情境。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6"&gt;長短期記憶（Long Short-Term Memory, 後簡稱 LSTM）&lt;/a&gt;就是被設計來解決 RNN 的這個問題。&lt;/p&gt;
&lt;p&gt;如下圖所示，你可以把 LSTM 想成是 RNN 中用來實現細胞 A 內部處理邏輯的一個特定方法：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/lstm-cell.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        以抽象的層次來看，LSTM 就是實現 RNN 中細胞 A 邏輯的一個方式
                        （&lt;a href="https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基本上一個 LSTM 細胞裡頭會有 3 個閘門（Gates）來控制細胞在不同時間點的記憶狀態：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Forget Gate：決定細胞是否要遺忘目前的記憶狀態&lt;/li&gt;
&lt;li&gt;Input Gate：決定目前輸入有沒有重要到值得處理&lt;/li&gt;
&lt;li&gt;Output Gate：決定更新後的記憶狀態有多少要輸出&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這些閘門控管機制，LSTM 可以將很久以前的記憶狀態儲存下來，在需要的時候再次拿出來使用。值得一提的是，這些閘門的參數也都是神經網路自己訓練出來的。&lt;/p&gt;
&lt;p&gt;下圖顯示各個閘門所在的位置：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/lstm-cell-detailed.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        LSTM 細胞頂端那條 cell state 正代表著細胞記憶的轉換過程
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想像 LSTM 細胞裡頭的記憶狀態是一個包裹，上面那條直線就代表著一個輸送帶。&lt;/p&gt;
&lt;p&gt;LSTM 可以把任意時間點的記憶狀態（包裹）放上該輸送帶，然後在未來的某個時間點將其原封不動地取下來使用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/accumulation-conveyor-101.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為這樣的機制，讓 LSTM 即使面對很長的序列數據也能有效處理，不遺忘以前的記憶。&lt;/p&gt;
&lt;p&gt;因為效果卓越，LSTM 非常廣泛地被使用。事實上，當有人跟你說他用 RNN 做了什麼 NLP 專案時，有 9 成機率他是使用 LSTM 或是 &lt;a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit"&gt;GRU（LSTM 的改良版，只使用 2 個閘門）&lt;/a&gt; 來實作，而不是使用最簡單的 &lt;code&gt;SimpleRNN&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，在這次 Kaggle 競賽中，我們的第一個模型也將使用 LSTM。而在 Keras 裡頭要使用 LSTM 也是輕鬆寫意：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;lstm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在，既然我們已經有了在&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理步驟&lt;/a&gt;被轉換完成的序列數據，也決定好要使用 LSTM 作為我們的 NLP 模型，接著就讓我們試著將這些數據讀入 LSTM 吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="詞向量：將詞彙表達成有意義的向量"&gt;詞向量：將詞彙表達成有意義的向量&lt;a class="anchor-link" href="#詞向量：將詞彙表達成有意義的向量"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在將序列數據塞入模型之前，讓我們重新檢視一下數據。比方說，以下是在訓練資料集裡頭前 5 筆的假新聞標題 A：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"新聞標題 {i + 1}: "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題 1: 
[   0    0    0  185  300   72 4029   37    1  121  250   95   30  511
   92 2358   33 2565   19   55]

新聞標題 2: 
[   0    0    0    0    0    0    0    0    0    0    0    0    0 7149
   54  130 8454 3404 6172   66]

新聞標題 3: 
[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0   87 6339   59 5236 2848]

新聞標題 4: 
[   0    0    0    0    0    0    0   59   18 1780    1   63   30 2526
 1017 1466   25   11  139   50]

新聞標題 5: 
[   0    0    0    0    0   25    9   24 1402   12  667   63   64  483
 9523  303 1402   18  332 3258]

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可以看到，每個新聞標題都被轉成長度為 20 的數字序列。裡頭的每個數字都代表著一個詞彙（ &lt;code&gt;0&lt;/code&gt; 代表 &lt;a href="#序列的-Zero-Padding"&gt;Zero Padding&lt;/a&gt;）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(288488, 20)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而我們在訓練資料集則總共有 288,488 筆新聞標題，每筆標題如同剛剛所說的，是一個包含 20 個數字的序列。&lt;/p&gt;
&lt;p&gt;當然，我們可以用 &lt;code&gt;tokenizer&lt;/code&gt; 裡頭的字典 &lt;code&gt;index_word&lt;/code&gt; 還原文本看看：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"新聞標題 {i + 1}: "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;tokenizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;index_word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seq&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題 1: 
['', '', '', '皮肤', '白', '到', '逆', '天', '的', '范冰冰', '美白', '方法', '大', '揭秘', '做', '面膜', '个', '小动作', '就', '可以']

新聞標題 2: 
['', '', '', '', '', '', '', '', '', '', '', '', '', '张家口', '一个', '男子', '持', '猛', '踹', '孩子']

新聞標題 3: 
['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '种', '杂草', '农民', '年收入', '几十万']

新聞標題 4: 
['', '', '', '', '', '', '', '农民', '能', '享受', '的', '10', '大', '政府', '特别', '补助', '农村', '人', '得', '知道']

新聞標題 5: 
['', '', '', '', '', '农村', '这', '3', '类人', '有', '近', '10', '万', '宅基地', '补偿款', '还有', '类人', '能', '免费', '住房']

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其他新聞標題像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;訓練資料集中的新聞標題 B &lt;code&gt;x2_train&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;驗證資料集中的新聞標題 A &lt;code&gt;x1_val&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;驗證資料集中的新聞標題 B &lt;code&gt;x2_val&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也都是以這樣的數字序列形式被儲存。&lt;/p&gt;
&lt;p&gt;但事實上要讓神經網路能夠處理標題序列內的詞彙，我們要將它們表示成向量（更精準地說，是&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B5%E9%87%8F"&gt;張量：Tensor&lt;/a&gt;），而不是一個單純數字。&lt;/p&gt;
&lt;p&gt;如果我們能做到這件事情，則 RNN 就能用以下的方式讀入我們的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-process-vectors.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        注意：在每個時間點被塞入 RNN 的「詞彙」不再是 1 個數字，而是一個 N 維向量（圖中 N 為 3）
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以現在的問題變成：&lt;/p&gt;
&lt;p&gt;「要怎麼將一個詞彙表示成一個 N 維向量 ？」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其中一個方法是我們隨便決定一個 N，然後為語料庫裡頭的每一個詞彙都指派一個隨機生成的 N 維向量。&lt;/p&gt;
&lt;p&gt;假設我們現在有 5 個詞彙：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;野狼&lt;/li&gt;
&lt;li&gt;老虎&lt;/li&gt;
&lt;li&gt;狗&lt;/li&gt;
&lt;li&gt;貓&lt;/li&gt;
&lt;li&gt;喵咪&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照剛剛說的方法，我們可以設定 N = 2，並為每個詞彙隨機分配一個 2 維向量後將它們畫在一個平面空間裡頭：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些代表詞彙的向量被稱之為詞向量，但是你可以想像這樣的隨機轉換很沒意義。&lt;/p&gt;
&lt;p&gt;比方說上圖，我們就無法理解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何「狗」是跟「老虎」而不是跟同為犬科的「野狼」比較接近？&lt;/li&gt;
&lt;li&gt;為何「貓」的維度 2 比「狗」高，但卻比「野狼」低？&lt;/li&gt;
&lt;li&gt;維度 2 的值的大小到底代表什麼意義？&lt;/li&gt;
&lt;li&gt;「喵咪」怎麼會在那裡？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這是因為我們只是將詞彙隨機地轉換到 2 維空間，並沒有讓這些轉換的結果（向量）反應出詞彙本身的語意（Semantic）。&lt;/p&gt;
&lt;p&gt;一個理想的轉換應該是像底下這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;在這個 2 維空間裡頭，我們可以發現一個好的轉換有 2 個特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;距離有意義：「喵咪」與意思相近的詞彙「貓」距離接近，而與較不相關的「狗」距離較遠&lt;/li&gt;
&lt;li&gt;維度有意義：看看（狗, 貓）與（野狼, 老虎）這兩對組合，可以發現我們能將維度 1 解釋為貓科 VS 犬科；維度 2 解釋為寵物與野生動物&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/dog-and-cat.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們能把語料庫（Corpus）裏頭的每個詞彙都表示成一個像是這樣有意義的詞向量，神經網路就能幫我們找到潛藏在大量詞彙中的語義關係，並進一步改善 NLP 任務的精準度。&lt;/p&gt;
&lt;p&gt;好消息是，大部分的情況我們並不需要自己手動設定每個詞彙的詞向量。我們可以隨機初始化所有詞向量（如前述的隨機轉換），並利用平常訓練神經網路的&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"&gt;反向傳播算法（Backpropagation）&lt;/a&gt;，讓神經網路自動學到一組適合當前 NLP 任務的詞向量（如上張圖的理想狀態）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/backpropagation-example.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        反向傳播讓神經網路可以在訓練過程中修正參數，持續減少預測錯誤的可能性
                        （&lt;a href="https://www.youtube.com/watch?v=Ilg3gGewQ5U" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 NLP 裏頭，這種將一個詞彙或句子轉換成一個實數詞向量（Vectors of real numbers）的技術被稱之為&lt;a href="https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B5%8C%E5%85%A5"&gt;詞嵌入（Word Embedding）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;而在 Keras 裡頭，我們可以使用 &lt;code&gt;Embedding&lt;/code&gt; 層來幫我們做到這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;layers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;MAX_NUM_WORDS&lt;/code&gt; 是我們的字典大小（10,000 個詞彙）、&lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 則是詞向量的維度。常見的詞向量維度有 128、256 或甚至 1,024。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Embedding&lt;/code&gt; 層一次接收 k 個長度任意的數字序列，並輸出 k 個長度相同的序列。輸出的序列中，每個元素不再是數字，而是一個 &lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 維的詞向量。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假如我們將第一筆（也就是 k = 1）假新聞標題 A 丟入 &lt;code&gt;Embedding&lt;/code&gt; 層，並設定 &lt;code&gt;NUM_EMBEDDING_DIM&lt;/code&gt; 為 3 的話，原來的標題 A：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題:
[
	0,
	0,
	0,
	185,
	300,
	72,
	4029,
	37,
	1,
	121,
	250,
	95,
	30,
	511,
	92,
	2358,
	33,
	2565,
	19,
	55,

]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就會被轉換成類似以下的形式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;新聞標題:
[
	[0.212, 0.111, 0.666], 
	[0.212, 0.111, 0.666], 
	[0.212, 0.111, 0.666], 
	[0.528, 0.344, 0.452], 
	[0.163, 0.93, 0.58], 
	[0.527, 0.262, 0.246], 
	[0.077, 0.695, 0.776], 
	[0.624, 0.962, 0.96], 
	[0.456, 0.927, 0.404], 
	[0.353, 0.119, 0.108], 
	[0.805, 0.969, 0.725], 
	[0.379, 0.265, 0.473], 
	[0.436, 0.186, 0.738], 
	[0.923, 0.287, 0.967], 
	[0.477, 0.614, 0.838], 
	[0.089, 0.328, 0.993], 
	[0.887, 0.913, 0.885], 
	[0.604, 0.118, 0.646], 
	[0.907, 0.52, 0.437], 
	[0.443, 0.432, 0.498], 
]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;序列裡頭的每個數字（即詞彙）都被轉換成一個 3 維的詞向量，而相同數字則當然都會對應到同一個詞向量（如前 3 個 &lt;code&gt;0&lt;/code&gt; 所對應到的詞向量）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rnn-process-vectors.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Keras 的 Embedding Layer 讓我們可以輕鬆地將詞彙轉換成適合神經網路的詞向量
                        （&lt;a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這樣的轉換，我們就能將轉換後的詞向量丟入 RNN / LSTM 裏頭，讓模型逐步修正隨機初始化的詞向量，使得詞向量裡頭的值越來越有意義。&lt;/p&gt;
&lt;p&gt;有了兩個新聞標題的詞向量，接著讓我們瞧瞧能夠處理這些數據的神經網路架構吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一個神經網路，兩個新聞標題"&gt;一個神經網路，兩個新聞標題&lt;a class="anchor-link" href="#一個神經網路，兩個新聞標題"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一般來說，多數你見過的神經網路只會接受一個資料來源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入一張圖片，判斷是狗還是貓&lt;/li&gt;
&lt;li&gt;輸入一個音訊，將其轉成文字&lt;/li&gt;
&lt;li&gt;輸入一篇新聞，判斷是娛樂還是運動新聞&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/one-data-source-nn.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;單一輸入的神經網路架構可以解決大部分的深度學習問題。但在這個 Kaggle 競賽裡頭，我們想要的是一個能夠讀入成對新聞標題，並判斷兩者之間關係的神經網路架構：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不相關（unrelated）&lt;/li&gt;
&lt;li&gt;新聞 B 同意 A（agreed）&lt;/li&gt;
&lt;li&gt;新聞 B 不同意 A（disagreed）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要怎麼做到這件事情呢？&lt;/p&gt;
&lt;p&gt;我們可以使用&lt;a href="https://www.coursera.org/lecture/convolutional-neural-networks/siamese-network-bjhmj"&gt;孿生神經網路（Siamese Network）&lt;/a&gt;架構：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        使用孿生神經網路架構來處理同類型的 2 個新聞標題
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖是本文最重要的一張圖，但現在你只需關注紅框的部分即可。剩餘細節我會在後面的&lt;a href="#定義神經網路的架構"&gt;定義神經網路的架構&lt;/a&gt;小節詳述。&lt;/p&gt;
&lt;p&gt;重複觀察幾次，我相信你就會知道何謂孿生神經網路架構：一部份的神經網路（紅框部分）被重複用來處理多個不同的資料來源（在本篇中為 2 篇不同的新聞標題）。&lt;/p&gt;
&lt;p&gt;而會想這樣做，是因為不管標題內容是新聞 A 還是新聞 B，其標題本身的語法 &amp;amp; 語義結構大同小異。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        神經網路說到底，就跟其他機器學習方法相同，都是對輸入進行一連串有意義的數據轉換步驟。神經網路將輸入的數據轉換成更適合解決當前任務的數據格式，並利用轉換後的數據進行預測。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以這樣的觀點來看的話，我們並不需要兩個不同的 LSTM 來分別將新聞 A 以及新聞 B 的詞向量做有意義的轉換，而是只需要讓標題 A 與標題 B 共享一個 LSTM 即可。畢竟，標題 A 跟標題 B 的數據結構很像。&lt;/p&gt;
&lt;p&gt;如果我們只寫一個 Python 函式就能處理 2 個相同格式的輸入的話，為何要寫 2 個函式呢？&lt;/p&gt;
&lt;p&gt;孿生神經網路也是相同的概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-cats.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Siamese 事實上代表暹羅貓。就像是這邊的暹羅貓雙胞胎一樣，你可以想像孿生神經網路架構裡頭也有 2 個一模一樣的神經網路雙胞胎
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好了，在了解如何同時讀入 2 個資料來源後，就讓我們實際用 Keras 動手將此模型建出來吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="深度學習-3-步驟"&gt;深度學習 3 步驟&lt;a class="anchor-link" href="#深度學習-3-步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;深度學習以及 NLP 領域的學問博大精深，但一般來說，當你想要實際動手寫出一個神經網路的時候，有 3 個基本步驟可以 follow：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deep-learning-three-steps-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        用深度學習框架 Keras 來實作深度學習的基本 3 步驟
                        （&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017_2/Lecture/keras.pdf" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ol&gt;
&lt;li&gt;定義神經網路的架構&lt;/li&gt;
&lt;li&gt;決定如何衡量模型的表現&lt;/li&gt;
&lt;li&gt;訓練模型並挑選最好的結果&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;接下來你會看到，大約 80 % 的程式碼會花在實作第一個步驟。剩餘 2 個步驟在使用 Keras 的情況下非常容易就能實現；但後面我們也會談到，你將花 80 % 的時間在最後一個步驟上面。&lt;/p&gt;
&lt;p&gt;首先，先讓我們進入第一步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="定義神經網路的架構"&gt;定義神經網路的架構&lt;a class="anchor-link" href="#定義神經網路的架構"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實作之前，先讓我們回顧一下前面段落看到的模型架構：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        本文用來實現假新聞分類的神經網路架構
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從左到右掃過一遍，你可以很清楚地發現我們需要以下 5 個元素來完成這個模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;兩個新聞標題（兩個長度為 20 的數字序列）&lt;/li&gt;
&lt;li&gt;一個詞嵌入層：將數字序列轉換為詞向量序列&lt;/li&gt;
&lt;li&gt;一個 LSTM 層：讀入前層的詞向量並萃取標題語義&lt;/li&gt;
&lt;li&gt;一個串接層：將兩個新聞標題的處理結果（也是向量）串接成一個向量&lt;/li&gt;
&lt;li&gt;一個全連接層：將前層的向量轉換為 3 個分類的預測機率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有些層我們已經在前面章節看過 Keras 的實現，比方說&lt;a href="#詞向量：將詞彙表達成有意義的向量"&gt;詞嵌入層&lt;/a&gt;以及 &lt;a href="#記憶力好的-LSTM-細胞"&gt;LSTM 層&lt;/a&gt;。剩下的串接層以及全連結層在 Keras 也都有現成的模組可供使用。&lt;/p&gt;
&lt;p&gt;另外值得一提的是，圖上的每個層（Layer）以及向量右下的灰字都對應了底下 Python 程式碼裡頭的變數名稱：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        灰字代表程式碼裡頭對應的變數名稱
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此，如果等等你不了解底下某個特定的變數所代表的意義，可以回來利用這張架構圖來釐清概念。&lt;/p&gt;
&lt;p&gt;以下就是此模型的 Keras 實作：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 基本參數設置，有幾個分類&lt;/span&gt;
&lt;span class="n"&gt;NUM_CLASSES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;

&lt;span class="c1"&gt;# 在語料庫裡有多少詞彙&lt;/span&gt;
&lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10000&lt;/span&gt;

&lt;span class="c1"&gt;# 一個標題最長有幾個詞彙&lt;/span&gt;
&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;

&lt;span class="c1"&gt;# 一個詞向量的維度&lt;/span&gt;
&lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;256&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 輸出的向量維度&lt;/span&gt;
&lt;span class="n"&gt;NUM_LSTM_UNITS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;128&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 建立孿生 LSTM 架構（Siamese LSTM）&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.layers&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; \
    &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Dense&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.models&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;

&lt;span class="c1"&gt;# 分別定義 2 個新聞標題 A &amp;amp; B 為模型輸入&lt;/span&gt;
&lt;span class="c1"&gt;# 兩個標題都是一個長度為 20 的數字序列&lt;/span&gt;
&lt;span class="n"&gt;top_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'int32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'int32'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 詞嵌入層&lt;/span&gt;
&lt;span class="c1"&gt;# 經過詞嵌入層的轉換，兩個新聞標題都變成&lt;/span&gt;
&lt;span class="c1"&gt;# 一個詞向量的序列，而每個詞向量的維度&lt;/span&gt;
&lt;span class="c1"&gt;# 為 256&lt;/span&gt;
&lt;span class="n"&gt;embedding_layer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;MAX_NUM_WORDS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;NUM_EMBEDDING_DIM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;top_embedded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;top_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_embedded&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;embedding_layer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;bm_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# LSTM 層&lt;/span&gt;
&lt;span class="c1"&gt;# 兩個新聞標題經過此層後&lt;/span&gt;
&lt;span class="c1"&gt;# 為一個 128 維度向量&lt;/span&gt;
&lt;span class="n"&gt;shared_lstm&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;LSTM&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;NUM_LSTM_UNITS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;top_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared_lstm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top_embedded&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bm_output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared_lstm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bm_embedded&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 串接層將兩個新聞標題的結果串接單一向量&lt;/span&gt;
&lt;span class="c1"&gt;# 方便跟全連結層相連&lt;/span&gt;
&lt;span class="n"&gt;merged&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;concatenate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bm_output&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 全連接層搭配 Softmax Activation&lt;/span&gt;
&lt;span class="c1"&gt;# 可以回傳 3 個成對標題&lt;/span&gt;
&lt;span class="c1"&gt;# 屬於各類別的可能機率&lt;/span&gt;
&lt;span class="n"&gt;dense&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;Dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;NUM_CLASSES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;activation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'softmax'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dense&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;merged&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 我們的模型就是將數字序列的輸入，轉換&lt;/span&gt;
&lt;span class="c1"&gt;# 成 3 個分類的機率的所有步驟 / 層的總和&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;inputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;top_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bm_input&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;outputs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這段程式碼的確不短，但有將近一半是我寫給你的註解。而且這段程式碼的邏輯跟上面的架構圖一模一樣，只差架構圖是從左到右、程式碼是從上到下而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了確保用 Keras 定義出的模型架構跟預期相同，我們也可以將其畫出來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;keras.utils&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;plot_model&lt;/span&gt;
&lt;span class="n"&gt;plot_model&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;to_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'model.png'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;show_shapes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;show_layer_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="n"&gt;rankdir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'LR'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/model.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了模型架構以外，我們還可以看到所有層的輸入 / 輸出張量（Tensor）的維度。在 Keras 裏頭，張量的第 1 個維度通常為樣本數（比方說 5 則新聞標題），而 &lt;code&gt;None&lt;/code&gt; 則代表可以指定任意值。&lt;/p&gt;
&lt;p&gt;最重要的是，這個用 Keras 定義出來的模型，跟我們之前想像中的孿生神經網路可以說是一模一樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/siamese-network.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我沒有騙你，對吧？&lt;/p&gt;
&lt;p&gt;現在你應該發現，只要擁有前面幾章學到的 NLP 知識以及基礎 Python 程式能力，要建立一個像這樣看似複雜的孿生 LSTM（Siamese LSTM）神經網路其實也並沒有那麼困難。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，使用 Keras 建立深度學習模型這件事情感覺上就像是在玩疊疊樂一樣，一層加上一層：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/playing-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        一位研究生利用 Keras 做深度學習的心得
                        （&lt;a href="https://youtu.be/Lx3l4lOrquw?t=277" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="全連接層"&gt;全連接層&lt;a class="anchor-link" href="#全連接層"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;唯一沒有在前面章節提到的是&lt;a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/fc_layer.html"&gt;全連接層（Fully Connected Layer）&lt;/a&gt;以及其使用的 &lt;a href="https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0"&gt;Softmax 函式&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;全連接層顧名思義，代表該層的每個神經元（Neuron）都會跟前一層的所有神經元享有連結：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/fully-connected.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        因為只需要預測 3 個分類，本文的全連接層只有 3 個神經元
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而為了確認我們計算的參數量無誤，還可以使用 &lt;code&gt;model.summary()&lt;/code&gt; 來看每一層的參數量以及輸出的張量（Tensor）長相：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/model-summary.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;全連接層在最下面。而因為其與前一層「緊密」連接的緣故，它在 Keras 裏頭被稱為 &lt;code&gt;Dense&lt;/code&gt; 層。它也是最早出現、最簡單的神經網路層之一。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Param #&lt;/code&gt; 則紀錄了每一層所包含的模型參數（Parameters）。在機器學習的過程中，這些參數都會不斷地被調整，直到能讓模型能做出很好的預測。詞嵌入層有最多的參數，因為我們要為 字典裡頭的每個詞彙都建立一個 256 維度的詞向量，因此參數量為 10,000 * 256。&lt;/p&gt;
&lt;p&gt;這張表另外一個值得注意的地方是所有層的 Output Shape 的第一個維度都是 &lt;code&gt;None&lt;/code&gt;。而 &lt;code&gt;None&lt;/code&gt; 代表著可以是任意的數字。&lt;/p&gt;
&lt;p&gt;在 Keras 裡頭，第一個維度代表著樣本數（#Samples），比方說前 9,527 筆新聞標題 A 的數字序列的 &lt;code&gt;shape&lt;/code&gt; 應該要是 &lt;code&gt;（9527, 20）&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;9527&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;(9527, 20)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;嗯，結果跟我們想像的一樣。&lt;/p&gt;
&lt;p&gt;而之所以每層的樣本數為 &lt;code&gt;None&lt;/code&gt; 是因為 Keras 為了因應在不同場合會丟入不同數量的樣本需求。比方說，在訓練時你可能會一次丟 32 筆資料給模型訓練，但在預測的時候一次只丟 16 筆資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Softmax-函式"&gt;Softmax 函式&lt;a class="anchor-link" href="#Softmax-函式"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Softmax 函式一般都會被用在整個神經網路的最後一層上面，比方說我們這次的全連接層。&lt;/p&gt;
&lt;p&gt;Softmax 函式能將某層中的所有神經元裡頭的數字作正規化（Normalization）：將它們全部壓縮到 0 到 1 之間的範圍，並讓它們的和等於 1。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/softmax-and-fully-connectead.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Softmax 能將多個數字作正規化，讓它們的值為 1
                        （&lt;a href="https://towardsdatascience.com/deep-learning-concepts-part-1-ea0b14b234c8" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有數值都位於 0 到 1 之間&lt;/li&gt;
&lt;li&gt;所有數值相加等於 1&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這兩個條件恰好是機率（Probability）的定義，Softmax 函式的運算結果可以讓我們將每個神經元的值解釋為對應分類（Class）的發生機率。&lt;/p&gt;
&lt;p&gt;以我們的假新聞分類任務來說的話，每個值就各代表以下分類的發生機率：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不相關： 0.46&lt;/li&gt;
&lt;li&gt;新聞 B 同意新聞 A：0.34&lt;/li&gt;
&lt;li&gt;新聞 B 不同意新聞 B：0.20&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果現在是在做預測且我們只能選出一個分類當作答案的話，我們可以說這次的分類結果最有可能是「不相關」這個類別，因為其發生機率最高。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在定義好模型以後，我們就可以進入下個步驟：定義衡量模型好壞的指標。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="決定如何衡量模型的表現"&gt;決定如何衡量模型的表現&lt;a class="anchor-link" href="#決定如何衡量模型的表現"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓機器自動「學習」，我們得給它一個&lt;a href="https://zh.wikipedia.org/wiki/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"&gt;損失函數（Loss Function）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;給定一個正確解答 &lt;code&gt;y&lt;/code&gt; 以及模型預測的結果 &lt;code&gt;y_head&lt;/code&gt;，我們的模型透過損失函數就能自動計算出現在的預測結果跟正解的差距為多少。&lt;/p&gt;
&lt;p&gt;透過損失函數的回饋，模型會盡全力修正參數，以期將此損失函數的值下降到最低（也就是讓預測結果 &lt;code&gt;y_head&lt;/code&gt; 跟正解 &lt;code&gt;y&lt;/code&gt; 越來越接近）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/loss-function.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        圖中的拋物線即為損失函數 J(w)。當參數 w 有不同值時，損失函數的值也有所不同。模型會持續修正參數 w 以期最小化損失函數
                        （&lt;a href="https://medium.com/data-science-group-iitr/loss-functions-and-optimization-algorithms-demystified-bb92daff331c" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;那你會問，在假新聞分類裡頭，我們應該使用什麼損失函數呢？&lt;/p&gt;
&lt;p&gt;我們在&lt;a href="#將正解做-One-hot-Encoding"&gt;將正解做 One-hot Encoding&lt;/a&gt; 一節有稍微提到，我們會希望&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正確的分類的機率分佈 P1（例：&lt;code&gt;[1, 0, 0]&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;模型預測出的機率分佈 P2（例：&lt;code&gt;[0.7, 0.2, 0.1]&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這 2 個機率分佈的「差距」越小越好。而能計算 2 個機率分佈之間的差距的&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E7%86%B5"&gt;交叉熵（Cross Entropy）&lt;/a&gt;就是這次的分類問題中最適合的損失函數。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/cross-entropy.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        交叉熵能幫我們計算兩個機率分佈的差距，適合作為分類問題的損失函數
                        （&lt;a href="https://youtu.be/tRsSi_sqXjI?t=44" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Keras 裏頭，我們可以這樣定義模型的損失函數：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;optimizer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'rmsprop'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;metrics&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'accuracy'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;categorical_crossentropy&lt;/code&gt; 即是我們剛剛所說的交叉熵，而 &lt;code&gt;accuracy&lt;/code&gt; 則是準確度，會被我們用來在訓練過程中了解模型的表現情況。&lt;/p&gt;
&lt;p&gt;精準度的定義為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# 模型預測正確的樣本數
-------------------
#     總樣本數
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;雖然有了交叉熵來當作我們模型的損失函數，但是實際上模型要如何更新裡頭的參數呢？我們需要一個&lt;a href="https://keras-cn.readthedocs.io/en/latest/other/optimizers/"&gt;優化器（Optimizer）&lt;/a&gt;來做到這件事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/loss-function-learning.gif"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        不同優化器透過調整參數來降低損失函數的情形，就像是在想辦法往溜滑梯的低處滑一樣
                        （&lt;a href="https://stats.stackexchange.com/questions/357449/two-large-decreses-in-loss-function-with-adam-optimizer" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們有很多種優化器，但它們基本上都是從&lt;a href="https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"&gt;梯度下降法（Gradient Descent）&lt;/a&gt;延伸而來。&lt;/p&gt;
&lt;p&gt;在上圖的不同位置，梯度下降法會重新計算每個參數對損失函數的梯度（斜率）。接著梯度下降法會利用該梯度來修正參數，使得使用新參數算出來的損失函數的值能夠持續往下降。&lt;/p&gt;
&lt;p&gt;不同優化器則有各自往下滑的秘方，比方說自動調整 &lt;a href="https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10"&gt;Learning rate&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;現在就先讓我們使用 &lt;a href="https://keras-cn.readthedocs.io/en/latest/other/optimizers/"&gt;RMSProp 優化器&lt;/a&gt;。而在有了損失函數以及優化器以後，我們就可以正式開始訓練模型了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="訓練模型並挑選最好的結果"&gt;訓練模型並挑選最好的結果&lt;a class="anchor-link" href="#訓練模型並挑選最好的結果"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟很直觀，我們就是實際使用 &lt;code&gt;model.fit&lt;/code&gt; 來訓練剛剛定義出來的孿生 LSTM 模型：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 決定一次要放多少成對標題給模型訓練&lt;/span&gt;
&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;512&lt;/span&gt;

&lt;span class="c1"&gt;# 決定模型要看整個訓練資料集幾遍&lt;/span&gt;
&lt;span class="n"&gt;NUM_EPOCHS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="c1"&gt;# 實際訓練模型&lt;/span&gt;
&lt;span class="n"&gt;history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="c1"&gt;# 輸入是兩個長度為 20 的數字序列&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_train&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
    &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BATCH_SIZE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;NUM_EPOCHS&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="c1"&gt;# 每個 epoch 完後計算驗證資料集&lt;/span&gt;
    &lt;span class="c1"&gt;# 上的 Loss 以及準確度&lt;/span&gt;
    &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_val&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_val&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; 
        &lt;span class="n"&gt;y_val&lt;/span&gt;
    &lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="c1"&gt;# 每個 epoch 隨機調整訓練資料集&lt;/span&gt;
    &lt;span class="c1"&gt;# 裡頭的數據以讓訓練過程更穩定&lt;/span&gt;
    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊特別值得拿出來提的是以下兩個參數：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;BATCH_SIZE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NUM_EPOCHS&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照我們前面對損失函數（Loss Function）的說明，理論上模型是把訓練資料集裡頭的 32 萬筆資料全部看完一遍之後，再更新一次參數以降低損失函數。&lt;/p&gt;
&lt;p&gt;但是這樣太曠日廢時，訓練可能要花很久才能完成。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rawpixel-584290-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實務上都是每次只放入幾筆訓練數據，讓模型看完這些資料後就做一次參數的更新。而這個「幾筆」，就是 &lt;code&gt;BATCH_SIZE&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;依照 &lt;code&gt;BATCH_SIZE&lt;/code&gt; 的大小，梯度下降（Gradient Descent, 後稱 GD）可以概括為 3 個類別：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; = 訓練資料集大小，且這時不稱為 batch）&lt;/li&gt;
&lt;li&gt;Mini-batch GD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; 通常為一個較小的 2 的倍數）&lt;/li&gt;
&lt;li&gt;SGD（&lt;code&gt;BATCH_SIZE&lt;/code&gt; = 1）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/sgd-vs-mini-batch.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        想像損失函數是個越往裡面值就越低的碗，梯度下降就是要想辦法到達中心點
                        （&lt;a href="https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如上圖所示，下方的 GD 因為在每次更新參數前都會看完訓練資料集裡頭所有的數據，因此它更新參數的方向是最可靠的。但要往前走一步就就得看完 32 萬筆數據，未免成本也太大。&lt;/p&gt;
&lt;p&gt;另一個極端是上方的 SGD：模型每看完 1 個訓練數據就嘗試更新權重，而因為單一一筆訓練數據並不能很好地代表整個訓練資料集，前進的方向非常不穩定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/mini-batch.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        隨機梯度下降（SGD）與 Mini-batch 梯度下降的比較
                        （&lt;a href="https://datascience-enthusiast.com/DL/Optimization_methods.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此我們常常採用的是中庸之道： Mini-batch GD 的方式來訓練模型，而這靠的是指定 &lt;code&gt;model.fit&lt;/code&gt; 函式裡頭的 &lt;code&gt;batch_size&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;NUM_EPOCHS&lt;/code&gt; 則很容易理解：你希望模型不只將 32 萬筆的訓練數據都看過一遍，而是每一筆資料還要多看過好幾次，以讓模型確確實實地從它們身上學到東西。&lt;code&gt;NUM_EPOCHS&lt;/code&gt; = 10 的意思就代表模型會重複看整個訓練資料集 10 次。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著讓我們看看 Keras 的訓練過程：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/training-process.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Keras 訓練神經網路的過程
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為模型的目標就是要最小化損失函數（Loss Function），你可以觀察到當模型看過越多訓練資料集（Training Set）的數據以後，損失值（loss）就越低，分類的準確度（acc）則越高。&lt;/p&gt;
&lt;p&gt;這代表我們的模型越來越熟悉訓練資料集裡頭的數據，因此在訓練資料集裡頭的表現越來越好。&lt;/p&gt;
&lt;p&gt;如果依照準確度以及損失值分別畫圖的話則會長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/training-result.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很明顯地，我們的神經網路有過適（Overfittng）的問題：儘管在訓練資料集表現得非常好（準確度超過 90 %、損失小於 0.2），在從沒看過的驗證資料集的表現就相對遜色不少。且在第 6 個 epoch 之後驗證資料集的準確度 &lt;code&gt;val_acc&lt;/code&gt; 就沒什麼在上升，驗證集的損失 &lt;code&gt;val_loss&lt;/code&gt; 則已經逐漸上升。&lt;/p&gt;
&lt;p&gt;這代表模型利用從訓練資料集學到的模式（Pattern）還無法非常精準地預測沒見過的事物。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deep-learning-three-steps-with-keras.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        用 Keras 來實作深度學習的基本 3 步驟
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="#深度學習-3-步驟"&gt;這章節一開頭&lt;/a&gt;所說的，雖然第 3 步驟：「訓練模型並挑選最好的結果」的 Keras 實作非常簡單（基本上就是 &lt;code&gt;model.fit( ...)&lt;/code&gt;），但實際上在一個機器學習 / 深度學習專案裡頭，你將會花 80 % 的時間在這個步驟裡頭調整參數，想辦法找到一個最棒的模型。&lt;/p&gt;
&lt;p&gt;儘管如此，我們現在最想知道的還是這個模型在真實世界（也就是測試資料集）到底能表現多好，因此先讓我們試著拿這個簡單模型來做預測吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="進行預測並提交結果_1"&gt;進行預測並提交結果&lt;a class="anchor-link" href="#進行預測並提交結果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就跟我們對訓練 / 驗證資料集做的&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理&lt;/a&gt;一樣，要對測試資料集（Test Set）做預測，我們得先將裡頭的文本數據通通轉換成能夠丟進模型的數字序列資料。&lt;/p&gt;
&lt;p&gt;首先，讓我們把測試資料集讀取進來：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;TEST_CSV_PATH&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;index_col&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;tid1&lt;/th&gt;
&lt;th&gt;tid2&lt;/th&gt;
&lt;th&gt;title1_zh&lt;/th&gt;
&lt;th&gt;title2_zh&lt;/th&gt;
&lt;th&gt;title1_en&lt;/th&gt;
&lt;th&gt;title2_en&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;321187&lt;/th&gt;
&lt;td&gt;167562&lt;/td&gt;
&lt;td&gt;59521&lt;/td&gt;
&lt;td&gt;萨拉赫人气爆棚!埃及总统大选未参选获百万选票 现任总统压力山大&lt;/td&gt;
&lt;td&gt;辟谣！里昂官方否认费基尔加盟利物浦，难道是价格没谈拢？&lt;/td&gt;
&lt;td&gt;egypt 's presidential election failed to win m...&lt;/td&gt;
&lt;td&gt;Lyon! Lyon officials have denied that Felipe F...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;321190&lt;/th&gt;
&lt;td&gt;167564&lt;/td&gt;
&lt;td&gt;91315&lt;/td&gt;
&lt;td&gt;萨达姆被捕后告诫美国的一句话，发人深思&lt;/td&gt;
&lt;td&gt;10大最让美国人相信的荒诞谣言，如蜥蜴人掌控着美国&lt;/td&gt;
&lt;td&gt;A message from Saddam Hussein after he was cap...&lt;/td&gt;
&lt;td&gt;The Top 10 Americans believe that the Lizard M...&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;321189&lt;/th&gt;
&lt;td&gt;167563&lt;/td&gt;
&lt;td&gt;167564&lt;/td&gt;
&lt;td&gt;萨达姆此项计划没有此国破坏的话，美国还会对伊拉克发动战争吗&lt;/td&gt;
&lt;td&gt;萨达姆被捕后告诫美国的一句话，发人深思&lt;/td&gt;
&lt;td&gt;Will the United States wage war on Iraq withou...&lt;/td&gt;
&lt;td&gt;A message from Saddam Hussein after he was cap...&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;測試資料集跟訓練資料集的唯一差別只在沒有 &lt;code&gt;label&lt;/code&gt; 欄位，因此我們只需要將當初在&lt;a href="#資料前處理：讓機器能夠處理文字"&gt;資料前處理&lt;/a&gt;章節使用的步驟原封不動地套用在測試資料集即可。&lt;/p&gt;
&lt;p&gt;你可以趁機複習一下有哪些步驟：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 以下步驟分別對新聞標題 A、B　進行&lt;/span&gt;
&lt;span class="c1"&gt;# 文本斷詞 / Word Segmentation&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title1_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title1_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title2_tokenized'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; \
    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s1"&gt;'title2_zh'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; \
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jieba_tokenizer&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將詞彙序列轉為索引數字的序列&lt;/span&gt;
&lt;span class="n"&gt;x1_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title1_tokenized&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokenizer&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texts_to_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title2_tokenized&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 為數字序列加入 zero padding&lt;/span&gt;
&lt;span class="n"&gt;x1_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x1_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;keras&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;preprocessing&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sequence&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pad_sequences&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;x2_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        &lt;span class="n"&gt;maxlen&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;MAX_SEQUENCE_LENGTH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    

&lt;span class="c1"&gt;# 利用已訓練的模型做預測&lt;/span&gt;
&lt;span class="n"&gt;predictions&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x1_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2_test&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些步驟現在對你來說應該都已經不再陌生。&lt;/p&gt;
&lt;p&gt;讓我們看一下從模型得到的預測結果長什麼樣子：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/test-predictions.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;跟我們之前討論過的一樣，模型針對每一筆成對新聞標題的輸入，會回傳給我們 3 個分類的機率值。&lt;/p&gt;
&lt;p&gt;現在，我們只要將機率值最大的類別當作答案，並將這個結果轉回對應的文本標籤即可上傳到 Kaggle：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;index_to_label&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;label_to_index&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;()}&lt;/span&gt;

&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;index_to_label&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;predictions&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

&lt;span class="n"&gt;submission&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; \
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;submission&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'Id'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Category'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;submission&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/submission.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;得到上面的 DataFrame 以後，我們可以將其儲存成 CSV 並上傳到 kaggle，而結果如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/first-submission-result.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        我們的 NLP 模型第一次的結果
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你還記得我們在&lt;a href="#用直覺找出第一條底線"&gt;用直覺找出第一條底線&lt;/a&gt;的章節內容的話，就會知道這並不是應該多好的預測結果，但的確比多數票決好了一點點。&lt;/p&gt;
&lt;p&gt;不過不需要操之過急，因為任何機器學習專案都是一個持續重複改善的迴圈。在第一次預測就做出完美結果的情況很少，重點是持續改善。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/thor-alvis-754589-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在第一次提交結果以後，我們還可以做非常多事情來嘗試改善模型效能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;改變字典詞彙量、序列長度&lt;/li&gt;
&lt;li&gt;改變詞向量的維度&lt;/li&gt;
&lt;li&gt;嘗試&lt;a href="https://ithelp.ithome.com.tw/articles/10194633"&gt;預先訓練的詞向量&lt;/a&gt;如 &lt;a href="https://zhuanlan.zhihu.com/p/38254332"&gt;ELMo&lt;/a&gt;、&lt;a href="https://nlp.stanford.edu/projects/glove/"&gt;GloVe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;調整 LSTM 層的輸出維度&lt;/li&gt;
&lt;li&gt;使用不同優化器、調整 Learning rate&lt;/li&gt;
&lt;li&gt;改變神經網路架構如使用 GRU 層&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;能改善準確度的方式不少，但因為牽涉範圍太廣，請容許我把它們留給你當做回家作業。&lt;/p&gt;
&lt;p&gt;走到這裡代表你已經完整地經歷了一個 NLP 專案所需要的大部分步驟。在下一節．讓我們回顧一下在這趟旅程中你所學到的東西。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="我們是怎麼走到這裡的"&gt;我們是怎麼走到這裡的&lt;a class="anchor-link" href="#我們是怎麼走到這裡的"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這趟 NLP 旅程裏頭，我們學會了不少東西。&lt;/p&gt;
&lt;p&gt;現在的你應該已經了解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NLP 中常見的數據前處理以及實踐方法&lt;/li&gt;
&lt;li&gt;詞向量以及詞嵌入的基本概念&lt;/li&gt;
&lt;li&gt;神經網路常見的元件如全連接層、簡單 RNN 以及 LSTM&lt;/li&gt;
&lt;li&gt;能讀多個資料來源的孿生神經網路架構&lt;/li&gt;
&lt;li&gt;如何用 Keras 建構一個完整的神經網路&lt;/li&gt;
&lt;li&gt;深度學習 3 步驟：建模、定義衡量指標以及訓練模型&lt;/li&gt;
&lt;li&gt;梯度下降、優化器以及交叉熵等基本概念&lt;/li&gt;
&lt;li&gt;如何利用已訓練模型對新數據做預測&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;呼，這可真了不起，值得慶祝！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/wil-stewart-24562-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;能閱讀到這裡，我相信你對深度學習以及 NLP 領域是抱著不少興趣的。而為了讓你在閱讀本文以後能夠繼續探索這個世界，在下一章節我則會介紹 3 門非常推薦的線上課程。&lt;/p&gt;
&lt;p&gt;最後，我則會在文末總結一下自己的心得。&lt;/p&gt;
&lt;p&gt;現在，先看看有哪些課程吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="3-門推薦的線上課程"&gt;3 門推薦的線上課程&lt;a class="anchor-link" href="#3-門推薦的線上課程"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;為了奠定 NLP 的基礎，這一個月我一邊複習舊教材，一邊看了不少教學文章以及線上課程。&lt;/p&gt;
&lt;p&gt;截至目前，我認為有 3 個 CP 值十分高的課程值得推薦給你：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;台大電機系李宏毅教授的&lt;a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html"&gt;深度學習課程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;奠定理論基礎&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Coursera 的&lt;a href="https://www.coursera.org/specializations/deep-learning"&gt; Deep Learning 專項課程&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;理論 70 % + 實作 30 %&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.oreilly.com/library/view/deep-learning-with/9781617294433VE/"&gt;Deep Learning with Python&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;注重程式實作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這邊說的 CP 值高（對，我知道你最愛 CP 值）指的是能用最少的時間、精力以及金錢來確確實實地學好 NLP 的理論及實作基礎。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/Hung-yi-Lee-ml-courses.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        李宏毅教授的 Youtube 播放清單
                        （&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="http://www.ee.ntu.edu.tw/profile?id=1020908"&gt;李宏毅教授&lt;/a&gt;的機器學習課程內行的都知道，大概是全世界最好、最完整的 Deep Learning 中文學習資源。李教授在課程中廣徵博引學術論文，但卻同時非常淺顯易懂。你可以在這邊看到&lt;a href="https://www.youtube.com/channel/UC2ggjtuuWvxrHHHiaDH1dlQ/playlists"&gt;教授所有的 Youtube 課程播放清單&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;就我所知，教授在台大上課很注重實作，有不少作業需要完成，但因為線上只有影片可以查看，因此我將其分類為「奠定理論基礎」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deeplearning-ai-courses.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Deep Learning Specialization
                        （&lt;a href="https://www.coursera.org/specializations/deep-learning" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;原 Google Brain 的&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達教授&lt;/a&gt;的 &lt;a href="https://www.coursera.org/specializations/deep-learning"&gt;Deep Learning 專項課程&lt;/a&gt;則是 Coursera 上最受歡迎的深度學習課程。跟我們這篇文章最相關的 NLP 技術則被涵蓋在該專項課程的最後一堂課：&lt;a href="https://www.coursera.org/learn/nlp-sequence-models"&gt;Sequence Models&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我在大約一年前完成包含&lt;a href="https://www.coursera.org/learn/convolutional-neural-networks"&gt;卷積神經網路 CNN&lt;/a&gt; 的前四堂課，而因為課程上線已有一段時間，現在影片大都有簡體或繁體中文的字幕，不太需要煩惱聽不懂英文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/deeplearning-with-python.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://www.oreilly.com/library/view/deep-learning-with/9781617294433VE/"&gt;Deep Learning with Python Video Edition&lt;/a&gt; 的作者 &lt;a href="https://ai.google/research/people/105096"&gt;Fran&amp;ccedil;ois Chollet&lt;/a&gt; 為軟體工程師出身，設計出知名深度學習框架 &lt;a href="https://keras.io/"&gt;Keras&lt;/a&gt;，目前則在 Google AI 工作。&lt;/p&gt;
&lt;p&gt;該書以 Programmer 的角度出發，提供了利用 Keras 實現各種 NLP 任務的範例，十分適合在熟悉深度學習理論後想要實作的人閱讀。&lt;/p&gt;
&lt;p&gt;就算你不想花錢買書或是訂閱 &lt;a href="https://www.safaribooksonline.com"&gt;O'Relly Online&lt;/a&gt;，你也可以在他有 5,000 多顆星的 Github Repo &lt;a href="https://github.com/fchollet/deep-learning-with-python-notebooks"&gt;deep-learning-with-python-notebooks&lt;/a&gt; 看到跟該課程相關的所有 Jupyter Notebooks。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/maxwell-ridgeway-685077-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些課程可以說是幫助我完成這篇文章以及 Kaggle 競賽的最大功臣，而我也希望能透過這篇文章的微薄之力讓你知道他們的存在，並隨著他們繼續你從這裏開始的 NLP 探險。&lt;/p&gt;
&lt;p&gt;當然，除了以上 3 堂課程，你還可以在&lt;a href="https://leemeng.tw/deep-learning-resources.html"&gt;由淺入深的深度學習資源整理&lt;/a&gt;一文看到更多我整理的深度學習資源。你也可以直接前往 &lt;a href="https://github.com/leemengtaiwan/deep-learning-resources"&gt;Github Repo&lt;/a&gt; 查看。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語：從掌握基礎到運用巨人之力"&gt;結語：從掌握基礎到運用巨人之力&lt;a class="anchor-link" href="#結語：從掌握基礎到運用巨人之力"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;網路上多的是專業的 NLP 教學文章或論文探討，但平易近人的中文文章卻少之又少。&lt;/p&gt;
&lt;p&gt;在文章開頭我說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        希望這篇文章能成為你前往自然語言處理世界的最佳橋樑。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這野心聽起來很狂妄，但至少我已經嘗試用最平易近人的詞彙向你介紹這個 NLP 世界的一丁點基礎知識，而我也希望你真的學到了些什麼、獲得些啟發。&lt;/p&gt;
&lt;p&gt;現在深度學習以及 NLP 領域實在發展太快，就算一個人有興趣也常常不知從何開始學起。&lt;/p&gt;
&lt;p&gt;事實上，NLP 的發展速度還在加快，而這既是好消息也是壞消息。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/jack-anstey-383370-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        NLP 如果是輛衝往未來的火車的話，深度學習就是它的引擎，而我們的數據是它的燃料。另外，多數人還沒有登上這台火車
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊說的 NLP，其實更適合用人工智慧取代。&lt;/p&gt;
&lt;p&gt;對還沒掌握機器學習 / 深度學習 / NLP 知識的人來說，這些技術只會離自己越來越遠，最後遠到只會在&lt;a href="https://buzzorange.com/techorange/2018/12/22/ai-breakthrough-in-2018/"&gt;新聞報導&lt;/a&gt;或科幻小說上看到，儘管被這些技術驅動的龐大系統每天影響著他們的生活。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/rawpixel-780496-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;至於那些已經掌握這些知識的人，透過運用&lt;a href="https://github.com/google-research/bert"&gt;如遷移學習等巨人之力&lt;/a&gt;，就連一般人也能做到以前憑自己力量做不到的事情。&lt;/p&gt;
&lt;p&gt;比方說利用 Google 在今年 11 月公開的龐大&lt;a href="https://github.com/google-research/bert"&gt;語言代表模型 BERT&lt;/a&gt;，我不費吹灰之力就在本文的 &lt;a href="https://www.kaggle.com/c/fake-news-pair-classification-challenge/leaderboard"&gt;Kaggle 競賽&lt;/a&gt;達到 85 % 的正確率，距離第一名 3 %，總排名前 30 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/nlp-kaggle-intro/kaggle-final-result.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們之前設計的 LSTM 模型則僅有 67 % 準確度。&lt;/p&gt;
&lt;p&gt;並不是說只要用新的語言模型就好，這篇學的東西都不重要。事實上正好相反：正是因為有了此篇的 NLP 基礎知識，才讓我得以順利地運用該巨人之力。&lt;/p&gt;
&lt;p&gt;深度學習以及 NLP 領域發展快速，但你總要從某個地方開始好好地學習基礎，而且越快開始越好。&lt;/p&gt;
&lt;p&gt;所以我留給你的最後一個問題就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你，打算什麼時候出發？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="自然語言處理"></category><category term="Keras"></category><category term="Python"></category><category term="深度學習"></category></entry><entry><title>我在比利時 EMNLP 之旅中學到的 3 堂課</title><link href="https://leemeng.tw/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html" rel="alternate"></link><published>2018-11-19T08:00:00+09:00</published><updated>2018-11-19T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-11-19:/3-lessons-i-learnt-from-emnlp-2018-at-belgium.html</id><summary type="html">&lt;p&gt;這是一個 NLP 初心者勇闖自然語言處理的頂級學術會議 EMNLP 的故事。在這篇文章裡，我想跟你分享 3 個這次旅行中帶給我最重要的體悟。這些體悟改變了我的人生，而我也希望你能從這個故事裡頭獲得些啟發，重新思考你自己的學習，並做一些好的改變。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想將最近在比利時&lt;a href="https://zh.wikipedia.org/wiki/%E5%B8%83%E9%B2%81%E5%A1%9E%E5%B0%94"&gt;布魯塞爾&lt;/a&gt;參加自然語言處理的頂級會議 &lt;a href="http://emnlp2018.org/"&gt;EMNLP 2018&lt;/a&gt; 的心得記錄下來並與你分享。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-entrance.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 2018 會場門口
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇文章會把我數天參加會議時所感受到的個人想法總結成最重要的 3 個 lessons。希望你在閱讀我的故事以後，一樣也能從中獲得一些啟發。&lt;/p&gt;
&lt;p&gt;最後在文末，我則會說明這些想法將如何影響今後部落格的走向。如果你是忠實讀者，或許也會有興趣了解這個故事：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="計畫之外的-NLP-之旅"&gt;計畫之外的 NLP 之旅&lt;a class="anchor-link" href="#計畫之外的-NLP-之旅"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今年 10 月底，我跟公司請了一個禮拜的假參加在布魯塞爾舉辦的 &lt;a href="http://emnlp2018.org/"&gt;EMNLP 會議&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;EMNLP 作為世界頂尖的&lt;a href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"&gt;自然語言處理&lt;/a&gt;會議之一，每年都有無以數計的專業人士聚集在此，與他人分享自己最新的研究成果。與大多數國際會議相同，&lt;a href="https://zh.wikipedia.org/zh-hant/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"&gt;深度學習（Deep Learning）&lt;/a&gt;的蹤影基本上無所不在。&lt;/p&gt;
&lt;p&gt;你可以在&lt;a href="http://emnlp2018.org/schedule"&gt;這邊看到所有議程以及論文&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-line-up.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Workshops / Tutorials 第一天報到的人龍
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過老實說，在同事提及此會議之前，我並沒有聽過它的名號，更不用說考慮報名參加了。我本來預計是要參加跟資料工程相關的 &lt;a href="https://www.dataengconf.com/"&gt;DataEngConf&lt;/a&gt; 會議。（你可能已經從&lt;a href="https://leemeng.tw/tag/zi-liao-gong-cheng.html"&gt;我寫過的幾篇資料工程文章&lt;/a&gt;了解我對 DE 的興趣）&lt;/p&gt;
&lt;p&gt;但想説難得有機會深入了解現在 NLP 的研究趨勢，況且人多有個照應，稍微衡量一下就決定參加 EMNLP 了。&lt;/p&gt;
&lt;p&gt;當時的我還不曉得，這趟旅程為自己帶來的收穫，比原先預想地來得多。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="幾萬呎高空上的兩本書"&gt;幾萬呎高空上的兩本書&lt;a class="anchor-link" href="#幾萬呎高空上的兩本書"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這趟旅行從我坐上飛機就開始了。&lt;/p&gt;
&lt;p&gt;從東京到比利時，飛行距離大約有 1 萬公里，直飛也需快 12 小時。在長途飛行中沒有網路，因此我這次決定帶兩本買了好一陣子都沒翻開的書，計畫去程與回程各看一本。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;中途因為沒有任何如 Facebook 通知的干擾，我在飛機快抵達布魯塞爾時消化完《你要如何衡量你的人生？》的內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/two-books.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這次跟我一起去比利時的兩本書
                        （&lt;a href="https://leemeng.tw/books.html" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過此書我學到，那些你在職場或人生中設定的策略以及計劃，在實際展開行動去執行它們之前，什麼都不是。為了達成你要的目標，你得實際分配精力、時間等資源在上面，而非只是空想或說大話。&lt;/p&gt;
&lt;p&gt;在回東京時，我則閱讀了&lt;a href="https://gettingmore.com/"&gt;《華頓商學院最受歡迎的談判課》&lt;/a&gt;。戴蒙教授用深入淺出的說明以及大量真實案例，再次提醒我在進行溝通或談判時，以「人」為本、設身處地的重要性。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/aaron-burden-236415-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這兩本書值得推薦，但在這裏，重點其實並不在於這兩本書的內容。在閱讀完《你要如何衡量你的人生？》時飛機正好抵達比利時，我則驚覺：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        為何我當初在買書時早已預感能從此書獲得許多寶貴的思想，卻拖到現在才閱讀？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這正是「沒有下定決心分配資源以執行策略」的活生生例子。&lt;/p&gt;
&lt;p&gt;你的書櫃上是否也放了不少買了卻沒看的書？當初買書時你期望透過書本學到什麼？沒看完的原因又是什麼呢？&lt;/p&gt;
&lt;p&gt;如果「沒時間」是你的理由，那麼正說明了你跟當時的我一樣，沒有下定決心將自己的資源（時間）花在執行策略上面（看書變聰明、豐富人生）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/chuttersnap-412981-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資訊爆炸時代，我們的閱讀時間變得極度零碎，也難以長時間集中自己的注意力。很多時候跟看 Youtube 影片比起來，我們會覺得讀一本書的「投資報酬率」太低：花費時間太多，帶來的刺激太少。&lt;/p&gt;
&lt;p&gt;但其實並不是那麼一回事。好的書籍能改變你的一生，讓你終身受惠。而這次的機上閱讀帶給我的第一堂課即是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        閱讀好書是最好的長期投資，能豐富並讓你的人生更好。確保你會實際安排時間與精力去閱讀自己感興趣的書籍。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;的確，你不需要像我一樣在幾萬呎高空上閱讀才能得到一樣的感想。但多虧了長途飛行給的專注時間，讓我在這趟旅行的一開始就重新體會到這件重要的事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="從零開始的-NLP-之路"&gt;從零開始的 NLP 之路&lt;a class="anchor-link" href="#從零開始的-NLP-之路"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/La-place-Royale.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        到達布魯塞爾的當天飄著綿綿細雨
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;下了飛機，坐地鐵來到市區，EMNLP 會議也即將拉開序幕。讓我們回到 NLP 的話題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我一直以來都對 NLP 抱持著不少興趣，過去卻沒有認真去了解近年深度學習在 NLP 領域的快速發展以及創新。&lt;/p&gt;
&lt;p&gt;因此我明白，以自己當下幾乎是 0 的 NLP 知識水平，要在像 EMNLP 這種專業的會場內頭，迅速理解演講者們的論文發表這件事情的難度是很高的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/emnlp-conference.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 其中一個會議廳
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;基於這樣的背景，我將此次參加會議的目標設定為「掌握 NLP 基本概念以及關鍵字」。&lt;/p&gt;
&lt;p&gt;為了達到這樣的目標，我有一個非常 naive 的策略，其分為三個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;選擇有興趣的 Sessions 聆聽&lt;/li&gt;
&lt;li&gt;聽到不熟悉的關鍵字就把它們記下來&lt;/li&gt;
&lt;li&gt;Session 結束後 Google 這些關鍵字&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/food-in-belgium.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        來比利時，用功之餘也不能錯過淡菜及啤酒
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然你可以想像得到，一開始的幾場演講，作者的一句話或是一張投影片就能讓我打下無數關鍵字。&lt;/p&gt;
&lt;p&gt;不過會議每進行一天，我就記越少關鍵字。這並不稀奇，畢竟大部分論文運用的「基本」 NLP 概念是相通的，而我也逐漸熟悉這些概念。（謝了，Google！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你實際感受一下，以下節錄一些被我紀錄下來的關鍵字：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recurrent Neural Network（RNN）&lt;ul&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6"&gt;LSTM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://datascience.stackexchange.com/a/25657"&gt;BiLSTM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zhuanlan.zhihu.com/p/32481747"&gt;GRU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.sohu.com/a/240293276_610300"&gt;SRNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Word Embedding&lt;ul&gt;
&lt;li&gt;&lt;a href="https://allennlp.org/elmo"&gt;ELMo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://nlp.stanford.edu/projects/glove/"&gt;GloVe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1810.04805"&gt;BERT&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Evaluation / Dataset&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/BLEU"&gt;BLEU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://rajpurkar.github.io/SQuAD-explorer/"&gt;SQuAD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NLP Tasks&lt;ul&gt;
&lt;li&gt;&lt;a href="https://1fly2sky.wordpress.com/2016/04/02/%E5%91%BD%E5%90%8D%E5%AF%A6%E9%AB%94%E8%AD%98%E5%88%A5%E6%8A%80%E8%A1%93named-entity-recognition/"&gt;Named Entity Recognition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Machine_translation"&gt;Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E5%95%8F%E7%AD%94%E7%B3%BB%E7%B5%B1"&gt;Question Answering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://machinelearningmastery.com/gentle-introduction-text-summarization/"&gt;Text Summarization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1711.06861"&gt;Style Transfer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54"&gt;Reading Comprehension&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/"&gt;Open / Closed Domain Conversation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://skymind.ai/wiki/attention-mechanism-memory-network"&gt;Attention Mechanism&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bigdatafinance.tw/index.php/news/578-transformer-rnn-lstm"&gt;Transformer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你平常有在接觸 NLP 領域，可能都已經對這些詞彙朗朗上口；但假如你跟當初參加會議時的我一樣，對 NLP 有興趣但卻什麼都不知道的話也別擔心，之後我會在其他文章解釋這些 NLP 術語並附上最好的學習資源。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/nlp-word-cloud.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;EMNLP 當然不只談了上述東西，但以上詞彙應該沒有人會否認是現在 NLP 研究/應用領域裡頭常用的關鍵字。別忘了我們的目標是「掌握 NLP 基本概念以及關鍵字」。即使是 NLP 初學者如我，先了解這些詞彙的意義以及背後的理論，也能讓你對現在的 NLP 領域有個「還可以」的掌握。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/pan-xiaozhen-423533-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個「高頻關鍵字策略」很簡單，就跟我們從小學外語的方式如出一轍。在初學語言時，比較有效率的學習方法通常是先拿起「英文高頻 5000 單字」或是「常用日本會話 1000 句」來看，而不是去背一輩子可能看不到 5 次的「&lt;a href="https://www.ettoday.net/news/20121228/146060.htm"&gt;火山矽肺症&lt;/a&gt;」英文。&lt;/p&gt;
&lt;p&gt;下個小節你會看到，這個策略的效果還不賴。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="美術館驗收學習成果"&gt;美術館驗收學習成果&lt;a class="anchor-link" href="#美術館驗收學習成果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為期數天的 EMNLP 會議裡的某一天晚上，在&lt;a href="https://zh.wikipedia.org/wiki/%E6%AF%94%E5%88%A9%E6%97%B6%E7%9A%87%E5%AE%B6%E7%BE%8E%E6%9C%AF%E5%8D%9A%E7%89%A9%E9%A6%86"&gt;皇家美術館&lt;/a&gt;有一個與會者專屬的 Social Event。此活動讓所有人都可以欣賞到創作時期橫跨 15 世紀到 21 世紀的 20,000 件藝術作品。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/La-Mort-de-Marat.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        路易．大衛的《馬拉之死》
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了欣賞如法國新古典主義畫家&lt;a href="https://zh.wikipedia.org/wiki/%E9%9B%85%E5%85%8B-%E8%B7%AF%E6%98%93%C2%B7%E5%A4%A7%E5%8D%AB"&gt;路易．大衛&lt;/a&gt;最為人知的&lt;a href="https://gushi.tw/%E6%B3%95%E5%9C%8B%E5%A4%A7%E9%9D%A9%E5%91%BD%E7%9A%84%E7%9C%9F%E5%AF%A6%E6%9A%97%E6%AE%BA%EF%BC%9A%E3%80%8A%E9%A6%AC%E6%8B%89%E4%B9%8B%E6%AD%BB%E3%80%8B/"&gt;《馬拉之死》&lt;/a&gt;等經典藝術作品之外，很多來參加 Social Event 的人是來「 Social 」的：跟一起來的同事聊聊天吃點心、想辦法多認識幾個厲害學者要個名片、或是找幾個陌生人討論彼此的研究。&lt;/p&gt;
&lt;p&gt;利用上節説的簡單策略，我將目前流行的 NLP 術語理解了一遍，接著就這樣在皇家美術館裡頭拿著香檳與比利時巧克力，跟完全陌生的研究者、工程師們互相寒暄，大聊 NLP。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/art-museum.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        皇家美術館裡的 Social Event
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我都跟他們說：「我完全不懂 NLP，是劉姥姥到大觀園。」但卻不只一位跟我說：「我覺得你 NLP 概念很不錯啊！我講的內容你都能理解，甚至還能給我的研究一些建議！」&lt;/p&gt;
&lt;p&gt;但那只是因為我在前幾天學會了這門「 NLP 語言 」的基礎詞彙，並運用我不受任何限制的想像力，針對他們的研究給出一些自己的想法而已。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個夜晚，我學到了第二堂課：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在這個科技變化快速的時代，思考如何用最有效率的方式學習新知非常重要。未來，我們最大的潛力取決於能多快熟悉並掌握新事物。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;別誤會，我並沒有說自己去了 EMNLP 就已經掌握了所有 NLP 專業知識，也沒有說學了一門知識的「基礎詞彙」就已經足夠。但對的方式能為你後面的學習奠定非常好的基礎及方向。&lt;/p&gt;
&lt;p&gt;這邊的重點在於你要找出最有效率的方式學習，並突破傳統「要掌握一門學門得花數年時間的正統教育」的思考框架。現在網際網路上有數不清的資源等待你的探索，幫助你快速起飛。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="開啟全新的學習之旅"&gt;開啟全新的學習之旅&lt;a class="anchor-link" href="#開啟全新的學習之旅"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我當初努力思考「從這趟 EMNLP 之旅，我究竟學到什麼？」這個問題時，發現會議裡頭的確有不少振奮人心的演說以及構思巧妙的論文，但真正讓我自己獲益最多的是以下 3 個體悟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;閱讀好書是最好的長期投資，能豐富並讓你的人生更好。確保你會實際安排時間與精力去閱讀自己感興趣的書籍。&lt;/li&gt;
&lt;li&gt;在這個科技變化快速的時代，思考如何用最有效率的方式學習新知非常重要。未來我們最大的潛力取決於能多快熟悉並掌握新事物。&lt;/li&gt;
&lt;li&gt;旅行其中一個好處是能讓你探索自我並改變人生。&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Eglise-Notre-Dame-du-Sablon.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        薩布隆聖母教堂
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;前 2 點我們已經在前面花了不少篇幅解釋，在這邊我們花一點點篇幅說明最後一項：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        旅行其中一個好處是能讓你探索自我並改變人生。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對我而言，這次的旅行是一個人生的轉捩點。它正式地打開了我「多年」對深度學習以及 NLP 興趣的開關，促使我開始大量學習相關知識。&lt;/p&gt;
&lt;p&gt;之後的部落格，除了&lt;a href="https://leemeng.tw/tag/zi-liao-ke-xue.html"&gt;資料科學&lt;/a&gt;以及&lt;a href="https://leemeng.tw/tag/zi-liao-gong-cheng.html"&gt;資料工程&lt;/a&gt;的文章以外，也將會包含自己學習深度學習以及 NLP 時使用到的線上資源和個人心得。如果你也對 NLP 與深度學習有興趣，或許之後可以從這裡學到點東西；而如果你能跟我分享好的 NLP 學習資源，我也會非常感激！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/bruno-van-der-kraan-750941-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管如何，我都希望你能從我的故事裡頭獲得些啟發，重新思考你自己的學習，並做一些好的改變。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="布魯塞爾美麗風景"&gt;布魯塞爾美麗風景&lt;a class="anchor-link" href="#布魯塞爾美麗風景"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;篇幅有限，這邊簡單跟你分享這次旅程中我所看到的一些美麗景色。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/IMG_1186.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        EMNLP 會場附近風光
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Grand-Place.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        布魯塞爾大廣場
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Cathedrale-des.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖彌額爾聖古都勒主教座堂
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Cathedrale-des-inner.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        主教座堂內部
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale-2.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖心聖殿
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale-inner.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        聖殿內部
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/emnlp2018/Basilique-Nationale.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        從聖心聖殿眺望布魯塞爾
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這趟旅途雖然到此告一段落，但讓我們在下次的 NLP 文章再次碰面吧！：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="隨筆"></category><category term="自然語言處理"></category><category term="深度學習"></category></entry><entry><title>資料科學家 L 的奇幻旅程 Vol.2 如何用資料工程當個時間旅人</title><link href="https://leemeng.tw/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html" rel="alternate"></link><published>2018-11-09T21:00:00+09:00</published><updated>2018-11-09T21:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-11-09:/journey-of-data-scientist-L-part-2-time-traveling-with-data-engineering.html</id><summary type="html">&lt;p&gt;「資料工程」與「時間旅行」，兩個看似毫無相關的詞能擦出什麼火花？在這篇文章裡頭，我想跟你分享一個輕鬆話題：身為資料科學家的我，是如何利用資料工程在公司裡頭當個「時間旅人」的。當然，實際上每家公司的 DS 以及 DE 的工作內容都會有所不同，了解這個事實並調整期待，將幫助你找到最適合自己的工作環境。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;奇幻旅程的第一篇&lt;/a&gt;裡頭你已經看到，為何了解企業內部使用的 KPI 以及熟悉公司內部的「數據流動」能讓一個資料科學家在工作上更如魚得水。&lt;/p&gt;
&lt;p&gt;那是一篇稍微正經嚴肅，但我認為對資料科學家來說（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist，後簡稱 DS）很有幫助的一篇文章。不過今天，我想跟你分享一個輕鬆話題：身為 DS 的我，是如何利用資料工程（Data Engineering）在公司裡頭當個「時間旅人」的。&lt;/p&gt;
&lt;p&gt;「時間旅人？你在開玩笑嗎？」&lt;/p&gt;
&lt;p&gt;「資料工程跟時間旅行八竿子沒關係吧！」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/dog-705820_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        這可能是現在困惑的你的最佳寫照
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對對對我知道。&lt;/p&gt;
&lt;p&gt;你或許正歪著頭，想著我是不是下了個釣魚標題騙你進來。我得承認自己是個浪漫主義者，常常會將工作上的任務跟看的小說、電影做聯想。但我想，聯想力或許就是人類跟 AI 最大的差距吧！我也不覺得這是件壞事：）&lt;/p&gt;
&lt;p&gt;拉回正題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="所以什麼是時間旅人"&gt;所以什麼是時間旅人&lt;a class="anchor-link" href="#所以什麼是時間旅人"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對我來說，一個理想的「時間旅人」要能掌握兩種超能力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能夠預測未來，洞察先機&lt;/li&gt;
&lt;li&gt;能夠回到過去，修正錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而事實上後面我們會發現要實現這兩個能力，尤其是後者，除了「資料科學」以外，我們還需要「資料工程」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/wormhole-2514312_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        掌握資料工程讓我們彷彿可以穿越時空
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="預測未來，洞察先機"&gt;預測未來，洞察先機&lt;a class="anchor-link" href="#預測未來，洞察先機"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你也是一名 DS 或是分析人員的話，應該可以猜得到，在資料科學領域裡頭，所謂的「預測未來」是指「建立某些預測模型」。&lt;/p&gt;
&lt;p&gt;只不過，光是建立出一個可以做預測的模型並不足夠。&lt;/p&gt;
&lt;p&gt;不管是簡單的 &lt;a href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"&gt;Random Forest&lt;/a&gt; 還是複雜的 &lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"&gt;Neural Network&lt;/a&gt;，要讓你的預測模型真正發揮影響力，你需要讓它實際上線做預測，而不只是活在你的 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt; 裡頭。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在資料工程領域裡，讓預測模型實際部署上線，才代表你能真正地開始「預測未來」。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/crystal-kwok-487022-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        你需要資料工程的知識來將一個 DS 做的預測模型「弄上線」
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一些常見的預測模型案例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用者在安裝 App 7 天以後會不會繼續使用&lt;/li&gt;
&lt;li&gt;顯示給使用者的廣告的點擊率&lt;/li&gt;
&lt;li&gt;推薦給使用者的文章會不會被閱讀&lt;/li&gt;
&lt;li&gt;預測使用者性別（儘管她/他沒說）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等。&lt;/p&gt;
&lt;p&gt;在目前的公司，我主要使用 &lt;a href="https://aws.amazon.com/tw/sagemaker/"&gt;Amazon SageMaker&lt;/a&gt; 、 &lt;a href="https://aws.amazon.com/tw/ecs/features/?nc1=h_ls"&gt;Amazon ECS&lt;/a&gt; 並搭配 &lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;Airflow&lt;/a&gt; 來將這些預測模型部署到 Production 環境，以對真實世界做預測。&lt;/p&gt;
&lt;p&gt;眼尖的讀者會發現，撇除模型或演算法，上述提到的工具並不實際跟「分析」有關，而比較偏向「工程」。為了發揮這些工具的最大效用，你可能需要了解 &lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;ETL 的概念&lt;/a&gt;以及&lt;a href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html"&gt;如何使用 Docker&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;想要有效地預測真實世界，這些工具不可或缺。&lt;/p&gt;
&lt;p&gt;在下篇文章，我將說明如何應用上述工具以建立可靠的預測流程。而在本文，我想強調的是另一個你能透過資料工程培養的超能力：「回到過去」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="回到過去，修正錯誤"&gt;回到過去，修正錯誤&lt;a class="anchor-link" href="#回到過去，修正錯誤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;如果你現在正努力學習資料科學，期待未來能成為一個 DS，你可能會「想像」進了一間新公司以後，前人都已經幫你把所有專案 / 產品分析需要的關鍵績效指標（&lt;strong&gt;K&lt;/strong&gt;ey &lt;strong&gt;P&lt;/strong&gt;erformance &lt;strong&gt;I&lt;/strong&gt;ndicators，即 KPI）定義完成。&lt;/p&gt;
&lt;p&gt;除此之外，所有需要分析的數據也都事先被計算好並存放在&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html#%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2"&gt;資料倉儲或是資料湖&lt;/a&gt;裡頭供你大展身手。&lt;/p&gt;
&lt;p&gt;而你所需要做的，就是開始下 &lt;a href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;SQL 查詢&lt;/a&gt;並建立分析模型。&lt;/p&gt;
&lt;p&gt;如果你的公司規模如 Facebook、Google 或是 Netflix 那麽龐大，裡頭已經有非常專業的&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;資料平台團隊&lt;/a&gt;，則或許上述為真。身為一個小小的 DS，你無須擔心什麼 KPI 的定義或是數據品質。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/data-science/sean-pollock-203658-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        規模非常大的企業讓你看到自己的渺小，但好處是身為一個 DS，你要擔心的東西可能也比較少（數據品質、KPI 定義 etc）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但很多時候，這種抱持著「KPI 永遠是對的！」的假設需要承擔不小風險。&lt;/p&gt;
&lt;p&gt;一般企業（尤其是新創）在事後發現，一直以來追蹤、監視的 KPI 計算需要做修正是常有的事情。&lt;/p&gt;
&lt;p&gt;最常見的一個例子就是發現當時用來計算 KPI 的 SQL 查詢需要修正，而其原因可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;之前產品釋出新功能，但使用者利用該功能的歷史紀錄沒有被反映到 KPI 裡頭&lt;/li&gt;
&lt;li&gt;少做了數據品質的檢查，導致表格裡頭有 NULL 的使用者 ID 等問題，無法識別用戶&lt;/li&gt;
&lt;li&gt;KPI 裡頭包含了不該被計算在裡頭的雜訊&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不管是哪項，我們都需要做修正。&lt;/p&gt;
&lt;p&gt;具體來說，是修正該 SQL 查詢的邏輯、更新 KPI 定義，並將改變反映到 Production 環境。&lt;/p&gt;
&lt;p&gt;這樣你才能確保在新的一天，該 KPI 能以最正確的方式被計算出來（假設我們一天算一次該 KPI）。&lt;/p&gt;
&lt;p&gt;畢竟如同我們在奇幻旅程的第一篇：&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;新人不得不問的 2 個問題&lt;/a&gt;裡頭看到的，錯誤的 KPI 數字會讓整個數據團隊或是公司策略走錯方向，影響可說是非常深遠，得及早修正。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/airflow/tim-gouw-68319-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在你修正該 SQL 查詢並部署到 Production 環境以後，唷呼！明天我們的 KPI 就會用最正確的邏輯被計算了！&lt;/p&gt;
&lt;p&gt;不過別開心得太早。&lt;/p&gt;
&lt;p&gt;過去的數個月，甚至數年間持續被顯示在儀表板（Dashboard）上的數字可不會全部「自動地」被以新的邏輯重新計算。&lt;/p&gt;
&lt;p&gt;但同時每個 PM 都拉著你，急著向你確認，到底用了最新的定義以後，該 KPI 過去的數字會變得如何、以及其對過去的分析的影響有多大。&lt;/p&gt;
&lt;p&gt;這時你需要用新的計算邏輯 / KPI 定義來「更新」過去全部的計算結果，才能讓你公平地比較過去、現在以及未來的數字。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/carlos-muza-84523-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        修正 KPI 定義以後，你會想要確保過去的數據也都隨之更新
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這時候資料分析能力幫不了你，你需要的是資料工程的知識（或是一個老實的資料工程師，&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer，DE）。&lt;/p&gt;
&lt;p&gt;好消息是，如果你已經有在使用如 &lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;Airflow&lt;/a&gt; 等工作流程管理工具來管理你的 ETL，要「回到過去」並利用最新的計算邏輯來修正過去所有「錯誤數字」 並不是一件太難的事情。&lt;/p&gt;
&lt;p&gt;事實上，「將過去執行過的 ETL 工作重新執行」這個任務在各個公司屢見不鮮，在資料工程領域裡頭甚至有其專業術語：Backfill。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/backfilling.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        Backfill：行家才懂的資料工程關鍵字
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Backfill 本身直接翻譯成「回填」，在資料工程領域裡頭，代表著「用新的計算邏輯 / SQL 查詢」將過去執行過的 ETL 工作重新執行。&lt;/p&gt;
&lt;p&gt;更白話的比喻，你可以想像 Backfill 就是把以前的你或是前人挖的坑、犯的錯「填好填滿」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這邊，「計算 KPI 」就是所謂的 ETL 工作。&lt;/p&gt;
&lt;p&gt;目前我常常使用 Airflow 以及 &lt;a href="https://aws.amazon.com/tw/emr/"&gt;Amazon EMR&lt;/a&gt; 來重新執行 ETL 工作，並讓實際的計算運行在 EMR 環境上以 scale。&lt;/p&gt;
&lt;p&gt;Backfill 常見到 Airbnb 甚至自己建立了一個 &lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-the-series-finale-2cc92ff14b0"&gt;Backfill Framework&lt;/a&gt;。而在&lt;a href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;裡頭，我則詳細探討了 Airflow 與資料工程的關係，以及你可以如何利用 Airflow 來「回到過去」，修正一切的錯誤。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/time-machine.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        利用 Airflow 回到過去，修正錯誤
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就算你現在不需自己做資料工程，了解相關概念也會有所幫助。&lt;/p&gt;
&lt;p&gt;在尋找數據相關工作或者想了解某個公司的數據環境時，可以詢問該公司的 DS / DE：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        所以你們平常是怎麼做 Backfill ？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這是了解一個公司內部的數據處理流程很好的一個切入點。&lt;/p&gt;
&lt;p&gt;驚艷對方的同時，又能讓你實際了解非常多該公司數據平台的細節。&lt;/p&gt;
&lt;p&gt;如果你立志成為 DS，且不希望之後操心數據品質或是自己對資料工程沒興趣，那你反而更需要搞清楚，想去的公司的數據環境如何，能否讓你專注在數據分析；如果你是想成為 DE，你能透過這個問題，逐漸了解這家公司適不適合你大展身手。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這篇文章，我非常輕描淡寫地談了作為一個 DS，我如何利用資料工程當個「時間旅人」：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;預測未來，洞察先機&lt;/li&gt;
&lt;li&gt;回到過去，修正錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/journal/wormhole.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這只是我個人的例子。&lt;/p&gt;
&lt;p&gt;實際上，每家公司的 DS 以及 DE 的工作內容都會有所不同。了解這個事實並調整期待，將幫助你找到最適合自己的工作環境。&lt;/p&gt;
&lt;p&gt;如果你對資料工程多了點興趣，可以參考之前的文章：&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;就這樣，我們下個蟲洞見！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="日誌"></category><category term="資料科學"></category><category term="資料工程"></category></entry><entry><title>資料科學文摘 Vol.7 數據技能、深度學習以及 AI 的倫理道德</title><link href="https://leemeng.tw/data-science-digest-volume-7.html" rel="alternate"></link><published>2018-10-26T08:00:00+09:00</published><updated>2018-10-26T08:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-26:/data-science-digest-volume-7.html</id><summary type="html">&lt;p&gt;今天讓我跟你分享 4 篇跟數據以及人工智慧相關的文章。在第一篇文章，我們將看到如何用一個簡單、有效的方式來決定應該學習什麼「數據技能」；在第二篇文章，我們則會看到如何透過數據，了解網際網路是如何快速發展成為人們每天不可或缺的一部分。接著我們會聽聽在計算神經科學領域的先驅之一，泰瑞教授解釋何謂「深度學習」以及 AI 與人類智慧如何擦出火花；最後，我們將一窺 AI 的倫理道德議題以及著名的電車難題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今天讓我跟你分享 4 篇與數據以及人工智慧相關的文章。&lt;/p&gt;
&lt;p&gt;在第一篇文章，我們將看到如何用一個簡單、有效的方式來決定應該學習什麼「數據技能」；在第二篇文章，我們則會看到如何透過數據，了解網際網路是如何快速地發展成為人們每天不可或缺的一部分。&lt;/p&gt;
&lt;p&gt;接著我們會聽聽在計算神經科學領域的先驅之一，泰倫教授解釋何謂「深度學習」以及 AI 與人類智慧如何擦出火花；最後，我們將一窺 AI 的倫理道德議題以及著名的電車難題。&lt;/p&gt;
&lt;p&gt;本週閱讀清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;Which Data Skills Do You Actually Need? This 2&amp;times;2 Matrix Will Tell You.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#The-internet-history-has-just-begun"&gt;The internet's history has just begun&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#A-pioneering-scientist-explains-"&gt;A pioneering scientist explains "deep learning"&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;Establishing an AI code of ethics will be harder than people think&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;廢話不多說，讓我們開始閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;
&lt;a href="https://hbr.org/2018/10/which-data-skills-do-you-actually-need-this-2x2-matrix-will-tell-you" target="_blank"&gt;Which Data Skills Do You Actually Need? This 2&amp;times;2 Matrix Will Tell You.&lt;/a&gt;&lt;a class="anchor-link" href="#Which-Data-Skills-Do-You-Actually-Need?-This-2&amp;times;2-Matrix-Will-Tell-You."&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://hbr.org/2018/10/which-data-skills-do-you-actually-need-this-2x2-matrix-will-tell-you" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/oct18_18_607367679.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同我們在&lt;a href="https://leemeng.tw/demystify-the-hype-of-data-science-and-its-value.html"&gt;揭開資料科學的神秘面紗&lt;/a&gt;一文提到，在一個數據時代，提升「資料科學力」這件事情不管是對你自己，或者是對公司的資料科學團隊來說都非常重要。畢竟&lt;a href="http://reports.weforum.org/future-of-jobs-2016/employment-trends/"&gt;未來將需要更多跟數據處理相關的人才&lt;/a&gt;，數據導向的企業也越來越多。&lt;/p&gt;
&lt;p&gt;但是要學的東西太多，你可能不知從何下手，或者什麼都想學。&lt;/p&gt;
&lt;p&gt;這篇文章提供了一個簡單矩陣，將那些商業分析師、資料科學家以及機器學習工程師等數據相關職業的常見技能，依照&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;學習、精通該技能所需時間（Time, X 軸）&lt;/li&gt;
&lt;li&gt;學習後能為自己及企業帶來的效用（Utility, Y 軸）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;兩個要素，劃分出一個有 4 個象限的矩陣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/data-skill-matrix.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        將常見的數據技能分門別類，以利建立學習的優先順序
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從圖中你可以看到每個象限有不同的特色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;左上 Plan：這邊的技能如人工智慧、機器學習，雖然需要花更多時間來精通，但是未來很有用，因此你應該開始規劃長期的學習計畫&lt;/li&gt;
&lt;li&gt;左下 Ignore：這裡頭的數據技能要花不少時間學習，但在未來能產生的價值卻不高，你應該盡可能忽略它們&lt;/li&gt;
&lt;li&gt;右上 Learn：這邊的技能不需花太多成本精通，但能為你自己及企業帶來不少價值，應該馬上找時間學習&lt;/li&gt;
&lt;li&gt;右下 Browse：這邊的技能用處普普，但學習成本也不高，可以瀏覽、儲存相關文章，等有需要的時候拿出來用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;事實上，上面的技能擺放位置僅供參考，因為它只是某家公司的資料團隊自己判斷的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        你要思考的是，那些你想學的「數據技能」，在你現有的實力下，分別需要花多少時間精通？而它們又能在未來為你帶來多少幫助？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在你心中或是企業策略裡頭，每個數據技能有了自己的位置以後，你就能非常清楚地知道該開始規劃什麼長期學習目標、該著手學習什麼，而哪些技能可以慢點再點。&lt;/p&gt;
&lt;p&gt;以我自己為例，就有一些長期學習「機器學習」的規劃，而在日常工作時就頻繁地學習「資料科學」以及「資料工程」。&lt;/p&gt;
&lt;p&gt;這個決定學習優先順序的概念，跟我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html"&gt;資料科學文摘 Vol.5 數據科學家面臨的挑戰、儀表板設計以及未來的被駭人生&lt;/a&gt;一文中出現過的&lt;a href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;艾森豪矩陣&lt;/a&gt;有異曲同工之妙。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-internet-history-has-just-begun"&gt;
&lt;a href="https://ourworldindata.org/internet-history-just-begun" target="_blank"&gt;The internet history has just begun&lt;/a&gt;&lt;a class="anchor-link" href="#The-internet-history-has-just-begun"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://ourworldindata.org/internet-history-just-begun" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/Share-of-internet-users-cover.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然多數的我們早已習慣網際網路（Internet）的存在，但事實上以人類幾百萬年的歷史來看，網際網路的出現也不過短短 20 年，是一個非常年輕的發明（儘管它已經展現巨大影響力）&lt;/p&gt;
&lt;p&gt;現在很多人已經無法脫離 Facebook、Google Maps、維基百科甚至是 Github。不過很難想像在我出生的時候（西元 1990 年）這些服務以及網際網路本身都還不存在。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/Share-of-internet-users.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        圖中粗線代表各大洲近 3 個月有使用任何裝置上網的人口比例，每一條細線則代表一個國家。頂端粗線為北美（78 %）、最底下的粗線則為撒哈拉以南非洲（20 %）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管從上圖我們已經可以了解 20 年來網際網路的蓬勃發展，你會發現在 2016 年，上網人口也只佔全球人口的 46 %。&lt;/p&gt;
&lt;p&gt;也就是說，世界上還有一半以上的人類沒有像你閱讀這篇文章般地使用網際網路。南亞以及撒哈拉以南也只有 20 ~ 30 % 的人在上網、東亞平均則為 53 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/curtain.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;隨著網際網路在這些人口成長迅速的地區快速普及，可以合理相信，網際網路在接下來數年還會持續大幅度地改變人們的生活模式。&lt;/p&gt;
&lt;p&gt;或許 Internet 的歷史現在才正式拉開序幕。&lt;/p&gt;
&lt;p&gt;對我來說，閱讀 Max Roser 這篇文章給我的最大的啟示是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        人類生活模式的轉變只會越來越快，我們需要加速運轉自己的大腦，以跟上未來的變化。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 deep-learning""="" id="A-pioneering-scientist-explains-"&gt;
&lt;a href="https://www.theverge.com/2018/10/16/17985168/deep-learning-revolution-terrence-sejnowski-artificial-intelligence-technology" target="_blank"&gt;A pioneering scientist explains "deep learning"&lt;/a&gt;&lt;a class="anchor-link" deep-learning""="" href="#A-pioneering-scientist-explains-"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://www.theverge.com/2018/10/16/17985168/deep-learning-revolution-terrence-sejnowski-artificial-intelligence-technology" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/jbareham_170215_1460_0001_v2_4.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://mitpress.mit.edu/books/deep-learning-revolution"&gt;The Deep Learning Revolution&lt;/a&gt; 的作者 &lt;a href="https://www.salk.edu/scientist/terrence-sejnowski/"&gt;Terrence Sejnowski（後簡稱泰瑞）&lt;/a&gt;教授專注在研究神經科學（Neuroscience）以及計算機科學。&lt;/p&gt;
&lt;p&gt;在這篇採訪裡頭，他簡單解釋了人工智慧、機器學習及近年備受注目的深度學習之間的關係。一言以蔽之，就如下圖所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/couins-of-ai.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        人工智慧包含了機器學習，而機器學習包含深度學習
                        （&lt;a href="https://towardsdatascience.com/cousins-of-artificial-intelligence-dda4edc27b55" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我想平常有在閱讀本部落格的讀者應該都十分熟悉這個關係，不須贅述。不過了解深度學習為何變得如此熱門的人就不多了。&lt;/p&gt;
&lt;p&gt;一切要從 2012 年，全世界最大的 AI 學術會議 &lt;a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems"&gt;NIPS&lt;/a&gt; 說起。當年深度學習裡頭最關鍵的技術 &lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"&gt;Backpropagation&lt;/a&gt; 的發明者 &lt;a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton"&gt;Geoffrey Hinton&lt;/a&gt; 教授與他的團隊展示了如何利用深度學習，一口氣將擁有 10,000 個圖片分類以及多達 1,000 萬張照片的 &lt;a href="http://www.image-net.org/"&gt;ImageNet 分類挑戰&lt;/a&gt;的錯誤率降低近 20 %。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/imagenet.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這之前，儘管已經有非常多的研究，這個挑戰的錯誤率每年下降不到 1 %。我們可以說，深度學習模型的出現，瞬間縮減了 20 年的研究時間。在那之後，人人爭相學習，開啟「大深度學習」時代。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在人工智慧發展的背後推手主要即為深度學習，而深度學習的概念則來自於我們對人類大腦的理解。&lt;/p&gt;
&lt;p&gt;泰瑞教授表示我們正處於人工智慧以及人類智慧相互匯合的時代：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        AI 與人類智慧正在匯合。當我們越了解大腦運算的方式，就會越傾向將該知識反映到 AI 上面，讓 AI 變得更強大。但同時，更強大的 AI 也讓我們用全新的方式以及理論來了解人類大腦以及上千萬神經元的運作方式。因此你可以看到在「神經科學」以及「人工智慧」之間有一個不斷互相學習的循環。
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ Terrence&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個論點跟我們之前在&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;一文中聊到的想法十分類似：到最後，我們及我們的下一代將不在只是從其他人類學習知識，而是向那些我們創造出來的 AI 學習。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/learn-from-machine/andy-kelly-402111-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        未來教育模式的可能改變：從機器 / AI 中學習
                        （圖片來源：&lt;a href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html" target="_blank"&gt;從彼此學習 - 淺談機器學習以及人類學習&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;舉個簡單例子，等到語音辨識的技術更為成熟，以後你的小孩可能不再需要一位昂貴的英文老師教他 / 她怎麼唸英文單字，而是透過一個 24 小時不休息的 AI，聆聽由深度學習自動產生的擬人發音來學習英文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;
&lt;a href="https://www.technologyreview.com/s/612318/establishing-an-ai-code-of-ethics-will-be-harder-than-people-think/" target="_blank"&gt;Establishing an AI code of ethics will be harder than people think&lt;/a&gt;&lt;a class="anchor-link" href="#Establishing-an-AI-code-of-ethics-will-be-harder-than-people-think"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://www.technologyreview.com/s/612318/establishing-an-ai-code-of-ethics-will-be-harder-than-people-think/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/timeline-ai-now_1.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        人工智慧的進步一日千里，快到我們還無法為其建立一套完善的道德準則。更甚者，完美的準則一開始就不存在。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;AI 的快速發展讓我們已經（快要）可以把一些複雜任務如臉部辨識、自動駕駛等工作交給機器處理，從此過著輕鬆快樂的生活。&lt;/p&gt;
&lt;p&gt;但你知道事情從來沒有那麼單純。&lt;/p&gt;
&lt;p&gt;除了合乎程式邏輯以外，AI 在執行這些複雜任務時，很多時候會牽涉到道德問題。那麼又應該要由誰來決定這些 AI 在執行任務時應該要遵守什麼規定呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/Artificial-intelligence-human-looking-robot-thinking-machine-world.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        「思考」中的 AI
                        （&lt;a href="https://engineercalcs.com/ethics-and-ai-the-future-dilemma-humans-will-face/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;美國麻省理工大學 MIT 開發了一個名為「&lt;a href="http://moralmachine.mit.edu/"&gt;道德機器（Moral Machine）&lt;/a&gt;」的網站，裡頭重現了著名的&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%89%E8%BD%A8%E7%94%B5%E8%BD%A6%E9%9A%BE%E9%A2%98"&gt;電車難題&lt;/a&gt;，目的就是為了告訴大家，每個人都有不同的道德標準，要為 AI 建立一套所有人都能滿意的道德準則非常困難。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/moral-machine.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        自動駕駛版本的電車問題：誰該活？誰死了也沒關係？AI 該遵守誰的道德準則？
                        （圖片來源：&lt;a href="http://moralmachine.mit.edu/" target="_blank"&gt;麻省理工大學「道德機器」網頁截圖&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你點進去回答完 13 道難題了嗎？&lt;/p&gt;
&lt;p&gt;如果還沒，我強烈建議你點進去&lt;a href="http://moralmachine.mit.edu/"&gt;該網站（站內可選中文）&lt;/a&gt;，並利用自己的道德準則決定自動駕駛車的運行方向，再實際看看有多少人以及動物因此受到影響，並了解其他人下的決定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/button-161555_1280.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        哪邊的按鈕你點比較多次，左邊還是右邊？
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你跟我一樣，花了不少時間掙扎猶豫，你就會了解「奠定 AI 所需要遵守的道德準則」這個課題有多麽困難。&lt;/p&gt;
&lt;p&gt;就算你好不容易決定了，你也知道該判斷並不完美，你可能之後會後悔，且也不是所有人都同意你的決定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/humanism.jpeg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E7%BA%BD%E7%BA%A6%E5%A4%A7%E5%AD%A6%E6%B3%95%E5%AD%A6%E9%99%A2"&gt;紐約大學法學院&lt;/a&gt;的 &lt;a href="https://en.wikipedia.org/wiki/Philip_Alston"&gt;Philip Alston&lt;/a&gt; 教授則認為我們應該以「維護人權」為最高判斷原則，建立不會傷害到人類的 AI。以上面的自動駕駛來說，一個以「人文主義」為原則的自動駕駛車會選擇避開人群，而往一整群貓咪撞下去。&lt;/p&gt;
&lt;p&gt;人文主義或許不完美，但或許是一個不錯的基準點。&lt;/p&gt;
&lt;p&gt;只是我擔心的是，在這數據主義以及資本主義橫行的年代，人文主義最後是否能站得住腳。&lt;/p&gt;
&lt;p&gt;如果自動駕駛還搭配了臉部辨識系統，利用大數據分析以及搜尋&lt;a href="https://www.legalaidnyc.org/nypd-gang-database/"&gt;犯罪記錄系統&lt;/a&gt;，自動車發現前方分別是一隻貓以及一個罪犯，它能否選擇撞人不撞貓呢？&lt;/p&gt;
&lt;p&gt;畢竟以「數據主義」的立場，「人」不再是至高無上的存在，一切由數據說的算。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;呼！以上就是本週文摘的內容啦！&lt;/p&gt;
&lt;p&gt;希望這些跟數據、AI 相關的文章以及我個人的想法有刺激到你的思考，讓你的生活變得豐富了一些，並實際思考做點什麼。&lt;/p&gt;
&lt;p&gt;歡迎留言跟我說說你自己的想法、分享這篇文章或是點擊下面的訂閱按鈕。&lt;/p&gt;
&lt;p&gt;最重要的，記得去&lt;a href="http://moralmachine.mit.edu/"&gt;道德機器網站&lt;/a&gt;實際做一下題目，感受一下 AI 時代的倫理難題。&lt;/p&gt;
&lt;p&gt;就這樣，我們下次見啦！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.6 人類壽命大進展、GAN、數據工廠以及產品分析</title><link href="https://leemeng.tw/data-science-digest-volume-6.html" rel="alternate"></link><published>2018-10-14T14:00:00+09:00</published><updated>2018-10-14T14:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-14:/data-science-digest-volume-6.html</id><summary type="html">&lt;p&gt;這週我們一樣保持閱讀的「營養均衡」，從全球平均壽命變化的資料視覺化、深度學習最夯的「對抗生成網路」話題、產品分析框架到理解何謂「數據工廠」，我希望能讓閱讀本文摘的你，廣泛地了解各領域跟「資料」相關的議題，並進一步找出自己的興趣，加以深度探索。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文摘來到第 6 篇，不知道這是你看的第幾篇呢？&lt;/p&gt;
&lt;p&gt;這週我們一樣保持閱讀的「營養均衡」，從全球平均壽命變化的資料視覺化、深度學習最夯的「對抗生成網路」話題、產品分析框架到理解何謂「數據工廠」，我希望能讓閱讀本文摘的你，廣泛地了解各領域跟「資料」相關的議題，並進一步找出自己的興趣，加以深度探索。&lt;/p&gt;
&lt;p&gt;本週閱讀清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;Twice as long &amp;ndash; life expectancy around the world&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;Interview with Deep Learning Researcher and The GANfather: Dr. Ian Goodfellow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data-Factories"&gt;Data Factories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;Engagement Drives Stickiness Drives Retention Drives Growth&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始閱讀吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;
&lt;a href="https://ourworldindata.org/life-expectancy-globally" target="_blank"&gt;Twice as long &amp;ndash; life expectancy around the world&lt;/a&gt;&lt;a class="anchor-link" href="#Twice-as-long-&amp;ndash;-life-expectancy-around-the-world"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://ourworldindata.org/life-expectancy-globally" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/life-expectancy.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在全球健康以及公衛還是存在很多不平等，但別忘了我們已經取得巨大進展。&lt;/p&gt;
&lt;p&gt;如同我們上週在&lt;a href="https://leemeng.tw/gapminder.html"&gt;如何用 30 秒了解台灣發展與全球趨勢：用 GapMinder 培養正確世界觀&lt;/a&gt;一文中聊到，好的資料視覺化可以幫助我們快速地了解世界。這週牛津大學的經濟學家 &lt;a href="https://www.maxroser.com/about/"&gt;Max Roser&lt;/a&gt; 用 3 張橫跨 2 世紀的世界地圖，來告訴我們全球平均壽命（Life Expectancy）的變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/3-world-maps-of-life-expectancy-e1538651530288.png"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以看到這 200 年來，生活在世界上的人們經歷了 3 個階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 1800 年以前所有人的平均壽命 &amp;lt; 40 歲，大部分兒童早夭&lt;/li&gt;
&lt;li&gt;在 1950 年，部分地區健康大幅改善，歐美及日本的平均壽命為 60 歲，為非洲整體平均的 2 倍，鴻溝顯而易見&lt;/li&gt;
&lt;li&gt;在 2015 年，幾乎全球所有地區都能活到 60 歲以上，鴻溝逐漸縮小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們都希望自己親人及朋友活得長久。就是因為這樣，你更應該感激這 200 年人類取得的進步。&lt;/p&gt;
&lt;p&gt;近 2 世紀人類在健康狀況改善的卓越成就，套句 Max Roser 的說法就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        在人類歷史上，這是我們第一次改善了整個人群的健康狀況。在人類健康狀況停滯千年後，封印終於解除。
                        &lt;br/&gt;
&lt;span style="float:right;margin-right: 1.5rem"&gt;─ Max Roser&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是，在 1950 年，台灣的平均壽命為 55.5 歲，經過了 65 年，來到了 80 歲。平均每 3 年，台灣人的平均壽命增加 1 歲，成長速度不可小覷。&lt;/p&gt;
&lt;p&gt;你也可以用 &lt;a href="https://ourworldindata.org/life-expectancy"&gt;Our World in Data&lt;/a&gt; 提供的圖表來看看全球變化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;iframe src="https://ourworldindata.org/grapher/life-expectancy?year=2015" style="width: 100%; height: 600px; border: 0px none;"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;
&lt;a href="https://hackernoon.com/interview-with-deep-learning-researcher-and-the-ganfather-dr-ian-goodfellow-cd300863ecff" target="_blank"&gt;Interview with Deep Learning Researcher and The GANfather: Dr. Ian Goodfellow&lt;/a&gt;&lt;a class="anchor-link" href="#Interview-with-Deep-Learning-Researcher-and-The-GANfather:-Dr.-Ian-Goodfellow"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://hackernoon.com/interview-with-deep-learning-researcher-and-the-ganfather-dr-ian-goodfellow-cd300863ecff" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/v2-11b2d0d097085a51360d3756aff65435_1200x500.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;伊恩．古德費洛（Ian Goodfellow）是 &lt;a href="https://ai.google/research/people/105214"&gt;Google Brain 的研究科學家&lt;/a&gt;，最知名的成就是在 2014 年推出&lt;a href="https://buzzorange.com/techorange/2018/03/12/google-super-intern/"&gt;生成對抗網路（Generative Adversarial Network, 簡稱 GAN）&lt;/a&gt;。GAN 最基本的概念是讓兩個神經網路互相對抗，讓模型可以依靠較少的人類介入以及訓練資料，自己學會高度複雜的工作。自從那之後，GAN 領域的研究一日千里，現在 &lt;a href="https://arxiv.org/abs/1406.2661"&gt;arXiv 上該論文有超過 5,000 次引用&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/gan-example.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        GAN 有很多用途，像是自動產生高畫質圖片
                        （圖片來源：&lt;a href="https://youtu.be/AJVyzd0rqdc?t=575" target="_blank"&gt;NIPS 2016 Tutorial&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;GAN 有非常多「用途」，像是自動產生圖片、創作音樂、寫詩或是製造假新聞。但在這篇文摘裡頭，讓我們先專注於這篇訪問伊恩的內容。&lt;/p&gt;
&lt;p&gt;在這篇訪談裡頭，伊恩給想開始研究 ML 的人一些建議：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;徹底學好基礎。像是寫程式、除錯、並學習機率及線性代數。很多時候在研究 ML 的時候，幫助你最多的是扎實的基礎，而不是非常前衛的想法（這是他從 Google Brain 創立者&lt;a href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE"&gt;吳恩達&lt;/a&gt;得到的建議）&lt;/li&gt;
&lt;li&gt;沒有什麼運算資源時，要選對研究主題。（沒有像是 Google 那樣等級的運算資源的話，就不要想去實現全世界最準的 &lt;a href="http://www.image-net.org/"&gt;ImageNet&lt;/a&gt; 分類器）&lt;/li&gt;
&lt;li&gt;一開始找個人家已經做過的題目來磨練你的 ML 能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最後一點需要額外解釋一下。&lt;/p&gt;
&lt;p&gt;如果你在練習 ML 的時候，選擇跟隨前人「已經成功」的東西來實作的話，這樣就算自己實作出來的模型表現不好，你也知道只是你的實作、基本功出了問題，而不是這個點子錯了。接著只要回去複習基本概念、加強實作功力即可。&lt;/p&gt;
&lt;p&gt;但如果你的 ML 的實作能力沒到一個水平，然後又馬上想要嘗試一個天馬行空的點子／演算法，最後實作出來失敗，你很難知道，到底是點子本身有瑕痴，還是因為你實作能力差而出問題。&lt;/p&gt;
&lt;p&gt;另外如果你現在就想開始了解 GAN 的話，可以試試 &lt;a href="https://poloclub.github.io/ganlab/"&gt;GAN lab&lt;/a&gt;，在網頁上玩玩生成對抗網路。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/gan-lab.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
                        GAN lab 讓你可以利用網頁瀏覽器直接探索 GAN 並了解其運作原理
                        （&lt;a href="https://poloclub.github.io/ganlab/" target="_blank"&gt;圖片來源&lt;/a&gt;）
                        
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data-Factories"&gt;
&lt;a href="https://stratechery.com/2018/data-factories/" target="_blank"&gt;Data Factories&lt;/a&gt;&lt;a class="anchor-link" href="#Data-Factories"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://stratechery.com/2018/data-factories/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/data-factory.jpg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身處數據時代，我們應該更關心自己的資料被怎麼利用。&lt;/p&gt;
&lt;p&gt;這篇文章想說的是，其實 Facebook、Google 以及其他廣告業者都是所謂的「數據工廠」，而如果政府要立法規範這些工廠，最有效的方法就是請它們允許使用者看到工廠裡頭的情況。&lt;/p&gt;
&lt;p&gt;我認為「數據工廠」是對 Google 及 Facebook 這種利用數據來創造價值的公司的一個貼切比喻。因為他們除了使用者的行為數據，也從廣告代理商以及第三方數據收集業者取得大量資料。透過將這些原始資料「加工」並產生衍生價值，據此創造巨大收益。&lt;/p&gt;
&lt;p&gt;然而這些「數據工廠」跟一般傳統的「工廠」有一個非常大的差異：誰都無法窺探該「工廠」的內部情況。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/P1-BP885_NIKE3_GR_20140421170339.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;記者可以去 Nike 製造足球的工廠裡頭拍拍照，讓世人知道這些工廠內部的運作情況，但在這年代，你無法去 Facebook 裡頭拍拍照，了解他們是怎麼利用各式各樣的演算法，來「活用」所有跟你相關的資料（你按過讚的內容、瀏覽過的網頁，甚至是你為了雙重認證而輸入的電話號碼）。&lt;/p&gt;
&lt;p&gt;因此立法者以及那些關心自己數據可能被濫用的使用者要了解的是，要規範 Facebook 這種公司，不能只要求 Facebook 公布他們從使用者手上拿到的原始資料（Raw Data），而是應該公布那些他們利用演算法以及結合多種數據來源所產生出的 user profile，讓使用者自行判斷要不要繼續讓該公司使用自己的 profile。&lt;/p&gt;
&lt;p&gt;雖然多數人其實只在乎 Facebook 能不能秀給他們更多的動物影片以及朋友動態，不太在意自己的數據被怎麼拿來獲利。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;
&lt;a href="https://medium.com/swlh/engagement-drives-stickiness-drives-retention-drives-growth-3a6ac53a7a00" target="_blank"&gt;Engagement Drives Stickiness Drives Retention Drives Growth&lt;/a&gt;&lt;a class="anchor-link" href="#Engagement-Drives-Stickiness-Drives-Retention-Drives-Growth"&gt;&amp;para;&lt;/a&gt;
&lt;/h2&gt;
&lt;center&gt;
&lt;a href="https://medium.com/swlh/engagement-drives-stickiness-drives-retention-drives-growth-3a6ac53a7a00" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/product-analysis-framework.jpeg"/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在以提供 App 作為服務的公司裡頭，資料科學家大都會需要進行產品分析（Product Analysis）進而改善自家產品。&lt;/p&gt;
&lt;p&gt;這篇文章介紹了 App 產業以及我常在使用的一個分析框架，讓你可以感受一下，實際上 DS 在做產品分析的時候，要看些什麼東西。&lt;/p&gt;
&lt;p&gt;有做過產品分析的你，應該能很快地理解這個流程圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/digests/engagement-framework.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這張圖最重要的核心概念是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        當使用者發現你產品的價值以後，他們會主動回來。
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當使用者發現你的產品的價值後，就會進一步參與使用（Engage），而好的參與程度（Engagement Level）會增加他們對此產品的黏著度（Stickiness），進一步讓他們願意回來繼續使用你的產品（Retentaion）。而有了越來越多的忠實用戶，就能進一步帶給你的產品成長（Growth），不斷持續地這個好的循環。&lt;/p&gt;
&lt;p&gt;在我們理解每個階段代表的意義以後，我們還需要一些指標（indicators）來實際幫助我們了解產品在每個階段的表現。&lt;/p&gt;
&lt;p&gt;像是 Engagement 底下的 TS/DAU 即分別代表「使用時間（&lt;strong&gt;T&lt;/strong&gt;ime &lt;strong&gt;S&lt;/strong&gt;pent）」以及「每天活躍使用者人數（&lt;strong&gt;D&lt;/strong&gt;aily &lt;strong&gt;A&lt;/strong&gt;ctive &lt;strong&gt;U&lt;/strong&gt;sers）」。這兩個都很常被拿來衡量使用者參與一個產品的程度。有了好的參與程度，一個使用者就更有可能在安裝 7 天後還回來繼續使用（Retention 階段的 D7）。&lt;/p&gt;
&lt;p&gt;這邊沒有篇幅一個個介紹圖中的指標，但要注意的是，在看指標的時候，要去想它是早期指標（Early Indicators）還是延遲指標（Lagging Indicators）。&lt;/p&gt;
&lt;p&gt;比方說你的最終目標是提升每月活躍使用者人數（&lt;strong&gt;M&lt;/strong&gt;onthly &lt;strong&gt;A&lt;/strong&gt;ctive &lt;strong&gt;U&lt;/strong&gt;sers，最右邊 Growth 階段的 MAU）這個延遲指標（延遲在於要過了 1 個月你才知道結果），那你除了看 MAU 以外，還需要去看 TS/DAU 等早期指標。因為 MAU 需要一個月的時間才能計算出來，有時候產品表現差，你從每天使用的人數下降就可以略知一二，可以馬上做調整而不需等到一個月後 MAU 數字難看才大傷腦筋。&lt;/p&gt;
&lt;p&gt;及早發現，及早治療。&lt;/p&gt;
&lt;p&gt;產品分析領域在網路上的資源不多，有機會再跟你分享我的心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;呼！這就是本週文摘的內容啦！希望你閱讀後有感覺自己腦中多了點東西，變得聰明了一點。&lt;/p&gt;
&lt;p&gt;社會人口、機器學習、產品分析以及數據隱私的議題，你會發現這些文章儘管領域大相徑庭，他們都與「數據」脫離不了關係。&lt;/p&gt;
&lt;p&gt;在這個時代，任何人的日常生活中都充斥著大量數據。我們需要重新思考、檢視並理解身邊的數據，甚至活用它們來創造更好的世界。&lt;/p&gt;
&lt;p&gt;這也是我寫這系列文章的原因，希望讓更多人（包含我自己）能更輕鬆地用數據理解這個世界。歡迎你點擊下面的訂閱按鈕，未來跟著我一起繼續探索這個世界：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>如何用 30 秒了解台灣發展與全球趨勢：用 GapMinder 培養正確世界觀</title><link href="https://leemeng.tw/gapminder.html" rel="alternate"></link><published>2018-10-08T01:50:00+09:00</published><updated>2018-10-08T01:50:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-10-08:/gapminder.html</id><summary type="html">&lt;p&gt;這篇文章提供你一個輕鬆探索台灣與世界的資料視覺化工具：GapMinder 中文版。除了工具本身以外，文中會透過大量動態的資訊圖表以及各國公開數據來帶你探索台灣以及世界。閱讀本文之後，你將了解全球的發展趨勢、對台灣的社會、經濟以及能源發展有個基礎認知，並重新建立一個宏觀、積極的世界觀。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;
再稍微花個 5 秒鐘咀嚼一下你所看到的。&lt;/p&gt;
&lt;p&gt;現在問你自己，你看到了什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這個資訊爆炸的時代，大腦為了保護你的心智不被大量數據淹沒，可能已經很習慣性地忽視眼前數據其背後所隱含的意義。&lt;/p&gt;
&lt;p&gt;但讓我提醒你一下，就在剛剛的 30 秒內，全世界過去 200 年至今的經濟（所得收入）與社會（平均壽命）發展狀況活生生地重現在你眼前！&lt;/p&gt;
&lt;p&gt;這可不是小時候歷史老師會 / 能秀給你看的東西（至少我的老師沒有）我不知道你感受如何，但在我&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen"&gt;第一次見識到此圖&lt;/a&gt;的時候，內心可說是激動得不得了！&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen#t-249222" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/gapminder/ted-video-screenshot.jpg" style=""/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
    瑞典全球公衛教授 &lt;a href="https://zh.wikipedia.org/zh-tw/%E6%B1%89%E6%96%AF%C2%B7%E7%BD%97%E6%96%AF%E6%9E%97" target="_blank"&gt;漢斯・羅斯林&lt;/a&gt;
&lt;br/&gt;
    2006 年在 TED 利用上面的泡泡圖向觀眾們解說世界的經濟與社會發展
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;將專注拉回台灣。看著台灣的發展軌跡，你甚至還可以發現一些值得注意的現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1939 至 1945 年，人民所得以及平均壽命走倒車（二戰）&lt;/li&gt;
&lt;li&gt;1945 至 1953 年國民平均壽命的大幅提升，所得回歸正常&lt;/li&gt;
&lt;li&gt;1960 年代以後，經濟與社會的持續穩定發展&lt;/li&gt;
&lt;li&gt;2000 年後成長趨緩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了本身的發展軌跡以外，還可以發現到了 21 世紀，台灣在右上角，名列前茅。&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/taiwan-development.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/taiwan-development.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;&lt;/p&gt;
&lt;center&gt;
    泡泡圖除了可以讓我們觀察世界趨勢，也能同時了解台灣的發展軌跡以及與其他國家的相對位置
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;剛剛在看圖的時候，你應該還有很多其他發現且迫不及待地想要了解更多。&lt;/p&gt;
&lt;p&gt;事實上，如果在看了剛剛的動畫以後，你突然渴望想要知道更多是很正常的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        重要的是不要停止問問題，好奇心有其存在的理由。
        &lt;br/&gt;
&lt;span style="float:right"&gt;─ 愛因斯坦&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;如果你現在想要更加地了解台灣或是其他不同的國家在各種社會 / 經濟 / 健康指標的發展（如所得收入、兒童死亡率、二氧化碳排放量等），我鼓勵你先上去改改 X 或 Y 軸、點選不同國家，查看結果以後再繼續往下讀。&lt;/p&gt;
&lt;p&gt;畢竟文章跑不掉，你的好奇心則可能在幾秒鐘後消逝：）&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;你回來了嗎？&lt;/p&gt;
&lt;p&gt;你現在應該已經暸解，透過值得信賴的數據來源（比方說&lt;a href="https://www.gapminder.org/data/documentation/gd004/"&gt;聯合國&lt;/a&gt;）以及良好的呈現方式（文章開頭的泡泡圖），能讓你在很短時間內「正確」地掌握全世界趨勢以及台灣的發展狀況。&lt;/p&gt;
&lt;p&gt;儘管媒體總是報憂不報喜，你會發現全世界大致上變得越來越好。&lt;/p&gt;
&lt;p&gt;你也會發現以「人均收入」以及「平均壽命」的角度來看，台灣的表現在全世界也是數一數二，這點值得我們欣慰及驕傲。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/factfulness-cover.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    《真確》是 2018 年由漢斯・羅斯林（Hans Rosling）所撰。（圖片來源：&lt;a href="https://meet.eslite.com/tw/tc/product/201807030007" target="_blank"&gt;迷誠品&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在《真確》這本書裡，羅斯林教授闡述如何利用數據以及正確心態來理解世界，是一本深具啟發性的著作。而「泡泡圖」則是他在傳達知識時，經常使用到的工具。&lt;/p&gt;
&lt;p&gt;首先你需要知道，文中的泡泡圖（Bubble Chart）的開發以及各個國家的數據整理，並非由我獨自完成，而是由漢斯・羅斯林教授與他所創辦的 &lt;a href="https://www.gapminder.org/"&gt;GapMinder 基金會&lt;/a&gt;從多個國際組織（如聯合國、國際衛生組織、世界銀行等）&lt;a href="https://github.com/Gapminder"&gt;蒐集、整理&lt;/a&gt;而來。（給他們點掌聲！）&lt;/p&gt;
&lt;p&gt;事實上，你可以直接使用&lt;a href="https://www.gapminder.org/tools/"&gt;官方的泡泡圖&lt;/a&gt;，或是像本文一樣，依照&lt;a href="https://bl.ocks.org/angieskazka/ed82b664173a9023fa8a"&gt;這邊的教學&lt;/a&gt;來將泡泡圖內嵌在你自己的網站裡頭。&lt;/p&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;「既然官方都已經有泡泡圖了，為何你要在這裡再弄一個出來呢？」&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/emily-morter-188019-unsplash.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;非常好的問題，但讓我先賣個關子。&lt;/p&gt;
&lt;p&gt;我會在&lt;a href="#為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;/a&gt;章節裡頭仔細說明。（提示：跟台灣有關係）&lt;/p&gt;
&lt;p&gt;在這邊想先讓你知道的是，文章接下來會說明泡泡圖裡頭有什麼台灣數據可供你探索，以及提供一些探索台灣以及世界的例子，讓你在了解世界的同時熟悉泡泡圖的使用方式。&lt;/p&gt;
&lt;p&gt;等你熟悉泡泡圖以後，可以利用它來更深入瞭解台灣與以及任何你有興趣的國家，並培養正確的世界觀。最重要的是，在有了正確思維以後，你能怎樣讓世界以及台灣變得更加美好。&lt;/p&gt;
&lt;p&gt;前言很長，不過接下來才是重頭戲。準備好了就跟上我們的探索之旅吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本文章節"&gt;本文章節&lt;a class="anchor-link" href="#本文章節"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#有什麼台灣數據可供探索？"&gt;有什麼台灣數據可供探索？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#用泡泡圖探索世界"&gt;用泡泡圖探索世界&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#媽媽不生寶寶了：生育率大幅下降"&gt;媽媽不生寶寶了：生育率大幅下降&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;怎麼創造乾淨未來：煤炭消耗與環境污染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#民主大躍進：我很自由，不過不想參與政治"&gt;民主大躍進：我很自由，不過不想參與政治&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#story-behind-data"&gt;看到數據背後的故事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#你能怎樣讓世界更好？"&gt;你能怎樣讓世界更好？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="為何需要本文的泡泡圖？"&gt;為何需要本文的泡泡圖？&lt;a class="anchor-link" href="#為何需要本文的泡泡圖？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;你可能在想，何必要大費周章地弄出自己的泡泡圖。畢竟，只要使用 GapMinder 基金會（以下簡稱 GapMinder）&lt;a href="https://www.gapminder.org/tools/#"&gt;官方釋出的泡泡圖&lt;/a&gt;就可以透過數據來探索「全世界」與「台灣」了啊？&lt;/p&gt;
&lt;p&gt;這句話只對了前半段。&lt;/p&gt;
&lt;p&gt;第一個沒有那麼嚴重但是有點令人困擾的問題是，目前官方的泡泡圖只有英文，沒有繁體中文。&lt;/p&gt;
&lt;p&gt;雖然台灣人的英文能力普遍不差，但是要所有人在看到每個國家的英文名字後馬上反應出來，可不是一件簡單的事情。&lt;/p&gt;
&lt;p&gt;你還有多少把握可以認出東帝汶或柬埔寨的英文名字？（提示：下圖有其中一個）&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/chuttersnap-176806-unsplash.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;更不用說聯合國以及各個國際組織定義的各式各樣社會 / 經濟 / 公衛指標的英文了。（還記得結核病、旱災或是償債出口比怎麼唸嗎？）&lt;/p&gt;
&lt;p&gt;我們看泡泡圖的主要目的是為了瞭解世界，而不是學習翻譯各種英文專業術語。&lt;/p&gt;
&lt;p&gt;就算這樣講，英翻中或許問問 Google 還是勉強可以解決。但官方泡泡圖存在的第二個問題，則非常致命。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/official-page.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    GapMinder 釋出的&lt;a href="https://www.gapminder.org/tools/#" target="_blank"&gt;泡泡圖&lt;/a&gt;截圖。在右邊的清單搜尋「 Taiwan 」不會有結果
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在我撰寫此文的這個時間點（2018 年 10 月），在 &lt;a href="https://www.gapminder.org/tools/#"&gt;GapMinder 上的泡泡圖&lt;/a&gt;裡頭，你並無法找到「 Taiwan 」的存在。&lt;/p&gt;
&lt;p&gt;沒錯，你可以現在&lt;a href="https://www.gapminder.org/tools/#"&gt;去搜尋看看&lt;/a&gt;。然後你會發現有 2,300 多萬人口的台灣並不存在 GapMinder 的泡泡圖之中。&lt;/p&gt;
&lt;p&gt;依據 &lt;a href="https://getsatisfaction.com/gapminder/topics/what-happened-to-taiwan-it-used-to-be-included" target="_blank"&gt;GapMinder 的說法&lt;/a&gt;，泡泡圖預設只顯示&lt;a href="http://www.un.org/en/member-states/#gotoT" target="_blank"&gt;聯合國會員國&lt;/a&gt;。因此理所當然地，台灣不會被顯示在上面。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/keith-lee-803568-unsplash.jpg"/&gt;
&lt;/center&gt;
&lt;center&gt;
    儘管沒有在聯合國裡頭，在台灣努力生活的人們確確實實地存在著（&lt;a href="https://unsplash.com/photos/nYq3nW9Z9ok" target="_blank"&gt;圖&lt;/a&gt;為寧夏夜市）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;2018 年 7 月，GapMinder 表示&lt;a href="https://getsatisfaction.com/gapminder/topics/i-really-want-to-know-what-is-the-latest-situation-of-those-countries" target="_blank"&gt;他們正在想辦法讓非聯合國會員國（如台灣、香港）也能被加到泡泡圖裡頭&lt;/a&gt;，但自從那之後已經過了數個月。&lt;/p&gt;
&lt;p&gt;我真的不怪他們，畢竟他們是非營利機構，人手有限且已經為世界做出很多貢獻了。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/united-nations-headquarters.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    聯合國總部，紐約（圖片來源：&lt;a href="https://foreignpolicy.com/2017/03/13/white-house-seeks-to-cut-billions-in-funding-for-united-nations/" target="_blank"&gt;Foreign Policy&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;只是，我無法忍受在閱讀完《真確》並想要開始認真地探索這個世界的時候，發現裡頭竟然沒有熟悉的台灣。&lt;/p&gt;
&lt;p&gt;後來的故事你大概猜得到了。我開始研究 GapMinder &lt;a href="https://github.com/vizabi/vizabi"&gt;製作泡泡圖的程式碼&lt;/a&gt;以及&lt;a href="https://github.com/open-numbers/ddf--gapminder--systema_globalis"&gt;數據儲存格式&lt;/a&gt;。我寫些程式、閱讀聯合國以及各個國際組織的相關文獻以後，把台灣「駭」進泡泡圖的國家列表裡頭，並將裡頭所有國家以及（幾乎）所有指標翻譯成中文。你在文章開頭看到的泡泡圖就這樣誕生了。（感謝 Google 大神以及咖啡因！）&lt;/p&gt;
&lt;p&gt;現在，在了解本文泡泡圖的典故之後，讓我們看一下目前的泡泡圖裡頭有哪些台灣數據可供你探索。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="有什麼台灣數據可供探索？"&gt;有什麼台灣數據可供探索？&lt;a class="anchor-link" href="#有什麼台灣數據可供探索？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;GapMinder 將所有搜集來的資料整理在這個 &lt;a href="https://github.com/open-numbers/ddf--gapminder--systema_globalis"&gt;Github Repo&lt;/a&gt; 裡頭，也是本文泡泡圖的數據來源。&lt;/p&gt;
&lt;p&gt;理想上，每個指標（如二氧化碳排放量、國民平均壽命、人均收入）都會（或者說都要）包含每個國家及地區每年的資料才能方便我們做比較。但你可以想像，這不太可能實現。&lt;/p&gt;
&lt;p&gt;實際上，依照不同國家的數據開放狀況、國際組織蒐集數據的方法差異，都有可能造成指標裡頭沒有某些國家的資料。&lt;/p&gt;
&lt;p&gt;以台灣為例，透過分析 GapMinder 數據來源，我們可以知道，截至目前為止，泡泡圖裡頭總共有 500 多個指標，其中約有 40 % （ 200 個 ）指標含有台灣數據。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/gapminder-indicators-with-twn.svg"/&gt;
&lt;/center&gt;
&lt;center&gt;
    （跟本文的泡泡圖以及數據來源一樣，此圖的資訊也會定期更新）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;以大分類來看的話，「健康」及「工作」分類有較多的資料可供我們檢視台灣的狀況並同時與其他國家做比較；相較之下，「社會」及「人口」涵蓋的台灣指標較少，公共建設分類則只有 1 個（交通死亡人數）。&lt;/p&gt;
&lt;p&gt;健康分類中，屬男女的「癌症」相關數據最為完整：大腸癌、胃癌、肝癌、乳癌、攝護腺癌 .. 應有盡有。&lt;/p&gt;
&lt;p&gt;工作分類則有各個年齡層的失業 / 就業率及「勞動參與率」等指標，你可以自行稍後在泡泡圖上查看。&lt;/p&gt;
&lt;p&gt;不過實際上，你也不需記住哪些分類有多少台灣數據。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/menu-demo.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
    利用泡泡圖的選單，我們可以馬上知道每個分類底下有多少指標、有哪些指標有台灣數據、最早的年份為何
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果你剛剛有玩泡泡圖的話，可能會好奇在每個分類後面的數字代表什麼。圖中健康分類後面的 &lt;code&gt;（63/166）&lt;/code&gt;　代表在泡泡圖中，健康分類底下總共有 166 個指標，而其中的 63 個有台灣數據。這跟我們上一張長條圖吻合。&lt;/p&gt;
&lt;p&gt;現在看到上圖第三欄的「肺癌病例數」：指標名稱後面的 &lt;code&gt;（1990 ~&lt;/code&gt; 則代表在該指標中，台灣數據最早可以追溯到西元 1990 年。有了這些額外資訊，可以讓你更方便地探索台灣與世界的關係。&lt;/p&gt;
&lt;p&gt;值得一提的是，以上的結果僅代表 GapMinder 目前有的數據。他們持續努力地在添加新的數據，而我也預計在未來導入更多的台灣數據。但現在，先讓我們從已有的指標裡頭選幾個來探索看看吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用泡泡圖探索世界"&gt;用泡泡圖探索世界&lt;a class="anchor-link" href="#用泡泡圖探索世界"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在《真確》裡頭，漢斯・羅斯林教授已經向我們展示了很多很棒的泡泡圖範例。而在這個章節裡頭，我會列出一些自己利用泡泡圖探索世界以及了解台灣的例子。&lt;/p&gt;
&lt;p&gt;（小提醒：底下的圖幾乎都是動態的。如果你發現它們沒有動靜，請另外使用電腦或是手機上的瀏覽器開啟此頁連結以最佳化閱讀體驗，謝謝！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="媽媽不生寶寶了：生育率大幅下降"&gt;媽媽不生寶寶了：生育率大幅下降&lt;a class="anchor-link" href="#媽媽不生寶寶了：生育率大幅下降"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多我們以為是常態的事物，事實上在幾十年前完全不存在。&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/decline-of-female-fertility.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/decline-of-female-fertility.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;以婦女人均嬰兒數為例，在 1950 年前，跟亞洲大多數國家相同，台灣每個婦女平均有 6 個嬰兒。現代大多數的年輕人應該無法想像這件事情。&lt;/p&gt;
&lt;p&gt;但我們可以看到從 1960 年代開始，婦女人均嬰兒數以不可思議的速度溜滑梯下降，直到近年每位婦女平均只有一名嬰兒。&lt;/p&gt;
&lt;p&gt;解釋歷史從來不簡單，但我們可以想像在當時，醫療技術以及節育概念還不高，間接造成較高的兒童死亡率。兒童的死亡率高，也就代表平均一位婦女需要生產更多嬰兒來延續後代。要證實這點，我們可以把 X 軸的「人均所得」換成「兒童死亡率」：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/femaile-fertility-vs-child-death-rate.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/femaile-fertility-vs-child-death-rate.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;不只台灣，我們可以發現全世界有一樣的趨勢：兒童死亡率下降，而同時媽媽們也不需再生那麼多寶寶。這現象很大部分是因為醫療進步、女性教育的普及以及家庭觀念的改變。&lt;/p&gt;
&lt;p&gt;另外從代表不同洲的顏色可以看到，在 2018 年，所有婦女人均嬰兒數 &amp;gt; 6 的國家都位在非洲。&lt;/p&gt;
&lt;p&gt;當然，婦女人均嬰兒數減少，同時也代表&lt;a href="https://www.sfaa.gov.tw/SFAA/Pages/ashx/File.ashx?FilePath=~/File/Attach/1613/File_2086.pdf"&gt;高齡化社會的來臨&lt;/a&gt;。讓我們將 X 軸換成「60 歲以上人口佔總人口比例」以後，看看日本的發展：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/japan-child-death-vs-elder.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/japan-child-death-vs-elder.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.stat.go.jp/data/topics/topi971.html"&gt;日本的高齡化人口比例增加&lt;/a&gt;，也代表青壯年的負擔加重。不只日本，在未來要怎樣建立一個良好的長照制度，在台灣也是一個日漸重要的議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;怎麼創造乾淨未來：煤炭消耗與環境污染&lt;a class="anchor-link" href="#怎麼創造乾淨未來：煤炭消耗與環境污染"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;台灣能源供給高度仰賴進口，其進口量長期維持在 97 到 98 ％，而&lt;a href="https://secured-static.greenpeace.org/taiwan/PageFiles/770030/%E5%85%A8%E7%90%83%E6%9A%A8%E5%8F%B0%E7%81%A3%E7%87%83%E7%85%A4%E7%99%BC%E9%9B%BB%E4%B8%8D%E5%8F%AF%E4%B8%8D%E7%9F%A5%E7%9A%84%E7%9C%9F%E7%9B%B8.pdf"&gt;煤炭又為台灣第二大主要進口能源&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;因為碳密度高，燃燒煤炭又會產生比其他化石燃料（石油、天然氣）來得更多的二氧化碳，造成更嚴重的氣候暖化以及環境破壞。讓我們看看從以前到現在，一個台灣人平均消耗的煤炭以及產生的二氧化碳的變化趨勢：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/coal-consumption.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/coal-consumption.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;我們可以看到從 1990 年起，台灣煤炭的人均消耗量（用來發電）快速增加，而同時人均二氧化碳的排放量也逐年增高。儘管近年趨向穩定，我們可以看到作為對照組的美國在 2010 年以後的人均煤炭消耗量已經低於我們。&lt;/p&gt;
&lt;p&gt;環境考量以及再生能源的成本下降，讓歐美各國的政府以及能源業者決定投向再生能源懷抱，但台灣似乎還想要&lt;a href="https://www.cmmedia.com.tw/home/articles/9316"&gt;建立燃煤電廠&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/coal-consumption-comparison.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;在 2014 年時，只有哈薩克跟澳大利亞的煤炭消耗量超越我們。而作為世界第一煤炭出口國，澳洲自己也因為大量開挖煤炭而導致大堡礁的生態浩劫。&lt;/p&gt;
&lt;p&gt;怎麼減少煤炭消耗並維持人民生活水準（如提高再生能源利用率），是台灣的重要議題之一。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="民主大躍進：我很自由，不過不想參與政治"&gt;民主大躍進：我很自由，不過不想參與政治&lt;a class="anchor-link" href="#民主大躍進：我很自由，不過不想參與政治"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對於現在的台灣人來說，「民主」是如吃飯喝水般的基本存在。&lt;/p&gt;
&lt;p&gt;但台灣的「民主」一直都存在嗎？要回答這個問題，我們可以看看台灣的&lt;a href="https://zh.wikipedia.org/wiki/%E6%B0%91%E4%B8%BB%E6%8C%87%E6%95%B0"&gt;民主指數（Democracy Index）&lt;/a&gt;發展：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/democracy-index-tw.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/democracy-index-tw.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;雖然上頭的數據只到 2011 年，但我想要你看的是，1990 年（也是我出生的那年）之後，比起所得提升速度，我們的民主指數的成長速度讓人驚訝，可以說是三級跳！&lt;/p&gt;
&lt;p&gt;基本上近年台灣的分數變動不大。而在最新的 &lt;a href="http://news.ltn.com.tw/news/politics/breakingnews/2327881"&gt;2017 年全球民主指數&lt;/a&gt;裡頭，台灣則獲得了 7.73 分，全球排名第 33 名。（第一名為挪威，美國 21，日本 23，中國則為 139 名）&lt;/p&gt;
&lt;p&gt;民主指數滿分為 10 分，由 5 個評量標準做平均：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;選舉過程及多元程度（獲 9.58 分）&lt;/li&gt;
&lt;li&gt;政府功能（獲 8.21 分）&lt;/li&gt;
&lt;li&gt;政治參與（獲 6.11 分）&lt;/li&gt;
&lt;li&gt;政治文化（僅 5.63 分）&lt;/li&gt;
&lt;li&gt;公民自由度（ 9.12 分）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到雖然我們的公民自由度很高，但政治參與以及政治文化不足。&lt;/p&gt;
&lt;p&gt;我個人認為跟長期無意義的藍綠對抗文化以及年輕一代普遍對政壇上的政治人物冷感有關。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        要讓民主成功，我們必須參與，而非只是冷眼旁觀。沒有投票的人沒有權利抱怨。
        &lt;br/&gt;
&lt;span style="float:right"&gt;─ 路易．路蒙，美國小說家&lt;/span&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;儘管我們的民主程度已經值得讚賞，在公民參與部分還有很多地方可以改善。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="kan dao shu ju bei hou de gu shi_1"&gt;&lt;span id="story-behind-data"&gt;看到數據背後的故事&lt;/span&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在上一章節，我們看了一些利用泡泡圖探索台灣以及世界的例子。&lt;/p&gt;
&lt;p&gt;相信你也有這種錯覺：搭配著大量數據，泡泡圖彷彿讓你站在上帝的視角綜觀全球。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/gods_point_view_2013_10_08-12.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;但我們不能就這樣停止，自我膨脹地以為彷彿透過泡泡圖裡頭的數據，就已經暸解世間萬物。&lt;/p&gt;
&lt;p&gt;正如《真確》裡頭漢斯・羅斯林教授跟我們說的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
        我要你看到統計數據背後的個別故事，也要你看到個別故事背後的統計數據。不靠數據無法了解世界，但光靠數據也無法了解世界。
    &lt;/p&gt;
&lt;/blockquote&gt;&lt;p&gt;舉例來說，在我查看台灣婦女在工業（Industry Sector）的勞動比例時，發現一個有趣的現象：&lt;/p&gt;
&lt;p&gt;&lt;video autoplay="" loop="" muted="" playsinline="" poster="https://leemeng.tw/images/gapminder/female-industry-sector-tw-and-al-jaza-ir.jpg"&gt;
&lt;source src="https://leemeng.tw/images/gapminder/female-industry-sector-tw-and-al-jaza-ir.mp4" type="video/mp4"/&gt;
    您的瀏覽器不支援影片標籤，請留言通知我：Ｓ
&lt;/video&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;工業一般給人的印象就是包含了很多需要體力的工作，因此看到右邊台灣婦女在工業的勞動比例逐年下降（與之相對，服務業勞動比例上升）完全符合我的期待。但是，看看那個&lt;a href="https://zh.wikipedia.org/wiki/%E9%98%BF%E5%B0%94%E5%8F%8A%E5%88%A9%E4%BA%9A#%E7%BB%8F%E6%B5%8E"&gt;阿爾及利亞&lt;/a&gt;！&lt;/p&gt;
&lt;p&gt;光看那條節節上升的曲線無法幫助我們實際了解阿爾及利亞，如同我們無法光靠數據了解世界。&lt;/p&gt;
&lt;p&gt;說來慚愧，在觀察到這現象前，儘管小時候從歷史老師的口中聽過它，我完全沒有研究過這個國家。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/gapminder/algeria-oran.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    阿爾及利亞, &lt;a href="https://zh.wikipedia.org/wiki/%E7%93%A6%E8%B5%AB%E8%98%AD" target="_blank"&gt;瓦赫蘭&lt;/a&gt;（&lt;a href="https://www.ft.com/content/ee80ed52-29de-11e2-a5ca-00144feabdc0" target="_blank"&gt;圖片來源&lt;/a&gt;）
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;透過一些閱讀，我現在了解阿爾及利亞（Algeria）是一個位於非洲北部的國家，1962 年從法國殖民統治下獲得獨立。因為&lt;a href="http://www.hkislam.com/index.php?action-viewnews-itemid-3616"&gt;婦女解放&lt;/a&gt;以及女權運動崛起地相對較其他伊斯蘭國家早，該國的女性在各個階級都很活躍。在勞動市場可以看到她們開大卡車、當加油站工人並穿寬大的工作服；&lt;a href="https://news.un.org/zh/story/2012/05/173592"&gt;女性議員在議會佔的比例&lt;/a&gt;在阿拉伯世界也是獨占鰲頭，最近甚至&lt;a href="https://www.demotivateur.fr/article/algerie-3-200-jeune-femmes-en-bikini-pour-lutter-contre-l-obscurantisme-religieux-10710"&gt;還舉辦比基尼示威&lt;/a&gt;，來呼籲保守的社會給予女性更多自由。&lt;/p&gt;
&lt;p&gt;在這邊不是要推薦你去阿爾及利亞觀光或是 Google 搜尋比基尼照片。&lt;/p&gt;
&lt;p&gt;我想強調的是，讓你的好奇心跨越冷冰冰的數字。在透過數據有個宏觀的概念以後，針對你有興趣的問題去實際查查資料，問問人並了解背後的故事。&lt;/p&gt;
&lt;p&gt;在你開始這麼做以後，會發現世界變得更遼闊，更多采多姿。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="你能怎樣讓世界更好？"&gt;你能怎樣讓世界更好？&lt;a class="anchor-link" href="#你能怎樣讓世界更好？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;看了那麼多的泡泡圖以及數據，實際上我們可以怎樣讓台灣以及世界變得更好呢？&lt;/p&gt;
&lt;p&gt;我相信每個人都有自己的想法，但這邊讓我給出一些拙見。&lt;/p&gt;
&lt;p&gt;如果你是老師或是從事教育業，開始思考要怎麼利用數據來教導學生或是下一代正確的世界觀吧！不要再教他們背誦歷史年表或是生硬數字，而是利用容易理解的資料視覺化工具（如本文的泡泡圖）將過去、現在的世界展示給他們看，刺激他們的好奇心，讓他們自主發問、蒐集資料並想像未來。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/children-ask-questions.jpeg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;如果你是從事經濟 / 社會 / 公衛 / 能源 / 政治 / 國際關係等專業領域的話，重新思考在這個世紀，我們應該要密切關注的人類發展指標吧！&lt;/p&gt;
&lt;p&gt;舉國民平均所得這個指標來說，我們在文章開頭看到近 200 年來全世界每個國家在國民平均所得皆有改善，但在 21 世紀只看這個就夠了嗎？&lt;/p&gt;
&lt;p&gt;21 世紀，我們面臨的新問題是貧富差距。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://leemeng.tw/images/gapminder/the-indicator-we-need-in-the-future.jpg"/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;從「平均所得」這單一數字來看一個國家的經濟發展非常危險，因為這會讓我們忽視一件事情：國家的總所得實際上是怎麼分配到所有人手上的。&lt;/p&gt;
&lt;p&gt;在 21 世紀，我們應該更關注如上圖的指標：「最富有的 10 % 人所擁有的收入份額」，來確保我們不只解決貧困，還會記得要對付社會不平等問題。&lt;/p&gt;
&lt;p&gt;就算你認為自己不屬於上面兩種人，別擔心！我幫你列了一個自由勾選的行動清單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分享本文以讓更多人開始探索台灣與世界&lt;/li&gt;
&lt;li&gt;閱讀《真確》一書&lt;/li&gt;
&lt;li&gt;查看漢斯・羅斯林&lt;a href="https://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen#t-249222" target="_blank"&gt;在 TED 上的演講&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;查看 GapMinder 官網，尤其是 &lt;a href="https://www.gapminder.org/dollar-street/matrix"&gt;Dollar Street&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;找出泡泡圖的翻譯錯誤並通知我（如果有的話）&lt;/li&gt;
&lt;li&gt;加強數據科學力，學習利用數據說故事（尤其適合資料科學家）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以用任何方式探索世界，但如果你打算回來玩玩泡泡圖，隨時歡迎！我會持續更新數據來源並將我（和你）的新發現更新到文章裡頭。&lt;/p&gt;
&lt;p&gt;你可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將&lt;a href="https://leemeng.tw/gapminder.html"&gt;本頁網址&lt;/a&gt;加入書籤，方便隨時回來查看最新的泡泡圖&lt;/li&gt;
&lt;li&gt;用下面的按鈕訂閱部落格文章，在新文章出來的時候收到消息&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;img src="https://leemeng.tw/images/gapminder/alessandro-erbetta-786007-unsplash.jpg"/&gt;
&lt;br/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;blockquote&gt;
&lt;p&gt;
                        最後，也是最重要的，對世界多點好奇並盡情探索吧！希望你享受我們這趟探索旅程，是時候展開你自己的冒險了：）
                        &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="致謝"&gt;致謝&lt;a class="anchor-link" href="#致謝"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;感謝&lt;a href="https://zh.wikipedia.org/wiki/%E6%B1%89%E6%96%AF%C2%B7%E7%BD%97%E6%96%AF%E6%9E%97"&gt;漢斯・羅斯林&lt;/a&gt;教授，我要謝謝他帶我用更宏觀、積極的態度來理解這個世界並帶給我無數啟發。這篇文章以及文內的泡泡圖是我向他的致敬。&lt;/p&gt;
&lt;p&gt;（漢斯・羅斯林教授已於 2017 年 2 月 7 日在瑞典烏普薩拉逝世）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="GapMinder"></category><category term="資料視覺化"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.5 數據科學家面臨的挑戰、儀表板設計以及未來的被駭人生</title><link href="https://leemeng.tw/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html" rel="alternate"></link><published>2018-09-17T12:00:00+09:00</published><updated>2018-09-17T12:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-09-17:/data-science-digest-volume-5-challenges-that-data-scientists-facing-dashboard-design-and-hackable-humans.html</id><summary type="html">&lt;p&gt;真正的數據科學家面臨的 8 個挑戰是什麼？何時一個資料科學家可以說他 / 她真正地「完成」了工作？ 10 個儀表板設計的原則是什麼？何謂「被駭」人生？為了了解這些跟資料科學息息相關的問題以及可能的解答，這週我們一樣會透過閱讀幾篇文章，來分別了解幾位優秀的資料科學家、UI/UX 設計師甚至是歷史學家是怎麼思考這些問題的。如同以往的文摘，我會附上摘要並穿插自己的心得，供時間寶貴的你參考。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;真正的數據科學家面臨的 8 個挑戰是什麼？&lt;/li&gt;
&lt;li&gt;何時一個資料科學家可以說他 / 她真正地「完成」了工作？ &lt;/li&gt;
&lt;li&gt;10 個儀表板設計的原則是什麼？&lt;/li&gt;
&lt;li&gt;何謂「被駭」人生？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了了解這些跟資料科學息息相關的問題以及可能的解答，這週我們一樣會透過閱讀幾篇文章，來分別了解幾位優秀的資料科學家、UI/UX 設計師甚至是歷史學家是怎麼想的。如同以往的&lt;a href="https://leemeng.tw/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，針對每篇英文文章我會附上摘要並穿插自己的心得，供時間寶貴的你做參考。&lt;/p&gt;
&lt;p&gt;事不宜遲，讓我們直接開始吧：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;When Your Job Is Done as a Data Scientist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#8-Real-Challenges-Data-Scientists-Face"&gt;8 Real Challenges Data Scientists Face&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data-visualisation,-from-1987-to-today"&gt;Data visualisation, from 1987 to today&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#10-rules-for-better-dashboard-design"&gt;10 rules for better dashboard design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Hackable-humans-and-digital-dictators"&gt;Hackable humans and digital dictators&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本週想跟你分享 5 篇文章。如同以往的&lt;a href="https://leemeng.tw/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，你可以點擊任一連結，從有興趣的摘要看起。有時間的話，我則鼓勵你點擊下面各文章的標題 / 圖片來查看英文原文。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;&lt;a href="https://towardsdatascience.com/when-your-job-is-done-as-a-data-scientist-c5d887bb0d0e"&gt;When Your Job Is Done as a Data Scientist&lt;/a&gt;&lt;a class="anchor-link" href="#When-Your-Job-Is-Done-as-a-Data-Scientist"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://towardsdatascience.com/when-your-job-is-done-as-a-data-scientist-c5d887bb0d0e" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_7cF6Us4qWFN6jX49OI4zgg.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在一個企業裡頭，資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist, &lt;strong&gt;DS&lt;/strong&gt;）常常會被各個部門（Product, Marketing, Sales Team etc）要求做各種不同的分析。如果你把每個分析視為一個專案（Project）的話，2 個你常常會需要問自己的問題是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什麼時候可以說這個專案完成了？&lt;/li&gt;
&lt;li&gt;要做到什麼程度可以說我這個工作做完了？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇文章裡頭，資料科學家 &lt;a href="https://towardsdatascience.com/@conordewey3"&gt;Conor Dewey&lt;/a&gt; 說明了一個簡單的判斷原則：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;如果利害關係人無法利用你的成果做出決策，則你的工作就不算完成。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果專案的利害關係人（Stakeholders）沒有辦法利用你的分析成果做出（好的）決策，則你的工作就還沒結束。反之，當你確定自己的工作結果能夠影響企業決策後，就不需要再去鑽研一些太複雜但沒有 actionable impact 的事情上面。&lt;/p&gt;
&lt;p&gt;如同我們在&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;之前的文摘&lt;/a&gt;中看到的，比起建立複雜的深度學習模型，學會做一個好的簡報，並跟非技術專業的利害關係人溝通結果，進而&lt;strong&gt;影響企業決策&lt;/strong&gt;才是對一個 DS 來說更為重要的事情。&lt;/p&gt;
&lt;p&gt;為了產生最大的影響力，不管在做什麼分析或者專案的時候，都得要好好控管自己的時間以及專案的優先順序（Priority）。&lt;/p&gt;
&lt;p&gt;雖然該作者在文中並沒有著墨於如何管理時間，你可以利用美國總統&lt;a href="https://zh.wikipedia.org/wiki/%E5%BE%B7%E6%80%80%E7%89%B9%C2%B7%E8%89%BE%E6%A3%AE%E8%B1%AA%E5%A8%81%E5%B0%94"&gt;艾森豪&lt;/a&gt;的&lt;a href="https://en.wikipedia.org/wiki/Time_management#The_Eisenhower_Method"&gt;時間管理準則&lt;/a&gt;來決定專案的優先順序：&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://jamesclear.com/eisenhower-box" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/eisenhower-box.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會發現，這其實就是我們從小到大在說的「輕重緩急」。&lt;/p&gt;
&lt;p&gt;將專案依照重要性（Importance）以及緊急程度（Urgency）分為四個象限以後，你就能很清楚地知道該把自己大部分的工作時間花在那些最重要，且緊急的專案上面（上圖的左上角），藉此最大化自己的影響力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;重要的事情通常不太緊急；緊急的事情大多不太重要 - 艾森豪&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="8-Real-Challenges-Data-Scientists-Face"&gt;&lt;a href="https://www.forbes.com/sites/laurencebradford/2018/09/06/8-real-challenges-data-scientists-face/"&gt;8 Real Challenges Data Scientists Face&lt;/a&gt;&lt;a class="anchor-link" href="#8-Real-Challenges-Data-Scientists-Face"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.forbes.com/sites/laurencebradford/2018/09/06/8-real-challenges-data-scientists-face/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/8-challenges.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://www.forbes.com/"&gt;富比士&lt;/a&gt;的這篇文章說明數據科學家在實際工作時會面臨到的 8 個挑戰。以下是我針對這些挑戰，整理出來 5 點 DS 應該時時刻刻放在心上的準則：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;你得至少專精一個部門的領域專業。此部門可以是銷售、行銷、廣告或是產品部門，擇你所愛&lt;/li&gt;
&lt;li&gt;能向非技術人才、利害關係人簡單明瞭地說明洞見以及可執行的決策，並把技術細節留到 Q&amp;amp;A&lt;/li&gt;
&lt;li&gt;不要盲目地想從資料中找出什麼。先利用領域專業或者是直覺來弄出一個假設，然後利用數據驗證結果&lt;/li&gt;
&lt;li&gt;明白一個分析的「可信度」只跟你用來做出該分析的原數據「品質」一樣高&lt;/li&gt;
&lt;li&gt;不斷地磨練自己處理數據的技能。這通常體現在使用 Python、&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;R&lt;/a&gt; 以及 &lt;a href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;SQL&lt;/a&gt; 的能力&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;關於第 2 點，此篇文章則是這樣說明的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;A data scientist that cannot articulate what their model does and why it&amp;rsquo;s of value to business stakeholders is going to have a difficult path to success.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有固定在追蹤本部落格的你，想必已經非常了解清晰溝通的重要性。你也可閱讀之前的&lt;a href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html"&gt;資料科學文摘 Vol.4&lt;/a&gt; 來了解更多相關內容。至於第 4 點，我們則在兩篇文章中有針對資料工程以及數據品質做些著墨：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html"&gt;資料科學家 L 的奇幻旅程 Vol.1 新人不得不問的 2 個問題&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Garbage in, garbage out。&lt;/p&gt;
&lt;p&gt;了解企業內的資料處理流程，可以讓你合理地評估利用這些數據產生出來的分析，到底有多少價值以及可信度。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Data-visualisation,-from-1987-to-today"&gt;&lt;a href="https://medium.economist.com/data-visualisation-from-1987-to-today-65d0609c6017"&gt;Data visualisation, from 1987 to today&lt;/a&gt;&lt;a class="anchor-link" href="#Data-visualisation,-from-1987-to-today"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://medium.economist.com/data-visualisation-from-1987-to-today-65d0609c6017" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/leroy-stencil-set.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在經濟學人負責資料視覺化的 &lt;a href="https://medium.economist.com/@grahamdouglas_75252"&gt;Graham Douglas&lt;/a&gt; 分享他從 1987 年工作到現在，所使用的工具以及製圖歷程。遠在 2, 30年前，在「資料科學」這詞根本還不存在的年代，資料視覺化更像是一門藝術，而不是資料科學：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Before computers, creating charts was a lot more like art than data science.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對已經習慣使用 &lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt;、&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;ggplot2&lt;/a&gt; 以及 &lt;a href="https://www.tableau.com/"&gt;Tableau&lt;/a&gt; 等資料視覺化工具的 DS 來說，可能很難想像製作一張折線圖，還需要自己拿尺出來畫等間距格線的時代。&lt;/p&gt;
&lt;p&gt;雖然我們現在已經可以利用各種程式語言來輕鬆製圖，讀這篇文章能讓我們重新思考並感謝現代資料視覺化工具帶給我們的方便。我們也看到持續學習新技術以及工具的重要。&lt;/p&gt;
&lt;p&gt;對資料視覺化或是 R 語言中的 ggplot2 有興趣的話，可以參考&lt;a href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="10-rules-for-better-dashboard-design"&gt;&lt;a href="https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c"&gt;10 rules for better dashboard design&lt;/a&gt;&lt;a class="anchor-link" href="#10-rules-for-better-dashboard-design"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://uxplanet.org/10-rules-for-better-dashboard-design-ef68189d734c" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_gOwMfjZn3odOcYdCatiHCw.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;UX/UI 設計師的 &lt;a href="https://uxplanet.org/@taras.bakusevych"&gt;Taras Bakusevych&lt;/a&gt; 提供了一些很不錯的儀表板（Dashboard）設計建議。&lt;/p&gt;
&lt;p&gt;3 點我覺得可以特別提出來：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;簡潔，想辦法把精華弄在一頁&lt;/li&gt;
&lt;li&gt;不要太依賴互動性，要讓使用者不需什麼操作就能得到重要資訊&lt;/li&gt;
&lt;li&gt;選擇對的視覺呈現方式來陳述你想表達的數據關係&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;針對第 1 點，文章是這樣說的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Don&amp;rsquo;t tell the full story, instead summarize, surface only key info.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;大部分儀表板的用意是要讓使用者在「幾秒鐘」之內掌握所有他需要知道的重要資訊。&lt;/p&gt;
&lt;p&gt;為了達到這個目的，你應該仔細思考，到底該在儀表板上的有限空間裡頭（一個視窗畫面內）顯示什麼圖表。&lt;/p&gt;
&lt;p&gt;不要因為大部分的儀表板可以無限捲動，你就一直往下加新的圖表。什麼圖表都放進去的話，很容易造成資訊過多（Information Overload）而導致使用者抓不到重點。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;針對&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「選擇對的視覺呈現方式來陳述你想表達的數據關係」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這點，文中則給出一個數據關係跟圖表類型的對照表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/1_9VanG02d4If1TOIbpcTWbA.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對於一個老練的 DS，這些判斷基準應該都已經很自然地存在你腦海之中的吧！不過我覺得這很適合當做一個 reference 或者 cheatsheet 來使用，提醒自己。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Hackable-humans-and-digital-dictators"&gt;&lt;a href="https://www.aljazeera.com/indepth/features/hackable-humans-digital-dictators-qa-yuval-noah-harari-180824095306982.html"&gt;Hackable humans and digital dictators&lt;/a&gt;&lt;a class="anchor-link" href="#Hackable-humans-and-digital-dictators"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.aljazeera.com/indepth/features/hackable-humans-digital-dictators-qa-yuval-noah-harari-180824095306982.html" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/d0c2f05a21404458aee9066c6cd5219a_18.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇文章記錄了&lt;a href="https://www.books.com.tw/products/0010647371"&gt;人類大歷史&lt;/a&gt;的作者，以色列歷史學家 &lt;a href="http://www.ynharari.com/"&gt;Yuval Noah Harari&lt;/a&gt; 最近在接受新書訪談：&lt;a href="https://www.books.com.tw/products/0010796370?loc=P_037_001"&gt; 21 世紀的 21 堂課&lt;/a&gt;的內容。&lt;/p&gt;
&lt;p&gt;你會說，為何在資料科學文摘裡頭包含了這篇文章？&lt;/p&gt;
&lt;p&gt;在這個一切以數據為本，「數據主義」超越「人文主義」的時代，身為一個 DS，我覺得除了注重數據分析的手法以外，作為一個有血有肉的「人」，也需要去了解數據、機器學習以及 AI 會對未來的我們以及下一代造成什麼樣的影響。這篇訪談中 Harari 用易懂的方式，以歷史學家的角度說明這件事情，值得一讀。以下是我閱讀後整理的摘要。&lt;/p&gt;
&lt;p&gt;21 世紀人類面臨的 3 個挑戰：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核子戰爭&lt;/li&gt;
&lt;li&gt;氣候變遷&lt;/li&gt;
&lt;li&gt;科技破壞（Technological Disruption） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些挑戰最難的點在於，它們並不能只靠單一一個國家解決，而是要跨國合作。&lt;/p&gt;
&lt;p&gt;而前 2 個挑戰幾乎所有人都理解，因此或許不會發生，但最後一項挑戰（科技破壞）的影響卻不太明顯。&lt;/p&gt;
&lt;p&gt;未來的人工智慧（&lt;strong&gt;A&lt;/strong&gt;rtifical &lt;strong&gt;I&lt;/strong&gt;ntelligence, &lt;strong&gt;AI&lt;/strong&gt;）肯定會自動化掉更多人的「現有」工作。這些 AI 系統也將透過更多的 IoT 裝置來蒐集更多我們的資料（像是搜尋紀錄、身體資訊、情緒變化等），分析這些數據以後來幫我們自動做決策。&lt;/p&gt;
&lt;p&gt;這些系統甚至最後可能會告訴我們（現在已經有些系統號稱）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「透過大數據分析，我比你自己還懂你自己」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這就是所謂的「被駭人生」：這些利用機器學習或是人工智慧的系統能 hack 我們，透過大數據分析，在我們實際行動之前，就已經精準地預測，或者說是大幅度地直接影響我們內心、腦中的決策。你只要想像你現在在做大多數決策的時候，是比較常「聆聽自己內心的聲音」還是去「查看網站、服務、App 給你的個人推薦」就可以稍微了解這點了。&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re becoming Hackable human.&lt;/p&gt;
&lt;p&gt;注意的是我們可不是在討論科幻小說，這邊的 AI 不會有情緒感情，只是有著龐大數據、運算能力以及複雜演算法的系統。&lt;/p&gt;
&lt;p&gt;如果我們是這些 AI 系統的主人，AI 是為我們每個人自己的利益來服務的話很好。但看看那些大量蒐集你的數據的科技公司：一個比較可能出現的未來是，少數菁英掌握了 AI 力量，而 AI 會為了他們的利益而服務。在這樣的情況下，大多數的人類都會成為不重要的存在，等著被機器取代（如果我們什麼都不做的話）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;The most important fact anybody who is alive today needs to know about the 21 century is that we are becoming hackable animals ... If you can hack something, you can replace it.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這不是在危言聳聽，而是在討論現在的科技發展趨勢之下，可能產生的一個未來。重點是我們在了解現況以後，打算怎麼改變未來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在找出解決方案之前，你得先了解有什麼問題。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在還在閱讀 21 世紀的 21 堂課，希望之後能再跟你分享一些我的讀後心得。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;&lt;a name="ending"&gt;&lt;/a&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文摘裡頭，我們透過幾篇文章來了解以下幾個議題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;數據科學家的一些工作準則&lt;/li&gt;
&lt;li&gt;最大化你的工作影響力並為專案分優先順序&lt;/li&gt;
&lt;li&gt;幾個儀表板設計的原則&lt;/li&gt;
&lt;li&gt;數據主義時代下的「被駭」人生&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為本文篇幅有限，我只能跟你分享閱讀這些文章以後，自己覺得最精華的一小部分。&lt;/p&gt;
&lt;p&gt;閱讀這些文章讓我受益匪淺，因此我分享了自己的摘要，希望能幫助到沒有時間閱讀全部文章的你。儘管如此，我仍建議你從有興趣的議題開始閱讀原文或者相關文章以進一步學習。&lt;/p&gt;
&lt;p&gt;同時非常歡迎閱讀後跟我分享你的想法，或是提供一些你覺得有幫助的相關文獻，我會很感激。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Remember we are what we read. Read those books or articles that will make you a better person ：）&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>給資料科學家的 Docker 指南：3 種活用 Docker 的方式（上）</title><link href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html" rel="alternate"></link><published>2018-09-08T19:00:00+09:00</published><updated>2018-09-08T19:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-09-08:/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html</id><summary type="html">&lt;p&gt;本系列文章將分上下篇，本篇將直觀解釋 Docker 概念，並說明資料科學家能如何利用 Docker 來改善自己的開發效率；下篇則將分享作者在實際從事資料科學家時，為了解決一些數據問題而時常碰到的 3 種 Docker 使用方式。在本篇中，我們首先將透過一些簡單的比喻來直觀地理解 Docker，並讓讀者在閱讀本文後能馬上開始利用 Docker 來加速自己的開發效率，並為下篇的進階內容打好基礎。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;今天我們來聊聊如何將 &lt;a href="https://zh.wikipedia.org/wiki/Docker_(%E8%BB%9F%E9%AB%94)" target="_blank"&gt;Docker&lt;/a&gt; 應用在資料科學領域裡頭吧！&lt;/p&gt;
&lt;p&gt;全文共分上下 2 篇。在這篇裡頭，我們將透過一些簡單的比喻來直觀地理解何謂 Docker，並讓你能在閱讀本文後馬上利用 Docker 來加速你的開發效率；在下篇的內容當中，我則會分享一個資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist：DS）為了解決一些數據問題而時常碰到的 3 種 Docker 使用方式。&lt;/p&gt;
&lt;p&gt;不管是哪一篇，我們都不會深入探討 Docker 本身是以什麼技術被實現的。反之，我們將會以 DS 的角度，專注在「應用」層面：如何把 Docker 實際應用在資料科學以及資料工程領域裡頭。&lt;/p&gt;
&lt;p&gt;這系列文章適合 2 種讀者：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對 Docker 完全沒有概念，但想讓自己的 Workflow 更有效率的資料科學家&lt;/li&gt;
&lt;li&gt;熟悉 Docker，但好奇其在資料科學領域如何被應用的工程師&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="雲端運算-&amp;amp;-Docker"&gt;雲端運算 &amp;amp; Docker&lt;a class="anchor-link" href="#雲端運算-&amp;amp;-Docker"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在解釋何謂 Docker 之前，讓我把你已經非常熟悉的雲端運算（Cloud Computing）老朋友叫出來。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/tw/"&gt;Amazon Web Service（AWS）&lt;/a&gt;、&lt;a href="https://cloud.google.com/"&gt;Google 雲端平台（GCP）&lt;/a&gt; 以及 &lt;a href="https://azure.microsoft.com/zh-tw/"&gt;Microsoft Azure&lt;/a&gt; 大概是大家最耳熟能詳的幾家雲端計算 / 服務平台了。隨著時代的演進，這些平台提供越來越多樣的機器學習 API，讓開發人員不需做複雜的開發，透過一個 HTTP 要求就能直接使用各種酷炫的服務，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/tw/lex/"&gt;Amazon Lex&lt;/a&gt; 讓你使用 Amazon Alexa 的深度學習技術建立聊天機器人&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cloud.google.com/vision/"&gt;Google Cloud Vision API&lt;/a&gt; 讓你快速建立一個圖像辨識服務&lt;/li&gt;
&lt;li&gt;&lt;a href="https://azure.microsoft.com/zh-tw/services/cognitive-services/content-moderator/"&gt;Azure Content Moderate API&lt;/a&gt; 讓你自動審核網路上的圖片以及文字&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;儘管如此，很多時候只使用這些現成的 API 並不能滿足我們這些 DS 以及企業的野心。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/network-2402637_1280.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    比起使用現成 API，如何運用雲端運算來 scale 各種數據處理工作是一個 DS / DE 更常問的問題
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a name="three-tasks"&gt;&lt;/a&gt;除了直接用各家雲端平台提供的 API 以外，一個 DS 可能更常需要利用雲端上的計算資源來完成以下的工作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;部署一些新的分析工具來嘗試提升自己及分析團隊的效率&lt;/li&gt;
&lt;li&gt;開發、訓練、部署並規模化（scale）自己的機器學習模型&lt;/li&gt;
&lt;li&gt;對大量數據做批次處理，將結果儲存後顯示在儀表板上&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;事實上，這就是本系列文章最想要跟你分享的 3 件 DS 可以活用 Docker 來最大化產出的案例。&lt;/p&gt;
&lt;p&gt;當我們透過這篇文章（上篇）熟悉了 Docker 的基本概念以及操作以後，就能在下篇裡頭深入地探討它們。因此在這篇先讓我們專注在學習 Docker 的基礎知識吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們現在不會細談，但如果你再看一次上面的 3 個工作的話，會發現裡頭可不只包含資料科學（Data Science）。除了建置儀表板以及設計 ML 演算法以外，這裡頭還包含了不少軟體工程、資料工程甚至 &lt;a href="https://zh.wikipedia.org/wiki/DevOps"&gt;DevOps&lt;/a&gt; 成分。當然資料工程師（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer）很樂意幫助你，但如果你想要快速地自己兜出一些方法呢？你該用什麼工具？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/work-2005640_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你可能覺得一個 DS 要在各種 deadlines 內完成以上所有的事情是不可能的。不過後面我們會慢慢發現，活用 Docker 能讓這些工作變得簡單許多。&lt;/p&gt;
&lt;p&gt;接著就讓我們以 DS 的角度了解 Docker 到底是什麼技術。我相信閱讀接下來的文章，對你之後開發效率的提升是一個非常好的投資。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker：可愛的大鯨魚"&gt;Docker：可愛的大鯨魚&lt;a class="anchor-link" href="#Docker：可愛的大鯨魚"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先看看以下這張 Docker 示意圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/1_JAJ910fg52ODIRZjHXASBQ.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有什麼感覺嗎？注意到上圖包含了 3 個要素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;海洋&lt;/li&gt;
&lt;li&gt;鯨魚&lt;/li&gt;
&lt;li&gt;貨櫃&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在讓我們發揮點想像力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你把雲端運算的平台想像成一個充滿運算資源的&lt;strong&gt;大海&lt;/strong&gt;的話，Docker 就是如圖中在裡頭悠遊的大&lt;strong&gt;鯨魚&lt;/strong&gt;。這隻&lt;strong&gt;鯨魚&lt;/strong&gt;將上述所有 DS 想要做的數據處理工作、執行的 App，一個個封裝成彼此獨立的&lt;strong&gt;貨櫃&lt;/strong&gt;，並載著它們在這大海上運行。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://towardsdatascience.com/how-docker-can-help-you-become-a-more-effective-data-scientist-7fc048ef91d5" target="_blank"&gt;Docker&lt;/a&gt; 提供的抽象化讓我們能輕鬆地運行任何想使用的資料科學工具、軟體而不需花費過多時間在建置底層環境。&lt;/p&gt;
&lt;p&gt;我知道你可能還是沒什麼感覺，讓我們看下去。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="鯨魚背上的貨櫃：Docker-容器"&gt;鯨魚背上的貨櫃：Docker 容器&lt;a class="anchor-link" href="#鯨魚背上的貨櫃：Docker-容器"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;實際上這一個個假想的貨櫃就代表著 Docker 術語裡頭的容器（Container）。&lt;/p&gt;
&lt;p&gt;「容器」顧名思義，是一個「容納」了某些東西的「器具」。&lt;/p&gt;
&lt;p&gt;一般而言，一個容器裡通常會包含了一個完整的 App。這邊的 App 不是手機上的 App，而是指廣義的應用程式（&lt;strong&gt;App&lt;/strong&gt;lication）。&lt;/p&gt;
&lt;p&gt;DS 常用的 App 可以是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個包含 &lt;a href="https://www.tensorflow.org/"&gt;TensorFlow&lt;/a&gt; 函式庫的 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook 伺服器&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個 ML 產品，如透過已訓練的模型來判斷圖片裡頭有沒有貓咪的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Flask App&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個 SQL 查詢以及資料視覺化的工具，如 &lt;a href="https://github.com/apache/incubator-superset"&gt;Superset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一個簡單的 Python Script，針對輸入的大量數據做處理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要從頭建構這些 App 的環境不是不可能，但除了基本的 &lt;code&gt;pip install&lt;/code&gt; 以外你還需要花不少工夫；更令人困擾的是，很多時候你在 Mac、Windows 上安裝環境的步驟，到了雲端上的 Linux 機器上就完全行不通了。&lt;/p&gt;
&lt;p&gt;如果這時候有人先幫我們把一個在哪邊都能跑的 App 環境建好，我們不是就能馬上開始使用各種分析工具，進行各種有趣的分析，而不用煩惱底層如不同 OS 的差異了嗎？&lt;/p&gt;
&lt;p&gt;Docker 的容器就是這樣的一個概念，幫你事先將一個 App 所需要的所有環境，包含作業系統都「容納」在一起。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/docker-inside-container.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://stackoverflow.com/a/50489813/2447655" target="_blank"&gt;Docker&lt;/a&gt; 將一個 App 會使用到的程式語言函式庫（JAVA、Python、R）、資料庫、甚至作業系統（OS）都包在一個自給自足的容器（CONTAINER）裡頭。想使用某個 App 的 DS 不用從頭建置環境，只需利用 Docker 啟動該容器即可開始工作
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;容器裡頭不只包含 App 自己本身的程式碼，也涵蓋了所有能讓這個 App 順利執行的必要環境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;App 需要的各種 Python 函式庫，如特定版本的 TensorFlow、Pandas 及 Jupyter Notebook&lt;/li&gt;
&lt;li&gt;MySQL、MongoDB 等 App 會用到的資料庫&lt;/li&gt;
&lt;li&gt;App 會用到的各種 metadata、資料集&lt;/li&gt;
&lt;li&gt;各種 OS 限定的驅動程式（drivers）、依賴函式庫&lt;/li&gt;
&lt;li&gt;（把所有你想得到的東西填進來）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包羅萬象。&lt;/p&gt;
&lt;p&gt;因此只要我們能利用 Docker 把一個 App 需要執行的環境全部包在一個容器裡頭，我們就能在任何有 Docker 的地方啟動並運行該容器。不再需要每次重新建置環境，也不用考慮不同機器上的安裝問題。&lt;/p&gt;
&lt;p&gt;而這正是 Docker 最強大的地方：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker - Build, Ship, and Run Any App, Anywhere&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為連 OS 都被包起來了，實際上每個容器（container）的執行環境都是自給自足的（self-contained）。&lt;/p&gt;
&lt;p&gt;你可以把它想像成非常輕量的&lt;a href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E6%A9%9F%E5%99%A8"&gt;虛擬機器&lt;/a&gt;，其執行結果不會因為啟動該容器的「計算環境」不同而受到影響，在任何地方（Anywhere）都能順利被執行，且執行的結果都是一樣的。&lt;/p&gt;
&lt;p&gt;以我們前面的比喻來說的話，每個貨櫃（容器 / App）都是我們想要 Docker 幫我們運送（執行）的東西，而不管 Docker 這隻鯨魚（或大船）現在在哪個海洋（計算環境）裡頭，它都能使命必達。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/container-on-the-sea.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://flipboard.com/topic/container" target="_blank"&gt;Docker&lt;/a&gt; 就像艘大船，幫我們在任何海洋（計算環境）上運送我們的貨櫃（容器）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有一點值得澄清的是，就算 Docker 幫我們抽象化建置一個 App 環境的工作，在執行一個容器的時候，我們還是需要實際的計算資源來跑這些容器。&lt;/p&gt;
&lt;p&gt;因此前面所謂的「計算環境」指的是一個擁有計算資源（CPU、GPU、記憶體 etc）且我們實際運行 Docker 的地方。這計算環境可以是任何一家雲端服務平台上的機器，如 AWS 的某台 &lt;a href="https://aws.amazon.com/tw/ec2/"&gt;EC2 機器&lt;/a&gt;、&lt;a href="https://cloud.google.com/kubernetes-engine/"&gt;GCP&lt;/a&gt; 上一個包含數千台機器的群集（Cluster），或是你現在用來看本文的筆電。只要 Docker 能在該計算環境下運行，它就能幫我們在該環境「之上」執行任何容器。&lt;/p&gt;
&lt;p&gt;簡單來說：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker 幫我們抽象化在任何 OS 上建置環境的工作。只要給 Docker 一個容器，它就能在任何地方啟動該容器以供你使用。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你對 Docker 以及容器概念有個高層次的理解了，讓我們來看看這些 Docker 容器實際上是怎麼來的吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="貨櫃（Docker-容器）從哪來"&gt;貨櫃（Docker 容器）從哪來&lt;a class="anchor-link" href="#貨櫃（Docker-容器）從哪來"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解 Docker 這隻大鯨魚能幫我們運行任意的容器 / App 以後，你腦中浮現的第一個問題應該是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這些容器（貨櫃）最初是怎麼被產生的？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;非常好的一個問題。&lt;/p&gt;
&lt;p&gt;事實上，要產生一個新的 Docker 容器，Docker 需要一份「環境安裝步驟書」來讓它幫我們自動地建置容器內的環境，比方說使用什麼 OS，用什麼版本的 TensorFlow 等等。這份步驟書在 Docker 的世界裡被稱作 &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;Dockerfile&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;舉個例子，以下是 Tensorflow 官方釋出的一個 &lt;a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile"&gt;Dockerfile&lt;/a&gt;（截錄重要部分）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; ubuntu:16.04&lt;/span&gt;

...

&lt;span class="k"&gt;RUN&lt;/span&gt; pip --no-cache-dir install &lt;span class="se"&gt;\&lt;/span&gt;
        ipykernel &lt;span class="se"&gt;\&lt;/span&gt;
        jupyter &lt;span class="se"&gt;\&lt;/span&gt;
        numpy &lt;span class="se"&gt;\&lt;/span&gt;
        pandas &lt;span class="se"&gt;\&lt;/span&gt;
        sklearn &lt;span class="se"&gt;\&lt;/span&gt;
        &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    python -m ipykernel.kernelspec

...

&lt;span class="c"&gt;# Install TensorFlow CPU version from central repo&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; pip --no-cache-dir install &lt;span class="se"&gt;\&lt;/span&gt;
    http://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.0.0-cp27-none-linux_x86_64.whl

...

&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; ["/run_jupyter.sh", "--allow-root"]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;除了 &lt;code&gt;RUN&lt;/code&gt;、&lt;code&gt;CMD&lt;/code&gt; 等 Docker 專屬的關鍵字以後，你會發現這份 Dockfile 裡頭的指令其實跟你平常在本地開發時也會使用的指令如 &lt;code&gt;pip install&lt;/code&gt; 沒有相差太多。差別在於透過第一行的 &lt;code&gt;FROM ubuntu:16.04&lt;/code&gt; 指令，我們要求 Docker 在這個容器裡頭建置一個 Ubuntu OS 後，在其之上安裝這些函式庫。&lt;/p&gt;
&lt;h2 id="追求規模性：Docker-映像檔的誕生"&gt;追求規模性：Docker 映像檔的誕生&lt;a class="anchor-link" href="#追求規模性：Docker-映像檔的誕生"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;聽完以上的解釋，你可能會覺得在我們每次要啟動一個新的容器的時候，Docker 就得拿出 Dockerfile，一步步建置該容器的環境。&lt;/p&gt;
&lt;p&gt;這樣的實作也不是不行，但很沒有效率。為什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;其中一個考量是可擴展性（Scalability）。&lt;/p&gt;
&lt;p&gt;有時你會想要用同一份 Dockerfile 在短時間內迅速地產生好幾個一模一樣的容器(s)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用多個相同的機器學習模型，同時對大量的新數據做批次預測&lt;/li&gt;
&lt;li&gt;使用多個相同的 Python Script 來處理大量數據&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這時候與其在每次要啟動新的容器時才拿出 Dockerfile 建置環境，Docker 可以事先用這個 Dockerfile 把建置環境所需的步驟先做好一遍，然後把該環境「拍張照」，存成一個 Docker 映像檔（image）後等待之後的使用。&lt;/p&gt;
&lt;p&gt;等你決定要開始使用容器的時候，因為我們已經有一個環境的快照（Snapshot），Docker 就能利用該映像檔，快速地啟動 1 個（或 100 個）相同的容器給你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/docker-three-basic-elements.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://medium.com/platformer-blog/practical-guide-on-writing-a-dockerfile-for-your-application-89376f88b3b5" target="_blank"&gt;Docker 三元素&lt;/a&gt;： Dockerfile、Docker 映像檔以及 Docker 容器
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到了這邊，我們已經了解 Docker 最基本也是最重要的概念：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Docker 利用 Dockerfile 預先建置好一個 Docker 映像檔。在使用者想要使用容器的時候，以該映像檔為基礎，運行一個對應的 Docker 容器&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;坐而言不如起而行。&lt;/p&gt;
&lt;p&gt;在掌握了這些概念以後，我相信你也迫不及待地想要開始使用 Docker 了，接下來就讓我們實際操作 Docker 來體會一下它的威力。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker-映像檔：法式千層酥"&gt;Docker 映像檔：法式千層酥&lt;a class="anchor-link" href="#Docker-映像檔：法式千層酥"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管是 Windows 或是 Mac 用戶，你都可以很輕鬆地在&lt;a href="https://www.docker.com/get-started"&gt;官方網站&lt;/a&gt;下載 Docker 並安裝。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://www.docker.com/get-started" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/docker/website.png" style=""/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;下載完以後啟動 Docker，大鯨魚就會在你的筆電上開始閒晃，等待你的指示。一般而言，我們會在 terminal 使用各種 &lt;code&gt;docker&lt;/code&gt; 指令來跟大鯨魚溝通。&lt;/p&gt;
&lt;p&gt;當 Docker 就緒以後，依照我們前面的所學，你會需要一個 Dockerfile 或是 Docker 映像檔來產生一個 Docker 容器。就像 &lt;a href="https://github.com/"&gt;Github&lt;/a&gt; 是一個被大家拿來分享程式碼的地方，&lt;a href="https://hub.docker.com/"&gt;Dockerhub&lt;/a&gt; 則被用來分享 Dockerfile 以及 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;假設我們現在要開始一個新的 TensorFlow 專案，並且想透過 Jupyter Notebook 進行開發，最省力的方式就是從 Dockerhub 下載一個 &lt;a href="https://hub.docker.com/r/tensorflow/tensorflow/"&gt;TensorFlow 官方&lt;/a&gt;幫我們弄好的 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;讓我們打開一個 terminal 並輸入 &lt;code&gt;docker pull&lt;/code&gt; 指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;第 1 個 &lt;code&gt;tensorflow&lt;/code&gt; 代表 Tensorflow 的官方 Dockerhub repository，就跟 Github repository 的概念相同；第 2 個則是容器名稱。&lt;/p&gt;
&lt;p&gt;你會看到當 Docker 在下載映像檔的時候，同時也在建置環境，而其環境會分成一層一層（Layer）的：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker pull tensorflow/tensorflow
Using default tag: latest
latest: Pulling from tensorflow/tensorflow
3b37166ec614: Already exists
ba077e1ddb3a: Already exists
34c83d2bc656: Already exists
84b69b6e4743: Already exists
0f72e97e1f61: Already exists
6086c6484ab2: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
25817b9e5842: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
5252e5633f1c: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
8de57ae4ad7d: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
4b7717108c3b: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
b65e9e47e80a: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
006d31e013ea: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
700521cc53f3: Pull &lt;span class="nb"&gt;complete&lt;/span&gt;
Digest: sha256:f45d87bd473bf999241afe444748a2d3a9be24f8d736a808277b4f3e32159566
Status: Downloaded newer image &lt;span class="k"&gt;for&lt;/span&gt; tensorflow/tensorflow:latest
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;我們不會細談 Docker 實作細節，但你可以想像 Docker 映像檔是一個法式千層酥（Mille Feuille）。&lt;/p&gt;
&lt;p&gt;這時候的 Docker 是一名蛋糕師傅，利用 Dockerfile 作為食譜，逐行執行裡頭的指令以建立一層層的環境。每做出一層新的環境，就把它加在目前所有環境的上面，最後成為一個 Docker 映像檔。&lt;/p&gt;
&lt;p&gt;這樣做有 2 個好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;當你對 Dockerfile 做變動的時候，Docker 可以只針對被改變的那一層環境做修改，而不用重建每一層，減少建置環境所需要的時間&lt;/li&gt;
&lt;li&gt;有利用到一樣環境的不同映像檔可以分享部分結果（如上面的 &lt;code&gt;Already exists&lt;/code&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/mille_feuille.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個 Docker 映像檔就像是蛋糕師傅利用 Dockerfile 食譜做出來的法式千層酥
    &lt;br/&gt;
    （誠摯地希望你不是晚上看本文，餓了）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照你的網路速度，下載映像檔所需的時間可能有所不同。&lt;/p&gt;
&lt;p&gt;在下載完成以後，輸入 &lt;code&gt;docker images&lt;/code&gt; 指令可以顯示所有目前本地端擁有的 Docker 映像檔：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker images tensorflow/tensorflow
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
tensorflow/tensorflow   latest              76fb62c3cb89        &lt;span class="m"&gt;2&lt;/span&gt; weeks ago         &lt;span class="m"&gt;1&lt;/span&gt;.23GB
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這邊因為我的環境裡已經有一大堆的映像檔，我在 &lt;code&gt;docker images&lt;/code&gt; 後面加入額外的篩選器來告訴 Docker 只顯示 &lt;code&gt;tensorflow&lt;/code&gt; repository 裡頭的 &lt;code&gt;tensorflow&lt;/code&gt; 容器。&lt;/p&gt;
&lt;p&gt;有了映像檔以後，最令人期待的時刻終於來臨了！&lt;/p&gt;
&lt;p&gt;我們現在要呼叫 Docker 幫我們從這個映像檔產生並執行（run）一個新的 Docker 容器：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run -it -p &lt;span class="m"&gt;1234&lt;/span&gt;:8888 tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;短短一行指令，包含了 3 個你不可不知的重要概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 &lt;code&gt;docker run&lt;/code&gt; 來告訴 Docker 我們要利用 &lt;code&gt;tensorflow/tensorflow&lt;/code&gt; 映像檔來運行一個容器。實際上 Docker 容器就是在 Docker 映像檔的環境之上再加 1 層可執行的環境供你使用（貫徹千層酥的理念） &lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;-it&lt;/code&gt; 參數來告訴 Docker 我們同時要建立一個互動式的 TTY 連線，讓容器內的結果直接顯示在我們的 terminal 裡頭，彷彿我們在本地環境下執行該 App 一樣。我們之後還可以直接在 terminal 使用 Ctrl + C 或 Command + C 來終止容器&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;-p 1234:8888&lt;/code&gt; 告訴 Docker 我們將會透過本地端的 &lt;code&gt;1234&lt;/code&gt; port 來連到容器裡頭的 &lt;code&gt;8888&lt;/code&gt; port&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以透過&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker run --help
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;來查看所有 &lt;code&gt;docker run&lt;/code&gt; 可以使用的參數。&lt;/p&gt;
&lt;p&gt;另外，一個 DS 應該都知道，&lt;code&gt;8888&lt;/code&gt; 是 Jupyter Notebook 預設的 port。因此我們的企圖就跟司馬昭之心一樣，打算透過本地端的 &lt;code&gt;1234&lt;/code&gt; port 連到在容器裡頭跑的 Jupyter Notebook。&lt;/p&gt;
&lt;p&gt;現在打開你的瀏覽器並輸入 &lt;code&gt;localhost:1234&lt;/code&gt;，應該就能連到容器內部的 Jupyter Notebook 伺服器：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/tensorflow-notebook.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    容器內的 Juypter Notebook 畫面，所有環境包含 TensorFlow 都已經幫你設置好
    &lt;br/&gt;
    （輸入你在啟動容器的 terminal 裡看到的 token 就能通過認證）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對你沒看錯，你已經用 Docker 建置了一個完整的資料科學環境，裡頭有 TensorFlow 以及 Jupyter Notebook。&lt;/p&gt;
&lt;p&gt;而你只需要 2 個指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull tensorflow/tensorflow
docker run -it -p &lt;span class="m"&gt;1234&lt;/span&gt;:8888 tensorflow/tensorflow
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;建置環境什麼的交給 Docker 吧，你已經能馬上開始實作機器學習模型了。&lt;/p&gt;
&lt;p&gt;有些 DS 可能會覺得他的 &lt;a href="https://anaconda.org/"&gt;Anaconda&lt;/a&gt; 或者是 pip 功能爐火純青，不需要用到 Docker 也能自己在本地建出這樣的環境。其實沒錯，如果你只是開發個人專案，說真的不學 Docker 也沒關係（喂！）&lt;/p&gt;
&lt;p&gt;但就如我們在下篇會看到的，當你在開發企業等級的數據處理工作、機器學習模型的時候，你可不能永遠躲在你的本地環境裡頭。當你習慣於在不透過 Docker 的情況下在本機建置環境，等到要在各種雲端平台上的機器重現你的結果的時候，你就會發現不妙了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="利用-Docker-分享你的成果"&gt;利用 Docker 分享你的成果&lt;a class="anchor-link" href="#利用-Docker-分享你的成果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了加強你使用 Docker 的動機，讓我再給個例子。&lt;/p&gt;
&lt;p&gt;有持續關注我文章的讀者會發現，我在&lt;a href="https://leemeng.tw/data-science-digest-volume-3.html"&gt;資料科學文摘 Vol.3 Pandas、Docker 以及數據時代的反思&lt;/a&gt;裡頭有提到，Docker 除了讓我們免除建置環境的痛苦以外，也能讓我們與他人簡單地分享開發結果。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Cat Recognizer&lt;/a&gt; 是我用 TensorFlow 以及 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 實作的一個非常 naive 的貓咪辨識 App。&lt;/p&gt;
&lt;p&gt;如同我們前面所說的，我事先將所有此 App 需要的環境用一個 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app/blob/master/Dockerfile"&gt;Dockerfile&lt;/a&gt; 定義、全部包在一個 Docker 映像檔後分享在 &lt;a href="https://hub.docker.com/r/leemeng/"&gt;Docker Hub&lt;/a&gt; 上面。&lt;/p&gt;
&lt;p&gt;任何想要使用此 App 的人，只需要利用 Docker 輸入兩行指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull leemeng/cat
docker run -it -p &lt;span class="m"&gt;2468&lt;/span&gt;:5000 leemeng/cat
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著他們就能在瀏覽器輸入 &lt;code&gt;localhost:2468&lt;/code&gt; 來看到我的 App：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/cat-demo.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Docker 讓你與其他人分享成果，不須額外做一大堆環境設定
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然這個 ML App 在預測能力以及 UI 上都不完美，但這邊重點是你能利用 Docker 與他人快速地分享成果。如果你有想到其他利用 Docker 封裝好的 ML App 例子（或者是你接下來打算做一個自己的），非常歡迎留言讓我知道它們的存在：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="總結"&gt;總結&lt;a class="anchor-link" href="#總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;呼！看完本文以後，相信你現在應該對 Docker 有個非常清楚的認識了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker 是一個能幫我們在各種不同 OS 上建置開發環境的工具&lt;/li&gt;
&lt;li&gt;Docker 三元素包含 Dockerfile、Docker 映像檔（Image）以及 Docker 容器（Container）&lt;/li&gt;
&lt;li&gt;Docker 利用 Dockerfile 預先建置好一個 Docker 映像檔。在使用者想要使用容器的時候，以該映像檔為基礎，運行一個對應的 Docker 容器&lt;/li&gt;
&lt;li&gt;Docker Hub 上有各式各樣可以直接供使用的映像檔&lt;/li&gt;
&lt;li&gt;你只需要 &lt;code&gt;docker pull&lt;/code&gt; 及 &lt;code&gt;docker run&lt;/code&gt; 就能開始一個分析專案&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;給自己鼓鼓掌！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/docker/1_JAJ910fg52ODIRZjHXASBQ.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    現在這張 Docker 的示意圖在你眼裡應該變得平易近人許多
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;正因為我們是資料科學家，利用 Docker能幫我們抽象化很多不必要的環境建置工作，加速我們的開發效率。&lt;/p&gt;
&lt;p&gt;在本系列文章的下篇出爐之前，我鼓勵你先&lt;a href="https://www.docker.com/get-started"&gt;下載 Docker&lt;/a&gt;，並開始在 &lt;a href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt; 或者 Google 搜尋一些你感興趣的映像檔，甚至自己寫一個 Dockerfile 將你目前的專案打包起來跟別人分享。&lt;/p&gt;
&lt;p&gt;雖然我們這篇因為篇幅關係沒有細講，但只要有一個 Dockerfile，你就能使用 &lt;code&gt;docker build&lt;/code&gt; 來輕鬆建立一個自給自足的 Docker 映像檔。一個 Dockerfile 也不難寫，像是上面貓咪的 App 的 Dockerfile 也不過就如此幾行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt;&lt;span class="s"&gt; python:3.6.3&lt;/span&gt;
&lt;span class="k"&gt;MAINTAINER&lt;/span&gt;&lt;span class="s"&gt; Meng Lee "b98705001@gmail.com"&lt;/span&gt;
COPY ./requirements.txt /app/requirements.txt
&lt;span class="k"&gt;WORKDIR&lt;/span&gt;&lt;span class="s"&gt; /app&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt; pip install -r requirements.txt
COPY . /app
&lt;span class="k"&gt;ENTRYPOINT&lt;/span&gt;&lt;span class="s"&gt; [ "python3" ]&lt;/span&gt;
&lt;span class="k"&gt;CMD&lt;/span&gt;&lt;span class="s"&gt; ["app.py"]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在本篇裡頭我們都是在自己的機器上使用 Docker。在下篇，我們將利用本篇學到的 Docker 知識，將其運用在浩瀚無垠的雲端平台之上，去最大化我們的影響力。&lt;/p&gt;
&lt;p&gt;在那之前你可以先熟悉熟悉 Docker，下次遇到你的 DS 同事時，可以問問他/她：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;嘿！你的 Docker Image 呢？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="Docker"></category></entry><entry><title>資料科學文摘 Vol.4 數據科學 MMORPG 上線！你，選好自己的角色了嗎？</title><link href="https://leemeng.tw/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html" rel="alternate"></link><published>2018-08-29T00:30:00+09:00</published><updated>2018-08-29T00:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-29:/data-science-digest-volume-4-choose-your-own-character-in-data-science-role-play-game.html</id><summary type="html">&lt;p&gt;這篇文摘透過多篇跟資料科學家相關的文章，闡述資料科學家這個職業近年可能產生，或者是已經正在發生的一些職涯趨勢。透過掌握大局觀，讓對資料科學領域感興趣的讀者能夠理性地思考自己未來如何進入這塊領域，並在符合自己興趣以及能力的情況下，發揮自己最大的價值。我們將探討在這個什麼職業都跟數據扯上關係的年代，你要如何在「全球數據科學 MMORPG」裡頭，找出自己的定位以及角色。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同以往，這篇文摘會介紹幾篇最近作者閱讀的文章以及其摘要。&lt;/p&gt;
&lt;p&gt;不過這次在條列式列出文章以前，我想先跟你分享身為一個資料科學家（&lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist，DS），我在閱讀這些文章後得到的一些想法。&lt;/p&gt;
&lt;p&gt;與其說是想法，應該說是「針對資料科學家這個職業，自己感受到的一些發展趨勢以及對這個職業接下來數年的職涯預測」。對於那些只有 3 分鐘可以閱讀此文的你，這些想法可以歸納成以下幾點：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/li&gt;
&lt;li&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/li&gt;
&lt;li&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/li&gt;
&lt;li&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/diablo-3-characters.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    如同&lt;a href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E5%9E%8B%E5%A4%9A%E4%BA%BA%E5%9C%A8%E7%BA%BF%E8%A7%92%E8%89%B2%E6%89%AE%E6%BC%94%E6%B8%B8%E6%88%8F" target="_blacnk"&gt;大型多人線上角色扮演遊戲（MMORPG）一般&lt;/a&gt;，在後數據時代，萬能、什麼數據工作都會的「資料科學家」這個幻想已在式微。取而代之的是各個對相關領域專精的「數據」職業角色們：商業分析師、資料工程師、機器學習工程師、AI 研究者等（圖為&lt;a href="https://tw.diablo3.com/zh/" target="_blacnk"&gt;線上遊戲：暗黑破壞神 3 &lt;/a&gt;的角色一覽）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接下來我將會列出本週的閱讀清單，並在簡單說明各篇摘要的同時，一一描述它們是如何跟上述幾點概念互相呼應。最重要的，我們將探討在這個什麼職業都跟數據扯上關係的年代，你要如何在「全球數據科學 MMORPG」裡頭，找出自己的定位以及角色。&lt;/p&gt;
&lt;p&gt;這篇文章適合對資料科學領域有興趣，或是未來想從事數據相關工作的你。放心，以文章長度來說，保證比上一篇文章：「&lt;a href="https://leemengtaiwan.github.io/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;」要來得平易近人許多。&lt;/p&gt;
&lt;p&gt;讓我們開始本週的閱讀之旅吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;One Data Science Job Doesn&amp;rsquo;t Fit All&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#The-Death-of-the-Data-Scientist"&gt;The Death of the Data Scientist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-to-be-a-bad-data-scientist!"&gt;How to be a bad data scientist!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;Beyond Interactive: Notebook Innovation at Netflix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;What Data Scientists Really Do, According to 35 Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同以往的&lt;a href="https://leemengtaiwan.github.io/tag/wen-zhai.html"&gt;文摘&lt;/a&gt;，你可以從任意一篇開始看我寫的摘要。不過建議先把所有標題掃過一遍，感受一下我們接下來要談的話題。&lt;/p&gt;
&lt;p&gt;另外如果真的很趕時間，可以直接&lt;a href="#ending"&gt;跳到文章最後&lt;/a&gt;看我給你的建議。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;&lt;a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/"&gt;One Data Science Job Doesn&amp;rsquo;t Fit All&lt;/a&gt;&lt;a class="anchor-link" href="#One-Data-Science-Job-Doesn&amp;rsquo;t-Fit-All"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.linkedin.com/pulse/one-data-science-job-doesnt-fit-all-elena-grewal/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/one-data-science-job.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在這篇文章中，Airbnb 解釋他們如何在經過多年發展資料科學以後，將資料科學家分為三個路線（Tracks）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分析路線（Analytics）&lt;/li&gt;
&lt;li&gt;演算法路線（Algorithms）&lt;/li&gt;
&lt;li&gt;推論路線（Inference） &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;會這樣做的其中一個很大原因是因為「資料科學」包含的領域太廣，不像這樣細分的話，第一，DS 們不知道自己該注重在什麼方面的知識；第二，公司內部跟某個 DS 合作的團隊也不知道他的專精以及該怎麼期待他的能力。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/airbnb-data-roles.png" style=""/&gt;
&lt;p&gt;Airbnb 經過多年經驗，將資料科學家細分為三個路線，主要就是為了讓每個 DS 能專注在對的地方&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;其實想想很自然。就像是現在我們很習慣將工程師粗淺地分為前端（Frontend）和後端（Backend），未來的資料科學家也有很大機會依照個人的專精以及企業需求來細分路線。要不現在你想知道一家公司對 DS 的定義，還得親自去問裡頭的資料科學家到底在做什麼，且十家公司的 DS 可能會給你 9 種答案。&lt;/p&gt;
&lt;p&gt;理想上一個資料科學家是通才（Generalist），三個路線的專業都大致了解。儘管如此，學海無涯。一個建議是至少找出哪個路線你有興趣，去專精它，並尋找渴望你專業的企業。&lt;/p&gt;
&lt;p&gt;這呼應到我們最前面提到的第 4 項趨勢（也是最重要的一項）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將這些路線想像成角色扮演遊戲（RPG）中的角色就對了！順帶一提，作者自己想專注在演算法路線，輔修分析路線，你呢？&lt;/p&gt;
&lt;p&gt;另外這篇沒提到跟資料科學密切相關的資料工程（Data Engineering），個人臆測是因為 Airbnb 的資料平台本身建得夠齊全，有很專業的資料工程師在幫 DS 完成這些事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="The-Death-of-the-Data-Scientist"&gt;&lt;a href="https://www.datasciencecentral.com/profiles/blogs/the-death-of-the-data-scientist"&gt;The Death of the Data Scientist&lt;/a&gt;&lt;a class="anchor-link" href="#The-Death-of-the-Data-Scientist"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://www.datasciencecentral.com/profiles/blogs/the-death-of-the-data-scientist" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/Dinosaur.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;「資料科學家的滅亡」。&lt;/p&gt;
&lt;p&gt;非常聳動的標題，而且你可以從封面圖片看出作者想要表達 DS 會像恐龍一樣滅絕。&lt;/p&gt;
&lt;p&gt;不過基本上我是認同的。&lt;/p&gt;
&lt;p&gt;不是說 DS 不再重要，而是再過幾年，就像當年的「大數據」風潮，各企業或許不會再像現在一窩蜂地招聘大量的「資料科學家」，而是各行各業的每個人都能很自然地將資料科學應用在自己的工作裡頭。
如同我們在&lt;a href="https://leemengtaiwan.github.io/demystify-the-hype-of-data-science-and-its-value.html#%E5%85%85%E5%AF%A6%E4%BD%A0%E7%9A%84%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8%E5%8A%9B"&gt;揭開資料科學的神秘面紗&lt;/a&gt;一文提到的一樣，在數據驅動的時代之下，培養「資料科學力」將不再只是資料科學家的專利；就算你不是資料科學家，也應該加入這個行業。&lt;/p&gt;
&lt;p&gt;這呼應到我們最前面提到的第 3 個趨勢：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="How-to-be-a-bad-data-scientist!"&gt;&lt;a href="https://towardsdatascience.com/how-to-be-a-bad-data-scientist-434dfb5a209c"&gt;How to be a bad data scientist!&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-be-a-bad-data-scientist!"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://towardsdatascience.com/how-to-be-a-bad-data-scientist-434dfb5a209c" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/1_IDUj1IN8ZvQo2ZO0Fx68pA.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇說明了一般人在學習資料科學時會有的一些錯誤思維，我們應該隨時警惕自己並改善學習態度。&lt;/p&gt;
&lt;p&gt;我自己歸納一下新手 DS 常會遇到的迷思或困境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缺乏持續學習的動力：剛開始你可能因為資料科學很夯，薪水很高決定成為一個 DS。但資料科學領域的最大特色是變動很快。缺乏熱情或是單純跟隨潮流的人，如果沒有持續學習的動力可能會中途開始懷疑人生&lt;/li&gt;
&lt;li&gt;誤以為了解全世界：上了幾門線上課程或是參加過 Kaggle 競賽，利用乾淨的資料在 Jupyter Notebook 上建立一個 XGboost 模型就誤以為掌握了所有的資料科學。事實上，業界的 DS 需要做更多事情，如清理資料、建立可靠的資料管道以及與其他部門溝通協調等等。雖然本文沒辦法教你怎麼做良好溝通，想多了解資料工程的話可以參考&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;為了學而學，沒有思考如何應用所學：這點甚至稍微資深的 DS 都會遺忘。你最少要嘗試將平常閱讀的文章、學到的分析手法應用在解決工作上的問題。甚至更好的是，改善自己或者周遭人們的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇並不直接跟本篇主題相關，不過值得 DS 們參考。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;&lt;a href="https://medium.com/netflix-techblog/notebook-innovation-591ee3221233"&gt;Beyond Interactive: Notebook Innovation at Netflix&lt;/a&gt;&lt;a class="anchor-link" href="#Beyond-Interactive:-Notebook-Innovation-at-Netflix"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://medium.com/netflix-techblog/notebook-innovation-591ee3221233" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/neflix-notebook.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;平常有在關注 &lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt; 的 DS 們想必都注意到 Netflix 這篇文章了吧。&lt;/p&gt;
&lt;p&gt;Netflix 的資料平台（Data Platform）團隊發現，儘管企業內部有各式各樣使用該平台的使用者（如 DS、資料工程師以及分析人員等），並且表面上看來都在使用不同的程式語言，不同的工具，但事實上這些平常在處理數據的人的工作流程（Workflow）大多都可以分為這幾個步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存取資料&lt;/li&gt;
&lt;li&gt;資料處理&lt;/li&gt;
&lt;li&gt;資料視覺化&lt;/li&gt;
&lt;li&gt;排程以及產品化（Productization）&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/netflix-data-roles.jpeg" style=""/&gt;
&lt;p&gt;Netflix：不同數據專業的人使用很不一樣的工具以及程式語言，但其實宏觀來看，處理數據的工作流程都很類似&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在明白這點以後，Netflix 的資料平台團隊展示了他們如何利用 Notebook 的「介面跟計算分離」這個特性，開發出能讓所有分析人員使用的統一介面。&lt;/p&gt;
&lt;p&gt;在 Netflix 裡頭，任何一個 DS / DE 都可以利用一個簡單的 Notebook 介面做到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存取 Netflix 裡頭所有的數據：內部有專門的團隊維護一個可以存取所有資料的 Python 函式庫&lt;/li&gt;
&lt;li&gt;參數化 Notebook：一個 Notebook 可以變成一個模板（Template），讓使用者可以每次利用不同參數重新執行類似的數據處理&lt;/li&gt;
&lt;li&gt;排程（Scheduling）。當使用者決定為目前 Notebook 規劃排程後，該平台會將當下使用者的 Notebook 存到 AWS S3 變成排程工作的參數設定，並在實際排程時建立輸出用的 Notebook，將所有 Logs 以及輸出都放在該輸出用的 Notebook 裡面，方便之後查看以及除錯。這最小化了一個 DS 建立 ETL 工作的時間以及人力成本。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇因為篇幅關係不會進一步解釋，但就算你平常沒在用 Notebook，應該也能感受到 Netflix 的數據平台團隊為了支援每天能在 100 PB 的數據量上跑的 15 萬個處理工作（Job）所做出的努力吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;抽象化（Abstraction）是對付複雜性（Complexity）最好的解藥。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這個例子我們看到，Netflix 為了提高他們內部資料科學家的效率以及規模性（Scalability），做了一個這樣的數據平台，將所有基本的資料工程，甚至是對一個正常的 DS 來說需要花不少時間熟悉的數據處理流程都自動化 / 抽象化了。&lt;/p&gt;
&lt;p&gt;在全球數據量仍然爆炸性成長的今天，這樣的抽象化只會越來越普遍地出現在各個企業裡頭，而這對一個資料科學家來說當然是好事。再過一陣子，一個一般的 DS 或許也就不用再花所謂的 80 % 時間來做數據清理、建構資料管道等瑣事上，而是能有更多的時間在建構預測模型、進行複雜分析等更高層次的工作。&lt;/p&gt;
&lt;p&gt;現在我們已經有各種開源的自動化工具，幫我們快速地將機器學習產品化（如 Amazon 的 &lt;a href="https://aws.amazon.com/tw/sagemaker/"&gt;SageMaker&lt;/a&gt;）、自動化清理數據的工具（如 Google 的 &lt;a href="https://cloud.google.com/dataprep/"&gt;CLOUD DATAPREP&lt;/a&gt;）等等。一方面 DS 要慶幸這些事情可以被自動化，一方面則要努力學習新知，不能停滯不前。&lt;/p&gt;
&lt;p&gt;這呼應到我們前面提到的第 1 點趨勢：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我們並不都在有這些平台的企業工作，了解自己企業的現有狀況，盡可能將能夠自動化的「數據處理瑣事」抽象化，能讓一個 DS 提高自己的效率以及工作價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;&lt;a href="https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists"&gt;What Data Scientists Really Do, According to 35 Data Scientists&lt;/a&gt;&lt;a class="anchor-link" href="#What-Data-Scientists-Really-Do,-According-to-35-Data-Scientists"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;center&gt;
&lt;a href="https://hbr.org/2018/08/what-data-scientists-really-do-according-to-35-data-scientists" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/digests/aug18-15-137888421-burakpekakcan-1200x675.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果只有閱讀一篇原文的時間的話，我推薦你這篇哈佛商業評論的文章。&lt;/p&gt;
&lt;p&gt;這篇透過訪談多位資料科學家的工作經驗，讓我們能好好地思考「資料科學家」這個職業的未來走向。&lt;/p&gt;
&lt;p&gt;首先，根據這些資料科學家所說，（事實上我也這麼認為）一個 DS 並不像有些人想像的，整天在研究 AI 演算法。&lt;/p&gt;
&lt;p&gt;實際上，這些 DS 在做的是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料搜集、資料清理&lt;/li&gt;
&lt;li&gt;統計推論（Statistical Inference）&lt;/li&gt;
&lt;li&gt;建立儀表板（Dashboard）或是績效報告&lt;/li&gt;
&lt;li&gt;實作機器學習以及資料處理管道（Date Pipeline）&lt;/li&gt;
&lt;li&gt;跟決策者辯論，影響企業決策&lt;/li&gt;
&lt;li&gt;跟專案的利害關係人說明分析結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從這篇文章，我們也再次觀察到同樣的趨勢：現在的資料科學家的工作範圍以及被期待的技能樹過於廣泛，未來將會再進一步細分。其專業領域的細分的方式則可能依企業不同而異，像是前面提到 Airbnb 的 DS 的三個路線；或是此篇文章內提到的 Type A、Type B 的資料科學家；或是更廣泛地分為資料科學家、資料工程師以及機器學習工程師。&lt;/p&gt;
&lt;p&gt;我們同時也從這些專業的資料科學家的口中再度認識到溝通能力的重要。&lt;/p&gt;
&lt;p&gt;比起建立複雜的深度學習模型，學會做一個好的簡報，並跟非技術專業的利害關係人溝通結果，進而影響企業決策才是對一個 DS 來說更為重要的事情。&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.books.com.tw/products/0010647371"&gt;人類大歷史&lt;/a&gt;的作者&lt;a href="http://www.ynharari.com/"&gt;哈拉瑞 Yuval Noah Harari&lt;/a&gt; 最近也在&lt;a href="https://www.wired.co.uk/article/yuval-noah-harari-extract-21-lessons-for-the-21st-century"&gt;訪談&lt;/a&gt;中提到未來 AI 時代裡頭，人類 4 個最重要的技能 4C：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;批判性思考（Critical Thinking）&lt;/li&gt;
&lt;li&gt;合作能力（Collaboration）&lt;/li&gt;
&lt;li&gt;創造能力（Creativity）&lt;/li&gt;
&lt;li&gt;溝通能力（Communication）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這呼應到我們最前面的第 2 點的發現：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;&lt;a name="ending"&gt;&lt;/a&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這篇文摘裡頭，我們透過閱讀不少跟資料科學家相關的文章，了解到了幾個 DS 的職涯趨勢：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家未來將能花更多時間在從事「更高層次」的工作，但同時也需具備更專業的能力&lt;/li&gt;
&lt;li&gt;學習程式語言及分析工具很重要，但是對資料科學家來說，溝通能力以及領域專業順位第一&lt;/li&gt;
&lt;li&gt;資料科學家這個職業終將式微或消失，不只 IT 產業，未來（現在）各行各業都會有善用數據的人才&lt;/li&gt;
&lt;li&gt;跟資料科學領域相關的工作會依照專業越分越細，最終成為各式各樣的數據職業&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些都是不錯的發現，但如果你只能記住其中一個的話，我希望是最後一個。&lt;/p&gt;
&lt;p&gt;如同我們在 Airbnb、Netflix 的例子以及多名專業的 DS 口中可以觀察到這個現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在不久的將來，非常有可能各個企業都依照分析領域的不同，再度細分一個 DS 的工作，並將其分為不同的路線，或是直接產生新的職業。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要我打個比方的話，就是像真實世界的 RPG 一樣。&lt;/p&gt;
&lt;p&gt;在急著成為一個資料科學家之前，仔細思考數據科學領域裡頭，究竟什麼地方吸引你？&lt;/p&gt;
&lt;p&gt;你是喜歡做統計分析、執行 AB 測試來提供產品改善的洞見嗎？&lt;/p&gt;
&lt;p&gt;還是你熱衷於研究機器學習演算法，想辦法利用龐大數據改善企業的數據產品（Data Product）呢？&lt;/p&gt;
&lt;p&gt;或者你對建構能夠處理大規模資料的數據平台的工作感興趣呢？&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/digests/doors-1767562_1280.jpg" style=""/&gt;
&lt;p&gt;現在就開始思考你想要開的門、走的路線、想要成為的角色是什麼，專精它，並尋找渴望你專業的企業&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;不管你的答案是什麼，既然我們在玩 MMORPG 遊戲（好吧，可能只有我玩）的時候都會去認真地理解每個職業的優缺點、技能樹等等，為何不將各種數據職業視為一個個的 RPG 角色，了解自己的興趣以及跟這些職業的適合程度呢？&lt;/p&gt;
&lt;p&gt;玩遊戲很嗨，能把規劃數據相關的職涯當做遊戲來玩更嗨。&lt;/p&gt;
&lt;p&gt;最後，讓我把文章開頭所問的問題交給你思考並回答：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;數據科學 MMORPG 全球玩家齊聚上線。你，選好自己的角色了嗎？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category></entry><entry><title>一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載</title><link href="https://leemeng.tw/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html" rel="alternate"></link><published>2018-08-21T23:30:00+09:00</published><updated>2018-08-21T23:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-21:/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html</id><summary type="html">&lt;p&gt;Airflow 是一個以 Python 開發的工作流管理系統，也是資料工程不可或缺的利器之一。近年不管是資料科學家、資料工程師還是任何需要處理數據的軟體工程師，Airflow 都是他們用來建構 ETL 以及處理批量資料的首選之一。這篇文章希望以一個簡易的漫畫連載通知 App 作為引子，讓讀者直觀地了解 Airflow 背後的運作原理、建立資料工程的知識基礎，並在閱讀本文後發揮自己的創意，實際應用 Airflow 來解決並自動化自己及企業的數據問題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;這是一篇當初我在入門資料工程以及 Airflow 時希望有人能為我寫好的文章。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt; 是一個從 Airbnb 誕生並開源，以 &lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; 寫成的&lt;a href="https://zh.wikipedia.org/wiki/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F"&gt;工作流程管理系統（Workflow Management System）&lt;/a&gt;，也是&lt;a href="https://github.com/apache/incubator-airflow#who-uses-airflow"&gt;各大企業&lt;/a&gt;的資料工程環節中不可或缺的利器之一。&lt;/p&gt;
&lt;p&gt;近年不管是資料科學家、資料工程師還是任何需要處理數據的軟體工程師，Airflow 都是他們用來建構可靠的 ETL 以及定期處理批量資料的首選之一。（事實上在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt;，除了 DS/DE，會使用 Airflow 的軟體工程師也不在少數）&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/journal/smartnews-dmp.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我們在
    &lt;a href="https://leemengtaiwan.github.io/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html#%E5%84%80%E8%A1%A8%E6%9D%BF%E4%B8%8A%E7%9A%84-KPI-%E6%98%AF%E6%80%8E%E9%BA%BC%E7%94%A2%E7%94%9F%E7%9A%84%EF%BC%9F" target="_blank"&gt;「資料科學家 L 的奇幻旅程(1)：新人不得不問的 2 個問題&lt;/a&gt;
    」一文提到 SmartNews 如何利用 Airflow 建立資料管道並管理各種 ETL
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;儘管它的方便以及強大，在完全熟悉 Airflow 之前，因為有些專業術語以及資料工程概念的存在，不少初學者（包含當時的我）在剛開始的時候容易四處撞壁。另外如果一開始就以 ETL 當作 Airflow 的入門的話，未免難度過高且缺少共鳴。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="追連載：一個-Airflow-的輕鬆使用案例"&gt;追連載：一個 Airflow 的輕鬆使用案例&lt;a class="anchor-link" href="#追連載：一個-Airflow-的輕鬆使用案例"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這篇文章希望以一個簡易的漫畫連載通知 App 作為引子，讓完全沒有資料工程經驗的讀者也能夠透過這個 App 的例子，輕鬆地理解工作流程的概念、自動化排程以及 Airflow 的使用方式。閱讀完本文，你將對 Airflow 以及自動排程工作有更深的理解，並學會如何建立多個能在 Airflow 上穩定運行的工作流程。更重要的，我相信你能利用這些學到的基礎，開始自動化自己生活中以及企業的數據處理 pipeline。&lt;/p&gt;
&lt;p&gt;如果你對資料工程有興趣，不太熟悉如 Airflow 這種工作流程管理系統，但有基本的 Python 程式基礎的話（或是純粹對用 Python 寫一個漫畫連載通知 App 有興趣），我相信這篇文章應該會很適合你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/app.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Slack 截圖：追漫畫應該要是件輕鬆的事情。&lt;br/&gt;我們將利用 Airflow 來實作一個像這樣會每天從 &lt;a href="https://slack.com/" target="_blank"&gt;Slack&lt;/a&gt; 推送最新漫畫連載的 App
    &lt;br/&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想重新複習 ETL 概念的讀者可以參考先前的文章：&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html#%E8%B3%87%E6%96%99%E7%AE%A1%E9%81%93"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="章節傳送門"&gt;章節傳送門&lt;a class="anchor-link" href="#章節傳送門"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#所以為何要這-App-？"&gt;了解需求：所以為何要這 App ？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#工作流概念-&amp;amp;-Airflow"&gt;工作流概念 &amp;amp; Airflow&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Python-&amp;amp;-Airflow-實作"&gt;Python 實作 &amp;amp; Airflow 操作&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#建置-Airflow-環境"&gt;建置 Airflow 環境&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Airflow-基本概念"&gt;Airflow 基本概念&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#App-版本一：大鍋炒"&gt;App 版本一：大鍋炒&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#app-v3"&gt;App 版本三：填填樂&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為讓讀者完整了解開發這個 App 的背景脈絡、此 App 的執行邏輯以及使用 Airflow 來定期執行 App 的原因，在我們實際開始寫 Python 之前有兩小節的解說。&lt;/p&gt;
&lt;p&gt;如果你已經有 Airflow 及工作流程的基礎知識，且迫不及待想看 Python 程式碼，可以直接跳到 &lt;a href="#Python-&amp;amp;-Airflow-實作"&gt;Python 實作 &amp;amp; Airflow 操作&lt;/a&gt;章節之後再回來查看前面段落。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/toc-demo.jpg" style=""/&gt;
&lt;p&gt;
        這篇文章章節不少，你有時可能會需要回到前面章節回顧一些內容。活用左側放大鏡按鈕下面的章節傳送門能讓你更輕鬆地徜徉在本文的 Airflow 世界（此功能因為作者時間有限，目前只在寬螢幕實現）
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="所以為何要這-App-？"&gt;所以為何要這 App ？&lt;a class="anchor-link" href="#所以為何要這-App-？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;平常有在網路上追漫畫連載的讀者們應該都了解，市面上的漫畫網站通常都不是會員制的。更不用說「在新連載出的時候自動通知您！」這種推送功能（Push Notification）了。也因為這樣，導致我常常三不五時上去這些漫畫網站，看每個關注的漫畫到底出了最新一話了沒。可想而知，答案通常是否定的。（一週出一次每天檢查也沒用啊啊啊）&lt;/p&gt;
&lt;p&gt;如果你只看海賊王一個漫畫（索隆好帥！），這或許沒什麼負擔。但就像上面 Slack 截圖顯示的，我不只關注海賊王，還看很多其他漫畫。讓事情更糟的是，到最後你會發現：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不記得自己到底在追哪些漫畫&lt;/li&gt;
&lt;li&gt;每一部漫畫最後到底是看到第幾話&lt;/li&gt;
&lt;li&gt;上一話是什麼時候出的&lt;/li&gt;
&lt;li&gt;有幾話是新出而你還沒看的 &lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/tim-gouw-68319-unsplash.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;手動追最新連載經常讓我追到懷疑人生&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;追漫畫連載應該要是個輕鬆且享受的事情。在一個人人會寫 code 的時代，何不自己做個 App 幫我們自動檢查新連載呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="工作流概念-&amp;amp;-Airflow"&gt;工作流概念 &amp;amp; Airflow&lt;a class="anchor-link" href="#工作流概念-&amp;amp;-Airflow"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;概念上我們可以把此 App 需要做的工作按照「先後順序」由上往下列出來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;想像上述的工作清單由上往下流動，就形成了一個工作流程（Workflow）：前一個工作如寄 Slack 通知就是下一個工作：更新閱讀紀錄的上游工作（Upstream Task）。&lt;/p&gt;
&lt;p&gt;反過來說，更新閱讀紀錄則是寄 Slack 通知的下游工作（Downstream Task）。&lt;/p&gt;
&lt;p&gt;定義出工作之間的上下游關係的好處是什麼？&lt;/p&gt;
&lt;p&gt;可以讓我們確保工作之間的相依性（Dependencies）並讓如 Airflow 這種工作流程管理系統幫我們管理工作流程。一般而言，下游工作只能在上游「成功」完成之後被執行；如果上游工作失敗的話，下游工作應該被終止，通常也沒有繼續執行的意義（例：如果 App 在執行上游工作「取得使用者閱讀紀錄」時就失敗的話，不需要也不應該執行下游的「更新閱讀紀錄」工作）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/www-headsmartmedia-com-179929-unsplash.jpg" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;我們的 App 實際上就是一個完整的工作流程。&lt;br/&gt;
       App 從工作 A 執行到工作 B 就像是水從上游 A 流動到下游 B 一樣。&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我知道你在想什麼。&lt;/p&gt;
&lt;p&gt;屏除剛剛介紹的工作流程概念，要實作這 App 的邏輯一點都不難。事實上我們只需要寫個 Python script，把每個工作各別用一個函式（Function）實作後再按照順序呼叫它們就好（你甚至可以只用一個函式實現所有邏輯！），為何需要 Airflow？&lt;/p&gt;
&lt;p&gt;在你往下滑前給個提示：我們這個 App 不是每一秒鐘都在執行。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/thought-2123970_1280.jpg" style=""/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;對！顯而易見的，因為這個 App / 工作流程設計的方式不是即時工作（Realtime Job），而是批次工作，執行一次以後就結束它的生命了。&lt;/p&gt;
&lt;p&gt;我們可不希望它只在明天早上（比方說早上 9 點）去檢查新連載。我們希望它明天、下個月或是明年的今天早上都在運作。這也是為何我們需要一個像是 Airflow 的工作流程管理系統：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定期執行工作流程&lt;/li&gt;
&lt;li&gt;維護相依性，確保工作流程從上游到下游執行，不會在上游沒完成前執行到下游&lt;/li&gt;
&lt;li&gt;各個工作失敗時自動重試（&lt;a href="https://zh.wikipedia.org/wiki/%E6%91%A9%E8%8F%B2%E5%AE%9A%E7%90%86"&gt;墨菲定律&lt;/a&gt;，所有你認為邏輯上萬無一失的工作都會因為各種無法預期的情況給你失敗的驚喜）&lt;/li&gt;
&lt;li&gt;簡單易懂的 &lt;a href="https://airflow.apache.org/"&gt;Web UI&lt;/a&gt; 方便管理工作流程&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Airflow 非常適合用來管理相依性複雜，且具批次處理性質的工作流程。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a href="https://airflow.apache.org/" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/airflow.gif" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Airflow 的 &lt;a href="https://airflow.apache.org/" target="_blank"&gt;Web UI&lt;/a&gt; 讓我們能更輕鬆地管理及排程工作流程（後面我們會實際利用此 UI 管理並開發 App）&lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上我們也可以透過 Linux 排程工具 &lt;a href="https://zh.wikipedia.org/wiki/Cron"&gt;Cron&lt;/a&gt; 來定期執行我們的 App。但 Cron 本身沒有工作流程的概念，沒辦法管理上下游工作的相依性、失敗時無法自動重跑、當然也沒有易懂的 Web UI。因此以 2, 3, 4 項的角度來看，Airflow 是一個比較好的選擇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到此為止，我們已經了解&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何要做這個 App&lt;/li&gt;
&lt;li&gt;此 App 的工作流程以及工作流程（Workflow）的基本概念&lt;/li&gt;
&lt;li&gt;為何要使用 Airflow 來幫我們管理 App 的工作流程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接著只差用 Python 將 App 的邏輯以 Airflow 工作流程的方式實現了，讓我們開始實作吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/show-me-the-code.jpg" style=""/&gt;
&lt;p&gt;[Warning] 接下來不只給你 Python 程式碼，而是給你大量的 Python 程式碼&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Python-&amp;amp;-Airflow-實作"&gt;Python &amp;amp; Airflow 實作&lt;a class="anchor-link" href="#Python-&amp;amp;-Airflow-實作"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;程式碼都會放在這個 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Github Repo&lt;/a&gt; 裡頭供你在閱讀完文章後參考。但如果你正在用電腦瀏覽的話且想趕快熟悉 Airflow 開發的話，可以 &lt;code&gt;git clone&lt;/code&gt; 下來以後跟著文章走。&lt;/p&gt;
&lt;p&gt;開啟一個新的 terminal，移動到你平常放新專案的資料夾，然後輸入：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/leemengtaiwan/airflow-tutorials.git
&lt;span class="nb"&gt;cd&lt;/span&gt; airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;之後沒特別明說的話，指令都會是在 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下執行。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="建置-Airflow-環境"&gt;建置 Airflow 環境&lt;a class="anchor-link" href="#建置-Airflow-環境"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;雖然 production 環境需要很多調整，以建構測試環境來說，基本上參考官方的 &lt;a href="https://airflow.apache.org/start.html#quick-start"&gt;Quick Start&lt;/a&gt; 就可以很輕鬆地完成。因為 Airflow 是以 Python 實作的，我們可以很輕易地用 &lt;code&gt;pip install&lt;/code&gt; 來安裝所有需要的東西。用 &lt;a href="https://anaconda.org/"&gt;Anaconda&lt;/a&gt; 則是能讓你事後管理不同專案的環境時輕鬆不少：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda create -n airflow-tutorials &lt;span class="nv"&gt;python&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6 -y
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
pip install &lt;span class="s2"&gt;"apache-airflow[crypto, slack]"&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
airflow initdb
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以上的指令幫我們：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建立並啟動一個新的 Anaconda 環境&lt;/li&gt;
&lt;li&gt;在此環境下安裝 Airflow 以及&lt;a href="https://airflow.apache.org/installation.html#extra-packages"&gt;支援 Slack 功能的額外函式庫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;設定專用路徑以讓 Airflow 之後知道要在哪找檔案、存 log&lt;/li&gt;
&lt;li&gt;初始化 Airflow Metadata DB。此 DB 被用來記錄所有工作流程的執行狀況&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;理想上把 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 加入到 &lt;code&gt;~/.bash_profile&lt;/code&gt; 裡頭之後會比較輕鬆，不過現在不做也沒關係。&lt;/p&gt;
&lt;p&gt;【2018/08/27 加註】如果沒有設定 &lt;code&gt;export AIRFLOW_HOME="$(pwd)"&lt;/code&gt; 就執行 &lt;code&gt;airflow initdb&lt;/code&gt;的話，會讓 Airflow 使用作者當初測試時使用的路徑，而不是你 &lt;code&gt;git clone&lt;/code&gt; 下來的 repo 的路徑而造成問題，務必記得設定。&lt;/p&gt;
&lt;p&gt;在環境都搞定之後，我們可以啟動 Airflow 的網頁伺服器：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow webserver -p &lt;span class="m"&gt;8080&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著在瀏覽器輸入 &lt;code&gt;localhost:8080&lt;/code&gt; 就能看到 Airflow 簡潔的 Web UI 了：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-impression-of-airflow-web-ui.jpg" style=""/&gt;
&lt;p&gt;Airflow Web UI 首頁：顯示所有已定義的工作流程（DAG）。&lt;br/&gt;
        圖中的 3 個 DAG 就對應到我們接下來逐漸改善 App 時產生的三個 App 版本&lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Airflow-基本概念"&gt;Airflow 基本概念&lt;a class="anchor-link" href="#Airflow-基本概念"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;這邊值得注意的是 Airflow 利用 &lt;a href="https://airflow.apache.org/concepts.html#dags"&gt;DAG&lt;/a&gt; 一詞來代表一種特殊的工作流程（Workflow）。如工作流程一樣，DAG 定義了我們有什麼工作、工作之間的執行順序以及依賴關係。DAG 的最終目標是將所有工作依照上下游關係全部執行，而不是關注個別的工作實際上是怎麼被實作的（這點在後面的 &lt;a href="#Operator：將實作邏輯跟-DAG-排程分離"&gt;Operator&lt;/a&gt; 章節會有詳細解釋）。&lt;/p&gt;
&lt;p&gt;另外從它的全名&lt;a href="http://www.csie.ntnu.edu.tw/~u91029/DirectedAcyclicGraph.html"&gt;有向無環圖（&lt;strong&gt;D&lt;/strong&gt;irected &lt;strong&gt;A&lt;/strong&gt;cyclic &lt;strong&gt;G&lt;/strong&gt;raph）&lt;/a&gt;你可以看出它具備兩個特色：「有向」及「無環」。事實上我們的 App 邏輯就是一個理想的 DAG。首先，裡頭包含多個邏輯上的工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很明顯地， App 是從上而下地執行每個工作，即為「有向」；同時 App 不會在更新閱讀紀錄以後（下游工作），還跑回去漫畫網站看有沒有新的章節（上游工作）：上游會指向下游，但下游不會指回上游，此即「無環」。&lt;/p&gt;
&lt;p&gt;有了這個理解以後，我們的目標就很明顯了：將 App 的工作流程轉換成一個能在 Airflow 上執行的 DAG，然後排程它，就能讓它每天去找新連載！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本一：大鍋炒"&gt;App 版本一：大鍋炒&lt;a class="anchor-link" href="#App-版本一：大鍋炒"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 Airflow 世界裡，一個 DAG 是由一個 Python script 所定義的。&lt;/p&gt;
&lt;p&gt;以下是我們 App 的第一個版本，也是最簡單的 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 的程式碼（&lt;code&gt;airflow-tutorials/dags&lt;/code&gt; 資料夾底下的 &lt;code&gt;comic_app_v1.py&lt;/code&gt;）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;

&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fn_superman&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Murphy's Law&lt;/span&gt;
    &lt;span class="n"&gt;accident_occur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;accident_occur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;天有不測風雲,人有旦夕禍福"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"工作遇到預期外狀況被中斷&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;new_comic_available&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_comic_available&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"寄 Slack 通知"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"什麼都不幹，工作順利結束"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了讓你能專注在 Airflow 及 DAG 最核心的概念，讓我先用 &lt;code&gt;print()&lt;/code&gt; 假裝我們已經在一個函式 &lt;code&gt;fn_superman&lt;/code&gt; 裡頭實作所有工作的邏輯了。在修改完代表一個 DAG 的 Python script 後，要確保 Airflow 能正確地將其視為一個 DAG，最基本的檢查就是用 Python 直接執行該 script。&lt;/p&gt;
&lt;p&gt;你目前的 terminal 應該正被 Airflow 的網頁伺服器所使用。如果你還沒有把 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 加到 &lt;code&gt;~/.bash_profile&lt;/code&gt; 裡頭的話，開啟一個新的 terminal，重新進入 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾以後執行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這邊我們為新的 terminal 啟動 Anaconda 環境，並告訴 Airflow 在 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下找所有它要的東西。（之後要打開新的 terminal 也要做一樣的事情）&lt;/p&gt;
&lt;p&gt;接著我們就可以用 Python 測試 script 的正確性：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python dags/comic_app_v1.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;沒有特別設定的話， Airflow 會去 &lt;code&gt;AIRFLOW_HOME&lt;/code&gt; 路徑底下的 &lt;code&gt;dags&lt;/code&gt; 子資料夾找 DAG，這也是為何我們在上面路徑有個 &lt;code&gt;dags&lt;/code&gt;。（你可以去 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Repo&lt;/a&gt; 確定檔案的路徑。）&lt;/p&gt;
&lt;p&gt;如果沒有任何錯誤跑出來，恭喜！Airflow 能將其視為一個正常的 DAG 並顯示在 Web UI 上。之後只要你有修改 DAG 裡頭的程式碼，都應該做這個檢查。&lt;/p&gt;
&lt;p&gt;這個 DAG 的程式碼雖不長，卻隱含了一些非常重要的概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="輕鬆排程"&gt;輕鬆排程&lt;a class="anchor-link" href="#輕鬆排程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;靠近 &lt;a href="#App-版本一：大鍋炒"&gt;Script&lt;/a&gt; 尾端的這行實際上就定義了我們的 DAG 並將它命名為 &lt;code&gt;comic_app_v1&lt;/code&gt;。而此 DAG 的排程（Scheduling）設定如&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;'start_date': datetime(2100, 1, 1, 0, 0)&lt;/code&gt; 代表從西元 2100 年開始第一次執行此 DAG &lt;/li&gt;
&lt;li&gt;每次執行之間間隔多久。&lt;code&gt;'schedule_interval': '@daily'&lt;/code&gt; 代表每天執行一次&lt;/li&gt;
&lt;li&gt;&lt;code&gt;'retries': 2&lt;/code&gt; 則允許 Airflow 在 DAG 失敗時重試 2 次 &lt;/li&gt;
&lt;li&gt;DAG 失敗後等多久後開始重試（&lt;code&gt;'retry_delay': timedelta(minutes=1)&lt;/code&gt;　代表等一分鐘）&lt;/li&gt;
&lt;li&gt;更多更多 ...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;乍看之下沒什麼了不起的，就是些設定。&lt;/p&gt;
&lt;p&gt;但如果你有自己從頭實作過資料管道的經驗或者使用過 &lt;a href="https://zh.wikipedia.org/wiki/Cron"&gt;Cron&lt;/a&gt; 排程 ETL，就能體會 Airflow 這樣的「Configuration as Code」有多麽的強大：你只做一些設定（Config），Airflow 就幫你自動建立可靠、失敗時會自動重試的工作流程。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/utah-mechanical-contractors-1103725_1280.jpg" style=""/&gt;
&lt;p&gt;按幾個按鈕就能做出可靠的工作流程，將自動化、失敗重試、相依性管理全部交給 Airflow&lt;/p&gt;
&lt;/center&gt;&lt;p&gt;這些排程設定為了方便管理，一般都另外定義在 &lt;code&gt;default_args&lt;/code&gt; 變數並放在 script 的最上面。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Operator：將實作邏輯跟-DAG-排程分離"&gt;Operator：將實作邏輯跟 DAG 排程分離&lt;a class="anchor-link" href="#Operator：將實作邏輯跟-DAG-排程分離"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;最有趣的是我們使用 &lt;code&gt;with&lt;/code&gt; 關鍵字來定義一個只屬於 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 的領域。在這裡頭我們則定義了唯一一個工作 &lt;code&gt;superman_task&lt;/code&gt; 處理所有事情（你應該能猜到為何它被這樣命名）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這段程式碼用白話翻譯的話，就是說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 裡頭，利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個名為 &lt;code&gt;superman_task&lt;/code&gt; 的工作，而實際執行這個工作的時候，呼叫 &lt;code&gt;fn_superman&lt;/code&gt; 函式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一個非常重要且需要你搞懂的概念是，現在說的工作（Task），是指那些實際透過程式碼宣告，在 DAG 裡頭被定義出來的工作，如 &lt;code&gt;superman_task&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;前面我們提到，App 概念上本身就包含了多個工作（步驟）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些是「邏輯上」的工作，而在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭，為了方便說明，我們將它們全部包起來，定義成唯一一個 Airflow 工作： &lt;code&gt;superman_task&lt;/code&gt;。（在 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節裡，我們則會分別為這些「邏輯工作」建立他們自己的 Airflow 工作）。&lt;/p&gt;
&lt;p&gt;回到 Opeartor 的話題。在 Airflow 裡頭，DAG 只知道有哪些工作以及這些工作之間的執行順序。而實際上這些工作要怎麼被完成，其實作邏輯則是由各種 &lt;a href="https://airflow.apache.org/code.html#operators"&gt;Operator&lt;/a&gt; 負責。&lt;/p&gt;
&lt;p&gt;你可以想像 &lt;a href="https://airflow.apache.org/code.html#airflow.operators"&gt;Opeartors&lt;/a&gt; 就是幫我們完成特定種類工作的小幫手，像是一些常見的例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.PythonOperator"&gt;PythonOperator&lt;/a&gt; 執行一個 Python 函式&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.BashOperator"&gt;BashOperator&lt;/a&gt; 執行 Bash 指令&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.S3KeySensor"&gt;S3KeySensor&lt;/a&gt; 監測 S3 上的檔案存不存在&lt;/li&gt;
&lt;li&gt;&lt;a href="https://airflow.apache.org/code.html#airflow.operators.SlackAPIPostOperator"&gt;SlackAPIPostOperator&lt;/a&gt; 送訊息給 Slack&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要建立一個 DAG 裡的工作（Task）就是依照你想要它完成的特定目標，來選擇合適的 Operator。比方說上面的 &lt;code&gt;superman_task&lt;/code&gt; 就是透過 &lt;code&gt;PythonOperator&lt;/code&gt; 來執行特定的 Python 函式 &lt;code&gt;fn_superman&lt;/code&gt;，而該函式則把 App 裡頭所有的「邏輯工作」實作了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;PythonOperator&lt;/code&gt; 可以說是 Airflow 裡最基本也最強大的 &lt;a href="https://airflow.apache.org/code.html#airflow.operators"&gt;Opeartors&lt;/a&gt; 之一。學會使用方法以後，你可以將任何你定義的 Python 函式變成一個 Airflow 工作。&lt;/p&gt;
&lt;p&gt;基本的使用方法非常簡單，你只要指定一個可呼叫的 Python 函式給 &lt;code&gt;python_callable&lt;/code&gt; 參數以及設定一個工作名稱（task_id）即可：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在後面的 &lt;a href="#Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;/a&gt;章節，我們則會看到如何使用其他 Operator 如 &lt;a href="https://airflow.apache.org/code.html#airflow.operators.SlackAPIPostOperator"&gt;SlackAPIPostOperator&lt;/a&gt; 來新增一個可以幫我們送 Slack 訊息的工作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="測試開發-Airflow-工作"&gt;測試開發 Airflow 工作&lt;a class="anchor-link" href="#測試開發-Airflow-工作"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你現在應該已經理解 DAG 本身關注的是有哪些工作以及他們的相依性，而不是各個工作的實作邏輯。（雖然在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭只有一個工作所以不存在相依性問題）&lt;/p&gt;
&lt;p&gt;我們用 &lt;code&gt;python dags/comic_app_v1.py&lt;/code&gt; 確保 DAG 本身沒有語法問題以後，接著就是要確保裡頭每個工作（Task）的執行結果如我們預期。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭，我們只有一個工作 &lt;code&gt;superman_task&lt;/code&gt; （其透過一個函式 &lt;code&gt;fn_superman&lt;/code&gt; 幫我們做所有邏輯上的工作）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fn_superman&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# Murphy's Law&lt;/span&gt;
    &lt;span class="n"&gt;accident_occur&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;accident_occur&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;天有不測風雲,人有旦夕禍福"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"工作遇到預期外狀況被中斷&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt;

    &lt;span class="n"&gt;new_comic_available&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;new_comic_available&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"寄 Slack 通知"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"什麼都不幹，工作順利結束"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v1'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;superman_task&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'superman_task'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fn_superman&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這樣的設計有什麼優點？&lt;/p&gt;
&lt;p&gt;一般來說 DAG 跟工作是一對多的關係（一個工作流程裡有多個小工作要做）：要讓一個 DAG 順利跑完，理所當然所有工作都要順利執行完畢。但 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 是個特例，它裡頭只有一個工作，一人吃全家飽。只要測試且確保 &lt;code&gt;superman_task&lt;/code&gt; 工作的執行結果如我們預期，就代表 DAG &lt;code&gt;comic_app_v1&lt;/code&gt; 能順利完成，簡單易懂！&lt;/p&gt;
&lt;p&gt;我們可以使用 Airflow 的 &lt;code&gt;test&lt;/code&gt; 指令來幫我們測試這個工作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-18
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這行指令是讓 Airflow 幫我們測試 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭的 &lt;code&gt;superman_task&lt;/code&gt; 工作，並假設這個工作是在 &lt;code&gt;2018-08-18&lt;/code&gt; 這個日期被執行。在我們的 App 例子中，&lt;code&gt;superman_task&lt;/code&gt; 工作的執行結果基本上不會受到執行日期的影響，可以隨便你改。&lt;/p&gt;
&lt;p&gt;但想像一個每天 24 點 0 分準備被啟動，從資料庫撈出數據並計算「當天」使用者數目的工作。其 SQL 查詢可能長這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{execute_date}'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因為此工作的結果會受到執行日期的影響，在測試的時候，你就得仔細選擇執行日期（execute_date）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;拉回 &lt;code&gt;superman_task&lt;/code&gt; 工作的測試。&lt;/p&gt;
&lt;p&gt;從上面 &lt;code&gt;fn_superman&lt;/code&gt; 函式的程式碼你可能已經注意到，我埋了個小彩蛋，每次執行都會有不同的執行結果。&lt;/p&gt;
&lt;p&gt;幸運的話你會得到下面這種：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-01
取得使用者的閱讀紀錄
去漫畫網站看有沒有新的章節
跟紀錄比較，有沒有新連載？
什麼都不幹，工作順利結束
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;喔耶！這執行結果如我們預期，可以讓 DAG 上線定期執行了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不過別高興得太早。多執行幾次看看。如果墨菲定律發生，你會得到失敗的結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v1 superman_task &lt;span class="m"&gt;2018&lt;/span&gt;-08-01
取得使用者的閱讀紀錄
去漫畫網站看有沒有新的章節
跟紀錄比較，有沒有新連載？

天有不測風雲,人有旦夕禍福
工作遇到預期外狀況被中斷
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設此執行結果不是我們預期的結果，該怎麼辦？&lt;/p&gt;
&lt;p&gt;如果你反應夠快，會說：&lt;/p&gt;
&lt;p&gt;「那又怎麼樣？墨菲定律不會每次發生，而且就算遇到而導致工作失敗的話， Airflow 不是會自己幫我們重試嗎？」&lt;/p&gt;
&lt;p&gt;的確，這是我們在前面&lt;a href="#輕鬆排程"&gt;輕鬆排程&lt;/a&gt;章節提到 Airflow 的強處。畢竟我們這 App 只是在檢查最新連載，不是做什麼很複雜的運算。基本上就算 DAG 裡頭這唯一一個工作 &lt;code&gt;superman_task&lt;/code&gt; 失敗了導致整個 DAG 要重跑，Airflow 也可以應付得來。&lt;/p&gt;
&lt;p&gt;但問題在於，企業在運行資料管道的時候，常常需要分成很多步驟，某些步驟可能需要龐大的計算資源跟時間（像是將每天使用者使用 App 的幾億筆紀錄做匯總存入資料庫），有些則很輕量（如存取一個外部 API 取得外匯比例）。&lt;/p&gt;
&lt;p&gt;現在假設你無視這些不同步驟的性質差異，將它們全部放在一個 &lt;code&gt;fn_superman&lt;/code&gt; 函式裡頭並只建立一個 Airflow 工作，當該 Airflow 工作裡頭任何一個輕量的步驟失敗，Airflow 得重跑整個工作，導致所有龐大計算的步驟也得跟著重新執行，重試的時間/計算成本會大到你哭出來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;雞蛋不要放在同個籃子裡。為邏輯上獨立的工作/步驟分別建立 Airflow 工作，可以讓 Airflow 只從失敗的工作開始重新做起。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此一個比較好的 Airflow DAG 設計模式是為我們 App 裡頭每個邏輯上獨立的工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？&lt;ul&gt;
&lt;li&gt;沒有：&lt;ul&gt;
&lt;li&gt;什麼都不幹，結束&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;有：&lt;ul&gt;
&lt;li&gt;寄 Slack 通知&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都分別建立如同 &lt;code&gt;superman_task&lt;/code&gt; 的 Airflow 工作，並定義好它們之間的相依性（Dependencies）。而這將是我們下一節的重點。&lt;/p&gt;
&lt;p&gt;題外話：你可能會納悶為何我們只測試 &lt;code&gt;superman_task&lt;/code&gt; 工作而沒測試整個 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG。當然「一人吃全家飽」是個理由：只要確定 DAG 裡頭唯一一個工作正確運作，我們就能保證此 DAG 沒問題。&lt;/p&gt;
&lt;p&gt;事實上還有一個原因：&lt;code&gt;airflow test&lt;/code&gt; 指令實際上只能用來測試單一工作，而不能測試整個 DAG。關於 DAG 的測試我們在後面的 &lt;a href="#Airflow-排程器"&gt;Airflow 排程器&lt;/a&gt; 章節會詳細說明。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本二：模組化_1"&gt;&lt;a name="app-v2"&gt;&lt;/a&gt;App 版本二：模組化&lt;a class="anchor-link" href="#App-版本二：模組化"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以現在我們要做的改善（Refactoring）很簡單：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將 App 邏輯從 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 中的函式 &lt;code&gt;fn_superman&lt;/code&gt; 中拿出來&lt;/li&gt;
&lt;li&gt;為 App 的每個步驟分別定義一個 Python 函式&lt;/li&gt;
&lt;li&gt;在 DAG 裡頭利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立多個 Airflow 工作並分別呼叫這些函式&lt;/li&gt;
&lt;li&gt;定義這些工作的執行順序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;版本二的 App 完整的程式碼如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;datetime&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.dummy_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.slack_operator&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;

&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"取得使用者的閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"更新閱讀紀錄"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"去漫畫網站看有沒有新的章節"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;anything_new&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;generate_message&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"產生要寄給 Slack 的訊息內容並存成檔案"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;update_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'update_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;generate_message&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"YOUR_SLACK_TOKEN"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;do_nothing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;update_read_history&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;天啊這可比 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 的程式碼長了不少！&lt;/p&gt;
&lt;p&gt;不過在你開始懷疑自己適不適合寫 Airflow DAG 之前讓我提醒你一下。就跟我們剛剛上面提到的，實際上這個 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的架構從上到下也就分為三個區塊：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用 &lt;code&gt;def&lt;/code&gt; 定義負責實作的 Python 函式（們）&lt;/li&gt;
&lt;li&gt;在 DAG 利用各種 &lt;code&gt;Operator&lt;/code&gt; 定義 DAG 工作（大部分是 &lt;code&gt;PythonOperator&lt;/code&gt;，並使用 &lt;code&gt;python_callable&lt;/code&gt; 指定執行步驟 1 定義的函式）&lt;/li&gt;
&lt;li&gt;定義這些 DAG 工作的執行順序（Workflow）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;回頭再看一遍，有沒有清楚一點了？&lt;/p&gt;
&lt;p&gt;在細看 &lt;code&gt;comic_app_v2&lt;/code&gt; 的程式碼前，先讓我們用 Airflow Web UI 研究一下這個 DAG 在做什麼：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a ,="" href="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.gif" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;Airflow Web UI 裡頭的 Graph View 幫我們視覺化 DAG 的工作流程&lt;br/&gt;
        （&lt;a ,="" href="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.gif" target="_blank"&gt;這個 GIF 展示如何從 Airflow UI 開啟此畫面&lt;/a&gt;）
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Airflow 工作寫成英文是為了方便使用 &lt;code&gt;airflow test&lt;/code&gt; 指令測試每個工作。&lt;/p&gt;
&lt;p&gt;儘管工作名稱都是英文，你應該不會覺得陌生。因為這就是我們 App 的邏輯：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取得使用者的閱讀紀錄（get_read_history）&lt;/li&gt;
&lt;li&gt;去漫畫網站看有沒有新的章節（check_comic_info）&lt;/li&gt;
&lt;li&gt;跟紀錄比較，有沒有新連載？（new_comic_available）&lt;ul&gt;
&lt;li&gt;沒有（no_do_nothing）&lt;/li&gt;
&lt;li&gt;有（yes_generate_notification）&lt;ul&gt;
&lt;li&gt;寄 Slack 通知（send_notification）&lt;/li&gt;
&lt;li&gt;更新閱讀紀錄（update_read_history）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看來這應該不是巧合：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Airflow-排程器"&gt;Airflow 排程器&lt;a class="anchor-link" href="#Airflow-排程器"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同當初測試 &lt;code&gt;comic_app_v1&lt;/code&gt; DAG 裡頭的 &lt;code&gt;superman_task&lt;/code&gt; 工作一樣，在我們放心讓 Airflow 幫我們排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 以前，應該分別測試裡頭所有工作，確保它們的執行結果如我們預期：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 get_read_history &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
取得使用者的閱讀紀錄

airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 check_comic_info &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
跟紀錄比較，有沒有新連載？

airflow &lt;span class="nb"&gt;test&lt;/span&gt; comic_app_v2 new_comic_available &lt;span class="m"&gt;2018&lt;/span&gt;-01-01
去漫畫網站看有沒有新的章節

...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們已經做完所有工作的測試，想讓 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 開始被 Airflow 排程，除了已經被開啟的 Airflow 網頁伺服器以外，我們需要另外開啟 Airflow 排程器（Scheduler）。&lt;/p&gt;
&lt;p&gt;因為目前為止一直在運轉的 Airflow 網頁伺服器只負責：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顯示 DAG 資訊，如工作流程圖、各個 DAG 的運行狀況以及 Logs&lt;/li&gt;
&lt;li&gt;讓我們輕鬆地終止/開始 DAG 排程（在有排程器的前提）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而實際要執行 DAG、分配每個工作的運算資源則需要 Airflow 排程器。Airflow 的架構圖能幫助我們理解這件事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/airflow-architecture.png" style="width:70%"/&gt;
&lt;p&gt;
&lt;a href="https://medium.com/@dustinstansbury/understanding-apache-airflows-key-concepts-a96efed52b1a" target="_blank"&gt;Airflow 架構圖&lt;/a&gt;：Scheduler 是實際做排程、呼叫 Worker 執行工作的傢伙；我們熟悉的 Webserver 則提供一個 Web UI 讓我們可以輕鬆檢視工作執行時產生的 Logs、DAG 的程式碼以及工作的執行結果；所有資料都被存在 Metadata Database 裡頭。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事不宜遲，讓我們啟動 Airflow 排程器吧！&lt;/p&gt;
&lt;p&gt;現在再打開一個 terminal，進入 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾後設定環境：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;AIRFLOW_HOME&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;pwd&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著啟動排程器：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;airflow scheduler
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到目前為止你應該有 3 個 terminals 各司其職：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用來輸入 &lt;code&gt;airflow&lt;/code&gt; 相關指令的 terminal&lt;/li&gt;
&lt;li&gt;Airflow Webserver&lt;/li&gt;
&lt;li&gt;Airflow Scheduler&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我保証不會再多了。&lt;/p&gt;
&lt;p&gt;有了排程器以後，打開 UI，在左邊將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 設成「On」後，點擊右邊「Trigger Dag」按鈕可以呼叫排程器馬上開始執行該 DAG。先讓我們按下去以後，再讓我解釋這樣做會發生什麼事情。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;a ,="" href="https://leemeng.tw/images/airflow/trigger-dag-demo.gif" target="_blank"&gt;
&lt;img src="https://leemeng.tw/images/airflow/ready-to-trigger-dag.png" style=""/&gt;
&lt;/a&gt;
&lt;p&gt;在左邊將 DAG 設成「On」後，可以利用右邊「Trigger Dag」按鈕呼叫排程器馬上開始執行該 DAG &lt;br/&gt;
        （&lt;a ,="" href="https://leemeng.tw/images/airflow/trigger-dag-demo.gif" target="_blank"&gt;這個 GIF 展示如何從 Airflow UI 觸發一個 DAG&lt;/a&gt;）
&lt;/p&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了避免預料之外的排程，Airflow 所有 DAG 的預設狀態都是暫停的（Paused），也就是上圖中如 &lt;code&gt;comic_app_v1&lt;/code&gt; 左邊的「Off」。只有在你將 DAG 的狀態設定成如圖中的 &lt;code&gt;comic_app_v2&lt;/code&gt; 的「On」，排程器才會開始為其做排程。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="手動觸發-DAG"&gt;手動觸發 DAG&lt;a class="anchor-link" href="#手動觸發-DAG"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖說將一個 DAG 取消暫停（Unpause）可以讓它成為 Airflow 的排程對象，實際上 Airflow 的排程又分兩種方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;手動觸發（Manual）&lt;ul&gt;
&lt;li&gt;常用在測試 DAG 或是有意外發生，需要手動重新執行 DAG 的時候&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;定期執行（Scheduled）&lt;ul&gt;
&lt;li&gt;也就是所謂的「正式上線」。&lt;/li&gt;
&lt;li&gt;依照 DAG 的 &lt;code&gt;start_date&lt;/code&gt; 及 &lt;code&gt;schedule_interval&lt;/code&gt; 設定決定何時執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在讓我們先專注在手動觸發。&lt;/p&gt;
&lt;p&gt;當然你也可以在不透過 Web UI 的情況下，直接利用 terminal 取消暫停一個 DAG 並觸發它：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;airflow unpause comic_app_v2
airflow trigger_dag comic_app_v2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;理論上我們剛剛手動觸發的 &lt;code&gt;comic_app_v2&lt;/code&gt; 應該已經跑完了。重新整理你應該會看到 Airflow UI 顯示 DAG 已被成功執行的畫面：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-dag.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從 Web UI 我們可以清楚地看到剛剛手動觸發的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 已經被 Airflow 排程器拿去執行，產生一個新的 DAG Run 並成功執行。DAG 跟 DAG Run 的差異在於前者只是個定義好的工作流程，後者則是該 DAG 在某個時間點實際被排程器拿去執行（Run）過後的結果，會有一個執行日期（execute_date）。&lt;/p&gt;
&lt;p&gt;接著點擊右邊 Links 中長得像太陽的 Graph View 按鈕後就可以看到這個 DAG Run 的執行狀況：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-tasks-in-dag.png" style=""/&gt;
&lt;p&gt;
        將游標放在右邊的「Success」狀態按鈕上可以顯示此 DAG Run 中被成功執行的工作（圖內的工作從左到右被執行）&lt;br/&gt;
        注意圖中 DAG Run 的 ID： manual_2018-08-19... 表示這是一個在 2018-08-19 被手動觸發的 DAG Run。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們可以清楚地看到這個 DAG Run 完美地模擬了我們 App 在檢查到新連載情報時送 Slack 訊息給我們的情境。我甚至收到一個 Slack 訊息：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-slack-message.png" style=""/&gt;
&lt;p&gt;
        comic_app_v2 DAG 如果發現有新連載就會寄一個罐頭 Slack 訊息，包含 DAG 執行日期。因為我是在 2018-08-19 當天手動觸發此 DAG，因此日期即為 2018-08-19。後面我們會看到如何客製化 Slack 訊息內容。
    &lt;/p&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="定義工作流程"&gt;定義工作流程&lt;a class="anchor-link" href="#定義工作流程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要在 DAG 裡頭定義出如上圖的工作流程也非常的直觀，讓我們參考這兩個工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;yes_generate_notification&lt;/li&gt;
&lt;li&gt;send_notification&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它們在 &lt;code&gt;dags/comic_app_v2.py&lt;/code&gt; 裡頭被這樣定義（節錄最重要的部分）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以發現在 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡，我們分別定義好這兩個工作以後，在最下面用 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 語法告訴 Airflow 這兩個工作的相依性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;yes_generate_notification&lt;/code&gt; 工作要在 &lt;code&gt;send_notification&lt;/code&gt; 之前執行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外眼尖的讀者會發現，Python 變數名稱 &lt;code&gt;generate_notification&lt;/code&gt; 跟實際上的工作名稱（task_id） &lt;code&gt;yes_generate_notification&lt;/code&gt; 並不一致。我們將實際的工作 &lt;code&gt;PythonOperator&lt;/code&gt; 命名為 &lt;code&gt;generate_notification&lt;/code&gt;，只是為了後面在定義工作流程的時候好提到它。參考下面的程式碼：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;task1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;task2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;# define workflow&lt;/span&gt;
    &lt;span class="n"&gt;task1&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;task2&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這段程式碼跟上一段程式碼在定義工作流程上有一模一樣的效果，只是後者的 naming convention 在定義工作流程的時候比較易懂。&lt;/p&gt;
&lt;p&gt;雖然要多打幾個字，為了其他 DS/DE 以及未來的自己，一般推薦 Python 變數名稱取跟 &lt;code&gt;task_id&lt;/code&gt; 類似的名字。&lt;/p&gt;
&lt;p&gt;針對其他工作，我們也是用相同語法將它們串起來：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;

&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;

&lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;update_read_history&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然後我們就得到前面看過的工作流程圖了：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;/center&gt;&lt;p&gt;你也可以回到 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節，確認 &lt;code&gt;comic_app_v2&lt;/code&gt; 完整的程式碼後再利用左邊的傳送門回來，我等你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;a class="anchor-link" href="#Airflow-變數以及-Jinja-模板"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在你應該已經了解如何使用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個新的工作，並利用 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 語法定義 Airflow 的工作流程（DAG）了。我們也實際觸發 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 讓 Airflow 排程器幫我們排程，最後收到一個 Slack 訊息。&lt;/p&gt;
&lt;p&gt;現在讓我們仔細研究一下負責寄 Slack 訊息的工作，也就是下圖的 &lt;code&gt;send_notificiation&lt;/code&gt;：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;p&gt;
        依照 Opeartor 種類不同，工作在 Web UI 上顯示的背景顏色也有所不同，方便區分。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;你會發現它的顏色跟其他工作不一樣，這是因為它並不是一個 &lt;code&gt;PythonOperator&lt;/code&gt;，而是一個 &lt;code&gt;SlackAPIPostOperator&lt;/code&gt;。由此 Operator 定義的工作並不會呼叫一個 Python 函式，而是直接呼叫 Slack API 來傳送訊息。下面是我們在當初落落長的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡頭定義的 &lt;code&gt;send_notificiation&lt;/code&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"YOUR_SLACK_TOKEN"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意 &lt;code&gt;text&lt;/code&gt; 參數的值。 &lt;code&gt;{{ ds }}&lt;/code&gt; 實際上是 &lt;a href="https://airflow.apache.org/tutorial.html#templating-with-jinja"&gt;Jinja&lt;/a&gt; 語法，它允許我們將 Python 變數渲染（Render）到字串裡頭，動態地產生文本。這就像是我們有個變數 &lt;code&gt;ds&lt;/code&gt;，然後利用 &lt;code&gt;format&lt;/code&gt; 語法一樣：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;text = "[{ds}] 海賊王有新番了!".format(ds=ds)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而這邊的重點是 Airflow 在執行一個 DAG 的時候會提供一些預設的&lt;a href="https://airflow.apache.org/code.html?highlight=macros#macros"&gt;環境變數&lt;/a&gt;供我們使用，像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ds&lt;/code&gt;：代表 DAG Run 的執行日期（execute_date），以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yesterday_ds&lt;/code&gt;：DAG Run 的執行日期的前一天，以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tomorrow_ds&lt;/code&gt;：DAG Run 的執行日期的後一天，以 &lt;code&gt;YYYY-MM-DD&lt;/code&gt; 形式表現&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而因為我們在 2018-08-19 的時候，利用下面這個指令手動觸發 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;trigger_dag&lt;/span&gt; &lt;span class="n"&gt;comic_app_v2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Airflow 會將實際執行該 DAG 的日期設定為執行日期（execute_date）。因此 &lt;code&gt;ds&lt;/code&gt; 即為 &lt;code&gt;2018-08-19&lt;/code&gt;，&lt;code&gt;SlackAPIPostOperator&lt;/code&gt; 裡頭的 &lt;code&gt;"[{{ ds }}] 海賊王有新番了!"&lt;/code&gt; 就會被渲染成 &lt;code&gt;[2018-08-19] 海賊王有新番了!&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;最後我們就得到這個 Slack 訊息：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/first-slack-message.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;現在你也了解使用 Jinja 語法可以動態地調整每次 DAG 運行的邏輯以及執行結果。讓我們實際將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 丟上線試試看吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="執行日期：排程最重要的概念"&gt;執行日期：排程最重要的概念&lt;a class="anchor-link" href="#執行日期：排程最重要的概念"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過前面的幾個章節，我們已經對 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的測試及開發下了不少功夫：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;利用 &lt;code&gt;airflow test&lt;/code&gt; 指令分別測試每個 Airflow 工作執行如預期&lt;/li&gt;
&lt;li&gt;&lt;code&gt;python dags/comic_app_v2.py&lt;/code&gt; 確保 DAG 定義無誤&lt;/li&gt;
&lt;li&gt;使用 Web UI 點擊「 Trigger Dag 」按鈕或是透過 &lt;code&gt;airflow trigger&lt;/code&gt; 來手動觸發 DAG 確認結果&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些都是將一個 DAG 正式上線前必須完成的步驟。在這些測試都完成以後，是時候將我們的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 交給 Airflow 排程器，讓 Airflow 幫我們每天執行這個 DAG 了！&lt;/p&gt;
&lt;p&gt;在&lt;a href="#手動觸發-DAG"&gt;手動觸發 DAG&lt;/a&gt; 章節我們有看到，要讓 Airflow 排程器開始排程一個 DAG，首先要終止暫停（Unpause）該 DAG。而為何當時 Airflow 沒有在我們 &lt;code&gt;comic_app_v2&lt;/code&gt;一終止暫停 就開始自動排程，而要等到我們手動觸發呢？&lt;/p&gt;
&lt;p&gt;這是因為當時的 &lt;code&gt;comic_app_v2&lt;/code&gt; 的排程設定如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;'start_date': datetime(2100, 1, 1, 0, 0)&lt;/code&gt; 代表我們希望 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的第一個執行日期（execute_date）為西元 2100 年 1 月 1 號 0 點。&lt;/p&gt;
&lt;p&gt;你可能覺得為何要把話說得那麼複雜，就說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不就好了嗎？&lt;/p&gt;
&lt;p&gt;不這麼說的原因，就是因為上面的理解是錯的。事實上這是很多人在利用 Airflow 排程時最容易搞錯的&lt;a href="https://airflow.readthedocs.io/en/latest/scheduler.html?highlight=start_date"&gt;概念&lt;/a&gt;之一，值得花點篇幅徹底搞清楚。&lt;/p&gt;
&lt;p&gt;假如西元 2100 年我們架的 Airflow 排程器還在運作的話，它會在：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;start_date 2100 年 1 月 1 號 0 點 0 分 + 1 * schedule_interval
=   2100 年 1 月 1 號 0 點 0 分 + 1 * @daily
=   2100 年 1 月 1 號 0 點 0 分 + 1 * 24 小時
=   2100 年 1 月 2 號 0 點 0 分
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;也就是 2100 年 1 月 2 號 0 點 0 分的時候，將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 拿出來做第一次執行，而該 DAG Run 的執行日期為 2100 年 1 月 1 號 0 點 0 分。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/black-man-question.jpg" style=""/&gt;
&lt;p&gt;
        我知道你現在可能滿臉黑人問號，但讓我們好好想一想這到底是怎麼一回事。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;要理解為何我們一開始的猜想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是非常矛盾的，讓我們做個我最愛的假想實驗。還記得在&lt;a href="#測試開發-Airflow-工作"&gt;測試開發 Airflow 工作&lt;/a&gt;章節提到的 SQL 查詢嗎？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'{execute_date}'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;現在假設我們給這個工作跟 &lt;code&gt;comic_app_v2&lt;/code&gt; 一模一樣的排程設定：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;'start_date': datetime(2100, 1, 1, 0, 0)
'schedule_interval': '@daily'
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;根據本章節一開始的敘述，這個 DAG 的第一個執行日期（execute_date）為 &lt;code&gt;2100-01-01&lt;/code&gt;。而按照我們在 &lt;a href="#Airflow-變數以及-Jinja-模板"&gt;Airflow 變數以及 Jinja 模板&lt;/a&gt;章節所說的，此 SQL 查詢裡頭的 Jinja 語法會被渲染成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'2100-01-01'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著假設我們一開始的猜想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「 Airflow 排程器會在 西元 2100 年 1 月 1 號 0 點第一次執行此 DAG 」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是對的話，該 SQL 查詢會取回什麼資料？&lt;/p&gt;
&lt;p&gt;答案是什麼都沒有。&lt;/p&gt;
&lt;p&gt;因為如果這猜想是對的話，這個 SQL 查詢工作會馬上在西元 2100 年 1 月 &lt;strong&gt;1&lt;/strong&gt; 號的 0 點，想辦法去把西元 2100 年 1 月 &lt;strong&gt;1&lt;/strong&gt; 號整天的使用者資料全部撈出來。而因為此 SQL 查詢執行時， 1 月 1 號才剛開始，這個查詢不會取得任何資料。&lt;/p&gt;
&lt;p&gt;很明顯哪裡出了差錯了。&lt;/p&gt;
&lt;p&gt;而如果照我剛剛解釋的版本，就會顯得合理許多：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 2100 年 1 月 &lt;strong&gt;2&lt;/strong&gt; 號 0 點的時候，以下的 SQL 查詢會被執行&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_id&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;num_new_users&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;user_activities&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;dt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'2100-01-01'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這代表我們在 1 月 1 號 23 點 59 分結束以後，也就是 1 月 2 號 0 點的時候，將 1 月 1 號所有的使用者資料做彙總。&lt;/p&gt;
&lt;p&gt;一般而言，Airflow 會在 &lt;code&gt;start_date&lt;/code&gt; 加上一個 &lt;code&gt;schedule_interval&lt;/code&gt; 之後開始&lt;a href="https://airflow.readthedocs.io/en/latest/scheduler.html?highlight=start_date"&gt;第一次執行某個 DAG&lt;/a&gt;，而該 DAG Run 的 &lt;code&gt;execute_date&lt;/code&gt; 為 &lt;code&gt;start_date&lt;/code&gt;。這樣的設計就是為了避免像是上面那個 SQL 查詢在當天才剛開始的時候就想要搜集該天所有資料的窘境。&lt;/p&gt;
&lt;p&gt;Airflow 擅長的是管理那些允許「事件發生時間」跟「實際數據處理時間」有落差的批次工作。因此 Airflow 都會在 &lt;code&gt;start_date&lt;/code&gt; 加上 &lt;code&gt;schedule_interval&lt;/code&gt; 長度的時間過完&lt;strong&gt;以後&lt;/strong&gt;，才開始處理發生在 &lt;code&gt;start_date&lt;/code&gt; 到 &lt;code&gt;start_date + schedule_interval&lt;/code&gt; 之間的資料。&lt;/p&gt;
&lt;p&gt;再換句話說，&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個 DAG Run 中的執行日期，只等於它「負責」的日期，不等於它實際被 Airflow 排程器執行的日期。一個被自動排程且執行日期為 dt 的 DAG Run，實際上是在 dt + schedule_period 後被 Airflow 執行。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們換了好幾種說法，希望你能百分之百地掌握這個 Airflow 排程的概念，因為這實在太重要了。&lt;/p&gt;
&lt;p&gt;有了這章節的排程概念以後，我們可以正式開始排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="正式排程"&gt;正式排程&lt;a class="anchor-link" href="#正式排程"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過上一章節排程概念的洗禮，想必你還記得 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的開始排程日期（start_date）是遙遠的西元 2100 年 1 月 1 號：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;作者目前撰寫這段落的日期為西元 2018 年 8 月 20 號，所以大概還要再等 82 年，而且我啟動的 Airflow 排程器還活著，這個 DAG 才會被第一次執行。我們可等不了那麼久。&lt;/p&gt;
&lt;p&gt;在完全地理解上一章&lt;a href="#執行日期：排程最重要的概念"&gt;執行日期：排程最重要的概念&lt;/a&gt;所提到的概念以後，你可能會說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「那我們可以把 start_date 設為 2018 年 8 月 20 號，並維持 schedule_interval 為一天，這樣等到 8 月 21 號 0 點的時候，這個 DAG 就會被執行，然後我們就知道它 work 不 work 了！」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;好傢伙（好姑娘？），我給你 100 分！&lt;/p&gt;
&lt;p&gt;這句話已經抓到 Airflow 排程的精髓中的精髓，只不過別誤會，我趕時間。何不讓我們當個時空旅人，將 start_date 設為 8 月 20 號以前的日期，比方說 8 月 17 號？&lt;/p&gt;
&lt;p&gt;畢竟我們在上一章提到：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個 DAG Run 中的執行日期，只等於它「負責」的日期，不等於它實際被 Airflow 排程器執行的日期。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將 start_date 設為今天（8 月 20 號）&lt;strong&gt;以前&lt;/strong&gt;的日期，並啟動 Airflow 排程器的話，就會讓 Airflow 排程器馬上開始排程執行日期為 start_date 的 DAG Run，並且一直執行到最新的 DAG Run 為止。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/time-machine.jpg" style=""/&gt;
&lt;p&gt;
    Airflow 排程器彷彿就像台時光機器，幫我們排程那些執行日期在過去的 DAG Run，重建過去。
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;所以現在讓我修改 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的程式碼以排程「過去」的 DAG Run：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2018&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v2'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;保持好習慣，修改完程式碼以後用 Python 確認 DAG 沒語法錯誤：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;python dags/comic_app_v2.py
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通常 Airflow 沒多久就會重新載入最新的程式碼。如果你懷疑程式碼沒有被更新，可以點擊 Airflow UI 首頁中 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 最右邊 Links 裡頭的「Refresh」按鈕。&lt;/p&gt;
&lt;p&gt;問題時間。&lt;/p&gt;
&lt;p&gt;將 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 的 start_date 設定成 2018 年 8 月 17 號以後，在作者撰文的 8 月 20 號晚間 10 點為止， Airflow 會排程幾次 DAG Runs？它們分別的執行日期為何？花個幾秒鐘思考，確定你知道答案。（schedule_interval 一樣為 &lt;code&gt;@daily&lt;/code&gt; ）&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/clock-1274699_1280.jpg" style=""/&gt;
&lt;p&gt;
        滴答滴答，你能在我們的時光機完成工作之前想出答案嗎？
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;答案揭曉，Airflow 排程器總共排程三個 DAG Runs，他們的執行日期分別為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2018-08-17&lt;/li&gt;
&lt;li&gt;2018-08-18&lt;/li&gt;
&lt;li&gt;2018-08-19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;8 月 20 號的 DAG Run 則要等到 8 月 21 號 0 點才會被執行。&lt;/p&gt;
&lt;p&gt;喝杯水重新載入 UI，我們可以從 Airflow UI 裡頭確認 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 總共有 4 個成功的 DAG Runs：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/success-dags.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;除了第一個 DAG Run 是我們之前手動觸發以外（你可以從它的 Run Id 以及最右邊的 External Trigger 看出），其他三個都是 Airflow 排程器實際排程並執行的結果（一樣你可以從它們的 Run Id 看出端倪）。&lt;/p&gt;
&lt;p&gt;同時我的 Slack 作響。我們可以看到儘管執行日期相異，三個被排程的 DAG Runs 按照順序通知我有新番。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/three-slack-messages.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;嗯 .. 海賊王一週出一次，想必其中有幾個是 fake news。&lt;/p&gt;
&lt;p&gt;不管如何，我們在這章節成功讓 Airflow 排程器從好幾天前開始自動排程 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 並確認結果成功！&lt;/p&gt;
&lt;p&gt;如果我不將 Airflow 排程器關掉的話，之後每天的 0 點（UTC）它都會幫我執行 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG。沒有意外的話，或許 Airflow 排程器可以幫我們持續排程此 DAG 到西元 2100 年，希望到時海賊王已經完結，不用叫孫子燒給我了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="App-版本三：填填樂_1"&gt;&lt;a name="app-v3"&gt;&lt;/a&gt;App 版本三：填填樂&lt;a class="anchor-link" href="#App-版本三：填填樂"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;目前為止，本文為了讓你能專注在理解 Airflow 及工作流程的核心概念（而非個別工作的實作細節），以 &lt;code&gt;print()&lt;/code&gt; 代替我們 App 的實作邏輯。&lt;/p&gt;
&lt;p&gt;在此章節，我們則會一窺實作所有邏輯的 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG，也就是實現本文開頭展示的 App 的程式碼。&lt;/p&gt;
&lt;p&gt;但為何說「一窺」呢？&lt;/p&gt;
&lt;p&gt;因為 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 為了處理 JSON 檔案、利用 &lt;a href="http://selenium-python.readthedocs.io/" target="_blank"&gt;Selenium&lt;/a&gt; 存取網頁等事情，其程式碼變得比只用 &lt;code&gt;print()&lt;/code&gt; 的 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 要長得多，且其程式碼很大一部份已經不直接跟 Airflow 相關了。&lt;/p&gt;
&lt;p&gt;我相信大部分的讀者是為了學習 Airflow 而來，而不是看我東 try 西 try 來實作這個 App。當然，如果你有興趣且想要練習如何建立一個自己的漫畫連載 App，你可以嘗試將實作邏輯填入到 &lt;code&gt;comic_app_v2&lt;/code&gt; DAG 裡頭的各個 Python 函式即可，或者直接執行我已經實作好所有邏輯的 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG，這個我們在後面的&lt;a href="#quick-start"&gt;如何建立你自己的連載通知 App（懶人法）&lt;/a&gt;章節會有詳細講解。&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/BLOG-fill-in-the-blank@1X.jpg" style=""/&gt;
&lt;p&gt;
        填填樂：以 comic_app_v2 建立好的工作流程為基礎，實作每個工作的邏輯就像是填空題一般，將邏輯填入對應的 Python 函式就好。（comic_app_v3 也是從 comic_app_v2 為基礎開發的，工作流程一模一樣）
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;在這章節，我想跟你分享一些在實作 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 時用到的 Airflow 知識及技巧。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="重複利用-Python-函式"&gt;重複利用 Python 函式&lt;a class="anchor-link" href="#重複利用-Python-函式"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;在 &lt;a href="#app-v2"&gt;App 版本二：模組化&lt;/a&gt;章節我們看到，大部分的 Airflow 工作都是由一個 &lt;code&gt;PythonOperator&lt;/code&gt; 所定義，而每個 &lt;code&gt;PythonOperator&lt;/code&gt; 分別呼叫不同的 Python 函式。但在 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 裡頭，我們只利用一個 Python 函式 &lt;code&gt;process_metadata&lt;/code&gt; 專門負責讀 / 寫使用者的閱讀紀錄：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;mode&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="n"&gt;get_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'get_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'read'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;       

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;update_read_history&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'update_read_history'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_metadata&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;op_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'write'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你會發現上面兩個 Airflow 工作的 &lt;code&gt;python_callable&lt;/code&gt; 都呼叫 &lt;code&gt;process_metadata&lt;/code&gt;，因為它們做類似的事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;get_read_history&lt;/code&gt; 負責讀取閱讀紀錄&lt;/li&gt;
&lt;li&gt;&lt;code&gt;update_read_history&lt;/code&gt; 負責更新閱讀紀錄&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而這兩個工作則利用不同的 &lt;code&gt;op_args&lt;/code&gt; 來使用 &lt;code&gt;process_metadata&lt;/code&gt; 函式的不同功能。這樣的好處是我們不需要為每個類似的 &lt;code&gt;PythonOperator&lt;/code&gt; 都分別建立一個新的 Python 函式，而是利用參數 &lt;code&gt;op_args&lt;/code&gt; 來改變同個 Python 函式的執行結果。&lt;/p&gt;
&lt;p&gt;當然，傳遞參數給 Python 函式這件事情本身就是很常見，這時候 &lt;code&gt;op_args&lt;/code&gt; 就會派上用場。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Xcom：工作之間的訊息交換"&gt;Xcom：工作之間的訊息交換&lt;a class="anchor-link" href="#Xcom：工作之間的訊息交換"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;a href="https://airflow.apache.org/concepts.html?highlight=xcom#xcoms"&gt;Xcom（Cross Communication）&lt;/a&gt; 是 Airflow 工作之間交換訊息的方式。一個被 &lt;code&gt;PythonOperator&lt;/code&gt; 呼叫的 Python 函式所回傳（return）的值，都可以被其他 Airflow 工作透過 Xcom 存取：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"檢查有無新連載"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;

&lt;span class="o"&gt;...&lt;/span&gt;


&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以看到最底下的 &lt;code&gt;check_comic_info&lt;/code&gt; 工作呼叫上方的 &lt;code&gt;check_comic_info&lt;/code&gt; 函式，而該函式回傳 &lt;code&gt;anything_new, all_comic_info&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;接著 &lt;code&gt;decide_what_to_do&lt;/code&gt; 函式則利用以下語法來取得該結果：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下游工作可以透過這樣的方式取得上游工作的執行結果，來決定接下來要做的任務。&lt;/p&gt;
&lt;p&gt;值得注意的是 XCom 的所有資料在 pickle 之後會被存到 Airflow 的 Metadata Database（通常是 MySQL）裡頭，因此不適合交換太大的數據（例：100 萬行的 Pandas DataFrame），而適合用在交換 Metadata。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="o"&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;裡頭的 &lt;code&gt;**context&lt;/code&gt; 的語法是為了取得 Airflow 在執行工作時產生的&lt;a href="https://airflow.apache.org/code.html?highlight=macros#macros"&gt;環境變數&lt;/a&gt;，其中就包含 XCom。除了要在 Python 函式設置 &lt;code&gt;**context&lt;/code&gt; 以外，我們還必須將 &lt;code&gt;PythonOperator&lt;/code&gt; 的 &lt;code&gt;provide_context&lt;/code&gt; 參數設置為 &lt;code&gt;True&lt;/code&gt;，Airflow 才會把環境變數傳給該工作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;check_comic_info&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="在工作流程內加入條件分支"&gt;在工作流程內加入條件分支&lt;a class="anchor-link" href="#在工作流程內加入條件分支"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;有時候我們會想要在工作流程裡頭加入分支，當某條件符合的時候執行這個分支，當不符合的時候執行別的分支。&lt;/p&gt;
&lt;p&gt;比方說我們的 App 就含有這樣的邏輯：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic_app_v2_graph_view.png" style=""/&gt;
&lt;p&gt;利用 BranchPythonOperator 實現 Airflow DAG 裡的條件分支
    &lt;/p&gt;
&lt;/center&gt;&lt;p&gt;圖中的 &lt;code&gt;check_comic_info&lt;/code&gt; 「上游」工作會去漫畫網頁檢查有沒有新的連載，依照結果的不同，我們希望不同分支被執行：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有的話，執行上面分支的 &lt;code&gt;yes_generate_notification&lt;/code&gt; 「下游」工作&lt;/li&gt;
&lt;li&gt;沒有的話，則執行下面分支的 &lt;code&gt;no_do_nothing&lt;/code&gt; 「下游」工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要在 Airflow 裡頭實現這樣的邏輯，可以在上下游工作「之間」新增一個 &lt;code&gt;BranchPythonOperater&lt;/code&gt;（如圖中的 &lt;code&gt;new_comic_available&lt;/code&gt; 工作）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;砍掉原上游工作跟下游工作之間的 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;將原上游工作 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 該 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 工作&lt;/li&gt;
&lt;li&gt;將該 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 工作 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; 原下游工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;資料工程很大一部份的工作就是在建立資料管道/工作流程，接個水管合情合理對吧？&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class="nn"&gt;BranchPythonOperator&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;all_comic_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'task_instance'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xcom_pull&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_ids&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'check_comic_info'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"跟紀錄比較，有沒有新連載？"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;anything_new&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'yes_generate_notification'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;DAG&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'comic_app_v3'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;dag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BranchPythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'new_comic_available'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;python_callable&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;decide_what_to_do&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;provide_context&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;generate_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PythonOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;do_nothing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DummyOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'no_do_nothing'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;generate_notification&lt;/span&gt;
    &lt;span class="n"&gt;decide_what_to_do&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;do_nothing&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而 &lt;code&gt;BranchPythonOperator&lt;/code&gt; 一樣會呼叫一個 Python 函式（上例的 &lt;code&gt;decide_what_to_do&lt;/code&gt; 函式），由該函式決定到底最後哪個下游工作會被執行。基本上該函式會依照實際情況決定哪個下游工作被執行，並將該下游工作的 &lt;code&gt;task_id&lt;/code&gt; 回傳。&lt;/p&gt;
&lt;p&gt;而因為在這個例子中，我們希望依照上游工作 &lt;code&gt;check_comic_info&lt;/code&gt; 回傳的一個布林值 &lt;code&gt;anything_new&lt;/code&gt; 來決定要執行哪個下游工作，因此可以使用 &lt;code&gt;xcom_pull&lt;/code&gt; 取得該結果以後回傳要執行的下游工作 ID &lt;code&gt;task_id&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;好啦，這就是我想跟你分享在實作 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 時的幾個實用技巧，希望對你上手 Airflow 有所幫助。&lt;/p&gt;
&lt;p&gt;接下來我們將針對那些想要建立自己的連載通知 App 的你，提供一個快速起手指南。&lt;/p&gt;
&lt;p&gt;不過如果你現在沒有打算做這件事情的話，可以放心跳到最後面的&lt;a href="#結語"&gt;結語&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何建立你自己的連載通知-App（懶人法）_2"&gt;&lt;a name="quick-start"&gt;&lt;/a&gt;如何建立你自己的連載通知 App（懶人法）&lt;a class="anchor-link" href="#如何建立你自己的連載通知-App（懶人法）"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;此章節提供一個懶人指南，讓那些想要建立自己的 App 的你，在（幾乎）不需要改變 &lt;code&gt;comic_app_v3&lt;/code&gt; 程式碼的前提下完成這件事情。&lt;/p&gt;
&lt;p&gt;如同我們在&lt;a href="#建置-Airflow-環境"&gt;建置 Airflow 環境&lt;/a&gt;提到的，首先你當然得先把跟這篇文章相關的 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials"&gt;Github Repo&lt;/a&gt; 複製下來：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/leemengtaiwan/airflow-tutorials.git
&lt;span class="nb"&gt;cd&lt;/span&gt; airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你在之前就有複製 Repo 下來跟著走，你只需要再另外安裝 &lt;a href="https://selenium-python.readthedocs.io/"&gt;Selenium&lt;/a&gt;。Selenium 是一個自動化網頁測試的工具，在這個 App 裡頭被我們用來當網路爬蟲，去漫畫網站看連載資訊。&lt;/p&gt;
&lt;p&gt;接著啟動目前為止 Airflow 一直在使用的 Anaconda 環境，然後安裝 Selenium：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
conda install -c conda-forge selenium
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果你之前沒有建置任何環境，可以利用 Repo 裡頭的 &lt;a href="https://github.com/leemengtaiwan/airflow-tutorials/blob/master/environment.yaml"&gt;environment.yaml&lt;/a&gt; 從頭安裝 Airflow 以及 Selenium：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;conda env create -n airflow-tutorials -f environment.yaml 
&lt;span class="nb"&gt;source&lt;/span&gt; activate airflow-tutorials
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在這個 App 裡頭，要讓 Selenium 正常運作，你還需要 &lt;a href="https://sites.google.com/a/chromium.org/chromedriver/"&gt;Chrome Driver&lt;/a&gt;。下載最新版本以後把它放在你的 &lt;code&gt;$PATH&lt;/code&gt; 讀得到的地方。Mac 使用者的話可以放到像是 &lt;code&gt;/usr/local/bin&lt;/code&gt; 資料夾下面。如果還是不懂可以查看&lt;a href="https://github.com/leemengtaiwan/gist-evernote#chrome-driver"&gt;這裡的 Chrome Driver 安裝教學&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;環境設定好以後，你會需要一個新的 &lt;a href="https://peppergeeks.slack.com/apps"&gt;Slack App&lt;/a&gt; 來送訊息到你的 Workspace。建立一個新的 Slack App，給予它寫訊息的權限以後，安裝到你自己的 Workspace。這時候你應該會得到一個開頭為 &lt;code&gt;xoxp-&lt;/code&gt; 的 Slack Token。將該 Token 複製下來，打開 &lt;code&gt;airflow-tutorials&lt;/code&gt; 資料夾底下的 &lt;code&gt;data/credentials/slack.json&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;將你的 Token 複製貼上如：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"token"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"xoxp-....."&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;搞定網路爬蟲以及 Slack 認證以後，你需要改變 &lt;code&gt;comic_app_v3.py&lt;/code&gt; 裡頭的一行程式碼，以讓 Airflow 送訊息到你 Workspace 底下指定的頻道（channel）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;send_notification&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SlackAPIPostOperator&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;task_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'send_notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_token&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="n"&gt;channel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'#comic-notification'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;get_message_text&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
    &lt;span class="n"&gt;icon_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'http://airbnb.io/img/projects/airflow3.png'&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將上述的 &lt;code&gt;channel='#comic-notification'&lt;/code&gt; 改成你自己的頻道，如 &lt;code&gt;channel='#my-new-channel'&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;接著你會需要一個正常運作的 Airflow 排程器。啟動方法參考 &lt;a href="#Airflow-排程器"&gt;Airflow 排程器&lt;/a&gt;章節。&lt;/p&gt;
&lt;p&gt;在 Airflow 排程器、Selenium 以及 Slack 都就緒以後，你可以直接手動觸發 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 來測試 App 的第一則訊息。如同我們在&lt;a href="#手動觸發-DAG"&gt;手動觸發 DAG&lt;/a&gt; 章節提到的，你可以透過 Web UI 或者 terminal 來終止暫停（Unpause）並手動觸發一個 DAG：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;unpause&lt;/span&gt; &lt;span class="n"&gt;comic_app_v3&lt;/span&gt;
&lt;span class="n"&gt;airflow&lt;/span&gt; &lt;span class="n"&gt;trigger_dag&lt;/span&gt; &lt;span class="n"&gt;comic_app_v3&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;一切順利的話，幾秒鐘之後，你會在自己的 Slack Workspace 及 channel 底下收到這個測試訊息：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/real-slack-message.png" style=""/&gt;
&lt;p&gt;
    圖中的 channel 會隨著你實際的設定改變
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;目前 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 將使用者的閱讀紀錄儲存在 &lt;code&gt;data/comic.json&lt;/code&gt; 裡頭，底下則是為了產生上面這個 Slack 訊息的假閱讀紀錄：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1152"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"海賊王"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;900&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/airflow/comic-website.jpg" style=""/&gt;
&lt;p&gt;
        上頭 comic.json 裡頭，海賊王的 "1152" 就代表該漫畫主頁在動漫狂的連結中的數字（1152.html）
    &lt;/p&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;目前此 App 只能從&lt;a href="https://www.cartoonmad.com/"&gt;動漫狂&lt;/a&gt;（歡迎你丟 PR 改善！）找最新的漫畫連載。為了新增你自己的漫畫，你需要找出該漫畫主頁在動漫狂的連結，將連結中的數字如上述的例子一樣新增在 &lt;code&gt;data/comic.json&lt;/code&gt; 裡頭。假設你想開始關注「進擊的巨人」，然後最近看到 100 話的話，可以把 &lt;code&gt;data/comic.json&lt;/code&gt; 改成這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1221"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"進擊的巨人"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這樣一來， &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 就會用該數字去「進擊的巨人」的頁面，幫你查看有沒有最新的連載。當然你也可以像我一樣，在 &lt;code&gt;comic.json&lt;/code&gt; 裡追加多個漫畫：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="nt"&gt;"1152"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"海賊王"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;911&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1221"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"進擊的巨人"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;107&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"4485"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"西遊"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;152&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1121"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"浪人劍客"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;327&lt;/span&gt;
  &lt;span class="p"&gt;},&lt;/span&gt;
  &lt;span class="nt"&gt;"1122"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"王者天下"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"previous_chapter_num"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;565&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="err"&gt;...&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;修改完 &lt;code&gt;comic.json&lt;/code&gt;，最後你會想要修改 &lt;code&gt;comic_app_v3.py&lt;/code&gt; 裡頭的排程設定：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;default_args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s1"&gt;'owner'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'Meng Lee'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'start_date'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'schedule_interval'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'@daily'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retries'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'retry_delay'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;timedelta&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;minutes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將 &lt;code&gt;start_date&lt;/code&gt; 改成你想要他它開始的日期，接著 Airflow 排程器就會每天幫你執行 &lt;code&gt;comic_app_v3&lt;/code&gt; DAG 並查看最新連載。搞定收工！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先，由衷感謝你花了那麼多寶貴時間與力氣跟隨著我們的 Airflow 冒險。&lt;/p&gt;
&lt;p&gt;回顧一下，這一路上你已經學會不少資料工程相關的知識以及 Airflow 的開發技巧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解工作流程、上下游工作、相依性的概念以及其與 Airflow DAG 的關係&lt;/li&gt;
&lt;li&gt;模組化工作流程的重要性&lt;/li&gt;
&lt;li&gt;了解如何利用 &lt;code&gt;PythonOperator&lt;/code&gt; 建立一個 Airflow 工作並呼叫自定義 Python 函式&lt;/li&gt;
&lt;li&gt;利用 &lt;code&gt;airflow test&lt;/code&gt; 指令以及 Web UI 測試 Airflow 工作以及 DAG&lt;/li&gt;
&lt;li&gt;了解如何利用 Python 定義一個工作流程以及決定工作間的相依性&lt;/li&gt;
&lt;li&gt;利用 Web UI 及 terminal 手動觸發 DAG 並確認執行結果&lt;/li&gt;
&lt;li&gt;了解 Airflow 排程概念（如執行日期）並實際讓工作流程上線（&lt;code&gt;comic_app_v2&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;了解一些 Airflow 開發時的技巧，如建立條件分支以及使用各種不同的 Operators 建立工作&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先給自己鼓個掌吧！&lt;/p&gt;
&lt;p&gt;如同我在文章開頭所述：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;這是一篇當初我在入門資料工程以及 Airflow 時希望有人能為我寫好的文章。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當時的我找不到這篇文章，而現在我自己寫了這篇文章。&lt;/p&gt;
&lt;p&gt;希望這篇文章能幫助到跟過去的我一樣，正在嘗試學習資料工程以及 Airflow 的你。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然使用 Airflow 來實作本篇的漫畫連載 App 可能是一個殺雞用牛刀的例子，但我希望你能參考本文的 App 例子，開始思考如何用本文學到的知識，去實際解決、自動化你自身或是所在企業的數據問題。&lt;/p&gt;
&lt;p&gt;儘管這篇的 Airflow 故事即將進入尾聲，你的 Airflow 之旅才剛剛展開。&lt;/p&gt;
&lt;p&gt;Keep learning and happy Airflowing！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Python"></category><category term="Airflow"></category><category term="資料工程"></category><category term="Selenium"></category><category term="Slack"></category></entry><entry><title>資料科學文摘 Vol.3 Pandas、Docker 以及數據時代的反思</title><link href="https://leemeng.tw/data-science-digest-volume-3.html" rel="alternate"></link><published>2018-08-10T21:00:00+09:00</published><updated>2018-08-10T21:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-10:/data-science-digest-volume-3.html</id><summary type="html">&lt;p&gt;不同於上週的文摘，這週的選文比較技術以及實作導向。本週將導讀 3 篇使用 Python 以及 Pandas 的文章，並鼓勵讀者實際動手學習。我們也會看到如何使用 Docker 來讓資料科學變得更簡單，並提供一個有趣的貓咪圖片辨識 App 給有興趣的讀者參考。最後，讓我們分別看看哈佛商業評論以及美國前首席資料科學家 DJ Patil 談談如何讓資料科學在企業內普及，以及數據時代我們面臨的各種道德議題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不同於上週的&lt;a href="https://leemengtaiwan.github.io/data-science-digest-volume-2.html"&gt;文摘 Vol.2 產品理解以及 DS / DE 之路&lt;/a&gt;，這週的選文比較技術以及實作導向。本週將導讀 3 篇使用 Python 以及 Pandas 的文章，並鼓勵讀者實際動手學習。我們也會看到如何使用 Docker 來讓資料科學變得更簡單，並提供一個有趣的貓咪圖片辨識 App 給有興趣的讀者參考。最後，讓我們分別看看哈佛商業評論以及美國前首席資料科學家 DJ Patil 談談如何讓資料科學在企業內普及，以及數據時代我們面臨的各種道德議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Pandas、Python&lt;ul&gt;
&lt;li&gt;&lt;a href="#How-to-Master-Your-Skills-for-Pandas?"&gt;How to Master Your Skills for Pandas?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;How to rewrite your SQL queries in Pandas, and more&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Learn-Functional-Python-in-10-Minutes"&gt;Learn Functional Python in 10 Minutes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Docker    &lt;ul&gt;
&lt;li&gt;&lt;a href="#Docker-for-Data-Scientists"&gt;Docker for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Try-It-Yourself"&gt;Cat Recognizer: A flask app showcasing how to recognize cats using Tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;數據時代的反思&lt;ul&gt;
&lt;li&gt;&lt;a href="#The-Democratization-of-Data-Science"&gt;The Democratization of Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Data's-day-of-reckoning"&gt;Data's day of reckoning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-to-Master-Your-Skills-for-Pandas?"&gt;&lt;a href="https://engmrk.com/module5-introduction-to-pandas/"&gt;How to Master Your Skills for Pandas?&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-Master-Your-Skills-for-Pandas?"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://engmrk.com/module5-introduction-to-pandas/" target="_blank"&gt;
&lt;img src="images/digests/Module-5-Introduction-to-Pandas.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;Python 裡頭最著名的資料處理 library 非 &lt;a href="https://pandas.pydata.org/"&gt;Pandas&lt;/a&gt; 莫屬了。&lt;a href="https://engmrk.com/module5-introduction-to-pandas/"&gt;這篇文章&lt;/a&gt;使用互動式的環境，列出挺完整的 Pandas 指令讓讀者可以邊參考 sample code 邊自己動手玩玩看。&lt;/p&gt;
&lt;p&gt;其中包含各種利用 Series 以及 Dataframe 兩種 Pandas 常見的資料格式來對數據進行各種操作，適合沒碰過 Pandas 的新手以及想要重新 refresh 語法的人。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;&lt;a href="https://codeburst.io/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e"&gt;How to rewrite your SQL queries in Pandas, and more&lt;/a&gt;&lt;a class="anchor-link" href="#How-to-rewrite-your-SQL-queries-in-Pandas,-and-more"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://codeburst.io/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e" target="_blank"&gt;
&lt;img src="images/digests/kofu-pandas.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
提供常見的 SQL 查詢以及其對應的 Pandas 寫法。一個有效率的資料科學家通常需要 SQL 及 pandas 兼具。雖然這篇一開始的目標讀者是那些已經熟悉 SQL 並打算使用 Pandas 的讀者，我認為熟悉 Pandas 但還不了解 SQL 的同學們也能從這篇學到點東西。&lt;/p&gt;
&lt;p&gt;這篇適合至少懂 Python 或是 SQL 並想學習另外一個語言的讀者。如果你想要深入了解 SQL 或是其與 Python 之間的差異，你可以看看我之前寫的&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;為何資料科學家需要學習 SQL&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Learn-Functional-Python-in-10-Minutes"&gt;&lt;a href="https://hackernoon.com/learn-functional-python-in-10-minutes-to-2d1651dece6f"&gt;Learn Functional Python in 10 Minutes&lt;/a&gt;&lt;a class="anchor-link" href="#Learn-Functional-Python-in-10-Minutes"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://hackernoon.com/learn-functional-python-in-10-minutes-to-2d1651dece6f" target="_blank"&gt;
&lt;img src="images/digests/1_ZXixptvL4rzkx3EDuj38xw.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/"&gt;這篇 Hackernon 文章&lt;/a&gt;則簡單介紹 Functional Programming 在 Python 可以如何被實作，函式（function）是怎麼被視為 Python 的第一公民以及我們能如何活用函式如 Map、Filter 函式。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你剛起步，想要有效率地學習 Python 的話，我建議可以從 &lt;a href="https://www.python-course.eu/list_comprehension.php"&gt;List comprehension&lt;/a&gt; 開始學起。&lt;/p&gt;
&lt;p&gt;一個簡單的例子是假設我們想從一個 List 中取得大於 50 的數字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;70&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;larger_than_50&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;larger_than_50&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;[100, 70]
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文章的後半段則透過 The Zen of Python （Python 的禪學）來說明為何使用 List comprehension 會比使用傳統 Functional Programming 中的 Map、Filter 函式來得簡單。&lt;/p&gt;
&lt;p&gt;Python 有一個著名的彩蛋，你可以利用 &lt;code&gt;import this&lt;/code&gt; 來顯示 The Zen of Python，它提供使用 Python 的人一個簡單的開發準則，具體如下：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;this&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;The Zen of Python, by Tim Peters

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Docker-for-Data-Scientists"&gt;&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/"&gt;Docker for Data Scientists&lt;/a&gt;&lt;a class="anchor-link" href="#Docker-for-Data-Scientists"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://bobbywlindsey.com/data-science/2018/07/16/docker-for-data-scientists/" target="_blank"&gt;
&lt;img src="images/digests/docker-flickr.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
很簡單地說明常見的 &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; 術語以及使用 Docker 可以為資料科學家帶來的好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;節省建置開發 / 分析環境所需的時間&lt;/li&gt;
&lt;li&gt;增加可重現性（Reproducibility）&lt;/li&gt;
&lt;li&gt;抽象化作業系統（OS）的概念，再也沒有只能在 Mac 跑而不能在 Windows 跑的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這篇提供非常初級的指令來開始在本機環境使用 Docker，可以嘗試看看。&lt;/p&gt;
&lt;p&gt;在 Smartnews 我則是使用 &lt;a href="https://aws.amazon.com/tw/ecs/"&gt;Amazon Elastic Container Service&lt;/a&gt; 來快速部署一些資料科學家們常會用到的分析工具，如大家的好朋友 &lt;a href="https://jupyterhub.readthedocs.io/en/stable/"&gt;Jupyter Hub&lt;/a&gt;、Airbnb 開發的 BI 工具 &lt;a href="https://github.com/apache/incubator-superset"&gt;Superset&lt;/a&gt;。之後有機會會另外撰文分享經驗。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Try-It-Yourself"&gt;Try It Yourself&lt;a class="anchor-link" href="#Try-It-Yourself"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Docker 讓我們可以快速重現其他人的分析環境或者是有趣的 application。如果你想馬上感受 Docker 的威力，可以看看我之前利用 &lt;a href="https://www.tensorflow.org/"&gt;Tensorflow&lt;/a&gt; 以及 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 實作的一個貓咪圖片辨識的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Github repo&lt;/a&gt;（feat. &lt;a href="https://github.com/mnicnc404"&gt;CNC&lt;/a&gt;）：&lt;/p&gt;
&lt;center&gt;
&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app" target="_blank"&gt;
&lt;img src="images/digests/cat-recog-cover.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app" target="_blank"&gt;Cat Recognizer&lt;/a&gt;
       ：利用 Tensorflow, Flask 實作 App 並使用 Docker 快速與他人分享成果
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;雖然 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Github repo&lt;/a&gt; 上也有教學指南，想要最快速地在你的電腦上使用這個 App 的話，下載 &lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt; 並開啟 Daemon 後，使用命令列輸入以下指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker pull leemeng/cat
docker run -it -p &lt;span class="m"&gt;2468&lt;/span&gt;:5000 leemeng/cat
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;接著在瀏覽器輸入 &lt;code&gt;localhost:2468&lt;/code&gt; 應該就能開始使用了。如果你想多了解點 Docker，可以參考我寫的&lt;a href="https://leemeng.tw/3-ways-you-can-leverage-the-power-of-docker-in-data-science-part-1-learn-the-basic.html"&gt;給資料科學家的 Docker 指南：3 種活用 Docker 的方式（上）&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;不過現在讓我們繼續看剩下的 2 篇好文章：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="The-Democratization-of-Data-Science_1"&gt;&lt;a href="https://hbr.org/2018/07/the-democratization-of-data-science"&gt;The Democratization of Data Science&lt;/a&gt;&lt;a class="anchor-link" href="#The-Democratization-of-Data-Science"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://hbr.org/2018/07/the-democratization-of-data-science" target="_blank"&gt;
&lt;img src="images/digests/jul18-27-833771544-Patricia-Toth-McCormick-1200x675.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;&lt;a href="https://hbr.org/"&gt;哈佛商業評論（Harvard Business Review, HBR）&lt;/a&gt;在這篇文章裏頭敘述為何不只是針對資料科學家，提升所有人的「資料素養」對一個企業來說是一件非常重要的事情。&lt;/p&gt;
&lt;p&gt;最明顯的優點是可以讓數據團隊專注在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解決更高層次的企業問題&lt;/li&gt;
&lt;li&gt;建立分析工具以加速所有部門的數據分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而不是處理每個部門的「資料瑣事」。&lt;/p&gt;
&lt;p&gt;這個議題並非只跟企業的管理階層相關。對一個資料科學家來說，想辦法利用資料工程（Data Engineering）等方式來自動化如「建立簡單儀表板」的工作，並教導各個部門實際的使用方式，可以讓你一勞永逸，避免永遠在處理非常瑣碎的「資料瑣事」，專著在更大的目標。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;你不會因為自己不是會計師就不遵守專案預算；你也不會因為不是資料科學家就不提升資料素養。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data's-day-of-reckoning"&gt;&lt;a href="https://www.oreilly.com/ideas/datas-day-of-reckoning"&gt;Data's day of reckoning&lt;/a&gt;&lt;a class="anchor-link" href="#Data's-day-of-reckoning"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://www.oreilly.com/ideas/datas-day-of-reckoning" target="_blank"&gt;
&lt;img src="images/digests/shower-of-sparks-3115784_1280.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
生活在數據驅動時代的我們或許都能感受到世界變化的快速。&lt;/p&gt;
&lt;p&gt;美國前首席資料科學家 &lt;a href="https://www.oreilly.com/people/15b77-dj-patil"&gt;DJ Patil&lt;/a&gt; 認為不管是資料科學、機器學習還是人工智慧領域，「道德倫理」以及「安全隱私」議題都應該越來越被重視。&lt;/p&gt;
&lt;p&gt;電腦科學（Computer Science）時代最著名的安全議題非 SQL 注入&lt;a href="https://zh.wikipedia.org/zh-hant/SQL%E8%B3%87%E6%96%99%E9%9A%B1%E7%A2%BC%E6%94%BB%E6%93%8A"&gt;（SQL Injection）&lt;/a&gt;莫屬了。如同這個議題，在數據驅動時代，我們也會面臨類似道德以及數據保護的議題，像是人工智慧模型產生具有偏見的預測、以及最近的 &lt;a href="https://zh.wikipedia.org/wiki/%E6%AD%90%E7%9B%9F%E4%B8%80%E8%88%AC%E8%B3%87%E6%96%99%E4%BF%9D%E8%AD%B7%E8%A6%8F%E7%AF%84"&gt;GDPR&lt;/a&gt; 等等。&lt;/p&gt;
&lt;p&gt;在教育方面，DJ Patil 認為我們應該教育下一代在數據處理時，應該遵守的準則並將其被納入課綱；以數據驅動的公司則需要將這些想法都納入企業文化，在招聘資料科學家的時候，除了考慮他 / 她的分析能力以外，也要評估道德倫理的部分。&lt;/p&gt;
&lt;p&gt;身為一個資料科學家，除了技術層面的提升，也應該稍微了解這些議題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;We can build a future we want to live in, or we can build a nightmare. The choice is up to us.&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas、SQL、Docker、資料素養的培養以及數據時代的道德倫理問題等等，這週我們也看了不少資料科學相關的文章，希望你有從這篇文章裡頭學到點東西。&lt;/p&gt;
&lt;p&gt;雖然因為篇幅關係沒辦法把所有實際的 Python 指令列在這邊，我希望透過摘要的方式能讓沒時間的你也能學習、初步地了解資料科學並進一步發現自己有興趣的地方鑽研。&lt;/p&gt;
&lt;p&gt;有時間的話我推薦實際閱讀這些文章（當然也可以閱讀其他你自己收藏的文章，也歡迎分享），也可以試試看我寫的 &lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;Cat Recognizer&lt;/a&gt; 並留言跟我說說你的想法。&lt;/p&gt;
&lt;p&gt;之後一樣會定期更新，希望收到第一手消息的話可以點擊下面的訂閱。另外如果你有其他會對這篇文章有興趣的朋友，也請幫忙分享給他 / 她：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;That's it for this week, stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="Pandas"></category><category term="SQL"></category><category term="Docker"></category><category term="資料科學"></category></entry><entry><title>資料科學文摘 Vol.2 產品理解以及 DS / DE 之路</title><link href="https://leemeng.tw/data-science-digest-volume-2.html" rel="alternate"></link><published>2018-08-03T14:20:00+09:00</published><updated>2018-08-03T14:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-08-03:/data-science-digest-volume-2.html</id><summary type="html">&lt;p&gt;這週一樣會透過導讀一些優質文章，讓讀者了解 3 個問題：為何一個專業的資料科學家需要具備「產品理解」？ 何謂「顧客流失分析」？ 我們該如何使用 Python（XGBoost）來建立簡單的預測模型以改善產品？ 此外，我們也將簡單介紹在資料科學領域中逐漸崛起的「資料工程師」，其職責以及專業跟「資料科學家」有何不同。最後也會分享一些與資料科學家/資料工程師相關的文章。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週一樣會透過導讀一些優質文章，讓讀者了解 3 個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;為何一個專業的資料科學家需要具備「產品理解」？ &lt;/li&gt;
&lt;li&gt;何謂「顧客流失分析」？ &lt;/li&gt;
&lt;li&gt;我們該如何使用 Python（XGBoost）來建立簡單的預測模型以改善產品？ &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，我們也將簡單介紹在資料科學領域中逐漸崛起的「資料工程師」，其職責以及專精領域跟「資料科學家」有何不同。&lt;/p&gt;
&lt;p&gt;最後也會分享一些與資料科學家/資料工程師相關的文章。&lt;/p&gt;
&lt;p&gt;後文為了減少累贅，可能會穿插以下縮寫：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學家 = &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;S&lt;/strong&gt;cientist = DS&lt;/li&gt;
&lt;li&gt;資料工程師 = &lt;strong&gt;D&lt;/strong&gt;ata &lt;strong&gt;E&lt;/strong&gt;ngineer  = DE&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外有興趣了解此文摘緣由的讀者可以參考前篇：&lt;a href="https://leemengtaiwan.github.io/data-science-digest-volume-1.html"&gt;資料科學文摘 Vol.1 AutoML、Airflow 及 DAU&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週閱讀清單"&gt;本週閱讀清單&lt;a class="anchor-link" href="#本週閱讀清單"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;產品理解&lt;ul&gt;
&lt;li&gt;&lt;a href="#Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;Why Data Scientists Must Focus on Developing Product Sense&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Product-Scientist-@-Medium"&gt;Product Scientist @ Medium&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Python、客戶流失預測&lt;ul&gt;
&lt;li&gt;&lt;a href="#Introduction-to-Churn-Prediction-in-Python"&gt;Introduction to Churn Prediction in Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DS / DE 相關&lt;ul&gt;
&lt;li&gt;&lt;a href="#Data-engineering:-A-quick-and-simple-definition"&gt;Data engineering: A quick and simple definition&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#How-To-Become-A-Data-Scientist-in-12-Months"&gt;How To Become A Data Scientist in 12 Months&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;Infographic &amp;ndash; 13 Common Mistakes Amateur Data Scientists Make and How to Avoid Them&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;就跟以往一樣，儘管下文會依照此順序列出文章與摘要，你仍然點擊上面的任意門，從最有興趣的文章開始閱讀：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;&lt;a href="https://www.kdnuggets.com/2018/04/data-scientists-product-sense.html"&gt;Why Data Scientists Must Focus on Developing Product Sense&lt;/a&gt;&lt;a class="anchor-link" href="#Why-Data-Scientists-Must-Focus-on-Developing-Product-Sense"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.kdnuggets.com/2018/04/data-scientists-product-sense.html" target="_blacnk"&gt;
&lt;img src="images/digests/customers-checking-products.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;作者闡述為何產品理解（Product Sense）對一個 DS 很重要，適合新手 DS 閱讀參考。&lt;/p&gt;
&lt;p&gt;通常在企業裡頭，一個資料科學家要發揮最大的影響力，就是透過手上的資料，產生可執行的洞見（Actionable Insight），進而影響產品（Product）的發展方向。不管我們做了多少分析、多少層的神經網路模型，或是產生多少特徵值（Features），如果最後這些產物沒有對產品的發展有任何影響，一切都白搭。&lt;/p&gt;
&lt;p&gt;我們可以透過深刻地了解自家產品（比方說使用自家的 App）、暸解競爭對手、與使用者直接溝通等方式，來培養「產品理解」。有了產品理解以後，甚至可以反過來幫助我們做特徵工程（Feature Engineering），知道在建立預測模型時什麼特徵會是重要的；還能培養從資料看不出來的敏銳直覺（intuition）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;理解產品的 DS 能同時從資料看出的趨勢以及業界直覺來改善產品並解決人們問題。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt;，資料科學團隊也是在產品部門之下，與此有異曲同工之妙：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Product-Scientist-@-Medium"&gt;&lt;a href="https://medium.com/@sall/product-scientist-ffd1ae846172"&gt;Product Scientist @ Medium&lt;/a&gt;&lt;a class="anchor-link" href="#Product-Scientist-@-Medium"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://medium.com/@sall/product-scientist-ffd1ae846172" target="_blacnk"&gt;
&lt;img src="images/digests/1_EWD67PTS_fxBjWoZJ30oCA.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
Medium 的人說明他們在找的 Product Scientist 應該要有什麼特質：簡單來說就是有「產品理解」的 DS，能將資料轉換成更好的產品的人材。&lt;/p&gt;
&lt;p&gt;一個好的 DS 需要強大的溝通能力來向其他人說明洞見、了解 A/B 測試的統計顯著性（statistical significance）、以及能合理地解釋 KPI 成長的背後因素。以及最重要的：你渴望改善某個產品。&lt;/p&gt;
&lt;p&gt;最後一點大概是所有分析領域的人都不可或缺的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;你要先對某個產品抱持著熱情，才會想方設法地找出洞見並改善它。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;不管是什麼領域的 DS，都要想辦法了解自家的產品，以提供可執行的洞見。反過來說，你應該選擇進入真的有興趣的公司 / 產業。老生常談：擇你所愛，愛你所擇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Introduction-to-Churn-Prediction-in-Python"&gt;&lt;a href="https://www.datascience.com/blog/churn-prediction-python"&gt;Introduction to Churn Prediction in Python&lt;/a&gt;&lt;a class="anchor-link" href="#Introduction-to-Churn-Prediction-in-Python"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.datascience.com/blog/churn-prediction-python" target="_blacnk"&gt;
&lt;img src="images/digests/churn-prediction-intro-2-407577-edited.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇適合沒用過 XGBoost 也不熟悉 App 產業的讀者。&lt;/p&gt;
&lt;p&gt;此文主要解釋了何謂客戶流失（Customer Churn）、如何利用 Python 來建立一個簡單的 XGBoost 模型，以及如何對一個簡單的資料集做預測。&lt;/p&gt;
&lt;p&gt;就跟預測使用一個產品 / 服務的使用者人數相同，能準確預測有多少使用者會在什麼時候放棄使用某產品（Churn）這件事情，對了解一個產品（如手機 App）的發展趨勢是很重要的事情。如果我們把「預測使用者會不會放棄使用產品」這個問題視為一個二元分類問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 = 客戶流失，停止使用某產品&lt;/li&gt;
&lt;li&gt;0 = 客戶持續使用某產品&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;並使用如 XGBoost 等 tree-based 的模型的話，可以直接從模型中得到各個特徵的重要程度（Feature Importance），由此獲得改善產品功能的靈感 / 線索。這同時告訴我們一個重要的事情：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;除了準確度，選擇解釋性高的預測模型可以讓 DS 更容易解釋模型給決策者並影響企業決策。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然，如何定義何謂「客戶流失」就需要資料科學家掌握領域知識。另外值得注意的是，隨著產品功能的進化，客戶流失的定義也有可能跟著改變。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data-engineering:-A-quick-and-simple-definition"&gt;&lt;a href="https://www.oreilly.com/ideas/data-engineering-a-quick-and-simple-definition"&gt;Data engineering: A quick and simple definition&lt;/a&gt;&lt;a class="anchor-link" href="#Data-engineering:-A-quick-and-simple-definition"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.oreilly.com/ideas/data-engineering-a-quick-and-simple-definition" target="_blacnk"&gt;
&lt;img src="images/digests/data-metal-tubes-crop-22ff1fb1bba80c8258fc47980bd7694b.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;適合想成為資料工程師（DE）並對大數據處理有興趣的讀者。&lt;/p&gt;
&lt;p&gt;不同於我們之前以 DS 的角度討論&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;為何資料科學家需要了解資料工程&lt;/a&gt;，這篇直接以 DE 角度探討 DE 對企業的重要：處理大數據的能力。&lt;/p&gt;
&lt;p&gt;以各別負責的領域來區分的話，DS 通常負責從資料找出可執行的洞見，DE 則是負責資料管道的開發以及保證數據品質。 儘管一個 DS 也需要具備基本的 ETL 素養以及資料清理能力，這些分析專家能提供最大的價值是在找出洞見，而不是清理資料。&lt;/p&gt;
&lt;p&gt;因此稍具規模的公司都會尋找具備大數據處理能力（&lt;a href="https://zh.wikipedia.org/wiki/Apache_Spark"&gt;Spark&lt;/a&gt;、&lt;a href="https://flink.apache.org/"&gt;Flink&lt;/a&gt;、&lt;a href="https://kafka.apache.org/"&gt;Kafka&lt;/a&gt; 等）的 DE 來處理數據，以讓 DS 能更專注在商業分析。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資料科學領域越趨成熟的情況下， 我們需要更多 DE 與 DS 分工合作，以從海量數據中創造更大價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="How-To-Become-A-Data-Scientist-in-12-Months"&gt;&lt;a href="https://medium.com/@FreddieO/how-to-become-a-data-scientist-in-12-months-7e0deb51fac5"&gt;How To Become A Data Scientist in 12 Months&lt;/a&gt;&lt;a class="anchor-link" href="#How-To-Become-A-Data-Scientist-in-12-Months"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://medium.com/@FreddieO/how-to-become-a-data-scientist-in-12-months-7e0deb51fac5" target="_blacnk"&gt;
&lt;img src="images/digests/1_Tcx7pHt5Jctu7tMrdztrcQ.jpeg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;&lt;p&gt;這篇適合想開始學習資料科學的讀者作為參考。&lt;/p&gt;
&lt;p&gt;一個誤打誤撞，闖入資料科學世界的工程師述說他是如何從自學程式語言到成為一個資料科學家。列了一些他個人給新人的建議、不少線上課程以及值得追蹤的資料科學家們。&lt;/p&gt;
&lt;p&gt;雖然每個人際遇不同，看完這篇可以確定的是，想要成為一個資料科學家絕對不是學完幾堂線上課程就可以了。關鍵在於持續學習新知。（這道理當然可以套用到各行各業上）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;&lt;a href="https://www.analyticsvidhya.com/blog/2018/07/infographic-common-mistakes-amateur-data-scientists-make-how-avoid-them/"&gt;Infographic &amp;ndash; 13 Common Mistakes Amateur Data Scientists Make and How to Avoid Them&lt;/a&gt;&lt;a class="anchor-link" href="#Infographic-&amp;ndash;-13-Common-Mistakes-Amateur-Data-Scientists-Make-and-How-to-Avoid-Them"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://www.analyticsvidhya.com/blog/2018/07/infographic-common-mistakes-amateur-data-scientists-make-how-avoid-them/" target="_blacnk"&gt;
&lt;img src="images/digests/13-common-mistake.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;一個簡單的資料圖表說明新手 DS 常犯的 13 個錯誤。&lt;/p&gt;
&lt;p&gt;每個項目值得一一查看，不過裡頭有幾點我認為值得特別強調：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學在於應用。總是要想著該怎麼實際應用學到的知識，而不是死記硬背。&lt;/li&gt;
&lt;li&gt;專注在能「解決什麼問題」，而不是該學什麼「工具」。&lt;/li&gt;
&lt;li&gt;業界想要解決的問題不是你在線上課程學到的那麼單純。要解決一個真正的企業問題，你還需要培養資料工程、領域知識（Domain Knowledge）以及良好的溝通能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週我們學到在分析任何數據之前，為何理解產品對一個資料科學家來說非常重要；我們也看到一個簡單利用 Python 嘗試預測顧客流失的案例；最後我們看到資料工程師的崛起以及閱讀了 2 篇跟資料科學相關的文章。&lt;/p&gt;
&lt;p&gt;程式能力以及分析能力固然重要，但對產品的理解、良好的溝通能力都是成為一個專業的 DS 不可不缺的能力。&lt;/p&gt;
&lt;p&gt;閱讀完之後如果有任何想法，或者有其他想推薦給其他讀者們閱讀的文章，都歡迎在底下留言跟其他讀者們分享。&lt;/p&gt;
&lt;p&gt;目前預計每週會發佈新文摘，不過當有別的系列文章要寫的話可能會順延一週。如果希望在新文摘出爐的時候馬上收到通知的話，可以點擊下面的訂閱：）&lt;/p&gt;
&lt;p&gt;Stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category><category term="資料工程"></category><category term="Python"></category></entry><entry><title>資料科學文摘 Vol.1 AutoML、Airflow 及 DAU</title><link href="https://leemeng.tw/data-science-digest-volume-1.html" rel="alternate"></link><published>2018-07-29T18:00:00+09:00</published><updated>2018-07-29T18:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-07-29:/data-science-digest-volume-1.html</id><summary type="html">&lt;p&gt;這週介紹幾篇機器學習、資料工程及 App 分析的優質文章以及重點摘要，關鍵字包含：AutoML、Airflow 以及 DAU / MAU。希望讓更多人能更快地掌握資料科學領域的知識，找出自己有興趣的領域專研，並激盪出更多的討論。透過閱讀大量的相關文章並從它們學習及模仿，我們可以更快地，且有效率地成為一個稱職的資料科學家。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;作為「資料科學文摘」系列文的第一篇，在開始介紹一些優質的文章之前，請讓我稍微說明一下為何會有這系列文章的誕生。先說結論：我希望透過分享一些優質文章的重點摘要，讓更多人能更快地掌握資料科學領域的知識，找出自己有興趣的領域專研，並激盪出更多的討論。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在開始閱讀之前"&gt;在開始閱讀之前&lt;a class="anchor-link" href="#在開始閱讀之前"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;或許所有職業皆如此，但個人認為資料科學家是前幾不「佛系」的一個職業，你需要擁有非常多知識來讓工作更為順利：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特定程式語言如 Python、SQL 及 R 的使用方法&lt;/li&gt;
&lt;li&gt;統計分析方法&lt;/li&gt;
&lt;li&gt;建構資料管道（Data Pipeline）&lt;/li&gt;
&lt;li&gt;訓練並部署機器學習模型&lt;/li&gt;
&lt;li&gt;業界趨勢&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/digests/budda-data-scientist.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當然，你也可以選擇當個佛系資料科學家（如果你知道有哪間企業在應徵，站內信 500 P）。&lt;/p&gt;
&lt;p&gt;不過身為一個（非佛系）資料科學家，我常需要閱讀大量的相關文章、新知，並且嘗試模仿文章內出現的演算法、分析手法，加以實踐並應用在自己的工作上。&lt;/p&gt;
&lt;p&gt;愛爾蘭詩人&lt;a href="https://zh.wikipedia.org/wiki/%E5%A5%A5%E6%96%AF%E5%8D%A1%C2%B7%E7%8E%8B%E5%B0%94%E5%BE%B7"&gt;奧斯卡．王爾德&lt;/a&gt; 曾說過一句&lt;a href="https://en.wikiquote.org/wiki/Talk:Oscar_Wilde"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;You are what you read. - Oscar Wilde&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以資料科學為例，你讀越多相關文章，你就越接近一個資料科學家。不管要精通什麼能力，最快的方式都是透過「模仿」專家怎麼做的。透過閱讀大量的相關文章並從它們學習及模仿，我們可以更快地，且有效率地成為一個稱職的資料科學家。&lt;/p&gt;
&lt;p&gt;以往我在閱讀完不錯的文章以後，都會在 &lt;a href="https://evernote.com/intl/zh-tw/"&gt;Evernote&lt;/a&gt; 裡頭寫重點摘要以供自己之後做參考、連結不同領域的知識。在回顧的時候節省了自己大量的時間。有鑑於現在越來越多人對資料科學有興趣，透過分享自己的文摘，希望能讓沒有什麼時間的人也能快速地了解新知，並進一步閱讀自己有興趣的文章。&lt;/p&gt;
&lt;p&gt;前言說得夠多了，讓我們來看看這週的文摘吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="本週分享：機器學習、資料工程及-App-分析"&gt;本週分享：機器學習、資料工程及 App 分析&lt;a class="anchor-link" href="#本週分享：機器學習、資料工程及-App-分析"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這週想分享 5 篇文章的文摘，大致上可分為三個主題。這週因為想一次分享 Rachel Thomas 在 &lt;a href="http://www.fast.ai/"&gt;fast.ai&lt;/a&gt; 談 AutoML 的三篇系列文章，機器學習的文章比例會佔得比較重。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;機器學習&lt;ul&gt;
&lt;li&gt;&lt;a href="#What-do-machine-learning-practitioners-actually-do"&gt;What do machine learning practitioners actually do&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;An Opinionated Introduction to AutoML and Neural Architecture Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Google's-AutoML:-Cutting-Through-the-Hype"&gt;Google's AutoML: Cutting Through the Hype&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;資料工程&lt;ul&gt;
&lt;li&gt;&lt;a href="#Airflow:-a-workflow-management-platform"&gt;Airflow: a workflow management platform&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;App 業界分析&lt;ul&gt;
&lt;li&gt;&lt;a href="#DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;DAU/MAU is an important metric to measure engagement, but here&amp;rsquo;s where it fails&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除了 AutoML 的系列文以外，閱讀順序不限：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="What-do-machine-learning-practitioners-actually-do"&gt;&lt;a href="http://www.fast.ai/2018/07/12/auto-ml-1/"&gt;What do machine learning practitioners actually do&lt;/a&gt;&lt;a class="anchor-link" href="#What-do-machine-learning-practitioners-actually-do"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/12/auto-ml-1/" target="_blacnk"&gt;
&lt;img src="images/digests/automl_1.jpg" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這篇介紹機器學習工程師平常在做些什麼，在理解這點以後，我們才知道中間有什麼地方可以自動化，以讓機器學習專案更有效率。&lt;/p&gt;
&lt;p&gt;一個完整的機器學習專案通常會包含這些步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解企業脈絡&lt;/li&gt;
&lt;li&gt;清理＆準備資料&lt;/li&gt;
&lt;li&gt;訓練模型&lt;/li&gt;
&lt;li&gt;實際部署&lt;/li&gt;
&lt;li&gt;事後監控模型表現&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;針對每個步驟，文內都有進一步的項目細分以及解釋，推薦閱讀。儘管一個機器學習工程師不需要自己做所有步驟，了解它們會讓專案更為順利。&lt;/p&gt;
&lt;p&gt;就算是專業的研究者，訓練一個深度學習的模型也不是一件非常簡單的事情。而這是 AutoML 以及其子領域，神經結構搜索（neural architecture search）嘗試要解決的。 Google 甚至號稱「只要我們有現在的一百倍計算能力，就可以取代所有機器學習人才」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;&lt;a href="http://www.fast.ai/2018/07/16/auto-ml2/"&gt;An Opinionated Introduction to AutoML and Neural Architecture Search&lt;/a&gt;&lt;a class="anchor-link" href="#An-Opinionated-Introduction-to-AutoML-and-Neural-Architecture-Search"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/16/auto-ml2/" target="_blacnk"&gt;
&lt;img src="images/digests/automl-headlines.png" style=""/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;/center&gt;
神經結構搜索或者 AutoML 領域可以幫助我們在「訓練模型」這個步驟的時候，訓練並選擇出最好的超參數（Hyperparameters）。&lt;/p&gt;
&lt;p&gt;但如同上篇文所述，這通常只是機器學習專案的其中一小部分，資料科學家或機器學習相關人才並不會因此被全部取代且失業。&lt;/p&gt;
&lt;p&gt;現在 AutoML 是非常計算密集（Computation-intensive）的：拿大量的 GPU 計算能力換取研究員的時間。但沒有大量計算能力的人，等 Google 等大公司把最佳化的架構推出來再使用或許是一個比較實際的方案。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.groundai.com/project/darts-differentiable-architecture-search/"&gt;DARTS&lt;/a&gt; 也是 CMU 與 DeepMind 在嘗試解決「神經結構搜索」這個問題時提出的一個架構，不過他們的假設是所有可行的模型之間是「連續的」，因此可以用常見的「梯度學習」的方式找出最佳模型。這個概念使得他們所需要的計算資源大量減少，值得關注。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Google's-AutoML:-Cutting-Through-the-Hype"&gt;&lt;a href="http://www.fast.ai/2018/07/23/auto-ml-3/"&gt;Google's AutoML: Cutting Through the Hype&lt;/a&gt;&lt;a class="anchor-link" href="#Google's-AutoML:-Cutting-Through-the-Hype"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="http://www.fast.ai/2018/07/23/auto-ml-3/" target="_blacnk"&gt;
&lt;img src="images/digests/sundar_pichai2.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
作者認為 Google 在推廣 AutoML 的主張：「我們需要更多計算能力來做神經架構搜尋」值得懷疑，因為就算我們能自動化搜尋出最好的神經模型架構，如何用這些模型解決真正的企業問題、如何實際部署並持續改善機器學習應用等課題，都需要人動腦筋來解決，而這部分還無法自動化。&lt;/p&gt;
&lt;p&gt;另外畢竟不是所有做機器學習的人都需要、且有（計算）能力使用神經架構搜尋來訓練自己的模型。但我們可以透過轉換學習（Transfer Learning）來使用已訓練過的模型（pre-trained model）來解決類似問題。與其想著自己也要做最夯的神經架構搜尋，不如多多善用如 Dropout、Batch Normalization 以及 ReLU Linear Unit 來強化模型的預測能力。&lt;/p&gt;
&lt;p&gt;不過 &lt;a href="https://colab.research.google.com/notebooks/welcome.ipynb"&gt;Google Colab Notebook&lt;/a&gt; 是不錯的免費計算資源，可以善加利用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Airflow:-a-workflow-management-platform"&gt;&lt;a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8"&gt;Airflow: a workflow management platform&lt;/a&gt;&lt;a class="anchor-link" href="#Airflow:-a-workflow-management-platform"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;center&gt;
&lt;a href="https://medium.com/airbnb-engineering/airflow-a-workflow-management-platform-46318b977fd8" target="_blacnk"&gt;
&lt;img src="images/digests/airflow-example-python-operator.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;
資料科學家在進行各式各樣的分析前，首先需要做的事情通常是蒐集、整理並匯總各式各樣的資料來源以供分析。舉幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建立數據倉儲（Data Warehousing）&lt;/li&gt;
&lt;li&gt;做 A/B 測試的效果分析&lt;/li&gt;
&lt;li&gt;Sessionization：了解使用者在一個 session 裡頭的探訪的網頁、點擊的廣告等活動&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了做這些分析，資料團隊需要建立可靠的資料管道及 ETL，來確保有資料可供分析以及保證資料的品質。&lt;/p&gt;
&lt;p&gt;Airflow 是一個由 Airbnb 開發，以 Python 實作的工作流管理系統（Workflow Management System, WMS）。 Airflow 被設計來幫助資料科學家們專注在建構資料管道的邏輯，而不是擔心如果資料管道中間出了什麼差錯時該怎麼維護、重新啟動工作流。（Airflow 有會自己重試失敗工作、當失敗時通知工程師等方便功能）。&lt;/p&gt;
&lt;p&gt;Airflow 現在已經進入 &lt;a href="https://incubator.apache.org/"&gt;Apache 孵化器&lt;/a&gt;，前景可期。其作者 &lt;a href="https://medium.com/@maximebeauchemin"&gt;Maxime Beauchemin&lt;/a&gt; 在這篇用淺顯易懂的方式解說 Airflow，值得一看。手癢的朋友可以參考 &lt;a href="http://pythonhosted.org/airflow/start.html"&gt;Quickstart&lt;/a&gt; 以及 &lt;a href="http://pythonhosted.org/airflow/tutorial.html"&gt;Tutorial&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;SmartNews 也有在使用 Airflow，我也寫了一篇給新手看的 Airflow 的指南：「&lt;a href="https://leemengtaiwan.github.io/a-story-about-airflow-and-data-engineering-using-how-to-use-python-to-catch-up-with-latest-comics-as-an-example.html"&gt;一段 Airflow 與資料工程的故事：談如何用 Python 追漫畫連載&lt;/a&gt;」，你可以參考看看：）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;&lt;a href="https://andrewchen.co/dau-mau-is-an-important-metric-but-heres-where-it-fails/"&gt;DAU/MAU is an important metric to measure engagement, but here&amp;rsquo;s where it fails&lt;/a&gt;&lt;a class="anchor-link" href="#DAU/MAU-is-an-important-metric-to-measure-engagement,-but-here&amp;rsquo;s-where-it-fails"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;center&gt;
&lt;a href="https://andrewchen.co/dau-mau-is-an-important-metric-but-heres-where-it-fails/" target="_blacnk"&gt;
&lt;img src="images/digests/daumau-header.jpg" style=""/&gt;
&lt;br/&gt;
&lt;/a&gt;
&lt;/center&gt;&lt;p&gt;多年前由 Facebook 開始使用，DAU / MAU 是一個 App 產業常用的指標，用來衡量使用者利用自家 App 的程度。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DAU：每天活躍人數（Daily Active Users）&lt;/li&gt;
&lt;li&gt;MAU：每月活躍人數（Monthly Active Users）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DAU / MAU 則是這兩者的比例。可以想像當此比例越高，代表在每月活躍的使用者人數（MAU）中，每天活躍的人數（DAU）越高，可以說明使用者的黏著度越高。&lt;/p&gt;
&lt;p&gt;但這篇重點在於說明不同服務、產品因為本身性質的不同，並不都適合用這個指標。像是 Airbnb 這種公司，有些使用者每年可能只使用一次（活躍次數一年才一次），但一次的消費金額很驚人。以 DAU 的角度來看這種顧客的話價值不高，但使用者的生涯價值（Life Time Value）卻很高。&lt;/p&gt;
&lt;p&gt;雖然業界很常使用，不盲目使用 DAU / MAU 這個指標，而是依照自己的產品種類，選擇最能代表使用者價值的指標，並將其最大化才是上策。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;呼！以上就是這週的文摘內容了！儘管我們在這篇文摘裡頭只包含了 5 篇文章， 3 篇還是系列文，你應該也能感受到不同領域的知識在腦海中互相激盪吧！&lt;/p&gt;
&lt;p&gt;在整理這幾篇文章的重點時我學到不少，希望你也一樣。之後會定期更新，可以隨時回來看看有沒有新文章。如果懶得每天打卡，但希望在新文摘出來的時候馬上收到通知的話，可以點擊下面的訂閱。如果你在閱讀完後有其他感想，也歡迎跟我分享：）&lt;/p&gt;
&lt;p&gt;Stay tuned and happy data science!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="文摘"></category><category term="資料科學"></category><category term="資料工程"></category><category term="機器學習"></category></entry><entry><title>資料科學家 L 的奇幻旅程 Vol.1 新人不得不問的 2 個問題</title><link href="https://leemeng.tw/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html" rel="alternate"></link><published>2018-07-07T20:30:00+09:00</published><updated>2018-07-07T20:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-07-07:/journey-of-data-scientist-L-part-1-two-must-ask-questions-when-on-board.html</id><summary type="html">&lt;p&gt;為了讓有志成為資料科學家，或是單純想要了解的讀者們能理解資料科學是如何實際被企業應用，以及讓自己多一點反思的機會，趁著最近開始在 SmartNews 的新工作，我打算開始紀錄自己平常的工作內容以及一些經驗分享。作為系列文的第一篇文章，我們將探討一個資料科學家在進入新公司熟悉環境的時候，除了問該裝什麼工具以外，可以問的兩個重要問題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為一個資料科學家，我平常會寫些相關領域的文章，像是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/demystify-the-hype-of-data-science-and-its-value.html"&gt;揭開資料科學的神秘面紗&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-sql-as-a-data-scientist.html"&gt;為何資料科學家需要學習 SQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://leemengtaiwan.github.io/data-visualization-from-matplotlib-to-ggplot2.html"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它們都獲得不錯的迴響，我也得到不少很棒的回饋。&lt;/p&gt;
&lt;p&gt;不過如果只是介紹特定跟資料科學（Data Science，以下簡稱 DS）相關的工具或概念的話，我們可能會陷入「見樹不見林」的窘境：知道很多 DS 的知識，但卻不曉得這些知識是如何實際被運用在解決人們或是企業的問題。實際上我相信大多數企業的資料科學家在做的事情，並不像很多線上課程那麼單純；有時候你需要結合多種領域的知識，如資料工程、分析手法以及領域知識（Domain Knowledge）來解決一個商業問題。&lt;/p&gt;
&lt;p&gt;為了讓有志成為資料科學家，或是單純想要了解的讀者們能理解 DS 是如何實際被（企業）應用，以及讓自己多一點反思的機會，趁著最近開始在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 的新工作，我打算開始（不定期地）紀錄自己平常的工作內容以及一些經驗分享（當然，在不洩漏隱私資訊的前提下）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/green-chameleon-21532-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我相信透過寫作，能讓更多人了解資料科學並幫助自己釐清重要概念
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這系列文章將以類似說故事（奇幻旅程，喔耶！）的手法，闡述我在 &lt;a href="https://www.smartnews.com/en/"&gt;SmartNews&lt;/a&gt; 遇到的一些挑戰，以及作為一名資料科學家（Data Scientist），我如何利用手邊各式各樣的工具以及手法來解決這些問題。透過問題導向（Problem-oriented）的方式，我希望能讓更多人理解 DS 是如何實際被應用在企業之中，進而思考自己該如何預先準備，減少進入這個領域的障礙。（歡迎分享你的想法！）&lt;/p&gt;
&lt;p&gt;在後面幾篇文章，我們將有機會深入探討一些分析手法、如何建置預測模型，以及建置可靠的資料流（Dataflow）。但在那之前可別忘了：「巧婦難為無米之炊」。我們才剛剛開始資料科學家的工作，就連筆電裡頭也是什麼軟體都還沒被安裝呢！&lt;/p&gt;
&lt;p&gt;因此在大展身手之前，在這篇文章我們將討論作為一個資料科學家，如何在開始第一個分析專案的同時，「有效率」地熟悉新環境。後面你將會發現，這個初始步驟看似瑣碎，卻能讓之後的工作進行地更為順利。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="熟悉環境-=-安裝軟體？"&gt;熟悉環境 = 安裝軟體？&lt;a class="anchor-link" href="#熟悉環境-=-安裝軟體？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們想像一下剛從 IT 管理部門手上拿到新筆電的情境。&lt;/p&gt;
&lt;p&gt;通常拿到公司配的新電腦以後，一個資料科學家會思考的幾個問題是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「我要在新電腦上面裝什麼軟體？」&lt;/li&gt;
&lt;li&gt;「公司的資料科學家們用什麼軟體？」&lt;/li&gt;
&lt;li&gt;「我要怎麼存取公司的資料？」&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/markus-spiske-37176-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    面對一片空白的環境，我們的腦袋可不能也是一片空白
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這些問體的確很重要也很實際（practical），也是我當初能馬上想到的問題。但後面我們會看到，該安裝什麼軟體、該怎麼存取資料庫都是「熟悉環境」裏頭最簡單的部分。為什麼？&lt;/p&gt;
&lt;p&gt;因為通常 manager 會準備好一個清單告訴你該裝什麼，只要照著做就好了。這個清單當然會依照公司內部使用的技術而有所差異，但在大 Google 搜尋時代之下，要在自己的筆電安裝任何東西（應該）都不是太困難的事情。&lt;/p&gt;
&lt;p&gt;就算公司沒有給你清單，沒問題！事實上，我也不過就安裝了以下軟體：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.python.org/"&gt;Python&lt;/a&gt; &amp;amp; &lt;a href="https://www.anaconda.com/download/#macos"&gt;Anaconda&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.r-project.org/"&gt;R 語言&lt;/a&gt; &amp;amp; &lt;a href="https://www.rstudio.com/"&gt;RStudio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jupyter.org/"&gt;Jupyter Notebook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.docker.com/"&gt;Docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.iterm2.com/"&gt;iTerm2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.jetbrains.com/pycharm/"&gt;PyCharm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sourcetreeapp.com/"&gt;SourceTree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;當然隨著專案的增加，你可能還會需要其他工具，但基本上沒有想像中的那麼多。有了開發/分析工具以後， IT 管理部門也會跟你說明該如何透過加密的方式，存取一些重要的資料庫以及伺服器。等到這些都搞定以後，理論上我們已經可以準備寫落落長的 SQL 查詢來結合多個資料庫的表格，並使用各種酷炫的 Python packages 進行分析了！&lt;/p&gt;
&lt;p&gt;不過在進行分析的同時，有一些問題值得我們花幾天慢慢地思考。這篇我想特別強調 2 個：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司內有什麼&lt;a href="https://zh.wikipedia.org/wiki/%E9%97%9C%E9%8D%B5%E7%B8%BE%E6%95%88%E6%8C%87%E6%A8%99"&gt;關鍵績效指標（KPI）&lt;/a&gt;？&lt;/li&gt;
&lt;li&gt;這些 KPI 是怎麼被產生並顯示在儀表板（Dashboard）上的？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可能覺得這些事情看起來並不直接跟資料分析相關，但接下來你會看到，為何在進入公司早期就理解它們，對一個資料科學家來說很重要。首先讓我們看看第一個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="公司內有什麼關鍵績效指標？"&gt;公司內有什麼關鍵績效指標？&lt;a class="anchor-link" href="#公司內有什麼關鍵績效指標？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為什麼了解公司內有什麼關鍵績效指標（Key Performance Indicator, 後簡稱 KPI）很重要？&lt;/p&gt;
&lt;p&gt;因為這些 KPI 代表著一企業或團隊衡量成功的方式，同時也決定了資料科學家們將要努力的方向。沒有這些 KPI，我們將不能評估我們是不是走在對的路上，也不知道前進的速度。講得浮誇點，一個資料科學家能提供的最大價值就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;分析數據、從中找出洞見讓企業做出更好的決策，以在最短的時間內最大化 KPI&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以這樣的角度來看，KPI 的概念就跟機器學習中的&lt;a href="http://terms.naer.edu.tw/detail/1316865/"&gt;目標函數（Objective Function）&lt;/a&gt;的概念相同，差別只在於我們是用電腦去最佳化目標函數；用人腦去最佳化企業的 KPI。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/journal/carlos-muza-84523-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    資料科學家的工作說穿了，就是如何利用資料以及 DS 的力量，來最大化儀表板上的 KPI
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;因為 SmartNews 是一個新聞 APP，讓我們舉些&lt;a href="https://www.adweek.com/digital/top-12-key-performance-indicators-for-maximizing-mobile-app-revenue/"&gt;手機 APP 產業中常被使用的 KPI&lt;/a&gt; 為例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安裝次數（#Installs）&lt;/li&gt;
&lt;li&gt;每人平均使用時間（Session Time）&lt;/li&gt;
&lt;li&gt;瀏覽頁面數（#Page Views）&lt;/li&gt;
&lt;li&gt;每天活躍人數（#Daily Active Users）&lt;/li&gt;
&lt;li&gt;每月活躍人數（#Monthly Active Users）&lt;/li&gt;
&lt;li&gt;重度使用者人數（#Heavy Users）&lt;/li&gt;
&lt;li&gt;每日廣告營收（Ad Revenue Per Day）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;儘管相同產業可能用類似的 KPI，每家公司給的實際定義（Definition）可能有所出入。不同公司之間的定義有差異是正常的，但該定義合不合理就是另外一回事了。&lt;/p&gt;
&lt;p&gt;就跟我們訓練一個機器學習模型的時候會注意目標函數的定義是否合理一樣，在了解有什麼 KPI 以後，我們也應該積極地去詢問相關人員，了解這些 KPI 的定義是否合理。像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;怎樣的行為可以算是完成安裝？是使用者第一次打開 APP 的瞬間算安裝，還是完成新手教學的時候呢？&lt;/li&gt;
&lt;li&gt;何謂活躍？使用者要做什麼操作才算活躍？打開 APP，更改設定就關掉也算活躍嗎？&lt;/li&gt;
&lt;li&gt;何謂重度使用者？過去一個月使用超過 7 天的人算嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/william-stitt-224297-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    把握 onboarding 的機會，詢問所有你能質疑的問題
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果 KPI 的定義不合理，糟一點的結果就是你的努力方向對了， KPI 卻沒有上升；更糟的結果則是你往錯的方向最佳化：錯誤的 KPI 提升了，你則沾沾自喜。儘管定義合適的 KPI 需要大量的領域知識，在剛開工的時候，你仍應該對現有的 KPI 做出適當的質疑，嘗試理解它們的合理性。&lt;/p&gt;
&lt;p&gt;現在假設 KPI 的定義沒有明顯問題，不管什麼公司都會希望能將這些 KPI 即時地顯示在儀表板上以方便監控自己的營運狀況。但如果一個 APP 的&lt;a href="http://about.smartnews.com/ja/2017/10/10/25million/"&gt;下載次數超過 2500 萬&lt;/a&gt;，每天產生上億筆使用者存取紀錄的話，幾個衍生出來的問題就是：KPI 該怎麼從這些原始資料產生出來的？如何保證中間沒有出錯？我們能信賴這些計算出來的值嗎？&lt;/p&gt;
&lt;p&gt;讓我們在下小節討論這個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="儀表板上的-KPI-是怎麼產生的？"&gt;儀表板上的 KPI 是怎麼產生的？&lt;a class="anchor-link" href="#儀表板上的-KPI-是怎麼產生的？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實作方式會依照公司有所不同，但讓我們以 SmartNews 為例。&lt;/p&gt;
&lt;p&gt;我們的儀表板是使用 &lt;a href="https://chartio.com/"&gt;CHARTIO&lt;/a&gt;，但基本上 CHARTIO 這種儀表板服務也只是一個 Web UI，它並不會自動幫我們把使用者的存取紀錄轉成 KPI。為了理解每天人們使用 APP 的情況，我們必須自己將所有網路伺服器（Web Servers）上的使用者存取紀錄（Log Data）做一系列的處理以後，轉變成儀表板上的 KPI。&lt;/p&gt;
&lt;p&gt;而一個使用者的使用行為大致上會經過以下幾個步驟轉變成 KPI：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用者打開 SmartNews App，手機客戶端向網路伺服器做出請求（Request）&lt;/li&gt;
&lt;li&gt;網路伺服器回傳結果，並將該請求紀錄存在自己的硬碟上&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fluentd.org/"&gt;fluentd&lt;/a&gt; 搜集所有伺服器上的請求資料，將它們存到 &lt;a href="https://aws.amazon.com/tw/s3/"&gt;Amazon S3&lt;/a&gt; 上&lt;/li&gt;
&lt;li&gt;工作流管理系統 &lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt; 進行 Batch 處理，定期將被存到 S3 上的使用者存取紀錄轉成 &lt;a href="https://en.wikipedia.org/wiki/Apache_Hive"&gt;Apache Hive&lt;/a&gt; SQL 表格（Tables）&lt;/li&gt;
&lt;li&gt;CHARTIO 透過分散式 SQL 查詢引擎 &lt;a href="https://prestodb.io/"&gt;Presto&lt;/a&gt; 對該表格作查詢，顯示 KPI&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從左到右來表示這個流程的話會如下圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/smartnews-dmp.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.slideshare.net/smartnews/20160127-building-a-sustainable-data-platform-on-aws" target="_blank"&gt;SmartNews 的資料平台&lt;/a&gt;：將大量原始日誌資料轉成儀表板上有用的 KPI（當然不只用在顯示 KPI）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;乍看之下，你可能會想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「這看起來跟資料科學完全沒相關啊！」&lt;/li&gt;
&lt;li&gt;「我只要能存取關聯式資料庫（Relational Database）裡頭的表格不就好了？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;沒錯，嚴格來說這是一個資料工程（Data Engineering）的問題。但正如我們在&lt;a href="https://leemengtaiwan.github.io/why-you-need-to-learn-data-engineering-as-a-data-scientist.html"&gt;資料科學家為何需要了解資料工程&lt;/a&gt;一文裡頭提到的，身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;
&lt;p&gt;事實上，了解儀表板上的 KPI 是怎麼產生的，有以下幾個優點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解工程師的痛點。能事先以他們的角度思考建立新表格所需的成本的話，他們會更願意幫你建立&lt;/li&gt;
&lt;li&gt;通常新的分析會需要新的 ETL，而你可以利用跟產生 KPI 一樣的 ETL 來產生自己的資料管道（Data Pipeline）&lt;/li&gt;
&lt;li&gt;確保資料品質。一旦使用的資料有瑕痴，做出來的分析也不會有意義。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/journal/studio-314-270213-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個資料科學家會去了解企業內的資料是怎麼流動的，確保資料的品質並建立自己需要的資料流
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最後一點尤其重要。在 SmartNews 的例子裡頭，資料科學家實際上想要分析的是「APP 使用者的存取行為」，而跟使用者行為最直接相關的其實是那些被存在網路伺服器上的 log。只是因為該資料量太大，我們必須建立資料管道做前處理，從大量原始資料中萃取、匯總出我們「可能」有興趣的資料存入關聯式資料庫供之後分析。&lt;/p&gt;
&lt;p&gt;以這種角度來看的話，資料彷彿是從網路伺服器（上游）經過一連串的河道（資料管道）流向資料庫（下游）。這也就暗示著兩個可能的風險：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料在經過河道的時候被污染，資料品質下降&lt;/li&gt;
&lt;li&gt;資料在經過河道的時候被限縮，有些有價值的資料沒辦法抵達下游&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個資料科學家如果只專注在下游的資料，就可能冒著以上的風險而不自知。這就是為什麼我們需要了解企業內的資料是如何流動的。&lt;/p&gt;
&lt;p&gt;資料的流動當然不限於 KPI 的產生，但我認為用這個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「儀表板上的 KPI 是怎麼產生的？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;來理解一個企業的資料流是一個很好的起始點。畢竟 KPI 是公司最重視的資訊，用來建構其的資料管道也會是最完善且重要的。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在這篇文章裏頭，我們討論了一個資料科學家在進入新公司熟悉環境的時候，除了問該裝什麼工具以外，可以問的兩個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司內有什麼 KPI？&lt;/li&gt;
&lt;li&gt;儀表板上的 KPI 是怎麼產生的？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表面上看來是兩個再簡單不過的問題，實際上第一個問題跟業界的專業知識（Domain Knowledge）息息相關；第二個問題則牽涉到大量的資料工程專業。而透過深刻地思考這兩個問題並詢問相關人員，一個資料科學家可以更全面的理解企業並掌握大局觀，做出最有影響力的分析。&lt;/p&gt;
&lt;p&gt;當然，除了這兩個問題以外，你還需要問很多其他重要的問題如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;公司的資料文化如何？&lt;/li&gt;
&lt;li&gt;我在 Data Science 團隊裡頭的定位為何？&lt;/li&gt;
&lt;li&gt;many more ..&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但作為「資料科學家 L 的奇幻旅程」系列文的第一篇文章，為了避免累贅，我把這些問題留給你們（可以留言跟我說你覺得還有什麼問題重要！）&lt;/p&gt;
&lt;p&gt;最後的 Bonus 問題：為何是資料科學家「L」？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="日誌"></category></entry><entry><title>從彼此學習 - 淺談機器學習以及人類學習</title><link href="https://leemeng.tw/some-thought-on-learning-from-machine-learning.html" rel="alternate"></link><published>2018-06-16T17:20:00+09:00</published><updated>2018-06-16T17:20:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-06-16:/some-thought-on-learning-from-machine-learning.html</id><summary type="html">&lt;p&gt;說到近年最熱門的機器學習或者人工智慧，因為知識背景以及觀點的不同，幾乎每個人都有不一樣的見解。雖然我們有千百種定義、無數的專業術語，這篇文章希望用直觀的方式以及具體的例子，讓讀者能夠在跳入一大堆 ML 的教學文章以及線上課程之前，能以一個更高層次且人性化的角度理解機器學習，並進而思考要如何開啟自己的機器學習旅程。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;說到近年最熱門的機器學習（Machine Learning）或者人工智慧（Artificial Intelligence），因為知識背景以及觀點的不同，幾乎每個人都有不一樣的見解。雖然我們有千百種定義、無數的專業術語，這篇文章希望用直觀的方式以及具體的例子，讓讀者能夠在跳入一大堆 ML 的教學文章以及線上課程之前，能以一個更高層次且人性化的角度理解機器學習，並進而思考要如何開啟自己的機器學習旅程。&lt;/p&gt;
&lt;p&gt;不僅如此，你將發現機器學習並不是冷冰冰的科學，隨處可見人類的巧思；就算不是資料科學家，你也能從『機器學習』獲得啟發，將一些概念用在改善『自己的學習』。&lt;/p&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#何謂機器學習"&gt;何謂機器學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#機器學習實例：智慧咖啡機"&gt;機器學習實例：智慧咖啡機&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何讓機器學得更好"&gt;如何讓機器學得更好&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何改善我們的學習"&gt;如何改善我們的學習&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂機器學習"&gt;何謂機器學習&lt;a class="anchor-link" href="#何謂機器學習"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;多虧了媒體的大量宣傳，我們現在都知道&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;被應用在各個領域。一些常見的例子包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自然語言處理，如 Google 翻譯、iPhone 的 Siri 語音辨識&lt;/li&gt;
&lt;li&gt;推薦系統，如 Amazon 的&lt;a href="https://technews.tw/2016/07/17/amazon-page-system/"&gt;『買了這個商品的人同時也購買了 ...』功能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;垃圾郵件自動判定，如同我們在&lt;a href="https://leemengtaiwan.github.io/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html"&gt;《直觀理解貝氏定理及其應用》&lt;/a&gt;一文中談到的&lt;/li&gt;
&lt;li&gt;電腦視覺，如 &lt;a href="https://www.techbang.com/posts/58630-facebook-calls-users-to-upload-nude-photos-in-order-not-to-make-you-the-yan-zhao-door-lead"&gt;Facebook 的人臉辨識&lt;/a&gt;、Youtube 的影片推薦，影像分類&lt;a href="https://github.com/leemengtaiwan/cat-recognition-app"&gt;〈這張照片是貓還是狗？〉&lt;/a&gt;等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例子不勝枚舉。有那麼多應用機器學習的例子，不禁讓人思考，究竟什麼是『機器學習』？&lt;/p&gt;
&lt;p&gt;依照目前機器學習的應用，一個大致上的定義是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;讓機器學習如何將輸入的資料 X 透過一系列的運算，轉換成指定的輸出 y。並提供一個衡量成功的方式，讓機器知道怎麼修正學習方向。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了這個定義，讓我們再看一下上面提到的幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自然語言處理：將得到的英文字串〈輸入〉，轉成中文文字〈輸出〉&lt;/li&gt;
&lt;li&gt;推薦系統：將使用者過去的購買記錄〈輸入〉，轉成使用者可能想要購買的商品列表〈輸出〉&lt;/li&gt;
&lt;li&gt;垃圾郵件判斷：將郵件內文〈輸入〉，轉成該郵件為垃圾信的機率〈輸出〉&lt;/li&gt;
&lt;li&gt;電腦視覺：將一個　400 x 400 像素的圖片，轉成多個標籤的機率〈輸出〉&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;a href="https://developers.google.com/machine-learning/practica/image-classification/" target="_blank"&gt;
&lt;img src="images/learn-from-machine/cat-image-classification.PNG" style="" title="Google Machine Learning Practica"/&gt;
&lt;/a&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://developers.google.com/machine-learning/practica/image-classification/" target="_blank"&gt;Google Machine Learning Practica&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;
&lt;br/&gt;
    Google 教你做影像分類，利用機器學習，將充滿著像素的圖片轉換成一個個標籤
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;嗯嗯，我想這定義還算合理。&lt;/p&gt;
&lt;p&gt;眼尖的讀者會發現，這邊的例子說明了上述定義的一半：將輸入 X 轉換成輸出 y。為了進一步解釋後半段『衡量成功的方式』，下面讓我們以一個虛構的咖啡機舉例。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="機器學習實例：智慧咖啡機"&gt;機器學習實例：智慧咖啡機&lt;a class="anchor-link" href="#機器學習實例：智慧咖啡機"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設你是個咖啡愛好者，家裡有好幾台高檔的咖啡機，但每次泡出來的咖啡都不合你胃口。&lt;/p&gt;
&lt;p&gt;經過無數的失敗，忍無可忍，你最後決定向月巴克公司買台『智慧』咖啡機。該咖啡機宣稱可以了解你的個人需求，泡出世界上最符合你胃口的咖啡。&lt;/p&gt;
&lt;p&gt;拆開咖啡機包裝，你興奮地把咖啡豆、砂糖以及牛奶加到該咖啡機裡頭。幾分鐘過後，號稱世界上最好喝的咖啡完成了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/nolan-issac-38299-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;外觀看起來不錯，你滿懷期待地啜了一口。&lt;/p&gt;
&lt;p&gt;『太甜了吧！砂糖太多了，什麼鳥機器！』&lt;/p&gt;
&lt;p&gt;你怒吼著，幾乎馬上萌生退貨的想法。這時候咖啡機感應到你的抱怨，用很委屈的聲調說：&lt;/p&gt;
&lt;p&gt;『目前調配咖啡的方式為原廠設定。經過統計分析，要得到一個正常台灣人的最佳評分，平均一杯咖啡裡頭的咖啡豆顆數、砂糖匙數以及牛奶的小杯數的比例應該要是 10 比 2 比 3。』&lt;/p&gt;
&lt;p&gt;你只覺得莫名其妙，心想這什麼神奇的比例。而且咖啡機剛剛是在拐彎抹角地說我不正常嗎？&lt;/p&gt;
&lt;p&gt;這時候咖啡機又說話了：&lt;/p&gt;
&lt;p&gt;『為了做出最符合您口味的咖啡，滿分 100 的情況下，請按鈕輸入你認為此杯咖啡值幾分。另外請告訴我是哪邊出了問題，如糖份比例太高還是牛奶太多，以讓我能記住您的喜好。』&lt;/p&gt;
&lt;p&gt;你翻了個白眼，喝杯咖啡還要教機器怎麼調配？哪裡智慧了？&lt;/p&gt;
&lt;p&gt;但為了喝到最符合自己喜好的咖啡，你決定給咖啡機一個機會，好好地調教它。針對眼前這杯咖啡，你把自己的回饋〈評分、調配比例的建議：砂糖太多〉老老實實地輸入進去。&lt;/p&gt;
&lt;p&gt;於是乎就這樣，不知不覺中你已經與月巴克咖啡機一起踏上了調配世界上最好喝咖啡的學習之旅。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/david-charles-schuett-362484-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了實際了解咖啡機怎麼學習，你翻開咖啡機使用手冊，看到以下內容：&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;《月巴克智慧咖啡機說明指南》&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本假設；使用者評分 = 使用者滿意程度&lt;/li&gt;
&lt;li&gt;預測使用者給咖啡的評分 &lt;code&gt;y'&lt;/code&gt; = &lt;code&gt;w1&lt;/code&gt; * 咖啡豆顆數 + &lt;code&gt;w2&lt;/code&gt; * 砂糖匙數 + &lt;code&gt;w3&lt;/code&gt; * 牛奶小杯數 + 基本分 &lt;code&gt;b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;目標：找出一組調配比重 &lt;code&gt;w1, w2, w3, b&lt;/code&gt;，使得咖啡機預測的評分 &lt;code&gt;y'&lt;/code&gt; 越接近實際的使用者評分 &lt;code&gt;y&lt;/code&gt; 越好&lt;/li&gt;
&lt;li&gt;咖啡製作：使用上述比重調配咖啡，使得預測評分 &lt;code&gt;y'&lt;/code&gt; 接近 100&lt;/li&gt;
&lt;li&gt;各原料調配比重〈原廠設定〉： &lt;code&gt;w1 = 10, w2 = 2, w3 = 3, b = 60&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;你恍然大悟，原來月巴克公司為了讓咖啡機最大化你給咖啡的評分，在咖啡機裡頭建構了一個簡單的&lt;a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8"&gt;線性回歸〈Linear Regression〉&lt;/a&gt;模型。&lt;/p&gt;
&lt;p&gt;在這模型裡頭，使用者針對一杯咖啡的評分 &lt;code&gt;y&lt;/code&gt; 會受到多個原料的量的影響。每個原料量的影響程度則透過個別的 &lt;code&gt;w&lt;/code&gt; 來描述。理想上，如果咖啡機可以找出一組比重〈weights〉 &lt;code&gt;w&lt;/code&gt; ，使得咖啡機『預測』出來的評分 &lt;code&gt;y'&lt;/code&gt; 跟『實際』使用者給的評分 &lt;code&gt;y&lt;/code&gt; 非常相近的話，咖啡機就可以利用該模型來合理地選擇咖啡豆、砂糖以及牛奶的量，調配出一杯預期能獲得你最高評分的咖啡。&lt;/p&gt;
&lt;p&gt;那咖啡機要如何實際『學習』呢？ 或者換句話說，咖啡機要怎麼樣知道它現在用的參數〈&lt;code&gt;w1&lt;/code&gt;、&lt;code&gt;b&lt;/code&gt;等〉夠不夠好呢？如果不夠好的話，要怎麼修正呢？&lt;/p&gt;
&lt;p&gt;在一開始完全沒有任何使用者回饋的時候，咖啡機可以很合理地使用原廠設定來計算使用者評分 &lt;code&gt;y'&lt;/code&gt;。等到你輸入了一些評分 &lt;code&gt;y&lt;/code&gt; 以後，將所有從你得到的評分 &lt;code&gt;y&lt;/code&gt; 跟咖啡機自己預測的 &lt;code&gt;y'&lt;/code&gt; 做比較，看咖啡機做的預測評分跟你的給分差了多少，據此修正原料的比重 &lt;code&gt;w&lt;/code&gt; 以及 &lt;code&gt;b&lt;/code&gt;。&lt;code&gt;y'&lt;/code&gt;跟&lt;code&gt;y&lt;/code&gt;的差異讓我們暫時稱作 &lt;code&gt;diff_y&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;修正以後，一般來說我們會得到新的比重　&lt;code&gt;w'&lt;/code&gt; 以及 &lt;code&gt;b'&lt;/code&gt;。當咖啡機使用 &lt;code&gt;w'&lt;/code&gt; 以及 &lt;code&gt;b'&lt;/code&gt;產生新的預測評分 &lt;code&gt;y''&lt;/code&gt;，其跟你的實際給分 &lt;code&gt;y&lt;/code&gt; 也會有一個差距，我們則將其稱作為 &lt;code&gt;diff_y'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;當使用新的參數〈&lt;code&gt;w1&lt;/code&gt;、&lt;code&gt;b&lt;/code&gt;等〉產生的 &lt;code&gt;diff_y'&lt;/code&gt; 比原來的 &lt;code&gt;diff_y&lt;/code&gt; 來小的時候，我們就能很開心地表示：『這咖啡機幹得真不錯！學到了點東西，能更準確地找出我的喜好！』。&lt;/p&gt;
&lt;p&gt;而在每次獲得你回饋的時候重複上述步驟，咖啡機不斷地修正它用來預估你給咖啡分數的參數，讓預測出來的值 &lt;code&gt;y'&lt;/code&gt; 跟你過去所有評分 &lt;code&gt;y&lt;/code&gt; 之間的差異都更小。雖然我們這邊不會細講，但在線性回歸裡頭，一個常被用來計算預測值 &lt;code&gt;y'&lt;/code&gt; 跟實際值 &lt;code&gt;y&lt;/code&gt; 差異的方式是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"&gt;最小平方法〈Least Squares〉&lt;/a&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;diff_y = 針對每次使用者的評分 y，機器利用當下的參數產生相對應的 y' 以後，用兩者計算 (y' - y) 的平方並加總它們
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以看到，當 &lt;code&gt;diff_y&lt;/code&gt; 越小，代表咖啡機越能準確地依據目前的原料量，來預測你會給咖啡的評分。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/daryan-shamkhali-89504-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;咖啡機學得很快。經過幾個怒吼以及失望的夜晚，透過你給的回饋，它現在做出的咖啡已經能很穩定地讓你給出 90 分以上的評價。&lt;/p&gt;
&lt;p&gt;透過詢問咖啡機，你現在知道，為了獲得你的高評價，咖啡機學到了以下的模型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你給咖啡的評分 = 咖啡豆顆數 * 13 + 砂糖匙數 * 1.2 + 牛奶小杯數 * 1.5 + 基本分 40 分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這跟一開始為了滿足所有人的原廠設定相比，還差真不少：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般使用者評分 = 咖啡豆顆數 * 10 + 砂糖匙數 * 2 + 牛奶小杯數 * 3 + 基本分 60 分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依照你過去的回〈ㄊㄧㄠˊ〉饋〈ㄐㄧㄠˋ〉，咖啡機發現跟一般人相比，咖啡豆量對你來說，是一杯咖啡好不好喝的重要指標〈13 vs 10〉，砂糖跟牛奶量則反而顯得沒那麼重要。而從基本分來看，咖啡機甚至學到你對咖啡的要求程度比一般人要來得嚴格〈40 vs 60〉，實實在在地說明機器了解你是個專業的咖啡愛好者。&lt;/p&gt;
&lt;p&gt;現在再讓我們看一次前面定義的機器學習：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;讓機器學習如何將輸入的資料 X 透過一系列的運算，轉換成指定的輸出 y。並提供一個衡量成功的方式，讓機器知道怎麼修正學習方向。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;經過上面的咖啡機例子，我們能清楚地歸納出以下幾點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;咖啡機是在進行機器學習，學習如何用一連串運算，將原物料的量〈咖啡豆顆數等〉&lt;code&gt;X&lt;/code&gt; 轉換成使用者評分 &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;機器學習裡所謂的一系列運算，在咖啡機的例子裡是進行線性回歸，即 &lt;code&gt;y = w * x + b&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;咖啡機衡量成功的方式是計算『預測評分 &lt;code&gt;y'&lt;/code&gt; 跟實際評分 &lt;code&gt;y&lt;/code&gt; 之間的差異大小』，此差異越小，代表學得越好&lt;/li&gt;
&lt;li&gt;衡量成功的方法很重要，因為咖啡機可以知道『努力/學習的方向』&lt;/li&gt;
&lt;li&gt;咖啡機透過反覆地修正參數，進而最小化上述差異，成功地『學習』&lt;/li&gt;
&lt;li&gt;機器學習是學習一組最符合目標的『參數』〈如基本分的 &lt;code&gt;40&lt;/code&gt;、咖啡豆顆數的 &lt;code&gt;13&lt;/code&gt;〉&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們可以總結說，咖啡機在你給的回饋以及監督之下，想辦法從三種原料〈咖啡豆、砂糖、牛奶〉中，『學習』出一個最棒的調配比例，以做出一杯能得到你最高評價的咖啡。在機器學習領域裡頭，這實際上被稱作&lt;a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92"&gt;監督式學習〈Supervised Learning〉&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;太棒了，你跟月巴克咖啡機從此過著幸福美滿的日子‧&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何讓機器學得更好"&gt;如何讓機器學得更好&lt;a class="anchor-link" href="#如何讓機器學得更好"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你閱讀完上面例子，開始思考以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;『除了原物料的量以外，或許還可以搜集其他類型的資料，像是咖啡機主人的性別、年齡甚至泡咖啡的時間，然後把它們加到模型裡頭以提高預測評分的準度？』&lt;/li&gt;
&lt;li&gt;『除了簡單的線性回歸，我們應該也可以用其他更複雜的模型或演算法來預測使用者的評分？』&lt;/li&gt;
&lt;li&gt;『與其預測使用者評分，能不能建立新的模型，直接預測使用者喜好？』&lt;/li&gt;
&lt;li&gt;『如果咖啡機得到更多我的回饋資料，是不是會更準？』&lt;/li&gt;
&lt;li&gt;『我的喜好會隨很多因素如時間做改變，要怎麼讓咖啡機模擬這情況？』&lt;/li&gt;
&lt;li&gt;『這咖啡機學到最後，是不是只能產生適合我口味的咖啡，而不能產生大家都喜歡的咖啡？』&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我得說聲恭喜，你已經擁有機器學習的思維且準備好進入機器學習的殿堂了。&lt;/p&gt;
&lt;p&gt;但在你摩拳擦掌，準備進入殿堂時，有些人可能會跟你說，近年因為機器學習在各領域發展神速，且機器能使用的訓練資料〈Training Data〉也越來越多，&lt;a href="https://zh.wikipedia.org/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7"&gt;強人工智慧〈Strong AI〉&lt;/a&gt;很快就會出現。不久的未來，我們甚至也不用自己設計演算法以及模型，A.I.會自動幫我們全部做好。也就是：機器會自己讓機器學得更好。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/strong-ai.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    當強人工智慧出現以後，或許人類就不再被需要了。因為機器會自己讓機器學得更好。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;真的嗎？沒有人能真正的預測未來，所以我們無從知曉。&lt;/p&gt;
&lt;p&gt;但至少在接下來幾年，要讓機器學習或者人工智慧再繼續進步，『人類的思考』是不可或缺的重要因素。主要體現在兩個地方：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;機器並沒有意識判斷『為什麼』以及何謂『對的方向』&lt;/li&gt;
&lt;li&gt;機器的世界觀是人類教的&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="機器並沒有意識判斷『為什麼』以及何謂『正確』"&gt;機器並沒有意識判斷『為什麼』以及何謂『正確』&lt;a class="anchor-link" href="#機器並沒有意識判斷『為什麼』以及何謂『正確』"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;電腦因為有著強大的記憶以及運算能力，在很多任務上面都已經可以超越人類的表現。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/image-classification-history.PNG" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://chtseng.wordpress.com/2017/11/20/ilsvrc-%E6%AD%B7%E5%B1%86%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92%E6%A8%A1%E5%9E%8B/" target="_blank"&gt;ILSVRC 歷屆的深度學習模型&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;近年電腦視覺〈Computer Vision〉領域發展快速，機器學習在影像分類〈Image Classification〉的表現已經超越人眼。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;但能達到這樣的成果的前提，都是因為有人類在設計模型、監督機器學習。&lt;/p&gt;
&lt;p&gt;目前機器學習或是 A.I. 的應用其背後的模型，當你去看裡頭一行行的程式碼的時候，裡頭並不會定義『為什麼』要做這些任務。實際上，在機器學習的過程中，機器並沒有意識到為什麼要做這些任務；而如果沒有人類的介入的話，機器也不會自己定義什麼樣的結果叫做『成功』或『正確』，而也就不知道該往什麼方向學習。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;該讓機器學習什麼&lt;/li&gt;
&lt;li&gt;怎麼定義『正確/成功』，讓機器遵從並往該方向改善&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩件事情只有依靠人類來做決定。而其決定將大大地影響機器學習的成果以及品質。機器不會跟你說：&lt;/p&gt;
&lt;p&gt;『我覺得把影片裡面的貓咪識別出來，比識別出交通號誌燈來得重要。』&lt;/p&gt;
&lt;p&gt;『喔... 我覺得我們學的方向怪怪的，讓我們往這個方向學習如何？』&lt;/p&gt;
&lt;p&gt;一個定義出錯的目標函式〈Objective Function〉將永遠無法讓機器學出我們想要的結果。&lt;/p&gt;
&lt;p&gt;針對這點，我們應該：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;找出值得解決的問題，下定我們的目標並明確定義何謂『正確』，以讓機器往該方向學習。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="機器的世界觀是人類教的"&gt;機器的世界觀是人類教的&lt;a class="anchor-link" href="#機器的世界觀是人類教的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;第二點應該也不難理解。一個機器的世界觀基本上取決於兩點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人類指定使用的模型〈Model〉&lt;/li&gt;
&lt;li&gt;餵給它的資料〈Data〉&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前面咖啡機的線性回歸，我們透過一個簡單的線性模型，教會咖啡機看世界。在咖啡機所認知的世界裡頭，使用者的評分就只會受到三種原物料量的影響：咖啡豆、砂糖及牛奶。這是一個非常簡單的世界，方便我們理解機器學習，但在真實世界上基本上不會成功運作，你需要考慮更多因素。&lt;/p&gt;
&lt;p&gt;如同我們前面有提到，你可能會思考以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;『我的喜好會隨很多因素如時間做改變，要怎麼讓咖啡機模擬這情況？』&lt;/li&gt;
&lt;li&gt;『除了原物料的量以外，或許還可以搜集其他類型的資料，然後把它們加到模型裡頭以提高預測評分的準度？』&lt;/li&gt;
&lt;li&gt;『除了簡單的線性回歸，我們應該也可以用其他更複雜的模型或演算法來預測使用者的評分？』&lt;/li&gt;
&lt;li&gt;『這咖啡機學到最後，是不是只能產生適合我口味的咖啡，而不能產生大家都喜歡的咖啡？』&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/ricardo-resende-692381-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我們怎麼看世界，將直接影響機器怎麼看世界。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上你已經在思考如何擴充機器的世界觀了。你可以使用各式各樣的模型、更多的資料以讓機器能用更全面的方式來理解這個世界。而這個新的世界觀只能由你來定義。&lt;/p&gt;
&lt;p&gt;〈現在的〉機器不會突然跟你說：&lt;/p&gt;
&lt;p&gt;『嗯... 我覺得我們應該考慮泡咖啡時有沒有下雨，因為這可能會嚴重地影響使用者心情，進而影響評分。』&lt;/p&gt;
&lt;p&gt;『我只依照你的評分做最佳化，可能會有&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適&lt;/a&gt;問題喔！』&lt;/p&gt;
&lt;p&gt;這些問題都是我們必須自己發現並解決，不能只期待機器自動解決〈至少這幾年〉。在機器學習領域裡頭，最怕的不是模型完全不行，而是上述的&lt;a href="https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9"&gt;過適〈Overfitting〉&lt;/a&gt;問題：機器所看到的資料本身太過侷限，導致其雖然只看到真實世界的一小部分，就誤以為那是全世界。換句話說，機器裡存在著強烈的偏見〈bias〉。前陣子常聽到的案例是&lt;a href="https://www.theguardian.com/technology/2017/dec/04/racist-facial-recognition-white-coders-black-people-police"&gt;白人設計出來的臉部辨識模型對黑人有偏見&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;以我們咖啡機的例子來說，如果你家裡只有你一人，咖啡機只需要服務你一人即好；但如果你們是一個家庭，家裡的人都希望咖啡機能為它們弄出好喝的咖啡，則每個人都需要給予咖啡機回饋，以讓咖啡機了解每個人喜好。如果仍然只有你一個人給予咖啡機回饋，其他人不給分，則咖啡機會以為得到的評分來自所有人，誤以為只要最佳化這些評分，就能滿足所有人，其實不然。&lt;/p&gt;
&lt;p&gt;為了讓機器看得更遠更全面，我們應該：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;想辦法在機器學習的模型內融入更多我們的直觀想法〈intuition〉，並讓機器看到更全面的資料，以拓展機器的『世界觀』。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何改善我們的學習_1"&gt;如何改善我們的學習&lt;a class="anchor-link" href="#如何改善我們的學習"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;閱讀到此，相信你對機器學習已經有個高層次的理解了。&lt;/p&gt;
&lt;p&gt;在對機器學習有個基本的了解以後，我們在前面章節提到為了讓機器學得更好，一個可行的方向是將我們的直觀想法、世界觀轉換成機器可以運算的模型或是目標函式，以讓機器能從聰明的我們身上學習。但換個角度思考，在我們教機器『學習』的時候，應該也能從機器『學習』到什麼才對。&lt;/p&gt;
&lt;p&gt;事實上，很多我們應用在機器學習領域的想法，緊密地跟我們的個人生活息息相關。&lt;/p&gt;
&lt;p&gt;舉個例子，在機器學習中，過適〈Overfitting〉是我們最想要避免的問題。我們不會希望機器只學到事物的表象，或者受到 outliers 的影響，而是希望機器學到更重要的模式〈Pattern〉、趨勢〈Trend〉。所以研究者們透過各種方式來讓機器不要過適：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;輸入更多資料&lt;/li&gt;
&lt;li&gt;用更簡單的模型&lt;/li&gt;
&lt;li&gt;減輕 outliers 的比重&lt;/li&gt;
&lt;li&gt;正規化〈Normalization〉&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而當機器成功地學到了事物的本質，就能精準地預測未來並且概括所有情況〈Generalize〉：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;預測股票漲幅&lt;/li&gt;
&lt;li&gt;預測誰最後會當上總統&lt;/li&gt;
&lt;li&gt;預測詐騙交易&lt;/li&gt;
&lt;li&gt;預測一張照片裡頭有什麼物件&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;畢竟，一個只看過貓跟狗照片的機器，不管未來看到什麼，就算是汽車或是人類，也只會將視它們為一定程度的貓或者是狗。&lt;/p&gt;
&lt;p&gt;知名心理學家&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%9A%E4%BC%AF%E6%8B%89%E7%BD%95%C2%B7%E9%A9%AC%E6%96%AF%E6%B4%9B"&gt;馬斯洛&lt;/a&gt;曾&lt;a href="https://www.brainyquote.com/authors/abraham_maslow"&gt;說過&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;如果你只有一個槌子，你可能就會把每個問題都視為釘子。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/tr-veler-671730-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    不管學習的是機器還是人類，學會概括〈Generalize〉並避免過適〈Overfitting〉是最重要的課題。手中只有槌子的人，什麼問題都看起來像釘子。
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同樣道理可以應用在人類的學習上。&lt;/p&gt;
&lt;p&gt;當我們只注重在參加各式各樣的線上深度學習〈Deep Learning〉課程，而不去了解機器學習背後的原理就是一種過適；當我們掙扎著要用 Python 還是 R 畫漂亮的圖，而不去理解為何要這樣畫，才能讓觀眾更容易理解時也是一種過適。更不用說一個只了解&lt;a href="https://zh.wikipedia.org/zh-hant/决策树"&gt;決策樹〈Decision Tree〉&lt;/a&gt;的同學，看到什麼問題都會想要用決策樹來解的案例了。&lt;/p&gt;
&lt;p&gt;學習表象比較簡單沒錯，但不能帶你走很遠。了解趨勢或者模式則讓你看到未來：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卓越的歷史學家忽視單一歷史事件，透過了解世界整體的歷史脈絡來預測未來&lt;/li&gt;
&lt;li&gt;愛因斯坦觀察到世界的運作原理而推出有名的質能轉換公式 &lt;code&gt;E = mc&amp;sup2;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;好的學習方式是理解事物背後的運作的趨勢、模式。為何我們要機器學習？為什麼深度學習會崛起？注重在詢問更多的『為什麼』以理解事物本質。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從一些已經被應用在機器學習的概念獲得啟發，我們可以重新思考並改善我們人類自己的學習。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這篇文章前半段以一個虛構的智慧咖啡機為例，深入探討機器學習的一些基本但十分的重要概念以及運作方式。&lt;/p&gt;
&lt;p&gt;在掌握機器學習的基本概念以後，我們討論了如何以『人』為本，融入我們人類的智慧以讓機器更聰明地學習、了解這個世界。接著，我們用了一點篇幅，討論了看似不相關的『人類學習』以及『機器學習』之間一個共同且最重要的核心目標：『學習如何去概括〈Generalize〉事物並避免過適〈Overfitting〉』。&lt;/p&gt;
&lt;p&gt;現在機器學習〈尤其是深度學習〉跟其他學術領域如統計、電腦科學相比，是一個相對新的領域，大家都還在摸索階段。但正如當年新興的程式設計已經普遍被重視，甚至加入國高中教育一般，我想再過幾年，等機器學習更為成熟後，人們也會開始呼籲將『機器學習』領域的知識納入課綱，成為我們下一代的基本素養之一。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/learn-from-machine/andy-kelly-402111-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    未來教育模式的改變：
    &lt;br/&gt;
    或許『機器學習』會如同『程式設計』素養一般，成為下一代必備的基本知識素養之一
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;或許那就是本篇所提到的『從機器學習中學習』。&lt;/p&gt;
&lt;p&gt;但在那時代到達之前，讓我們開心〈機器〉學習吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="機器學習"></category><category term="machine learning"></category></entry><entry><title>從經驗中學習 - 直觀理解貝氏定理及其應用</title><link href="https://leemeng.tw/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html" rel="alternate"></link><published>2018-05-25T15:30:00+09:00</published><updated>2018-05-25T15:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-05-25:/intuitive-understandind-of-bayes-rules-and-learn-from-experience.html</id><summary type="html">&lt;p&gt;貝氏定理（Bayes' theorem）是機率論中，一個概念簡單卻非常強大的定理。有了機率論的存在，人們才能理性且合理地評估未知事物發生的可能性（例：今天的下雨機率有多少？我中樂透的可能性有多高？），並透過貝氏定理搭配經驗法則來不斷地改善目前的認知，協助我們做更好的決策。這篇將利用生活上我們（或人工智慧）常需要考慮的事情當作引子，如今天的下雨機率是多少？來直觀地了解貝氏定理是怎麼被應用在各式各樣的地方。我們甚至可以效仿貝氏定理的精神，讓自己能更理性地評估未知並從經驗中學習。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;貝氏定理（Bayes' theorem）&lt;/a&gt;是機率論中，一個概念簡單卻非常強大的定理。有了機率論的存在，人們才能理性且合理地評估未知事物發生的可能性（例：今天的下雨機率有多少？我中樂透的可能性有多高？），並透過貝氏定理搭配經驗法則來不斷地改善目前的認知，協助我們做更好的決策。&lt;/p&gt;
&lt;p&gt;英國數學家&lt;a href="https://zh.wikipedia.org/wiki/%E5%93%88%E7%BD%97%E5%BE%B7%C2%B7%E6%9D%B0%E5%BC%97%E9%87%8C%E6%96%AF"&gt;哈羅德&amp;middot;傑弗里斯&lt;/a&gt;甚至&lt;a href="https://en.wikipedia.org/wiki/Bayes%27_theorem#cite_note-1"&gt;說過&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;貝氏定理之於機率論，就像是畢氏定理之於幾何學。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為其簡單且強大的特性，被廣泛應用在醫療診斷以及機器學習等領域。網路並不缺貝氏定理的教學文章，但多數以&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;機率公式&lt;/a&gt;出發，不夠直觀（至少以我個人來說），就算理解了也不易內化成自己的知識。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/Bayes_Theorem_MMB_01.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://commons.wikimedia.org/w/index.php?curid=14658489" target="_blank"&gt;貝氏定理公式&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;喔喔喔感覺到數學的力量了嗎？
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此這篇將利用生活上我們（或&lt;a href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"&gt;人工智慧&lt;/a&gt;）常需要考慮的事情當作引子，如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;今天的下雨機率是多少？&lt;/li&gt;
&lt;li&gt;這封 email 是垃圾郵件的可能性有多高？&lt;/li&gt;
&lt;li&gt;醫生說我得癌症了，這可靠度有多高？（好吧，或許這沒那麼常發生）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;來直觀地了解貝氏定理是怎麼被應用在各式各樣的地方。我們甚至可以效仿貝氏定理的精神，讓自己能更理性地評估未知並從經驗中學習。&lt;/p&gt;
&lt;p&gt;廢話不多說，讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="今天會下雨嗎？"&gt;今天會下雨嗎？&lt;a class="anchor-link" href="#今天會下雨嗎？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在實際說明貝氏定理的公式把你嚇跑之前，讓我們先做個簡單的假想實驗來說明貝氏定理的精神。&lt;/p&gt;
&lt;p&gt;假設大雄一早準備出門跟靜香見面，正在考慮要不要帶傘出門。&lt;/p&gt;
&lt;p&gt;起床的時候他想：&lt;/p&gt;
&lt;p&gt;「這地區不太會下雨，不需要帶傘吧！」&lt;/p&gt;
&lt;p&gt;往窗外一看，大雄眉頭一皺，發現烏雲密佈。&lt;/p&gt;
&lt;p&gt;「痾有烏雲，感覺下雨機率上升了，但好懶得帶傘 .. 先吃完早餐再說吧。」&lt;/p&gt;
&lt;p&gt;走到廚房，發現餐桌上一大堆螞蟻在開趴。&lt;/p&gt;
&lt;p&gt;「依據老媽的智慧，螞蟻往屋內跑代表&lt;a href="http://news.ltn.com.tw/news/local/paper/715319"&gt;下雨機率又提升了&lt;/a&gt;。真的不得不帶傘了嗎 .. 不不不！我不要帶好麻煩！」&lt;/p&gt;
&lt;p&gt;想著想著，這時候靜香打電話過來了：&lt;/p&gt;
&lt;p&gt;「胖虎說他也要去喔！」「蛤你說什麼！？」&lt;/p&gt;
&lt;p&gt;胖虎是有名的雨男，每次跟他出遊都會下雨。依照這個經驗以及前面看到的幾個現象，最後大雄放棄掙扎，帶著雨傘出門了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/andy-grizzell-543812-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在上面的例子中，大雄觀察到三個現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;烏雲密佈&lt;/li&gt;
&lt;li&gt;螞蟻開趴&lt;/li&gt;
&lt;li&gt;胖虎出沒&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;依據他過往的經驗，這些現象都會使得降雨的機率提升，讓他逐漸改變剛起床的時候「今天不太會下雨」的想法，最後決定帶傘出門。&lt;/p&gt;
&lt;p&gt;這個決策的轉變過程，其實就是貝氏定理的精神：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;針對眼前發生的現象以及獲得的新資訊，搭配過往經驗，來修正一開始的想法。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，大雄已經在腦海中進行了多次貝氏定理的運算而不自知（我家大雄哪有那麼聰明）。現在讓我們用比較數學的方式來重現大雄腦海中的運算。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="讓我們帶點數字進去"&gt;讓我們帶點數字進去&lt;a class="anchor-link" href="#讓我們帶點數字進去"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解貝氏定理的目的以後，讓我們以&lt;a href="https://zh.wikipedia.org/wiki/%E5%8F%91%E7%94%9F%E6%AF%94"&gt;發生比（odds）&lt;/a&gt;的方式來闡述定理。發生比很簡單，就只是列出兩個（或以上）的事件分別（可能）發生的次數。&lt;/p&gt;
&lt;p&gt;使用發生比的好處是可以很容易地比較不同事件發生的相對次數。後面會看到，我們也能把發生比轉成機率。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設依據過往氣象紀錄，大雄住的地區一年 365 天中有 270 天放晴，下雨的天數為 365 - 270 = 95 天。則下雨的發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天數：晴天數 = 95：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;你可以把發生比想像成是一種相對關係，上面這個發生比代表，在大雄所住的地區，每觀測到 95 個雨天的日子，我們同時會觀測到 270 個晴天。晴天約是雨天的三倍之多（270 / 95）。&lt;/p&gt;
&lt;p&gt;轉換成機率來看的話，就是把雨天的天數，去除以所有天數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;95 / (95 + 270) = 0.26 = 26%
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一年也就只有 26% 的降雨機會，這也是為何大雄一開始在還沒觀察到新現象（烏雲、螞蟻及胖虎）的時候，合理認為今天「應該」不會下雨的原因。&lt;/p&gt;
&lt;p&gt;我們再繼續假設，依據大雄的過往經驗，他發現：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時，早上烏雲密佈的頻率是晴天時出現烏雲的 9 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這個 9 倍是怎麼來的呢？&lt;/p&gt;
&lt;p&gt;這其實是所謂的&lt;a href="https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing"&gt;概度比（likelihood ratio）&lt;/a&gt;。分別計算雨天及晴天發生的情況下，出現「烏雲密佈」現象的機率以後，再將兩者相除：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天時烏雲密佈的機率 = P(烏雲|雨天）
-------------------------------
晴天時烏雲密佈的機率 = P(烏雲|晴天）
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這兩個機率又被稱為&lt;a href="https://zh.wikipedia.org/wiki/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"&gt;條件機率（conditional probability）&lt;/a&gt;。一般 &lt;code&gt;P(A|B)&lt;/code&gt; 代表在事件 B 發生的情況下，事件 A 發生的機率。&lt;/p&gt;
&lt;p&gt;假設平均來看，在 10 個雨天裡頭，早上烏雲密佈的天數為 9 天（也就是說平均有 1 天的雨天是早上沒有烏雲密佈的），則我們可以說，「給定雨天的條件下，烏雲密佈」的機率是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|雨天） = 9 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;另外在 10 個晴天裡頭，早上烏雲密佈的天數平均為 1 天（也就是說早上雖然烏雲密佈，但最後並沒有下雨的天數），則「給定晴天的條件下，烏雲密佈」的機率是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|晴天） = 1 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;則烏雲密佈的概度比即為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;P(烏雲|雨天）    9 / 10
-----------  = --------- = 9
P(烏雲|晴天）    1 / 10
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;雖然「概度比」一詞很饒舌，但它就是一個比例，也就是「幾分之幾」的概念。 9 就是「一分之九」＝ 9 倍，而因為分母是「晴天」，你可以解讀這個 9 為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「在烏雲密佈發生的情況下，每觀測到 1 個晴天，就會同時觀測到 9 個雨天」。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也可以像是大雄觀察到的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「雨天時，早上烏雲密佈的頻率是晴天時出現烏雲的 9 倍」。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/cloudy-field-2.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    經驗告訴我們，早上烏雲密佈的情況下，該天是雨天的機率就隨著上升
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="貝氏定理初顯鋒芒"&gt;貝氏定理初顯鋒芒&lt;a class="anchor-link" href="#貝氏定理初顯鋒芒"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以有了這個倍數可以做什麼？直覺及經驗告訴我們，在觀測到烏雲密佈的前提下，下雨機率理論上會有所提升。&lt;/p&gt;
&lt;p&gt;換句話說，在烏雲密佈，且觀測到的晴天數不變的情況下，觀測到的雨天數應該要有所上升，這樣下雨的天數在所有天數裡頭的比例才會上升。&lt;/p&gt;
&lt;p&gt;而其上升的倍數就是前面的概度比（ 9 倍）。因此在烏雲密佈發生的情況下，新的下雨發生比（odds）可以寫成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =   95   *   9   ： 270
　　　　　　　　 =       855      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;新的下雨發生比是我們利用觀測到的現象重新計算的，因此一般稱為「事後發生比」（posterior odds）；而一開始的發生比則被稱為「事前發生比」（prior odds）。&lt;/p&gt;
&lt;p&gt;事後發生比告訴我們，在烏雲密佈的情況下，每觀測 855 個雨天，就會同時觀測到 270 個晴天。跟事前發生比相反，現在雨天數反而超過晴天的三倍（855 /　270）。&lt;/p&gt;
&lt;p&gt;要計算新的下雨機率，我們一樣把雨天數去除以所有天數：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;855 / (855 + 270) = 0.76 = 76%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;跟一開始的 26% 相比，在觀測到烏雲密佈這個現象以後，下雨的機率足足上升了 50 個百分點，現在我們有更充分的理由請大雄帶把傘了。&lt;/p&gt;
&lt;p&gt;實際上，透過上面的計算，我們已經套用貝氏定理的公式了（&lt;a href="https://betterexplained.com/articles/understanding-bayes-theorem-with-ratios/"&gt;發生比版本&lt;/a&gt;）：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;事後發生比 = 概度比 * 事前發生比&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如同大雄的例子，一般應用貝氏定理的情境如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;對一件未知事物有初步的猜測（事前發生比）&lt;/li&gt;
&lt;li&gt;觀測到跟該事物相關的現象&lt;/li&gt;
&lt;li&gt;利用先前跟該現象有關的經驗計算出概度比&lt;/li&gt;
&lt;li&gt;利用概度比修正該猜測，得到修正後結果（事後發生比）&lt;/li&gt;
&lt;li&gt;重新評估、做決策&lt;/li&gt;
&lt;li&gt;又觀察到新現象，重複步驟 3 到 5 &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;透過貝氏定理，我們可以很快速地利用過去的經驗改善自己的想法，並產生更好的決策。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="大雄不死心：單純貝式"&gt;大雄不死心：單純貝式&lt;a class="anchor-link" href="#大雄不死心：單純貝式"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然觀察到了烏雲密佈，且利用過往經驗修正下雨的機率到了 76%，懶惰的大雄一開始還是不想帶傘出去。但為何最後還是帶傘出門了呢？那是因為除了烏雲密佈以外，他還觀察到了其他兩個影響下雨機率的現象：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;螞蟻開趴&lt;/li&gt;
&lt;li&gt;胖虎出沒&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;貝氏定理本身雖然強大，但其中一個使它被廣泛利用的是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"&gt;單純貝式（Naive Bayes）&lt;/a&gt;的概念：假設不同現象之間出現的機率為&lt;a href="https://zh.wikipedia.org/wiki/%E7%8B%AC%E7%AB%8B_(%E6%A6%82%E7%8E%87%E8%AE%BA"&gt;獨立&lt;/a&gt;)。&lt;/p&gt;
&lt;p&gt;設成獨立有什麼好處？事情變得很簡單，我們不用考慮現象 A 跟現象 B 之間的關聯性，能針對每個現象，分別去計算概度比，修正從「前面」的現象得到的結果，持續改善我們的認知。也就是上一節提到的貝氏定理的應用步驟 6。&lt;/p&gt;
&lt;p&gt;如法炮製，讓我們假設大雄針對其他兩個現象的經驗是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時，螞蟻出現在室內的天數是晴天的 2 倍&lt;/li&gt;
&lt;li&gt;雨天時，胖虎出遊的次數是晴天的 3 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們再次套用貝氏定理，但這次不是套用在一開始什麼都不知道的事前發生比：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;雨天數：晴天數 = 95：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;而是在觀察到烏雲密佈後的事後發生比：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;烏雲密佈下的雨天數：晴天數 = 855：270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先，讓我們套用跟螞蟻相關的經驗：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雨天時螞蟻出現在室內的天數是晴天的 2 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;概度比已經算好，所以依照貝氏定理的公式：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;事後發生比 = 概度比 * 事前發生比&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;新的（螞蟻）事後發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =   855  *   2   ： 270
　　　　　　　　 =      1710      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下雨的機率則提升為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1710 / (1710 + 270) = 0.86 = 86%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;比起只有烏雲密佈，在螞蟻也出現的情況下，降雨機率又提升了接近 10%。大雄是一個降雨機率不大於 90% 就不帶傘的傢伙，讓我們看看胖虎出沒能不能使他改變心意。&lt;/p&gt;
&lt;p&gt;同樣，再次套用定理到上一個（螞蟻的）發生比，則新的（胖虎）事後發生比為：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;新雨天數：晴天數 = 原雨天數 * 概度比：晴天數
　　　　　　　　 =  1710  *   3   ： 270
　　　　　　　　 =      5130      ： 270
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在轉換成機率之前，我們發現新的雨天數是晴天數的 10 倍以上，因此可以想像新的機率至少是 90% 以上。而實際計算下雨的機率：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;5130 / (5130 + 270) = 0.95 = 95%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在觀察到烏雲密佈、螞蟻以及胖虎出沒以後，大雄預估降雨機率上升至 95%，這下不得不帶傘出門了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/eddy-klaus-33079-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
重複套用貝氏定理以修正想法的過程就像是在創作：把眼前所有所見（顏料）一個一個納入考量，做出最後的判斷（作品）
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="動動腦時間"&gt;動動腦時間&lt;a class="anchor-link" href="#動動腦時間"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到了這邊，我相信你現在應該已經可以在腦中直觀地運用貝氏定理：針對眼前發生的現象，運用過去相關的經驗（計算概度比），來理性地評估某事件可能發生的機率。&lt;/p&gt;
&lt;p&gt;事實上在你繼續讀下去之前，我建議先停一停，思考幾個可以實際在生活中運用（或者已經在用）此定理的現象，以幫助你內化（internalize）這些概念。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/bayes/neonbrand-618322-unsplash.jpg" style=""/&gt;
&lt;/center&gt;&lt;p&gt;如果你一時想不到點子，這邊提供幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;email 內文裡頭出現「週年慶」時，該郵件為垃圾信的機率&lt;/li&gt;
&lt;li&gt;新聞內文出現「柯文哲」時，文章主題為政治的機率&lt;/li&gt;
&lt;li&gt;&lt;a href="https://zh.wikipedia.org/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"&gt;醫生說你得胰腺癌&lt;/a&gt;時，你真的得病的機率&lt;/li&gt;
&lt;li&gt;玩&lt;a href="https://zh.wikipedia.org/wiki/%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9F"&gt;英雄聯盟&lt;/a&gt;時，&lt;a href="https://baike.baidu.com/item/kDa/20623453"&gt;KDA&lt;/a&gt; 超過 4 的對手排位是鑽石以上的機率&lt;/li&gt;
&lt;li&gt;在東京藥妝店血拼，旁邊講中文的人是台灣人的機率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你有其他有趣的例子，歡迎留言跟大家分享。（現在留言不用登入了！）&lt;/p&gt;
&lt;p&gt;如同上述，貝氏定理有非常多應用。不過這邊想深入探討第一個 email 的案例：給定一封電子郵件的內文，你要怎麼判斷該信是不是垃圾信件？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="從人腦到電腦：讓機器幫我們做判斷"&gt;從人腦到電腦：讓機器幫我們做判斷&lt;a class="anchor-link" href="#從人腦到電腦：讓機器幫我們做判斷"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/spam.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    一個典型的垃圾郵件內文
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你說沒有什麼事情難得了我們人腦。依照過往經驗：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;垃圾信件裡頭出現「週年慶」一詞的機會是一般信件的 20 倍&lt;/li&gt;
&lt;li&gt;垃圾信件裡頭出現「折扣」一詞的機會是一般信件的 10 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在假設所有信件裡頭一半是垃圾信件（發生比 1：1）的前提下，依照單純貝氏的公式，這封信是垃圾信件的可能性上升 200 倍（20 * 10），我們可以放心把這封信丟入垃圾信分類。&lt;/p&gt;
&lt;p&gt;但是沒有人會想要在腦中對每封信做這個運算。人類是懶惰的，能自動化的東西就請電腦幫我們解決就好了。&lt;/p&gt;
&lt;p&gt;另外你也不可能記得每一個詞的倍數，實際上也沒有必要。只要讓電腦幫我們記住每個詞分別在垃圾郵件以及一般信件出現的次數，就能計算所有詞彙的概度比（odds）。&lt;/p&gt;
&lt;p&gt;等到一封新的信件來以後，找出裡頭的字對應的倍數做相乘以後，電腦就能自動分類郵件了。事實上這就是&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"&gt;機器學習&lt;/a&gt;中&lt;a href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"&gt;單純貝氏分類器（Naive Bayes Classifier）&lt;/a&gt;在做的事情。&lt;/p&gt;
&lt;p&gt;讓機器取代人腦自動判斷，有幾個顯而易見的好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;判斷速度倍增&lt;/li&gt;
&lt;li&gt;記憶能力超強&lt;/li&gt;
&lt;li&gt;（可以把分類郵件空出的時間拿去看貓咪影片）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;唷呼！垃圾郵件自動變不見！小鎮村又變得更美好了。&lt;/p&gt;
&lt;p&gt;當然你想自己實作單純貝氏分類器的話，Python 可以使用 &lt;a href="http://scikit-learn.org/stable/modules/naive_bayes.html"&gt;scikit-learn&lt;/a&gt; 來實作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="小心！你的經驗可靠嗎？"&gt;小心！你的經驗可靠嗎？&lt;a class="anchor-link" href="#小心！你的經驗可靠嗎？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們花了很長的篇幅講了幾個貝氏定理/單純貝氏的應用，也看到它既簡單又強大的特性。但在你摩拳擦掌並實際應用此定理的時候，有幾點需要注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同現象/事件真的獨立嗎？&lt;/li&gt;
&lt;li&gt;一開始的猜測以及經驗可靠嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;很多現象不一定是完全獨立而是相關的。不過一個常見的解決方法是想辦法增加更多的現象/事件/特徵值（features）來讓做出來的貝氏分類器比較可靠。貝氏定理當然不完美，但正如統計學家&lt;a href="https://www.google.co.jp/search?q=George+E.+P.+Box&amp;amp;rlz=1C5CHFA_enJP695JP700&amp;amp;oq=George+E.+P.+Box&amp;amp;aqs=chrome..69i57j69i60&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8"&gt;喬治&amp;middot;E&amp;middot;P&amp;middot;博克斯&lt;/a&gt;&lt;a href="https://en.wikipedia.org/wiki/All_models_are_wrong"&gt;所說&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;所有模型（models）都是錯的；但有些是有用的。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管「獨立」這個假設在某些情況下不合常理，但在如垃圾郵件分類等問題上，貝氏分類器有不錯的表現。而且重點是它實作簡單，可以拿來當作 baseline。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而一開始的猜測跟經驗可不可靠這個問題，英國數學家&lt;a href="https://zh.wikipedia.org/wiki/%E5%8D%A1%E5%B0%94%C2%B7%E7%9A%AE%E5%B0%94%E9%80%8A"&gt;卡爾&amp;middot;皮爾森&lt;/a&gt;，針對貝氏定理則給出一個我很愛的&lt;a href="https://en.wikipedia.org/wiki/Talk%3ABayesian"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;一個信奉貝氏定理的人常常做這樣的事情：模糊地期待著馬的出現，瞥見驢子的蹤影，強烈地相信他是見到了一匹駝子。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;「先入為主」大概是應用貝氏定理最忌諱的點了。下次再套用定理時，記得先思考自己一開始的假設以及經驗是否值得信任或者有什麼盲點。需不需要搜集更多資料來修正一開始的想法。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/bayes/tim-mossholder-603227-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    我真的是驢子不是駝子啊！（豆知識：駝是馬跟驢生下的動物）
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="總結"&gt;總結&lt;a class="anchor-link" href="#總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們在這篇開頭首先用「大雄評估下雨」的例子來直觀地理解貝氏定理背後的精神，接著透過簡單的數學概念、發生比（odds）以及概度比（likelihood ratio）來推出基本的貝氏定理公式。&lt;/p&gt;
&lt;p&gt;接著進一步延伸至單純貝氏（naive bayes）的概念，讓機器透過過去累積的資訊，為我們自動分類垃圾郵件。&lt;/p&gt;
&lt;p&gt;最後我們提到一些應用貝氏定理需要注意的事情。&lt;/p&gt;
&lt;p&gt;即使基本的貝氏定理不難，延伸的領域非常的廣。這篇沒辦法包含所有範圍，但希望透過這篇基礎介紹，能讓讀者能利用貝氏定理的概念，更理性地評估未知並從經驗中學習（或者是建立自己的貝氏分類器）。&lt;/p&gt;
&lt;p&gt;另外如果你有其他有趣的例子可以應用在貝氏定理，歡迎留言跟大家分享。（現在留言不用登入了！）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="貝氏定理"></category><category term="機率"></category><category term="機器學習"></category></entry><entry><title>揭開資料科學的神秘面紗</title><link href="https://leemeng.tw/demystify-the-hype-of-data-science-and-its-value.html" rel="alternate"></link><published>2018-05-11T21:10:00+09:00</published><updated>2018-05-11T21:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-05-11:/demystify-the-hype-of-data-science-and-its-value.html</id><summary type="html">&lt;p&gt;市面上有大量資料科學相關課程、書籍供我們自由學習，但你有想過為何我們需要學習資料科學嗎？為什麼資料科學現在那麼夯？我們應該拿資料科學來做什麼？抽離技術實作或者分析手法的討論，這篇文章試著用簡單的經濟學解釋其背後原因。希望閱讀完本文的讀者能了解為何資料科學在資訊時代扮演重要角色，以及我們要怎麼有效率地把握「資料科學力」以創造更大的價值。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;幾乎每天我們都能看到跟資料科學（Data Science）相關的新聞與文章，像是最近 &lt;a href="https://www.bnext.com.tw/article/49070/google-ai-phone-call-assistant-duplex-ethical-social-implications"&gt;Google 利用遞迴神經網路建立可以跟真人對話而不被發現的語音助理&lt;/a&gt;、 &lt;a href="https://www.inside.com.tw/2018/04/24/data-scientist-interview"&gt;成為 Apple 等公司的資料科學家前必讀的面試題目&lt;/a&gt;等等。&lt;/p&gt;
&lt;p&gt;市面上有大量資料科學相關課程、書籍供我們自由學習，事實上，多到一個人不可能看完。你有想過為何我們需要學習資料科學嗎？為什麼資料科學現在那麼夯？我們應該拿資料科學來做什麼？&lt;/p&gt;
&lt;p&gt;抽離技術實作或者分析手法的討論，這篇文章試著用簡單的經濟學原理回答這幾個問題。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;希望閱讀完本文的讀者能了解為何資料科學在資訊時代扮演重要角色，以及我們要怎麼有效率地把握「資料科學力」以創造更大的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;本文大致上會分成以下段落：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#聽說你想當資料科學家？"&gt;聽說你想當資料科學家？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料科學到底在夯什麼？"&gt;資料科學到底在夯什麼？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#啊所以那個資料科學勒？"&gt;啊所以那個資料科學勒？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#充實你的資料科學力"&gt;充實你的資料科學力&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;讓我們開始吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="聽說你想當資料科學家？"&gt;聽說你想當資料科學家？&lt;a class="anchor-link" href="#聽說你想當資料科學家？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料科學大概是近年最夯的流行語之一了。不管在哪邊，你都可以聽到媒體相關的報導：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://taronews.tw/2018/05/07/34472/"&gt;食農教育科研成果農業大數據結合資料科學&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.inside.com.tw/2018/04/24/data-scientist-interview"&gt;想成為資料科學家？來挑戰 Google、FB、Apple 等六間公司人工智慧最新面試題&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.digitimes.com.tw/iot/article.asp?cat=130&amp;amp;cat1=&amp;amp;cat2=&amp;amp;id=0000529979_36M8SBKK8S3C4K8O2RHKM&amp;amp;social_share=y"&gt;台灣產業AI化 最大問題人才不足&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ithome.com.tw/news/121342"&gt;成為搶手資料科學家應具備什麼技能？先學Python準沒錯&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... 族繁不及備載。&lt;/p&gt;
&lt;p&gt;而因為企業對擁有資料科學能力的人才需求大，想成為資料科學家（Data Scientist）的同學們也不少，相關的教學文章、線上課程如雨後春筍般湧現。這邊我沒辦法把它們一一列出，但你可以前往一些知名的線上課程平台如 &lt;a href="https://www.coursera.org/"&gt;Coursera&lt;/a&gt;、&lt;a href="https://www.udemy.com/"&gt;Udemy&lt;/a&gt;、&lt;a href="https://www.datacamp.com/"&gt;DataCamp&lt;/a&gt; 並搜尋「資料科學」（或者 Data Science）就知道我的意思了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/datacamp-courses.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/" target="_blank"&gt;DataCamp&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;基本上全部都是資料科學相關課程，寫程式寫到飽
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果我們把這些新聞報導或者教學課程，依照主題/領域做個粗略分類的話，還可以得到一些關鍵字：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大數據（Big Data）&lt;/li&gt;
&lt;li&gt;人工智慧（Artificial Intelligence）&lt;/li&gt;
&lt;li&gt;資料視覺化（Data Visualization）&lt;/li&gt;
&lt;li&gt;機器學習（Machine Learning）&lt;/li&gt;
&lt;li&gt;深度學習（Deep Learning）&lt;/li&gt;
&lt;li&gt;統計分析（Statistical Analytics）&lt;/li&gt;
&lt;li&gt;雲端運算 （Cloud Computing）&lt;/li&gt;
&lt;li&gt;Python、R、SQL&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/sean-pollock-203658-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/PhYq704ffdA?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料科學&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;涵蓋大量領域，各領域的專業知識就像一棟棟大樓將你包圍吞噬
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想學習資料科學的同學這時候就頭疼了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「全部都要學嗎？從哪邊開始 .. 」&lt;/li&gt;
&lt;li&gt;「選 &lt;a href="https://zh.wikipedia.org/wiki/Python"&gt;Python&lt;/a&gt; 或是 &lt;a href="https://zh.wikipedia.org/wiki/R%E8%AF%AD%E8%A8%80"&gt;R 語言&lt;/a&gt;？還是先學 &lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;SQL&lt;/a&gt;？」&lt;/li&gt;
&lt;li&gt;「資料視覺化要學 Python 的 &lt;a href="https://matplotlib.org/"&gt;Matplotlib&lt;/a&gt; 還是 R 的 &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt; ？」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;現在有些網站很用心，為了解決你的煩惱，還將相關的課程集結起來成一個&lt;a href="https://www.coursera.org/specializations/data-science-python"&gt;專業課程（Specialization）&lt;/a&gt;讓你一步一步跟著學。&lt;/p&gt;
&lt;p&gt;勤學如你，上了幾門課以後學會如何利用 &lt;a href="https://www.coursera.org/learn/python-machine-learning"&gt;Python 做簡單的機器學習模型&lt;/a&gt;、&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1"&gt;使用 R 做資料視覺化&lt;/a&gt;，甚至也懂得&lt;a href="https://www.datacamp.com/courses/intro-to-sql-for-data-science"&gt;使用 SQL 存取資料庫&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;恭喜！你是個資料科學家了！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;痾.. 這麼簡單？好像哪裡怪怪的？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你會不會開始思考：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;所以到底啥是資料科學？資料科學到底在夯什麼？為什麼我要學資料科學？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上會這樣想的不止你一人。在仔細思考並給上述問題一個合理的解釋之前，就算學了再多門課，充其量只是在不斷擴充自己的「資料科學工具盒」，但卻不知道「為何要買這些工具」、「要拿這些工具做什麼」。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/barn-images-12223-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/t5YUoHW6zRo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料科學工具箱&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;琳瑯滿目，酷！但你要用這些工具創造或是改善什麼？
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為你學的是方便實踐資料科學的程式語言、工具、方法論（Methodology），而不是「為什麼資料科學重要」。我會用剩下的篇幅試著對此問題給出一套解釋。解釋方法有很多種，所以非常歡迎在底下留言分享你的看法。&lt;/p&gt;
&lt;p&gt;不過現在，且聽我娓娓道來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料科學到底在夯什麼？"&gt;資料科學到底在夯什麼？&lt;a class="anchor-link" href="#資料科學到底在夯什麼？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了耳熟能詳的「技術發展快速」、「資料量龐大」的理由以外，資料科學之所以那麼夯，背後還有一個可想而知的巨大推手：「商業利益」。&lt;/p&gt;
&lt;p&gt;要進一步解釋這個概念，我們可以從 Google 首席經濟學家 &lt;a href="https://zh.wikipedia.org/wiki/%E5%93%88%E5%B0%94%C2%B7%E8%8C%83%E9%87%8C%E5%AE%89"&gt;哈爾&amp;middot;范里安&lt;/a&gt; 在 2009 年接受麥肯錫的訪問，探討&lt;a href="https://www.mckinsey.com/industries/high-tech/our-insights/hal-varian-on-how-the-web-challenges-managers"&gt;網際網路對企業的挑戰&lt;/a&gt;中看出一些端倪。（真知灼見，建議作課外閱讀）&lt;/p&gt;
&lt;p&gt;近年網際網路快速發展。要在網路上發表內容，對任何人或者任何企業來說都是輕而易舉的事情。這邊說的內容（Content）可以是任意資訊，比如説：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一則 Facebook 粉絲團貼文&lt;/li&gt;
&lt;li&gt;一則銷售青島啤酒的網頁&lt;/li&gt;
&lt;li&gt;一個教你學習資料科學的線上課程網頁&lt;/li&gt;
&lt;li&gt;一篇部落格文章（像你正在看的這篇）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為傳播媒介以及科技的進步，要在網路上發布這些資訊並讓他人注意到的成本趨近於零，而其導致的結果就是&lt;a href="https://www.ithome.com.tw/article/87190"&gt;全球的資訊量急速成長&lt;/a&gt;。被稱為人工智慧之父之一的經濟學家 &lt;a href="http://wiki.mbalib.com/zh-tw/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99"&gt;赫伯特&amp;middot;西蒙&lt;/a&gt; 針對這種現象就曾說過一句&lt;a href="https://en.wikiquote.org/wiki/Herbert_A._Simon"&gt;名言&lt;/a&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在一個資訊豐富的世界裡頭，資訊量的富裕導致人們注意力的貧窮。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以個人的角度來看，在時間以及精力有限的情況下，我們每天能接受資訊的時間以及注意力都是有限的。如何分配這些寶貴的注意力以接收對的資訊，變成現代人的課題。&lt;/p&gt;
&lt;p&gt;痛點即商機。很多企業透過解決這個&lt;a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E8%A8%8A%E8%B6%85%E8%BC%89"&gt;資料超載（Information Overload）&lt;/a&gt;的問題來提供使用者價值：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;漫畫網站把所有知名漫畫整理在一起供你閱讀&lt;ul&gt;
&lt;li&gt;價值：統整、數位化、自動更新散落各地的漫畫資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Google 提供搜尋功能給你&lt;ul&gt;
&lt;li&gt;價值：讓你快速找到存在地球上的任何相關資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Youtube 讓你免費看到飽&lt;ul&gt;
&lt;li&gt;價值：讓你隨時看全世界最新的貓咪影片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;只要喊「+1」Facebook 粉絲團就免費把「珍貴」的內容給你&lt;ul&gt;
&lt;li&gt;價值：給你數位內容如新產品資訊、整理過後的旅遊資訊等&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;天下沒有白吃的午餐，企業願意這麼做必定有得到什麼。你的確取得了免費的數位內容（文章、影片、漫畫），但又付出了什麼？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/velizar-ivanov-540528-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/lz_VB9yEc_c?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資訊時代最珍貴的資源&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;人們（與喵）的關注
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，不管是閱讀文章、觀看影片、瀏覽漫畫，你都是在拿了你最寶貴的「注意力」跟企業交換這些價值。而在成功獲得你目光的同時，這些企業則透過秀廣告給你來獲利（例 1 - 3，暫不考慮 AdBlock）。&lt;/p&gt;
&lt;p&gt;註：在這邊，「注意力」跟「時間」有些微秒差異。不過你只要回想昨天晚上跟朋友或是家人吃飯的時候，各自滑手機的景象就可以了：你把「時間」花在跟身旁的人吃飯，卻把「注意力」（或者說是關注）放在手機裡頭的數位資訊。（如果你沒用手機，我很抱歉。）&lt;/p&gt;
&lt;p&gt;例 4 很有趣，你是拿「你自己以及你朋友圈的人的注意力」來做價值交換（你的留言讓 Facebook 的演算法自動推播該貼文到你朋友的動態牆上，粉絲團賺到他們的關注），但基本上是同樣的道理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/rawpixel-552390-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/PUyuhpHr9Z4?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資訊時代最常見的價值交換&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;給我你的關注，我就給你免費資訊（外加廣告）
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以經濟學的角度來重述前面的觀點，現在的資訊時代最不缺的資源就是「資料」；稀有、價值高且需要小心分配的稀有財是「人們的注意力」。在這個資訊爆炸的時代，企業透過加工處理大量的原始資料，產生新產品、服務及價值來換取該稀有財：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;誰能善用資料科學的力量、從現有數據創造新價值、服務或產品，並以此吸引人們珍貴的關注，就能獲得商機。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這就是為何資料科學那麼夯的其中一個原因：從資料中創造新價值，進而產生商業利益。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="啊所以那個資料科學勒？"&gt;啊所以那個資料科學勒？&lt;a class="anchor-link" href="#啊所以那個資料科學勒？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;聽到上面的例子，有些人的想法可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「哇這些企業好狡猾把我的注意力都偷走了！」&lt;/li&gt;
&lt;li&gt;「這樣回覆 +1 好有罪惡感喔嗚嗚」&lt;/li&gt;
&lt;li&gt;「好險我用 AdBlock 嘻嘻」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但這邊重點是要說明，這種依靠廣告的商業模式已經行之多年。Facebook、Google 等企業為了抓住我們的目光，持續不斷地在精進，以求能有效率地儲存、處理以及分析由我們產生的大量數據。&lt;/p&gt;
&lt;p&gt;而他們用來處理、分析、視覺化以及理解數據的這些程式語言、工具、方法論的總集合就構成所謂的資料科學。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;搜集、理解、分析、處理、視覺化資料數據並從中萃取有用的價值就是資料科學。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們以一個簡單的 Google 搜尋做更進一步的解釋。&lt;/p&gt;
&lt;p&gt;想像你在 Google 上搜尋「 data science courses 」後可能跑出以下結果：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/google.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Google 日常：搜尋結果之上有幾個相關廣告
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;沒什麼特別的，Google 日常不是嗎？&lt;/p&gt;
&lt;p&gt;現在試著做以下步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;開一個新的分頁/視窗&lt;/li&gt;
&lt;li&gt;隨便搜尋一個你有興趣的商品/產品，記下出現的幾個廣告還有它們的順序。&lt;/li&gt;
&lt;li&gt;隨便點幾個連結或者什麼都不做&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;重複步驟 2 跟 3 幾次以後，你應該可以觀察到顯示的廣告消失或者順序改變了：而這是因為背後有 Google 的廣告競價系統在運作。下面是這系統的超級簡化示意圖：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/google-bidding-system.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    Google 廣告競價：運用使用者的行為資料，即時地推算出該使用者點擊各廣告的機率。搭配業主的出價，選出適當的廣告顯示。
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要完成此系統需要強大的資料科學技術支持。只有一個人搜尋的時候事情還好辦，但你得知道，在本文撰寫當下，Google &lt;a href="http://www.internetlivestats.com/one-second/#google-band"&gt;平均 1 秒鐘處理 67, 000 筆&lt;/a&gt;搜尋。試著想像一下，為了實現這個系統，Google 可能需要完成以下幾件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用深度學習進行自然語言處理，判斷使用者輸入的語言以及想要表達什麼&lt;/li&gt;
&lt;li&gt;即時處理所有使用者查詢的串流數據&lt;/li&gt;
&lt;li&gt;利用使用者過往的瀏覽紀錄來預測點擊某廣告的機率&lt;/li&gt;
&lt;li&gt;在公司內部監控目前台灣使用者的搜尋趨勢（類似 &lt;a href="https://trends.google.com.tw/trends/"&gt;Google Trend&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;機器學習、統計分析、大數據 ... 這些工作運用到的技術，不就是那些我們在&lt;a href="#聽說你想當資料科學家？"&gt;聽說你想當資料科學家&lt;/a&gt;章節裡頭看到的關鍵字嗎？&lt;/p&gt;
&lt;p&gt;我們這篇只以 Google 的廣告系統為例，但實際上現在幾乎可以說是全世界都在想辦法利用資料科學的力量來處理資料並創造新的價值、服務、公司。看看現在的新創，有哪些沒有用到資料科學？&lt;/p&gt;
&lt;p&gt;所以你現在知道為何資料科學那麼重要了。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;全世界都在想辦法活用資料科學以從龐大數據中為使用者創造更多價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="充實你的資料科學力"&gt;充實你的資料科學力&lt;a class="anchor-link" href="#充實你的資料科學力"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;綜觀資料科學一詞萌芽到最近的過程，全世界的資料量&lt;a href="https://www.ithome.com.tw/article/87190"&gt;持續成長&lt;/a&gt;，而人們也不斷地在想辦法追趕這些資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用最有效率的方式儲存這些資料&lt;/li&gt;
&lt;li&gt;用最快的速度處理及分析這些資料&lt;/li&gt;
&lt;li&gt;對這些資料做實驗，重複再重複測試不同的假說及演算法&lt;/li&gt;
&lt;li&gt;快速地從資料萃取出新的洞見（Insight）&lt;/li&gt;
&lt;li&gt;以這些洞見創造新的價值、產品、服務&lt;/li&gt;
&lt;li&gt;加速以上步驟所需要的循環時間&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前面 Google 的例子，這些都是資料科學。&lt;/p&gt;
&lt;p&gt;你會發現，所謂的資料科學（Data Science）就是對資料（Data）做科學、有系統地（Scientific）的處理罷了。資料科學一詞或許誕生沒多久，但對資料做科學這概念老早就存在了。只是近年因為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;數據量的快速成長（如&lt;a href="http://technews.tw/2017/06/07/seagate-one-fifth-of-global-data-will-be-real-time-and-most-of-them-belongs-to-internet-of-things/"&gt;物聯網裝置的火紅&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;運算能力的進步&lt;/li&gt;
&lt;li&gt;人工智慧的突破&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等等原因，讓我們更急迫地想辦法用以往做不到的方式來理解這個世界的龐大數據。 &lt;a href="https://www.youtube.com/watch?v=F1wlCerC40E"&gt;Youtube 現在能夠分析出你喜歡看貓咪影片&lt;/a&gt;，&lt;a href="https://www.bnext.com.tw/article/49070/google-ai-phone-call-assistant-duplex-ethical-social-implications"&gt;Google 可以建立跟真人對話而不被發現的語音助理&lt;/a&gt;。這些都是他們利用資料科學，從現有的大量數據創造額外價值的例子。如同&lt;a href="https://www.safaribooksonline.com/library/view/what-is-data/9781449336080/ch01.html"&gt;這篇&lt;/a&gt;所說的：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;未來是屬於那些能從大量資料數據創造價值的企業以及人才的。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一個好消息是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一企業擁有的資料量&lt;/li&gt;
&lt;li&gt;一企業裡能夠處理、分析此資料量的資料科學人才數量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這兩者在多數企業都是不成比例的（後者短缺），因此擁有資料科學能力的人才薪水可以說是水漲船高。而這當然也變成為何近年那麼多人想成為資料科學家的動機（儘管有些人可能不知道背後原因）。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-science/stefan-stefancik-257625-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/UCZF1sXcejo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;了解資料科學相關知識的人才&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;是大多數的企業積極尋找的對象
    &lt;br/&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在了解這點以後，你可以先想想自己的興趣在哪裡、想用資料科學創造什麼價值。這邊想強調的是，先思考你能透過資料科學，創造什麼新的「價值」，而不是什麼「商業利益」。&lt;/p&gt;
&lt;p&gt;如同我們前面看到的，資料科學是現行廣告經濟的背後推手，但為何我們願意看 Google、Facebook 丟給我們的廣告？那是因為他們「先」從資料創造了價值（方便的搜尋功能、社群網路功能）從而取得我們的關注。&lt;/p&gt;
&lt;p&gt;實際上，在取得關注以後，你的商業模式不是一定要秀廣告給使用者看。訂閱制（Subscription）或會員制是一個替代方案： NetFlix 和 Amazon 都是這樣。甚至，你可以&lt;a href="https://www.bnext.com.tw/article/49041/google-fb-business-model"&gt;不像 Google 一樣思考&lt;/a&gt;，使用新的商業模型。&lt;/p&gt;
&lt;p&gt;但「商業模式」不是這篇想討論的議題。重點是「價值」：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資訊爆炸的時代，各行各業的每個人都需要學習善用資料科學，從資料數據創造新的使用者價值。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，與其想著要成為一個資料科學家，不如先好好想想，在自己目前所在的業界、公司、職位能怎麼利用手邊的資料數據搭配資料科學來創造新的價值。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果你耐心地看到這邊，代表我得到你最珍貴的關注了，賺賺賺！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;稍微複習一下，我們在這篇文章開頭假想了一個有志學習資料科學的同學。在他/她學習資料科學的過程產生了幾個疑問：「為何資料科學那麼夯？」「為何我們需要資料科學？」&lt;/p&gt;
&lt;p&gt;而本篇則以非常簡單的經濟學供給概念，加上 Google 以及 Facebook 的運作方式來說明現在的企業是怎麽利用資料科學來創造新的使用者價值來交換人們的關注。&lt;/p&gt;
&lt;p&gt;我們接著說著為何今後各行各業都需要「資料科學力」來處理日益增加的資料數據並為人們建立新的價值。事實上很多職稱不是「資料科學家」的人現在都已經在做著資料科學：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;搜集、理解、分析、處理、視覺化資料數據並從中萃取有用的價值&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當年網際網路開始蓬勃發展，軟體工程師是最夯最潮的行業。儘管現在工程師的重要性並沒有下降，隨著人們的程式能力穩定上升，軟體工程師回歸平凡，甚至還有人戲稱為「碼農」、「程式猿」。&lt;/p&gt;
&lt;p&gt;歷史總是不斷重演。&lt;/p&gt;
&lt;p&gt;或許再過幾年，等人們的資料科學力上升到一定階段，資料科學變成呼吸喝水般的知識以後，資料科學家們也會被人戲稱為「資料農」。&lt;/p&gt;
&lt;p&gt;或許當你幾年後遇到我，我可能這樣回你：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;嘿！我就只是個資料農！你也是嗎？&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category></entry><entry><title>為何資料科學家需要學習 SQL</title><link href="https://leemeng.tw/why-you-need-to-learn-sql-as-a-data-scientist.html" rel="alternate"></link><published>2018-04-30T23:50:00+09:00</published><updated>2018-04-30T23:50:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-30:/why-you-need-to-learn-sql-as-a-data-scientist.html</id><summary type="html">&lt;p&gt;這篇將簡單討論資料科學家必備的能力之一：結構化查詢語言（SQL）在概念上跟命令式程式語言如 Python 有什麼不同之處，以及在什麼樣的情況下我們會想要利用 SQL 做資料分析。這篇注重在為何你會想要使用 SQL 做資料分析，而非 SQL 本身功能的教學。如果要學習 SQL 本身，可以參考本文最後面的推薦閱讀。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇簡單討論&lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;結構化查詢語言（SQL）&lt;/a&gt;在概念上跟命令式程式語言如 Python 有什麼不同之處，以及在什麼樣的情況下我們會想要利用 SQL 做資料分析。&lt;/p&gt;
&lt;p&gt;這篇注重在為何你會想要使用 SQL 做資料分析，而非 SQL 本身功能的教學。如果要學習 SQL 本身，可以參考最後面的&lt;a href="#推薦閱讀"&gt;推薦閱讀&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用-SQL-與數據對話"&gt;使用 SQL 與數據對話&lt;a class="anchor-link" href="#使用-SQL-與數據對話"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;身為資料科學家或者是分析人員，我們都知道 SQL 基本上是必備的分析工具。&lt;/p&gt;
&lt;p&gt;簡單來說，&lt;a href="https://zh.wikipedia.org/wiki/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;SQL 是一種程式語言&lt;/a&gt;，我們可以透過它對被儲存在&lt;a href="https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93"&gt;關聯式資料庫&lt;/a&gt;裡頭的資料進行查詢或操作。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;SQL 是資料科學家與資料庫（Database）溝通的語言&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在沒接觸過 SQL 之前，你可能會想&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;「做為一個程式語言，為何 SQL &lt;a href="https://insights.stackoverflow.com/survey/2018/"&gt;有那麼多人在使用？&lt;/a&gt;」&lt;/li&gt;
&lt;li&gt;「我們有 Python、R，不學 SQL 應該也沒關係吧？」&lt;/li&gt;
&lt;li&gt;「又要學一個程式語言好麻煩。」&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為了釐清這些疑問，讓我們做一個假想實驗。比方說我們現在想要知道某個特定顧客過去的所有購買記錄。&lt;/p&gt;
&lt;p&gt;如果你熟悉 SQL 的話，可以對資料庫下一個簡單的查詢（Query）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;totalprice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt; 
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt; 
       &lt;span class="k"&gt;INNER&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt; 
       &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; 
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt; 
 &lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面這個查詢翻為白話就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從顧客清單 &lt;code&gt;customer&lt;/code&gt; 還有購賣紀錄 &lt;code&gt;orders&lt;/code&gt; 裡頭&lt;ul&gt;
&lt;li&gt;FROM customer AS c INNER JOIN orders AS o ON c.custkey = o.custkey&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;找出名為 Customer#000000001 的顧客的所有購買紀錄&lt;ul&gt;
&lt;li&gt;WHERE c.name = 'Customer#000000001'&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;並把那些紀錄依照購買日期排序&lt;ul&gt;
&lt;li&gt;ORDER BY o.orderdate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最後只回傳顧客名稱、總購買金額、購買日期幾個項目&lt;ul&gt;
&lt;li&gt;SELECT c.name AS customer, o.totalprice, o.orderdate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這個查詢對第一次寫 SQL 的人可能會覺得很複雜，但注意，我們並沒有告訴資料庫「如何」取得這些資料，比方說：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;怎麼合併顧客跟購買紀錄？&lt;/li&gt;
&lt;li&gt;怎麼過濾特定顧客？&lt;/li&gt;
&lt;li&gt;怎麼排序？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們只告訴它該給我們「什麼資料」。而得到的結果是：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;customer            | totalprice | orderdate
--------------------+------------+------------
 Customer#000000001 |  152411.41 | 1993-06-05
 Customer#000000001 |  165928.33 | 1995-10-29
 Customer#000000001 |  270087.44 | 1997-03-04
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如同我們預期，只有該顧客的購買紀錄被回傳，且依照購買日期 &lt;code&gt;orderdate&lt;/code&gt; 從早排到晚。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上，資料庫可能需要做以下運算來取得資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將顧客表格 &lt;code&gt;customer&lt;/code&gt; 以及購買紀錄的表格 &lt;code&gt;orders&lt;/code&gt; 分別命名為 &lt;code&gt;c&lt;/code&gt; 及 &lt;code&gt;o&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;依照共通的鍵值 &lt;code&gt;custkey&lt;/code&gt; 合併（&lt;code&gt;JOIN&lt;/code&gt;）兩表格&lt;/li&gt;
&lt;li&gt;找出特定顧客 &lt;code&gt;Customer#000000001&lt;/code&gt; 的購買記錄&lt;/li&gt;
&lt;li&gt;將該紀錄依照購買日期 &lt;code&gt;orderdate&lt;/code&gt; 排序&lt;/li&gt;
&lt;li&gt;選出要顯示的欄位 &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這些運算最後都得依照「某個」順序執行，但是我們不需要考慮這些事情，完全依靠資料庫的&lt;a href="http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf"&gt;查詢最佳化器（Query Optimizer）&lt;/a&gt;來幫我們決定。&lt;/p&gt;
&lt;p&gt;寫 SQL 敘述時，你可以理解成我們是指定「要的資料」，而查詢最佳化器會依照此需求，找出一個最佳路徑來取得必要的資料。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/sql/yoal-desurmont-619654-unsplash.jpg" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/pcLLI0MTDNg?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;&lt;/a&gt;
    SQL 查詢
    &lt;font color="purple"&gt;: &lt;/font&gt;專注在你的目標，查詢最佳化器會負責找到達成目標的最佳路徑
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;換句話說，當我們在寫 SQL 的時候，是在進行&lt;a href="https://zh.wikipedia.org/wiki/%E5%AE%A3%E5%91%8A%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;宣告式程式設計（Declarative Programming）&lt;/a&gt;：我們只告訴資料庫，我們想要什麼資料（What），而不是怎麼取得（How）它們。&lt;/p&gt;
&lt;p&gt;這跟一般常見的&lt;a href="https://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%BC%8F%E7%B7%A8%E7%A8%8B"&gt;命令式程式語言（Imperative Programming）&lt;/a&gt;如 Python、Java 有所不同。在寫 SQL 時，我們告訴資料庫它該達成的目標 - 取得什麼資料（What）；在寫 Python 時，我們得告訴程式該怎麼達成該目標（How）。&lt;/p&gt;
&lt;p&gt;為了進一步闡述這個概念，接著讓我們試著使用 Python 來取得跟上面的 SQL 查詢一樣的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用-Python-達到-SQL-查詢效果"&gt;用 Python 達到 SQL 查詢效果&lt;a class="anchor-link" href="#用-Python-達到-SQL-查詢效果"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;首先先假設所有顧客資料是透過一個 &lt;code&gt;list&lt;/code&gt; 儲存，裡頭包含多個 &lt;code&gt;dict&lt;/code&gt;。每個 &lt;code&gt;dict&lt;/code&gt; 則代表一個顧客的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Customer#000000001"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custkey"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Customer#000000002"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"custkey"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"2"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;而購買記錄則是一個 &lt;code&gt;dict&lt;/code&gt;，&lt;code&gt;dict&lt;/code&gt; 的鍵值為所有顧客的 &lt;code&gt;custkey&lt;/code&gt;；鍵值對應的值則是包含該顧客所有購買紀錄的 &lt;code&gt;list&lt;/code&gt;：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;"1"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;152411.41&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1993-06-05"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;270087.44&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1997-03-04"&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
          &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"totalprice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mf"&gt;165928.33&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"orderdate"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"1995-10-29"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
         &lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以 &lt;code&gt;orders["1"]&lt;/code&gt; 就代表 &lt;code&gt;custkey = 1&lt;/code&gt; 的顧客的購買紀錄。&lt;/p&gt;
&lt;p&gt;了解背後的資料結構以後，我們可以寫一段 Python 程式碼來取得資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"customer           | totalprice| orderdate "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"------------------ | ----------| --------- "&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 從所有顧客找符合條件的人&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="c1"&gt;# 跳過我們沒興趣的顧客&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'name'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;continue&lt;/span&gt;
    &lt;span class="c1"&gt;# 利用 custkey 取德該顧客的購買紀錄&lt;/span&gt;
    &lt;span class="n"&gt;c_orders&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'custkey'&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 依照 orderdate 排序購買紀錄&lt;/span&gt;
    &lt;span class="n"&gt;c_orders_sorted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c_orders&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'orderdate'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    
    &lt;span class="c1"&gt;# 將所有排序後的記錄回傳&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;c_orders_sorted&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'name'&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'totalprice'&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'orderdate'&lt;/span&gt;&lt;span class="p"&gt;])]&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;" | "&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="c1"&gt;# 已經找到該顧客，提早結束迴圈以減少處理時間&lt;/span&gt;
    &lt;span class="k"&gt;break&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;customer           | totalprice| orderdate 
------------------ | ----------| --------- 
Customer#000000001 | 152411.41 | 1993-06-05
Customer#000000001 | 165928.33 | 1995-10-29
Customer#000000001 | 270087.44 | 1997-03-04
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所以我們使用 Python 達到跟上面的 SQL 查詢一樣的結果了。但兩者在執行上有什麼差異？&lt;/p&gt;
&lt;p&gt;使用命令式程式語言來處理資料時，我們需要：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解資料結構以操作資料（顧客是存在 &lt;code&gt;list&lt;/code&gt; 還是 &lt;code&gt;dict&lt;/code&gt; ？）&lt;/li&gt;
&lt;li&gt;明確地定義執行步驟（先排序購買記錄 &lt;code&gt;orders&lt;/code&gt; 還是先把顧客 &lt;code&gt;customers&lt;/code&gt; 跟購買紀錄合併？）&lt;/li&gt;
&lt;li&gt;最佳化（如最後的 &lt;code&gt;break&lt;/code&gt; ）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;再看一次先前的 SQL 查詢（+註解）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;-- 給我以下幾個欄位：顧客名稱、總購買金額、購買日期&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;totalprice&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
       &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;
&lt;span class="c1"&gt;-- 將有相同 custkey 的顧客跟購買紀錄合併&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customer&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;
       &lt;span class="k"&gt;INNER&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;orders&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;
       &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;custkey&lt;/span&gt;
&lt;span class="c1"&gt;-- 只需要此顧客的購買紀錄&lt;/span&gt;
 &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="k"&gt;c&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Customer#000000001'&lt;/span&gt;
&lt;span class="c1"&gt;-- 依照購買日期排序&lt;/span&gt;
 &lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;orderdate&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;這裡頭我們不需要了解資料被以什麼形式儲存，也不需要定義要以什麼順序執行查詢，更不用做最佳化。這些事情全部交給背後的資料庫處理，使得資料科學家可以專注在更高層次的問題：「我們需要什麼資料？」&lt;/p&gt;
&lt;p&gt;而這正是 SQL 最強大的地方：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;SQL 讓資料科學家可以專注在需要「什麼」資料而非要「怎麼」取得。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;雖然我們這篇只舉了一個十分簡單的例子，但一般來說 SQL 非常適合以下的使用情境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將多個資料來源（例：表格）合併起來並依照一些條件篩選結果&lt;/li&gt;
&lt;li&gt;依照取得的資料做一些簡易的 aggregation （如：加總、平均、最大值）&lt;/li&gt;
&lt;li&gt;簡單的資料轉換（例：把 datetime 欄位取出年份）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果需要十分複雜的資料轉換或者計算時，一般我還是推薦使用 Python 或 R。但是下次當你有機會使用 SQL 取得想要的資料時，不妨試著專注在「想要什麼資料」而不是「怎麼取得資料」。說不定一個 SQL 查詢就能幫你省下一些花在搜集資料的時間。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="推薦閱讀"&gt;推薦閱讀&lt;a class="anchor-link" href="#推薦閱讀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/intro-to-sql-for-data-science"&gt;DataCamp - Intro to SQL for Data Science&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/joining-data-in-postgresql"&gt;DataCamp - Joining Data in PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/learning/advanced-sql-for-data-scientists"&gt;LinkedIn Learning - Advanced SQL for Data Scientists&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="SQL"></category><category term="data-science"></category></entry><entry><title>資料科學家為何需要了解資料工程</title><link href="https://leemeng.tw/why-you-need-to-learn-data-engineering-as-a-data-scientist.html" rel="alternate"></link><published>2018-04-23T22:55:00+09:00</published><updated>2018-04-23T22:55:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-23:/why-you-need-to-learn-data-engineering-as-a-data-scientist.html</id><summary type="html">&lt;p&gt;透過描述資料科學家的一天日常，本文將簡單介紹資料工程（Data Engineering）的概念、其如何跟資料科學相關。以及最重要的，作為一個資料科學家應該如何學習並善用這些知識來創造最大價值。身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;透過描述資料科學家的一天日常，本文將簡單介紹資料工程（Data Engineering）的概念、其如何跟資料科學相關。以及最重要的，作為一個資料科學家（Data Scientist）應該如何學習並善用這些知識來創造最大價值。&lt;/p&gt;
&lt;p&gt;身為一個資料科學家，擁有資料工程的知識可以提升工作效率，點亮你的方向並加速專案前進。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料科學家的一天"&gt;資料科學家的一天&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料準備"&gt;資料準備&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#第一挑戰：資料量大增"&gt;第一挑戰：資料量大增&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#第二挑戰：非結構化資料"&gt;第二挑戰：非結構化資料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料為本"&gt;資料為本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料管道"&gt;資料管道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料倉儲"&gt;資料倉儲&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料湖"&gt;資料湖&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#如何實際應用資料工程？"&gt;如何實際應用資料工程？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料科學家的一天"&gt;資料科學家的一天&lt;a class="anchor-link" href="#資料科學家的一天"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;一說到資料科學，在你腦海中浮現的幾個關鍵字可能是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料分析&lt;/li&gt;
&lt;li&gt;資料視覺化&lt;/li&gt;
&lt;li&gt;A.I. / 機器學習&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;等為人津津樂道的面向。&lt;/p&gt;
&lt;p&gt;的確，這些都在資料科學的範疇裡頭，但實際上佔用多數資料科學家大部分時間，卻常被忽略的部分是資料準備：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/data-scientist-work-pie-chart.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#5d0184f76f63" target="_blank"&gt;Forbes&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;依據調查，多數資料科學家花 80 % 的時候在準備資料
    &lt;br/&gt;
&lt;/center&gt;&lt;h3 id="資料準備"&gt;資料準備&lt;a class="anchor-link" href="#資料準備"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;說到資料準備，你可能會聯想到我們在前一篇&lt;a href="data-visualization-from-matplotlib-to-ggplot2.html#載入資料-+-簡單資料處理"&gt;淺談資料視覺化以及 ggplot2 實踐&lt;/a&gt;裡頭，使用 R 語言做的簡單資料清理：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 將 CSV 檔案載入成資料框架（dataframe）&lt;/span&gt;
ramen_all &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"datasets//ramen-ratings.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# 將「星星數」轉成定量資料&lt;/span&gt;
ramen_all&lt;span class="o"&gt;$&lt;/span&gt;Stars &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kp"&gt;as.numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="o"&gt;$&lt;/span&gt;Stars&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="c1"&gt;# Subset 資料&lt;/span&gt;
ramen &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ramen_all &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  filter&lt;span class="p"&gt;(&lt;/span&gt;Country &lt;span class="o"&gt;%in%&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="p"&gt;,&lt;/span&gt; Country&lt;span class="p"&gt;,&lt;/span&gt; sort &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; drop&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  filter&lt;span class="p"&gt;(&lt;/span&gt;Style &lt;span class="o"&gt;%in%&lt;/span&gt; count&lt;span class="p"&gt;(&lt;/span&gt;ramen_all&lt;span class="p"&gt;,&lt;/span&gt; Style&lt;span class="p"&gt;,&lt;/span&gt; sort &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; drop&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在做分析之前，我們做了以下的步驟來準備資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;讀進&lt;code&gt;ramen-ratings.csv&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;轉變某些欄位的資料型態&lt;/li&gt;
&lt;li&gt;依照一些條件取出想要分析的資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然資料量不大，你仍然可以試著想像我們實際上建立了一個 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將資料從來源（硬碟）擷取出來（&lt;strong&gt;E&lt;/strong&gt;xtract）&lt;/li&gt;
&lt;li&gt;做了一些轉換（&lt;strong&gt;T&lt;/strong&gt;ransform）&lt;/li&gt;
&lt;li&gt;載入（&lt;strong&gt;L&lt;/strong&gt;oad）目的地（記憶體）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;假設我們把一般的資料分析專案分為以下兩階段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;資料準備：將資料轉換成適合分析的格式&lt;/li&gt;
&lt;li&gt;資料分析：探索資料、建構預測模型&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上面的 ETL 就屬於第一個步驟。又因為此資料集大概只包含 5,000 筆資料，步驟 1 所花的時間跟步驟 2 的所需時間相比，可以說微乎其微，它不會是你做資料科學的一個 bottleneck。&lt;/p&gt;
&lt;p&gt;但如果你要處理的資料量是這個的 1,000 倍大呢？你還能馬上進入分析階段嗎？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第一挑戰：資料量大增"&gt;第一挑戰：資料量大增&lt;a class="anchor-link" href="#第一挑戰：資料量大增"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;實際上一個資料科學家每天需要分析的資料量可能要乘上幾個級數。現在假設你從銷售部門拿到一個包含數百萬筆銷售紀錄，大小為 60G 的 CSV 檔案，我想你應該不會想要直接打開它，即使它在某些人眼裡還不夠資格稱為大數據 (&amp;acute;；&amp;omega;；｀)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你殫精竭慮，最後決定去問公司內一位資深的&lt;a href="https://medium.freecodecamp.org/the-rise-of-the-data-engineer-91be18f1e603"&gt;資料工程師（Data Engineer）&lt;/a&gt;該怎麼解決這問題。&lt;/p&gt;
&lt;p&gt;該仁兄施了點你不曉得的魔法，過了幾分鐘從 Slack 丟來個神秘的 URL。連到上面，你發現熟悉的 &lt;a href="http://jupyter.org/"&gt;Jupyter Nook&lt;/a&gt; 介面，而且 CSV 還幫你載好了 &amp;Sigma;(ﾟдﾟ;&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/jupyter-notebook.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.ithome.com.tw/news/121497" target="_blank"&gt;Bonus&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;Jupyter Lab 是 Jupyter Notebook 的改善版，大推
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;你開心地在資料工程師幫你搞定的機器上做出分析，最後在大家面前做口頭報告。大家針對報告的反應不錯，但坐在底下的廣告部門的人這時候提問了：&lt;/p&gt;
&lt;p&gt;「可以把這些銷售紀錄跟廣告點擊的串流日誌（log）合在一起分析嗎？這樣我們會有更多有趣的結果！」&lt;/p&gt;
&lt;p&gt;你的頭又痛了起來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="第二挑戰：非結構化資料"&gt;第二挑戰：非結構化資料&lt;a class="anchor-link" href="#第二挑戰：非結構化資料"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;除了資料量級的差異，一個資料科學家在企業裡頭會遇到的另外一個挑戰是非結構化資料（Unstructured Data）的快速增加。你如何將各種不同格式（JSON、存取日誌、CSV 等）的資料以有效率的方式跟平常熟悉的關聯式資料庫如 &lt;a href="https://www.postgresql.org/"&gt;PostgreSQL&lt;/a&gt; 裡頭的資料結合以供分析？&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/increasing-dark-data.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.slideshare.net/AmazonWebServices/how-to-build-a-data-lake-with-aws-glue-data-catalog-abd213r" target="_blank"&gt;AWS Reinvent&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;非結構化資料快速增加，但因為不存在關聯式資料庫裡，無法直接被拿來分析
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;如果我們能寫一個簡單的 &lt;a href="https://zh.wikipedia.org/wiki/SQL"&gt;SQL&lt;/a&gt; 查詢，把銷售資料（sales）跟廣告點擊（clicks）資料依照共有的鍵值 &lt;code&gt;sale_id&lt;/code&gt; 合起來該有多好：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT *
FROM sales AS s
INNER JOIN clicks AS c
ON s.sale_id = c.sale_id&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;你想著想著就到下班時間了。&lt;/p&gt;
&lt;p&gt;「算了，還是先回家睡個覺，明天再厚著臉皮問資料工程師吧！反正之前他也幫我在&lt;a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%80%89%E5%84%B2"&gt;資料倉儲（Data Warehouse）&lt;/a&gt;加了新的表格。」&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料為本_1"&gt;資料為本&lt;a class="anchor-link" href="#資料為本"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;從上面這個資料科學家的一天，我們得到什麼啟示？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料（的基礎設施）為資料科學之基礎 - 巧婦難為無米之炊&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;老實說這個例子裡頭的資料科學家已經非常幸運：公司裡有資料工程師能幫他把大量、複雜格式的資料做 ETL 並以資料倉儲中的一個新表格（Table）的方式呈現轉換過後的資料以供他使用。硬要說稍微不方便的地方，頂多就是該資料科學家得等資料工程師搞定好資料就是了。&lt;/p&gt;
&lt;p&gt;然而因為資料工程師是一個很新的職位，多數的企業現在並沒有這樣的人存在。大多數的資料科學家只能自己下海，想辦法生出可以用的資料。實際上，&lt;a href="https://hackernoon.com/@mrogati?source=post_header_lockup"&gt;Monica Rogati&lt;/a&gt; 在 &lt;a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007"&gt;The AI Hierarchy of Needs&lt;/a&gt; 提到，一些常見的資料科學專案像是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建置 AI &lt;/li&gt;
&lt;li&gt;建置簡單的機器學習模型&lt;/li&gt;
&lt;li&gt;資料分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都得建立在「有完善且可靠的資料」這個基礎之下：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/ai-need.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007" target="_blank"&gt;資料科學的金字塔層級要求&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;你需要建立好資料科學的基礎設施才有本錢往「上」發展
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以金字塔最下三層為例，要讓資料科學的專案順利進行，你最少要（由下而上）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;持續搜集（COLLECT）原始資料&lt;/li&gt;
&lt;li&gt;將該資料轉移（MOVE / STORE）到適合分析的地方如資料倉儲、&lt;a href="https://itw01.com/G4DCESL.html"&gt;資料湖&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;轉換（TRANSFORM）被轉移的資料，進行前處理以方便分析&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我認爲資料工程的重頭戲在上面的 2, 3 點：將資料以「轉換好」的形式「送」到可供分析的地方。（當然也可以先送再轉換，或者不轉換，詳見下面章節的&lt;a href="#資料湖"&gt;資料湖&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;身為資料科學家，如果你夠幸運，公司內部有專業的資料工程師幫你把上面這件事情做好，恭喜！你可以多專注在分析以及建置預測模型上面；
但假設公司裡頭只有資料科學家，而企業又想要處理大數據的話，抱歉，你得擔起這個攤子，想辦法把資料的基本設施搞定：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;每個成功的資料科學家背後都有個偉大的資料工程師。或者該資料科學家就是那個資料工程師。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為資料科學家，如果我們也能了解資料工程相關的知識的話，不就能更快地、更有效率地進行資料分析了嗎？&lt;/p&gt;
&lt;p&gt;這個想法即是所謂的&lt;a href="http://www.effectiveengineer.com/blog/master-adjacent-disciplines"&gt;從鄰近專業（Adjacent Disciplines）學習&lt;/a&gt;：透過學習跟本業息息相關的資料工程，資料科學家可以加速資料科學的專案進行，並為個人以及團隊創造更大價值。想閱讀更多，可以看看&lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7"&gt;在 Airbnb 工作的資料科學家怎麼說&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;接著讓我們稍微聊聊到底什麼是資料工程以及一些相關例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料管道"&gt;資料管道&lt;a class="anchor-link" href="#資料管道"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;依照前面的論述，資料工程最主要的目的就是建構資料科學的基本設施（Infrastructure）。而這些基礎設施裡頭一個很重要的部分是&lt;a href="https://www.alooma.com/answers/what-is-the-difference-between-a-data-pipeline-and-an-etl-pipeline"&gt;資料管道（Data Pipeline）&lt;/a&gt;的建置：將資料從來源 &lt;strong&gt;S&lt;/strong&gt;ource 導向目的地 
&lt;strong&gt;T&lt;/strong&gt;arget 以供之後的利用。有必要的話，對資料進行一些轉換。&lt;/p&gt;
&lt;p&gt;一些簡單的例子像是我們之前部落格提到的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html"&gt;將 NoSQL（MongoDB） 資料導向資料倉儲（Redshift）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="use-kinesis-streams-and-firehose-to-build-a-data-lake.html"&gt;將串流資料（Kinesis）導向資料湖（AWS S3）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;從上面的例子也可以看到，實際上資料管道是一個涵蓋範圍很廣的詞彙，包含&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;即時的串流資料處理&lt;/li&gt;
&lt;li&gt;Batch 處理（如：每 12 小時作一次）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ETL 做的事情跟資料管道類似，但偏重在 Batch 處理，這篇文章將 ETL 視為資料管道裡頭的一個子集。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/etl-flow.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://robinhood.engineering/why-robinhood-uses-airflow-aed13a9a90c8" target="_blank"&gt;ETL&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;從資料來源擷取、轉換資料並將其導入目的地
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料的來源或目的地可以是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;分散式檔案儲存系統（如 &lt;a href="https://zh.wikipedia.org/wiki/Apache_Hadoop"&gt;HDFS&lt;/a&gt;、&lt;a href="https://aws.amazon.com/tw/s3/"&gt;AWS S3&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;一般的資料庫 / 資料倉儲（如 &lt;a href="https://aws.amazon.com/tw/redshift/getting-started/"&gt;AWS Redshift&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ETL 最重要的是轉換步驟，一些常見的轉換包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;改變欄位名稱&lt;/li&gt;
&lt;li&gt;去除空值（Missing Value）&lt;/li&gt;
&lt;li&gt;套用商業邏輯，事先做資料整合（Aggregate）&lt;/li&gt;
&lt;li&gt;轉變資料格式（例：從 JSON 到適合資料倉儲的格式如 &lt;a href="https://parquet.apache.org/"&gt;Parquet&lt;/a&gt;）&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/man-on-data-pipeline.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://unsplash.com/photos/xNdPWGJ6UCQ?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank"&gt;資料工程師&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;建構資料管道以讓大量的資料可供分析
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;這些轉換都是為了讓之後使用資料的資料科學家們能更輕鬆地分析資料。為了建置可靠的資料管道 / ETL 流程，我們常會需要使用一些管理工具像是 &lt;a href="https://airflow.apache.org/"&gt;Airflow&lt;/a&gt;、 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 以確保資料的處理如同我們預期。&lt;/p&gt;
&lt;h3 id="一些關鍵技術"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Hadoop 生態環境&lt;/li&gt;
&lt;li&gt;分散式系統上的 ETL 設計&lt;/li&gt;
&lt;li&gt;SQL-on-Hadoop 的專案了解（如 Apache Hive, Spark SQL, Fackbook Presto）&lt;/li&gt;
&lt;li&gt;資料流程管理（如 Airflow、AWS Glue）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;那經過資料管道處理後的資料要怎麼存取/分析？依照存取方式的不同，資料管道的架構方式也會有所不同。&lt;/p&gt;
&lt;p&gt;而存取資料的方式大概可以分為兩種：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7"&gt;資料倉儲（Data Warehousing）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://itw01.com/G4DCESL.html"&gt;資料湖（Data Lake）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料倉儲_1"&gt;資料倉儲&lt;a class="anchor-link" href="#資料倉儲"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料倉儲的概念就跟實際的倉儲相同：你在這邊將原料（原始資料）轉化成可以消化的產品（資料庫裡頭的經過整理的一筆筆紀錄）並存起來方便之後分析。&lt;/p&gt;
&lt;p&gt;這邊最重要的概念是：為了方便商業智慧的萃取，在將資料放入資料倉儲前，資料科學家 / 資料工程師需要花很多的心力決定資料庫綱目（Database Schema）要長什麼樣子。
也就是說資料庫的綱要（Schema）在建立資料管道的時候就已經被決定了：這種模式稱之為 Schema-on-Write。這是為了確保資料在被放進資料倉儲的時候就已經是可以分析的形式，方便資料科學家分析。&lt;/p&gt;
&lt;p&gt;你可以想像資料工程師在建構資料管道 / ETL 的時候，得對原始資料做大量的轉換以讓資料在被&lt;strong&gt;寫&lt;/strong&gt;入資料倉儲時就已經符合一開始定義的 Schema。而資料倉儲最常被拿來使用的一個資料模型（Data Model）是所謂的 &lt;a href="https://en.wikipedia.org/wiki/Dimensional_modeling"&gt;Dimensional Modeling&lt;/a&gt;（Stars / Snowflaks Schema）。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/star-schema.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="http://publib.boulder.ibm.com/tividd/td/TEDW/SC32-1497-00/en_US/HTML/srfmst158.htm" target="_blank"&gt;資料倉儲最被廣泛使用的 Data Model&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;Stars Schema
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;資料工程師將企業最重要的事件（如：使用者下了訂單、發了一個 Facebook 動態）放到最中間的 Fact Table，並且為了可以使用所有想像得到的維度來分析這些事件，會把事件本身的維度（Dimensions）再分別存在外圍的多個 Dimension Tables。常見的維度有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;時間（此事件什麼時候產生、年月份、星期幾等）&lt;/li&gt;
&lt;li&gt;商品的製造商的資料、其他細節&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因為看起來就像是一個星星，因此被命名為 Stars Schema。Snowflakes 則是其變形。&lt;/p&gt;
&lt;h3 id="一些關鍵技術_1"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;在資料倉儲的部分，關鍵的技術與概念有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;了解正規化（Normalization）的好處&lt;/li&gt;
&lt;li&gt;分散式 SQL 查詢引擎的原理（如 &lt;a href="https://prestodb.io/"&gt;Presto&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;分析專用的資料模型的設計原理（如 Stars / Snowflakes schema）&lt;/li&gt;
&lt;li&gt;了解分散式系統背後各種 JOIN 的原理（Sort-Merge JOINs、Broadcast Hash JOINs、Paritioned Hash JOINs 等）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料湖_1"&gt;資料湖&lt;a class="anchor-link" href="#資料湖"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;「每天新增的資料量太多，要把所有想分析的資料都做詳細的 Schema 轉換再存入資料倉儲太花人力成本。總之先把這些資料原封不動地存到分散式檔案儲存系統上，之後利用如 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 等服務將資料的 schema 爬出來並分析。」這就是以資料湖為核心的資料管道架構想法。一般這種存取資料的方式我們稱之為 Schema-on-Read，因為 Schema 是在實際載入原始資料的時候才被使用。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aws.amazon.com/tw/athena/"&gt;AWS Athena&lt;/a&gt; 就是一個 AWS 依照這樣的想法打造的服務。&lt;/p&gt;
&lt;p&gt;舉個簡單的例子，假設我們現在想把&lt;a href="#資料科學家的一天"&gt;資料科學家的一天&lt;/a&gt;提到的銷售資料以及廣告資料合併起來做分析，在 AWS 上我們可以實作一個這樣的資料管道：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/data-lake-example.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    利用 AWS Athena 及 AWS Glue 實作以資料湖為基礎的分析架構
    &lt;font color="purple"&gt;: &lt;/font&gt;即時合併並分析不同格式的資料
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;我們將存在關聯式資料庫的銷售資料透過 ETL 存到資料湖（AWS S3）裡頭以後，利用 AWS Glue 將資料的中繼資料（Meta Data）存在資料目錄（Data Catalogue）底頭。常見的中繼資料有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表格定義（有哪些欄位，如：&lt;code&gt;sale_id&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;各個欄位的資料型態&lt;/li&gt;
&lt;li&gt;各個欄位實際在原始資料（如 CSV ）裡頭的排列順序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接著我們就可以利用提到的 SQL 查詢把銷售資料跟廣告資料合併：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT *
FROM sales AS s
INNER JOIN clicks AS c
ON s.sale_id = c.sale_id&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;收到以上的 SQL 查詢，Athena 會分別把銷售資料以及廣告資料依照對應的資料目錄解析資料後合併再回傳結果給我們。&lt;/p&gt;
&lt;p&gt;我認為今後這種以資料湖為基礎的分析架構會越來越熱門，原因如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;非結構化資料量越來越大，花費人力在事前為資料倉儲建立完整的 schema 越來越不實際&lt;/li&gt;
&lt;li&gt;分散式 SQL 查詢服務像是 Athena 抽象化複雜的資料格式，允許資料科學家下 SQL 查詢做 ad-hoc 分析&lt;/li&gt;
&lt;li&gt;透過 Parquet / ORC 等資料格式來自動減少資料湖沒有做正規化而導致的效能損失&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="一些關鍵技術_2"&gt;一些關鍵技術&lt;a class="anchor-link" href="#一些關鍵技術"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;雖然再過幾年，等到資料工程的人才增加，資料科學家或許可以完全不用介意背後的資料基礎設施的建置，但近幾年這部分可能還是要靠資料科學家自己實作。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料湖的概念&lt;/li&gt;
&lt;li&gt;AWS Glue + AWS Athena 的運用（Bonus: Serverless 分析架構，不需管理機器）&lt;/li&gt;
&lt;li&gt;Hive MetaData Store&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在資料湖的例子我主要都用 AWS 的服務來舉例，但你可以自由使用其他雲端服務或者 Hadoop。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="如何實際應用資料工程？_1"&gt;如何實際應用資料工程？&lt;a class="anchor-link" href="#如何實際應用資料工程？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;首先你得先了解目前環境的資料基礎設施。而為了釐清這點，你可以問自己或者相關人員以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料科學的金字塔，我們建到哪一層了？&lt;/li&gt;
&lt;li&gt;我們過去有哪些專案是在取得、準備資料階段就陷入瓶頸？&lt;/li&gt;
&lt;li&gt;我們有專業的資料工程師或相關人員在做資料倉儲或者是資料湖的準備嗎？&lt;/li&gt;
&lt;li&gt;我們的資料是儲存在什麼分散式檔案儲存系統上面？ HDFS 還是 S3？&lt;/li&gt;
&lt;li&gt;我們是怎麼管理/監管 ETL 工作的？ 要考慮用 Airflow 嗎？&lt;/li&gt;
&lt;li&gt;要建構一個新的資料管道的話，要自己架 Hadoop 群集還是使用雲端服務？&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在你思考過以上幾個問題以後，你就會發現為何過往有些資料科學的專案進展緩慢了。這時候與其一直在等待資料的到來，你可以把你想到的幾個問題拿去跟相關的工程師討論。相信我，從你開口跟他們討論如何解決資料基礎設施的瓶頸這點開始，他們將不再視你為「那個只想要拿到資料」的敵人，而是同伴。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/data-engineering/hadoop-framework.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://medium.com/@ssola/becoming-a-data-engineer-5e0f14048d42" target="_blank"&gt;Hadoop 的分散式基礎設施&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;要學的東西太多，不如就用雲端服務吧
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;假如很不幸，你們公司沒有專業的工程師，而你得自己想辦法兜出一個可以處理這些大量資料的方法，我會建議先從現存的全受管（Full-Managed）雲端服務找能解決痛點的方案。&lt;/p&gt;
&lt;p&gt;使用現成的雲端服務來建置資料基礎有幾個好處：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pay-as-you-go，通常是用多少花多少&lt;/li&gt;
&lt;li&gt;Proof-of-concept，你可以直接開始嘗試建立最重要的商業邏輯而非架機器&lt;/li&gt;
&lt;li&gt;Serverless 架構，不需管理機器（如 AWS Glue + Athena）&lt;/li&gt;
&lt;li&gt;導入成本降低（相較於自己架 Hadoop Cluster）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我嘗試在這篇文章說明資料工程對資料科學家的重要，以及你可以如何開始學習資料工程。&lt;/p&gt;
&lt;p&gt;在這個大數據時代，資料科學家的價值在於找出「大量」資料背後的潛在價值，不要反而讓「資料量太多」這邊成了你最大的限制。
從雲端服務開始，多學一點資料工程，讓你的資料科學專案前進地更快吧！&lt;/p&gt;
&lt;p&gt;如果你有任何想法想要提出或分享，都歡迎在底下留言或者透過社群網站聯絡我 B-)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="資料工程"></category><category term="data-science"></category><category term="data engineering"></category></entry><entry><title>淺談資料視覺化以及 ggplot2 實踐</title><link href="https://leemeng.tw/data-visualization-from-matplotlib-to-ggplot2.html" rel="alternate"></link><published>2018-04-14T15:10:00+09:00</published><updated>2018-04-14T15:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-14:/data-visualization-from-matplotlib-to-ggplot2.html</id><summary type="html">&lt;p&gt;這篇主要描述自己以往在利用 Python 做資料視覺化時常犯的思維瑕疵，而該思維如何在接觸 R 的 ggplot2 以後得到改善。本文會試著說明資料視覺化的本質為何，以及在設計視覺化時，概念上應該包含什麼要素以及步驟。最後展示如何透過 ggplot2 活用前述的概念，來實際做資料視覺化。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇主要描述自己以往在利用 Python 做資料視覺化 (data visualization) 時常犯的思維瑕疵，而該思維如何在接觸 R 的 &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt; 以後得到改善。&lt;/p&gt;
&lt;p&gt;本文會試著說明資料視覺化的本質為何，以及在設計視覺化時，概念上應該包含什麼要素以及步驟。最後展示如何透過 ggplot2 活用前述的概念，來實際做資料視覺化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="目錄"&gt;目錄&lt;a class="anchor-link" href="#目錄"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;文章內容大致上會分為以下幾個小節：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#資料視覺化應該是-.."&gt;資料視覺化應該是 ..&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ggplot2-實踐"&gt;ggplot2 實踐&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#結語"&gt;結語&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#References"&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;a class="anchor-link" href="#資料視覺化是資料與圖的直接映射？"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;身為一個 Python 起家的資料科學家，在做資料視覺化的時候，我很自然地使用 Python ecosystem 裡像是 &lt;a href="https://matplotlib.org/"&gt;matplotlib&lt;/a&gt; 以及 &lt;a href="https://seaborn.pydata.org/"&gt;seaborn&lt;/a&gt; 等繪圖 packages。針對手中的資料，我會想辦法找到一個「對應」的圖然後把資料塞進去。簡單無腦 &lt;em&gt;(:3 」&amp;ang;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;舉例來說，當我們手上有三個變數 x, y, z 且其各自的資料型態為：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x: &lt;a href="https://zh.wikibooks.org/zh-hant/%E7%B5%B1%E8%A8%88%E5%AD%B8/%E7%B5%B1%E8%A8%88%E8%B3%87%E6%96%99"&gt;定量變數 (quantitative)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;y: 定量變數&lt;/li&gt;
&lt;li&gt;z: &lt;a href="https://zh.wikibooks.org/zh-hant/%E7%B5%B1%E8%A8%88%E5%AD%B8/%E7%B5%B1%E8%A8%88%E8%B3%87%E6%96%99"&gt;定性變數（categorical）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;則我們想要進行資料視覺化的時候有幾種選擇：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;想分析 x, y -&amp;gt; 都是定量資料 -&amp;gt; 散佈圖 (scatter plot)&lt;/li&gt;
&lt;li&gt;想分析 x, z -&amp;gt; 一定量一定性 -&amp;gt; 長條圖 (bar chart)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這，「資料視覺化」的定義是一種映射關係 (mapping)：也就是如何將資料直接對應到某個「特定」圖表形式（折線圖、散佈圖 etc.）。基本上這種映射關係在做簡單的分析的時候沒有什麼問題，但是當想要同時分析/呈現的變數超過兩個 （例： x &amp;amp; y &amp;amp; z ）的時候就不容易找到適合的圖。一個折衷的方法是我們把變數兩兩畫圖做比較，但這樣會侷限我們能分析的資料維度數目，錯過一些有趣的洞見。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料視覺化應該是-.."&gt;資料視覺化應該是 ..&lt;a class="anchor-link" href="#資料視覺化應該是-.."&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="先確認觀眾及目的"&gt;先確認觀眾及目的&lt;a class="anchor-link" href="#先確認觀眾及目的"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在完成一些 &lt;a href="#References"&gt;ggplot2 的 tutorials&lt;/a&gt; 後，可以發現資料視覺化一般依用途可以分為兩種：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;探索、了解資料特性&lt;/li&gt;
&lt;li&gt;說故事：將探索過後得到的洞見 (insight) 傳達給其他人&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/data-vis-purpose.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;搞清楚資料視覺化的目的以及觀眾是重要的第一步
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照目的以及觀眾的不同，資料視覺化的方式會有所不同。一個常見的例子是當我們第一次接觸某個資料集。這時候資料視覺化的觀眾是自己，目的是在最短的時間了解資料特性。則這時我們在做圖的時候的要求就可以很寬鬆，像是不加上標題，或是只要能做出自己能理解的視覺化即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="正式定義"&gt;正式定義&lt;a class="anchor-link" href="#正式定義"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在確認觀眾及目的以後，我們終於可以開始進行資料視覺化了！資料視覺化的定義因人而異，而這邊我想給出一個非常直觀的定義：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料視覺化是將資料中的變數映射到視覺變數上，進而有效且有意義地呈現資料的樣貌&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;一些常見且肉眼容易識別的視覺變數 / 刻度（visual variables / scales）包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;位置（x / y axis）&lt;/li&gt;
&lt;li&gt;顏色（color）&lt;/li&gt;
&lt;li&gt;大小（size）&lt;/li&gt;
&lt;li&gt;透明程度（alpha）&lt;/li&gt;
&lt;li&gt;填滿（fill）&lt;/li&gt;
&lt;li&gt;形狀（shape）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用更口語的方式來解釋：在做資料視覺化的時候，我們希望能將&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;肉眼難以分析的資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;對應到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;肉眼容易解讀的視覺元素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;透過這個映射關係，我們可以將原本的變數的數值變化也映射到視覺變數的變化。而因為我們人類容易區別視覺變數的變化（位置差異、大小長度變化 etc），我們能更容易地理解原始資料的樣貌、變化以及模式。&lt;/p&gt;
&lt;p&gt;舉例來說，我們可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把不同捷運路線（文湖線、板南線）對應到不同顏色&lt;/li&gt;
&lt;li&gt;把各國的 GDP 對應到點的大小&lt;/li&gt;
&lt;li&gt;把某個資料的年份對應到 Ｘ 軸，越右邊代表越接近現代&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="一個簡單例子"&gt;一個簡單例子&lt;a class="anchor-link" href="#一個簡單例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;事實上，我們可能平常每天都在做資料視覺化而不自知。比方說我們有一個數列 &lt;code&gt;y&lt;/code&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;2.055&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.132&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;0.522&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.229&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.013&lt;/span&gt; &lt;span class="o"&gt;..&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;光是看這個數字，肉眼無法看出什麼模式，但我們可以簡單畫個圖：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/simple-visual-encoding.png" style="width:70%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們利用視覺變數「Y軸位置」來呈現數值的變化，可以馬上看出數列裡頭的值都落在 -3 到 3 之間，而這是因為我們肉眼很容易辨別「位置」這個視覺變數的變化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="圖像的分層文法"&gt;圖像的分層文法&lt;a class="anchor-link" href="#圖像的分層文法"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在 &lt;a href="http://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf"&gt;A Layered Grammar of Graphics&lt;/a&gt; 裡頭，&lt;a href="http://hadley.nz/"&gt;Hadley Wickham&lt;/a&gt; 闡述所謂的圖像（包含由資料視覺化產生的圖像）實際上如同我們平常使用的語言，是有文法的。而其文法可以拆成 7 個部分（層）。前述的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始資料 = 資料層（Data）&lt;/li&gt;
&lt;li&gt;視覺變數層（Visual variables = Aesthetics）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;則恰好是這個架構裡頭最底下的兩層。視覺變數是我為了方便理解建立的名詞，在原文以及 ggplot2 裡頭被稱作 &lt;strong&gt;Aesthetics&lt;/strong&gt;。（中文翻作「美學」，當初看好久也無法理解啊 (╯&amp;deg;Д&amp;deg;)╯ ┻━┻）&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/layered-grammar-of-graphics.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: &lt;/font&gt;圖像的分層文法
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;看到這你一定會「哇靠那我每次畫個圖都要實作七層？」。實際上不需要，上面幾層像是主題（Theme）比較像是裝飾品，給我們更大的自由與彈性來訂製（customize）視覺化結果。在下一節我們會看到，ggplot2 會自動幫我們設定合適的主題或座標。（如果沒特別指定的話）&lt;/p&gt;
&lt;p&gt;但一般而言，一個圖像最基本的組成是底下三層。也就是除了前述的兩層（資料、視覺變數）以外還需要加上&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;幾何圖形層（Geometries）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為何還要這層？假如我們有了資料，決定了視覺變數（第二層，例：把資料中的變數 A 對應到 X 軸；變數 B 對應到 Y 軸）後，實際上就可以畫一個充滿點（point）的散佈圖了不是嗎？&lt;/p&gt;
&lt;p&gt;這樣的思維如同&lt;a href="#資料視覺化是資料與圖的直接映射？"&gt;資料視覺化是資料與圖的直接映射？&lt;/a&gt;部分所提到的，有所瑕疵。如果變數 A 是分類型變數（Categorical）的話，單純以&lt;strong&gt;點&lt;/strong&gt;為圖形的散佈圖就會變得十分難以理解（下圖左）；這時候以&lt;strong&gt;長條&lt;/strong&gt;為圖形（下圖右）的方式會比較清楚：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/ggplot2/make-geom-layer-independent.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
    獨立幾何圖形層
    &lt;font color="purple"&gt;: &lt;/font&gt;
&lt;br/&gt;讓資料視覺化不再侷限於「我要畫什麼圖」，而是「我想要怎麼畫」
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;將「幾何圖形」這個選擇獨立出來一層讓我們在資料視覺化的時候有更大的彈性。有了這些基本概念以後，我們可以開始嘗試使用 ggplot2 來實際做一些資料視覺化。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="ggplot2-實踐_1"&gt;ggplot2 實踐&lt;a class="anchor-link" href="#ggplot2-實踐"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在這個章節裡頭我們將使用 Kaggle 的 &lt;a href="https://www.kaggle.com/residentmario/ramen-ratings/data"&gt;Ramen Ratings&lt;/a&gt; 來做資料視覺化。這資料集紀錄了各國泡麵所得到的星星數。首先我們要先載入這次的主角：R 語言裡頭最著名的視覺化 package ggplot2。&lt;a href="http://yaojenkuo.io/r_programming/ch14#(1"&gt;dplyr&lt;/a&gt; 則是 R 語言用來處理資料的 package。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="載入-packages"&gt;載入 packages&lt;a class="anchor-link" href="#載入-packages"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ggplot2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dplyr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是它們都是同屬於 &lt;a href="https://medium.com/datainpoint/tidyverse-r-%E8%AA%9E%E8%A8%80%E5%AD%B8%E7%BF%92%E4%B9%8B%E6%97%85%E7%9A%84%E6%96%B0%E8%B5%B7%E9%BB%9E-3b01ca6a348c"&gt;TidyVerse&lt;/a&gt; 的一員。TidyVerse 是 R 裡頭常被用來做資料科學的 packages 的集合，以 Python 來說大概就像是 Pandas + Matplotlib + Numpy 的感覺吧。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="載入資料-+-簡單資料處理"&gt;載入資料 + 簡單資料處理&lt;a class="anchor-link" href="#載入資料-+-簡單資料處理"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;如下註解所示，這邊將資料集讀入，做一些簡單的資料型態轉變後選擇一部分的資料集（subset）來做之後的視覺化：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# 將 CSV 檔案載入成資料框架（dataframe）&lt;/span&gt;
&lt;span class="n"&gt;ramen_all&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"datasets//ramen-ratings.csv"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# 將「星星數」轉成定量資料&lt;/span&gt;
&lt;span class="n"&gt;ramen_all&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Stars&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;numeric&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen_all&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;Stars&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 

&lt;span class="c1"&gt;# Subset 資料，選擇拉麵數量前幾多的國家方便 demo&lt;/span&gt;
&lt;span class="n"&gt;ramen&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="n"&gt;ramen_all&lt;/span&gt; &lt;span class="o"&gt;%&amp;gt;%&lt;/span&gt;
  &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Country&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;% count(ramen_all, Country, sort = TRUE)[1:6, 1, drop=TRUE]) %&amp;gt;%
  &lt;span class="nb"&gt;filter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Style&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;in&lt;/span&gt;% count(ramen_all, Style, sort = TRUE)[1:4, 1 , drop=TRUE])
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;除了我們使用 dplyr 的 &lt;code&gt;filter&lt;/code&gt; 依照條件 subset 資料集以外，值得一提的是 pipe 運算子 &lt;code&gt;%&amp;gt;%&lt;/code&gt;。它是前面提到的 TidyVerse 裡頭的 packages 共享的介面（interface），將前一個函示的輸出當作下一個函式的輸入，讓我們可以把運算全部串（chain）在一起。在 Linux 裡頭就是如同 &lt;code&gt;|&lt;/code&gt; 的存在。&lt;/p&gt;
&lt;p&gt;而實際我們的資料長這樣：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea "&gt;
&lt;table class="table table-striped table-responsive"&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th scope="col"&gt;Review..&lt;/th&gt;&lt;th scope="col"&gt;Brand&lt;/th&gt;&lt;th scope="col"&gt;Variety&lt;/th&gt;&lt;th scope="col"&gt;Style&lt;/th&gt;&lt;th scope="col"&gt;Country&lt;/th&gt;&lt;th scope="col"&gt;Stars&lt;/th&gt;&lt;th scope="col"&gt;Top.Ten&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;2580                                                       &lt;/td&gt;&lt;td&gt;New Touch                                                  &lt;/td&gt;&lt;td&gt;T's Restaurant Tantanmen                                   &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;Japan                                                      &lt;/td&gt;&lt;td&gt;37                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2579                                                       &lt;/td&gt;&lt;td&gt;Just Way                                                   &lt;/td&gt;&lt;td&gt;Noodles Spicy Hot Sesame Spicy Hot Sesame Guan-miao Noodles&lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;Taiwan                                                     &lt;/td&gt;&lt;td&gt; 7                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2578                                                       &lt;/td&gt;&lt;td&gt;Nissin                                                     &lt;/td&gt;&lt;td&gt;Cup Noodles Chicken Vegetable                              &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;USA                                                        &lt;/td&gt;&lt;td&gt;16                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2577                                                       &lt;/td&gt;&lt;td&gt;Wei Lih                                                    &lt;/td&gt;&lt;td&gt;GGE Ramen Snack Tomato Flavor                              &lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;Taiwan                                                     &lt;/td&gt;&lt;td&gt;19                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2575                                                       &lt;/td&gt;&lt;td&gt;Samyang Foods                                              &lt;/td&gt;&lt;td&gt;Kimchi song Song Ramen                                     &lt;/td&gt;&lt;td&gt;Pack                                                       &lt;/td&gt;&lt;td&gt;South Korea                                                &lt;/td&gt;&lt;td&gt;47                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;2574                                                       &lt;/td&gt;&lt;td&gt;Acecook                                                    &lt;/td&gt;&lt;td&gt;Spice Deli Tantan Men With Cilantro                        &lt;/td&gt;&lt;td&gt;Cup                                                        &lt;/td&gt;&lt;td&gt;Japan                                                      &lt;/td&gt;&lt;td&gt;39                                                         &lt;/td&gt;&lt;td&gt; &lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="簡單資料視覺化"&gt;簡單資料視覺化&lt;a class="anchor-link" href="#簡單資料視覺化"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了資料，讓我們再確定一下資料視覺化的目的及觀眾：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：探索資料&lt;/li&gt;
&lt;li&gt;觀眾：我們自己&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這樣的條件讓我們知道視覺化的條件是快速做出結果，不需調整如標題、主題的設定。&lt;/p&gt;
&lt;p&gt;現在讓我們問一些簡單的問題。像是&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;泡麵的包裝（碗裝、袋裝等）各佔多少比例？&lt;/li&gt;
&lt;li&gt;不同國家各有多少泡麵在資料集裡頭？&lt;/li&gt;
&lt;li&gt;不同包裝的泡麵所得到的星星總數，在不同國家有什麼差異嗎？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中一種能解決第一個問題的資料視覺化是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAYAAACPNyggAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;ramen&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; Style&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; geom_bar&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;裡頭，我們實際上已經建構了圖表最基礎的三層元素：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料層： &lt;code&gt;ramen&lt;/code&gt; 告訴 ggplot2 使用此資料框架&lt;/li&gt;
&lt;li&gt;視覺變數層： &lt;code&gt;aes(x = Style)&lt;/code&gt; 告訴 ggplot2 我們將使用「 X 軸位置」這個視覺變數來反映泡麵包裝 &lt;code&gt;Style&lt;/code&gt; 這個變數的變化&lt;ul&gt;
&lt;li&gt;因為包裝的值有四種可能，你可以想像 ggplot2 已經準備好要幫你在 X 軸上的四個位置畫圖&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aes&lt;/code&gt; 是我們前面提到 &lt;strong&gt;aesthetics&lt;/strong&gt; 的縮寫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;幾何圖形層： &lt;code&gt;geom_bar()&lt;/code&gt; 告訴 ggplot 去計算對應到 &lt;code&gt;x&lt;/code&gt; 視覺變數的變數裡頭，所有值的出現次數後將結果以&lt;strong&gt;長條&lt;/strong&gt;來呈現&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我們通常透過 &lt;code&gt;+&lt;/code&gt; 來疊加不同層的結果。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="基本層數缺一不可"&gt;基本層數缺一不可&lt;a class="anchor-link" href="#基本層數缺一不可"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的例子很簡單，但假如我們沒有指定幾何圖形層的話，圖會長什麼樣子呢？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAYAAACPNyggAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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="/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就像我們剛剛所說的，雖然 ggplot2 已經知道要用什麼資料框架、要用什麼視覺變數，不知道要用什麼圖形表示的話就會是空白一張圖。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="另個簡單例子"&gt;另個簡單例子&lt;a class="anchor-link" href="#另個簡單例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;讓我們依樣畫葫蘆，來解決第二個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同國家各有多少泡麵在資料集裡頭？&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Country&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fill&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;coord_flip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAAHgCAYAAABq5QSEAAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
這邊有兩個值得注意的地方：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;除了基本的三層以外，我們透過 &lt;code&gt;+ coord_flip()&lt;/code&gt; 額外對座標層（Coordinates）做操作，請 ggplot2 把 x, y 軸互換。&lt;/li&gt;
&lt;li&gt;透過 &lt;code&gt;aes(..., fill = Style)&lt;/code&gt; 裡頭的 &lt;code&gt;fill = Style&lt;/code&gt; ，我們告訴 ggplot2 將長條圖裡頭的填滿空間（fill）這個視覺變數，依照泡麵包裝（Style）做變化&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第二點是在做資料視覺化的時候，想辦法增加&lt;a href="https://en.wikipedia.org/wiki/Edward_Tufte"&gt;資料墨水量（Data Ink Ratio）&lt;/a&gt;的例子。透過增加顯示在同張圖上的變數數目，進而提高該圖能傳達的訊息量。&lt;/p&gt;
&lt;p&gt;舉例而言，我們可以很明顯地看到，在這資料集裡頭，台灣的杯裝泡麵（Cup）沒有被記錄到多少；而日本被記錄到的泡麵量最多，且袋裝（Pack）數目最多。這些是在我們沒有用「填滿」這個視覺變數時無法察覺的。而在 ggplot2 裡，要實現這種視覺化非常容易。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="複雜例子"&gt;複雜例子&lt;a class="anchor-link" href="#複雜例子"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;讓我們解決最後一個問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不同包裝的泡麵所得到的星星總數，在不同國家有什麼差異嗎？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;資料視覺化一個有趣的地方就是：同個問題不同的人會有不同的做法。而針對這問題其中一種做法是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將包裝 &lt;code&gt;Style&lt;/code&gt; 對應到 X 軸、星星數 &lt;code&gt;Stars&lt;/code&gt; 對應到 Y 軸，然後使用長條 &lt;code&gt;geom_bar&lt;/code&gt; 顯示數值&lt;/li&gt;
&lt;li&gt;依照每個國家重複步驟一&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而 ggplot2 的實作為：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ggplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ramen&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;aes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Style&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Stars&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  &lt;span class="n"&gt;geom_bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"identity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; 
  &lt;span class="n"&gt;facet_wrap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="n"&gt;Country&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAYAAABfdxm0AAAEGWlDQ1BrQ0dDb2xvclNwYWNl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"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;br/&gt;
實際上在上面的程式碼裡頭，我們多操作了額外兩層：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;統計層（Statistics）：專門負責匯總資料&lt;/li&gt;
&lt;li&gt;小平面層（Facets）：依照選定的變數分別畫圖，如上述的步驟二&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;首先 ggplot2 的 &lt;code&gt;geom_bar&lt;/code&gt; 預設只需要 &lt;code&gt;x&lt;/code&gt; 視覺變數，因為匯總資料的統計層會把 x 依照不同的值分別計數（也就是各個包裝的數量），然後讓 &lt;code&gt;geom_bar&lt;/code&gt; 顯示。但我們並不希望 &lt;code&gt;geom_bar&lt;/code&gt; 使用這個數值，因此使用 &lt;code&gt;geom_bar&lt;/code&gt; 裡頭的 &lt;code&gt;stat = "identity"&lt;/code&gt; 是告訴統計層不要分別計數，而是使用我們給定的星星數 &lt;code&gt;y&lt;/code&gt; 。&lt;/p&gt;
&lt;p&gt;而 &lt;code&gt;facet_wrap( ~ Country)&lt;/code&gt; 則是告訴小平面層依照 &lt;code&gt;Country&lt;/code&gt; 這個變數重複畫&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ggplot&lt;span class="p"&gt;(&lt;/span&gt;ramen&lt;span class="p"&gt;,&lt;/span&gt; aes&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;=&lt;/span&gt; Style&lt;span class="p"&gt;,&lt;/span&gt; y &lt;span class="o"&gt;=&lt;/span&gt; Stars&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
  geom_bar&lt;span class="p"&gt;(&lt;/span&gt;stat &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;"identity"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意所有的圖的 x, y 軸都是一致的，方便我們做比較。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語_1"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料視覺化需要統計知識以及設計美感，涵蓋範圍非常廣大。這篇雖然打了落落長，但真的只有碰到皮毛（淚）。資料視覺化感覺都可以打個系列文了。但最後再次重申資料視覺化的定義：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;資料視覺化是將資料中的變數映射到視覺變數上，進而有效且有意義地呈現資料的樣貌&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;總之先確認你的觀眾與目的，選好你想要觀察的變數，選擇適當的視覺變數做可視化吧！&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.datacamp.com/courses/data-visualization-with-ggplot2-1"&gt;DataCamp - Data Visualization with ggplot2 (Part 1)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://r-statistics.co/ggplot2-Tutorial-With-R.html"&gt;r-statistics.co - ggplot2 tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.safaribooksonline.com/library/view/data-visualization-in/9781491963661/"&gt;Safari - Data Visualization in R With ggplot2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="R"></category><category term="visualization"></category><category term="ggplot2"></category><category term="資料視覺化"></category></entry><entry><title>利用 Kinesis 處理串流資料並建立資料湖</title><link href="https://leemeng.tw/use-kinesis-streams-and-firehose-to-build-a-data-lake.html" rel="alternate"></link><published>2018-04-04T21:30:00+09:00</published><updated>2018-04-04T21:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-04-04:/use-kinesis-streams-and-firehose-to-build-a-data-lake.html</id><summary type="html">&lt;p&gt;所謂的資料湖指的是一企業裡頭所有形式的資料的集合。這些資料包含原始資料，以及經過轉換的衍生資料。資料湖的核心概念是將所有可用的資料全部整合在一個邏輯上相近的地方以供企業自由結合並做各式各樣的運用。資料湖可以用很多方式建立，這裏我們主要介紹如何利用 Amazon Kinesis 將串流資料載入資料湖。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所謂的&lt;a href="https://en.wikipedia.org/wiki/Data_lake"&gt;資料湖 (data lake) &lt;/a&gt; 指的是一企業裡頭所有形式的資料的集合。這些資料包含原始資料 (raw data)，以及經過轉換的衍生資料 (derived data)。&lt;/p&gt;
&lt;p&gt;資料湖的核心概念是將所有可用的資料全部整合在一個邏輯上相近的地方以供企業自由結合並做各式各樣的運用。資料湖可以用很多方式建立，這裏我們主要介紹如何利用 &lt;a href="https://aws.amazon.com/tw/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 將串流資料 (streaming data) 載入資料湖。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="概觀"&gt;概觀&lt;a class="anchor-link" href="#概觀"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;資料湖概念上可以說是企業的所有資料的最終目的地。現在假設我們打算以 &lt;a href="https://aws.amazon.com/tw/s3/"&gt;Amazon S3&lt;/a&gt; 中作為我們的資料湖，問題就變成：要如何將串流資料穩定地傳到 S3。這部分我們將透過 &lt;a href="https://aws.amazon.com/tw/kinesis/"&gt;Amazon Kinesis&lt;/a&gt; 來達成。 Kinesis 本質上是跟 &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; 類似的 &lt;a href="https://en.wikipedia.org/wiki/Message_broker"&gt;message broker&lt;/a&gt;，將訊息依照 message producers 產生的順序傳遞給 message consumers。實際上資料的流動會如下圖所示：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/simple-streaming-data-flow.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    Simple Dataflow
    &lt;font color="purple"&gt;: 將 streaming data 透過 Kinesis 保存在 S3&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上圖有幾點值得說明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作為一個簡易的 demo，這邊我們的串流資料產生者 (streaming data producer) 是一個簡易 python script&lt;/li&gt;
&lt;li&gt;Streams 指的是 &lt;a href="https://aws.amazon.com/tw/kinesis/data-streams/"&gt;Amazon Kinesis Data Streams&lt;/a&gt;。在 Kinesis 架構裡頭，一個 data stream 通常代表一個主題 (topic)，
跟這個主題相關的 producers 會把資料傳入該 stream 以讓該主題的 consumers 之後能接受訊息。&lt;/li&gt;
&lt;li&gt;Firehose 指的是 &lt;a href="https://aws.amazon.com/tw/kinesis/data-firehose/"&gt;Amazon Kinesis Data Firehose&lt;/a&gt;，是專門把接受到的串流資料寫入 AWS 上的資料存放區（如 S3、Redshift、ElasticSearch）以供後續分析的服務。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建構流程"&gt;建構流程&lt;a class="anchor-link" href="#建構流程"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要完成上述的資料傳輸 pipeline，我們會 follow 以下步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#建立一個-Kinesis-data-stream"&gt;建立一個 Kinesis data stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#建立一個-Firehose-delivery-stream"&gt;建立一個 Firehose delivery stream&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#用-Python-傳串流資料"&gt;用 Python 傳串流資料&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#確認-S3-上的資料"&gt;確認 S3 上的資料&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在每個步驟裡頭會稍微澄清一些概念。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立一個-Kinesis-data-stream"&gt;建立一個 Kinesis data stream&lt;a class="anchor-link" href="#建立一個-Kinesis-data-stream"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;現在假設有一個名為 naive-app 的應用程式，我們想要把使用者在上面做的操作紀錄下來。這時候我們可以建立一個新的 Kinesis Data Stream 來接受 app 的 streaming data。這邊指的 streaming data 是使用者存取應用程式時產生的 access log。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/create-kinesis-stream.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Scalability"&gt;Scalability&lt;a class="anchor-link" href="#Scalability"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊最重要的是 &lt;code&gt;Number of shards&lt;/code&gt; 的設定。Kinesis 將接收到的資料以 log 的方式儲存在硬碟上，而為了提高 scalability，Kinesis 利用 Partitioning 的概念將 log 切割成多個部分並分配到不同的 shards 上，再將這些 shards 分別存在不同機器上面以提高 read/write capacity。因此我們可以理解一個 Kinesis Stream (Topic) 的資料吞吐量 (throughput) 直接受到 shard 的數目影響： shard 數目越多，同時能處理 read/write 的機器越多，資料吞吐量越高。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="How-to-scale"&gt;How to scale&lt;a class="anchor-link" href="#How-to-scale"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;理想上是一開始就掌握該 Stream/Topic 需要的資料吞吐量，進而決定最佳的 &lt;code&gt;Number of shards&lt;/code&gt; ，但有時候事與願違。事後想要改變 shard 數目時需要透過 &lt;a href="http://docs.aws.amazon.com/kinesis/latest/APIReference/"&gt;AWS Streams API&lt;/a&gt; 做 Resharding。Resharding 實際上就是在改變 shard 數目：增加 shard 會讓已存在的 shard 再度被切割；減少 shard 則會合併已存在的 shard。&lt;/p&gt;
&lt;p&gt;在這邊我們就只直接使用一個 shard for demo。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Availability"&gt;Availability&lt;a class="anchor-link" href="#Availability"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外值得一提的是 Kinesis 為了避免資料損失，會在三個不同的 availability zones 進行資料的 replication。因為這個額外的 overhead 可能使得在同樣設定下， &lt;a href="https://www.opsclarity.com/evaluating-message-brokers-kafka-vs-kinesis-vs-sqs/"&gt;Kinesis 比 Kafka 慢&lt;/a&gt; 的情況。因為是 log-based message broker，資料會被暫時存在硬碟上，預設保留 24 小時，而最多可以付費提升到維持 7 天以用來 replay data。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立一個-Firehose-delivery-stream_1"&gt;建立一個 Firehose delivery stream&lt;a class="anchor-link" href="#建立一個-Firehose-delivery-stream"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有了接受 naive-app 串流資料的 Kinesis stream 以後，我們要建立一個 Firehose delivery stream 來接收 Kinesis stream 的資料。&lt;/p&gt;
&lt;p&gt;Firehouse delivery stream 簡單來說是一個將串流資料存到 AWS 資料存放區的服務（如 S3、Redshift、ElasticSearch）。因此除了 &lt;a href="https://aws.amazon.com/tw/about-aws/whats-new/2017/08/amazon-kinesis-firehose-can-now-read-data-directly-from-amazon-kinesis-streams/"&gt;Kinesis stream 的串流資料&lt;/a&gt;以外，當然也可以接其他的串流資料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CloudWatch 的 log &lt;/li&gt;
&lt;li&gt;AWS IoT&lt;/li&gt;
&lt;li&gt;使用者自定義的串流資料&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在這篇裡頭我們的串流資料是 Kinesis stream，因此 Source 選擇 &lt;code&gt;Kinesis stream&lt;/code&gt; 並填入我們剛剛建立的 stream 名稱： &lt;code&gt;naive-app-access-log&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/create-delivery-stream.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;值得一提的是 Firehose delivery stream 會 auto-scale，並不像 Kinesis stream 要手動調整 shard 數目。不過當然傳越多花越多。&lt;/p&gt;
&lt;p&gt;如上張圖所示，實際上 Firehose 還允許我們在 delivery stream 接受到串流資料以後把原始資料傳到指定的 &lt;a href="https://aws.amazon.com/tw/lambda/"&gt;Lambda function&lt;/a&gt; 做進一步的轉換。
但因為我們想要資料湖儲存原始的串流資料，這邊我們省略這步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Configuration"&gt;Configuration&lt;a class="anchor-link" href="#Configuration"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際上 Firehose 不會一接收到資料就進行資料轉移。我們可以設定 Buffer size 以及 Buffer interval 讓 Firehose 在達到其中一個條件的時候把接收到的訊息統整起來一次做資料的轉移 (batch processing)。這邊為了能讓 Firehose 盡快把收到的資料轉移到 S3，設定 Buffer interval 為 &lt;code&gt;60&lt;/code&gt; 秒。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/firehose-configure-settings.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="選擇-delivery-stream-目的地"&gt;選擇 delivery stream 目的地&lt;a class="anchor-link" href="#選擇-delivery-stream-目的地"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;在設定好 Firehose delivery stream 的串流資料來源（e.g., Kinesis stream）以及基本設定以後，我們要決定串流資料的目的地。這邊基本上很直覺， Destination 選擇 &lt;code&gt;Amazon S3&lt;/code&gt; 以及想要放資料的 bucket 即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/firehose-select-destination.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比較需要注意的是我們可以指定此 Firehose delivery stream 在放資料進入 bucket 時要為檔案加什麼前綴。&lt;/p&gt;
&lt;p&gt;假設未來其他的串流資料我們也想要統一放在 &lt;code&gt;me-data-lake&lt;/code&gt; 這個 bucket 裡頭。為了方便管理，我們可以為每個 delivery stream 設定一個識別用的 Prefix。以 naive-app 來說，我們指定 Prefix 為 &lt;code&gt;naive-app-access-log/&lt;/code&gt; 。加上 Firehose 預設的 &lt;code&gt;YYYY/MM/DD/HH/&lt;/code&gt; ，該 stream 的每個檔案的路徑就會變成如下圖的 &lt;code&gt;naive-app-access-log/YYYY/MM/DD/HH/file_name&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/kinesis/s3-bucket-path.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    加入 Prefix 後實際將串流資料存入 S3 時的檔案路徑
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="用-Python-傳串流資料_1"&gt;用 Python 傳串流資料&lt;a class="anchor-link" href="#用-Python-傳串流資料"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;確保 Kinesis stream -&amp;gt; Firehose delivery stream -&amp;gt; S3 的資料流設定以後，我們可以寫一個簡單的 Python script 實際傳資料進 Kinesis stream 做測試。但首先先讓我們使用 &lt;a href="https://boto3.readthedocs.io/en/latest/"&gt;AWS SDK for Python&lt;/a&gt; 實作一個寄訊息給 Kinesis stream 的 function &lt;code&gt;write_to_stream&lt;/code&gt; ：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;boto3&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write_to_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;stream_name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""Write streaming event to specified Kinesis Stream within specified region.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters&lt;/span&gt;
&lt;span class="sd"&gt;    ----------&lt;/span&gt;
&lt;span class="sd"&gt;    event_id: str&lt;/span&gt;
&lt;span class="sd"&gt;        The unique identifer for the event which will be needed in partitioning.&lt;/span&gt;
&lt;span class="sd"&gt;    event: dict&lt;/span&gt;
&lt;span class="sd"&gt;        The actual payload including all the details of the event.&lt;/span&gt;
&lt;span class="sd"&gt;    region_name: str&lt;/span&gt;
&lt;span class="sd"&gt;        AWS region identifier, e.g., "ap-northeast-1".&lt;/span&gt;
&lt;span class="sd"&gt;    stream_name: str&lt;/span&gt;
&lt;span class="sd"&gt;        Kinesis Stream name to write.&lt;/span&gt;

&lt;span class="sd"&gt;    Returns&lt;/span&gt;
&lt;span class="sd"&gt;    -------&lt;/span&gt;
&lt;span class="sd"&gt;    res: Response returned by `put_record` func defined in boto3.client('kinesis')&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;client&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boto3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'kinesis'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;region_name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;client&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put_record&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;StreamName&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;stream_name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;Data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;PartitionKey&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;code&gt;write_to_stream&lt;/code&gt; 基本上是把一個 Python dict &lt;code&gt;event&lt;/code&gt; 利用 &lt;code&gt;json.dumps&lt;/code&gt; 轉成字串後傳到指定的 region 的 Kinesis stream 裡的函式。（完整的 &lt;a href="https://gist.github.com/leemengtaiwan/b5edca45e12664164e6634d6fe24d913"&gt;Gist&lt;/a&gt; ）&lt;/p&gt;
&lt;p&gt;這邊值得注意的是 &lt;code&gt;Data=json.dumps(event) + '\n'&lt;/code&gt; 裡頭的 &lt;code&gt;'\n'&lt;/code&gt; 。如果之後想要利用 &lt;a href="https://aws.amazon.com/tw/glue/"&gt;AWS Glue&lt;/a&gt; 或者 &lt;a href="https://aws.amazon.com/tw/athena/"&gt;Athena&lt;/a&gt; 來進一步分析此串流資料的話，推薦在代表一個 event 的字串後面加上換行符號以維持「一行一事件」的資料形式，方便 schema 的自動產生。&lt;/p&gt;
&lt;p&gt;範例日誌檔案內容會像是這樣：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{"event_id": "56262", "timestamp": 1522740951, "event_type": "write_post"}
{"event_id": "35672", "timestamp": 1522740956 ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外值得一提的是因為 Kinesis 背後是使用 &lt;a href="https://docs.aws.amazon.com/streams/latest/dev/key-concepts.html"&gt;Hash partitioning&lt;/a&gt; 來分配資料到 shard，基本上 &lt;code&gt;PartitionKey=event_id&lt;/code&gt; 裡頭的 &lt;code&gt;event_id&lt;/code&gt; 只要每個訊息都是獨一無二的，就能保證資料能「平均地」分配到各個 shard 上。&lt;/p&gt;
&lt;p&gt;有了此函式以後，我們可以實際傳一些訊息進 Kinesis stream：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="s2"&gt;"event_id"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100000&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
        &lt;span class="s2"&gt;"event_type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;choice&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'read_post'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'write_post'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'make_comments'&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
        &lt;span class="s2"&gt;"timestamp"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;calendar&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timegm&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;datetime&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;utcnow&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;timetuple&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="c1"&gt;# send to Kinesis Stream&lt;/span&gt;
    &lt;span class="n"&gt;event_id&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'event_id'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;write_to_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;event_id&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;REGION_NAME&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;KINESIS_STREAM_NAME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們的 naive-app 可以讓使用者讀文章、寫文章以及寫評論，則上面的程式碼是模擬使用者使用 naive-app 時產生的事件，並將該事件的內容傳到 Kinesis stream &lt;code&gt;naive-app-access-log&lt;/code&gt;。60 秒內幾筆產生的事件如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{'event_id': '56262', 'event_type': 'write_post', 'timestamp': 1522740951}
{'event_id': '35672', 'event_type': 'make_comments', 'timestamp': 1522740956}
{'event_id': '71613', 'event_type': 'read_post', 'timestamp': 1522740962}
{'event_id': '48160', 'event_type': 'make_comments', 'timestamp': 1522740967}
{'event_id': '96093', 'event_type': 'write_post', 'timestamp': 1522740972}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="確認-S3-上的資料"&gt;確認 S3 上的資料&lt;a class="anchor-link" href="#確認-S3-上的資料"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意因為上面的 5 個事件在 $5 * 5 = 25$ 秒內就產生了。且因為我們前面設定 Firehose delivery stream 的 Buffer interval 為 60 秒，Firehose 會把以上的事件的訊息全部串接起來，放到一個檔案裡頭，而不是分成五個檔案：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/kinesis/s3-bucket-path.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;而實際檔案的內容如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{"event_id": "56262", "timestamp": 1522740951, "event_type": "write_post"}
{"event_id": "35672", "timestamp": 1522740956 ...
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="結語"&gt;結語&lt;a class="anchor-link" href="#結語"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到這邊為止成功把（偽）串流資料透過 Kinesis 存到 S3 了！為了方便之後的應用，輸出的檔案的內容格式或許還可以再改進，但資料湖的其中一個想法是 &lt;a href="https://www.youtube.com/watch?v=JHGkaShoyNs"&gt;Command Query Responsibility Segregation (CQRS)&lt;/a&gt;，也就是在存放資料的時候就只專心丟資料，不去在意之後資料會被以什麼方式、schema 使用，可以保證之後實際應用資料時有最大的彈性。&lt;/p&gt;
&lt;p&gt;另外在確保資料好好地儲存在資料湖以後，我們通常會實際針對串流資料再進行一些處理 / 分析像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://aws.amazon.com/tw/blogs/big-data/building-a-near-real-time-discovery-platform-with-aws/"&gt;放到 Elasticsearch 並用 Kibana 做 Visualization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;觸發 Lambda function 做進一步處理&lt;/li&gt;
&lt;li&gt;使用 Athena 做 ad-hoc 分析&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/kinesis/kinesis-firehose-intro.png" style="width:80%"/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;但這邊時間有限，之後有機會再來記錄資料湖之後的分析筆記。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=814aUb5n_Fk"&gt;Youtube: Introduction to Amazon Kinesis Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sumologic.com/blog/devops/kinesis-streams-vs-firehose/"&gt;sumologic - Kinesis Stream vs Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://acloud.guru/forums/aws-certified-big-data-specialty/discussion/-KhI3MgPEo-FY5rfgl3J/what_is_difference_between_kin"&gt;A Cloud Guru - difference betwwen Kinesis Streams and Kinesis Firehose&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.arundhaj.com/blog/getting-started-kinesis-python.html"&gt;Getting started with AWS Kinesis using Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.opsclarity.com/evaluating-message-brokers-kafka-vs-kinesis-vs-sqs/"&gt;opsclarity - Evaluating Message Brokers: Kafka vs. Kinesis vs. SQS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料工程"></category><category term="python"></category><category term="aws"></category><category term="kinesis"></category></entry><entry><title>AWS Data Migration Service - 從 MongoDB 遷移到 Redshift</title><link href="https://leemeng.tw/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html" rel="alternate"></link><published>2018-03-27T18:30:00+09:00</published><updated>2018-03-27T18:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-27:/replicate-data-from-mongodb-to-redshift-using-aws-data-migration-service.html</id><summary type="html">&lt;p&gt;同樣一份資料因應不同的使用案例，可能需要使用不同的存取方式。而針對這些不同的存取方式，我們通常需要選擇最適合的資料庫來最佳化使用者體驗。這篇文章將簡單介紹如何使用 AWS Database Migration Service來快速地達到我們的目標：將 MongoDB 資料遷移到 Redshift 上。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;同樣一份資料因應不同的使用案例，可能需要使用不同的存取方式。而針對這些不同的存取方式，我們通常需要選擇最適合的資料庫來最佳化使用者體驗。&lt;/p&gt;
&lt;p&gt;這篇文章將簡單介紹如何使用 &lt;a href="https://aws.amazon.com/tw/dms/"&gt;AWS Database Migration Service&lt;/a&gt; (以下簡稱 AWS DMS )來快速地達到我們的目標：將 MongoDB 資料遷移到 Redshift 上。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用案例"&gt;使用案例&lt;a class="anchor-link" href="#使用案例"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;舉例來說，一個電子商務網站的後端可以使用一個具有高度彈性的 NoSQL 資料庫如 &lt;a href="https://www.mongodb.com/"&gt;MongoDB&lt;/a&gt; 來應對變化快速的使用者需求；而公司內部的資料科學家可以利用資料倉儲如 &lt;a href="https://aws.amazon.com/tw/redshift/"&gt;Redshift&lt;/a&gt; 來找出 business insight 。但這時候一個問題產生了：資料科學家用的資料倉儲 (例：Redshift) 的資料哪裡來？&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;常見的方式是對 MongoDB 裡頭的資料定期做 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 以後將轉換過後的資料載入 Redshift 供分析需求。理論上在做 ETL 時要依照資料倉儲的 Data Model 重新設計 Tables (例： &lt;a href="https://en.wikipedia.org/wiki/Star_schema"&gt;Star Schema&lt;/a&gt;)，但為了能在最短的時間將 MongoDB 上的資料轉到 Redshift 進行一些 Query，這篇文章將簡單介紹 AWS DMS 的運作方式，以及如何運用它來實際進行資料遷移所需要的步驟。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/intro.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://aws.amazon.com/tw/dms/" target="_blank"&gt;AWS DMS&lt;/a&gt;
&lt;font color="purple"&gt;: 遷移（並轉換） AWS 上的資料庫&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="AWS-DMS-基本介紹"&gt;AWS DMS 基本介紹&lt;a class="anchor-link" href="#AWS-DMS-基本介紹"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;DMS 基本上運作方式就是幫我們啟動一台 EC2 機器 (稱之為 replication instance) ，然後在上面跑 replication task(s) 。 一個 instance 上可以有多個 tasks 進行資料遷移。 instance 則分別透過 &lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.Sources.html"&gt;Source Endpoint&lt;/a&gt; / &lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.Targets.html"&gt;Target Endpoint&lt;/a&gt; 連結來源 / 目標資料庫。在後面我們會看到， endpoints 實際上就只是告訴 AWS DMS 的 replication instance 如何連結到實際的資料庫的設定罷了。在我們的例子裡頭，來源 / 目標資料庫分別對應到 MongoDB / Redshift 。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/flow.png" style="width:80%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/Welcome.html" target="_blank"&gt;DMS 基本運作方式&lt;/a&gt;
&lt;font color="purple"&gt;: 資料遷移是由在 Replication Instance 上執行的 Replication Task 透過 endpoints 連結來源/目標資料庫完成的&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="基本遷移步驟"&gt;基本遷移步驟&lt;a class="anchor-link" href="#基本遷移步驟"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在假設來源 / 目標資料庫已經在運作的情況下，如同 AWS DMS 的 Get started, 一般會進行以下步驟來遷移資料：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="#建立-replication-instance"&gt;建立 replication instance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#確保-replication-instance-能連結到來源-/-目標資料庫"&gt;確保 replication instance 能連結到來源 / 目標資料庫&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#定義-replication-task"&gt;定義 replication task&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#Debugging"&gt;Debugging：確保一切運作正常&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下針對每個步驟，我會紀錄一些需要注意的地方。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立-replication-instance"&gt;建立 replication instance&lt;a class="anchor-link" href="#建立-replication-instance"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;點擊 AWS DMS 介面的 Get started 選項會請我們建立新的 instance:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/create-replicate-instance.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    建立 Replication Instance
    &lt;font color="purple"&gt;: 注意 VPC /設定&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟基本上沒什麼問題， replication task 會佔用大量的 CPU 以及記憶體資源，理想上是依據需求選擇 Instance class ，不過第一次測試功能的話用預設的 t2.medium 即可。這邊值得注意的是 VPC 以及下面進階選項的 VPC Security Group(s) 設定。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果來源 / 目標資料庫都可供公開存取的話，基本上不需要 VPC 。但一般來說我們都會有安全考量，也就是要求所有在 AWS 上的資源都要套用安全設定，則最簡單的架構是將來源資料庫、目標資料庫以及 Replication Instance 都放入同一個 VPC ，並利用 &lt;a href="https://docs.aws.amazon.com/zh_cn/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html"&gt;security group&lt;/a&gt; 設定來允許該 Instance 存取兩個資料庫。概念上此 VPC 的架構會如下 ( &lt;code&gt;sg&lt;/code&gt; 為 Security Group 之縮寫 )：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/naive-vpc-structure.png" style="width:60%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;來源 / 目標資料庫所在的 Security Group 要允許 Replication Instance 所在的 Security Group 存取&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;以上圖為例， Security Group &lt;code&gt;sg_mongodb&lt;/code&gt; 以及 &lt;code&gt;sg_redshift&lt;/code&gt; 的 Inbound Rule 要允許 &lt;code&gt;sg_replicate&lt;/code&gt; 存取。而允許存取的 Port 則依照資料庫實際使用的 Port 設定即可 (例： MongoDB 慣用 27017； Redshift 則是 5439)。最後別忘了在建立 replication instance 的進階設定的 VPC Security Group(s) 選擇 &lt;code&gt;sg_replicate&lt;/code&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;另外你可能已經注意到上圖的 S3 bucket 。就 replication tasks 的 log 來看， AWS DMS 在遷移資料的時候實際上會再細分為兩步驟：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replication Task 將來源資料庫的資料載出、轉換並暫存到 S3&lt;/li&gt;
&lt;li&gt;Task 將存在 S3 的資料載入目標資料庫&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;雖然 &lt;a href="https://aws.amazon.com/tw/cloudwatch/"&gt;ClodWatch&lt;/a&gt; 需要額外收費，但為了方便除錯，建議使用。在文章後面的 &lt;a href="#Debugging"&gt;Debugging&lt;/a&gt; 我們會實際看一些例子。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="確保-replication-instance-能連結到來源-/-目標資料庫"&gt;確保 replication instance 能連結到來源 / 目標資料庫&lt;a class="anchor-link" href="#確保-replication-instance-能連結到來源-/-目標資料庫"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;上一步驟設定好以後， AWS DMS 會馬上幫我們建立一個新的 replication instance。在等待的同時我們可以開始設定資料庫的 endpoints。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/check-replication-instance-can-connect-to-both-endpoints.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    設定來源 / 目標 enpoints
    &lt;font color="purple"&gt;: 在此步驟確保 Replication Instance 可以連到兩個資料庫可以減少除錯時間&lt;/font&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這步驟基本上依照資料庫的不同，需要的輸入的項目可能不一樣。不過值得一提的是，在&lt;a href="#建立-replication-instance"&gt;建立 replication instance&lt;/a&gt; 的時候我們已經讓來源 / 目標資料庫以及 replication instance 都待在同個 VPC 裡頭。假設我們的 MongoDB 是運行在該 VPC 裡頭的某個 EC2 instance 之上，要允許在同個 VPC 的 replication instance 存取該 EC2 instance，我們要在 Server name 選項輸入運行 MongoDB 的 EC2 的 Private IP (上圖第一個紅框)。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="MongoDB-as-Source-Database"&gt;MongoDB as Source Database&lt;a class="anchor-link" href="#MongoDB-as-Source-Database"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當 MongoDB 為來源資料庫時有一些值得注意的事情可以參考&lt;a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Source.MongoDB.html"&gt;官方文件&lt;/a&gt;。以下會說明一些值得特別注意的地方。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Metadata-mode"&gt;Metadata mode&lt;a class="anchor-link" href="#Metadata-mode"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;Metadata mode 預設為 &lt;code&gt;document&lt;/code&gt;（上圖第二個紅框），也就是把 MongoDB 裡頭的 json-formated 文件放到 Redshift 裡頭對應 Table 的一個 &lt;code&gt;_doc&lt;/code&gt; 欄位。假設 MongoDB 裡有一個 &lt;code&gt;users&lt;/code&gt; collection ，裡頭存了以下文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"user"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"leemeng"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"favorite"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"chocolate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="nt"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"For fun!"&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;"unnecessary_field"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Don't include me!"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;將會被以下的格式載入 Redshift：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;_doc                      |
---------------------------
{"user": "leemeng", "fav ..&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;而這通常不是我們要的。將 metadate mode 設定為 &lt;code&gt;table&lt;/code&gt; 模式能讓 AWS DMS 把文件裡頭的欄位扁平化後放入對應的欄位(column)：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;user    | favorite  | a.b     | unnecessary_field
-------------------------------------------------
leemeng | chocolate | For fun!| Don't include me!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意到這邊有一個我們不需要遷移到 Redshift 的 &lt;code&gt;unnecessary_field&lt;/code&gt; 。在後面的 &lt;a href="#Transformation Rules"&gt;Transformation Rules&lt;/a&gt; 我們會了解怎麼辦該欄位去除。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h4 id="Numbers-of-documents-to-scan"&gt;Numbers of documents to scan&lt;a class="anchor-link" href="#Numbers-of-documents-to-scan"&gt;&amp;para;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;而 Numbers of documents to scan 選項則讓我們決定要讓 AWS DMS 拿多少文件來決定要建立哪些欄位。如果要遷移的 MongoDB collection 的文件 schema 很常被更動（常有新鍵值）的話，建議可以讓 AWS DMS 掃描多一點文件來建立足夠的欄位。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Redshift-as-Target-Database_1"&gt;Redshift as Target Database&lt;a class="anchor-link" href="#Redshift-as-Target-Database"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;如果按照 AWS DMS 的 Get started 一步一步走的話基本上沒有問題。要注意的是 Redshift 要有允許 DMS 存取的 AMI Rule，否則會出錯。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="定義-replication-task_1"&gt;定義 replication task&lt;a class="anchor-link" href="#定義-replication-task"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在確定 replication instance 可以連線到兩個資料庫後，可以開始建立我們的 replication task：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/create-replication-task.png" width="90%"/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊我們可以看到有三種資料遷移方式 (圖中的 Migration type)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;遷移目前 MongoDB 的資料&lt;/li&gt;
&lt;li&gt;同上，但在遷移後之後繼續同步 MongoDB &amp;amp; Redshift (前提是 MongoDB 要以 Replica Set 模式執行)&lt;/li&gt;
&lt;li&gt;只把 Task 啟動後 MongoDB 的資料變動遷移到 Redshift&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這邊選擇自己的想要的遷移方式即可。接著我們要告訴 AWS DMS 想要進行遷移的 MongoDB Collections 以及在想要做的簡單轉換。兩者分別透過 &lt;a href="#Selection-Rules"&gt;Selection Rules&lt;/a&gt; 還有 &lt;a href="#Transformation-Rules"&gt;Transformation Rules&lt;/a&gt; 定義。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Selection-Rules"&gt;Selection Rules&lt;a class="anchor-link" href="#Selection-Rules"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Selection Rules 的用途是告訴 AWS DMS 該遷移以及不要遷移的 (MongoDB) collections 。我們可以定義一個 general rule 讓一個 task 處理某個 db 的所有 collections ；也能讓一個 task 只負責一個 collection 的遷移。後者的設定比較花時間但是彈性比較高，可以依照不同 collection 特性決定遷移的方式。&lt;/p&gt;
&lt;p&gt;下圖是定義一個 rule 告訴 AWS DMS 遷移所有在 MongoDB 的 Collections。另外如果想要排除哪個 collection 的話就新增一個 rule 並在 Action 選擇 &lt;code&gt;Exclude&lt;/code&gt;。基本上想要加幾個 Selection Rules 都可以。而 Exclude Rules 的效果是在所有 Include Rules 後套用。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/selection-rules.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://www.netpromoter.com/know/" target="_blank"&gt;Selection Rules&lt;/a&gt;
&lt;font color="purple"&gt;: 選擇要遷移到目標資料庫的 Tables / Collections&lt;/font&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Transformation-Rules"&gt;Transformation Rules&lt;a class="anchor-link" href="#Transformation-Rules"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;這邊所謂的轉換並不是對欄位的實際值 (value) 進行轉換，而是針對 Table / Column 層級做&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;排除（不遷移該 Table / Column）&lt;/li&gt;
&lt;li&gt;幫 Table / Column 更名、大小寫轉換或是名稱加上 prefix / postfix&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;這種操作。下圖是將 &lt;code&gt;users&lt;/code&gt; collection 裡頭不需要遷移的鍵值 &lt;code&gt;uncessary_field&lt;/code&gt; 從 Redshift 排除的 rules:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/transformation-rules.png" style=""/&gt;
&lt;br/&gt;
&lt;/center&gt;&lt;p&gt;透過這個 Transformation rule，我們上面 &lt;code&gt;users&lt;/code&gt; collection 的範例文件：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="nt"&gt;"user"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"leemeng"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"favorite"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"chocolate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="nt"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;"b"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"For fun!"&lt;/span&gt;
    &lt;span class="p"&gt;},&lt;/span&gt;
    &lt;span class="nt"&gt;"unnecessary_field"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Don't include me!"&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;就會被轉成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;user    | favorite  | a.b     
------------------------------
leemeng | chocolate | For fun!
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意 &lt;code&gt;uncessary_field&lt;/code&gt; 不會被存到 Redshift 裡頭。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Debugging_1"&gt;Debugging&lt;a class="anchor-link" href="#Debugging"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當建立並執行一個新的 replication task 後，我們可以從 Load State 看到每個 Table 載入的狀況。 Load State 有幾種可能的值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Before Loading&lt;/li&gt;
&lt;li&gt;Full Load&lt;/li&gt;
&lt;li&gt;Table completed&lt;/li&gt;
&lt;li&gt;Table error&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;當出現 &lt;code&gt;Table error&lt;/code&gt; 時，我們可以先看 log 瞭解情況：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;2018-03-28T01:23:30 [TARGET_LOAD ]E: RetCode: SQL_ERROR SqlState: XX000 NativeError: 30 Message: [Amazon][Amazon Redshift] (30) Error occurred while trying to execute a query: [SQLState XX000] ERROR: Load into table 'users' failed. Check 'stl_load_errors' system table for details. [1022502] (ar_odbc_stmt.c:4406)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;依照不同的錯誤、不同的目標資料庫，實際的 log 內容會有所不同。以我們目標資料庫 = Redshift 的情況下，上面的 log 告訴我們 replication task 在載入 &lt;code&gt;users&lt;/code&gt; Table 時出錯，詳情可以參考 Redshift 的 &lt;code&gt;stl_load_error&lt;/code&gt; Table (&lt;a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/r_STL_LOAD_ERRORS.html"&gt;官方文件&lt;/a&gt;)：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;pg_catalog&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stl_load_errors&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;starttime&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;span class="k"&gt;LIMIT&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/aws-dms/load-error-example.png" width="90%"/&gt;
&lt;/center&gt;
&lt;center&gt;
    查看 Redshift 裡頭 stl_load_error Table 來除錯
    &lt;br/&gt;
&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;就這個錯誤例子來看， err_reason 的內容告訴我們有個 &lt;code&gt;memo&lt;/code&gt; 欄位 ( colname ) 的值太長導致沒辦法載入 Redshift。這時候可以把正在運行的 replication task 暫停，用前面提到的 &lt;a href="#Transformation-Rules"&gt;Transformation Rules&lt;/a&gt; 來去除該欄位。而基本上其他錯誤也能用類似的方式解決。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;到這邊為止大致上應該可以順利把 MongoDB 的資料載入 Redshift 了。之後想到什麼再補充。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="aws"></category><category term="資料庫"></category><category term="資料工程"></category></entry><entry><title>Designing Data-Intensive Applications (1) - 序言</title><link href="https://leemeng.tw/designing-data-intensive-applications-1-preface.html" rel="alternate"></link><published>2018-03-24T15:33:00+09:00</published><updated>2018-03-24T15:33:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-24:/designing-data-intensive-applications-1-preface.html</id><summary type="html">&lt;p&gt;最近在拜讀 Martin Kleppmann 的 Designing Data-Intensive Applications， 覺得受益匪淺，且我也相信透過 Feynman Technique 將學到的東西用最淺顯易懂的方式表達能幫助自己內化這些知識，遂嘗試把閱讀後的心得記錄在此。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;最近在拜讀 &lt;a href="http://martin.kleppmann.com/"&gt;Martin Kleppmann&lt;/a&gt; 的 &lt;a href="https://dataintensive.net/"&gt;Designing Data-Intensive Applications&lt;/a&gt;，
覺得受益匪淺，且我也相信透過 
&lt;a href="http://blog.xxc.idv.tw/km/%E8%B2%BB%E6%9B%BC%E7%9A%84%E5%AD%B8%E7%BF%92%E6%8A%80%E5%B7%A7-the-feynman-technique.html"&gt;Feynman Technique&lt;/a&gt; 
將學到的東西用最淺顯易懂的方式表達能幫助自己內化這些知識，遂嘗試把閱讀後的心得記錄在此。&lt;/p&gt;
&lt;p&gt;另外在提到書內內容時都會盡量使用英文原文，不另做名詞的翻譯，以方便對照書內內容。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂-data-intensive-applications"&gt;何謂 data-intensive applications&lt;a class="anchor-link" href="#何謂-data-intensive-applications"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;所謂的 data-intensive applications 如同名稱所示，專注在如何有效率地處理、儲存&lt;a href="#何謂資料密集"&gt;密集資料&lt;/a&gt;。通常一個這樣的系統的後端要用多種方式處理資料，而不是只用一個資料庫就結束了。（雖然對 end users 來說可能看起來像這樣）&lt;/p&gt;
&lt;p&gt;舉個簡單例子，一個電子商務網頁的後端除了做為 &lt;a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E4%B8%8A%E4%BA%A4%E6%98%93%E8%99%95%E7%90%86"&gt;OLTP&lt;/a&gt; 的 NoSQL 資料庫 (e.g., MongoDB) 以外，可能還有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個專門存放網頁快取的資料庫 (e.g. Redis) &lt;/li&gt;
&lt;li&gt;給資料科學家分析用的資料倉儲 (e.g., Redshift) &lt;/li&gt;
&lt;li&gt;處理 streaming events 的 messaging queue (e.g., Kafka)&lt;/li&gt;
&lt;li&gt;定期將 NoSQL 資料庫的資料做 &lt;a href="https://zh.wikipedia.org/wiki/ETL"&gt;ETL&lt;/a&gt; 存到 資料倉儲的批次處理 (e.g., Hive jobs)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;光是要把以上所列的資料庫 / 分散式系統 / 資料流 以有系統的方式組合起來就需要大量經驗，更遑論還要達到以下三個要求了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可靠性 (reliable): 像是 zero-down time, 很短的回應時間 etc&lt;/li&gt;
&lt;li&gt;規模性 (scalable): 即使之後資料量增加，系統也能很好地運作&lt;/li&gt;
&lt;li&gt;維護性 (maintainable): 容易改善、新增功能的系統設計&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/ddia/jigsaw-puzzle.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="http://www.jigsaw-puzzle-club.co.uk/" target="_blank"&gt;Image Credit&lt;/a&gt;
&lt;font color="purple"&gt;: 如何了解各個 data system 的優缺點並予以組合&lt;/font&gt;&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;儘管我們不可能熟悉所有資料庫以及分散式系統的細節，了解他們背後設計的核心理念、演算法以及大致上的運作方式能讓我們了解每個 data system 的特性以及優缺點，依照不同的使用案例選擇最適合的 data system 並予以組合。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="何謂資料密集"&gt;何謂資料密集&lt;a class="anchor-link" href="#何謂資料密集"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;書中所指的「密集」資料有以下所列的特徵（一個以上）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大量資料&lt;/li&gt;
&lt;li&gt;資料的（格式、 schema etc）變動速度很快&lt;/li&gt;
&lt;li&gt;資料有複雜結構&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;針對「資料有複雜結構」以及「資料變動很快」這點，最為人所知的 solution 就是 NoSQL 等允許彈性 schema 的資料庫的崛起；
而針對「資料量很大」這點，則端看使用案例有各式各樣的資料庫、分散式系統。舉幾個例子：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能有效儲存大量資料的 Google BigTable&lt;/li&gt;
&lt;li&gt;以欄 (column) 為單位儲存以壓縮大量資料的資料倉儲 Redshift&lt;/li&gt;
&lt;li&gt;Amazon 的 Single-leader Replication - DynamoDB&lt;/li&gt;
&lt;li&gt;專門處理 realtime streaming data 的 Kafka, RabbitMQ etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如同前述，以上提到的系統依照它們想要解決的問題的特性，背後都會有一些假設以及 trade-off 。了解這些背後的原理可以讓我們了解哪些工具在什麼時候最 powerful 。&lt;/p&gt;
&lt;p&gt;這本書主要分成三部分來闡述，抓到大方向會比較容易閱讀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;針對單一機器上的資料，有哪些常用的資料儲存/處理方法&lt;/li&gt;
&lt;li&gt;類似前一部份，闡述針對分散式系統的資料儲存/處理方法&lt;/li&gt;
&lt;li&gt;資料密集型應用：如何將多個 data systems 組合起來&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="一句話總結"&gt;一句話總結&lt;a class="anchor-link" href="#一句話總結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;在資料密集的時代，我們的最終目標在於如何將各式各樣的 data systems 以有系統的方式「組合」起來，以建立一個可靠、具規模性以及維護性的系統。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料工程"></category></entry><entry><title>Google Data Studio 基礎</title><link href="https://leemeng.tw/google-data-studio-basics.html" rel="alternate"></link><published>2018-03-13T16:34:00+09:00</published><updated>2018-03-13T16:34:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-13:/google-data-studio-basics.html</id><summary type="html">&lt;p&gt;Google Data Studio 是 Google 推出的一個儀表板服務，讓我們可以利用多種連結器將儲存在如 Google Analytics、 Google 試算表及 Google BigQuery 等特定資料來源的資料做出漂亮的 visualization ，用資料講故事而不用自己設計 UI。這篇把學到的一些技巧以及使用心得記錄下來。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/data-studio/"&gt;Google Data Studio&lt;/a&gt; 是 Google 推出的一個 Dashboard / Reporting 的服務，讓我們可以利用多種&lt;a href="https://support.google.com/datastudio/answer/7530149?hl=en&amp;amp;ref_topic=6370347"&gt;連結器&lt;/a&gt;將儲存在如 Google Analytics、 Google 試算表及 Google BigQuery 等特定資料來源的資料做出漂亮的 visualization ，用資料講故事而不用自己設計 UI。公司內部雖然有自己的 dashboards 不過想說多試一些方案沒有壞處，而且現在 Data Studio 還是 Beta 版本，雖然介面是中文，說明文件還只有英文，想說把學到的一些技巧以及使用心得記錄下來。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="將-Google-試算表的資料可視化"&gt;將 Google 試算表的資料可視化&lt;a class="anchor-link" href="#將-Google-試算表的資料可視化"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;為了快速展示 Data Studio 的功能，我們將使用&lt;a href="https://data.gov.tw/"&gt;政府資料開放平臺&lt;/a&gt;上由交通部觀光局提供的&lt;a href="https://data.gov.tw/dataset/45444"&gt;105年來台旅客性別統計&lt;/a&gt;資料。將 CSV 檔案下載下來，稍微簡化格式後上傳到 Google 試算表以當作報表的資料來源。下圖是簡化後的資料：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/table-preview.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;a href="https://data.gov.tw/dataset/45444" target="_blank"&gt;資料來源&lt;/a&gt;
&lt;font color="purple"&gt;: 2016年來台旅客性別統計&lt;/font&gt;&lt;br/&gt;
    每一列代表某地區 / 國家的訪台人數以及男女比
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="條件欄位應用"&gt;條件欄位應用&lt;a class="anchor-link" href="#條件欄位應用"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://support.google.com/datastudio/answer/7359285"&gt;條件欄位&lt;/a&gt;讓我們可以針對試算表裡頭每一列做 IF ELSE 判斷，依照判斷結果給予不同的值。現在假設我們想知道有多少國家的男性遊客過半數，可以使用簡易的評量表來計算：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/male-over-half.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;訪台男性遊客過半國家佔全部國家的比例&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現高達八成的國家（有些是區域）的訪台男性遊客較女性為多。我們可以調查其他國家的訪客性別比，看是不是只有台灣有此現象。要產生分母的「國家數」很直覺，我們只要新增一個欄位並計算有幾個國家即可：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/num_countries_as_metric.png"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;新增一個名為「國家數」的欄位&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;但要計算分子的「男性遊客過半國家數」就稍微 tricky 了。我們想做的是，針對每一國家（每一列），只有在該國訪台男性遊客百分比過半（超過 50%)的時候才會被納入結果。而 Data Studio 的&lt;a href="https://support.google.com/datastudio/answer/7359285"&gt;條件欄位&lt;/a&gt;就是專門針對這種情況設計的。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/conditional-calculated-field.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;使用 CASE 語法對每一列做 IF-ELSE 判斷&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;&lt;p&gt;上面的公式用白話來說就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;針對每一列的國家，看它的「男性百分比」欄位的值有沒有大於50。有的話值為1，否則為0。在針對每列做完條件判斷以後再把所有 1 加起來，就等於符合條件的國家數。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="篩選器（filter）應用"&gt;篩選器（filter）應用&lt;a class="anchor-link" href="#篩選器（filter）應用"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;根據上個分析，我們知道女性遊客過半的國家只佔 20%。假設我們想確切知道是哪些國家的女性遊客過半，可以從女性百分比最高的國家開始列出男女比：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/multibar-female-over-half.png" style="width:100%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;訪台女性遊客過半國家&lt;br/&gt;
&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;我們發現女性遊客過半的都是亞洲國家，或許我們可以簡單解釋成這些國家與台灣的距離短，適合女性遊客拜訪。而為了讓圖表易讀，上面這張組合圖額外建立一個篩選器來過濾掉男性遊客比女性多的國家：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/female-more-than-half.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;新增一個篩選器以過濾男性遊客比例較高的國家&lt;br/&gt;&lt;/font&gt;
    註：一般的長條圖可以直接透過設定限制長條圖數目
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="維度-VS-指標"&gt;維度 VS 指標&lt;a class="anchor-link" href="#維度-VS-指標"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在 Data Studio 裡頭，了解&lt;a href="https://support.google.com/datastudio/answer/6402048?ref_topic=7441655&amp;amp;utm_source=product&amp;amp;utm_medium=cta&amp;amp;utm_campaign=wwr&amp;amp;utm_content=dims_mets"&gt;維度跟指標的差異&lt;/a&gt;很重要。&lt;/p&gt;
&lt;p&gt;以我們現在的資料集為例，每一列就是一筆紀錄（record），每一行則是一個欄位。每個欄位則是維度或指標。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指標（Metric，底下藍色）&lt;ul&gt;
&lt;li&gt;數值型欄位，有經過「匯總」，負責 quantify 資料&lt;/li&gt;
&lt;li&gt;如「國家數」、「總人數」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;維度（Dimension，底下綠色）&lt;ul&gt;
&lt;li&gt;分類型欄位，負責 qualify 資料&lt;/li&gt;
&lt;li&gt;如「國家」、「居住地」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/metric-versus-dimension.png" style=""/&gt;
&lt;/center&gt;
&lt;center&gt;
&lt;font color="purple"&gt;fx 則代表是額外利用公式建立的欄位&lt;/font&gt;&lt;br/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;像我們前面定義的「男性遊客過半國家數」欄位因為有經過 &lt;code&gt;SUM&lt;/code&gt; 公式匯總成為一個數值，因此為一個指標（藍）。而如果我們透過 &lt;code&gt;CASE&lt;/code&gt; 語法新定義一個「男性過半」欄位如下：&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/define-a-dimension-with-case-syntax.png" style="width:70%"/&gt;
&lt;/center&gt;&lt;p&gt;此欄位沒有經過匯總因此被視為維度，在上一張圖被標為綠色。因此一句話總結維度跟指標的功能就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;維度負責「描述」資料； 指標則負責「衡量」資料。&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="資料透視表-(Pivot-Table)"&gt;資料透視表 (Pivot Table)&lt;a class="anchor-link" href="#資料透視表-(Pivot-Table)"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;資料透視表很適合拿來看在不同條件下某個指標的表現。下圖是一個依照&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;居住地&lt;/li&gt;
&lt;li&gt;國家&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;兩個維度計算「男性人數」指標的資料透視表：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/pivot-table.png" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照&lt;a href="https://support.google.com/datastudio/answer/7516660?hl=en"&gt;官方文件&lt;/a&gt;有幾點值得注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資料透視表最多處理 50,000 筆資料，為了避免 scan 資料太花時間，可以額外建立一些篩選器 subset 資料&lt;/li&gt;
&lt;li&gt;列維度跟欄維度最多可以分別設定 2 個維度（上例列欄各設定 1 個維度）&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="限制"&gt;限制&lt;a class="anchor-link" href="#限制"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;可能因為還處在 beta 版本，在這篇文章寫的時候（2018/03）試用了一陣子發現 Data Studio 也有一些使用案例沒有辦法做到，像是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;篩選器（filter）只能設定像是「欄位 C 大於 X」這種條件，而不能做「當欄位 C1 &amp;gt; 欄位 C2」這種欄位間的比較。&lt;/li&gt;
&lt;li&gt;同上，條件欄位也只能設定像是「欄位 C 大於某固定值 X」的條件&lt;/li&gt;
&lt;li&gt;資料透視表包含的資料稍多 (&amp;gt; 2000筆)就開始變慢 ..&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="實戰演練"&gt;實戰演練&lt;a class="anchor-link" href="#實戰演練"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這篇文章用的報表連結在&lt;a href="https://datastudio.google.com/open/19a--FnAQ9asll18anhv7negoXGO0fpyH"&gt;此&lt;/a&gt;，可以自己試試不同 visualization。有任何 feedback 也歡迎聯絡。&lt;/p&gt;
&lt;center&gt;
&lt;img src="images/google-data-studio/google-data-studio-preview.png" style="width:70%"/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="資料視覺化"></category></entry><entry><title>Pelican 實戰手冊(主題篇)</title><link href="https://leemeng.tw/build-a-pelican-powered-blog-like-a-pro.html" rel="alternate"></link><published>2018-03-05T15:00:00+09:00</published><updated>2018-03-05T15:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-05:/build-a-pelican-powered-blog-like-a-pro.html</id><summary type="html">&lt;p&gt;Pelican 是一個用 Python 寫的靜態網頁生成器, 可以幫我們把 reStructedText, Markdown file 甚至 Jupyer notebook 轉成靜態的 HTML 檔案。 有些人可能已經注意到這個部落格是用 Pelican 所寫成並且 host 在 Github 上的。這篇主要紀錄如何使用 Jinja2 自訂主題。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;有些人可能已經注意到這個部落格是用 &lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt; 所寫成並且 host 在 &lt;a href="https://github.com/leemengtaiwan/leemengtaiwan.github.io"&gt;Github&lt;/a&gt; 上。這篇主要紀錄如何使用 &lt;a href="http://jinja.pocoo.org/docs/2.10/"&gt;Jinja2&lt;/a&gt; 自訂主題。&lt;/p&gt;
&lt;p&gt;Pelican 是一個用 Python 寫的靜態網頁生成器, 可以幫我們把 reStructedText, Markdown file 甚至 &lt;a href="http://jupyter.org/"&gt;Jupyer notebook&lt;/a&gt; 轉成靜態的 HTML 檔案。 靜態網頁的好處就是我們不需要一個 web server 或者是資料庫來管理內容, 可以把 HTML 檔案 host 在想要的地方，比方說 &lt;a href="https://pages.github.com/"&gt;Github Pages&lt;/a&gt;。用 Pelican 官網一句來介紹的話就是：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;blockquote&gt;&lt;p&gt;Pelican is a static site generator, written in Python, that requires no database or server-side logic. - Pelican Blog&lt;/p&gt;&lt;/blockquote&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Google 一下你會發現除了 Pelican 以外還有很多其他像是 Jekyll, Hexo 等&lt;a href="https://www.staticgen.com/"&gt;靜態網頁生成器&lt;/a&gt;。 之所以會選擇 Pelican 是因為以下幾點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pelican 是用 Python 寫的，讓 Python 開發者（我）很容易客製化&lt;/li&gt;
&lt;li&gt;可以把 &lt;a href="https://github.com/danielfrg/pelican-ipynb"&gt;jupyter notebook 轉成 HTML&lt;/a&gt;，這對每天寫一堆 notebooks 的資料科學家很友善&lt;/li&gt;
&lt;li&gt;主題是用強大的 &lt;a href="http://jinja.pocoo.org/docs/2.10/"&gt;Jinja2&lt;/a&gt; 模組引擎建立，可以用前人寫好的&lt;a href="http://www.pelicanthemes.com/"&gt;主題&lt;/a&gt;或是自己寫 templates，自由度很高，也是本篇重點。  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你的需求類似而且想要自己架一個部落格，可以現在就跳入 &lt;a href="https://github.com/getpelican/pelican/blob/master/docs/quickstart.rst"&gt;Pelican Quickstart&lt;/a&gt;，有問題再回來看這篇。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;img src="images/jinja2.jpeg"/&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Jinja2 是 Python 知名的模組引擎 (templating engine)，可以有系統地產生 HTML，很常出現在 &lt;a href="http://flask.pocoo.org/"&gt;Flask&lt;/a&gt; 或是 &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; Apps 裡頭。以下介紹在建立 Pelican blog 時常用到的功能。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="再利用-HTML-區塊"&gt;再利用 HTML 區塊&lt;a class="anchor-link" href="#再利用-HTML-區塊"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;比方說我們可以建立一個汎用的 template base.html 來定義整個部落格共用的資訊，像是 header 裡頭要 import 的 css / favicon 等等：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% block head %}
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"stylesheet"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text/css"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"css/vendor.css"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"icon"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"images/favicon.ico"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"image/x-icon"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
{% endblock head %}
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    {% block content %}
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;部落格內容&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    {% endblock content %}
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意到上面的 &lt;code&gt;{% block head %}&lt;/code&gt; jinja2 語法。會在多個 HTML 檔案重複使用的部分我們可以用 &lt;code&gt;{% block BLOCKNAME %}&lt;/code&gt; 以及 &lt;code&gt;{% endblock BLOCKNAME %}&lt;/code&gt; 包起來，然後在獨立顯示一篇文章的 article.html 裡頭我們可以定義：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;extends&lt;/span&gt; &lt;span class="s2"&gt;"base.html"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;
  &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;文章標題&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endblock&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;block&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;文章內容&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endblock&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;body&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的 code 基本上是告訴 jinja2 article.html 要繼承 base.html 的所有內容，而在 &lt;code&gt;head&lt;/code&gt; block 除了用&lt;code&gt;{{ super() }}&lt;/code&gt; 繼承 base.html 的內容以外，在下面再追加新的內容。而 &lt;code&gt;content&lt;/code&gt; block 則是完全取代。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因此最後 article.html 會被渲染成：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt; &lt;span class="na"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"stylesheet"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text/css"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"css/vendor.css"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;link&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"icon"&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"images/favicon.ico"&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"image/x-icon"&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;文章標題&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;title&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;head&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;文章內容&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="為當前文章取得前/後一篇文章連結"&gt;為當前文章取得前/後一篇文章連結&lt;a class="anchor-link" href="#為當前文章取得前/後一篇文章連結"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;center&gt;&lt;img src="images/pagination_prev_and_next.png" style="width:70%"/&gt;&lt;/center&gt;
&lt;center&gt;&lt;font color="purple"&gt; Pagination 範例: 顯示前後文章連結 &lt;br/&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;依照主題不同，有些主題可能文章頁面裡頭並沒有提供前一篇/後一篇文章的連結。要像上圖為每一篇文章取得前後文章的連結，可以在 article.html 裡存取 &lt;a href="https://github.com/getpelican/pelican/blob/master/docs/themes.rst#common-variables"&gt;articles Variable&lt;/a&gt; 並使用 jinja2 &lt;a href="http://jinja.pocoo.org/docs/2.10/templates/#assignments"&gt;namespace&lt;/a&gt; 來取得前後文章(&lt;code&gt;namespace&lt;/code&gt; 要在 jinja 2.10+ 以後才能使用)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# get prev- and next-article for pagination #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;namespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prev&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;next&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 要使用 break 要安裝 extension, 最佳化效率可省略 #}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%-&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;break&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endif&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 假設文章標題不會重複, unique #}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;found&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;true&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;prev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;previtem&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
        &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;ns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;next&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;loop&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;nextitem&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endif&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endfor&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;上面的 code 會 iterate 所有文章，當遇到當前文章的時候利用 &lt;code&gt;loop.previtem&lt;/code&gt; 以及 &lt;code&gt;loop.nextitem&lt;/code&gt; 把前後文章記下來。 &lt;a href="https://stackoverflow.com/questions/9486393/jinja2-change-the-value-of-a-variable-inside-a-loop"&gt;jinja2 預設是無法在 loop 裡頭改變變數的值&lt;/a&gt;，但使用 &lt;code&gt;namespace&lt;/code&gt; 即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;接著就能利用剛剛取得的前後 article 物件來渲染前後連結：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;{# 方便起見的 assignment %}
{% set prev_article = ns.prev %}
{% set next_article = ns.next %}

{% if prev_article %}
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"prev_article.url"&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"prev"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Previous Post&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        {{ prev_article.title }}
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% endif %}
{% if next_article %}
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"next_article.url"&lt;/span&gt; &lt;span class="na"&gt;rel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"next"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Next Post&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;span&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        {{ next_article.title }}
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% endif %}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="傳參數給子-template"&gt;傳參數給子 template&lt;a class="anchor-link" href="#傳參數給子-template"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;有時候多個 templates 會使用類似的 HTML，像是當首頁 index.html 以及部落格 blog.html 都用相同格式渲染最新幾篇文章時，我們可以定義一個 article_entries.html 如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 簡化版 #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt; &lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"col-block"&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"{{ SITEURL }}/{{ article.url }}"&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;{{&lt;/span&gt; &lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt; &lt;span class="p"&gt;}}&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="n"&gt;article&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endfor&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意這時候如果直接在 index.html 使用&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="s1"&gt;'article_entries.html'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;是會出現&lt;a href="https://stackoverflow.com/questions/9404990/how-to-pass-selected-named-arguments-to-jinja2s-include-context"&gt;錯誤&lt;/a&gt;的。理由是被 include 的 article_entries.html 看不到定義在 index.html 的 &lt;code&gt;articles&lt;/code&gt; 變數。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;解決方法是在 index.html 裡透過 &lt;code&gt;{% with %}&lt;/code&gt; 語法定義一個 scope：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 選擇前五篇文章來渲染 #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="n"&gt;articles_to_show&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;articles_page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;object_list&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="c1"&gt;# 定義 scope #}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;articles&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;articles_to_show&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="s1"&gt;'article_entries.html'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;endwith&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;使用 &lt;code&gt;with&lt;/code&gt; 的好處是可以把子 template article_entries.html 當作 function 來使用，我們可以依照母 template 的需要，傳進想要渲染的文章即可。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Reference"&gt;Reference&lt;a class="anchor-link" href="#Reference"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jinja.pocoo.org/docs/2.9/templates/#extensions"&gt;Jinja2 Extension&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="資料科學"></category><category term="data-science"></category><category term="日誌"></category></entry><entry><title>BeautifulSoup 筆記</title><link href="https://leemeng.tw/beautifulsoup-cheat-sheet.html" rel="alternate"></link><published>2018-03-02T15:34:00+09:00</published><updated>2018-03-02T15:34:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-02:/beautifulsoup-cheat-sheet.html</id><summary type="html">&lt;p&gt;Beautifulsoup 是一個可以幫助我們 parse HTML 的函式庫，不管是在寫爬蟲還是做 HTML 檔案的處理都很方便。這篇主要紀錄使用 beautifulsoup 時常用的指令。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Beautifulsoup 是一個可以幫助我們 parse HTML 的 lib, 這篇主要紀錄使用 beautifulsoup 時常用的指令。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="安裝"&gt;安裝&lt;a class="anchor-link" href="#安裝"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install beautifulsoup4
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="下載一個網頁並爬出特定內容"&gt;下載一個網頁並爬出特定內容&lt;a class="anchor-link" href="#下載一個網頁並爬出特定內容"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;這邊假設我們想要把維基百科上的&lt;a href="https://zh.wikipedia.org/wiki/ISO_3166-1#cite_note-taiwan-4"&gt;「國家區域代碼」&lt;/a&gt;的表格爬下來，並轉成一個 Pandas 的 Dataframe：&lt;/p&gt;
&lt;center&gt;
&lt;img src="https://leemeng.tw/images/beautifulsoup/wiki.png" style=""/&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;取得某個頁面的 HTML 字串&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;

&lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"https://zh.wikipedia.org/zh-tw/ISO_3166-1"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'html.parser'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;利用 class 從該 HTML 裡取得特定表格&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'wikitable sortable'&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生欄位名稱&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;th&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;th&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'th'&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="n"&gt;columns&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;['英文短名稱', '二位代碼', '三位代碼', '數字代碼', 'ISO 3166-2', '中文名稱', '獨立主權']&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生每個國家的對應資料&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;trs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;
&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;trs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;td&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\xa0&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;td&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'td'&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;[['Afghanistan', 'AF', 'AFG', '004', 'ISO 3166-2:AF', '阿富汗', '是'],
 ['&amp;Aring;land Islands', 'AX', 'ALA', '248', 'ISO 3166-2:AX', '奧蘭', '否'],
 ['Albania', 'AL', 'ALB', '008', 'ISO 3166-2:AL', '阿爾巴尼亞', '是'],
 ['Algeria', 'DZ', 'DZA', '012', 'ISO 3166-2:DZ', '阿爾及利亞', '是'],
 ['American Samoa', 'AS', 'ASM', '016', 'ISO 3166-2:AS', '美屬薩摩亞', '否']]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;產生 Dataframe&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;英文短名稱&lt;/th&gt;
&lt;th&gt;二位代碼&lt;/th&gt;
&lt;th&gt;三位代碼&lt;/th&gt;
&lt;th&gt;數字代碼&lt;/th&gt;
&lt;th&gt;ISO 3166-2&lt;/th&gt;
&lt;th&gt;中文名稱&lt;/th&gt;
&lt;th&gt;獨立主權&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;Afghanistan&lt;/td&gt;
&lt;td&gt;AF&lt;/td&gt;
&lt;td&gt;AFG&lt;/td&gt;
&lt;td&gt;004&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AF&lt;/td&gt;
&lt;td&gt;阿富汗&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;&amp;Aring;land Islands&lt;/td&gt;
&lt;td&gt;AX&lt;/td&gt;
&lt;td&gt;ALA&lt;/td&gt;
&lt;td&gt;248&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AX&lt;/td&gt;
&lt;td&gt;奧蘭&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;Albania&lt;/td&gt;
&lt;td&gt;AL&lt;/td&gt;
&lt;td&gt;ALB&lt;/td&gt;
&lt;td&gt;008&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AL&lt;/td&gt;
&lt;td&gt;阿爾巴尼亞&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;Algeria&lt;/td&gt;
&lt;td&gt;DZ&lt;/td&gt;
&lt;td&gt;DZA&lt;/td&gt;
&lt;td&gt;012&lt;/td&gt;
&lt;td&gt;ISO 3166-2:DZ&lt;/td&gt;
&lt;td&gt;阿爾及利亞&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;American Samoa&lt;/td&gt;
&lt;td&gt;AS&lt;/td&gt;
&lt;td&gt;ASM&lt;/td&gt;
&lt;td&gt;016&lt;/td&gt;
&lt;td&gt;ISO 3166-2:AS&lt;/td&gt;
&lt;td&gt;美屬薩摩亞&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="找出特定-HTML-物件"&gt;找出特定 HTML 物件&lt;a class="anchor-link" href="#找出特定-HTML-物件"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們有一個字串代表一個表格：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"""&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;"""&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;渲染成 HTML:&lt;/p&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;實際 HTML 架構：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
   &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;table&lt;/span&gt; &lt;span class="na"&gt;border&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"1"&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"dataframe"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;thead&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt; &lt;span class="na"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"text-align: right;"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;x&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;y&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;thead&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tbody&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;0&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-2.863752&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-1.066424&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;1&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;th&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;-0.779238&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;0.862169&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;td&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
         &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tr&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;tbody&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
   &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;table&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;利用 &lt;code&gt;BeautifulSoup&lt;/code&gt; 物件 parse HTML:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'html.parser'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;soup&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;找到第一個符合條件的 &lt;code&gt;table&lt;/code&gt; 標籤&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'dataframe'&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;table border="1" class="dataframe"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="設定新屬性-/-class"&gt;設定新屬性 / class&lt;a class="anchor-link" href="#設定新屬性-/-class"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;因為這時候我們取出來的 &lt;code&gt;table&lt;/code&gt; 物件是 reference 到 soup 裡頭對應的物件, 只要直接改變對應的 attr 就會直接反映結果到 &lt;code&gt;soup&lt;/code&gt; 物件:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'class'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'table'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'table-striped'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'table-responsive'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;div&amp;gt;&amp;lt;table border="1" class="dataframe table table-striped table-responsive"&amp;gt;&amp;lt;thead&amp;gt;&amp;lt;tr style="text-align:right;"&amp;gt;&amp;lt;th&amp;gt;&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;x&amp;lt;/th&amp;gt;&amp;lt;th&amp;gt;y&amp;lt;/th&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/thead&amp;gt;&amp;lt;tbody&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;0&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-2.863752&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;-1.066424&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;tr&amp;gt;&amp;lt;th&amp;gt;1&amp;lt;/th&amp;gt;&amp;lt;td&amp;gt;-0.779238&amp;lt;/td&amp;gt;&amp;lt;td&amp;gt;0.862169&amp;lt;/td&amp;gt;&amp;lt;/tr&amp;gt;&amp;lt;/tbody&amp;gt;&amp;lt;/table&amp;gt;&amp;lt;/div&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Iterate-標籤裡頭的子標籤"&gt;Iterate 標籤裡頭的子標籤&lt;a class="anchor-link" href="#Iterate-標籤裡頭的子標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;children&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;{c.name}&lt;/span&gt;&lt;span class="s1"&gt; in &lt;/span&gt;&lt;span class="si"&gt;{table.name}&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_subarea output_stream output_stdout output_text"&gt;
&lt;pre&gt;thead in table
tbody in table
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="移除標籤"&gt;移除標籤&lt;a class="anchor-link" href="#移除標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊假設我們要移除表格裡頭第一行的值 ( 第2個 &lt;code&gt;tr&lt;/code&gt; 標籤 ), 可以對要移除的標籤物件使用 &lt;code&gt;extract()&lt;/code&gt; func.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tr&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'tr'&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;tr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="建立新標籤"&gt;建立新標籤&lt;a class="anchor-link" href="#建立新標籤"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;假設我們想要建立一個新的 &lt;code&gt;blockquote&lt;/code&gt; 標籤，並加入一些文字：&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'I love BeautifulSoup!'&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;blockquote&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;new_tag&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'blockquote'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;blockquote&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;blockquote&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;&amp;lt;blockquote&amp;gt;I love BeautifulSoup!&amp;lt;/blockquote&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="beautifulsoup"></category><category term="html"></category></entry><entry><title>Seaborn 筆記</title><link href="https://leemeng.tw/seaborn-cheat-sheet.html" rel="alternate"></link><published>2018-03-02T00:10:00+09:00</published><updated>2018-03-02T00:10:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-03-02:/seaborn-cheat-sheet.html</id><summary type="html">&lt;p&gt;這篇記錄我在使用 seaborn 做資料分析還有 visualization 時常用的 code. 一般慣例會把 seaborn 更名成 sns for reference.&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇記錄我在使用 &lt;a href="https://seaborn.pydata.org/"&gt;seaborn&lt;/a&gt; 做資料分析還有 visualization 時常用的 code.
一般慣例會把 seaborn 更名成 &lt;code&gt;sns&lt;/code&gt; for reference.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="k"&gt;matplotlib&lt;/span&gt; inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;pd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sns&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="基本設定"&gt;基本設定&lt;a class="anchor-link" href="#基本設定"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊值得注意的是要調整的參數要一次全部設定, 用好幾次 &lt;code&gt;set()&lt;/code&gt; 的話只有最後一次的 &lt;code&gt;set()&lt;/code&gt; 的結果會被保留&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;font&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'IPAPMincho'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Histogram"&gt;Histogram&lt;a class="anchor-link" href="#Histogram"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_text output_subarea output_execute_result"&gt;
&lt;pre&gt;array([-0.53267554,  0.03851161, -0.16072742, -0.70889663,  0.23085979,
       -1.61295347, -0.46508874,  0.60112507,  0.42017249, -0.73656917])&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;seaborn 是建立在 matplotlib 之上, 因此 matplotlib 也可以直接拿來跟 seaborn 產生的圖互動&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Defualt style with kde'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kde&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;

&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_style&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'dark'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Dark style without kde'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;distplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;kde&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Scatter-plot"&gt;Scatter plot&lt;a class="anchor-link" href="#Scatter-plot"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
    &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x&lt;/th&gt;
&lt;th&gt;y&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;-2.863752&lt;/td&gt;
&lt;td&gt;-1.066424&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-0.779238&lt;/td&gt;
&lt;td&gt;0.862169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;0.016786&lt;/td&gt;
&lt;td&gt;-0.016519&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;0.948504&lt;/td&gt;
&lt;td&gt;0.298314&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;2.029428&lt;/td&gt;
&lt;td&gt;1.211997&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;要使用 seaborn 初始設定就再呼叫一次 &lt;code&gt;set()&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;注意點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一般用lmplot畫, 然後設定 &lt;code&gt;fit_reg=False&lt;/code&gt; 就可以讓 regression line 消失. 有時候有沒有那條線影響圖很大&lt;/li&gt;
&lt;li&gt;一樣先 &lt;code&gt;x&lt;/code&gt;, 再 &lt;code&gt;y&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;fit_reg&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lmplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'x'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'y'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;fit_reg&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fit_reg&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
               &lt;span class="n"&gt;scatter_kws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"marker"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"D"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"s"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'Show regression line'&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;fit_reg&lt;/span&gt; &lt;span class="k"&gt;else&lt;/span&gt; &lt;span class="s1"&gt;'Without regression line'&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;想要將兩個 &lt;code&gt;lmplot&lt;/code&gt; 並排 render 可以參考這個 &lt;a href="https://stackoverflow.com/a/33091668/3859572"&gt;stackoverflow 答案&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Correlation-matrix-/-Heatmap"&gt;Correlation matrix / Heatmap&lt;a class="anchor-link" href="#Correlation-matrix-/-Heatmap"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;df&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DataFrame&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;
    &lt;span class="s1"&gt;'x1'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'x2'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    &lt;span class="s1"&gt;'x3'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;0&lt;/th&gt;
&lt;td&gt;1.269566&lt;/td&gt;
&lt;td&gt;0.349083&lt;/td&gt;
&lt;td&gt;-0.000743&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;1&lt;/th&gt;
&lt;td&gt;-1.634587&lt;/td&gt;
&lt;td&gt;0.072568&lt;/td&gt;
&lt;td&gt;0.042596&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;td&gt;-0.581238&lt;/td&gt;
&lt;td&gt;-0.337935&lt;/td&gt;
&lt;td&gt;-0.412084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;td&gt;-0.080881&lt;/td&gt;
&lt;td&gt;-1.376481&lt;/td&gt;
&lt;td&gt;1.361046&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;td&gt;-0.609886&lt;/td&gt;
&lt;td&gt;-1.061285&lt;/td&gt;
&lt;td&gt;0.265788&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這邊利用 pandas 本身的 &lt;code&gt;corr()&lt;/code&gt; 計算 correlation matrix 然後使用 seaborn 做 vis.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;df&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;corr&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_html rendered_html output_subarea output_execute_result"&gt;
&lt;div&gt;
&lt;style scoped=""&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border="1" class="dataframe table table-striped table-responsive"&gt;
&lt;thead&gt;
&lt;tr style="text-align: right;"&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;x1&lt;/th&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;td&gt;-0.034731&lt;/td&gt;
&lt;td&gt;0.032407&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;x2&lt;/th&gt;
&lt;td&gt;-0.034731&lt;/td&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;td&gt;-0.192169&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th&gt;x3&lt;/th&gt;
&lt;td&gt;0.032407&lt;/td&gt;
&lt;td&gt;-0.192169&lt;/td&gt;
&lt;td&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="input_area"&gt;
&lt;div class=" highlight hl-ipython3"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;heatmap&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'Blues'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;annot_kws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"size"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
            &lt;span class="n"&gt;xticklabels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;yticklabels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;corr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="output_wrapper"&gt;
&lt;div class="output"&gt;
&lt;div class="output_area"&gt;
&lt;div class="output_png output_subarea "&gt;
&lt;img src="data:image/png;base64,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
"/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="References"&gt;References&lt;a class="anchor-link" href="#References"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://seaborn.pydata.org/api.html"&gt;API References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="seaborn"></category><category term="資料視覺化"></category></entry><entry><title>SQLite 筆記</title><link href="https://leemeng.tw/sqlite-note.html" rel="alternate"></link><published>2018-02-23T22:00:00+09:00</published><updated>2018-02-23T22:00:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2018-02-23:/sqlite-note.html</id><summary type="html">&lt;p&gt;這篇主要紀錄使用 SQLite shell 下 SQL Query 的指令。基本上在 shell 裡頭都是用 dot-command, 使用 .help 可以顯示所有可用的指令。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Table-of-Contents"&gt;Table of Contents&lt;a class="anchor-link" href="#Table-of-Contents"&gt;&amp;para;&lt;/a&gt;&lt;/h1&gt;&lt;div class="toc" style="margin-top: 1em;"&gt;&lt;ul class="toc-item" id="toc-level0"&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="Prettier-output-1" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#Prettier-output"&gt;Prettier output&lt;/a&gt;&lt;/span&gt;&lt;ul class="toc-item"&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="調整每一個-column-寬度-1.1" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#調整每一個-column-寬度"&gt;調整每一個 column 寬度&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="在-sqlite3-shell-裡清空畫面-2" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#在-sqlite3-shell-裡清空畫面"&gt;在 sqlite3 shell 裡清空畫面&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="使用-SQL-script-建立-tables-3" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#使用-SQL-script-建立-tables"&gt;使用 SQL script 建立 tables&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示目前的-tables-4" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示目前的-tables"&gt;顯示目前的 tables&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示-table-schema-5" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示-table-schema"&gt;顯示 table schema&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;a data-toc-modified-id="顯示-indexes-6" href="http://localhost:8890/notebooks/content/20180222-SQLite-practice-1.ipynb#顯示-indexes"&gt;顯示 indexes&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;這篇主要紀錄使用 SQLite shell 下 SQL Query 的指令。基本上在 shell 裡頭都是用 dot-command, 使用 &lt;code&gt;.help&lt;/code&gt; 可以顯示所有可用的指令.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Prettier-output"&gt;Prettier output&lt;a class="anchor-link" href="#Prettier-output"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在 command-line program 裡頭使用的 response format&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.mode column
.headers on

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Example output&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Code        Name        Price       Manufacturer
----------  ----------  ----------  ------------
7           CD drive    90          2           
9           Toner cart  66          3           

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="調整每一個-column-寬度"&gt;調整每一個 column 寬度&lt;a class="anchor-link" href="#調整每一個-column-寬度"&gt;&amp;para;&lt;/a&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;.width 5 18 15

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;缺點是不同的 tables, 不同的 columns 需要的寬度不同, 要自己調整
要重置設定:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.width 0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="在-sqlite3-shell-裡清空畫面_1"&gt;在 sqlite3 shell 裡清空畫面&lt;a class="anchor-link" href="#在-sqlite3-shell-裡清空畫面"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;要看 OS 決定實際的 shell command&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.shell clear

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;除了 &lt;code&gt;clear&lt;/code&gt; 以外, 其他 shell command都能使用, e.g.,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.shell cd&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="使用-SQL-script-建立-tables"&gt;使用 SQL script 建立 tables&lt;a class="anchor-link" href="#使用-SQL-script-建立-tables"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;比方我們有一個 &lt;code&gt;create_tables.sql&lt;/code&gt; 內容是：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE Departments (
  Code INTEGER PRIMARY KEY,
  Name varchar(255) NOT NULL ,
  Budget decimal NOT NULL 
);

INSERT INTO Departments(Code,Name,Budget) VALUES(14,'IT',65000);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我們可以用 &lt;code&gt;.read&lt;/code&gt; dot-command 在 shell 跑該 script 建立 &lt;code&gt;Department&lt;/code&gt; table:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.read create_tables.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示目前的-tables"&gt;顯示目前的 tables&lt;a class="anchor-link" href="#顯示目前的-tables"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.tables&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示-table-schema"&gt;顯示 table schema&lt;a class="anchor-link" href="#顯示-table-schema"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.schema &amp;lt;TABLE_NAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="顯示-indexes"&gt;顯示 indexes&lt;a class="anchor-link" href="#顯示-indexes"&gt;&amp;para;&lt;/a&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;.indexes

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 Table T 的 Column C 建立 index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE INDEX &amp;lt;INDEX_NAME&amp;gt; ON T(C);

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;砍掉 index&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DROP INDEX &amp;lt;INDEX_NAME&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="SQL"></category><category term="SQLite"></category><category term="資料庫"></category></entry><entry><title>Purpose of this blog</title><link href="https://leemeng.tw/purpose-of-this-blog.html" rel="alternate"></link><published>2017-09-17T12:30:00+09:00</published><updated>2017-09-17T12:30:00+09:00</updated><author><name>Lee Meng</name></author><id>tag:leemeng.tw,2017-09-17:/purpose-of-this-blog.html</id><summary type="html">&lt;p&gt;第一篇文章做一點 blog 的簡介，打算把自己在學 data science 還有 machine learning 過程中寫的筆記還有在 MOOC 上課的 code (主要是 jupyter notebook) 記錄下來方便自己以後搜尋。&lt;/p&gt;</summary><content type="html">
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;第一篇文章做一點 blog 的簡介，打算把自己在學 data science 還有 machine learning 過程中寫的筆記還有在 MOOC 上課的 code (主要是 jupyter notebook) 記錄下來方便自己以後搜尋。 雖然目前為止我都將 jupyter notebook render 成 HTML 然後存到 Evernote 搜尋, 但是如果該 notebook 一直更新的話就變得很不實際..&lt;/p&gt;
&lt;p&gt;&amp;lt;/br&amp;gt;
這次利用 python 的 pelican 將 jupyter notebook 轉成靜態網頁, 讓我可以不斷更新 notebooks 而且也希望 code 可以幫助到其他也在做 data science / machine learning 的人當作一些參考。 blog 的走向目前看來應該會是中英夾雜 ..&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is the first post of my blog.&lt;/p&gt;
&lt;p&gt;&amp;lt;/br&amp;gt;
I decided to record my learning path toward data scientist / machine learning engineer and make it easier for my future self to review what I have learnt. This blog will include codes from the courses on MOOC like Coursera, Udacity and also some pet projects. It would also be wonderful if these code and thought can help someone who want to become a data scientist.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="pelican"></category><category term="資料科學"></category><category term="blogging"></category></entry></feed>