{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vUI-dMnfxKbb"
   },
   "source": [
    "- author: Lee Meng\n",
    "- date: 2019-09-21 17:22\n",
    "- title: 神經網路的本質：直觀理解神經網路 & 線性代數\n",
    "- slug: the-essence-of-neural-network-better-understanding-of-nn-and-linear-algebra\n",
    "- tags: Manim, Python\n",
    "- summary: s\n",
    "- description: s \n",
    "- image: TwoLayersReLUInBetweenSolveHardTwoCurves.jpg\n",
    "- status: draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!quote\n",
    "- 這是篇透過動畫來「直觀」理解神經網路的科普文。讀完本文，你將能夠更直觀地體會神經網路與線性代數之間的緊密關係，並進一步展開自己的深度學習之旅。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（小提醒：因動畫皆為暗色背景，本文適合以**暗色模式**閱讀。你可以點擊頁面左下的按鈕來切換模式）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這是個眾人對人工智慧（**A**rtificial **I**ntelligence, AI）趨之若鶩的時代。此領域近年的快速發展很大一部份可歸功於[深度學習](https://leemeng.tw/deep-learning-resources.html)以及[人工神經網路（**N**eural **N**etwork, 後簡稱為 NN）](https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)。深度學習框架也日漸成熟，讓任何人都可以輕易地使用 [TensorFlow](https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/quickstart/beginner.ipynb) 或 [PyTorch](https://pytorch.org/) 在 30 秒內就訓練出一個具有 98% 正確率的阿拉伯數字辨識模型：\n",
    "\n",
    "```python\n",
    "# 此例使用 TensorFlow，但各大深度學習框架的實現邏輯基本上類似\n",
    "import tensorflow as tf\n",
    "\n",
    "# 載入深度學習 Hello World: MNIST 數字 dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 建立一個具有 10 萬參數的神經網路（模型）\n",
    "# 在現在模型參數動輒上千萬的年代，此神經網路可說是小到不行\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 選擇 loss func、optimizer 並訓練模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 訓練後的 NN 在測試集上可得到近 98% 正確辨識率\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "# 測試結果\n",
    "# loss: 0.0750 - accuracy: 0.9763\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是的，15 行內就搞定了。有興趣的讀者也可以執行[這個 Colab 筆記本](https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/r2/tutorials/quickstart/beginner.ipynb)。我假設你已經能夠讀懂上面這段 [Python](https://www.python.org/) 程式碼並了解大多數線上課程都會教的[基本神經網路概念](https://www.youtube.com/watch?v=Dr-WRlEFefw)。本文的目的是透過一些圖片與動畫，來讓你對神經網路（NN）多些更**直觀**的理解。\n",
    "\n",
    "回到我們剛剛建立的 NN。儘管擁有近 10 萬個可訓練參數，上面這個透過 [Keras](https://www.tensorflow.org/guide/keras) 定義的 `model` 是個在深度學習領域裡會被視為 Hello World 等級的**簡單**神經網路。這很正常，畢竟我們在之前跟自然語言處理相關的 [BERT](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html) 以及 [GPT-2 文章](https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html)裡看到的都是擁有**上億**參數的強大神經網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!image\n",
    "- manim/mnist-simple.jpg\n",
    "- 輸入是 28*28 = 768 維的圖片像素，輸出則是 10 個數字類別的簡單 2-layers NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但就算是一個如此「簡單」的 NN，你真的跟它夠「熟」嗎？\n",
    "\n",
    "講白點，儘管現在會使用 TensorFlow 或是 PyTorch 來建立神經網路的人多如牛毛，不少人（包含剛入門的我）事實上對最基本的神經網路也沒有足夠直觀的理解。而之所以會有這樣的現象，主要是因為：\n",
    "- 強大的深度學習框架把底層細節邏輯都包了起來\n",
    "- 不少人到現在還沒搞懂跟 NN 相關的[線性代數](https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)概念\n",
    "- 能視覺化神經網路內部機制的手法並不那麼普遍\n",
    "\n",
    "為了讓更多人能夠更**直觀**地體會神經網路的運作方式，在本文我將透過以下 3 者：\n",
    "1. 繪圖工具：[3Blue1Brown](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) 的強大 Python 動畫引擎 [Manim](https://github.com/3b1b/manim)\n",
    "2. 學習任務：比 [MNIST](https://en.wikipedia.org/wiki/MNIST_database) 還簡單的[二分類](https://en.wikipedia.org/wiki/Binary_classification)問題\n",
    "3. 模型架構：1 到 2 層、只有不到 10 個參數的超簡單神經網路\n",
    "\n",
    "來闡述基本的 NN 以及相關線性代數（Linear Algebra）概念。如果這 idea 聽起來還不錯，或是你喜歡看動畫來了解數學概念，那我會建議你繼續閱讀：）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 返璞歸真：神經網路是怎麼解決二分類任務？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[二分類（Binary Classification）](https://en.wikipedia.org/wiki/Binary_classification)是一個在[機器學習（Machine Learning）](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML19.html)領域中時常出現的詞彙，指的是將一個集合（set）的元素依照某種分類規則（classification rule）劃分成兩個族群（groups）的任務。換句話說，預測每個數據點（data point）屬於兩個族群裡頭的哪一個。\n",
    "\n",
    "我知道，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "會寫金庸，能做英翻中，能偵測 fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一印象：直觀感受簡單 NN 如何解決二分類任務"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "秀出 data 圖，問讀者要怎麼解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的時間寶貴，因此我事先將本文的精華都濃縮在底下這個 1 分鐘的短片了。此影片展示了一個簡單神經網路解決二分類任務的**完整過程**。我等等會更仔細地說明影片內容，但現在請你馬上點擊播放鍵觀看吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!mp4\n",
    "- options: no-loop, no-autoplay, controls\n",
    "- images/manim/TwoLayersReLUInBetweenSolveHardTwoCurves.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "順帶一提，這是一個只有 9 個參數的神經網路，其規模跟現在媒體整天在報導的 A.I. 相比可說是滄海一粟。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!quote\n",
    "- 但這是我看過最美麗、直觀的神經網路運作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我不知道看影片前的你對神經網路或是線性代數的理解程度，但我相信很多人都能在這短短的一分鐘內（重新）獲得些啟發。如果你願意，我強烈建議你至少再看一次影片並在需要時暫停咀嚼。裡頭有很多十分基本但重要的 NN 概念值得掌握。\n",
    "\n",
    "你有再看一遍嗎？讓我幫你把影片裡隱含的重要概念一一列出：\n",
    "- 神經網路是將輸入（維度）做一連串簡單轉換，最後得到理想輸出（維度）的函式\n",
    "- 最基本且常見的神經網路是「層」為單位，每一層的矩陣相乘事實上都在做線性轉換\n",
    "- 線性轉換基本上就是對輸入空間的數據做旋轉、縮放、延伸等轉換\n",
    "- 層跟層之間常會透過非線性轉換函式來提升神經網路整體的轉換能力\n",
    "- 神經網路也常被視為是在做 representation learning，因為每一層的轉換都將該層輸入的數據轉換成更適合達到任務目標的形式\n",
    "- 透過對輸入數據做一連串適當的\n",
    "- 針對某些任務，特定的神經網路架構有其能力極限，我們透過學習從該架構中找出一組參數，讓神經網路做適合的轉換以完成任務\n",
    "\n",
    "\n",
    "很多東西你可能都知道了，人類是視覺動物，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結論\n",
    "- 下一代"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
