<!DOCTYPE html>
<!--[if lt IE 9 ]><html class="no-js oldie" lang="zh-hant-tw"> <![endif]-->
<!--[if IE 9 ]><html class="no-js oldie ie9" lang="zh-hant-tw"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html class="no-js" lang="zh-hant-tw">
<!--<![endif]-->

<head>

    <!--- basic page needs
    ================================================== -->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="author" content="Lee Meng" />
<title>LeeMeng - 淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯</title>
    <!--- article-specific meta data
    ================================================== -->
        <meta name="description" content="" />
        <meta name="keywords" content="自然語言處理, NLP, Tensorflow" />
        <meta name="tags" content="自然語言處理" />
        <meta name="tags" content="NLP" />
        <meta name="tags" content="Tensorflow" />


    <!--- Open Graph Object metas
    ================================================== -->
        <meta property="og:image" content="https://leemeng.tw/theme/images/background/Tour_de_babel.jpg" />
        <meta property="og:type" content="article" />
        <meta property="og:url" content="https://leemeng.tw/drafts/neural-machine-translation-with-transformer-and-tensorflow2.html" />
        <meta property="og:title" content="淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯" />
        <meta property="og:description" content="" />

    <!-- mobile specific metas
    ================================================== -->
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- CSS
    ================================================== -->
    <!--for customized css in individual page-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/bootstrap.min.css">

    <!--for showing toc navigation which slide in from left-->
        <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/toc-nav.css">

    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/base.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/vendor.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/main.css">
    <link rel="stylesheet" type="text/css" href="https://leemeng.tw/theme/css/ipython.css">
    <link rel="stylesheet" type="text/css" href='https://leemeng.tw/theme/css/progress-bar.css' />


    <!--TiqueSearch-->
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/normalize.css">
    <link rel="stylesheet" href="https://leemeng.tw/theme/tipuesearch/css/tipuesearch.css">

    <!-- script
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/modernizr.js"></script>
    <script src="https://leemeng.tw/theme/js/pace.min.js"></script>


    <!-- favicons
    ================================================== -->
    <link rel="shortcut icon" href="../theme/images/favicon.ico" type="image/x-icon"/>
    <link rel="icon" href="../theme/images/favicon.ico" type="image/x-icon"/>

<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-106559980-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments)};
  gtag('js', new Date());

  gtag('config', 'UA-106559980-1');
</script>



</head>


<body id="top">

    <!-- header
    ================================================== -->
    <header class="s-header">

        <div class="header-logo">
            <a class="site-logo" href="../index.html"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
        </div>
<!--navigation bar ref: http://jinja.pocoo.org/docs/2.10/tricks/-->



<nav class="header-nav-wrap">
    <ul class="header-nav">
        <li>
            <a href="../index.html#home">Home</a>
        </li>
        <li>
            <a href="../index.html#about">About</a>
        </li>
        <li>
            <a href="../index.html#projects">Projects</a>
        </li>
        <li class="current">
            <a href="../blog.html">Blog</a>
        </li>
        <li>
            <a href="https://demo.leemeng.tw">Demo</a>
        </li>
        <li>
            <a href="../books.html">Books</a>
        </li>
        <li>
            <a href="../index.html#contact">Contact</a>
        </li>

    </ul>

    <!--<div class="search-container">-->
        <!--<form action="../search.html">-->
            <!--<input type="text" placeholder="Search.." name="search">-->
            <!--<button type="submit"><i class="im im-magnifier" aria-hidden="true"></i></button>-->
        <!--</form>-->
    <!--</div>-->

</nav>
        <a class="header-menu-toggle" href="#0"><span>Menu</span></a>

    </header> <!-- end s-header -->



    <!--TOC navigation displayed when clicked from left-navigation button-->
    <div id="tocNav" class="overlay" onclick="closeTocNav()">
      <div class="overlay-content">
        <div id="toc"><ul><li><a class="toc-href" href="#" title="淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯">淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯</a><ul><li><a class="toc-href" href="#Experiment" title="Experiment">Experiment</a></li><li><a class="toc-href" href="#Gdrive" title="Gdrive">Gdrive</a></li><li><a class="toc-href" href="#Setup-input-pipeline" title="Setup input pipeline">Setup input pipeline</a><ul><li><a class="toc-href" href="#TODO" title="TODO">TODO</a></li></ul></li><li><a class="toc-href" href="#Positional-encoding_1" title="Positional encoding">Positional encoding</a></li><li><a class="toc-href" href="#Masking" title="Masking">Masking</a><ul><li><a class="toc-href" href="#TODO_1" title="TODO">TODO</a></li></ul></li><li><a class="toc-href" href="#Scaled-dot-product-attention_1" title="Scaled dot product attention">Scaled dot product attention</a></li><li><a class="toc-href" href="#Multi-head-attention" title="Multi-head attention">Multi-head attention</a></li><li><a class="toc-href" href="#Point-wise-feed-forward-network" title="Point wise feed forward network">Point wise feed forward network</a></li><li><a class="toc-href" href="#Encoder-and-decoder" title="Encoder and decoder">Encoder and decoder</a><ul><li><a class="toc-href" href="#Encoder-layer" title="Encoder layer">Encoder layer</a></li><li><a class="toc-href" href="#Decoder-layer" title="Decoder layer">Decoder layer</a></li><li><a class="toc-href" href="#Encoder" title="Encoder">Encoder</a></li><li><a class="toc-href" href="#Decoder" title="Decoder">Decoder</a></li></ul></li><li><a class="toc-href" href="#Create-the-Transformer_1" title="Create the Transformer">Create the Transformer</a></li><li><a class="toc-href" href="#Set-hyperparameters" title="Set hyperparameters">Set hyperparameters</a><ul><li><a class="toc-href" href="#Setup-experiment-path" title="Setup experiment path">Setup experiment path</a></li></ul></li><li><a class="toc-href" href="#Optimizer_1" title="Optimizer">Optimizer</a></li><li><a class="toc-href" href="#Loss-and-metrics" title="Loss and metrics">Loss and metrics</a></li><li><a class="toc-href" href="#Training-and-checkpointing" title="Training and checkpointing">Training and checkpointing</a><ul><li><a class="toc-href" href="#Chinese-font-setup-for-matplotlib" title="Chinese font setup for matplotlib">Chinese font setup for matplotlib</a></li><li><a class="toc-href" href="#TODO_2" title="TODO">TODO</a></li></ul></li><li><a class="toc-href" href="#Tensorboard_1" title="Tensorboard">Tensorboard</a></li><li><a class="toc-href" href="#Evaluate" title="Evaluate">Evaluate</a></li><li><a class="toc-href" href="#Summary" title="Summary">Summary</a></li></ul></li></ul></div>
      </div>
    </div>

    <!--custom images with icon shown on left nav-->
    <!--the details are set in `pelicanconf.py` as `LEFT_NAV_IMAGES`-->

    <article class="blog-single">

        <!-- page header/blog hero, use custom cover image if available
        ================================================== -->
            <div class="page-header page-header--single page-hero" style="background-image:url(https://leemeng.tw/theme/images/background/Tour_de_babel.jpg)">

            <div class="row page-header__content narrow">
                <article class="col-full">
                    <div class="page-header__info">
                        <div class="page-header__cat">
                            <a href="https://leemeng.tw/tag/zi-ran-yu-yan-chu-li.html" rel="tag">自然語言處理</a>
                            <a href="https://leemeng.tw/tag/nlp.html" rel="tag">NLP</a>
                            <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">Tensorflow</a>
                        </div>
                    </div>
                    <h1 class="page-header__title">
                        <a href="https://leemeng.tw/drafts/neural-machine-translation-with-transformer-and-tensorflow2.html" title="">
                            淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯
                        </a>
                    </h1>
                    <ul class="page-header__meta">
                        <li class="date">2019-06-03 (Mon)</li>
                        <li class="page-view">
                            1 views
                        </li>
                    </ul>

                </article>
            </div>

        </div> <!-- end page-header -->

        <div class="KW_progressContainer">
            <div class="KW_progressBar"></div>
        </div>

        <div class="row blog-content" style="position: relative">
<div id="left-navigation">

    <div id="search-wrap">
        <i class="im im-magnifier" aria-hidden="true"></i>
        <div id="search">
            <form action="../search.html">
            <div class="tipue_search_right"><input type="text" name="q" id="tipue_search_input" pattern=".{2,}" title="想搜尋什麼呢？（請至少輸入兩個字）" required></div>
            </form>
        </div>
    </div>

    <div id="toc-wrap">
        <a title="顯示/隱藏 文章章節">
            <i class="im im-menu" aria-hidden="true" onclick="toggleTocNav()"></i>
        </a>
    </div>



    <!--custom images with icon shown on left nav-->

</div>

            <div class="col-full blog-content__main">

                
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote>
<p>
                        那時，全世界的語言都一樣。『來吧，我們要建造一座城和一座塔，塔頂通天，為了揚我們的名，免得我們被分散到世界各地。』耶和華說：『看哪！他們成爲一樣的人民、用同樣的語言。如今既蓋起塔來，以後只要是他們想要做的任何事情、就沒有無法完成的了。我們下去！在那裏變亂他們的口音，使他們的言語彼此不通。』
                        <br/>
<span style="float:right;margin-right: 1.5rem">─ 《創世記》第十一章</span>
<br/>
</p>
</blockquote>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>TOC</p>
<ul>
<li>MT intro<ul>
<li>pbmt</li>
<li>seq2seq</li>
<li>seq2seq with attention</li>
<li>切入上面這個 transformer 的圖: self-attention</li>
<li>vis 介紹 intution</li>
<li>MIT tools</li>
</ul>
</li>
<li>Transformer 實作</li>
<li>Tensor2tensor 套用 Transformer</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>先想 input / output 是什麼，再實作</p>
<p>Components and implementation order</p>
<ul>
<li>~Masking (Masked Multi-Head Attention 起頭)~<ul>
<li>~padding mask~</li>
<li>~look ahead mask~</li>
</ul>
</li>
<li>~Scaled Dot-Product Attention~</li>
<li>~Multi-Head Attention~</li>
<li>~Feed Forward~</li>
<li>~Encoder block~<ul>
<li>~Residual Connection &amp; Layer Normalization~</li>
</ul>
</li>
<li>Decoder block</li>
<li>Encoder</li>
<li>Decoder</li>
<li>Positional Encoding</li>
<li>Transformer</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table align="left" class="tfo-notebook-buttons table table-striped table-responsive">
<td>
<a href="https://www.tensorflow.org/alpha/tutorials/text/transformer" target="_blank">
<img src="https://www.tensorflow.org/images/tf_logo_32px.png"/>
    View on TensorFlow.org</a>
</td>
<td>
<a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb" target="_blank">
<img src="https://www.tensorflow.org/images/colab_logo_32px.png"/>
    Run in Google Colab</a>
</td>
<td>
<a href="https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/text/transformer.ipynb" target="_blank">
<img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png"/>
    View source on GitHub</a>
</td>
</table>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This tutorial trains a <a class="external" href="https://arxiv.org/abs/1706.03762">Transformer model</a> to translate Portuguese to English. This is an advanced example that assumes knowledge of <a href="text_generation.ipynb">text generation</a> and <a href="nmt_with_attention.ipynb">attention</a>.</p>
<p>The core idea behind the Transformer model is <em>self-attention</em>&mdash;the ability to attend to different positions of the input sequence to compute a representation of that sequence. Transformer creates stacks of self-attention layers and is explained below in the sections <em>Scaled dot product attention</em> and <em>Multi-head attention</em>.</p>
<p>A transformer model handles variable-sized input using stacks of self-attention layers instead of <a href="text_classification_rnn.ipynb">RNNs</a> or <a href="../images/intro_to_cnns.ipynb">CNNs</a>. This general architecture has a number of advantages:</p>
<ul>
<li>It make no assumptions about the temporal/spatial relationships across the data. This is ideal for processing a set of objects (for example, <a href="https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8">StarCraft units</a>).</li>
<li>Layer outputs can be calculated in parallel, instead of a series like an RNN.</li>
<li>Distant items can affect each other's output without passing through many RNN-steps, or convolution layers (see <a href="https://arxiv.org/pdf/1903.03878.pdf">Scene Memory Transformer</a> for example).</li>
<li>It can learn long-range dependencies. This is a challenge in many sequence tasks.</li>
</ul>
<p>The downsides of this architecture are:</p>
<ul>
<li>For a time-series, the output for a time-step is calculated from the <em>entire history</em> instead of only the inputs and current hidden-state. This <em>may</em> be less efficient.   </li>
<li>If the input <em>does</em> have a  temporal/spatial relationship, like text, some positional encoding must be added or the model will effectively see a bag of words. </li>
</ul>
<p>After training the model in this notebook, you will be able to input a Portuguese sentence and return the English translation.</p>
<p><img alt="Attention heatmap" src="https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png" width="800"/></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">clear_output</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install tf-nightly-gpu-2.0-preview
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow_datasets</span> <span class="k">as</span> <span class="nn">tfds</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>在 TF2 裡頭 <code>tf.logging</code> 被 deprecated，我們可以直接用 <code>logging</code>  模組：
ref: <a href="https://www.tensorflow.org/alpha/guide/effective_tf2">https://www.tensorflow.org/alpha/guide/effective_tf2</a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="s2">"error"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>'2.0.0-dev20190525'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Experiment">Experiment<a class="anchor-link" href="#Experiment">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># corpus_generator = ['使用 Transformer 做機器翻譯很猛']</span>
<span class="c1"># tokenizer_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(corpus_generator, target_vocab_size=2**13, max_subword_length=1)</span>

<span class="c1"># sample_string = '使用 Transformer 做機器翻譯很猛'</span>

<span class="c1"># tokenized_string = tokenizer_zh.encode(sample_string)</span>
<span class="c1"># print ('Tokenized string is {}'.format(tokenized_string))</span>

<span class="c1"># original_string = tokenizer_zh.decode(tokenized_string)</span>
<span class="c1"># print ('The original string: {}'.format(original_string))</span>

<span class="c1"># assert original_string == sample_string</span>

<span class="c1"># for ts in tokenized_string:</span>
<span class="c1">#   print ('{} ----&gt; {}'.format(ts, tokenizer_zh.decode([ts])))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># tokenizer_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(</span>
<span class="c1">#     (zh.numpy() for zh, _ in train_examples), target_vocab_size=2**17)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># sample_string = '使用 Transformer 做機器翻譯很猛'</span>

<span class="c1"># tokenized_string = tokenizer_zh.encode(sample_string)</span>
<span class="c1"># print ('Tokenized string is {}'.format(tokenized_string))</span>

<span class="c1"># original_string = tokenizer_zh.decode(tokenized_string)</span>
<span class="c1"># print ('The original string: {}'.format(original_string))</span>

<span class="c1"># assert original_string == sample_string</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for ts in tokenized_string:</span>
<span class="c1">#   print ('{} ----&gt; {}'.format(ts, tokenizer_zh.decode([ts])))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gdrive">Gdrive<a class="anchor-link" href="#Gdrive">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">save_to_gdrive</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="s2">"nmt"</span>

<span class="k">if</span> <span class="n">save_to_gdrive</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="k">import</span> <span class="n">drive</span>
    <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">'/content/gdrive'</span><span class="p">)</span>
    <span class="n">output_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">"/content/gdrive/My Drive"</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">)</span>
    

<span class="n">en_vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"en_vocab"</span><span class="p">)</span>
<span class="n">zh_vocab_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"zh_vocab"</span><span class="p">)</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s2">"checkpoints"</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'logs'</span><span class="p">)</span>

    
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Save result to </span><span class="si">{output_dir}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&amp;response_type=code

Enter your authorization code:
&middot;&middot;&middot;&middot;&middot;&middot;&middot;&middot;&middot;&middot;
Mounted at /content/gdrive
Save result to /content/gdrive/My Drive/nmt
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span>
  <span class="n">en_vocab_file</span><span class="p">,</span>
  <span class="n">zh_vocab_file</span><span class="p">,</span>
  <span class="n">checkpoint_path</span><span class="p">,</span>
  <span class="n">log_dir</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>['/content/gdrive/My Drive/nmt/en_vocab',
 '/content/gdrive/My Drive/nmt/zh_vocab',
 '/content/gdrive/My Drive/nmt/checkpoints',
 '/content/gdrive/My Drive/nmt/logs']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup-input-pipeline">Setup input pipeline<a class="anchor-link" href="#Setup-input-pipeline">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Use <a href="https://www.tensorflow.org/datasets">TFDS</a> to load the <a href="https://github.com/neulab/word-embeddings-for-nmt">Portugese-English translation dataset</a> from the <a href="https://www.ted.com/participate/translate">TED Talks Open Translation Project</a>.</p>
<p>This dataset contains approximately 50000 training examples, 1100 validation examples, and 2000 test examples.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>dataset reference: <a href="https://www.tensorflow.org/datasets/datasets#wmt19_translate">https://www.tensorflow.org/datasets/datasets#wmt19_translate</a></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># # 顯示 subset 用</span>
<span class="c1"># tmp_builder = tfds.builder("wmt19_translate/zh-en")</span>
<span class="c1"># tmp_builder.subsets</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">translate</span><span class="o">.</span><span class="n">wmt</span><span class="o">.</span><span class="n">WmtConfig</span><span class="p">(</span>
    <span class="n">version</span><span class="o">=</span><span class="s2">"0.0.2"</span><span class="p">,</span>
    <span class="n">language_pair</span><span class="o">=</span><span class="p">(</span><span class="s2">"zh"</span><span class="p">,</span> <span class="s2">"en"</span><span class="p">),</span>
    <span class="n">subsets</span><span class="o">=</span><span class="p">{</span>
        <span class="n">tfds</span><span class="o">.</span><span class="n">Split</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span> <span class="p">[</span><span class="s2">"newscommentary_v14"</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">builder</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">builder</span><span class="p">(</span><span class="s2">"wmt_translate"</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">builder</span><span class="o">.</span><span class="n">download_and_prepare</span><span class="p">()</span>
<span class="c1"># builder.download_and_prepare(download_dir="tensorflow-datasets/downloads")</span>
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>reference:</p>
<ul>
<li><a href="https://github.com/tensorflow/datasets/blob/master/docs/splits.md">https://github.com/tensorflow/datasets/blob/master/docs/splits.md</a></li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_perc</span> <span class="o">=</span> <span class="mi">90</span>
<span class="n">drop_prec</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">train_perc</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">split</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">Split</span><span class="o">.</span><span class="n">TRAIN</span><span class="o">.</span><span class="n">subsplit</span><span class="p">([</span><span class="n">drop_prec</span><span class="p">,</span> <span class="n">train_perc</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">split</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(NamedSplit('train')(tfds.percent[0:9]),
 NamedSplit('train')(tfds.percent[9:99]),
 NamedSplit('train')(tfds.percent[99:100]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">examples</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">as_dataset</span><span class="p">(</span><span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">metadata</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">info</span>
<span class="n">examples</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(&lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&gt;,
 &lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&gt;,
 &lt;_OptionsDataset shapes: ((), ()), types: (tf.string, tf.string)&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">train_examples</span><span class="p">,</span> <span class="n">val_examples</span> <span class="o">=</span> <span class="n">examples</span>
<span class="c1"># train_examples, val_examples = examples</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_samples</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">sample_examples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">en</span><span class="p">,</span> <span class="n">zh</span> <span class="ow">in</span> <span class="n">train_examples</span><span class="p">:</span>
    <span class="n">num_en_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">en</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
    <span class="n">num_zh_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">zh</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">num_zh_words</span> <span class="o">&lt;</span> <span class="mi">16</span> <span class="ow">or</span> <span class="n">num_zh_words</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
      <span class="k">continue</span>
    
    <span class="k">if</span> <span class="n">num_en_words</span> <span class="o">&lt;</span> <span class="mi">5</span> <span class="ow">or</span> <span class="n">num_en_words</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
      <span class="k">continue</span>
  
    <span class="n">sample_examples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span>
        <span class="n">en</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">),</span>
        <span class="n">zh</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
    <span class="p">))</span>
    <span class="n">c</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">c</span> <span class="o">&gt;</span> <span class="n">num_samples</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fix sentence for consistency</span>
<span class="n">sample_examples</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">'This year will be another difficult one for China.'</span><span class="p">,</span> <span class="s1">'今年对中国来说又将是艰难的一年。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'It is the only such case in the world.'</span><span class="p">,</span> <span class="s1">'它是世界上此类案例中唯一的一个。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'When that happens, a recession typically follows.'</span><span class="p">,</span> <span class="s1">'一旦出现这种情况衰退通常就会随之而来。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Right-wing populists such as Trump engage in identity politics.'</span><span class="p">,</span>
  <span class="s1">'特朗普等右翼民粹主义者采取身份政治。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Given the reaction in financial markets, they have succeeded.'</span><span class="p">,</span>
  <span class="s1">'鉴于金融市场的反应，他们已经成功了。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'The first lesson is that markets are not self-correcting.'</span><span class="p">,</span>
  <span class="s1">'第一个教训是，市场不会自动纠正错误。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'And they are gateways to Europe, Africa, and Asia.'</span><span class="p">,</span> <span class="s1">'它们也是通往欧洲、非洲和亚洲的门户。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Will the energy reforms produce another false dawn?'</span><span class="p">,</span> <span class="s1">'能源改革会再一次只是昙花一现吗？'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'In economic terms, they have had considerable success.'</span><span class="p">,</span>
  <span class="s1">'在经济方面，它们取得了相当大的成功。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'But even this comparison involves a selection bias.'</span><span class="p">,</span>
  <span class="s1">'但是，就连这个比较也带有一定的选择偏误。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'The shifting economic operating environment bolsters these opportunities.'</span><span class="p">,</span>
  <span class="s1">'不断变化的经济运行环境支撑了这些机遇。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'That memory is discouraging political innovation today.'</span><span class="p">,</span>
  <span class="s1">'如今，这段记忆阻碍人们进行政治创新。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'They are just buying real estate because they need it.'</span><span class="p">,</span>
  <span class="s1">'他们购置不动产时出于实际的需要。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Sixth, the authors admiringly cite the British experience.'</span><span class="p">,</span>
  <span class="s1">'第六，作者们以敬仰之情援引了英国的经验。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Are banks, markets, or regulators to blame?'</span><span class="p">,</span> <span class="s1">'我们应该归罪于银行、市场或监管者么？'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Moreover, Ukraine has strong investment and consumption growth.'</span><span class="p">,</span>
  <span class="s1">'此外，乌克兰投资和消费增长强劲。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Another factor that has been overlooked is the Chinese consumer.'</span><span class="p">,</span>
  <span class="s1">'中国消费者是一直被忽视的另外一个因素。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Europe&rsquo;s leaders must imbue their citizens with renewed hope.'</span><span class="p">,</span>
  <span class="s1">'欧洲领导人必须让民众看到新的希望。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Moreover, discrimination in India often begins in the family.'</span><span class="p">,</span>
  <span class="s1">'此外，印度的歧视往往从家庭就开始了。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Mueller obviously hopes to &ldquo;flip&rdquo; both Flynn and Manafort.'</span><span class="p">,</span>
  <span class="s1">'米勒显然希望策反弗林和马纳福特。'</span><span class="p">),</span>
 <span class="p">(</span><span class="s1">'Others continue to advocate for national reconciliation.'</span><span class="p">,</span>
  <span class="s1">'也有人继续宣传民族和解才能解决问题。'</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create a custom subwords tokenizer from the training dataset.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TODO">TODO<a class="anchor-link" href="#TODO">&para;</a></h3><p>依照不同 split 選擇不同 vocab files</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_perc</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>90</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">en_vocab_file</span> <span class="o">=</span> <span class="n">en_vocab_file</span> <span class="o">+</span> <span class="s2">"_"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_perc</span><span class="p">)</span>
<span class="n">zh_vocab_file</span> <span class="o">=</span> <span class="n">zh_vocab_file</span> <span class="o">+</span> <span class="s2">"_"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_perc</span><span class="p">)</span>
<span class="p">[</span>
    <span class="n">en_vocab_file</span><span class="p">,</span> 
    <span class="n">zh_vocab_file</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>['/content/gdrive/My Drive/nmt/en_vocab_90',
 '/content/gdrive/My Drive/nmt/zh_vocab_90']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
try:
    tokenizer_en = tfds.features.text.SubwordTextEncoder.load_from_file(en_vocab_file)
    print(f"Vocab file loaded from {en_vocab_file}")
except:
    tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(
        (en.numpy() for en, _ in train_examples), target_vocab_size=2**13)
    
    tokenizer_en.save_to_file(en_vocab_file)
    print(f"Build from corpus and saved to {en_vocab_file}")
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Build from corpus and saved to /content/gdrive/My Drive/nmt/en_vocab_90
CPU times: user 4min 39s, sys: 25.2 s, total: 5min 4s
Wall time: 3min 45s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>
try:
    tokenizer_zh = tfds.features.text.SubwordTextEncoder.load_from_file(zh_vocab_file)
    print(f"Vocab file loaded from {zh_vocab_file}")
except:
    tokenizer_zh = tfds.features.text.SubwordTextEncoder.build_from_corpus(
    (zh.numpy() for _, zh in train_examples), target_vocab_size=2**17, max_subword_length=1)
    
    tokenizer_zh.save_to_file(zh_vocab_file)
    print(f"Build from corpus and saved to {zh_vocab_file}")
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Build from corpus and saved to /content/gdrive/My Drive/nmt/zh_vocab_90
CPU times: user 38min 43s, sys: 25.8 s, total: 39min 9s
Wall time: 37min 57s
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(8159, 4849)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_string</span> <span class="o">=</span> <span class="s1">'Transformer is awesome.'</span>

<span class="n">tokenized_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">'Tokenized string is </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">))</span>

<span class="n">original_string</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">'The original string: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">original_string</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">original_string</span> <span class="o">==</span> <span class="n">sample_string</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tokenized string is [2728, 466, 9, 3354, 145, 1355, 7949]
The original string: Transformer is awesome.
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokenized_string</span><span class="p">:</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'</span><span class="si">{}</span><span class="s1"> ----&gt; </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">ts</span><span class="p">])))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>2728 ----&gt; Trans
466 ----&gt; former 
9 ----&gt; is 
3354 ----&gt; aw
145 ----&gt; es
1355 ----&gt; ome
7949 ----&gt; .
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_string</span> <span class="o">=</span> <span class="n">sample_examples</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

<span class="n">tokenized_string</span> <span class="o">=</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sample_string</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">'Tokenized string is </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">))</span>

<span class="n">original_string</span> <span class="o">=</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenized_string</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">'The original string: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">original_string</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">original_string</span> <span class="o">==</span> <span class="n">sample_string</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tokenized string is [260, 25, 24, 16, 4, 28, 176, 553, 49, 6, 1108, 269, 1, 7, 25, 3]
The original string: 今年对中国来说又将是艰难的一年。
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The tokenizer encodes the string by breaking it into subwords if the word is not in its dictionary.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tokenized_string</span><span class="p">:</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'</span><span class="si">{}</span><span class="s1"> ----&gt; </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">ts</span><span class="p">])))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>260 ----&gt; 今
25 ----&gt; 年
24 ----&gt; 对
16 ----&gt; 中
4 ----&gt; 国
28 ----&gt; 来
176 ----&gt; 说
553 ----&gt; 又
49 ----&gt; 将
6 ----&gt; 是
1108 ----&gt; 艰
269 ----&gt; 难
1 ----&gt; 的
7 ----&gt; 一
25 ----&gt; 年
3 ----&gt; 。
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">128</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Add a start and end token to the input and target.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span><span class="p">):</span>
  <span class="n">lang1</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang1</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

  <span class="n">lang2</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
      <span class="n">lang2</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="p">[</span><span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
  
  <span class="k">return</span> <span class="n">lang1</span><span class="p">,</span> <span class="n">lang2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note: To keep this example small and relatively fast, drop examples with a length of over 40 tokens.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">40</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">filter_max_length</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">,</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Operations inside <code>.map()</code> run in graph mode and receive a graph tensor that do not have a numpy attribute. The <code>tokenizer</code> expects a string or Unicode symbol to encode it into integers. Hence, you need to run the encoding inside a <code>tf.py_function</code>, which receives an eager tensor having a numpy attribute that contains the string value.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tf_encode</span><span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">py_function</span><span class="p">(</span><span class="n">encode</span><span class="p">,</span> <span class="p">[</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">],</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_examples</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span>
<span class="c1"># cache the dataset to memory to get a speedup while reading from it.</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span>
    <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>


<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_examples</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf_encode</span><span class="p">)</span>
<span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_max_length</span><span class="p">)</span><span class="o">.</span><span class="n">padded_batch</span><span class="p">(</span>
    <span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">padded_shapes</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">en_batch</span><span class="p">,</span> <span class="n">zh_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">))</span>
<span class="n">en_batch</span><span class="p">,</span> <span class="n">zh_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>W0526 09:21:16.849860 140617539618560 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0526 09:21:16.851555 140617539618560 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0526 09:21:16.874526 140617548011264 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0526 09:21:16.876014 140617548011264 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
W0526 09:21:16.881912 140617539618560 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(&lt;tf.Tensor: id=2935815, shape=(128, 40), dtype=int64, numpy=
 array([[8159,  424,  778, ...,    0,    0,    0],
        [8159,  129,   47, ...,    0,    0,    0],
        [8159, 5097,  565, ...,    0,    0,    0],
        ...,
        [8159,  609,  614, ...,    0,    0,    0],
        [8159,   86,  586, ...,    0,    0,    0],
        [8159,   40,   41, ...,    0,    0,    0]])&gt;,
 &lt;tf.Tensor: id=2935816, shape=(128, 40), dtype=int64, numpy=
 array([[4849,   10,   66, ...,  427,    3, 4850],
        [4849,   69,  227, ...,    0,    0,    0],
        [4849,    9,  160, ...,    0,    0,    0],
        ...,
        [4849,   35,    6, ...,    0,    0,    0],
        [4849,   10,    7, ...,    0,    0,    0],
        [4849,   35,   10, ...,    0,    0,    0]])&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Positional-encoding_1">Positional encoding<a class="anchor-link" href="#Positional-encoding">&para;</a></h2><p>Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence.</p>
<p>The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the <em>similarity of their meaning and their position in the sentence</em>, in the d-dimensional space.</p>
<p>See the notebook on <a href="https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb">positional encoding</a> to learn more about it. The formula for calculating the positional encoding is as follows:</p>
<p>$$\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$
$$\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_angles</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
  <span class="n">angle_rates</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">d_model</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">pos</span> <span class="o">*</span> <span class="n">angle_rates</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">positional_encoding</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
  <span class="n">angle_rads</span> <span class="o">=</span> <span class="n">get_angles</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">position</span><span class="p">)[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
                          <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d_model</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span>
                          <span class="n">d_model</span><span class="p">)</span>
  
  <span class="c1"># apply sin to even indices in the array; 2i</span>
  <span class="n">sines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
  <span class="c1"># apply cos to odd indices in the array; 2i+1</span>
  <span class="n">cosines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angle_rads</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>
  
  <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">sines</span><span class="p">,</span> <span class="n">cosines</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  
  <span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
    
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"seaborn-notebook"</span><span class="p">)</span>
<span class="c1"># plt.style.use("ggplot")</span>
<span class="c1"># plt.style.use("fivethirtyeight")</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">pos_encoding</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span><span class="n">pos_encoding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'RdBu'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Depth'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Position'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(1, 50, 512)
</pre>
</div>
</div>
<div class="output_area">
<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAecAAAFfCAYAAAB0lARMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Masking">Masking<a class="anchor-link" href="#Masking">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value <code>0</code> is present: it outputs a <code>1</code> at those locations, and a <code>0</code> otherwise.</p>
<p>實際上在 Transformer 裡頭有兩種 masks：</p>
<ul>
<li>padding mask</li>
<li>look ahead mask</li>
</ul>
<p>前者是讓 Transformer 用來識別 sequence 實際的內容到哪裡；後者則是讓 Decoder 在生成輸出序列的時候，不會不小心看到未來的句子。</p>
<p>mask 序列裡頭那些值為 1 的位置即為未來會被遮蓋住的位置。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_padding_mask</span><span class="p">(</span><span class="n">seq</span><span class="p">):</span>
  <span class="n">seq</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  
  <span class="c1"># add extra dimensions so that we can add the padding</span>
  <span class="c1"># to the attention logits.</span>
  <span class="k">return</span> <span class="n">seq</span><span class="p">[:,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, 1, 1, seq_len)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>而這邊之所以要新增兩個 dimensions 是因為在 Multi-Head Attention 裡頭一組 attention logits 的維度為 <code>(batch_size, num_heads, seq_len, seq_len)</code>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
                 <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">create_padding_mask</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=2935832, shape=(3, 1, 1, 5), dtype=float32, numpy=
array([[[[0., 0., 1., 1., 1.]]],


       [[[0., 0., 0., 1., 1.]]],


       [[[0., 0., 0., 0., 0.]]]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Tensor 裡頭為 <code>1</code> 的位置的值在之後的計算就會忽略。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.</p>
<p>This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_look_ahead_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mask</span>  <span class="c1"># (seq_len, seq_len)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">temp</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>&lt;tf.Tensor: id=2935848, shape=(3, 3), dtype=float32, numpy=
array([[0., 1., 1.],
       [0., 0., 1.],
       [0., 0., 0.]], dtype=float32)&gt;</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>第一維度代表處理次數，而可以看得出來，第二維度從上到下就代表 Decoder 在產生翻譯時每次能看到的位置。</p>
<p>第一個時間點只能看到第一個位置，以此類推。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TODO_1">TODO<a class="anchor-link" href="#TODO">&para;</a></h3><p>增加 ene-to-end 例子</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># dec_target_padding_mask = create_padding_mask(tar)</span>
<span class="c1"># print(dec_target_padding_mask)</span>
<span class="c1"># look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])</span>
<span class="c1"># print(look_ahead_mask)</span>
<span class="c1"># tf.maximum(dec_target_padding_mask, look_ahead_mask)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Scaled-dot-product-attention_1">Scaled dot product attention<a class="anchor-link" href="#Scaled-dot-product-attention">&para;</a></h2><p>在實作 Multi-head 之前，先讓我們實作基本的 Attention 機制。</p>
<p>注意力機制基本上可以想成資料庫比對。給定一個查詢 Q，我們去看該 Q 跟所有 K 的匹配程度，接著以此匹配程度對實際的 V 做加權平均，得到最後的 Repr.</p>
<p>$$Attention(Q, K, V) = softmax({QK^T \over \sqrt{d_{k}}})V $$</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img alt="scaled_dot_product_attention" src="https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png" width="500"/></p>
<p>The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:</p>
<p>$$\Large{Attention(Q, K, V) = softmax_k(\frac{QK^T}{\sqrt{d_k}}) V} $$</p>
<p>The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax.</p>
<p>For example, consider that <code>Q</code> and <code>K</code> have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of <code>dk</code>. Hence, <em>square root of <code>dk</code></em> is used for scaling (and not any other number) because the matmul of <code>Q</code> and <code>K</code> should have a mean of 0 and variance of 1, so that we get a gentler softmax.</p>
<p>The mask is multiplied with <em>-1e9 (close to negative infinity).</em> This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install pysnooper
<span class="kn">import</span> <span class="nn">pysnooper</span>
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># @pysnooper.snoop()</span>

<span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
  <span class="sd">"""Calculate the attention weights.</span>
<span class="sd">  q, k, v must have matching leading dimensions.</span>
<span class="sd">  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.</span>
<span class="sd">  The mask has different shapes depending on its type(padding or look ahead) </span>
<span class="sd">  but it must be broadcastable for addition.</span>
<span class="sd">  </span>
<span class="sd">  Args:</span>
<span class="sd">    q: query shape == (..., seq_len_q, depth)</span>
<span class="sd">    k: key shape == (..., seq_len_k, depth)</span>
<span class="sd">    v: value shape == (..., seq_len_v, depth_v)</span>
<span class="sd">    mask: Float tensor with shape broadcastable </span>
<span class="sd">          to (..., seq_len_q, seq_len_k). Defaults to None.</span>
<span class="sd">    </span>
<span class="sd">  Returns:</span>
<span class="sd">    output, attention_weights</span>
<span class="sd">  """</span>

  <span class="n">matmul_qk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)</span>
  
  <span class="c1"># scale matmul_qk</span>
  <span class="n">dk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">k</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">scaled_attention_logits</span> <span class="o">=</span> <span class="n">matmul_qk</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dk</span><span class="p">)</span>

  <span class="c1"># add the mask to the scaled tensor.</span>
  <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">scaled_attention_logits</span> <span class="o">+=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="o">-</span><span class="mf">1e9</span><span class="p">)</span>

  <span class="c1"># softmax is normalized on the last axis (seq_len_k) so that the scores</span>
  <span class="c1"># add up to 1.</span>
  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scaled_attention_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (..., seq_len_q, seq_len_k)</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>  <span class="c1"># (..., seq_len_v, depth_v)</span>

  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>很大的負值丟入 Softmax 函式以後會接近 0 ，則如果我們想把後三個位置遮住丟入 softmax 的話，則 mask 應該要是 [..., 0, 1, 1, 1] （要被遮住的位置的 mask 值為 1），再乘上 -1e9 以後加入 scaled_attention_logits 即可讓後三個位置經過 softmax 出來的值為 0</p>
<p>As the softmax normalization is done on K, its values decide the amount of importance given to Q.</p>
<p>The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words we want to focus on are kept as is and the irrelevant words are flushed out.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_out</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
  <span class="n">temp_out</span><span class="p">,</span> <span class="n">temp_attn</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
      <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'Attention weights are:'</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="n">temp_attn</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'Output is:'</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="n">temp_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">temp_k</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (4, 3)</span>

<span class="n">temp_v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span>   <span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span>  <span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
                      <span class="p">[</span> <span class="mi">100</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
                      <span class="p">[</span><span class="mi">1000</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (4, 2)</span>

<span class="c1"># This `query` aligns with the second `key`,</span>
<span class="c1"># so the second `value` is returned.</span>
<span class="n">temp_q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 3)</span>

<span class="c1"># print_out(temp_q, temp_k, temp_v)</span>
<span class="n">temp_out</span><span class="p">,</span> <span class="n">temp_attn</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
      <span class="n">temp_q</span><span class="p">,</span> <span class="n">temp_k</span><span class="p">,</span> <span class="n">temp_v</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This query aligns with a repeated key (third and fourth), </span>
<span class="c1"># so all associated values get averaged.</span>
<span class="n">temp_q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 3)</span>
<span class="n">print_out</span><span class="p">(</span><span class="n">temp_q</span><span class="p">,</span> <span class="n">temp_k</span><span class="p">,</span> <span class="n">temp_v</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Attention weights are:
tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)
Output is:
tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This query aligns equally with the first and second key, </span>
<span class="c1"># so their values get averaged.</span>
<span class="n">temp_q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (1, 3)</span>
<span class="n">print_out</span><span class="p">(</span><span class="n">temp_q</span><span class="p">,</span> <span class="n">temp_k</span><span class="p">,</span> <span class="n">temp_v</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Attention weights are:
tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)
Output is:
tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Pass all the queries together.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">temp_q</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (3, 3)</span>
<span class="n">print_out</span><span class="p">(</span><span class="n">temp_q</span><span class="p">,</span> <span class="n">temp_k</span><span class="p">,</span> <span class="n">temp_v</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Attention weights are:
tf.Tensor(
[[0.  0.  0.5 0.5]
 [0.  1.  0.  0. ]
 [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)
Output is:
tf.Tensor(
[[550.    5.5]
 [ 10.    0. ]
 [  5.5   0. ]], shape=(3, 2), dtype=float32)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Multi-head-attention">Multi-head attention<a class="anchor-link" href="#Multi-head-attention">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img alt="multi-head attention" src="https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png" width="500"/></p>
<p>Multi-head attention consists of four parts:</p>
<ul>
<li>Linear layers and split into heads.</li>
<li>Scaled dot-product attention.</li>
<li>Concatenation of heads.</li>
<li>Final linear layer.</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.</p>
<p>The <code>scaled_dot_product_attention</code> defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using <code>tf.transpose</code>, and <code>tf.reshape</code>) and put through a final <code>Dense</code> layer.</p>
<p>Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    
    <span class="k">assert</span> <span class="n">d_model</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">==</span> <span class="mi">0</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">wq</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wk</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        
  <span class="k">def</span> <span class="nf">split_heads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="sd">"""Split the last dimension into (num_heads, depth).</span>
<span class="sd">    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)</span>
<span class="sd">    """</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">q</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wq</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wv</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
    
    <span class="n">q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_q, depth)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_k, depth)</span>
    <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_heads</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>  <span class="c1"># (batch_size, num_heads, seq_len_v, depth)</span>
    
    <span class="c1"># scaled_attention.shape == (batch_size, num_heads, seq_len_v, depth)</span>
    <span class="c1"># attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)</span>
    <span class="n">scaled_attention</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">scaled_dot_product_attention</span><span class="p">(</span>
        <span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    
    <span class="n">scaled_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># (batch_size, seq_len_v, num_heads, depth)</span>

    <span class="n">concat_attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">scaled_attention</span><span class="p">,</span> 
                                  <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>  <span class="c1"># (batch_size, seq_len_v, d_model)</span>

    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">concat_attention</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len_v, d_model)</span>
        
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create a <code>MultiHeadAttention</code> layer to try out. At each location in the sequence, <code>y</code>, the <code>MultiHeadAttention</code> runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">temp_mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>  <span class="c1"># (batch_size, encoder_sequence, d_model)</span>
<span class="n">out</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">temp_mha</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attn</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Point-wise-feed-forward-network">Point wise feed forward network<a class="anchor-link" href="#Point-wise-feed-forward-network">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">dff</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>  <span class="c1"># (batch_size, seq_len, dff)</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>  <span class="c1"># (batch_size, seq_len, d_model)</span>
  <span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>
<span class="n">sample_ffn</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([64, 50, 512])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Encoder-and-decoder">Encoder and decoder<a class="anchor-link" href="#Encoder-and-decoder">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img alt="transformer" src="https://www.tensorflow.org/images/tutorials/transformer/transformer.png" width="600"/></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The transformer model follows the same general pattern as a standard <a href="nmt_with_attention.ipynb">sequence to sequence with attention model</a>.</p>
<ul>
<li>The input sentence is passed through <code>N</code> encoder layers that generates an output for each word/token in the sequence.</li>
<li>The decoder attends on the encoder's output and its own input (self-attention) to predict the next word. </li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoder-layer">Encoder layer<a class="anchor-link" href="#Encoder-layer">&para;</a></h3><p>Each encoder layer consists of sublayers:</p>
<ol>
<li>Multi-head attention (with padding mask) </li>
<li>Point wise feed forward networks. </li>
</ol>
<p>Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.</p>
<p>The output of each sublayer is <code>LayerNorm(x + Sublayer(x))</code>. The normalization is done on the <code>d_model</code> (last) axis. There are N encoder layers in the transformer.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">EncoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EncoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mha</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>

    <span class="n">attn_output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
    <span class="n">attn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">attn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
    
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">out1</span> <span class="o">+</span> <span class="n">ffn_output</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
    
    <span class="k">return</span> <span class="n">out2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_encoder_layer</span> <span class="o">=</span> <span class="n">EncoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

<span class="n">sample_encoder_layer_output</span> <span class="o">=</span> <span class="n">sample_encoder_layer</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">43</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">sample_encoder_layer_output</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([64, 43, 512])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoder-layer">Decoder layer<a class="anchor-link" href="#Decoder-layer">&para;</a></h3><p>Each decoder layer consists of sublayers:</p>
<ol>
<li>Masked multi-head attention (with look ahead mask and padding mask)</li>
<li>Multi-head attention (with padding mask). V (value) and K (key) receive the <em>encoder output</em> as inputs. Q (query) receives the <em>output from the masked multi-head attention sublayer.</em></li>
<li>Point wise feed forward networks</li>
</ol>
<p>Each of these sublayers has a residual connection around it followed by a layer normalization. The output of each sublayer is <code>LayerNorm(x + Sublayer(x))</code>. The normalization is done on the <code>d_model</code> (last) axis.</p>
<p>There are N decoder layers in the transformer.</p>
<p>As Q receives the output from decoder's first attention block, and K receives the encoder output, the attention weights represent the importance given to the decoder's input based on the encoder's output. In other words, the decoder predicts the next word by looking at the encoder output and self-attending to its own output. See the demonstration above in the scaled dot product attention section.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DecoderLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DecoderLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">point_wise_feed_forward_network</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dff</span><span class="p">)</span>
 
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>
    <span class="c1"># enc_output.shape == (batch_size, input_seq_len, d_model)</span>

    <span class="n">attn1</span><span class="p">,</span> <span class="n">attn_weights_block1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    <span class="n">attn1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">attn1</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm1</span><span class="p">(</span><span class="n">attn1</span> <span class="o">+</span> <span class="n">x</span><span class="p">)</span>
    
    <span class="n">attn2</span><span class="p">,</span> <span class="n">attn_weights_block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mha2</span><span class="p">(</span>
        <span class="n">enc_output</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">out1</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    <span class="n">attn2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">attn2</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm2</span><span class="p">(</span><span class="n">attn2</span> <span class="o">+</span> <span class="n">out1</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    <span class="n">ffn_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">ffn_output</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">out3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layernorm3</span><span class="p">(</span><span class="n">ffn_output</span> <span class="o">+</span> <span class="n">out2</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    
    <span class="k">return</span> <span class="n">out3</span><span class="p">,</span> <span class="n">attn_weights_block1</span><span class="p">,</span> <span class="n">attn_weights_block2</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_decoder_layer</span> <span class="o">=</span> <span class="n">DecoderLayer</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">2048</span><span class="p">)</span>

<span class="n">sample_decoder_layer_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_decoder_layer</span><span class="p">(</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">512</span><span class="p">)),</span> <span class="n">sample_encoder_layer_output</span><span class="p">,</span> 
    <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">sample_decoder_layer_output</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([64, 50, 512])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoder">Encoder<a class="anchor-link" href="#Encoder">&para;</a></h3><p>The <code>Encoder</code> consists of:</p>
<ol>
<li>Input Embedding</li>
<li>Positional Encoding</li>
<li>N encoder layers</li>
</ol>
<p>The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    
    
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">EncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
  
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
        
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>

    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># adding embedding and position encoding.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
                         <span class="n">dff</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">8500</span><span class="p">)</span>

<span class="n">sample_encoder_output</span> <span class="o">=</span> <span class="n">sample_encoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">62</span><span class="p">)),</span> 
                                       <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="n">sample_encoder_output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (batch_size, input_seq_len, d_model)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>(64, 62, 512)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoder">Decoder<a class="anchor-link" href="#Decoder">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>Decoder</code> consists of:</p>
<ol>
<li>Output Embedding</li>
<li>Positional Encoding</li>
<li>N decoder layers</li>
</ol>
<p>The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
               <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">positional_encoding</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">DecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span> 
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> 
           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">):</span>

    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">attention_weights</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># (batch_size, target_seq_len, d_model)</span>
    <span class="n">x</span> <span class="o">*=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:]</span>
    
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">block1</span><span class="p">,</span> <span class="n">block2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                                             <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
      
      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">'decoder_layer</span><span class="si">{}</span><span class="s1">_block1'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block1</span>
      <span class="n">attention_weights</span><span class="p">[</span><span class="s1">'decoder_layer</span><span class="si">{}</span><span class="s1">_block2'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">block2</span>
    
    <span class="c1"># x.shape == (batch_size, target_seq_len, d_model)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> 
                         <span class="n">dff</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>

<span class="n">output</span><span class="p">,</span> <span class="n">attn</span> <span class="o">=</span> <span class="n">sample_decoder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">26</span><span class="p">)),</span> 
                              <span class="n">enc_output</span><span class="o">=</span><span class="n">sample_encoder_output</span><span class="p">,</span> 
                              <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                              <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">attn</span><span class="p">[</span><span class="s1">'decoder_layer2_block2'</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Create-the-Transformer_1">Create the Transformer<a class="anchor-link" href="#Create-the-Transformer">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> <span class="n">input_vocab_size</span><span class="p">,</span> 
               <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
                           <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span> 
                           <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">)</span>
    
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">,</span> 
           <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">):</span>

    <span class="n">enc_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">enc_padding_mask</span><span class="p">)</span>  <span class="c1"># (batch_size, inp_seq_len, d_model)</span>
    
    <span class="c1"># dec_output.shape == (batch_size, tar_seq_len, d_model)</span>
    <span class="n">dec_output</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
        <span class="n">tar</span><span class="p">,</span> <span class="n">enc_output</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span><span class="p">)</span>
    
    <span class="n">final_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_layer</span><span class="p">(</span><span class="n">dec_output</span><span class="p">)</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)</span>
    
    <span class="k">return</span> <span class="n">final_output</span><span class="p">,</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">dff</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> 
    <span class="n">input_vocab_size</span><span class="o">=</span><span class="mi">8500</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="o">=</span><span class="mi">8000</span><span class="p">)</span>

<span class="n">temp_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">62</span><span class="p">))</span>
<span class="n">temp_target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">26</span><span class="p">))</span>

<span class="n">fn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sample_transformer</span><span class="p">(</span><span class="n">temp_input</span><span class="p">,</span> <span class="n">temp_target</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                               <span class="n">enc_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                               <span class="n">look_ahead_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                               <span class="n">dec_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">fn_out</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># (batch_size, tar_seq_len, target_vocab_size)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>TensorShape([64, 26, 8000])</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Set-hyperparameters">Set hyperparameters<a class="anchor-link" href="#Set-hyperparameters">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To keep this example small and relatively fast, the values for <em>num_layers, d_model, and dff</em> have been reduced.</p>
<p>The values used in the base model of transformer were; <em>num_layers=6</em>, <em>d_model = 512</em>, <em>dff = 2048</em>. See the <a href="https://arxiv.org/abs/1706.03762">paper</a> for all the other versions of the transformer.</p>
<p>Note: By changing the values below, you can get the model that achieved state of the art on many tasks.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_layers</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">d_model</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">dff</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>

<span class="n">input_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">2</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(8161, 4851)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Setup-experiment-path">Setup experiment path<a class="anchor-link" href="#Setup-experiment-path">&para;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">run_id</span> <span class="o">=</span> <span class="n">f</span><span class="s2">"</span><span class="si">{num_layers}</span><span class="s2">layers_</span><span class="si">{d_model}</span><span class="s2">d_</span><span class="si">{num_heads}</span><span class="s2">heads_</span><span class="si">{dff}</span><span class="s2">dff_</span><span class="si">{train_perc}</span><span class="s2">train_perc"</span>
<span class="n">run_id</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>'4layers_128d_8heads_512dff_90train_perc'</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">run_id</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span>
    <span class="n">checkpoint_path</span><span class="p">,</span>
    <span class="n">log_dir</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>['/content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc',
 '/content/gdrive/My Drive/nmt/logs/4layers_128d_8heads_512dff_90train_perc']</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Optimizer_1">Optimizer<a class="anchor-link" href="#Optimizer">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Use the Adam optimizer with a custom learning rate scheduler according to the formula in the <a href="https://arxiv.org/abs/1706.03762">paper</a>.</p>
<p>$$\Large{lrate = d_{model}^{-0.5} * min(step{\_}num^{-0.5}, step{\_}num * warmup{\_}steps^{-1.5})}$$</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">CustomSchedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">4000</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CustomSchedule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">=</span> <span class="n">warmup_steps</span>
    
  <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="n">arg1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
    <span class="n">arg2</span> <span class="o">=</span> <span class="n">step</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">warmup_steps</span> <span class="o">**</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> 
                                     <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"seaborn-whitegrid"</span><span class="p">)</span>
<span class="c1"># plt.style.use("ggplot")</span>
<span class="c1"># plt.style.use("fivethirtyeight")</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">temp_learning_rate_schedule</span> <span class="o">=</span> <span class="n">CustomSchedule</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">temp_learning_rate_schedule</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">40000</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Learning Rate"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Train Step"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 0, 'Train Step')</pre>
</div>
</div>
<div class="output_area">
<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAFYCAYAAAAlTUT9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># temp_learning_rate_schedule.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-and-metrics">Loss and metrics<a class="anchor-link" href="#Loss-and-metrics">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the target sequences are padded, it is important to apply a padding mask when calculating the loss.</p>
<p>這邊 <code>reduction</code> 設成 <code>none</code> 是因為我們會套用 mask 以後自己 sum up</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss_object</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span>
    <span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">'none'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">loss_</span> <span class="o">=</span> <span class="n">loss_object</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

  <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">loss_</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
  <span class="n">loss_</span> <span class="o">*=</span> <span class="n">mask</span>
  
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">loss_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'train_loss'</span><span class="p">)</span>
<span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'train_accuracy'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># real = tf.constant([1, 1, 0], shape=(1, 3), dtype=tf.float32)</span>
<span class="c1"># pred = tf.constant([[0, 1], [0, 1], [0, 1]], dtype=tf.float32)</span>
<span class="c1"># loss_object(real, pred)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># tf.keras.losses.SparseCategoricalCrossentropy(</span>
<span class="c1">#     from_logits=True)(real, pred)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-and-checkpointing">Training and checkpointing<a class="anchor-link" href="#Training-and-checkpointing">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dff</span><span class="p">,</span>
                          <span class="n">input_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
  <span class="c1"># Encoder padding mask</span>
  <span class="n">enc_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
  
  <span class="c1"># Used in the 2nd attention block in the decoder.</span>
  <span class="c1"># This padding mask is used to mask the encoder outputs.</span>
  <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
  
  <span class="c1"># Used in the 1st attention block in the decoder.</span>
  <span class="c1"># It is used to pad and mask future tokens in the input received by </span>
  <span class="c1"># the decoder.</span>
  <span class="n">look_ahead_mask</span> <span class="o">=</span> <span class="n">create_look_ahead_mask</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tar</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
  <span class="n">dec_target_padding_mask</span> <span class="o">=</span> <span class="n">create_padding_mask</span><span class="p">(</span><span class="n">tar</span><span class="p">)</span>
  <span class="n">combined_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">dec_target_padding_mask</span><span class="p">,</span> <span class="n">look_ahead_mask</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">tar</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">inp</span><span class="p">,</span> <span class="n">tar</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>(&lt;tf.Tensor: id=2940903, shape=(3, 4), dtype=float32, numpy=
 array([[1., 2., 3., 0.],
        [2., 2., 5., 6.],
        [5., 1., 0., 0.]], dtype=float32)&gt;,
 &lt;tf.Tensor: id=2940904, shape=(3, 3), dtype=float32, numpy=
 array([[2., 5., 1.],
        [3., 4., 0.],
        [1., 0., 0.]], dtype=float32)&gt;)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create_padding_mask(inp)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># dec_target_padding_mask = create_padding_mask(tar)</span>
<span class="c1"># print(dec_target_padding_mask)</span>
<span class="c1"># look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])</span>
<span class="c1"># print(look_ahead_mask)</span>
<span class="c1"># tf.maximum(dec_target_padding_mask, look_ahead_mask)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every <code>n</code> epochs.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">ckpt_manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># if a checkpoint exists, restore the latest checkpoint.</span>
<span class="k">if</span> <span class="n">ckpt_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
  <span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">ckpt_manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'Latest checkpoint restored!!'</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Start from scratch!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Start from scratch!
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. <code>tar_real</code> is that same input shifted by 1: At each location in <code>tar_input</code>, <code>tar_real</code> contains the  next token that should be predicted.</p>
<p>For example, <code>sentence</code> = "SOS A lion in the jungle is sleeping EOS"</p>
<p><code>tar_inp</code> =  "SOS A lion in the jungle is sleeping"</p>
<p><code>tar_real</code> = "A lion in the jungle is sleeping EOS"</p>
<p>The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next.</p>
<p>During training this example uses teacher-forcing (like in the <a href="./text_generation.ipynb">text generation tutorial</a>). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.</p>
<p>As the transformer predicts each word, <em>self-attention</em> allows it to look at the previous words in the input sequence to better predict the next word.</p>
<p>To prevent the model from peaking at the expected output the model uses a look-ahead mask.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">50</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">):</span>
  <span class="n">tar_inp</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">tar_real</span> <span class="o">=</span> <span class="n">tar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
  
  <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">)</span>
  
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar_inp</span><span class="p">,</span> 
                                 <span class="kc">True</span><span class="p">,</span> 
                                 <span class="n">enc_padding_mask</span><span class="p">,</span> 
                                 <span class="n">combined_mask</span><span class="p">,</span> 
                                 <span class="n">dec_padding_mask</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

  <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>    
  <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">transformer</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
  
  <span class="n">train_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
  <span class="n">train_accuracy</span><span class="p">(</span><span class="n">tar_real</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>英文是我們的來源語言，而我們目標則是將其轉成（簡體）中文。因此 <code>inp</code> 為 <code>en</code>，<code>tar</code> 為 <code>zh</code>。</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># @pysnooper.snoop()</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">):</span>
  <span class="n">start_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span>
  <span class="n">end_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
  
  <span class="c1"># inp sentence is english, hence adding the start and end token</span>
  <span class="n">inp_sentence</span> <span class="o">=</span> <span class="n">start_token</span> <span class="o">+</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">)</span> <span class="o">+</span> <span class="n">end_token</span>
  <span class="n">encoder_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inp_sentence</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
  
  <span class="c1"># as the target is chinese, the first word to the transformer should be the</span>
  <span class="c1"># chinese start token.</span>
  <span class="n">decoder_input</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">]</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
    <span class="n">enc_padding_mask</span><span class="p">,</span> <span class="n">combined_mask</span><span class="p">,</span> <span class="n">dec_padding_mask</span> <span class="o">=</span> <span class="n">create_masks</span><span class="p">(</span>
        <span class="n">encoder_input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
  
    <span class="c1"># predictions.shape == (batch_size, seq_len, vocab_size)</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">encoder_input</span><span class="p">,</span> 
                                                 <span class="n">output</span><span class="p">,</span>
                                                 <span class="kc">False</span><span class="p">,</span>
                                                 <span class="n">enc_padding_mask</span><span class="p">,</span>
                                                 <span class="n">combined_mask</span><span class="p">,</span>
                                                 <span class="n">dec_padding_mask</span><span class="p">)</span>
    
    <span class="c1"># select the last word from the seq_len dimension</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[:</span> <span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># (batch_size, 1, vocab_size)</span>

    <span class="n">predicted_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="c1"># return the result if the predicted_id is equal to the end token</span>
    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">predicted_id</span><span class="p">,</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">attention_weights</span>
    
    <span class="c1"># concatentate the predicted_id to the output which is given to the decoder</span>
    <span class="c1"># as its input.</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">output</span><span class="p">,</span> <span class="n">predicted_id</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Chinese-font-setup-for-matplotlib">Chinese font setup for matplotlib<a class="anchor-link" href="#Chinese-font-setup-for-matplotlib">&para;</a></h3><p>reference</p>
<ul>
<li><a href="https://www.jianshu.com/p/fc9a502ad243">https://www.jianshu.com/p/fc9a502ad243</a></li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>wget -O /usr/share/fonts/truetype/liberation/simhei.ttf <span class="err">\</span>
    <span class="s2">"http://d.xiazaiziti.com/en_fonts/fonts/s/SimHei.ttf"</span>
<span class="c1"># !test NotoSans-unhinted.zip || wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSans-unhinted.zip</span>
<span class="c1"># !test -d fonts || mkdir fonts</span>
<span class="c1"># !unzip -d fonts NotoSans-unhinted.zip</span>
<span class="c1"># !cp fonts/NotoSans* /usr/share/fonts/truetype/liberation/</span>
<span class="c1"># clear_output()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>--2019-05-26 09:21:29--  http://d.xiazaiziti.com/en_fonts/fonts/s/SimHei.ttf
Resolving d.xiazaiziti.com (d.xiazaiziti.com)... 67.198.189.58
Connecting to d.xiazaiziti.com (d.xiazaiziti.com)|67.198.189.58|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 10050868 (9.6M) [application/octet-stream]
Saving to: &lsquo;/usr/share/fonts/truetype/liberation/simhei.ttf&rsquo;

/usr/share/fonts/tr 100%[===================&gt;]   9.58M  4.17MB/s    in 2.3s    

2019-05-26 09:21:32 (4.17 MB/s) - &lsquo;/usr/share/fonts/truetype/liberation/simhei.ttf&rsquo; saved [10050868/10050868]

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="c1"># zhfont = mpl.font_manager.FontProperties(fname='/usr/share/fonts/truetype/liberation/NotoSans-Regular.ttf')</span>
<span class="n">zhfont</span> <span class="o">=</span> <span class="n">mpl</span><span class="o">.</span><span class="n">font_manager</span><span class="o">.</span><span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s1">'/usr/share/fonts/truetype/liberation/simhei.ttf'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"seaborn-whitegrid"</span><span class="p">)</span>
<span class="c1"># plt.style.use("fivethirtyeight")</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># @pysnooper.snoop()</span>
<span class="k">def</span> <span class="nf">plot_attention_weights</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_file_name</span><span class="o">=</span><span class="s1">''</span><span class="p">):</span>
    
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
  
  <span class="n">sentence</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
  
  <span class="c1"># for pretty rendering intermidate result</span>
  <span class="k">if</span> <span class="n">max_len_tar</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="p">[:</span><span class="n">max_len_tar</span><span class="p">]</span>
  
  <span class="n">attention</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">attention</span><span class="p">[</span><span class="n">layer</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  
  <span class="k">for</span> <span class="n">head</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">attention</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">head</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># plot the attention weights</span>
    <span class="k">if</span> <span class="n">max_len_tar</span><span class="p">:</span>
      <span class="n">attn_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">attention</span><span class="p">[</span><span class="n">head</span><span class="p">][:</span><span class="n">max_len_tar</span><span class="p">,</span> <span class="p">:])</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attn_map</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>  <span class="c1"># (inp_seq_len, tar_seq_len)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">attn_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">attention</span><span class="p">[</span><span class="n">head</span><span class="p">])</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">attn_map</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>
    <span class="n">fontdict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"fontproperties"</span><span class="p">:</span> <span class="n">zhfont</span><span class="p">}</span>
    
    <span class="k">if</span> <span class="n">max_len_tar</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">max_len_tar</span><span class="p">:</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_len_tar</span><span class="p">))</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_len_tar</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)))</span>
      <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span><span class="o">+</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">result</span> 
                        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">],</span> 
                       <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>    
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">(</span>
        <span class="p">[</span><span class="s1">'&lt;start&gt;'</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">tokenizer_en</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="s1">'&lt;end&gt;'</span><span class="p">],</span> 
        <span class="n">fontdict</span><span class="o">=</span><span class="n">fontdict</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Head </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">head</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"y"</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
  
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

  
  <span class="k">if</span> <span class="ow">not</span> <span class="n">save_file_name</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">save_file_name</span><span class="p">)</span>
    
  <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
  <span class="n">result</span><span class="p">,</span> <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
  
  <span class="n">predicted_sentence</span> <span class="o">=</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">result</span> 
                                            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">tokenizer_zh</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">])</span>  
  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Input: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Predicted translation: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">predicted_sentence</span><span class="p">))</span>
  
  <span class="k">if</span> <span class="n">plot</span><span class="p">:</span>
    <span class="n">plot_attention_weights</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">result</span><span class="p">,</span> <span class="n">plot</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">predicted_sentence</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TODO_2">TODO<a class="anchor-link" href="#TODO">&para;</a></h3><p>依照層數自動選最後一層 vis</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># plot_layer_block = ""</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translation</span> <span class="o">=</span> <span class="n">translate</span><span class="p">(</span><span class="n">sample_examples</span><span class="p">[</span><span class="mi">14</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> 
          <span class="n">plot</span><span class="o">=</span><span class="s1">'decoder_layer4_block2'</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Input: Are banks, markets, or regulators to blame?
Predicted translation: 丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁丁娿娿娿娿娿娿娿娿娿丁丁丁丁丁
</pre>
</div>
</div>
<div class="output_area">
<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABMAAAAHMCAYAAAAzsNRKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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"/>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># inp_sentence = "America"</span>
<span class="c1"># result, attention_weights = evaluate(inp_sentence)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># def translate(sentence):</span>
<span class="c1">#   result, attention_weights = evaluate(sentence)</span>
  
<span class="c1">#   predicted_sentence = tokenizer_zh.decode([i for i in result </span>
<span class="c1">#                                             if i &lt; tokenizer_zh.vocab_size])  </span>

<span class="c1">#   print('Input: {}'.format(sentence))</span>
<span class="c1">#   print('Predicted translation: {}'.format(predicted_sentence))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># predicted_sentence = tokenizer_zh.decode([i for i in result </span>
<span class="c1">#                                             if i &lt; tokenizer_zh.vocab_size])  </span>

<span class="c1"># print('Input: {}'.format(inp_sentence))</span>
<span class="c1"># print('Predicted translation: {}'.format(predicted_sentence))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tensorboard_1">Tensorboard<a class="anchor-link" href="#Tensorboard">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> tensorboard
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span><span class="nb">kill</span> <span class="m">692</span>
<span class="o">%</span><span class="k">tensorboard</span> --logdir /content/gdrive/My\ Drive/nmt/logs
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>/bin/bash: line 0: kill: (692) - No such process
</pre>
</div>
</div>
<div class="output_area">
<div class="output_html rendered_html output_subarea ">
<div id="root"></div>
<script>
      (function() {
        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};
        window.TENSORBOARD_ENV["IN_COLAB"] = true;
        document.querySelector("base").href = "https://localhost:6006";
        function fixUpTensorboard(root) {
          const tftb = root.querySelector("tf-tensorboard");
          // Disable the fragment manipulation behavior in Colab. Not
          // only is the behavior not useful (as the iframe's location
          // is not visible to the user), it causes TensorBoard's usage
          // of `window.replace` to navigate away from the page and to
          // the `localhost:<port>` URL specified by the base URI, which
          // in turn causes the frame to (likely) crash.
          tftb.removeAttribute("use-hash");
        }
        function executeAllScripts(root) {
          // When `script` elements are inserted into the DOM by
          // assigning to an element's `innerHTML`, the scripts are not
          // executed. Thus, we manually re-insert these scripts so that
          // TensorBoard can initialize itself.
          for (const script of root.querySelectorAll("script")) {
            const newScript = document.createElement("script");
            newScript.type = script.type;
            newScript.textContent = script.textContent;
            root.appendChild(newScript);
            script.remove();
          }
        }
        function setHeight(root, height) {
          // We set the height dynamically after the TensorBoard UI has
          // been initialized. This avoids an intermediate state in
          // which the container plus the UI become taller than the
          // final width and cause the Colab output frame to be
          // permanently resized, eventually leading to an empty
          // vertical gap below the TensorBoard UI. It's not clear
          // exactly what causes this problematic intermediate state,
          // but setting the height late seems to fix it.
          root.style.height = `${height}px`;
        }
        const root = document.getElementById("root");
        fetch(".")
          .then((x) => x.text())
          .then((html) => void (root.innerHTML = html))
          .then(() => fixUpTensorboard(root))
          .then(() => executeAllScripts(root))
          .then(() => setHeight(root, 800));
      })();
    </script>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">summary_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_examples</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">zh</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>
  
<span class="n">track_sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"China, India, and others have enjoyed continuing economic growth."</span><span class="p">,</span>
    <span class="s2">"When that happens, a recession typically follows."</span><span class="p">,</span>
    <span class="s2">"In fact, central banks typically only have very fuzzy measures."</span><span class="p">,</span>
    <span class="s2">"Given the reaction in financial markets, they have succeeded."</span><span class="p">,</span>
    <span class="s2">"Moreover, discrimination in India often begins in the family."</span><span class="p">,</span>
    <span class="s2">"Europe&rsquo;s leaders must imbue their citizens with renewed hope."</span><span class="p">,</span>
    <span class="s2">"Are banks, markets, or regulators to blame?"</span>
<span class="p">]</span>


<span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">track_sentences</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
  <span class="n">name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="s2">"s_</span><span class="si">{:02d}</span><span class="s2">_attn_epoch_</span><span class="si">{:02d}</span><span class="s2">.png"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s_idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">translate</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="s1">'decoder_layer4_block2'</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">save_file_name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
  
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">EPOCHS</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>50</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  
  <span class="n">train_loss</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  <span class="n">train_accuracy</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>
  
  <span class="c1"># inp -&gt; english, tar -&gt; chinese</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">))</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">):</span>
    <span class="n">train_step</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">tar</span><span class="p">)</span>
    
<span class="c1">#     if batch % 100 == 0:</span>
<span class="c1">#       print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(</span>
<span class="c1">#           epoch + 1, batch, train_loss.result(), train_accuracy.result()))</span>
      
  <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">ckpt_save_path</span> <span class="o">=</span> <span class="n">ckpt_manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s1">'Saving checkpoint for epoch </span><span class="si">{}</span><span class="s1"> at </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
                                                         <span class="n">ckpt_save_path</span><span class="p">))</span>
    

  <span class="c1"># tensorboard</span>
  <span class="k">with</span> <span class="n">summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">"train_loss"</span><span class="p">,</span> <span class="n">train_loss</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s2">"train_acc"</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1"> Loss </span><span class="si">{:.4f}</span><span class="s1"> Accuracy </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> 
                                                <span class="n">train_loss</span><span class="o">.</span><span class="n">result</span><span class="p">(),</span> 
                                                <span class="n">train_accuracy</span><span class="o">.</span><span class="n">result</span><span class="p">()))</span>
  <span class="nb">print</span> <span class="p">(</span><span class="s1">'Time taken for 1 epoch: </span><span class="si">{}</span><span class="s1"> secs</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
    
  <span class="c1"># intermidate translation</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_examples</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="n">translate</span><span class="p">(</span><span class="n">en</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">summary_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">en</span><span class="p">,</span> <span class="n">translation</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  
  <span class="c1"># attention vis by time</span>
  <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">track_sentences</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="s2">"s_</span><span class="si">{:02d}</span><span class="s2">_attn_epoch_</span><span class="si">{:02d}</span><span class="s2">.png"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">translation</span> <span class="o">=</span> <span class="n">translate</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="s1">'decoder_layer4_block2'</span><span class="p">,</span> <span class="n">max_len_tar</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">save_file_name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>Saving checkpoint for epoch 1 at /content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc/ckpt-1
Epoch 1 Loss 4.0243 Accuracy 0.0911
Time taken for 1 epoch: 502.05626130104065 secs

Saving checkpoint for epoch 2 at /content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc/ckpt-2
Epoch 2 Loss 2.6707 Accuracy 0.2102
Time taken for 1 epoch: 288.889924287796 secs

Saving checkpoint for epoch 3 at /content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc/ckpt-3
Epoch 3 Loss 2.2492 Accuracy 0.2600
Time taken for 1 epoch: 283.77642273902893 secs

Saving checkpoint for epoch 4 at /content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc/ckpt-4
Epoch 4 Loss 1.9446 Accuracy 0.3051
Time taken for 1 epoch: 282.2802734375 secs

Saving checkpoint for epoch 5 at /content/gdrive/My Drive/nmt/checkpoints/4layers_128d_8heads_512dff_90train_perc/ckpt-5
Epoch 5 Loss 1.7020 Accuracy 0.3426
Time taken for 1 epoch: 284.10588788986206 secs

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Evaluate">Evaluate<a class="anchor-link" href="#Evaluate">&para;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following steps are used for evaluation:</p>
<ul>
<li>Encode the input sentence using the Portuguese tokenizer (<code>tokenizer_pt</code>). Moreover, add the start and end token so the input is equivalent to what the model is trained with. This is the encoder input.</li>
<li>The decoder input is the <code>start token == tokenizer_en.vocab_size</code>.</li>
<li>Calculate the padding masks and the look ahead masks.</li>
<li>The <code>decoder</code> then outputs the predictions by looking at the <code>encoder output</code> and its own output (self-attention).</li>
<li>Select the last word and calculate the argmax of that.</li>
<li>Concatentate the predicted word to the decoder input as pass it to the decoder.</li>
<li>In this approach, the decoder predicts the next word based on the previous words it predicted.</li>
</ul>
<p>Note: The model used here has less capacity to keep the example relatively faster so the predictions maybe less right. To reproduce the results in the paper, use the entire dataset and base transformer model or transformer XL, by changing the hyperparameters above.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># def evaluate(inp_sentence):</span>
<span class="c1">#   start_token = [tokenizer_zh.vocab_size]</span>
<span class="c1">#   end_token = [tokenizer_zh.vocab_size + 1]</span>
  
<span class="c1">#   # inp sentence is portuguese, hence adding the start and end token</span>
<span class="c1">#   inp_sentence = start_token + tokenizer_zh.encode(inp_sentence) + end_token</span>
<span class="c1">#   encoder_input = tf.expand_dims(inp_sentence, 0)</span>
  
<span class="c1">#   # as the target is english, the first word to the transformer should be the</span>
<span class="c1">#   # english start token.</span>
<span class="c1">#   decoder_input = [tokenizer_en.vocab_size]</span>
<span class="c1">#   output = tf.expand_dims(decoder_input, 0)</span>
    
<span class="c1">#   for i in range(MAX_LENGTH):</span>
<span class="c1">#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(</span>
<span class="c1">#         encoder_input, output)</span>
  
<span class="c1">#     # predictions.shape == (batch_size, seq_len, vocab_size)</span>
<span class="c1">#     predictions, attention_weights = transformer(encoder_input, </span>
<span class="c1">#                                                  output,</span>
<span class="c1">#                                                  False,</span>
<span class="c1">#                                                  enc_padding_mask,</span>
<span class="c1">#                                                  combined_mask,</span>
<span class="c1">#                                                  dec_padding_mask)</span>
    
<span class="c1">#     # select the last word from the seq_len dimension</span>
<span class="c1">#     predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)</span>

<span class="c1">#     predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)</span>
    
<span class="c1">#     # return the result if the predicted_id is equal to the end token</span>
<span class="c1">#     if tf.equal(predicted_id, tokenizer_en.vocab_size+1):</span>
<span class="c1">#       return tf.squeeze(output, axis=0), attention_weights</span>
    
<span class="c1">#     # concatentate the predicted_id to the output which is given to the decoder</span>
<span class="c1">#     # as its input.</span>
<span class="c1">#     output = tf.concat([output, predicted_id], axis=-1)</span>

<span class="c1">#   return tf.squeeze(output, axis=0), attention_weights</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="inner_cell">
<div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># def plot_attention_weights(attention, sentence, result, layer):</span>
<span class="c1">#   fig = plt.figure(figsize=(8, 16))</span>
  
<span class="c1">#   sentence = tokenizer_en.encode(sentence)</span>
  
<span class="c1">#   attention = tf.squeeze(attention[layer], axis=0)</span>
  
<span class="c1">#   for head in range(attention.shape[0]):</span>
<span class="c1">#     ax = fig.add_subplot(4, 2, head+1)</span>
    
<span class="c1">#     # plot the attention weights</span>
<span class="c1">#     ax.matshow(attention[head][:-1, :], cmap='viridis')</span>

<span class="c1">#     fontdict = {'fontsize': 10, "fontproperties": zhfont}</span>
    
<span class="c1">#     ax.set_xticks(range(len(sentence)+2))</span>
<span class="c1">#     ax.set_yticks(range(len(result)))</span>
    
<span class="c1">#     ax.set_ylim(len(result)-1.5, -0.5)</span>
        
<span class="c1">#     ax.set_xticklabels(</span>
<span class="c1">#         ['&lt;start&gt;']+[tokenizer_en.decode([i]) for i in sentence]+['&lt;end&gt;'], </span>
<span class="c1">#         fontdict=fontdict, rotation=90)</span>
    
<span class="c1">#     ax.set_yticklabels([tokenizer_zh.decode([i]) for i in result </span>
<span class="c1">#                         if i &lt; tokenizer_zh.vocab_size], </span>
<span class="c1">#                        fontdict=fontdict)</span>
    
<span class="c1">#     ax.set_xlabel('Head {}'.format(head+1))</span>
  
<span class="c1">#   plt.tight_layout()</span>
<span class="c1">#   plt.show()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can pass different layers and attention blocks of the decoder to the <code>plot</code> parameter.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&para;</a></h2><p>In this tutorial, you learned about positional encoding, multi-head attention, the importance of masking and how to create a transformer.</p>
<p>Try using a different dataset to train the transformer. You can also create the base transformer or transformer XL by changing the hyperparameters above. You can also use the layers defined here to create <a href="https://arxiv.org/abs/1810.04805">BERT</a> and train state of the art models. Futhermore, you can implement beam search to get better predictions.</p>
</div>
</div>
</div>


                <!-- Tags -->
                <p class="blog-content__tags">
                    <span>Post Tags</span>

                    <span class="blog-content__tag-list">
                        <a href="https://leemeng.tw/tag/zi-ran-yu-yan-chu-li.html" rel="tag">自然語言處理</a>
                        <a href="https://leemeng.tw/tag/nlp.html" rel="tag">NLP</a>
                        <a href="https://leemeng.tw/tag/tensorflow.html" rel="tag">Tensorflow</a>
                    </span>

                </p>













































































                <!-- end Tags -->


                <!-- Mail-list-subscribe -->
                <div id="article-inner-subscribe" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                        <div class="blog-content__prev">
                            <a class="open-popup" rel="subscribe">
                                <span>Get Latest Arrivals</span>
                                訂閱最新文章
                            </a>
                        </div>
                        <div class="blog-content__next">
                            <p>
                                跟資料科學相關的最新文章直接送到家。</br>
                                只要加入訂閱名單，當新文章出爐時，</br>
                                你將能馬上收到通知 <i class="im im-newspaper-o" aria-hidden="true"></i>
                            </p>
                        </div>
                    </div>
                    <div class="blog-content__all">
                        <a class="open-popup btn btn--primary " style="color: #FFFFFF">&nbsp;&nbsp;Subscribe&nbsp;&nbsp;&nbsp;</a>
                    </div>
                </div>
                <!-- end Mail-list-subscribe -->

                <!--Pagination-->
                <div id="article-inner-neighbor-pages" class="blog-content__pagenav">
                    <div class="blog-content__nav">
                    </div>

                    <div class="blog-content__all">
                        <a href="blog.html" class="btn btn--primary">
                            View All Post
                        </a>
                    </div>
                </div>
                <!-- end Pagination-->

            </div><!-- end blog-content__main -->


        </div>
        </div> <!-- end blog-content -->

    </article>

<div class="comments-wrap">
    <div id="comments" class="row">
        <div class="col-full">
            <div id="disqus_thread"></div>
        </div>
    </div>
</div>

<script type="text/javascript">
var disqus_shortname = 'leemengtaiwan';
var disqus_title = '淺談神經機器翻譯：如何用 Transformer 以及 Tensorflow 2 實現英中翻譯';

(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


    <!-- footer
    ================================================== -->
    <footer>
        <div class="row">
            <div class="col-full">

                <div class="footer-logo">
                    <a class="footer-site-logo" href="#0"><img src="https://leemeng.tw/theme/images/logo.png" alt="Homepage"></a>
                </div>

                <ul class="footer-social">
<li><a href="https://github.com/leemengtaiwan" target="_blank">
    <i class="im im-github" aria-hidden="true"></i>
    <span>Github</span>
</a></li>
<li><a href="https://www.facebook.com/LeeMengTaiwan" target="_blank">
    <i class="im im-facebook" aria-hidden="true"></i>
    <span>Facebook</span>
</a></li>
<li><a href="https://www.instagram.com/leemengtaiwan/" target="_blank">
    <i class="im im-instagram" aria-hidden="true"></i>
    <span>Instagram</span>
</a></li>
<li><a href="https://www.linkedin.com/in/leemeng1990/" target="_blank">
    <i class="im im-linkedin" aria-hidden="true"></i>
    <span>LinkedIn</span>
</a></li>                </ul>
            </div>
        </div>

        <div class="row footer-bottom">
            <div class="col-twelve">
                <div class="copyright">
                    <span>Powered by <a href="http://getpelican.com/" target="_blank">Pelican</a></span>
                    <span>© Copyright Hola 2017</span>
                    <span>Design by <a href="https://www.styleshout.com/" target="_blank">styleshout</a></span>
                </div>

                <div class="go-top">
                <a class="smoothscroll" title="Back to Top" href="#top"><i class="im im-arrow-up" aria-hidden="true"></i></a>
                </div>
            </div>
        </div> <!-- end footer-bottom -->
    </footer> <!-- end footer -->


    <div id="preloader">
        <div id="loader"></div>
    </div>

        <!-- Javascript
    ================================================== -->
    <script src="https://leemeng.tw/theme/js/jquery-3.2.1.min.js"></script>
    <script src="https://leemeng.tw/theme/js/plugins.js"></script>
    <script src="https://leemeng.tw/theme/js/main.js"></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--https://instant.page/-->
    <script src="//instant.page/1.0.0" type="module" integrity="sha384-6w2SekMzCkuMQ9sEbq0cLviD/yR2HfA/+ekmKiBnFlsoSvb/VmQFSi/umVShadQI"></script>


    <script type='text/javascript' src='https://leemeng.tw/theme/js/progress-bar.js'></script>
    <script type='text/javascript' src='https://leemeng.tw/theme/js/scroll-detect.js'></script>

    <!--show and hide left navigation by scrolling-->
    <script>
    $(document).scroll(function() {
        var y = $(this).scrollTop();
      if ( $(window).width() > 980 ) {
        if (y > 600) {
          $('#left-navigation').fadeIn(300);
        } else {
          $('#left-navigation').fadeOut(300);
        }
      }
    });
    </script>

<!--reference: https://gist.github.com/scottmagdalein/259d878ad46ed6f2cdce-->
<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false">
</script>

<script type="text/javascript">
  function showMailingPopUp() {
    require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us18.list-manage.com","uuid":"151cb59f2de814c499c76b77a","lid":"dd1d78cc5e"})})
    document.cookie = "MCPopupClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
    document.cookie = "MCPopupSubscribed=; expires=Thu, 01 Jan 1970 00:00:00 UTC";
  };

  $(function() {
    $(".open-popup").on('click', function() {
      showMailingPopUp();
    });
  });
</script>
<!--reference: https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_overlay-->
<script>
function openTocNav() {
    document.getElementById("tocNav").style.width = "100%";
}

function closeTocNav() {
    document.getElementById("tocNav").style.width = "0%";
}

function toggleTocNav() {
    var current_width = document.getElementById("tocNav").style.width;
    if (current_width == "100%") {
        document.getElementById("tocNav").style.width = "0%";
    } else {
        document.getElementById("tocNav").style.width = "100%";
    }
}

function closeLeftNavImage(elementId) {
    document.getElementById(elementId).style.width = "0%";
}

function toggleLeftNavImage(elementId) {
    var current_width = document.getElementById(elementId).style.width;
    if (current_width == "100%") {
        document.getElementById(elementId).style.width = "0%";
    } else {
        document.getElementById(elementId).style.width = "100%";
    }
}

</script>


</body>
</html>